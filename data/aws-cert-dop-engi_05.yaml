- en: 'Chapter 4: Amazon S3 Blob Storage'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章：Amazon S3 Blob 存储
- en: Amazon S3 is one of the core tenants of Amazon Web Services. However, in the
    context of being a DevOps professional, there are certain nuances about the service
    that you must not only familiarize yourself with but also become comfortable with
    implementing.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon S3 是 Amazon Web Services 的核心组成部分之一。然而，在 DevOps 专业人员的上下文中，有一些关于该服务的细微差别，你不仅需要熟悉它们，还需要在实施时感到得心应手。
- en: Amazon's **Simple Storage Service** (**S3**) is the entry point for many users
    and companies looking to get into the cloud. Some of the main features it provides
    are being highly available, exceedingly durable, extremely performant, and easily
    managed, along with the ability to be thoroughly secure. One of the major features
    of S3 is its eleven 9's of durability (99.999999999%), which means that it doesn't
    lose objects or data. Once you upload an object, before it returns the 200 success
    status, that object must be copied to multiple systems in multiple Availability
    Zones to prevent data loss in an array of scenarios.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊的**简单存储服务**（**S3**）是许多用户和公司进入云计算的入口。它提供的一些主要特点是高度可用、极其耐用、性能卓越并且易于管理，同时具备彻底的安全性。S3
    的一个主要特点是其 11 个 9 的耐用性（99.999999999%），这意味着它不会丢失对象或数据。一旦你上传一个对象，在返回 200 成功状态之前，该对象必须复制到多个系统和多个可用区，以防止在各种场景下的数据丢失。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要内容：
- en: S3 concepts
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3 概念
- en: Using lifecycle policies in S3
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 S3 中使用生命周期策略
- en: Using S3 events to trigger other AWS services
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 S3 事件触发其他 AWS 服务
- en: S3 access logs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3 访问日志
- en: S3 endpoints
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3 端点
- en: S3 concepts
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: S3 概念
- en: 'Before we dive into S3, let''s at least briefly talk about the three distinct
    types of cloud storage:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解 S3 之前，让我们简要了解一下三种不同类型的云存储：
- en: '**Object storage** – Data is saved as an object and is bundled with the associated
    metadata of that object.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对象存储** – 数据作为对象保存，并与该对象的相关元数据一起打包。'
- en: '**File storage** – Data is stored as a single piece of information in a folder
    structure.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文件存储** – 数据作为单个信息存储在文件夹结构中。'
- en: '**Block storage** – Data and files are separated into blocks. Each of these
    blocks is then stored as a separate piece of data.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**块存储** – 数据和文件被分隔成块。每个块作为独立的数据片段进行存储。'
- en: S3 is an object storage service, and although it seems to have a folder structure,
    this is really just the metadata that is tagged to the object in key/value pairs
    so that the data can be categorized more efficiently.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: S3 是一种对象存储服务，尽管它看起来有文件夹结构，但实际上这只是附加到对象上的元数据，通过键/值对的方式，使数据可以更高效地分类。
- en: 'Once an S3 bucket has been created, then not only is it ready for data, but
    it is also at that point almost infinitely scalable. There are also a number of
    helper services that AWS has created to assist you in moving data into S3\. These
    range from streaming solutions such as Amazon Kinesis to **SSH File Transfer Protocol**
    (**SFTP**) alternatives such as AWS SFTP, and even bulk data load services such
    as AWS Snowball and Snowball Edge:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了 S3 桶，不仅可以存储数据，而且此时它几乎是无限可扩展的。AWS 还创建了许多辅助服务，帮助你将数据迁移到 S3。它们包括像 Amazon
    Kinesis 这样的流式解决方案、AWS SFTP 等 **SSH 文件传输协议**（**SFTP**）替代方案，甚至像 AWS Snowball 和 Snowball
    Edge 这样的批量数据加载服务：
- en: '![Figure 4.1 – S3 options for data transfer'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.1 – 数据传输的 S3 选项'
- en: '](img/Figure_4.1_B17405.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_4.1_B17405.jpg)'
- en: Figure 4.1 – S3 options for data transfer
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – 数据传输的 S3 选项
- en: By default, AWS accounts are allowed to provision up to one hundred S3 buckets.
    This is a soft limit, and if you need more buckets this can be raised by placing
    a service limit increase ticket.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，AWS 账户最多可以创建 100 个 S3 桶。这是一个软性限制，如果需要更多的桶，可以通过提交服务限制提升请求来增加该数量。
- en: Interacting with S3
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与 S3 的交互
- en: Users have a few ways to interact with S3, starting with the AWS console. This
    will show you a graphical listing of your buckets and display your objects in
    a folder-like format based on the object tags that you have given the different
    objects.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 用户有几种与 S3 交互的方式，从 AWS 控制台开始。通过它，你可以图形化地列出你的桶，并根据你为不同对象指定的标签，以文件夹形式展示你的对象。
- en: As you become more comfortable with S3 and its capabilities, you might find
    that the console requires more than one click to perform simple tasks such as
    deleting a file, and this is where the CLI and knowing its commands can become
    your ally.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 随着您对 S3 及其功能的熟悉，您可能会发现，控制台需要多个点击才能执行诸如删除文件之类的简单操作，这时 CLI 和掌握其命令可以成为您的有力助手。
- en: 'In the AWS CLI, there are a few base commands that you can use to interact
    with S3:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AWS CLI 中，有一些基础命令可以用来与 S3 交互：
- en: There is the base `aws s3` command – this command gives you the ability to perform
    nine basic operations, such as creating a bucket, listing buckets or their contents,
    and even creating a pre-signed URL for access to a bucket.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 还有基础的 `aws s3` 命令——该命令使您能够执行九种基本操作，例如创建桶、列出桶或其内容，甚至创建一个预签名 URL 以访问桶。
- en: There is the `aws s3api` command – this command provides a different set of
    secondary commands for the items in the base `s3` command.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 还有 `aws s3api` 命令——该命令为基础 `s3` 命令中的项目提供了一组不同的二级命令。
- en: The `aws s3control` command allows you granular access to the S3 control plane.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aws s3control` 命令允许您对 S3 控制面板进行精细化访问。'
- en: And finally, there is the `aws s3outposts` command – this command provides access
    to S3 on AWS Outposts.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，还有 `aws s3outposts` 命令——该命令提供对 AWS Outposts 上 S3 的访问。
- en: S3 naming guidelines
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: S3 命名指南
- en: Every S3 bucket name across all of AWS must be unique, not just in your account.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 AWS 上的 S3 桶名称必须是唯一的，不仅仅是在您的账户中。
- en: 'When you create your bucket, there are a few rules that you must follow in
    order for the name to be compliant with S3:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 创建桶时，您必须遵循一些规则，以确保名称符合 S3 的要求：
- en: A bucket name must be at least 3 but no longer than 63 characters long.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 桶名称的长度必须至少为 3 个字符，最多不超过 63 个字符。
- en: Bucket names can only be made up of numbers, lowercase letters, dots (.), and
    hyphens (-).
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 桶名称只能由数字、小写字母、点号 (.) 和连字符 (-) 组成。
- en: A bucket name must start and end with either a number or a letter.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 桶名称必须以数字或字母开头和结尾。
- en: Bucket names cannot start with the name `xn–`.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 桶名称不能以 `xn–` 开头。
- en: A bucket name may not be formatted like an IP address (such as `192.168.2.1`).
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 桶名称不能像 IP 地址那样格式化（例如 `192.168.2.1`）。
- en: It's also Amazon's recommendation that you do not use dots (.) in your bucket
    names unless you are using the S3 bucket for static web hosting.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊还建议，除非您将 S3 桶用于静态网页托管，否则不要在桶名称中使用点号 (.)。
- en: Bucket names for enterprises
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 企业的桶名称
- en: The preceding rules are the minimum guidelines for naming S3 buckets. As you
    move into the real world, most large organizations that are already in the AWS
    cloud have a bucket naming scheme. Some small and medium firms still do not have
    organizational standards relating to how to name their S3 buckets, but this can
    be a mistake.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 前述规则是命名 S3 桶的最低标准。随着您进入实际应用，大多数已经在 AWS 云中的大型组织都有桶命名方案。某些中小型企业仍然没有关于如何命名 S3 桶的组织标准，但这可能是一个错误。
- en: S3 buckets are very easy to create, not only for developers but for almost anyone
    that has access to the service. The issue arises when you start to find buckets
    that are named like `mytest-bucket123`. Once again, this comes back to those initial
    principles of trying to figure out things like who the owner of this data is and
    whether it needs to be replicated for safekeeping or can be safely deleted.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: S3 桶非常容易创建，不仅开发人员可以创建，几乎任何有权限访问该服务的人都可以创建。问题出现在您开始遇到像 `mytest-bucket123` 这样的桶名称时。再一次，这与最初的原则有关，即如何弄清楚谁是这些数据的拥有者，以及是否需要为了安全存储而复制这些数据，或是否可以安全删除。
- en: 'As you move to an enterprise naming scheme, you and your organization need
    to come to a consensus regarding a uniform naming standard for the buckets in
    the accounts for which you are responsible:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 随着您进入企业命名方案，您和您的组织需要就负责账户中桶的统一命名标准达成共识：
- en: '![Figure 4.2 – Enterprise bucket naming example'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.2 – 企业桶命名示例'
- en: '](img/Figure_4.2_B17405.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_4.2_B17405.jpg)'
- en: Figure 4.2 – Enterprise bucket naming example
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 企业桶命名示例
- en: Using an abbreviated schema such as `<region>-<environment>-<department>-<product>-<identifier>`
    creates a unique name for each bucket that still stays within AWS naming standards.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用如 `<region>-<environment>-<department>-<product>-<identifier>` 这样的简化模式，可以为每个桶创建一个唯一的名称，并且仍然符合
    AWS 的命名标准。
- en: This helps to quickly identify who owns each bucket and allows teams and account
    managers to sort and search through resources quickly and easily, not only identifying
    who created the buckets by the product or project they belong to. This is shown
    in *Figure 4.2* and with the bucket named `oh-d-devops-pip-cont1`. This is bucket
    name is shorthand for `ohio-development-devops-pipeline-containers`.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这有助于快速识别每个存储桶的所有者，并允许团队和账户管理员快速、轻松地排序和搜索资源，不仅能按产品或项目区分谁创建了存储桶。这在 *图 4.2* 中显示，并且存储桶名称为
    `oh-d-devops-pip-cont1`。这个存储桶名称是 `ohio-development-devops-pipeline-containers`
    的简写。
- en: Creating an S3 bucket
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建 S3 存储桶
- en: 'If you want to back up your instance either for point-in-time recovery purposes
    or to use in a launch configuration with autoscaling, then you need to create
    an AMI image:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想备份实例，无论是为了恢复目的还是用于自动扩展中的启动配置，则需要创建一个 AMI 镜像：
- en: Launch an `EC2` instance.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动一个 `EC2` 实例。
- en: 'We need to have an instance to back up and create the AMI:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要一个实例来备份并创建 AMI：
- en: '[PRE0]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: You will need to use a different bucket name than the one shown in this example.
    You can name your bucket anything you like as long as you stick to the S3 naming
    guidelines.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您需要使用与示例中不同的存储桶名称。只要遵守 S3 命名规则，您可以随意命名存储桶。
- en: 'If it was successful, then you should see the following output:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果成功，您应该看到以下输出：
- en: '[PRE1]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You now have a bucket we can work with. If you wanted to see the bucket in
    the command line, we could list it with the following command:'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在您有了一个我们可以操作的存储桶。如果你想在命令行中查看存储桶，可以使用以下命令列出它：
- en: '[PRE2]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This bucket that we just created is now ready to hold files, media, logs, or
    whatever you'd like to store in it at this point.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们刚刚创建的这个存储桶现在已经准备好存放文件、媒体、日志或您希望存储的任何内容。
- en: Moving data to S3
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数据迁移到 S3
- en: At this point, we have now created at least one bucket. As we go through later
    exercises, you'll notice that some of the AWS services create buckets in your
    account, such as **CloudFormation**.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，我们至少创建了一个存储桶。随着后续操作的进行，您会注意到一些 AWS 服务会在您的账户中创建存储桶，例如 **CloudFormation**。
- en: If we were simply trying to move items one at a time or a folder at a time,
    then we could use the AWS Management Console or the CLI using the `aws s3 copy`
    command.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只是尝试一次迁移一个项目或一个文件夹，那么我们可以使用 AWS 管理控制台或 CLI 中的 `aws s3 copy` 命令。
- en: If we had a server that was generating logs, and we wanted to put those logs
    into an S3 bucket for either storage, backup, analysis, or a combination of those
    options, then we could use the `aws s3 sync` command. The `s3 sync` command will
    sync all objects in the stated folder with the specified bucked in S3\. This works
    extremely well in concert with a `cron` or cron-like job for enacting the command
    on a schedule.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一台生成日志的服务器，并且希望将这些日志存储到 S3 存储桶中，用于存储、备份、分析或这些选项的组合，那么我们可以使用`aws s3 sync`命令。`s3
    sync`命令将同步指定文件夹中的所有对象与 S3 中指定的存储桶。这与 `cron` 或类似的计划任务一起使用时效果极佳，可以按照预定计划执行该命令。
- en: When trying to move a whole server or data center, it can be time-consuming
    to try and push all the files and objects across the wire. This is where the **Snowball**
    family of services comes into play. A **Snowball Edge Storage Optimized** (**SESO**)
    allows secure transport of your data with up to 80 TB of usable hard disk drive
    storage, which, after being uploaded to the device and shipped to AWS, is then
    offloaded to an S3 bucket that you designate.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当试图迁移整个服务器或数据中心时，尝试通过网络推送所有文件和对象可能会非常耗时。在这种情况下，**Snowball** 系列服务就派上用场了。**Snowball
    Edge 存储优化版**（**SESO**）允许安全地传输最多 80 TB 可用硬盘存储的数据，数据上传到设备后，再运送到 AWS，最终被卸载到您指定的 S3
    存储桶中。
- en: S3 inventory
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: S3 清单
- en: 'Using the list command to see the different objects in your bucket is helpful
    until you start to have tens of thousands to millions of objects in your buckets.
    At that point, it can be helpful to have a more powerful tool at your disposal.
    **S3 inventory** was created for just this purpose. The S3 inventory tool creates
    a report, which is then delivered to another bucket and provides information about
    your objects on items such as the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用列出命令查看存储桶中不同对象非常有用，直到你开始拥有成千上万到百万级别的对象。当达到这个数量时，拥有一个更强大的工具就显得尤为重要。**S3 清单**就是为这个目的而创建的。S3
    清单工具会创建一份报告，然后将其交付到另一个存储桶中，并提供有关您的对象的各种信息，如以下内容：
- en: Creation date
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建日期
- en: Storage class
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储类
- en: Encryption status
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加密状态
- en: Replication status
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复制状态
- en: Object size
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象大小
- en: You have the option to encrypt the reports either with SSE-S3 or with a **Key
    Management Service** (**KMS**) key of your choosing.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择使用 SSE-S3 或 **密钥管理服务**（**KMS**）密钥对报告进行加密。
- en: Once the reports have been delivered, then you can use tools such as Amazon
    Athena to query the reports using Standard SQL, looking for trends or anomalies.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦报告生成完成，您可以使用 Amazon Athena 等工具使用标准 SQL 查询报告，寻找趋势或异常。
- en: S3 inventory does come with a small cost to generate the reports (less than
    .003 cents per million objects); however, it should not be assumed that the tool
    comes with the S3 service for free.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: S3 清单报告生成需要小额费用（每百万个对象少于 0.003 美分）；但不应假定该工具是免费的，它是 S3 服务的一部分。
- en: S3 storage tiers
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: S3 存储层
- en: The Amazon S3 service has a collection of different storage tiers that can serve
    different needs as well as different cost structures. The default storage tier
    is the standard storage tier, although this is not always the correct choice for
    storing your data, especially if your organization is looking for long-term storage
    and/or cost savings.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 S3 服务有一系列不同的存储层，可以满足不同的需求以及不同的成本结构。默认存储层是标准存储层，尽管这并不总是存储数据的正确选择，特别是当您的组织需要长期存储和/或寻求节省成本时。
- en: You can create lifecycle policies to move your objects from one storage tier
    to another or even be deleted if the object is unneeded after a set period of
    time.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以创建生命周期策略，将对象从一个存储层移动到另一个存储层，或者在一段时间后如果对象不再需要则删除它。
- en: S3 Standard
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: S3 Standard
- en: Once you initially set up a bucket, by default, without specifying any other
    storage tier, it will be in the S3 Standard tier. This is a highly available general
    access storage policy that provides millisecond access to objects when requesting
    their retrieval. Although this is the costliest of all the storage tiers, S3 Standard
    storage is extremely inexpensive when compared to other types of storage services
    like file and block storage.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您初次设置了一个存储桶，默认情况下，除非指定其他存储层，否则它将位于 S3 Standard 层。这是一个高可用性的通用访问存储策略，提供毫秒级别的对象访问。尽管这是所有存储层中最昂贵的，但与其他类型的存储服务（如文件存储和块存储）相比，S3
    Standard 存储非常便宜。
- en: 'Key points to remember about S3 Standard:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的关于 S3 Standard 的要点：
- en: The Standard tier provides high throughput and low latency and performance for
    object uploads and downloads.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Standard 层提供高吞吐量、低延迟和对象上传与下载的性能。
- en: If no other storage tier is indicated, then Standard is the default storage
    class.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有指定其他存储层，则 Standard 是默认的存储类。
- en: Crafted for 99.99% availability during a given year.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计为每年 99.99% 的可用性。
- en: Ideal for objects that need frequent access.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适合需要频繁访问的对象。
- en: Ideal for use cases such as data lakes, cloud-native applications, websites,
    and content distribution.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适合用于数据湖、云原生应用、网站和内容分发等用例。
- en: S3 Intelligent-Tiering
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: S3 智能分层（Intelligent-Tiering）
- en: There are times when you might think that the algorithm that Amazon has derived
    to move your objects to the different tiers of storage may be more efficient than
    any you may be able to come up with. This is a perfect case of when to choose
    S3 Intelligent-Tiering. With Intelligent-Tiering, AWS will move your objects automatically
    between the frequently accessed tiers and the infrequently accessed tiers based
    on your usage and then charge you accordingly.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 有时您可能认为亚马逊推导出来的将对象移动到不同存储层的算法，比您自己提出的任何方法都更有效。这时选择 S3 智能分层是一个完美的案例。使用智能分层，AWS
    将根据您的使用情况自动在频繁访问层和不频繁访问层之间移动您的对象，并根据使用情况向您收费。
- en: 'Key points to remember about S3 Intelligent-Tiering are as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的关于 S3 智能分层的要点如下：
- en: Designed to optimize storage costs by automatically moving objects to the most
    cost-effective storage tier.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计为通过自动将对象移动到最具成本效益的存储层来优化存储成本。
- en: Designed for longer storage of at least 30 days (minimum 30-day charge) and
    Intelligent-Tiering takes 30 days to start to figure out access patterns.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计用于至少 30 天的长期存储（最低 30 天的充电时间），并且智能分层（Intelligent-Tiering）需要 30 天才能开始分析访问模式。
- en: It stores objects in two access tiers and optimizes that storage based on frequently
    and infrequently accessed objects.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将对象存储在两个访问层中，并基于频繁访问和不频繁访问的对象优化存储。
- en: There is no performance impact, and there are no additional fees when Intelligent-Tiering
    moves objects between tiers.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当智能分层在不同层级之间移动对象时，不会影响性能，也不会产生额外费用。
- en: Crafted for 99.99% availability during a given year.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计为每年 99.99% 的可用性。
- en: Optimized for data lakes and other datasets where the access patterns are unknown.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对数据湖和其他访问模式不确定的数据集进行了优化。
- en: S3 Standard Infrequent Access (S3 Standard-IA)
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: S3 标准低频访问（S3 Standard-IA）
- en: If you have data that you don't access frequently but still need to be able
    to retrieve it in real time, Standard-IA is an option to consider. There are some
    points that need to be considered when thinking about this storage option, such
    as the files need to be stored for a minimum of 30 days before deletion (or be
    charged for the 30 days), along with having a minimum file size of 128 KB.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有不常访问但仍需要实时检索的数据，Standard-IA 是一个值得考虑的选项。考虑此存储选项时需要注意一些要点，例如文件需要至少存储 30 天才可以删除（或者需要为这
    30 天支付费用），并且文件的最小大小为 128 KB。
- en: 'Key points to remember about S3 Standard-IA are as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 S3 Standard-IA，需记住的关键点如下：
- en: Designed for files over 128 KB (smaller files will be charged as if they were
    128 KB).
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计用于大于 128 KB 的文件（小于 128 KB 的文件将按 128 KB 计费）。
- en: Designed for longer storage of at least 30 days (minimum 30-day charge).
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计用于至少存储 30 天（最低 30 天费用）。
- en: There is a higher GET, PUT, COPY, POST, LIST, and SELECT charge than Standard
    but a lower storage cost, so it is designed for infrequent access, as the name
    states.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比标准存储，S3 One Zone-IA 在 GET、PUT、COPY、POST、LIST 和 SELECT 操作上的费用较高，但存储成本较低，因此它是为低频访问而设计的，正如其名称所示。
- en: Objects are available to access in real time with no delays.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象可以实时访问，且没有延迟。
- en: Crafted for 99.99% availability during a given year.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为保证一年内 99.99% 的可用性而设计。
- en: Copies of data are stored in multiple Availability Zones.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的副本存储在多个可用区中。
- en: S3 One Zone Infrequent Access (S3 One Zone-IA)
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: S3 单区低频访问（S3 One Zone-IA）
- en: S3 One Zone-IA has many of the features of Standard-IA but at a lower price
    because the data is being stored in only one availability zone instead of a minimum
    of three. This is not a good option for critical data but can present large cost
    savings for files that are infrequently accessed and can be re-created if necessary.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: S3 One Zone-IA 具有与 Standard-IA 相同的许多功能，但由于数据只存储在一个可用区而不是至少三个可用区，因此价格更低。这对于关键数据并不是一个好选择，但对于不常访问且可以在必要时重新创建的文件来说，可以大幅节省成本。
- en: 'Key points to remember about S3 One Zone-IA are as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 S3 One Zone-IA，需记住的关键点如下：
- en: Ideal for data that can be re-created or object replicas when setting *cross-region
    replication*.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适用于可重新创建的数据或在设置*跨区域复制*时的对象副本。
- en: Designed for longer storage of at least 30 days (minimum 30-day charge).
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计用于至少存储 30 天（最低 30 天费用）。
- en: Objects are available for real-time access.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象可以进行实时访问。
- en: Crafted for 99.95% availability during a given year.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为保证一年内 99.95% 的可用性而设计。
- en: Data is subject to loss stemming from data center outages caused by disasters
    such as floods or earthquakes.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可能会因灾难性事件（如洪水或地震）导致的数据中心停机而丢失。
- en: S3 Glacier
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: S3 Glacier
- en: The S3 Glacier storage tier provides you an option for a low-cost, durable storage
    archive with low fees for data retrieval. Unlike the Glacier service from AWS,
    there is no need to wait for days for your objects to appear back in your S3 bucket.
    S3 Glacier has 3 tiers of retrieval speeds. The first is an expedited tier that
    can bring your objects back in just 1-5 minutes. The second is the standard retrieval
    tier, which restores objects in 3-5 hours, and the third is the bulk tier, which
    takes around 12 hours to restore objects to your bucket.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: S3 Glacier 存储层提供低成本、持久的存档存储选项，并且数据检索费用低。与 AWS Glacier 服务不同，您无需等待数天才能将对象恢复到 S3
    存储桶中。S3 Glacier 有 3 种检索速度等级：第一种是加急等级，可在 1-5 分钟内恢复对象；第二种是标准检索等级，可在 3-5 小时内恢复对象；第三种是批量等级，恢复对象大约需要
    12 小时。
- en: 'Key points to remember about S3 Glacier are as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 S3 Glacier，需记住的关键点如下：
- en: Designed for longer storage of at least 90 days (minimum charge of 90 days).
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计用于至少存储 90 天（最低 90 天费用）。
- en: Crafted for 99.9% availability during a given year.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为保证一年内 99.9% 的可用性而设计。
- en: Objects can be locked via the **VAULT LOCK** feature.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象可以通过**VAULT LOCK**功能进行锁定。
- en: Glacier retrieval times can be configured from minutes to hours.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Glacier 检索时间可以配置为几分钟到几小时不等。
- en: Appropriate for low-cost data archival on infrequently accessed objects, especially
    for compliance purposes.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适合低成本的数据归档，尤其适用于合规目的，不常访问的对象。
- en: S3 Glacier Deep Archive
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: S3 Glacier 深度归档
- en: Like the Glacier service, if you have items that are rarely retrieved but need
    to be retained, then Glacier Deep Archive can be a practical solution to your
    storage problems. Often, there are cases such as moving from a tape backup system
    to a digital tape backup system where you would only be retrieving the data once
    or twice per year and could withstand waiting 12 hours for data retrieval. These
    controls come with deep savings because storage in Glacier Deep Archive costs
    only $1 per TB per month.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 像 Glacier 服务一样，如果你有很少检索的数据但需要保存，那么 Glacier Deep Archive 可以成为一个切实可行的存储解决方案。通常，有一些场景比如从磁带备份系统迁移到数字磁带备份系统，数据每年只需要检索一到两次，并且可以接受等待
    12 小时来检索数据。这些控制提供了巨大的节省，因为 Glacier Deep Archive 的存储费用仅为每月每 TB 1 美元。
- en: 'Key points to remember about S3 Glacier Deep Archive are as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 S3 Glacier Deep Archive，有几个关键点需要记住：
- en: Designed for long-term digital storage that may be accessed once or twice during
    a given year
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计用于长期数字存储，可能在某一年内仅访问一次或两次
- en: Crafted for 99.9% availability during a given year
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旨在保证每年 99.9% 的可用性
- en: Designed for longer storage of at least 180 days (minimum 180-day charge)
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计用于至少存储 180 天（最低 180 天的费用）
- en: An alternative to on-premises tape libraries
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是本地磁带库的替代方案
- en: Note
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: S3 Glacier and S3 Glacier Deep Archive are storage classes within S3 and, as
    such, the object stays within the S3 service.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: S3 Glacier 和 S3 Glacier Deep Archive 是 S3 中的存储类，因此，对象将一直保存在 S3 服务内。
- en: Using lifecycle policies in S3
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 S3 中使用生命周期策略
- en: 'As we just talked about the different storage classes available with S3, not
    all data that you store in S3 needs to be in the standard tier at all times, as
    shown here:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们刚才讨论过的，S3 提供不同的存储类，并非所有存储在 S3 中的数据都需要始终处于标准存储层，如下所示：
- en: '![Figure 4.3 – An example S3 lifecycle policy'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.3 – 一个示例 S3 生命周期策略](img/Figure_4.3_B17405.jpg)'
- en: '](img/Figure_4.3_B17405.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_4.3_B17405.jpg)'
- en: Figure 4.3 – An example S3 lifecycle policy
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – 一个示例 S3 生命周期策略
- en: Depending on how long you need to access your data on a regular basis, you can
    move your objects to different tiers using object lifecycles.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你定期访问数据的频率，你可以通过对象生命周期将你的对象移动到不同的存储层。
- en: Creating a lifecycle policy
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建生命周期策略
- en: 'The following exercise will use the AWS console and the bucket we created previously
    in this chapter:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 以下练习将使用 AWS 控制台和我们在本章前面创建的桶：
- en: Log in to the AWS console (in the account in which you created the S3 bucket
    earlier in this chapter). Make sure you have logged into the account with a user
    that has S3 full access rights.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录 AWS 控制台（使用你在本章中创建的 S3 桶所在账户）。确保你已使用具有 S3 完全访问权限的用户登录账户。
- en: Navigate to the S3 page ([https://s3.console.aws.amazon.com/](https://s3.console.aws.amazon.com/)).
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 S3 页面（[https://s3.console.aws.amazon.com/](https://s3.console.aws.amazon.com/)）。
- en: If you have more than one S3 bucket, click on the bucket that you made in the
    previous exercise.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你有多个 S3 桶，请点击你在前面的练习中创建的桶。
- en: This bucket should currently have no objects and no current lifecycle policy
    associated with it.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该桶当前应没有任何对象，也没有与其关联的生命周期策略。
- en: Once you're on the bucket's main page, click on the **Management** tab on the
    main screen.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你进入桶的主页时，点击主屏幕上的 **管理** 选项卡。
- en: 'This will bring the **Lifecycle rules** section to the middle of the main screen.
    It should have a **(0)** right after the **Lifecycle rules**, meaning that there
    are no **Lifecycle rules** currently associated with this bucket:'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将把 **生命周期规则** 部分显示在主屏幕的中间，并且在 **生命周期规则** 后面会有一个 **(0)**，意味着当前没有与此桶关联的 **生命周期规则**：
- en: '![Figure 4.4 – S3 lifecycle rules via the Management tab'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.4 – 通过管理选项卡查看 S3 生命周期规则](img/Figure_4.4_B17405.jpg)'
- en: '](img/Figure_4.4_B17405.jpg)'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_4.4_B17405.jpg)'
- en: Figure 4.4 – S3 lifecycle rules via the Management tab
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.4 – 通过管理选项卡查看 S3 生命周期规则
- en: Now we can click on the button in the **Lifecycle Rules** section labeled **Create
    lifecycle rule**. This will bring us to the area where we can start to create
    our own lifecycle rules.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以点击 **生命周期规则** 部分中的 **创建生命周期规则** 按钮。这将引导我们进入创建生命周期规则的界面。
- en: We are going to create a rule that deletes objects in our bucket after one day.
    We could create multiple rules that follow the path in *Fi**gure 4.2*, but if
    you remember the key points of the Infrequent Access storage tier, any object
    that isn't kept for at least 30 days will be charged for 30 days of storage. Rather
    than have those charges when testing out how to create lifecycle rules, we will
    just create a rule that will delete the objects after a certain period of time
    instead.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将创建一个规则，在一天后删除存储桶中的对象。我们可以创建多个规则，遵循*图 4.2*中的路径，但如果你记得低频访问存储层的关键点，任何未保存至少 30
    天的对象将会被收取 30 天的存储费用。在测试如何创建生命周期规则时，我们将创建一个规则，删除对象，而不是测试期间产生额外的费用。
- en: Call the rule `devopspro-1day-delete`.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将规则命名为`devopspro-1day-delete`。
- en: Under the rule scope, click the option that says **This rule applies to all
    objects in the bucket**.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在规则范围下，点击选项**此规则适用于存储桶中的所有对象**。
- en: Click the box that appears saying **I acknowledge this rule will apply to all
    objects in the bucket**:![Figure 4.5 – Configuring the lifecycle rule
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 勾选出现的框，标明**我确认此规则将适用于存储桶中的所有对象**：![图 4.5 – 配置生命周期规则
- en: '](img/Figure_4.5_B17405.jpg)'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_4.5_B17405.jpg)'
- en: Figure 4.5 – Configuring the lifecycle rule
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.5 – 配置生命周期规则
- en: Under the **Lifecycle rule actions**, check the box that is labeled **Expire
    current versions of objects**.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**生命周期规则操作**下，勾选标有**过期当前对象版本**的框。
- en: When the `1`.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当`1`。
- en: 'Click on **Create rule** at the bottom of the page:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击页面底部的**创建规则**按钮：
- en: '![Figure 4.6 – Create rule button'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.6 – 创建规则按钮'
- en: '](img/Figure_4.6_B17405.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_4.6_B17405.jpg)'
- en: Figure 4.6 – Create rule button
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 创建规则按钮
- en: We have now created our lifecycle rule and, in order to test it out, we need
    to upload a file into the bucket and then wait for a day so that we can see it
    be automatically deleted.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经创建了生命周期规则，为了测试它，我们需要上传一个文件到存储桶中，然后等待一天，以便看到它被自动删除。
- en: S3 endpoints
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: S3 终端节点
- en: Prior to the creation of S3 endpoints, all data being accessed from S3 traversed
    the public internet. If you had private information that you were passing from
    a private S3 bucket to a resource in a private subnet in your **Virtual Private
    Cloud** (**VPC**), then not only did this pose some security risks, but it also
    required some extra networking to allow the resources in the private subnet to
    talk to the internet so that the S3 buckets that you wanted to access could be
    uploaded to and downloaded from.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在 S3 终端节点创建之前，所有访问 S3 的数据都必须经过公共互联网。如果你有私人信息从私有 S3 存储桶传输到 VPC 中私有子网的资源，那么不仅存在一些安全风险，还需要额外的网络配置，使得私有子网中的资源能够与互联网通信，以便可以上传和下载你想要访问的
    S3 存储桶。
- en: If we have resources in a private subnet of a VPC that do not have a public
    route to the internet via a NAT instance or a NAT gateway, then we would not be
    able to access items in our S3 buckets without setting up that NAT instance, or
    we can make a more secure connection by using an S3 endpoint.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的 VPC 中的资源位于一个私有子网，并且没有通过 NAT 实例或 NAT 网关与互联网建立公共路由，那么我们将无法访问 S3 存储桶中的项目，除非设置那个
    NAT 实例，或者我们可以通过使用 S3 终端节点来建立更安全的连接。
- en: An S3 endpoint, which is a gateway endpoint, allows us to add an entry to the
    route table of our **VPC**. By adding this endpoint, we can now bypass the public
    internet with both our public and private instances and protect the privacy of
    our data being passed along the route. This is a much more secure solution for
    transporting your data from EC2 instances and other services residing within your
    VPC than using the public route.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: S3 终端节点，作为一个网关终端节点，允许我们向**VPC**的路由表中添加一条入口。通过添加这个终端节点，我们现在可以绕过公共互联网，既可以通过公共实例，也可以通过私有实例，同时保护我们数据沿路由传输过程中的隐私。这比使用公共路由更安全，是从
    EC2 实例和其他在 VPC 中的服务传输数据的更好解决方案。
- en: S3 access control
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: S3 访问控制
- en: Once you have data and objects uploaded into your bucket, unless you have a
    bucket with public access, then you might want to restrict who can access the
    objects within the bucket. Starting small, you may just allow the default access
    controls to whoever has authorization into the account. They may access the data
    in any non-public bucket. As you move to most corporate environments, there will
    be segments of data that will need to be cordoned off from one business unit to
    another. One product team would most likely have no need to access the data stored
    by another data team. Along those same lines, data being stored by the financial
    and business departments will probably need to restrict any technology members
    from accessing and possibly deleting the data.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你将数据和对象上传到桶中，除非你的桶具有公共访问权限，否则你可能希望限制谁可以访问桶中的对象。刚开始时，你可能只允许具有帐户授权的任何人访问。这些人可以访问任何非公开的桶中的数据。当你进入大多数企业环境时，数据的某些部分可能需要在不同业务部门之间进行隔离。一个产品团队很可能没有必要访问另一个数据团队存储的数据。类似地，财务和业务部门存储的数据可能需要限制任何技术人员访问，甚至可能删除这些数据。
- en: 'This is where the access controls of S3 come into play. There are two main
    methods for implementing access controls: using S3 bucket policies on who and
    what can access the individual objects themselves and then by using IAM controls
    to limit users, groups, and resources that can access the buckets individually,
    or by using controls such as tags in an **attribute-based control model**.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这时，S3 的访问控制就发挥了作用。实现访问控制有两种主要方法：一种是使用 S3 桶策略来限制谁和什么可以访问单个对象，另一种是使用 IAM 控制来限制可以单独访问桶的用户、组和资源，或者使用**基于属性的控制模型**（如标签）等控制。
- en: 'It''s generally a good idea to pick one method of access or the other and not
    try to mix the two since this can lead to some very frustrating sessions of trying
    to troubleshoot permission issues:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，选择一种访问方法而非两者混合使用是个好主意，因为混合使用可能会导致一些非常令人沮丧的排错会话，试图解决权限问题：
- en: '![Figure 4.7 – S3 resource versus user-based policies'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.7 – S3 资源与基于用户的策略'
- en: '](img/Figure_4.7_B17405.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_4.7_B17405.jpg)'
- en: Figure 4.7 – S3 resource versus user-based policies
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – S3 资源与基于用户的策略
- en: You should also know that you must explicitly make an S3 bucket public as all
    S3 buckets are private by default and block public access.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 你还应该知道，必须显式地将 S3 桶设置为公共访问，因为所有 S3 桶默认都是私有的，并且阻止公共访问。
- en: Resource-based policies
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于资源的策略
- en: If you and your organization prefer to restrict at the object level, then you
    can use **Access Control Lists** (**ACLs**) either at the bucket access level
    or at the object access level.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你和你的组织更倾向于在对象级别进行限制，那么你可以在桶访问级别或对象访问级别使用**访问控制列表**（**ACLs**）。
- en: User-based policies
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于用户的策略
- en: Many, on the other hand, would rather control access to their S3 buckets with
    IAM policies. This allows you to control entitlement from the bucket and folder
    level, along with the ability to construct more complex conditions in the IAM
    policy based on a tag, `VPC-id`, `source-IP` address, and other factors.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，许多人更愿意通过 IAM 策略来控制对 S3 桶的访问。这使你能够控制从桶和文件夹级别的权限，并且可以根据标签、`VPC-id`、`source-IP`
    地址和其他因素在 IAM 策略中构建更复杂的条件。
- en: Cross-account access
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跨账户访问
- en: If you need a user or resource in one account to be able to access the objects
    in another account, then you can set up a cross-account access role as we did
    in the IAM exercise in [*Chapter 3*](B17405_03_Final_JM_ePub.xhtml#_idTextAnchor083),
    *Identity and Access Management and Working with Secrets in AWS*.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要一个账户中的用户或资源能够访问另一个账户中的对象，那么你可以设置跨账户访问角色，就像我们在 IAM 练习中所做的那样，见 [*第 3 章*](B17405_03_Final_JM_ePub.xhtml#_idTextAnchor083)，*AWS
    中的身份与访问管理和密钥管理*。
- en: S3 access logs
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: S3 访问日志
- en: When storing different objects in S3, especially those that are to be downloaded
    by various users and groups, you might want to know who is accessing the different
    files, when, and from what location.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在 S3 中存储不同的对象时，尤其是那些需要被各种用户和组下载的对象，你可能希望知道谁在何时从什么位置访问了不同的文件。
- en: Users can capture all the access logs and records of who is accessing various
    objects in a bucket via a simple setting in S3\. You cannot store the logs in
    the same bucket as the items that you are tracking, so you need to either create
    an entirely new bucket expressly for the purpose of capturing the logs or designate
    a previously created bucket in your current account to hold the logs.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以通过 S3 中一个简单的设置捕获所有访问日志和谁在访问桶中不同对象的记录。你不能将日志存储在与正在跟踪的项目相同的桶中，因此你需要创建一个全新的桶，专门用于捕获日志，或者指定当前账户中已创建的桶来存储这些日志。
- en: Logs are not pushed to that bucket in real time as items are accessed, as would
    be the case for logs on a web server. Amazon pushes the logs in batches in a best-effort
    approach.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Web 服务器上的日志不同，日志不会在访问项目时实时推送到该桶。亚马逊会以批量的形式推送日志，尽力而为。
- en: If you don't want to set up an entirely different bucket to capture these logs,
    and if you have **CloudTrail logs** turned on for the account, then you can gather
    IAM user information on S3 API calls.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不想设置一个完全不同的桶来捕获这些日志，并且你已为该账户启用**CloudTrail 日志**，那么你可以收集 IAM 用户对 S3 API 调用的信息。
- en: Encryption options with S3
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: S3 的加密选项
- en: S3 allows encryption at rest for the objects it stores. The default option when
    you store an object is to store it unencrypted. If you are working in any kind
    of environment that requires compliance, then you will most likely need to encrypt
    the objects you are storing.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: S3 允许对其存储的对象进行静态加密。存储对象时，默认选项是将其以未加密的形式存储。如果你在任何需要合规性的环境中工作，那么你很可能需要加密你存储的对象。
- en: 'If you have decided that your objects stored in S3 need to be encrypted, then
    you do have options. You can choose between *server-side encryption* and *client-side
    encryption*. There are some key questions to ask before making this decision:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经决定将存储在 S3 中的对象进行加密，那么你确实有选择。你可以在*服务器端加密*和*客户端加密*之间进行选择。在做出这个决定之前，有几个关键问题需要考虑：
- en: Do you need to manage the encryption key?
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要管理加密密钥吗？
- en: Where is the encryption key going to be stored?
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加密密钥将存储在哪里？
- en: Who is going to do the encryption and decryption of the data?
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁将负责数据的加密和解密？
- en: Server-side encryption
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务器端加密
- en: 'AWS has made the process of encrypting your objects and data in S3 storage
    easy with their server-side encryption options:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 通过其服务器端加密选项使得加密存储在 S3 中的对象和数据变得简单：
- en: '`SSE-S3`: Using the `SSE-S3` option allows you to use the AWS S3 master key
    to encrypt your objects and data. This allows your data to be stored encrypted
    at rest without a lot of management or extra configuration on your or your team''s
    part in the setup. You simply upload your objects to the S3 bucket of your choice,
    and then once they are received successfully, the S3 service handles the encryption
    of those objects. By the same token, when an object is requested by a service
    or user, and as long as that service or user has the proper authorization to access
    the object, then the S3 service decrypts the requested object.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SSE-S3`：使用 `SSE-S3` 选项可以让你使用 AWS S3 主密钥来加密你的对象和数据。这使得你的数据可以在静态存储时进行加密，而无需在设置过程中做过多管理或额外配置。你只需将对象上传到你选择的
    S3 桶，一旦成功接收，S3 服务会处理这些对象的加密。类似地，当服务或用户请求一个对象时，只要该服务或用户有权限访问该对象，S3 服务就会解密该请求的对象。'
- en: '`SSE-K:MS`: Integrating the **Key Management Service** (**KMS**) into server-side
    encryption adds a small cost, but a few more features and benefits over just using
    the default encryption key provided with the S3 service. You now have another
    layer of granular control of the customer keys and of which IAM entities are allowed
    to access that key. KMS also provides an audit trail of who has accessed the key.
    And one of the main features is that you have the control to rotate the key if
    needed.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SSE-K:MS`：将**密钥管理服务**（**KMS**）集成到服务器端加密中，会增加少许费用，但相较于仅使用 S3 服务提供的默认加密密钥，它带来了一些额外的功能和好处。你现在可以更细粒度地控制客户密钥以及哪些
    IAM 实体可以访问该密钥。KMS 还提供了密钥访问的审计记录。其主要特点之一是，你可以根据需要旋转密钥。'
- en: Client-side encryption
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 客户端加密
- en: When choosing client-side encryption, the full responsibility for encrypting
    and decrypting falls on you the client. This method involves encrypting the objects
    before they reach S3\. You are also responsible for any master/child key management
    along with key rotation. Client-side encryption is a good choice if your organization
    needs total control of both the master keys and the encryption algorithm used.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 选择客户端加密时，完全的加密和解密责任由您，客户端承担。这种方法涉及在对象到达 S3 之前进行加密。您还需要负责任何主密钥/子密钥的管理及密钥轮换。如果您的组织需要完全控制主密钥和加密算法，客户端加密是一个不错的选择。
- en: We are going to take a deep dive into the protection of data in flight and at
    rest in [*Chapter 19*](B17405_19_Final_JM_ePub.xhtml#_idTextAnchor447), *Protecting
    Data in Flight and at Rest*.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第19章*](B17405_19_Final_JM_ePub.xhtml#_idTextAnchor447)，《*保护传输中的数据和静态数据*》中深入探讨数据的传输和存储保护。
- en: Using S3 events to trigger other AWS services
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 S3 事件触发其他 AWS 服务
- en: 'The S3 service can notify other services when certain things happen to objects
    in a bucket. Two of the most common scenarios are if an object was uploaded or
    if an object was deleted from a particular bucket. The S3 bucket can then notify
    one of three other AWS services of what has happened and the bucket where the
    event occurred. The three services that allow S3 event notifications are as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: S3 服务可以在存储桶中的对象发生特定变化时通知其他服务。最常见的两种场景是对象被上传或对象从某个特定存储桶中删除。然后，S3 存储桶可以通知其他三种
    AWS 服务发生了什么事情，以及事件发生的存储桶。允许 S3 事件通知的三种服务如下：
- en: AWS **Lambda**
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS **Lambda**
- en: Amazon **Simple Queue Service** (**SQS**)
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊 **简单队列服务** (**SQS**)
- en: Amazon **Simple Notification Service** (**SNS**)
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊 **简单通知服务** (**SNS**)
- en: 'You can arrange for notifications to be issued to SQS or SNS when a new object
    is added to the bucket or overridden. Notifications can also be delivered to AWS
    Lambda for processing by a Lambda function:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 当向存储桶添加或覆盖新对象时，您可以安排将通知发送到 SQS 或 SNS。通知也可以传递到 AWS Lambda，由 Lambda 函数处理：
- en: '![Figure 4.8 – S3 Event Flow'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.8 – S3 事件流'
- en: '](img/Figure_4.8_B17405.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_4.8_B17405.jpg)'
- en: Figure 4.8 – S3 Event Flow
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – S3 事件流
- en: Let's think about this and how we would use this from a DevOps perspective.
    AWS Lambda is an extremely powerful tool that we will explore in detail in [*Chapter
    12*](B17405_12_Final_JM_ePub.xhtml#_idTextAnchor307), *Lambda Deployments and
    Versioning*, and it can be used to invoke almost any other AWS service. In our
    current scenario, we could have a customer who is using the AWS SFTP service to
    upload a file to an Amazon S3 bucket. That bucket could trigger a bucket event
    to AWS Lambda. The Lambda function could then kick off an AWS Pipeline build that
    would process the file, which, on passing or failing, sends a notification to
    the development team of a new build available for deployment.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 DevOps 的角度来思考这个问题，看看如何使用它。AWS Lambda 是一个极其强大的工具，我们将在[*第12章*](B17405_12_Final_JM_ePub.xhtml#_idTextAnchor307)，《*Lambda
    部署与版本管理*》中详细探讨，它可以用于调用几乎任何其他的 AWS 服务。在我们当前的场景中，我们可能有一个客户正在使用 AWS SFTP 服务将文件上传到
    Amazon S3 存储桶。该存储桶可以触发一个存储桶事件到 AWS Lambda。Lambda 函数可以启动一个 AWS Pipeline 构建来处理文件，处理结果无论是成功还是失败，都会向开发团队发送通知，告知有新的构建可供部署。
- en: Note
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In order to use S3 events, you must grant the S3 principle the necessary permissions
    in order to use the requested services. This includes the permission to publish
    to SNS queues or SQS topics, as well as the ability to invoke Lambda.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 S3 事件，必须授予 S3 相关权限，以便使用请求的服务。这包括发布到 SNS 队列或 SQS 主题的权限，以及调用 Lambda 的能力。
- en: Triggering an S3 event
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 触发 S3 事件
- en: 'We will go through the exercise of using our previously created bucket to add
    an event trigger whenever an object is uploaded to the bucket. This event will
    be something simple to start with: an email notification to ourselves. In order
    to send that email, we will need to create an SNS topic and then subscribe to
    that topic with our email. Then we can go back to our bucket and add the bucket
    event configuration so that whenever an object is uploaded, it will send us a
    notification.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过一个示例来使用我们之前创建的存储桶，在每次上传对象到存储桶时添加事件触发器。这个事件一开始会是一个简单的操作：向我们自己发送电子邮件通知。为了发送这封邮件，我们需要创建一个
    SNS 主题，并用我们的电子邮件订阅该主题。然后，我们可以返回到存储桶并添加存储桶事件配置，这样每当上传一个对象时，就会发送通知给我们。
- en: 'Now that we know that we have to set up an SNS topic, let''s use our CLI to
    create that topic and subscribe so we can get the emails once something has been
    uploaded to our bucket:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们知道需要设置一个SNS主题，让我们使用CLI创建该主题并订阅，以便上传到我们的存储桶时能够收到邮件：
- en: 'Open up your terminal and type the following commands so we can create the
    topic:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端并输入以下命令，创建该主题：
- en: '[PRE3]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If the topic is created successfully, then it should return something like
    this:'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果主题创建成功，那么应该返回如下内容：
- en: '[PRE4]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now that we have our topic, we need to subscribe using our email address:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经有了主题，需要使用我们的电子邮件地址进行订阅：
- en: '[PRE5]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This should return a JSON statement telling you that the subscription is pending:'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这应该返回一条JSON语句，告诉你订阅正在等待中：
- en: '[PRE6]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now we need to go to our email account and find the email that the SNS service
    has just sent, and then click on the link that says **Confirm Subscription**.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要进入我们的电子邮件账户，找到SNS服务刚刚发送的邮件，然后点击上面写着**确认订阅**的链接。
- en: Now let's log into our account and go to our S3 bucket so that we can configure
    the **Event Notifications**.
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在让我们登录到我们的账户，进入我们的S3存储桶，以便配置**事件通知**。
- en: The final step for our SNS topic to be ready is to add an IAM role that allows
    it to receive the notification events from the S3 bucket.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的SNS主题准备就绪的最后一步是添加一个IAM角色，允许它接收来自S3存储桶的通知事件。
- en: 'We will use the following policy and then need to fill in the following values
    before saving them to a file:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将使用以下策略，并在保存到文件之前填写以下值：
- en: '**Account Number**'
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**账户编号**'
- en: '**Region**'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**区域**'
- en: '**Bucket name**'
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储桶名称**'
- en: 'We will create the following policy and then add this to the topic in the **Access**
    section once we log into the AWS console:'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将创建以下策略，然后在登录AWS控制台后将其添加到**访问**部分的主题中：
- en: '[PRE7]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Let's now log into our AWS account and go to the SNS service so we can update
    our access policy. This way, the SNS topic has the correct permissions to interact
    with the S3 event notification.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们登录到我们的AWS账户，进入SNS服务，以便更新我们的访问策略。这样，SNS主题就能拥有正确的权限来与S3事件通知交互。
- en: Once on the SNS service, choose **Topics**.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦进入SNS服务，选择**主题**。
- en: In the **Topics** menu, you should see the topic we created via **CLI – s3events**.
    Click on the topic name so we can get to the configuration.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**主题**菜单中，你应该能够看到我们通过**CLI – s3events**创建的主题。点击主题名称以进入配置页面。
- en: Once inside the topic, we need to press the **Edit** button near the top-right
    of the main page:![Figure 4.9 – Edit button near the top of the page
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入主题后，我们需要点击页面右上方的**编辑**按钮：![图4.9 – 页面顶部的编辑按钮
- en: '](img/Figure_4.9_B17405.jpg)'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_4.9_B17405.jpg)'
- en: Figure 4.9 – Edit button near the top of the page
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.9 – 页面顶部的编辑按钮
- en: Now find the `JSON` policy we made earlier into this section. Once you have
    replaced the previous value with the new access policy, click the orange **Save
    changes** button at the bottom of the page.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在在这一部分找到我们之前创建的`JSON`策略。一旦将之前的值替换为新的访问策略，点击页面底部的橙色**保存更改**按钮。
- en: Now we can go to the S3 console ([https://s3.console.aws.amazon.com/](https://s3.console.aws.amazon.com/)).
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以进入S3控制台（[https://s3.console.aws.amazon.com/](https://s3.console.aws.amazon.com/)）。
- en: Find the bucket that you made previously in this chapter (ours was named `devopspro-beyond`).
    If you haven't made a bucket already, you could choose any bucket you have in
    your account or create a new bucket quickly. Click on that bucket name so that
    you are brought to the main bucket page.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到你在本章中创建的存储桶（我们的存储桶名为`devopspro-beyond`）。如果你还没有创建存储桶，你可以选择账户中已有的任何存储桶，或者快速创建一个新存储桶。点击该存储桶名称进入主存储桶页面。
- en: Once you are on the main bucket page, then click the **Properties** menu item
    in the horizontal menu in the main window frame:![Figure 4.10 – S3 horizontal
    menu with Properties highlighted
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦进入主存储桶页面，点击主窗口框中的水平菜单中的**属性**菜单项：![图4.10 – S3水平菜单，属性高亮显示
- en: '](img/Figure_4.10_B17405.jpg)'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_4.10_B17405.jpg)'
- en: Figure 4.10 – S3 horizontal menu with Properties highlighted
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.10 – S3水平菜单，属性高亮显示
- en: Now scroll down the screen until you find the panel named **Event Notifications**:![Figure
    4.11 – S3 Event notifications with no created notifications
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在向下滚动页面，直到找到名为**事件通知**的面板：![图4.11 – 没有创建通知的S3事件通知
- en: '](img/Figure_4.11_B17405.jpg)'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_4.11_B17405.jpg)'
- en: Figure 4.11 – S3 Event notifications with no created notifications
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.11 – 没有创建通知的S3事件通知
- en: Now click on the **Create event notification** button.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在点击**创建事件通知**按钮。
- en: 'Use the following configurations for our S3 event test:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下配置进行我们的 S3 事件测试：
- en: '`S3 Test`'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`S3 测试`'
- en: '`.txt`'
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.txt`'
- en: '**Event Types** – Check the box labeled **Put**:'
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件类型** – 勾选标记为 **Put** 的复选框：'
- en: '![Figure 4.12 – Configuring an S3 event notification'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.12 – 配置 S3 事件通知'
- en: '](img/Figure_4.12_B17405.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_4.12_B17405.jpg)'
- en: Figure 4.12 – Configuring an S3 event notification
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.12 – 配置 S3 事件通知
- en: Scroll down to the bottom of the page where you see **Destination**.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动到页面底部，直到看到 **目标**。
- en: Choose the radio button that is next to `s3-event`):![Figure 4.13 – Choosing
    the destination for our S3 event notification
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择位于 `s3-event` 旁边的单选按钮：![图 4.13 – 选择 S3 事件通知的目标
- en: '](img/Figure_4.13_B17405.jpg)'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_4.13_B17405.jpg)'
- en: Figure 4.13 – Choosing the destination for our S3 event notification
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.13 – 选择 S3 事件通知的目标
- en: Click the orange **Save changes** button.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击橙色的 **保存更改** 按钮。
- en: It's now time to upload a text file and test that we receive an email notification.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是上传文本文件并测试我们是否能收到邮件通知的时候了。
- en: 'All we need to test is any text file (remember we configured the event to only
    be configured on `.txt` files and no other types of files). We will use the CLI
    to upload our file:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要测试的只是一份文本文件（记住，我们配置的事件仅限于 `.txt` 文件，其他类型的文件不适用）。我们将使用 CLI 上传文件：
- en: '[PRE8]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you uploaded your file successfully, then you should see this output:'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你成功上传了文件，应该会看到如下输出：
- en: '[PRE9]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Once the file is uploaded, you should receive an email notification at the email
    address you used to subscribe to the SNS topic.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文件上传后，你应该会收到一封邮件通知，通知会发送到你订阅 SNS 主题时使用的邮箱地址。
- en: Now that we have seen how we can trigger operations on other services, such
    as **Lambda**, **SNS**, and **SQS**, we can think about how this would be of use
    to us in the real world. In the case of SNS, you may have a client who has an
    account and would like to be notified whenever one of their clients uploads one
    or more files to their personal S3 bucket so they can review the files. In the
    case of Lambda, you may be receiving invoices from another department and need
    to extract out the data before storing it into one or more data stores, and by
    using S3 events this can all happen automatically once the file is uploaded to
    the bucket.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到如何触发其他服务（如 **Lambda**、**SNS** 和 **SQS**）的操作，我们可以思考一下这种方式如何在现实世界中对我们有帮助。以
    SNS 为例，你可能有一个客户，他有一个账户，并希望在他们的客户上传一个或多个文件到他们的个人 S3 存储桶时收到通知，以便查看这些文件。对于 Lambda
    来说，你可能会收到另一个部门的发票，需要在将其存储到一个或多个数据存储中之前提取数据，使用 S3 事件，这一切都可以在文件上传到存储桶后自动发生。
- en: In the next section, we will look at S3 Batch operations and see how, with the
    help of a manifest file, we can process a few or a few thousand files at once
    using just the S3 service.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将了解 S3 批量操作，看看如何借助清单文件，我们可以一次处理少量或几千个文件，仅使用 S3 服务。
- en: S3 Batch operations
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: S3 批量操作
- en: Having a good tagging strategy is part of recommended AWS account hygiene. Just
    like other initiatives, many of these strategies evolve over time. There may come
    a time when you or your organization feels the need to change some of the mandatory
    tags on the objects in your current set of S3 buckets. If you have been running
    in AWS for any period of time then there are most likely too many objects to re-tag
    by hand and so you are left trying to devise a solution. This is where the power
    of AWS **S3 Batch operations** can come into play. It can perform batch operations
    on files and buckets with ease.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有良好的标签策略是推荐的 AWS 账户管理的一部分。就像其他举措一样，这些策略中的许多会随着时间的推移而不断发展。也许会有某个时刻，你或你的组织会觉得需要更改当前
    S3 存储桶中对象的某些强制性标签。如果你已经在 AWS 中运行了一段时间，那么很可能有太多对象需要手动重新标记，因此你需要想办法制定一个解决方案。这时，AWS
    **S3 批量操作**的强大功能就能派上用场了。它可以轻松地对文件和存储桶执行批量操作。
- en: 'S3 Batch operations allow you to do more than just modify tags. The following
    operations can be performed with S3 Batch operations:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: S3 批量操作不仅仅是修改标签。以下操作可以通过 S3 批量操作来执行：
- en: Modify objects and metadata properties.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改对象和元数据属性。
- en: Copy objects between S3 buckets.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 S3 存储桶之间复制对象。
- en: Replace object tag sets.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 替换对象标签集。
- en: Modify access controls to sensitive data.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改对敏感数据的访问控制。
- en: Restore archive objects from Glacier.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 Glacier 恢复归档对象。
- en: Invoke AWS Lambda functions.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用 AWS Lambda 函数。
- en: 'Once the job has been created, then it goes through a series of statutes before
    it either reaches the completed or failed state. The following table describes
    the different statuses available to an Amazon S3 Batch job:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 作业创建后，会经历一系列法规，然后达到完成或失败状态。以下表格描述了 Amazon S3 批处理作业可用的不同状态：
- en: '![](img/011.jpg)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![](img/011.jpg)'
- en: S3 Batch hands on-example
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: S3 批处理实例
- en: To test out the power of S3 Batch, we are going to take 75 files, upload them
    to our bucket, and then use AWS Batch to add a tag to each of the files almost
    instantly.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试 S3 批处理的功能，我们将取 75 个文件，上传到我们的存储桶，然后使用 AWS 批处理几乎即时为每个文件添加一个标签。
- en: Note
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you don't want to re-create all the files for this exercise, then simply
    go to the GitHub repository for this book; there are 75 small files available
    in [*Chapter 4*](B17405_04_Final_JM_ePub.xhtml#_idTextAnchor110), *Amazon S3 Blob
    Storage*, in the batch subfolder.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不想重新创建此练习的所有文件，只需转到本书的 GitHub 仓库；在[*第四章*](B17405_04_Final_JM_ePub.xhtml#_idTextAnchor110)，*Amazon
    S3 Blob Storage*，批处理子文件夹中有 75 个小文件可用。
- en: Also, since all the files have the `.txt` extension, you may want to turn off
    the S3 event notification or unsubscribe from the topic before uploading all of
    the exercise files to the S3 bucket.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，由于所有文件都具有`.txt`扩展名，您可能希望在将所有练习文件上传到 S3 存储桶之前，关闭 S3 事件通知或取消订阅主题。
- en: 'We will now use a hands-on example with S3 Batch to update the tags on a number
    of files at once. If you have a mandatory tagging strategy in place and files
    are missing some of those tags, then this can be an efficient way of managing
    those changes rather than trying to either write a custom script to perform the
    task or changing the tags on the files manually:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用 S3 批处理的实际示例一次性更新多个文件的标签。如果您有强制性的标签策略，并且文件缺少其中一些标签，则这可能是管理这些更改的有效方式，而不是尝试编写自定义脚本执行任务或手动更改文件的标签：
- en: Before we start, in order for the job to be able to execute, we need to ensure
    that we have an IAM role. Let's first log in to the AWS Management Console and
    navigate to the IAM service.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开始之前，为了使作业能够执行，我们需要确保有一个 IAM 角色。让我们首先登录 AWS 管理控制台，并导航到 IAM 服务。
- en: Create a role for an AWS service, choose **S3**, and then at the very bottom
    of the page, choose **S3 Batch Operations**:![Figure 4.14 – Selecting the use
    case for S3 permissions in IAM
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 AWS 服务创建角色，选择**S3**，然后在页面底部选择**S3 批处理操作**：![图 4.14 – 在 IAM 中选择 S3 权限的用例
- en: '](img/Figure_4.14_B17405.jpg)'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_4.14_B17405.jpg)'
- en: Figure 4.14 – Selecting the use case for S3 permissions in IAM
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.14 – 在 IAM 中选择 S3 权限的用例
- en: 'Click on the blue button labeled **Next: Permissions**.'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击标有**下一步：权限**的蓝色按钮。
- en: 'When you get to policy, click on the `JSON` code from GitHub named `S3_batch_IAM.json`.
    You will need to replace the name of your S3 bucket in all the places where it
    asks for variables. (The variable names are notated as `<<TargetResource>>`, `<<ManifestBucket>>`,
    and `<<ResourceBucket>>`.) Unless you are storing the manifests and reports in
    different buckets, then just replace the same bucket name in each value. When
    you are done, you can click the blue button labeled **Next: Tags**. There is no
    need for any tags at this moment, so just click the blue button labeled **Next:
    Review**.'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到达策略时，从 GitHub 中点击`S3_batch_IAM.json`的`JSON`代码。您需要在所有需要变量的地方替换您的 S3 存储桶名称。（变量名称标记为`<<TargetResource>>`，`<<ManifestBucket>>`和`<<ResourceBucket>>`）。完成后，您可以点击标有**下一步：标签**的蓝色按钮。此时不需要任何标签，只需点击标有**下一步：审核**的蓝色按钮。
- en: Now we can name and save our role; a good descriptive name is something like
    `S3-Batch-Tagging-Role`. Add the description if you desire and then click the
    blue **Create Policy** button.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在可以命名和保存我们的角色；一个好的描述性名称可以是`S3-Batch-Tagging-Role`。如果需要，添加描述，然后点击蓝色的**创建策略**按钮。
- en: Go back to the other tab where we were creating the role and search for the
    policy we just created, named `S3-Batch-Tagging`. Once this role has been created,
    we need to take a note of the ARN so that we can use it in our `batch` command
    later.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回到创建角色的其他标签页，并搜索我们刚刚创建的名为`S3-Batch-Tagging`的策略。创建完角色后，我们需要记下 ARN，以便稍后在`batch`命令中使用。
- en: Download the 75`.txt` files from the GitHub directory (or create your own set
    of files) into a single directory so that they can be uploaded into the S3 bucket
    you created earlier.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 GitHub 目录下载 75 个`.txt`文件（或创建您自己的文件集），放入单个目录中，以便可以将它们上传到您之前创建的 S3 存储桶。
- en: 'Next, we will use the `s3 sync` command to quickly move the files from our
    local directory:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 `s3 sync` 命令快速将文件从本地目录移动：
- en: '[PRE10]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We will also need to download the manifest (`.csv` file) from the GitHub repository
    in order to start our batch job. In the manifest, you will need to replace the
    current bucket name, `devopspro-beyond`, with the bucket name where you have uploaded
    your objects. Once you have changed those values, make sure that you upload the
    manifest to the S3 bucket, as S3 Batch needs to read the manifest from an S3 location
    when using a `CSV` file and not from a locally sourced file.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还需要从 GitHub 仓库下载清单（`.csv` 文件），以便开始我们的批处理任务。在清单中，你需要将当前的存储桶名称`devopspro-beyond`替换为你上传对象的存储桶名称。更改这些值后，确保将清单上传到
    S3 存储桶，因为当使用 `CSV` 文件时，S3 批处理需要从 S3 位置读取清单，而不是从本地文件读取。
- en: 'The final report also needs a *folder* in our bucket to reside in. We will
    use the `s3 cp` command to move a file into the new folder and have it ready to
    receive the final report:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终报告还需要一个*文件夹*来存放。我们将使用 `s3 cp` 命令将文件移动到新文件夹，并使其准备好接收最终报告：
- en: '[PRE11]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now that our objects and manifest have been uploaded, we can go back to the
    AWS management console and start the batch job. Going back to the browser window
    where you had previously made your IAM role, navigate to the **S3 service**.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们的对象和清单已经上传，我们可以返回到 AWS 管理控制台并开始批处理任务。返回到你之前创建 IAM 角色的浏览器窗口，导航到**S3 服务**。
- en: On the left-hand menu, click on **Batch Operations**:![Figure 4.15 – Batch Operations
    menu item
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧菜单中，点击**批处理操作**：![图 4.15 – 批处理操作菜单项
- en: '](img/Figure_4.15_B17405.jpg)'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_4.15_B17405.jpg)'
- en: Figure 4.15 – Batch Operations menu item
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.15 – 批处理操作菜单项
- en: Click on the orange button on the right-hand side that is labeled **Create Job**.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击右侧的橙色按钮，标签为**创建任务**。
- en: On the Manifest page, select the radio button that says `manifest.csv` file
    in your S3 bucket. The manifest ETag will populate automatically:![Figure 4.16
    – The manifest information for S3 Batch
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在清单页面，选择 S3 存储桶中标记为 `manifest.csv` 文件的单选按钮。清单的 ETag 会自动填充：![图 4.16 – S3 批处理的清单信息
- en: '](img/Figure_4.16_B17405.jpg)'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_4.16_B17405.jpg)'
- en: Figure 4.16 – The manifest information for S3 Batch
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.16 – S3 批处理的清单信息
- en: Click the orange **Next** button at the bottom of the page.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击页面底部的橙色**下一步**按钮。
- en: Under **Operation**, choose the radio button next to **Replace All tags**.
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**操作**下，选择**替换所有标签**旁边的单选按钮。
- en: This will make another set of options appear. For the `TAG`, and for the `Chapter4`.
    Once you have done this, click on the orange **Next** button:![Figure 4.17 – Adding
    the key and value for what to change
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这会使另一个选项集出现。选择 `TAG` 和 `Chapter4`。完成后，点击橙色的**下一步**按钮：![图 4.17 – 添加要更改的键和值
- en: '](img/Figure_4.17_B17405.jpg)'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_4.17_B17405.jpg)'
- en: Figure 4.17 – Adding the key and value for what to change
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.17 – 添加要更改的键和值
- en: For the completion report, browse to the `final-reports` folder that we created
    earlier by uploading a copy of the `manifest` file via the CLI:![Figure 4.18 –
    Choosing the destination for the S3 Batch reports
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于完成报告，通过 CLI 上传 `manifest` 文件副本后，浏览到我们之前创建的 `final-reports` 文件夹：![图 4.18 –
    选择 S3 批处理报告的目的地
- en: '](img/Figure_4.18_B17405.jpg)'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_4.18_B17405.jpg)'
- en: Figure 4.18 – Choosing the destination for the S3 Batch reports
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.18 – 选择 S3 批处理报告的目的地
- en: Under permission, choose from the existing IAM roles and then, in the drop-down
    box, select the **S3-Batch-Tagging-Role** that you created at the beginning of
    this exercise. Click on the orange **Next** button at the bottom of the page.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在权限下，选择现有的 IAM 角色，然后在下拉框中选择你在本次练习开始时创建的**S3-Batch-Tagging-Role**。点击页面底部的橙色**下一步**按钮。
- en: On the review page, scroll all the way to the bottom and click on the orange
    **Create job** button.
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在审查页面，滚动到底部并点击橙色的**创建任务**按钮。
- en: Once you have created the job you will now be brought back to the S3 batch main
    screen. It may take a minute or two for the job to finish being created, but once
    it has, you can select the radio button to the left and then click on the button
    labeled **Run job**. This will start processing all the tags on the files in your
    manifest.
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你创建了任务，你将被带回 S3 批处理主界面。任务创建可能需要一两分钟，但创建完成后，你可以选择左侧的单选按钮，然后点击标有**运行任务**的按钮。这将开始处理清单中所有文件的标签。
- en: We can now go back to the AWS Management Console and navigate to our S3 bucket
    so we can look at our files to see if the **Delete** tag has been added.
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以返回AWS管理控制台并导航到我们的S3存储桶，查看我们的文件，看看是否已经添加了**删除**标签。
- en: Note
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意事项
- en: The manifest that has been uploaded in the GitHub repository has the S3 example
    bucket name. You will need to change the bucket name on the manifest for the S3
    bucket that you have created before uploading and running your batch job.
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在GitHub存储库中上传的清单包含了S3示例存储桶的名称。在上传和运行批处理作业之前，您需要更改清单中的存储桶名称，修改为您创建的S3存储桶名称。
- en: S3 replication
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: S3复制
- en: 'Even with its high durability guarantees, there are numerous cases where you
    need to devise a plan to protect your data in case of regional outage or loss.
    You might even want to copy your original data, which is restricted by access
    policies, somewhere else so that another team can access that data. This is where
    **S3 replication** comes into play. It gives you the ability to asynchronously
    copy your data to another bucket. There are two versions of S3 replication available:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在其高耐久性保证下，仍然有许多情况需要您制定计划以保护数据，以防出现区域性故障或数据丢失。您甚至可能希望将受访问策略限制的原始数据复制到其他地方，以便另一个团队可以访问这些数据。这时，**S3复制**功能就派上用场了。它使您能够异步地将数据复制到另一个存储桶中。S3复制有两种版本可用：
- en: '**Cross-Region Replication** (**CRR**): This is where the objects in the bucket
    are replicated into a separate bucket that has been created in a different region
    than the primary region in which the original bucket was created.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跨区域复制**（**CRR**）：这意味着存储桶中的对象会被复制到一个在与原始存储桶所在区域不同的区域中创建的独立存储桶中。'
- en: '**Single Region Replication** (**SRR**): In SRR, objects are still replicated
    to a new separate bucket from the originating bucket, but both buckets are in
    the same geographical region.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单区域复制**（**SRR**）：在SRR中，对象仍然会被复制到一个新的独立存储桶中，但两个存储桶都位于相同的地理区域。'
- en: S3 versioning
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: S3版本控制
- en: In the S3 service, you can keep track of how files change over time using the
    versioning feature. While this feature does add additional cost, it is especially
    useful as a way to help restore deleted objects.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在S3服务中，您可以使用版本控制功能跟踪文件随时间的变化。虽然该功能确实会增加额外的成本，但它在帮助恢复被删除对象时特别有用。
- en: 'Once you enable versioning, each object in that S3 bucket gets a value for
    the version ID. If you haven''t enabled versioning on the bucket, then the version
    id for the objects in the bucket is set to null:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦启用版本控制，S3存储桶中的每个对象都会获得一个版本ID。如果您没有在存储桶上启用版本控制，那么存储桶中对象的版本ID将被设置为null：
- en: '![Figure 4.19 – An S3 bucket with versioning enabled showing version ids'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.19 – 启用版本控制的S3存储桶，显示版本ID'
- en: '](img/Figure_4.19_B17405.jpg)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_4.19_B17405.jpg)'
- en: Figure 4.19 – An S3 bucket with versioning enabled showing version ids
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.19 – 启用版本控制的S3存储桶，显示版本ID
- en: Once you upload a subsequent version of the object with versioning turned on,
    Amazon produces a new version id for the new version of the object and then places
    that newer version of the object in the bucket.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您上传启用了版本控制的对象的新版本，亚马逊会为该新版本生成一个新的版本ID，并将该新版本的对象放入存储桶中。
- en: Summary
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the AWS S3 service and many of its features. We
    examined not only the basics of creating buckets and how buckets are secured with
    the different types of access policies but also how you can encrypt your data
    at rest using different encryption methods from AWS. We also saw how to trigger
    workflows using bucket events to do things such as kick off our DevOps pipeline.
    Now that we have a firm understanding of object storage, we will move on to the
    serverless NoSQL database DynamoDB.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们介绍了AWS S3服务及其众多功能。我们不仅讲解了创建存储桶的基础知识，以及如何通过不同类型的访问策略保护存储桶，还介绍了如何使用AWS的不同加密方法对静态数据进行加密。我们还看到了如何通过存储桶事件触发工作流，例如启动我们的DevOps流水线。现在我们对对象存储有了更深入的了解，接下来我们将继续学习无服务器的NoSQL数据库DynamoDB。
- en: Review questions
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 复习题
- en: You have a department in your company that needs an S3 bucket configured where
    the objects are accessed on a weekly basis and need to be both durable and reliable.
    Which S3 storage class should you use to configure the bucket?
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您公司有一个部门需要配置一个S3存储桶，该存储桶中的对象每周都会被访问，并且需要具备高耐久性和可靠性。您应该使用哪个S3存储类型来配置该存储桶？
- en: You have five departments in your organization. Three of the departments are
    product teams, one is the accounting department, and one is the HR department.
    The accounting department has decided to migrate their files to S3 from the data
    center in order to save costs. How can you be sure that only members of the accounting
    department have access to the accounting files and no one else?
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的组织有五个部门。其中三个部门是产品团队，一个是会计部门，另一个是人力资源部门。会计部门决定将其文件从数据中心迁移到S3以节省成本。如何确保只有会计部门的成员可以访问会计文件，而其他人无法访问？
- en: A healthcare company is preparing for an internal audit. They need to make sure
    that all of their files stored in S3 have been encrypted and that the keys are
    rotated no less than once per year. The company has been in business for over
    15 years and has recently (in the last 5 years) made a digital push to move the
    majority of its files onto the cloud. This has resulted in over 1.5 million documents,
    including billing records, patient information, business information, and other
    documents being stored. What is the most effective way to check for this continually?
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一家医疗保健公司正在准备内部审计。他们需要确保存储在S3中的所有文件都已加密，并且密钥每年至少轮换一次。该公司成立已超过15年，并在最近5年内推动了大量文件转移到云上。这导致存储了超过150万份文件，包括账单记录、患者信息、业务信息和其他文档。最有效的持续检查方法是什么？
- en: Review answers
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查答案
- en: S3 Standard.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: S3标准。
- en: Make sure that an IAM group has been created just for members of the accounting
    department. Create an IAM (user-based) policy that allows members of the accounting
    group to have full permissions on the accounting bucket. You could go a step further
    and create a policy boundary that explicitly denies access to the accounting bucket
    and place that on all other groups.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保为会计部门的成员创建了一个IAM组。创建一个IAM（基于用户）策略，允许会计组的成员对会计桶具有完全权限。您还可以进一步创建一个策略边界，明确拒绝其他所有组访问会计桶。
- en: Create an S3 inventory report. Use AWS Athena to query for files that are not
    encrypted.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个S3清单报告。使用AWS Athena查询未加密的文件。
