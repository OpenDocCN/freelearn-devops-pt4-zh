- en: '*Chapter 8*: Understanding GKE Essentials to Deploy Containerized Applications'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第8章*：理解 GKE 基础知识以部署容器化应用'
- en: Kubernetes or K8s is an open source container orchestration system for automating
    the application deployment, scaling, and management of a cluster running containerized
    applications. The previous chapter introduced K8s fundamentals, including cluster
    anatomy, master plane components, Kubernetes objects (such as Pods and Services),
    workloads such as Deployments, StatefulSets, DaemonSets, and so on, and deep-dived
    into deployment strategies. However, setting up an open source Kubernetes cluster
    involves a lot of work at the infrastructure level and will also take a lot of
    time to set up. This also includes post-maintenance activities such as updating,
    upgrading, or repairing the cluster. GCP provides a compute offering that provides
    a managed Kubernetes or K8s environment called **Google Kubernetes Engine** (**GKE**).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 或 K8s 是一个开源的容器编排系统，用于自动化应用程序的部署、扩展和管理运行容器化应用程序的集群。前一章介绍了 K8s 的基础知识，包括集群结构、主平面组件、Kubernetes
    对象（如 Pods 和 Services）、工作负载（如 Deployments、StatefulSets、DaemonSets 等），并深入探讨了部署策略。然而，搭建一个开源的
    Kubernetes 集群涉及大量基础设施层面的工作，并且需要花费大量时间来设置。此外，还包括后期的维护活动，如更新、升级或修复集群。GCP 提供了一个计算服务，提供一个托管的
    Kubernetes 或 K8s 环境，称为 **Google Kubernetes Engine** (**GKE**)。
- en: 'The chapter introduces Google Kubernetes Engine as the managed Kubernetes option
    in GCP and uses the concepts introduced in [*Chapter 7*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154),
    *Understanding Kubernetes Essentials to Deploy Containerized Applications*, to
    create a managed GKE cluster, deploy a containerized application into the cluster,
    and expose the application to be accessible from external clients. The chapter
    later details key GKE features, including the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了作为 GCP 中托管 Kubernetes 选项的 Google Kubernetes Engine，并使用在 [*第7章*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154)
    中介绍的概念，*理解 Kubernetes 基础知识以部署容器化应用*，来创建一个托管的 GKE 集群，将容器化应用程序部署到集群中，并使该应用程序可供外部客户端访问。本章随后详细介绍了
    GKE 的关键特性，包括以下内容：
- en: '**Google Kubernetes Engine (GKE) – introduction**'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Kubernetes Engine (GKE) – 介绍**'
- en: '**GKE – core features**'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GKE – 核心特性**'
- en: '**GKE Autopilot – hands-on lab**'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GKE 自动驾驶模式 – 实操实验**'
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'There are four main technical requirements:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 有四个主要的技术要求：
- en: 'A valid **Google Cloud Platform** (**GCP**) account to go hands-on with GCP
    services: [https://cloud.google.com/free](https://cloud.google.com/free)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个有效的 **Google Cloud Platform** (**GCP**) 账户，以便使用 GCP 服务： [https://cloud.google.com/free](https://cloud.google.com/free)
- en: 'Install Google Cloud SDK: [https://cloud.google.com/sdk/docs/quickstart](https://cloud.google.com/sdk/docs/quickstart)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '安装 Google Cloud SDK: [https://cloud.google.com/sdk/docs/quickstart](https://cloud.google.com/sdk/docs/quickstart)'
- en: 'Install Git: [https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '安装 Git: [https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)'
- en: 'Install Docker: [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '安装 Docker: [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)'
- en: Google Kubernetes Engine (GKE) – introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Google Kubernetes Engine (GKE) – 介绍
- en: GKE is managed K8s and abstracts away the need to manage the master plane components
    from a user's standpoint. Creating a GKE cluster is much easier than creating
    a K8s cluster. This is because GKE cluster creation removes the need to manually
    create nodes, configure nodes and certificates, and establish network communication
    between the nodes. GKE also offers options to autoscale and manage auto-upgrades
    of the cluster's node software.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 是一个托管的 K8s，能够从用户的角度抽象出管理主平面组件的需求。创建 GKE 集群比创建 K8s 集群要简单得多。这是因为 GKE 集群创建过程中无需手动创建节点、配置节点和证书、以及建立节点间的网络通信。GKE
    还提供了自动扩展和管理集群节点软件自动升级的选项。
- en: 'The following are the key features of a GKE cluster. These features differentiate
    GKE from open source Kubernetes or K8s:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 GKE 集群的关键特性，这些特性使 GKE 与开源 Kubernetes 或 K8s 区别开来：
- en: Fully managed and abstracts away the need for a user to provide underlying resources.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全托管，抽象出用户无需提供底层资源的需求。
- en: Uses a container-optimized OS, an OS that is maintained by Google and is built
    to scale quickly with minimal resource requirements.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一种容器优化的操作系统，这是一种由 Google 维护的操作系统，专为快速扩展且资源需求最小化而设计。
- en: Supports auto-upgrade and provides options to either get the latest available
    features or a more stable version without manual intervention.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持自动升级，并提供选项，可以选择获取最新的功能，或是选择更稳定的版本，而无需手动干预。
- en: Provides the ability to auto-repair nodes by continuously monitoring the status
    of the nodes. If unhealthy, the nodes are gracefully drained and recreated.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供自动修复节点的功能，通过持续监控节点的状态。如果节点不健康，会优雅地将其排空并重新创建。
- en: Automatically scales the cluster by adding more nodes as needed.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据需要自动扩展集群，添加更多的节点。
- en: 'In addition to the preceding list, here are some additional key features that
    are available in K8s but need to be added and explicitly maintained as add-ons.
    These come as standard with GKE, thus making GKE a more viable and preferred option
    when compared to K8s:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除了前述功能，以下是一些 K8s 中可用的关键功能，这些功能需要作为附加组件添加并显式维护。而这些功能在 GKE 中是标准配置，使得 GKE 相比 K8s
    更加可行和优选：
- en: Load balancer – GKE provides a HTTP(S) load balancer.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负载均衡器——GKE 提供了一个 HTTP(S) 负载均衡器。
- en: DNS – GKE implements service discovery and provides a managed DNS.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DNS——GKE 实现了服务发现，并提供了托管 DNS。
- en: Logging, monitoring, and dashboard – GKE provides these features built in due
    to its integration with Google Cloud operations.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志、监控和仪表板——由于与 Google Cloud 操作的集成，GKE 提供了这些内置功能。
- en: Until recently, GKE offered only one mode of operation called **Standard** (also
    referred to as default). The Standard mode allows users to select the configurations
    needed to run workloads such as the node's machine type. This mode also allows
    you to select security configuration features, provides the ability to group nodes
    that run similar workloads, provides options to configure networking, and so on.
    Essentially, creating a cluster through GKE Standard mode is much easier than
    in open source K8s, but there is still a learning curve.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 直到最近，GKE 只提供了一种操作模式，称为 **标准** 模式（也称为默认模式）。标准模式允许用户选择运行工作负载所需的配置，例如节点的机器类型。此模式还允许选择安全配置功能，提供将运行相似工作负载的节点分组的能力，提供配置网络的选项等。总的来说，通过
    GKE 标准模式创建集群比在开源 K8s 中要容易，但仍然有学习曲线。
- en: GKE recently introduced a new mode of operation called Autopilot. Autopilot
    has many of the configurations pre-selected and essentially creates a production-grade
    cluster that is hardened from a security standpoint. There are a few options to
    configure but, most importantly, the nodes are provisioned only when workloads
    are deployed. Autopilot mode will be discussed in detail later in this chapter
    through a hands-on lab.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 最近引入了一种新的操作模式，称为 Autopilot。Autopilot 预先选择了许多配置，基本上创建了一个从安全角度强化的生产级集群。虽然有一些配置选项，但最重要的是，只有在工作负载部署时才会配置节点。Autopilot
    模式将在本章后面通过动手实验详细讨论。
- en: Important note
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The current chapter focuses on *Standard* mode unless explicitly specified.
    This will help you to understand the available options while creating a GKE cluster
    and provides insights into GKE features. Later in this chapter, the Autopilot
    mode will be elaborated on, calling out the key differences between the Standard
    and Autopilot modes, along with a hands-on lab.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当前章节重点讲解 *标准* 模式，除非明确说明。本章将帮助你了解在创建 GKE 集群时可用的选项，并提供 GKE 功能的洞见。后续章节会详细介绍 Autopilot
    模式，强调标准模式和 Autopilot 模式之间的主要区别，并附带一个动手实验。
- en: GKE provides seamless integration with multiple service offerings from GCP.
    GKE provides options to automate deployment by building code stored in a source
    code repository using Cloud Build, which results in private container images that
    could be stored in Google's Container Registry. In addition, access to the cluster
    and the ability to configure GKE cluster options can be controlled via Google's
    **Identity and Access Management** (**IAM**). GKE integrates with GCP's network
    offerings as a GKE cluster is created as part of Google's Virtual Private Cloud
    or VPC. GCP provides insights into a GKE cluster and its resources as GKE integrates
    with Google's Cloud operations, a suite of tools from Google aimed at providing
    integrated services related to monitoring and logging.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 与 GCP 的多项服务提供无缝集成。GKE 提供选项，通过使用 Cloud Build 构建存储在源代码仓库中的代码自动化部署，从而生成可以存储在
    Google 容器注册表中的私有容器镜像。此外，通过 Google 的**身份和访问管理**（**IAM**）可以控制访问集群的权限和配置 GKE 集群选项。GKE
    与 GCP 的网络服务集成，因为 GKE 集群作为 Google 的虚拟私有云（VPC）的一部分创建。GCP 提供对 GKE 集群及其资源的洞察，GKE 与
    Google 的 Cloud operations 集成，Cloud operations 是 Google 提供的一套旨在提供与监控和日志相关的集成服务的工具。
- en: We will start by creating a GKE cluster through a step-by-step process. This
    will provide an insight into the possible configuration options. Once the cluster
    is created, the user will be able to deploy an application through the concept
    of a Deployment and expose the application through the concept of a Service. The
    application runs inside a container wrapped by a Pod. The Deployment specification
    will manage the Pod. The Pod is then exposed using the concept of a Service. The
    concepts of Pods, Deployments, and services are K8s fundamentals that were discussed
    in [*Chapter 7*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154), *Understanding
    Kubernetes Essentials to Deploy Containerized Applications*, and these concepts
    will be put into action on an actual GKE cluster.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过逐步过程创建一个 GKE 集群，这将提供对可能配置选项的洞察。集群创建完成后，用户将能够通过 Deployment 的概念部署应用，并通过 Service
    的概念暴露应用。应用运行在由 Pod 包裹的容器中。Deployment 规格将管理 Pod。Pod 随后通过 Service 的概念进行暴露。Pod、Deployment
    和 Service 这些概念是 K8s 基础知识，已经在[*第 7 章*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154)《理解
    Kubernetes 基础知识以部署容器化应用》中讨论过，这些概念将在实际的 GKE 集群中付诸实践。
- en: Creating a GKE cluster
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 GKE 集群
- en: 'There are multiple ways to create a GKE cluster – the Cloud Console, CLI, or
    REST. To create a cluster, the user or the service account should have one of
    the following pre-defined roles: Kubernetes Engine Admin or Kubernetes Engine
    Cluster Admin.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 GKE 集群有多种方式——Cloud Console、CLI 或 REST。要创建集群，用户或服务帐户应具备以下预定义角色之一：Kubernetes
    引擎管理员或 Kubernetes 引擎集群管理员。
- en: 'The following is a step-by-step process to create a GKE cluster from the Google
    Cloud Console. The mode of operation will be **Standard** in this specific example:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过 Google Cloud Console 创建 GKE 集群的逐步过程。此示例中的操作模式为**标准**模式：
- en: Navigate to the GCP Console and select the compute service – **Kubernetes Engine**.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航至 GCP 控制台并选择计算服务 – **Kubernetes 引擎**。
- en: Select the option to create a cluster and choose the **Standard** mode.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择创建集群的选项并选择**标准**模式。
- en: Enter the name for the cluster as `my-first-cluster`.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入集群名称为 `my-first-cluster`。
- en: Leave the default selections for the rest of the options. Refer to *Figure 8.1*:![Figure
    8.1 – Creating a GKE Cluster from the GCP Console
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保留其余选项的默认选择。请参见 *图 8.1*：
- en: '](img/B15587_08_01.jpg)'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_01.jpg)'
- en: Figure 8.1 – Creating a GKE Cluster from the GCP Console
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.1 – 从 GCP 控制台创建 GKE 集群
- en: Select the option to **CREATE** the cluster. This will initiate the cluster
    creation process.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**创建**集群的选项。这将启动集群创建过程。
- en: 'The newly created cluster will be displayed on the cluster home page. Refer
    to *Figure 8.2*:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新创建的集群将在集群主页显示。请参见 *图 8.2*：
- en: '![Figure 8.2 – The GKE cluster list page displays the newly created cluster'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.2 – GKE 集群列表页面显示新创建的集群](img/B15587_08_02.jpg)'
- en: '](img/B15587_08_02.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_02.jpg)'
- en: Figure 8.2 – The GKE cluster list page displays the newly created cluster
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 – GKE 集群列表页面显示新创建的集群
- en: 'The newly created cluster used the default options. Nothing really was changed
    during the cluster creation except for the cluster name. The following are some
    important points to know when a GKE cluster is created with default options. Each
    of the default options mentioned in the following list can be explicitly changed
    during cluster creation:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 新创建的集群使用了默认选项。除集群名称外，集群创建过程中没有进行任何实际更改。以下是使用默认选项创建GKE集群时需要了解的一些重要事项。列表中提到的每个默认选项都可以在集群创建过程中显式更改：
- en: The default **Location type** of the cluster is **Zonal**. **Location type**
    refers to the cluster based on availability requirements. The options are **Zonal**
    and **Regional**.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群的默认**位置类型**为**区域性**。**位置类型**指的是基于可用性要求的集群类型。可选项有**区域性**和**区域级别**。
- en: The default `us-central1-c`. This indicates the zone where the control plane
    components are created.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认值为`us-central1-c`。这表示控制平面组件的创建区域。
- en: The default `us-central1-c`. This indicates where the nodes are created. Multiple
    locations within a region can be selected to form a cluster where the location
    type is a multi-zonal cluster.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认值为`us-central1-c`。这表示节点创建的位置。可以选择区域内的多个位置来形成一个集群，其中位置类型是多区域集群。
- en: The default **Control plane version** is **Release channel**. **Control plane
    version** provides options to signify the cluster version. The cluster version
    is indicative of the preferred feature set in terms of stability.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认**控制平面版本**为**发布通道**。**控制平面版本**提供了指示集群版本的选项。集群版本代表了在稳定性方面首选的功能集。
- en: The `3`, indicating the number of worker nodes. The cluster, by default, only
    has 1 node pool. It's important to note that the cluster size doesn't include
    the master node count. Customers only pay for the worker nodes. The master node
    and the associated master plane components are entirely managed by GKE.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`3`，表示工作节点的数量。集群默认只有1个节点池。需要注意的是，集群大小不包括主节点的数量。客户仅需为工作节点付费。主节点及其相关的主平面组件完全由GKE管理。'
- en: The `default-pool`. A node pool is a collection of VMs.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`default-pool`。节点池是虚拟机的集合。'
- en: The default node pool consists of 3 nodes and the machine type for the node
    is `e2-medium` (2 vCPU, 4 GB memory).
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认节点池由3个节点组成，节点的机器类型为`e2-medium`（2个vCPU，4 GB内存）。
- en: The default **Maintenance Window** is **anytime**. This implies that GKE maintenance
    can run at any time on the cluster. This is not the preferred option when running
    production workloads.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认**维护窗口**为**随时**。这意味着GKE维护可以在集群上的任何时间进行。这不是在运行生产工作负载时的首选选项。
- en: The default cluster type based on networking is **Public cluster** and the default
    **VPC network** is **default**. This indicates how clients can reach the control
    plane and how applications in the cluster communicate with each other and with
    the control plane.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于网络的默认集群类型为**公共集群**，默认**VPC网络**为**default**。这表示客户端如何访问控制平面，以及集群中的应用程序如何彼此之间以及与控制平面进行通信。
- en: Advanced networking options such as **VPC-native traffic routing** and **HTTP
    Load Balancing** are *enabled* by default. These options are discussed in detail
    in the sub-section *Networking in GKE*, later in this chapter
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级网络选项，如**VPC原生流量路由**和**HTTP负载均衡**，默认是*启用*的。这些选项将在本章稍后的子章节*GKE中的网络*中详细讨论。
- en: '`110`.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`110`。'
- en: The security feature **Shielded GKE Node** is *enabled*. This feature provides
    strong cryptographic identity for nodes joining a cluster and is discussed in
    detail as part of [*Chapter 9*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201),
    *Securing the Cluster Using GKE Security Constructs*.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全功能**Shielded GKE节点**已*启用*。该功能为加入集群的节点提供强加密身份，并将在[*第9章*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201)中详细讨论，章节标题为*使用GKE安全构件保护集群*。
- en: Cloud operations for GKE are enabled and are set to **System, workload logging
    and monitoring**. This feature aggregates logs, events, and metrics for both infrastructure
    and application-level workloads.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE的云操作已启用，并设置为**系统、工作负载日志记录和监控**。此功能会聚合基础设施和应用级工作负载的日志、事件和指标。
- en: 'A cluster can also be created from the **Command-Line Interface** (**CLI**).
    The following is the CLI command to create a cluster with default options. The
    default options used in the CLI are the same as the default options used while
    creating a cluster from the console as described previously. One significant difference,
    however, is that it is mandatory to explicitly specify a zone while executing
    through the CLI. However, the zone is auto-filled in the UI unless modified:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以通过**命令行界面**（**CLI**）创建集群。以下是使用默认选项创建集群的 CLI 命令。CLI 中使用的默认选项与之前从控制台创建集群时使用的默认选项相同。一个显著的区别是，在通过
    CLI 执行时，必须显式指定一个区域。然而，在 UI 中，区域会自动填充，除非进行了修改：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This CLI command can be run from the terminal window of your local machine,
    which has Google Cloud SDK installed and configured. Alternatively, the CLI command
    can also be executed using Google Cloud Shell, activated through the Google Cloud
    Console.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 该 CLI 命令可以从本地计算机的终端窗口运行，该计算机已经安装并配置了 Google Cloud SDK。或者，也可以通过 Google Cloud
    Console 激活 Google Cloud Shell 来执行该命令。
- en: Given that a GKE cluster is created, the next step is to deploy an application
    onto the GKE cluster and expose the application to an external client. This is
    discussed as the next topic.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GKE 集群创建后，下一步是将应用程序部署到 GKE 集群，并将其公开给外部客户端。接下来将讨论这一主题。
- en: GKE cluster – deploying and exposing an application
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE 集群 – 部署并公开应用程序
- en: In [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131), *Building
    code using Cloud Build, and Pushing to Container Registry*, we created a container
    image, and the container image was deployed using Cloud Run. In this chapter and
    in this sub-section, we will reuse this image and deploy it to the newly created
    GKE cluster by creating appropriate workloads. Once the application is deployed,
    the application will be exposed via a Service so that the application can be reached
    via an external client such as a web browser.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第 6 章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)中，*使用 Cloud Build
    构建代码并推送到容器注册表*，我们创建了一个容器镜像，并使用 Cloud Run 部署了该容器镜像。在本章及本小节中，我们将重用此镜像，并通过创建适当的工作负载将其部署到新创建的
    GKE 集群中。应用程序部署后，将通过服务公开，以便外部客户端（如网页浏览器）可以访问该应用程序。
- en: Important note
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: For continuity from an example standpoint, we will be using the container image
    created in [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131), *Building
    code using Cloud Build, and Pushing to Container Registry* – `gcr.io/gcp-devops-2021/cloud-build-trigger`.
    It's recommended to use an appropriate container image of your choice that you
    have access to. For example, if you followed the step-by-step instructions in
    [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131), *Building code
    using Cloud Build, and Pushing to Container Registry*, and ended up creating a
    container image in your project, you can reuse the same image in this chapter.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持示例的连续性，我们将使用在[*第 6 章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)中创建的容器镜像，*使用
    Cloud Build 构建代码并推送到容器注册表* – `gcr.io/gcp-devops-2021/cloud-build-trigger`。建议使用你有权限访问的适当容器镜像。例如，如果你按照[*第
    6 章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)中的逐步说明，*使用 Cloud Build 构建代码并推送到容器注册表*，并最终在你的项目中创建了一个容器镜像，你可以在本章中重用相同的镜像。
- en: 'We will deploy the application and expose the application in two different
    ways:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以两种不同的方式部署并公开应用程序：
- en: GKE Console
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE 控制台
- en: The CLI approach via Cloud Shell
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 Cloud Shell 的 CLI 方法
- en: It's important to note that a cluster is typically deployed in most cases through
    the command line. However, we will first explore the GKE Console approach as this
    will give us insights into the available configuration options. This is covered
    as the next topic.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，在大多数情况下，集群通常通过命令行部署。然而，我们将首先探索 GKE 控制台的方法，因为这将使我们深入了解可用的配置选项。接下来将讨论这一主题。
- en: GKE Console
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE 控制台
- en: The first step is to deploy the application to the GKE cluster through the GKE
    Console.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是通过 GKE 控制台将应用程序部署到 GKE 集群中。
- en: Deploying an application to the GKE cluster
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将应用程序部署到 GKE 集群
- en: 'The following is the step-by-step process to deploy an application through
    the GKE Console:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在 GKE 控制台中部署应用程序的逐步过程：
- en: Navigate to the **Clusters** page in the **Kubernetes Engine** section of the
    GCP Console.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 GCP 控制台的 **Kubernetes Engine** 部分，导航到 **Clusters** 页面。
- en: Select the cluster that was previously created – `my-first-cluster`.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择之前创建的集群 – `my-first-cluster`。
- en: On the left-hand pane, select the section **Workloads**. From a GKE perspective,
    workloads refer to Deployments, StatefulSets, DaemonSets, Jobs, and CronJobs.
    There are no workloads at this moment and the current state will be as shown in
    *Figure 8.3*:![Figure 8.3 – The Workloads section of a newly created cluster
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧面板中，选择**工作负载**部分。从 GKE 的角度来看，工作负载指的是 Deployments、StatefulSets、DaemonSets、Jobs
    和 CronJobs。目前没有工作负载，当前状态如下所示，参见*图 8.3*：![图 8.3 – 新创建集群的工作负载部分
- en: '](img/B15587_08_03.jpg)'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_03.jpg)'
- en: Figure 8.3 – The Workloads section of a newly created cluster
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.3 – 新创建集群的工作负载部分
- en: Create a workload by selecting the **DEPLOY** option. This action allows you
    to create a Deployment object in a two-step process.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过选择**部署**选项来创建工作负载。此操作允许您通过两步过程创建 Deployment 对象。
- en: The first step to create a Deployment is to define the containers required for
    the Deployment. Select the container image created in [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131),
    *Building code using Cloud Build, and Pushing to Container Registry*. For this
    example, select the container image `gcr.io/gcp-devops-2021/cloud-build-trigger`.
    Refer to *Figure 8.4*. Optionally, add environment variables for the container
    and click on **Done**:![Figure 8.4 – Selecting container image while defining
    a container for Deployment
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 Deployment 的第一步是定义 Deployment 所需的容器。选择在[*第 6 章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)中创建的容器镜像，*使用
    Cloud Build 构建代码并推送到容器注册表*。对于这个示例，选择容器镜像 `gcr.io/gcp-devops-2021/cloud-build-trigger`。参见*图
    8.4*。可选地，添加容器的环境变量，并点击**完成**：![图 8.4 – 在定义 Deployment 容器时选择容器镜像
- en: '](img/B15587_08_04.jpg)'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_04.jpg)'
- en: Figure 8.4 – Selecting container image while defining a container for Deployment
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.4 – 在定义 Deployment 容器时选择容器镜像
- en: Optionally, multiple containers can be added to the Pod by using the **ADD CONTAINER**
    option. Refer to *Figure 8.5*:![Figure 8.5 – The option to add multiple containers
    to a Deployment
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，可以通过使用**添加容器**选项将多个容器添加到 Pod 中。请参阅*图 8.5*：![图 8.5 – 向 Deployment 添加多个容器的选项
- en: '](img/B15587_08_05.jpg)'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_05.jpg)'
- en: Figure 8.5 – The option to add multiple containers to a Deployment
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.5 – 向 Deployment 添加多个容器的选项
- en: The second step in creating a Deployment is to configure the Deployment. This
    includes specifying the application name, namespace, labels, and the cluster to
    which the application should be deployed. For this specific example, set `hello-world`,
    `default`, `app` and `hello-world`, and select the cluster called `my-first-cluster`.
    Refer to *Figure 8.6*:![Figure 8.6 – Configuring a Deployment by specifying the
    required attributes
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 Deployment 的第二步是配置 Deployment。这包括指定应用程序名称、命名空间、标签以及应用程序应该部署到的集群。对于这个具体示例，设置
    `hello-world`、`default`、`app` 和 `hello-world`，并选择名为 `my-first-cluster` 的集群。参见*图
    8.6*：![图 8.6 – 通过指定所需属性来配置 Deployment
- en: '](img/B15587_08_06.jpg)'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_06.jpg)'
- en: Figure 8.6 – Configuring a Deployment by specifying the required attributes
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.6 – 通过指定所需属性来配置 Deployment
- en: Before selecting the **DEPLOY** option, the configuration YAML can be viewed
    by selecting the **VIEW YAML** option as shown in *Figure 8.6*. By default, the
    number of replicas is defined as 3\. This can optionally be changed to the desired
    replica count.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在选择**部署**选项之前，可以通过选择**查看 YAML**选项来查看配置的 YAML，如*图 8.6*所示。默认情况下，副本数定义为 3。这可以根据需要更改为所需的副本数量。
- en: Initiate the deployment creation process by selecting the **DEPLOY** option.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过选择**部署**选项来启动部署创建过程。
- en: 'The newly created Deployment – `hello-world` – will be displayed as follows.
    This Deployment created three replicas with the same image. Refer to *Figure 8.7*:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新创建的 Deployment – `hello-world` – 将如下所示显示。此 Deployment 创建了三个副本，使用相同的镜像。请参阅*图
    8.7*：
- en: '![Figure 8.7 – Details of the newly created Deployment'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.7 – 新创建的 Deployment 的详细信息'
- en: '](img/B15587_08_07.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_07.jpg)'
- en: Figure 8.7 – Details of the newly created Deployment
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 – 新创建的 Deployment 的详细信息
- en: 'It is important to note that the newly created Deployment – `hello-world` –
    cannot be accessed from external clients (such as a web browser or through a `ping`
    command) as the Deployment is not exposed as a Service. However, the application
    can still be tested by using the `port-forward` option. The CLI commands required
    to execute this option are shown in the following snippet. These commands can
    be executed through Google Cloud Shell:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，新创建的部署 – `hello-world` – 不能被外部客户端（如 Web 浏览器或通过 `ping` 命令）访问，因为该部署没有被暴露为
    Service。然而，仍然可以通过使用 `port-forward` 选项进行测试。执行此选项所需的 CLI 命令如下所示。这些命令可以通过 Google
    Cloud Shell 执行：
- en: '[PRE1]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once the preceding `port-forward` command is executed, traffic coming on `127.0.0.1:10080`
    will be forwarded to port `8080`. Port `8080` is the container port related to
    the `hello-world` Deployment. Refer to *Figure 8.8*:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦执行上述 `port-forward` 命令，来自 `127.0.0.1:10080` 的流量将被转发到端口 `8080`。端口 `8080` 是与
    `hello-world` 部署相关的容器端口。参见 *图 8.8*：
- en: '![Figure 8.8 – Forwarding traffic to a container inside a Pod'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.8 – 将流量转发到 Pod 内部的容器'
- en: '](img/B15587_08_08.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_08.jpg)'
- en: Figure 8.8 – Forwarding traffic to a container inside a Pod
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 – 将流量转发到 Pod 内部的容器
- en: 'To test whether traffic is getting forwarded, open another Cloud Shell window
    and run the `curl` command as shown. This will do a REST call invocation against
    the application running inside the container of a Pod. Refer to *Figure 8.9*:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试流量是否被转发，打开另一个 Cloud Shell 窗口并运行如下 `curl` 命令。这将对在 Pod 容器内运行的应用进行 REST 调用。参见
    *图 8.9*：
- en: '![Figure 8.9 – Result of accessing the application in a Pod through port-forwarding'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.9 – 通过端口转发访问 Pod 中应用的结果'
- en: '](img/B15587_08_09.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_09.jpg)'
- en: Figure 8.9 – Result of accessing the application in a Pod through port-forwarding
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9 – 通过端口转发访问 Pod 中应用的结果
- en: Alternatively, you can also use the web preview option on port `10080` in Cloud
    Shell to view the application. Given that the application is now deployed and
    is working as expected, the next step is to expose the application as a Service.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你也可以在 Cloud Shell 中使用 `10080` 端口的 Web 预览选项来查看应用。由于应用已经部署并按预期工作，下一步是将该应用暴露为
    Service。
- en: Exposing the application as a Service
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将应用暴露为 Service
- en: 'The following is a step-by-step process to expose the application as a Service
    through the GCP Console:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过 GCP 控制台将应用暴露为 Service 的逐步过程：
- en: Navigate to the **Clusters** page in the **Kubernetes Engine** section of the
    GCP Console.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 GCP 控制台中 **Kubernetes Engine** 部分的 **Clusters** 页面。
- en: Select the cluster that was previously created – `my-first-cluster`.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择之前创建的集群 – `my-first-cluster`。
- en: Select the Deployment that was previously created – `hello-world`.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择之前创建的部署 – `hello-world`。
- en: Under the **Actions** menu on the deployment details page, select the **EXPOSE**
    option. This will open a pop-up window where **Port**, **Target port**, **Protocol**,
    and **Service type** need to be selected.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在部署详情页面的 **Actions** 菜单下，选择 **EXPOSE** 选项。这将打开一个弹出窗口，需要选择 **端口**、**目标端口**、**协议**
    和 **Service 类型**。
- en: Enter `80` (this represents the port where the Service will be listening for
    incoming traffic), `8080` (this is the port the container will be listening on),
    `TCP`, and `Load balancer`. Select the **EXPOSE** option. Refer to *Figure 8.10*:![Figure
    8.10 – Specifying port mapping to expose a Pod as a Service of type Load balancer
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入 `80`（表示 Service 监听传入流量的端口）、`8080`（表示容器监听的端口）、`TCP` 和 `负载均衡器`。选择 **EXPOSE**
    选项。参见 *图 8.10*：![图 8.10 – 指定端口映射，将 Pod 暴露为负载均衡器类型的 Service
- en: '](img/B15587_08_10.jpg)'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_10.jpg)'
- en: Figure 8.10 – Specifying port mapping to expose a Pod as a Service of type Load
    balancer
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.10 – 指定端口映射，将 Pod 暴露为负载均衡器类型的 Service
- en: Once the Pod is exposed, a Service will be created as shown in the following
    screenshot. Given the Service is of type **LoadBalancer**, the Service will have
    an external endpoint. Refer to *Figure 8.11*:![Figure 8.11 – The LoadBalancer
    Service created by exposing the Pod
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦 Pod 被暴露，就会创建一个 Service，如下图所示。由于该 Service 是 **LoadBalancer** 类型，Service 将具有一个外部端点。参见
    *图 8.11*：![图 8.11 – 通过暴露 Pod 创建的 LoadBalancer Service
- en: '](img/B15587_08_11.jpg)'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_11.jpg)'
- en: Figure 8.11 – The LoadBalancer Service created by exposing the Pod
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.11 – 通过暴露 Pod 创建的 LoadBalancer Service
- en: 'Select the external endpoint. This will open the application in the browser
    as shown in the following screenshot. This essentially is the output of deploying
    the application to the GKE cluster. The output is the same as the output in [*Chapter
    6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131), *Building code using Cloud
    Build, and Pushing to Container Registry*, when the same container image was deployed
    to Cloud Run. Refer to *Figure 8.12*:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择外部端点。这将在浏览器中打开应用程序，如下图所示。这基本上是将应用程序部署到 GKE 集群后的输出。输出与在 [*第 6 章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)，*使用
    Cloud Build 构建代码并推送到容器注册表* 中，使用相同的容器镜像部署到 Cloud Run 时的输出相同。参见 *图 8.12*：
- en: '![Figure 8.12 – Output of accessing the application through the load balancer
    Service'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.12 – 通过负载均衡器服务访问应用程序的输出'
- en: '](img/B15587_08_12.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_12.jpg)'
- en: Figure 8.12 – Output of accessing the application through the load balancer
    Service
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.12 – 通过负载均衡器服务访问应用程序的输出
- en: This completes the topic on deploying an application to the GKE cluster and
    exposing the application via a load balancer Service through the GKE Console.
    The next sub-section essentially works on a similar example but provides insights
    on how the same thing can be done through Cloud Shell using the CLI approach.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了将应用程序部署到 GKE 集群并通过 GKE 控制台将应用程序暴露为负载均衡器服务的主题。下一个子章节基本上是一个类似的示例，但提供了如何通过
    Cloud Shell 使用 CLI 方法完成相同任务的见解。
- en: The CLI approach via Cloud Shell
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过 Cloud Shell 使用 CLI 方法
- en: In this sub-section, we will deploy an application and expose the application
    as a load balancer Service through the CLI using Cloud Shell. We will use the
    same cluster as was previously created – `my-first-cluster`. It is also recommended
    to use the container image created as part of the exercise in [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131),
    *Building code using Cloud Build, and Pushing to Container Registry*. For this
    example, the container image `gcr.io/gcp-devops-2021/cloud-build-trigger` will
    be used.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个子章节中，我们将通过 CLI 使用 Cloud Shell 部署应用程序并将其暴露为负载均衡器服务。我们将使用之前创建的相同集群 — `my-first-cluster`。同时，建议使用作为练习一部分创建的容器镜像，位于
    [*第 6 章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)，*使用 Cloud Build 构建代码并推送到容器注册表*。在本示例中，将使用容器镜像
    `gcr.io/gcp-devops-2021/cloud-build-trigger`。
- en: Deploying an application to the GKE cluster
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将应用程序部署到 GKE 集群
- en: 'The following is the step-by-step process to deploy an application via Cloud
    Shell:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过 Cloud Shell 部署应用程序的逐步过程：
- en: 'Open Cloud Shell and connect to the cluster using the following CLI command:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Cloud Shell 并使用以下 CLI 命令连接到集群：
- en: '[PRE2]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create a new file called `hello-world-cli.yaml` with contents as follows. This
    file essentially creates a Deployment that has the container and respective image
    to be deployed. The replica count is also specified and in this case, is 1:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `hello-world-cli.yaml` 的新文件，内容如下。这个文件本质上创建了一个包含容器及其对应镜像的部署。还指定了副本数，在本例中为
    1：
- en: '[PRE3]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create the Deployment by running the following command:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令创建部署：
- en: '[PRE4]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once the Deployment is created, the Deployment and its respective Pod can be
    queried as follows through the CLI. Please note that this Deployment will create
    only one Pod. Refer to *Figure 8.13*:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦部署创建完成，可以通过 CLI 查询该部署及其相应的 Pod。请注意，此部署将只创建一个 Pod。参见 *图 8.13*：
- en: '![Figure 8.13 – Querying the Deployment through the CLI'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.13 – 通过 CLI 查询部署情况'
- en: '](img/B15587_08_13.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_13.jpg)'
- en: Figure 8.13 – Querying the Deployment through the CLI
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.13 – 通过 CLI 查询部署情况
- en: The deployed application cannot be accessed through an external client. However,
    the port-forward approach explained in the previous sub-section can be exactly
    applied in this context as well. Given that the application is now deployed, the
    next step is to expose the application as a Service.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 部署的应用程序无法通过外部客户端访问。然而，在前一个子章节中解释的端口转发方法也可以在此上下文中完全适用。鉴于应用程序已经部署，下一步是将应用程序暴露为服务。
- en: Exposing the application as a Service
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将应用程序暴露为服务
- en: 'The following is the step-by-step process to expose the application as a Service
    through Cloud Shell:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过 Cloud Shell 将应用程序暴露为服务的逐步过程：
- en: 'Create a new file called `hello-world-cli-service.yaml` with a definition as
    follows. This will create a load balancer Service that will expose a Pod with
    matching label selectors:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `hello-world-cli-service.yaml` 的新文件，定义如下。这将创建一个负载均衡器服务，将暴露带有匹配标签选择器的
    Pod：
- en: '[PRE5]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Create the load balancer Service by running the following command:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令创建负载均衡器服务：
- en: '[PRE6]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Once the Service is created, a load balancer will be created with an external
    endpoint. As per the Service definition, the Service will listen to traffic on
    port `80` and will forward the traffic to the container on port `8080`. The external
    endpoint of the Service can be found out by querying the Service as follows. Refer
    to *Figure 8.14*:![Figure 8.14 – Query the load balancer Service to fetch the
    external endpoint
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦创建了服务，负载均衡器将被创建并分配一个外部端点。根据服务定义，该服务将在`80`端口监听流量，并将流量转发到`8080`端口的容器。可以通过如下方式查询服务来获取服务的外部端点。请参见*图
    8.14*：![图 8.14 – 查询负载均衡器服务以获取外部端点
- en: '](img/B15587_08_14.jpg)'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_14.jpg)'
- en: Figure 8.14 – Query the load balancer Service to fetch the external endpoint
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.14 – 查询负载均衡器服务以获取外部端点
- en: 'Access the external endpoint through a browser window. The output will be the
    same as the output from [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131),
    *Building code using Cloud Build, and Pushing to Container Registry*, or the output
    from the application deployed in GKE through the console. This is because we are
    using the same image. Refer to *Figure 8.15*:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过浏览器窗口访问外部端点。输出将与[*第6章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)《使用Cloud
    Build构建代码并推送到容器注册表》中的输出或通过控制台在GKE中部署的应用程序的输出相同。这是因为我们使用的是相同的镜像。请参见*图 8.15*：
- en: '![Figure 8.15 – Viewing the output of the load balancer Service via an external
    endpoint'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.15 – 通过外部端点查看负载均衡器服务的输出'
- en: '](img/B15587_08_15.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_15.jpg)'
- en: Figure 8.15 – Viewing the output of the load balancer Service via an external
    endpoint
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.15 – 通过外部端点查看负载均衡器服务的输出
- en: This concludes this section, which introduced GKE and took a deep dive into
    the step-by-step process to create a GKE cluster, deploy an application to the
    cluster, and expose the deployed application as a Service to be accessed by external
    clients. Essentially, the output of this approach is the same as the output from
    the console approach. The goal is to understand the process of creating a cluster,
    deploying workloads, and exposing the workloads through a Service via the CLI.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 本节结束，介绍了GKE并深入探讨了创建GKE集群、将应用程序部署到集群并将已部署的应用程序公开为外部客户端可访问的服务的步骤。实际上，这种方法的输出与控制台方法的输出相同。目标是理解通过CLI创建集群、部署工作负载并通过服务暴露工作负载的过程。
- en: The concepts used while creating the cluster or deploying the application are
    the same concepts that form the fundamentals of K8s (learned about in [*Chapter
    7*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154), *Understanding Kubernetes
    Essentials to Deploy Containerized Applications*). However, the cluster creation
    is much simpler in nature since the maintenance of the master plane components
    is completely abstracted and is not the responsibility of the user. The upcoming
    section focuses on core GKE features and possible cluster types, and provides
    an introduction to integration with networking and cloud operations in GKE.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建集群或部署应用程序时使用的概念与构成K8s基础的概念相同（在[*第7章*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154)《理解Kubernetes基础以部署容器化应用》中已学习）。然而，集群创建的性质更加简单，因为主控平面组件的维护已完全抽象化，不再是用户的责任。接下来的部分将重点介绍GKE的核心功能和可能的集群类型，并介绍GKE中与网络和云操作的集成。
- en: GKE – core features
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GKE – 核心功能
- en: 'This section covers the following topics. These topics will provide a considerable
    amount of information, which is required to build a good understanding and working
    knowledge of GKE. Most of these GKE concepts are an extension of topics learned
    about in the Kubernetes section. The topics that will be covered are as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖以下主题。这些主题将提供大量信息，帮助您构建对GKE的良好理解和操作知识。这些GKE概念大多是Kubernetes部分学习的主题的扩展。将要覆盖的主题如下：
- en: GKE node pools
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE节点池
- en: GKE cluster types
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE集群类型
- en: Autoscaling in GKE
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE中的自动扩展
- en: Networking in GKE
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE中的网络
- en: Cloud operations for GKE
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE的云操作
- en: The first of the GKE constructs that will be detailed in the upcoming sub-section
    is GKE node pools.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来小节将详细介绍的第一个GKE构建块是GKE节点池。
- en: GKE node pools
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE节点池
- en: Nodes (that is, worker nodes) in a Kubernetes cluster deploy workloads. The
    nature of workloads deployed across all nodes might not be the same. Some workloads
    might be CPU-intensive, others might be memory-intensive, and some might need
    a minimum version of the CPU platform. Workloads can also be fault-tolerant batch
    jobs or might need a specific type of storage such as SSD.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群中的节点（即工作节点）部署工作负载。分布在所有节点上的工作负载性质可能不同。有些工作负载可能是 CPU 密集型的，有些可能是内存密集型的，还有些可能需要特定版本的
    CPU 平台。工作负载还可能是容错的批处理任务，或者需要特定类型的存储，如 SSD。
- en: A `nodeConfig` specification. All matching nodes that match the `nodeConfig`
    specification will be labeled using a node label where the key is `cloud.google.com/gke-nodepool`
    and the value is the name of the node pool.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`nodeConfig` 规范。所有符合 `nodeConfig` 规范的节点将使用节点标签标记，其中键为 `cloud.google.com/gke-nodepool`，值为节点池的名称。'
- en: 'The following is an example of a `nodeConfig` specification with a specific
    machine type, OAuth scopes, and a disk type:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个包含特定机器类型、OAuth 范围和磁盘类型的 `nodeConfig` 规范示例：
- en: '[PRE7]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: A cluster is always created with a default node pool with a specific number
    of nodes and a specific machine type (along with other attributes). Additional
    custom node pools can be added based on their respective `nodeConfig` and workload
    requirements.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 集群总是与默认节点池一起创建，默认节点池具有特定数量的节点和特定的机器类型（以及其他属性）。可以根据各自的 `nodeConfig` 和工作负载需求添加额外的自定义节点池。
- en: 'The following are some of the key characteristics of a node pool:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是节点池的一些关键特性：
- en: A new node pool, by default, runs the latest stable Kubernetes version.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新创建的节点池默认运行最新的稳定 Kubernetes 版本。
- en: The Kubernetes version on existing node pools can either be configured for auto-upgrade
    or can be manually upgraded.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现有节点池上的 Kubernetes 版本可以配置为自动升级，也可以手动升级。
- en: A node pool can be individually resized, upgraded, or deleted without impacting
    other node pools. Any change to the node pool impacts all nodes within the pool.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以单独调整节点池的大小、升级或删除，而不影响其他节点池。对节点池的任何更改都会影响池中的所有节点。
- en: The following are a few CLI commands that can perform actions on a node pool.
    These commands can be executed on the cluster that was previously created in this
    chapter – `my-first-cluster`.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些 CLI 命令，可以对节点池执行操作。这些命令可以在本章之前创建的集群 `my-first-cluster` 上执行。
- en: 'The following CLI command creates a node pool with a specific machine type:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 CLI 命令会创建一个特定机器类型的节点池：
- en: '[PRE8]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The created node pool will be reflected on the GKE Console against the cluster
    (refer to *Figure 8.16*):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 创建的节点池将在 GKE 控制台中反映出来，显示在集群对应位置（参见*图 8.16*）：
- en: '![Figure 8.16 – New custom node pool – my-high-mem-pool created'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.16 – 新建自定义节点池 – 创建了 my-high-mem-pool'
- en: '](img/B15587_08_16.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_16.jpg)'
- en: Figure 8.16 – New custom node pool – my-high-mem-pool created
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.16 – 新建自定义节点池 – 创建了 my-high-mem-pool
- en: 'The following are other CLI commands to resize a node pool, upgrade to a specific
    version, or delete a node pool:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是其他 CLI 命令，用于调整节点池大小、升级到特定版本或删除节点池：
- en: '[PRE9]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Node pools in a regional or multi-zonal cluster are replicated to multiple zones.
    Additionally, the workload can be deployed to a specific node pool by explicitly
    specifying the node pool name using a `nodeSelector` or by finding a node pool
    that satisfies the resource requests as defined for the workload.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在区域性或多区域集群中的节点池会被复制到多个区域。此外，可以通过明确指定节点池名称使用 `nodeSelector`，或者找到满足工作负载资源请求的节点池，来将工作负载部署到特定节点池中。
- en: If the node pool name is explicitly specified using the `nodeSelector` attribute,
    then `kube-scheduler` will deploy workloads to the specified node. Otherwise,
    `kube-scheduler` will find the node pool that meets the intended resource request
    for the workload.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如果节点池名称通过 `nodeSelector` 属性明确指定，则 `kube-scheduler` 会将工作负载部署到指定的节点。否则，`kube-scheduler`
    会找到符合工作负载资源请求的节点池。
- en: This completes the overview of GKE node pools. The next topic deep-dives into
    the various cluster configurations available in GKE.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了 GKE 节点池的概述。接下来的主题将深入探讨 GKE 中的各种集群配置。
- en: GKE cluster configuration
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE 集群配置
- en: GKE offers multiple cluster configuration choices based on cluster availability
    type, cluster version, network isolation, and Kubernetes features. Each of these
    configuration choices is discussed in the following sub-sections.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 提供多种集群配置选择，基于集群可用性类型、集群版本、网络隔离和 Kubernetes 特性。以下子章节将详细讨论这些配置选项。
- en: Cluster availability type
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集群可用性类型
- en: GKE allows you to create a cluster based on the availability requirements of
    the workloads. There are two types of cluster configuration based on availability
    types – zonal clusters (single-zone or multi-zonal) and regional clusters. These
    are discussed in the following sub-sections.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 允许你根据工作负载的可用性要求创建集群。根据可用性类型，有两种集群配置——区域集群（单区域或多区域）和区域集群。这些将在以下子章节中讨论。
- en: Zonal clusters
  id: totrans-187
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 区域集群
- en: A **zonal cluster** will have a single control plane running in a single zone.
    The nodes (that is, worker nodes) can run either in a single zone or run across
    multiple zones. If the nodes run in the same zone as the control plane, then it
    represents a **single-zone cluster**. However, if nodes run across multiple zones,
    then it represents a **multi-zonal cluster**. Note that GKE allows up to 50 clusters
    per zone.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**区域集群**将拥有一个在单一区域运行的控制平面副本。节点（即工作节点）可以运行在单一区域，也可以跨多个区域运行。如果节点与控制平面运行在同一区域，则表示为**单区域集群**。然而，如果节点跨多个区域运行，则表示为**多区域集群**。请注意，GKE
    允许每个区域最多创建 50 个集群。'
- en: A multi-zonal cluster will only have a single replica of the control plane.
    The choice between a single zone or multi-zonal cluster is based on the level
    of availability required for an application. Specific to a multi-zonal cluster
    and in the event of a cluster upgrade or a zone outage, the workloads running
    on the nodes will continue to run, but a new node or workload cannot be configured
    till the cluster control plane is available.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 多区域集群将仅有一个控制平面的副本。选择单区域集群还是多区域集群取决于应用程序所需的可用性级别。对于多区域集群，如果发生集群升级或区域故障，节点上运行的工作负载将继续运行，但直到集群控制平面可用之前，无法配置新的节点或工作负载。
- en: 'The following are CLI commands to create a zonal cluster (single zone and multi
    zonal):'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是创建区域集群（单区域和多区域）的 CLI 命令：
- en: '[PRE10]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The input parameter specific to the zone refers to the location of the control
    plane. The node locations refer to the locations of the worker node(s) and are
    not required for a single zone cluster as it will be the same as the master control
    plane.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 与区域相关的输入参数是指控制平面的位置。节点位置指的是工作节点的所在位置，对于单区域集群来说并不需要指定，因为它与主控制平面的位置相同。
- en: This completes a brief overview of GKE zonal clusters. The next topic will provide
    an overview of GKE regional clusters.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 GKE 区域集群的简要概述。下一个主题将概述 GKE 区域集群。
- en: Regional clusters
  id: totrans-194
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 区域集群
- en: A regional cluster provides high availability both in terms of worker nodes
    as well as the control plane. A regional cluster has multiple replicas of the
    control plane running across multiple zones in a region. The worker nodes are
    also replicated across multiple zones and the worker nodes run in conjunction
    in the same zone as the control plane. A regional cluster cannot be converted
    into a zonal cluster.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 区域集群提供了在工作节点和控制平面方面的高可用性。区域集群在多个区域内运行多个控制平面副本。工作节点也跨多个区域进行复制，并且工作节点与控制平面在同一区域内共同运行。区域集群不能转换为区域集群。
- en: 'The following is the CLI command to create a regional cluster:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是创建区域集群的 CLI 命令：
- en: '[PRE11]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The input parameter specific to `region` refers to the location of the control
    plane. The node locations refer to the locations of the worker node. This is required
    for a multi-zone cluster as node locations could be in multiple zones.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `region` 相关的输入参数是指控制平面的位置。节点位置指的是工作节点的位置。对于多区域集群，这是必需的，因为节点位置可能分布在多个区域。
- en: This completes a brief overview of GKE cluster configuration based on cluster
    availability type. The next topic will provide an overview of GKE cluster configuration
    based on cluster version.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是基于集群可用性类型的 GKE 集群配置的简要概述。下一个主题将概述基于集群版本的 GKE 集群配置。
- en: Cluster versions
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集群版本
- en: GKE allows you to choose the cluster version. The cluster version can be a very
    specific version, the current default version, or can be based on a release channel,
    which is a combination of features based on early availability and stability.
    These cluster version configurations are discussed in the following sub-sections.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 允许你选择集群版本。集群版本可以是非常特定的版本、当前默认版本，或者基于发布渠道，发布渠道是基于早期可用性和稳定性的功能组合。这些集群版本配置将在以下子章节中讨论。
- en: Specific versions
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特定版本
- en: A GKE cluster can be created by specifying a specific version. This information
    can be provided as part of the *Static Version* selection while creating the cluster
    from the console. The user will be provided with a choice of cluster versions
    and can select an available version.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过指定特定版本来创建 GKE 集群。在从控制台创建集群时，这些信息可以作为*静态版本*选择的一部分提供给用户。用户将获得集群版本的选择，并可以选择一个可用的版本。
- en: Release channels
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发布渠道
- en: 'Open source Kubernetes or K8s has a constant stream of releases. These could
    be required for the following purpose:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 开源 Kubernetes 或 K8s 持续发布新版本。这些版本可能出于以下目的而需要：
- en: To fix known issues
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修复已知问题
- en: To add new features
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加新功能
- en: To address any security risks/concerns
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决任何安全风险/问题
- en: Kubernetes users who run applications on a Kubernetes cluster will prefer to
    exercise control in terms of how frequently the releases should be applied or
    the rate at which new features should be adopted. Google provides this choice
    to customers using the concept of a **release channel**.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 Kubernetes 集群上应用程序的 Kubernetes 用户，更倾向于控制发布的频率或采用新功能的速度。Google 通过**发布渠道**的概念为客户提供这一选择。
- en: Each of the release channels provides **generally available** (**GA**) features
    but the maturity of the features in terms of their original release date will
    vary from one channel to another. In addition, Google can also add the latest
    GKE-specific features depending on the type of release channel. This ensures that
    a specific feature or fix has potentially gone through the grind and is vetted
    in terms of its correctness and consistency over a period.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 每个发布渠道都提供**普遍可用**（**GA**）功能，但功能的成熟度会根据其最初发布的日期在不同渠道之间有所不同。此外，Google 还可以根据发布渠道的类型添加最新的
    GKE 特定功能。这确保了某个特性或修复程序在一段时间内经过了验证，并确保其正确性和一致性。
- en: 'GKE provides three release channels:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 提供三个发布渠道：
- en: '**Rapid**: This release channel includes the latest Kubernetes and GKE features
    when compared to other release channels, but the features are still several weeks
    old after their respective open source GA release.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速**：与其他发布渠道相比，这个发布渠道包括最新的 Kubernetes 和 GKE 特性，但这些特性距离它们各自的开源 GA 版本发布仍有几周的时间。'
- en: '**Regular**: This is the default release channel, which includes Kubernetes
    and GKE-specific features that are reasonably new but are more stable in nature.
    The features are at least 2-3 months old after their release in the rapid channel
    and several months old from their open source GA release.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**常规**：这是默认的发布渠道，包括 Kubernetes 和 GKE 特定的功能，这些功能相对较新，但稳定性较好。这些功能在快速发布渠道发布后至少已有
    2-3 个月的历史，且距离开源 GA 版本发布已经有几个月。'
- en: '**Stable**: This is the most stable of the release channels since the features
    added to this channel are added at least 2-3 months after being added to the regular
    channel. Essentially, the features are thoroughly validated and tested to provide
    the utmost stability.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稳定**：这是最稳定的发布渠道，因为添加到此渠道的功能是在加入常规渠道后至少 2-3 个月添加的。实际上，这些功能经过充分验证和测试，以提供极致的稳定性。'
- en: 'The following is the CLI command to enroll a cluster in a release channel:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将集群注册到发布渠道的 CLI 命令：
- en: '[PRE12]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To summarize, new Kubernetes versions and GKE features are promoted from the
    rapid to the regular to the stable channel, providing users with the choice to
    use newer features over stable features. GKE handles the availability of versions
    and the upgrade cadence once a cluster is added to the release channel. Each of
    the release channels continues to receive critical security updates.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，新版本的 Kubernetes 和 GKE 特性会从快速发布渠道、常规发布渠道到稳定发布渠道依次推广，提供用户在使用新特性和稳定特性之间的选择。一旦集群被加入到发布渠道，GKE
    会处理版本的可用性和升级节奏。每个发布渠道都会继续接收关键的安全更新。
- en: The default version
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 默认版本
- en: If a specific version or a release channel is not specified, then GKE creates
    a cluster with the current default version. GKE selects a default version based
    on usage and real-world performance. GKE is responsible for changing the default
    version on a regular basis. Historically, new versions of Kubernetes are released
    every 3 months.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有指定特定的版本或发布渠道，则 GKE 会创建一个使用当前默认版本的集群。GKE 会根据使用情况和实际性能选择默认版本，并定期更改默认版本。历史上，Kubernetes
    的新版本每三个月发布一次。
- en: This completes a brief overview of GKE cluster configuration based on cluster
    version. The next topic will provide an overview of GKE cluster configuration
    based on network isolation choices.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了基于集群版本的 GKE 集群配置的简要概述。下一个主题将提供基于网络隔离选择的 GKE 集群配置概述。
- en: Network isolation choices
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络隔离选择
- en: There are two specific choices related to network isolation – a public cluster
    or a private cluster. A public cluster is the default configuration. However,
    this does not enforce network isolation and the cluster is accessible from any
    public endpoint. This makes the cluster vulnerable from a security standpoint.
    The drawbacks of configuring a public cluster can be handled through a private
    cluster, which is introduced in the following sub-sections.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个与网络隔离相关的特定选择——公有集群或私有集群。公有集群是默认配置。然而，这并不强制执行网络隔离，集群可以从任何公共端点访问。这使得集群在安全性方面存在漏洞。配置公有集群的缺点可以通过私有集群来解决，私有集群将在以下小节中介绍。
- en: Private clusters
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 私有集群
- en: GKE provides an option to create a private cluster where the nodes only have
    internal IP addresses. This means that the nodes and the pods running on the nodes
    are isolated from the internet and inherently will not have inbound or outbound
    connectivity to the public internet.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 提供了创建私有集群的选项，在该集群中，节点只有内部 IP 地址。这意味着节点和运行在节点上的 Pods 与互联网隔离，因此天然不会与公共互联网进行进出连接。
- en: A private cluster will have a control plane that includes a private endpoint,
    in addition to a public endpoint. Access to the public endpoint can be controlled
    through multiple options. In addition, the control plane will run on a VM that
    is in a VPC network in a Google-owned project. The details surrounding private
    clusters will be discussed in depth as part of [*Chapter 9*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201),
    *Securing the Cluster Using GKE Security Constructs*.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 私有集群将拥有一个包含私有端点的控制平面，此外还有一个公共端点。可以通过多种选项来控制对公共端点的访问。此外，控制平面将在 Google 拥有的项目中的
    VPC 网络中的虚拟机上运行。有关私有集群的详细信息将在 [*第 9 章*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201)，*使用
    GKE 安全构件保护集群* 中进行深入讨论。
- en: Kubernetes features – alpha clusters
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes 功能——alpha 集群
- en: New features in Kubernetes are rolled out to GKE as part of the release channel
    in most cases. The release channel includes choices of rapid, regular, and stable.
    However, alpha features are only available in special GKE alpha clusters. This
    is discussed in the following sub-sections.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 中的新功能通常通过发布渠道推广到 GKE。发布渠道包括快速、常规和稳定的选择。然而，alpha 功能仅在特殊的 GKE alpha
    集群中提供。以下小节将讨论这一点。
- en: Alpha clusters
  id: totrans-228
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Alpha 集群
- en: Alpha clusters are a specific feature of GKE that is designed for adopting new
    features that are not production-ready or generally available as open source.
    GKE creates alpha clusters as short-lived clusters and they are automatically
    deleted after 30 days.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Alpha 集群是 GKE 的一个特定功能，旨在用于采用那些尚未准备好投入生产或尚未普遍开放源代码的新功能。GKE 创建的 alpha 集群是短期存在的集群，并将在
    30 天后自动删除。
- en: 'The following is the CLI command to create an alpha cluster:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是创建 alpha 集群的 CLI 命令：
- en: '[PRE13]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: These clusters do not receive security updates, cannot be auto-upgraded or auto-repaired,
    and are not covered by any GKE-specific SLAs. Hence, alpha clusters are never
    recommended for production workloads.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这些集群不会接收安全更新，不能自动升级或自动修复，且不受任何 GKE 特定的 SLA 保障。因此，永远不建议将 alpha 集群用于生产工作负载。
- en: This completes a brief overview of GKE cluster configuration based on network
    isolation choices. This also concludes the sub-section on GKE cluster configuration
    in general. The next topic details possible autoscaling options in GKE.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了基于网络隔离选择的 GKE 集群配置的简要概述。这也结束了关于 GKE 集群配置的一般小节。下一个主题将详细介绍 GKE 中可能的自动扩展选项。
- en: AutoScaling in GKE
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE 中的自动扩展
- en: 'There are three potential options to perform autoscaling in GKE. Each of these
    options is suitable for specific needs and situations:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GKE 中有三种潜在的自动扩展选项。这些选项适用于特定的需求和场景：
- en: '**Cluster autoscaler**: A scaling option to resize a node pool in a GKE cluster'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群自动扩展器**：用于调整 GKE 集群中节点池大小的扩展选项'
- en: '**Horizontal Pod Autoscaler** (**HPA**): An option that indicates when application
    instances should be autoscaled based on their current utilization'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**水平 Pod 自动扩展器**（**HPA**）：一个选项，用于根据当前利用率指示何时应自动扩展应用实例'
- en: '**Vertical Pod Autoscaler** (**VPA**): An option that suggests recommended
    resources for a Pod based on the current utilization'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**垂直 Pod 自动缩放器** (**VPA**): 一种选项，根据当前利用率为 Pod 建议推荐资源。'
- en: The upcoming topics detail the preceding autoscaling mechanisms, starting with
    the cluster autoscaler.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的话题详细说明了先前的自动缩放机制，从集群自动缩放器开始。
- en: The cluster autoscaler
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集群自动缩放器
- en: The **cluster autoscaler** is a scaling mechanism to automatically resize a
    node pool in a GKE cluster. The scaling is based on the demands of workloads deployed
    within the node pool. This allows you to implement the core concept of cloud computing,
    called elasticity, and removes the need to over-provision or under-provision nodes.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '**集群自动缩放器**是自动调整 GKE 集群中节点池大小的机制。缩放基于节点池内部署的工作负载的需求。这允许您实现云计算的核心概念，称为弹性，从而消除了过度或不足提供节点的需要。'
- en: The cluster autoscaler works on a per-node pool basis and is based on resource
    requests (defined as part of the Pod specification) rather than the actual resource
    utilization. When a new Pod needs to be deployed, the Kubernetes scheduler works
    out of the Pod resource requests and attempts to find a node to deploy the Pod.
    If there is no node that matches the Pod resource requirement in terms of available
    capacity, then the Pod goes into a pending state until any of the existing pods
    are terminated or a new node is added.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 集群自动缩放器基于节点池的基础工作，并基于资源请求（作为 Pod 规范的一部分定义）而非实际资源利用率。当需要部署新的 Pod 时，Kubernetes
    调度器根据 Pod 的资源请求来寻找节点进行部署。如果没有节点满足 Pod 的资源需求以及可用容量，那么 Pod 将处于挂起状态，直到现有的 Pod 终止或者添加新节点。
- en: The cluster autoscaler keeps track of the pods that are in the pending state
    and subsequently tries to scale up the number of nodes. Similarly, the cluster
    autoscaler also scales down the number of nodes if the nodes are under-utilized.
    A minimum or maximum number of nodes can be defined for the cluster autoscaler,
    which allows it to operate within the specified limits.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 集群自动缩放器会跟踪处于挂起状态的 Pod，并随后尝试增加节点的数量。同样，如果节点未充分利用，集群自动缩放器也会减少节点的数量。可以为集群自动缩放器定义最小或最大节点数，以使其在指定的限制内运行。
- en: 'When a cluster is scaled down, there is a possibility that new workloads might
    have to wait till new nodes are added. This could cause a potential disruption.
    GKE profile types provide a choice of options to choose between balanced and aggressive
    scale-down:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '当集群缩小规模时，可能需要新的工作负载等待新节点的添加。这可能导致潜在的中断。GKE 配置文件类型提供了在平衡和激进缩小规模之间进行选择的选项:'
- en: '**Balanced**: The default profile option, which is not aggressive in nature.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平衡**: 默认的配置选项，性质不激进。'
- en: '**Optimize-utilization**: Scaling down is more aggressive and removes underutilized
    nodes faster.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优化利用率**: 缩小比较激进，更快地移除未充分利用的节点。'
- en: 'The following are some CLI commands related to the cluster autoscaler:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '以下是一些与集群自动缩放器相关的 CLI 命令:'
- en: '[PRE14]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following are some limitations that need to be considered when using the
    cluster autoscaler:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '在使用集群自动缩放器时需要考虑的一些限制如下:'
- en: There is a graceful termination of 10 minutes for rescheduling pods on to a
    different node before forcibly terminating the original node.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在将 Pod 重新调度到不同节点之前，对原始节点进行强制终止之前会进行 10 分钟的优雅终止。
- en: The node pool scaling limits are determined by zone availability. If a cluster
    has 3 nodes (with `min_nodes` = `1` and `max_nodes` = `5`) across 4 zones, then
    if 1 of the zones fails, the size of the cluster can vary from 4-20 nodes per
    cluster to 3-15 nodes per cluster.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点池缩放限制由区域可用性决定。如果集群跨越 4 个区域拥有 3 个节点（`min_nodes` = `1` 和 `max_nodes` = `5`），那么如果其中
    1 个区域失败，集群的大小可以从每个集群的 4-20 个节点变为 3-15 个节点。
- en: This concludes the overview of the cluster autoscaler. The next topic focuses
    on the **Horizontal Pod Autoscaler** (**HPA**).
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这里结束了对集群自动缩放器的概述。下一个主题关注**水平 Pod 自动缩放器** (**HPA**)。
- en: The Horizontal Pod Autoscaler
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 水平 Pod 自动缩放器
- en: The HPA is a Kubernetes controller object that automatically scales the number
    of pods in a replication controller, Deployment, ReplicaSet, or StatefulSet based
    on the observed CPU or memory utilization. The HPA indicates the Deployment or
    StatefulSet against which scaling needs to happen. The HPA doesn't apply to DaemonSets.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: HPA 是一个 Kubernetes 控制器对象，根据观察到的 CPU 或内存利用率自动调整复制控制器、Deployment、ReplicaSet 或
    StatefulSet 中 Pod 的数量。HPA 指示需要对其进行缩放的 Deployment 或 StatefulSet。HPA 不适用于 DaemonSets。
- en: 'To implement the HPA, the following factors need to be considered:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现HPA，需要考虑以下因素：
- en: One HPA object needs to be defined per Deployment or StatefulSet.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个Deployment或StatefulSet需要定义一个HPA对象。
- en: The attribute `--horizontal-pod-autoscaler-sync-period` allows you to implement
    the HPA as a control loop. The default value is 15 seconds per period.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--horizontal-pod-autoscaler-sync-period`属性允许您将HPA实现为控制循环。默认值为每周期15秒。'
- en: '`kube-controller-manager` (on a per-period basis) obtains metrics from the
    resource manager API or the custom metrics API and compares them against the metrics
    specified in each HPA definition.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-controller-manager`（按周期获取）从资源管理器API或自定义指标API获取指标，并将其与每个HPA定义中指定的指标进行比较。'
- en: 'The following are few key parameters that can define the HPA configuration:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些可以定义HPA配置的关键参数：
- en: '`--horizontal-pod-autoscaler-initial-readiness-delay`: A configurable window
    to ensure that a Pod is transitioned to the ready state.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--horizontal-pod-autoscaler-initial-readiness-delay`：一个可配置的窗口，确保Pod成功过渡到就绪状态。'
- en: '`--horizontal-pod-autoscaler-cpu-initialization-period`: A configurable window
    to set the CPU initialization period, once the Pod is transitioned to the ready
    state. The default is 5 minutes.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--horizontal-pod-autoscaler-cpu-initialization-period`：一个可配置的窗口，用于设置Pod转变为就绪状态后的CPU初始化时间。默认值为5分钟。'
- en: '`--horizontal-pod-autoscaler-downscale-stabilization`: A configurable window
    that autoscaler needs to wait before initiating a downscale operation after the
    current one is completed. The default is 5 minutes. This prevents thrashing.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--horizontal-pod-autoscaler-downscale-stabilization`：一个可配置的窗口，自动扩展器在当前扩展操作完成后需要等待多长时间才能启动缩减操作。默认值为5分钟。这样可以防止频繁波动。'
- en: 'The following is the sample definition of an HPA object based on CPU utilization:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基于CPU利用率的HPA对象示例定义：
- en: '[PRE15]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In the preceding example, `kube-controller-manager` will scale up the Deployment
    based on the HPA object specification, to a maximum of 5 instances if the target
    CPU utilization exceeds 75%. This concludes the overview of the HPA. The next
    topic focuses on the **Vertical Pod Autoscaler** (**VPA**).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述示例中，`kube-controller-manager`将根据HPA对象规范扩展Deployment，如果目标CPU利用率超过75%，最大可扩展至5个实例。这是HPA概述的总结，接下来的主题将重点讲解**垂直Pod自动扩展器**（**VPA**）。
- en: The Vertical Pod Autoscaler (VPA)
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 垂直Pod自动扩展器（VPA）
- en: The cluster autoscaler functions based on the workload's CPU and memory request
    limits. If these limits are not defined appropriately, then there is always a
    chance of over-provisioning or under-provisioning as the reference values will
    not be accurate.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 集群自动扩展器基于工作负载的CPU和内存请求限制进行操作。如果这些限制没有适当定义，则始终存在过度配置或配置不足的风险，因为参考值将不准确。
- en: The VPA is a Kubernetes resource that recommends values for CPU and memory requests/limits.
    Additionally, the VPA can automatically update workloads if the `updateMode` attribute
    is set to *On* on the VPA. This will potentially evict the existing Pod as a change
    is required to the pod's resource requests and will result in a new Pod with the
    updated recommendations.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: VPA是一个Kubernetes资源，推荐CPU和内存请求/限制的值。此外，如果VPA的`updateMode`属性设置为*开启*，VPA还可以自动更新工作负载。这可能会驱逐现有Pod，因为需要更改Pod的资源请求，并且会生成一个具有更新推荐值的新Pod。
- en: This ensures that the cluster nodes are optimally utilized and potentially removes
    the need to run benchmark tests to determine the correct values for CPU and memory
    requests. VPA communicates with the cluster autoscaler to perform the appropriate
    operations on the nodes tied to the node pools.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这确保了集群节点得到最佳利用，并可能不再需要运行基准测试来确定CPU和内存请求的正确值。VPA与集群自动扩展器进行通信，以便在与节点池相关的节点上执行适当的操作。
- en: 'The following is a sample definition of a VPA object:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个VPA对象的示例定义：
- en: '[PRE16]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `kind` attribute in the preceding snippet indicates that the Kubernetes
    resource is a VPA object. The `updateMode` attribute indicates that the recommendations
    suggested by the VPA are automatically applied against the running workloads.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码片段中的`kind`属性指示Kubernetes资源是VPA对象。`updateMode`属性指示VPA建议的推荐值会自动应用于正在运行的工作负载。
- en: 'The following are some CLI commands specific to the VPA:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些特定于VPA的CLI命令：
- en: '[PRE17]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: If an HPA object is configured to evaluate metrics for CPU or memory, it's recommended
    that HPA should not be used with VPA.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 如果配置了一个HPA对象来评估CPU或内存的指标，建议HPA不应与VPA一起使用。
- en: Multi-dimensional Pod autoscaling (MPA)
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 多维Pod自动扩展（MPA）
- en: This is a new autoscaling option that is currently in pre-GA. As per this option,
    it is possible to configure autoscaling to horizontally scale based on CPU and
    vertically scale based on memory at the same time. MPA is supported for clusters
    that are 1.19.4-gke.1700 or later.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个新的自动扩展选项，目前处于预GA阶段。根据该选项，可以配置自动扩展以基于CPU进行横向扩展，并同时基于内存进行纵向扩展。MPA支持1.19.4-gke.1700或更高版本的集群。
- en: This concludes the section on autoscaling in GKE where multiple mechanisms were
    detailed out. The next section focuses on networking constructs with respect to
    GKE. This will cover details about Pod networking, Service networking, and will
    deep dive into the usage of GKE load balancers to expose services for external
    consumption.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分总结了GKE中的自动扩展，详细介绍了多种机制。接下来的部分将重点介绍与GKE相关的网络构建。将涵盖有关Pod网络、服务网络的详细信息，并深入探讨使用GKE负载均衡器来暴露服务以供外部使用。
- en: Networking in GKE
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE中的网络
- en: Applications are deployed in Kubernetes as containers. Pods run containers.
    The desired state of the pods is controlled by Deployments and the applications
    are exposed for both internal and external networking through Services. The deployed
    pods run in GKE on nodes. Nodes in GKE are represented by virtual machines or
    VMs. These nodes are deployed in a **Virtual Private Cloud** (**VPC**).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序作为容器部署在Kubernetes中。Pods运行容器。Pods的期望状态由Deployments控制，应用程序通过Services暴露供内部和外部网络使用。已部署的pods在GKE的节点上运行。GKE中的节点由虚拟机或VM表示。这些节点部署在**虚拟私有云**（**VPC**）中。
- en: A VPC defines a virtual network topology that closely resembles a traditional
    network. It is a logically isolated network and provides connectivity between
    deployed resources. A VPC also provides complete control in terms of launching
    resources, selecting a range of RFC 1918 addressing, the creation of subnets,
    and so on.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: VPC定义了一个虚拟网络拓扑，类似于传统网络。它是一个逻辑隔离的网络，并提供已部署资源之间的连接。VPC还提供了启动资源、选择RFC 1918地址范围、创建子网等方面的完全控制。
- en: A VPC on GCP has a pre-allocated IP subnet, for every GCP region. When a GKE
    cluster is deployed within the VPC, a specific region or zone can be selected.
    Since GKE nodes are made up of Compute Engine VMs and these VMs need an IP address,
    the range of IP addresses is allocated from the IP subnet pre-allocated to the
    region. A VPC on GCP is considered a global resource since a single Google Cloud
    VPC can span multiple regions without communicating across the public internet.
    It is not required to have a connection in every region.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: GCP中的VPC为每个GCP区域预分配了一个IP子网。当在VPC中部署GKE集群时，可以选择特定的区域或区域。在GKE节点由计算引擎虚拟机（VM）组成且这些虚拟机需要IP地址时，IP地址范围将从分配给区域的IP子网中分配。GCP中的VPC被视为全球资源，因为单一的Google
    Cloud VPC可以跨多个区域而无需通过公共互联网进行通信。并不要求在每个区域都建立连接。
- en: GCP provides the option of configuring alias IP ranges. This allows VMs to have
    an additional secondary IP address. As a result, a VM can have multiple services
    running with a separate IP address. These secondary IP addresses are routable
    within the VPC without the need to configure additional routes.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: GCP提供了配置别名IP范围的选项。这使得虚拟机可以拥有额外的二级IP地址。因此，虚拟机可以在独立的IP地址上运行多个服务。这些二级IP地址可以在VPC内进行路由，而无需配置额外的路由。
- en: 'A GKE cluster might need to run cluster-wide services. GCP recommends deploying
    a GKE cluster as a **VPC-native cluster**. A VPC-native cluster uses three unique
    subnet IP address ranges:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: GKE集群可能需要运行集群范围的服务。GCP建议将GKE集群部署为**VPC原生集群**。VPC原生集群使用三个独特的子网IP地址范围：
- en: A primary IP address range of subnet for node IP addresses
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于节点IP地址的子网主IP地址范围
- en: A secondary IP address range for all Pod IP addresses
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有Pod IP地址的二级IP地址范围
- en: An additional secondary IP address range for all Service IP addresses
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于所有服务IP地址的附加二级IP地址范围
- en: GKE provides flexibility where the number of nodes in a cluster and the maximum
    number of pods per node are configurable. The next topic details how pods are
    assigned IP addresses when pods are deployed in a GKE cluster.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: GKE提供了灵活性，允许配置集群中节点的数量和每个节点的最大pod数。接下来的话题详细介绍了当pods在GKE集群中部署时，如何为pod分配IP地址。
- en: Pod networking
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pod网络
- en: When a Pod is scheduled on a node, Kubernetes creates a network namespace for
    the Pod on the node's Linux kernel and connects the node's physical network interface
    to the Pod with a virtual network interface, thus allowing communication among
    pods within the same node.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Pod 被调度到某个节点时，Kubernetes 会在该节点的 Linux 内核中为 Pod 创建一个网络命名空间，并通过虚拟网络接口将该节点的物理网络接口连接到
    Pod，从而允许同一节点内的 Pod 之间进行通信。
- en: Kubernetes assigns an IP address (the Pod's IP) to the virtual network interface
    in the Pod's network namespace from a range of addresses reserved for Pods on
    the node. This address range is a subset of the IP address range assigned to the
    cluster for Pods, which can be configured when creating a cluster.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 会将一个 IP 地址（即 Pod 的 IP 地址）分配给 Pod 的网络命名空间中的虚拟网络接口，这些 IP 地址来自为节点上的
    Pod 保留的地址范围。此地址范围是集群为 Pod 分配的 IP 地址范围的一个子集，创建集群时可以配置此范围。
- en: GKE automatically configures VPC to recognize this range of IP addresses as
    an authorized secondary subnet of IP addresses. As a result, the pod's traffic
    is permitted to pass the anti-spoofing filters on the network. Also, because each
    node maintains a separate IP address base for its pods, the nodes don't need to
    perform network address translation on the pod's IP address. The next topic details
    Service networking, specifically, how services can effectively receive traffic
    from external sources via the use of GKE load balancers.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 会自动配置 VPC 以识别这一 IP 地址范围为授权的次级子网地址范围。因此，Pod 的流量可以通过网络上的防伪过滤器。同时，由于每个节点为其
    Pod 保持独立的 IP 地址库，节点不需要对 Pod 的 IP 地址进行网络地址转换。下一个主题将详细讲解服务网络，特别是如何通过使用 GKE 负载均衡器有效地接收来自外部源的流量。
- en: Service networking
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务网络
- en: A Service is a Kubernetes resource that creates a dynamic collection of IP addresses
    called endpoints. These IP addresses belong to the Pod that matches the Service
    label selector. Kubernetes creates a Service by assigning a static virtual IP
    address and this IP address is assigned from the pool of IP addresses reserved
    for services by the cluster.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 服务是一个 Kubernetes 资源，它创建一个名为端点的动态 IP 地址集合。这些 IP 地址属于与服务标签选择器匹配的 Pod。Kubernetes
    通过分配一个静态虚拟 IP 地址来创建服务，这个 IP 地址从集群为服务保留的 IP 地址池中分配。
- en: Out of the available Service types, the `LoadBalancer` Service type is implemented
    in GKE using GCP's `LoadBalancer` is created within the GKE cluster. GCP will
    subsequently assign a static `LoadBalancer` IP address that is accessible from
    outside the cluster and the project.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在可用的服务类型中，`LoadBalancer` 服务类型通过 GCP 的 `LoadBalancer` 在 GKE 中实现，该负载均衡器是在 GKE
    集群内创建的。随后，GCP 会分配一个静态的 `LoadBalancer` IP 地址，该地址可以从集群外部以及项目中访问。
- en: 'For traffic sent to the GCP NLB, *Figure 8.17* depicts the interactions between
    the NLB and the nodes within the GKE cluster. These interactions are listed as
    follows in a step-by-step manner:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 对于发送到 GCP NLB 的流量，*图 8.17* 展示了 NLB 与 GKE 集群内节点之间的交互。这些交互按步骤列出如下：
- en: '![Figure 8.17 – Interactions between the NLB and a GKE cluster within a VPC'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.17 – NLB 与 GKE 集群在 VPC 中的交互'
- en: '](img/B15587_08_17.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_17.jpg)'
- en: Figure 8.17 – Interactions between the NLB and a GKE cluster within a VPC
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.17 – NLB 与 GKE 集群在 VPC 中的交互
- en: '**Step-by-step interactions**:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '**逐步交互**：'
- en: NLB will pick a random node in the cluster and forwards the traffic (say **Node
    2** as per *Figure 8.17*)
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NLB 会从集群中随机选择一个节点并转发流量（例如根据 *图 8.17*，选择 **Node 2**）。
- en: The Service might be tied to multiple pods spread across the cluster nodes.
    The `kube-proxy` Service on the node receives the client request and will select
    a Pod matching the Service at random. The selected Pod can be on the same node
    or a different node.
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务可能会绑定到多个分布在集群节点上的 Pod。节点上的 `kube-proxy` 服务接收客户端请求，并会随机选择一个匹配该服务的 Pod。所选的 Pod
    可能在同一节点或不同节点上。
- en: If the selected Pod is on a different node (say **Pod 8**), then the client
    request will be sent to the other node (**Node 4**) from the original node (**Node
    2**). The response goes back to the original node (**Node 2**) that received the
    request and subsequently goes back to the client.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果选择的 Pod 位于不同的节点（例如 **Pod 8**），则客户端请求将从原节点（**Node 2**）发送到其他节点（**Node 4**）。响应将返回到接收请求的原节点（**Node
    2**），然后再返回给客户端。
- en: The preceding process provides a way to access services from an external client
    and maintains an even balance with respect to Pod usage. However, there is a possibility
    that within the Kubernetes cluster, a response might have to go through multiple
    nodes as the request was directed from one node to the other, resulting in a **double
    hop**.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的过程提供了一种通过外部客户端访问服务的方式，并保持与 Pod 使用的平衡。然而，在 Kubernetes 集群中，响应可能需要经过多个节点，因为请求从一个节点被引导到另一个节点，这就可能导致**双重跳跃**问题。
- en: To avoid `externalTrafficPolicy`. If set to local, `kube-proxy` will pick a
    Pod on the local node (either **Pod 3** or **Pod 4**) and will not forward the
    client request to another node. However, this creates an imbalance and users must
    choose between better balance versus low-latency communication. GKE solves this
    by using the concept of container-native load balancing.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免`externalTrafficPolicy`。如果设置为本地，`kube-proxy` 将选择本地节点上的一个 Pod（无论是**Pod 3**还是**Pod
    4**），并且不会将客户端请求转发到另一个节点。然而，这会导致负载不平衡，用户必须在更好的负载均衡和低延迟通信之间做出选择。GKE 通过使用容器原生负载均衡的概念解决了这个问题。
- en: Container-native load balancing
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 容器原生负载均衡
- en: The essence of container-native load balancing is that instead of directing
    traffic to nodes, traffic will be sent to pods directly, avoiding an additional
    hop. The connection is made directly between the load balancer and the pods. GKE
    accomplishes this by leveraging **GCP HTTP(S) Load Balancing** and the use of
    a data model called a **Network Endpoint Group** (**NEG**). GKE needs to run in
    VPC-native mode to use the container-native load balancing feature.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 容器原生负载均衡的核心思想是，流量不再被引导到节点，而是直接发送到 Pod，从而避免了额外的跳跃。连接直接在负载均衡器与 Pods 之间建立。GKE 通过利用
    **GCP HTTP(S) Load Balancing** 和称为 **Network Endpoint Group**（**NEG**）的数据模型实现这一点。GKE
    需要在 VPC 原生模式下运行，才能使用容器原生负载均衡功能。
- en: 'A NEG is a set of network endpoints representing IP to port pairs. So instead
    of load balancing traffic using node IPs, the combination of Pod IPs and a port
    is used as a tuple. This information is maintained in the NEG. *Figure 8.18* depicts
    the interactions between GKE container-native load balancing and pods in GKE nodes
    through an NEG. As per *Figure 8.18*, a request to the container-native load balancer
    is forwarded to the NEG. The NEG then chooses the specific Pod based on the request,
    and directly forwards the traffic to the node associated with the Pod in a single
    hop, thus avoiding the *double hop*:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: NEG 是一组表示 IP 到端口对的网络端点。因此，负载均衡流量不再使用节点 IP，而是使用 Pod IP 和端口的组合作为元组。此信息在 NEG 中进行维护。*图
    8.18* 展示了 GKE 容器原生负载均衡与 GKE 节点中的 Pods 之间的交互，通过 NEG 实现。如 *图 8.18* 所示，发往容器原生负载均衡器的请求会转发到
    NEG，NEG 根据请求选择特定的 Pod，并直接将流量转发到与 Pod 关联的节点，实现单跳转发，从而避免了*双重跳跃*问题：
- en: '![Figure 8.18 – Solving the double hop problem using container-native load
    balancing'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.18 – 使用容器原生负载均衡解决双重跳跃问题](img/B15587_08_18.jpg)'
- en: '](img/B15587_08_18.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_18.jpg)'
- en: Figure 8.18 – Solving the double hop problem using container-native load balancing
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.18 – 使用容器原生负载均衡解决双重跳跃问题
- en: Apart from establishing a direct connection to the Pod, container-native load
    balancing allows direct visibility of Pods, leading to the possibility of accurate
    health checks. The source IP address is preserved thus giving insights into the
    roundtrip time between the client and the load balancer.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 除了建立与 Pod 的直接连接外，容器原生负载均衡还允许直接查看 Pod，从而实现准确的健康检查。源 IP 地址得以保留，从而可以获得客户端与负载均衡器之间的往返时间信息。
- en: This concludes a high-level overview of networking constructs specific to GKE.
    The next section summarizes the storage options available for containerized applications
    deployed in GKE.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 本文总结了 GKE 特定的网络构造的高级概述。下一节将总结 GKE 中容器化应用可用的存储选项。
- en: Storage options for GKE
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE 的存储选项
- en: Kubernetes offers storage abstractions in the form of Volumes and Persistent
    Volumes. These are used as storage options providing file system capacity that
    is directly accessible by applications running in a Kubernetes cluster. Persistent
    Volumes exist beyond the life of a container and can further be used as durable
    file storage or as a database backing store.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 提供了以卷（Volumes）和持久卷（Persistent Volumes）形式的存储抽象。这些被用作存储选项，提供直接可供在 Kubernetes
    集群中运行的应用程序访问的文件系统容量。持久卷的存在超出了容器的生命周期，且可以进一步作为耐久性文件存储或数据库后端存储使用。
- en: In GKE, Compute Engine persistent disks are used as persistent volumes. GKE
    also provides various managed backing stores such as Cloud SQL, Cloud Datastore,
    and so on, which removes the need to run a database as an application inside the
    GKE cluster, connecting applications in a GKE cluster to a managed datastore instead.
    For example, a frontend application in a GKE Cluster can be connected to Cloud
    SQL rather than the frontend application connecting to another application running
    a MySQL server. To be more specific, the frontend application can connect to Cloud
    SQL for database needs through a Cloud SQL proxy. This can be run inside the frontend
    application's Pod as a side-car container.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GKE 中，Compute Engine 持久磁盘用作持久卷。GKE 还提供了各种托管后端存储服务，如 Cloud SQL、Cloud Datastore
    等，这样就不需要在 GKE 集群内运行数据库应用程序，而是将 GKE 集群中的应用程序连接到托管的数据存储。例如，GKE 集群中的前端应用程序可以连接到 Cloud
    SQL，而不是将前端应用程序连接到运行 MySQL 服务器的其他应用程序。更具体地说，前端应用程序可以通过 Cloud SQL 代理连接到 Cloud SQL
    以满足数据库需求。该代理可以作为一个 side-car 容器运行在前端应用程序的 Pod 内。
- en: This abstracts away infrastructure requirements and reduces maintenance, allowing
    you to focus on the application. GCP offers managed services across relational,
    non-relational, and caching services that applications running in a GKE cluster
    can connect to.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 这抽象了基础设施需求并减少了维护，让您可以专注于应用程序。GCP 提供了跨关系型、非关系型和缓存服务的托管服务，供在 GKE 集群中运行的应用程序连接。
- en: 'In addition to applications that might require a backend data store, there
    could be applications running in a GKE cluster that might need object storage.
    **Google Cloud Storage** (**GCS**) is an object storage Service. Object-based
    storage refers to the storage of an ordered group of bytes where the structure
    and semantics of those bytes are not important. It can be used for a variety of
    applications, such as the following:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 除了可能需要后端数据存储的应用程序外，GKE 集群中可能还会有需要对象存储的应用程序。**Google Cloud Storage**（**GCS**）是一个对象存储服务。对象存储指的是存储一组有序字节的方式，其中这些字节的结构和语义并不重要。它可用于各种应用程序，例如以下几种：
- en: Serving images for a website
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为网站提供图像服务
- en: Streaming music, videos, and media hosting
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流式传输音乐、视频和媒体托管
- en: Constructing data lakes for analytics and machine learning workloads
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为分析和机器学习工作负载构建数据湖
- en: Applications within the GKE cluster can access Cloud Storage using Cloud Storage
    APIs. This concludes the summary of the storage options available in GCP for applications
    deployed in GKE. The next section summarizes details on cloud operations from
    a GKE perspective.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 集群中的应用程序可以通过 Cloud Storage API 访问 Cloud Storage。这是 GCP 中为部署在 GKE 中的应用程序提供的存储选项的总结。接下来的部分总结了从
    GKE 角度出发的云操作细节。
- en: Cloud Operations for GKE
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE 的 Cloud 操作
- en: '**Google Kubernetes Engine** (**GKE**) provides native integration with **Google''s
    Cloud operations** – a suite of tools that allows you to monitor workloads, collect
    application logs, capture metrics and provide alerting or notification options
    on key metrics. Cloud operations and the respective suite of services are elaborated
    on in detail as part of [*Chapter 10*](B15587_10_Final_ASB_ePub.xhtml#_idTextAnchor218),
    *Exploring GCP Cloud Operations*.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '**Google Kubernetes Engine**（**GKE**）提供与 **Google Cloud 操作**的本地集成——一套工具，允许您监控工作负载、收集应用程序日志、捕获指标并在关键指标上提供警报或通知选项。Cloud
    操作及其相关服务套件将在[*第 10 章*](B15587_10_Final_ASB_ePub.xhtml#_idTextAnchor218)《探索 GCP
    云操作》中详细阐述。'
- en: 'Cloud Operations for GKE is enabled by default at the time of cluster creation.
    However, it is possible to configure if the user chooses to disable Cloud Monitoring
    or Cloud Logging as part of the GKE cluster configuration. Cloud Operations for
    GKE monitors GKE clusters and provides a tailored, out-of-the-box dashboard that
    includes the following capabilities:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 的 Cloud 操作在创建集群时默认启用。然而，用户可以选择在 GKE 集群配置中禁用 Cloud Monitoring 或 Cloud Logging。GKE
    的 Cloud 操作监控 GKE 集群并提供一个量身定制的开箱即用仪表板，包含以下功能：
- en: Viewing cluster resources categorized by infrastructure, workloads, or services
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看按基础设施、工作负载或服务分类的集群资源
- en: Inspecting namespaces, nodes, workloads, services, pods, and containers
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查命名空间、节点、工作负载、服务、Pod 和容器
- en: Viewing application logs for pods and containers
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看 Pod 和容器的应用日志
- en: Viewing key metrics related to clusters, such as CPU utilization, memory utilization,
    and so on
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看与集群相关的关键指标，例如 CPU 利用率、内存利用率等
- en: Logging and monitoring are two critical aspects of reliably running a Service
    or application in a GKE cluster. These will be covered as part of upcoming topics
    from the aspect of Cloud Operations for GKE.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录和监控是可靠运行 GKE 集群中的服务或应用程序的两个关键方面。这些内容将在后续的 Cloud Operations 相关主题中进行详细介绍。
- en: Logging for GKE
  id: totrans-331
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GKE 日志记录
- en: GKE deploys applications and orchestrates multiple actions or events within
    a cluster. This results in a variety of logs such as application logs, system
    logs, event logs, and so on. Logging provides visibility of various actions that
    happen and is also considered a passive form of monitoring.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 部署应用程序并在集群内协调多个操作或事件。这会产生各种日志，如应用日志、系统日志、事件日志等。日志提供了对各种操作的可见性，也被认为是一种被动的监控方式。
- en: 'There are two options to view logs for a GKE cluster:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 GKE 集群日志有两种方式：
- en: Kubernetes Native Logging
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 原生日志
- en: GKE Cloud Logging
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE Cloud Logging
- en: Kubernetes Native Logging
  id: totrans-336
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes 原生日志
- en: Kubernetes supports native logging to standard output and standard error. In
    Kubernetes, the *container engine* can be used to redirect stdin/out and standard
    error streams from the containers to a logging driver. This driver is configured
    to write these container logs in JSON format and store them in the `/var/log`
    directory at the node level. This includes logs from containers and logs from
    node control plane components such as `kubelet` and `kube-proxy`. These logs can
    be retrieved using the `kubectl logs` command.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 支持将日志原生输出到标准输出和标准错误流。在 Kubernetes 中，*容器引擎* 可以将容器的标准输入/输出和标准错误流重定向到日志驱动程序。该驱动程序被配置为将容器日志以
    JSON 格式写入并存储在节点级别的 `/var/log` 目录中。这包括来自容器的日志和来自节点控制平面组件（如 `kubelet` 和 `kube-proxy`）的日志。这些日志可以通过
    `kubectl logs` 命令检索。
- en: 'The `kubectl logs` command can be used to retrieve logs for a Pod or a specific
    container within a Pod. The command also provides options to retrieve logs for
    a specific period or you can retrieve a portion of logs using the `tail` option.
    A few of such examples are provided as follows:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl logs` 命令可用于检索 Pod 或 Pod 中特定容器的日志。该命令还提供了检索特定时间段日志的选项，或者你可以使用 `tail`
    选项检索日志的某一部分。以下是一些示例：'
- en: '[PRE18]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Kubernetes native logging can lead to node saturation as the log files continue
    to grow in the node's storage directory. GKE solves this to an extent by running
    the Linux log rotate utility to clean up the log files. Any log files older than
    a day or more than 100 MB will be automatically compressed and copied into an
    archive file.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 原生日志可能导致节点饱和，因为日志文件会持续增长，最终占满节点存储目录的空间。GKE 通过运行 Linux 日志轮转工具来清理日志文件，从某种程度上解决了这一问题。任何超过一天或者大小超过
    100 MB 的日志文件会被自动压缩并复制到归档文件中。
- en: GKE only stores the five most recently archived log files on the nodes and will
    delete the previous archived log files. Though this ensures that the node doesn't
    saturate in terms of disk space, it still poses a problem if older application
    logs need to be analyzed or researched.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 只会在节点上存储最近的五个归档日志文件，并会删除之前的归档日志文件。尽管这样可以确保节点在磁盘空间方面不至于饱和，但如果需要分析或研究旧的应用日志，仍然会带来一定问题。
- en: By default, open source Kubernetes or K8s will delete logs related to a container
    either when a container is deleted or when a Pod tied to the container is deleted.
    GKE resolves problems related to node saturation and provides the ability to analyze
    logs related to deleted pods/containers by streaming the logs to Cloud Logging,
    as part of Cloud Operations. Application logs, system logs, and log events can
    be streamed to Cloud Logging, which will be discussed as part of upcoming topics.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，开源 Kubernetes 或 K8s 会在删除容器或与容器相关联的 Pod 被删除时删除相关日志。GKE 解决了与节点饱和相关的问题，并通过将日志流式传输到
    Cloud Logging，为分析与已删除 Pods/Containers 相关的日志提供了能力，作为 Cloud Operations 的一部分。应用日志、系统日志和日志事件可以被流式传输到
    Cloud Logging，相关内容将在后续章节中讨论。
- en: GKE Cloud Logging
  id: totrans-343
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GKE Cloud Logging
- en: Open source Kubernetes or K8s doesn't provide a log storage solution for cluster-level
    logging. GKE handles this by streaming log events to Cloud Logging. **Cloud Logging**
    is a centralized log management utility and a fully managed Service. Cloud Logging
    can automatically scale and can ingest terabytes of log data per second.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 开源 Kubernetes 或 K8s 并未提供集群级别日志存储解决方案。GKE 通过将日志事件流式传输到 Cloud Logging 来处理此问题。**Cloud
    Logging** 是一个集中式日志管理工具，且为完全托管的服务。Cloud Logging 可以自动扩展，且每秒可摄取数 TB 的日志数据。
- en: GKE streams to Cloud Logging by using `FluentD` logging agents. A `FluentD`
    agent is implemented as a DaemonSet because it needs to run on every node in the
    cluster.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 使用 `FluentD` 日志代理将日志流式传输到 Cloud Logging。`FluentD` 代理作为 DaemonSet 实现，因为它需要在集群中的每个节点上运行。
- en: Logging agents are pre-installed on each node as a DaemonSet and are pre-configured
    to push log data to Cloud Logging. `FluentD` collects container logs and system
    logs from the node. FluentD aggregates the logs, appends additional metadata,
    and pushes them to Cloud Logging.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 日志代理已预安装在每个节点上作为 DaemonSet，并预配置为将日志数据推送到 Cloud Logging。`FluentD` 收集来自节点的容器日志和系统日志。FluentD
    汇总日志，附加额外的元数据，并将其推送到 Cloud Logging。
- en: '*Figure 8.19* illustrates the interactions of logs being sent from GKE to Cloud
    Logging using the `FluentD` DaemonSet Pod on each node in the cluster:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 8.19* 说明了通过集群中每个节点上的 `FluentD` DaemonSet Pod 将日志从 GKE 发送到 Cloud Logging
    的交互过程：'
- en: '![Figure 8.19 – FluentD agent capturing logs and sending to Cloud Logging'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.19 – FluentD 代理捕获日志并发送到 Cloud Logging'
- en: '](img/B15587_08_19.jpg)'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_19.jpg)'
- en: Figure 8.19 – FluentD agent capturing logs and sending to Cloud Logging
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.19 – FluentD 代理捕获日志并发送到 Cloud Logging
- en: '**Event logs** are also streamed to Cloud Logging. Event logs refers to logs
    from operations that take place on the cluster such as the creation/deletion of
    a Pod, scaling of deployments, and so on. Events are stored as API objects on
    the Kubernetes master or control plane. GKE uses an event exporter in the cluster
    master to capture the events and automatically pushes them to Cloud Logging.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '**事件日志**也会流式传输到 Cloud Logging。事件日志指的是集群中发生的操作日志，如 Pod 的创建/删除、部署的扩展等。事件作为 API
    对象存储在 Kubernetes 主控或控制平面上。GKE 在集群主控中使用事件导出器来捕获事件，并自动将它们推送到 Cloud Logging。'
- en: Cloud Logging provides the ability to capture metrics from streaming logs and
    create alerting policies as needed. Cluster actions such as autoscaling can be
    configured based on custom metrics. By default, GKE-specific logs related to a
    cluster are available in Cloud Logging for 30 days. For longer retention, Cloud
    Logging offers options to export logs to Cloud Storage or Big Query using the
    concept of log sinks. [*Chapter 10*](B15587_10_Final_ASB_ePub.xhtml#_idTextAnchor218),
    *Exploring GCP Cloud Operations*, elaborates on topics related to Cloud Logging
    in depth.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: Cloud Logging 提供了从流式日志中捕获指标并根据需要创建告警策略的能力。集群操作（如自动扩展）可以根据自定义指标进行配置。默认情况下，与集群相关的
    GKE 特定日志会在 Cloud Logging 中保存 30 天。对于更长时间的保留，Cloud Logging 提供了通过日志接收器将日志导出到 Cloud
    Storage 或 BigQuery 的选项。[*第 10 章*](B15587_10_Final_ASB_ePub.xhtml#_idTextAnchor218),
    *深入探索 GCP Cloud Operations*，详细阐述了与 Cloud Logging 相关的主题。
- en: Monitoring for GKE
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GKE 监控
- en: Monitoring provides insights into how an application or Service functions based
    on key internal metrics related to a GKE cluster. In addition, monitoring also
    provides insights from a user's perspective based on the user's interaction with
    the Service. The previous chapters on site reliability engineering ([*Chapter
    1*](B15587_01_Final_ASB_ePub.xhtml#_idTextAnchor014), *DevOps, SRE, and Google
    Cloud Services for CI/CD*, to [*Chapter 4*](B15587_04_Final_ASB_ePub.xhtml#_idTextAnchor087),
    *Building SRE Teams and Applying Cultural Practices*), clearly call out Service
    reliability as one of the key aspects. Monitoring is the fundamental input to
    ensure that a Service runs reliably.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 监控提供了有关应用程序或服务功能的见解，基于与 GKE 集群相关的关键内部指标。此外，监控还从用户的角度提供见解，基于用户与服务的互动。前几章关于站点可靠性工程的内容（[*第
    1 章*](B15587_01_Final_ASB_ePub.xhtml#_idTextAnchor014), *DevOps、SRE 和 Google Cloud
    服务用于 CI/CD*，以及 [*第 4 章*](B15587_04_Final_ASB_ePub.xhtml#_idTextAnchor087), *建立
    SRE 团队和应用文化实践*）明确指出服务可靠性是关键方面之一。监控是确保服务可靠运行的基础输入。
- en: Monitoring provides data that is critical to make decisions about applications.
    This data can be used further to resolve an ongoing incident and perform a blameless
    postmortem, and you can use it further to improve an existing test suite and provide
    inputs to the product and development team for any further improvements or fine-tuning.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 监控提供了对决策至关重要的数据，帮助你做出有关应用程序的决策。这些数据还可以进一步用于解决正在进行的事件并执行无责后分析，你还可以使用它进一步改进现有的测试套件，并为产品和开发团队提供改进或微调的建议。
- en: '**Cloud Monitoring** is Google''s managed solution that provides a solution
    to monitor the state of services using key parameters such as latency, throughput,
    and so on, and identify performance bottlenecks. From a GKE perspective, monitoring
    can be divided into two domains:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '**云监控**是谷歌提供的托管解决方案，它使用关键参数（如延迟、吞吐量等）来监控服务状态，并识别性能瓶颈。从 GKE 的角度来看，监控可以分为两个领域：'
- en: '`kube-apiserver`, `etcd`, and other infrastructure elements.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-apiserver`、`etcd` 和其他基础设施元素。'
- en: '**Pod-Level Monitoring**: This includes monitoring resources using container-specific
    metrics, tracking deployment-specific system metrics, tracking instances, monitoring
    uptime checks, and monitoring application-specific metrics designed by the application''s
    developer(s).'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pod 级监控**：这包括使用容器特定的指标监控资源、跟踪特定部署的系统指标、跟踪实例、监控正常运行时间检查以及监控由应用程序开发者设计的应用程序特定指标。'
- en: 'Kubernetes uses the concept of labels to group or track resources. The same
    concept can be extended, and resources can be filtered in Cloud Monitoring using
    labels. Cloud Monitoring provides ways to track all relevant metrics and put them
    on a customized dashboard, thus giving visibility of a GKE cluster. *Figure 8.20*
    shows the built-in **GKE Dashboard** from Cloud Monitoring (with options displayed
    in collapsed mode). The GKE dashboard summarizes information about clusters, namespaces,
    nodes, workloads, Kubernetes services, Pods, and Containers:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 使用标签的概念来对资源进行分组或跟踪。这个概念可以扩展，资源可以通过标签在云监控中进行筛选。云监控提供了跟踪所有相关指标并将其展示在定制仪表板上的方式，从而实现对
    GKE 集群的可视化。*图 8.20* 展示了来自云监控的内置 **GKE 仪表板**（以折叠模式显示的选项）。GKE 仪表板总结了有关集群、命名空间、节点、工作负载、Kubernetes
    服务、Pods 和容器的信息：
- en: '![Figure 8.20 – Built-in GKE Dashboard from Cloud Monitoring'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.20 – 来自云监控的内置 GKE 仪表板'
- en: '](img/B15587_08_20.jpg)'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_20.jpg)'
- en: Figure 8.20 – Built-in GKE Dashboard from Cloud Monitoring
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.20 – 来自云监控的内置 GKE 仪表板
- en: This completes the topic on Cloud Operations for GKE and concludes the section
    on GKE where many key concepts and core features were discussed in detail. The
    next section elaborates on the latest operation mode in GKE, called **Autopilot**.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分内容涵盖了 GKE 的云操作，并结束了关于 GKE 的部分，其中详细讨论了许多关键概念和核心功能。接下来的部分将详细介绍 GKE 中的最新操作模式
    —— **自动驾驶模式**。
- en: GKE Autopilot – hands-on lab
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GKE 自动驾驶 – 动手实验
- en: '**GKE Autopilot or Autopilot** is one of the two modes of operation supported
    by GKE. The other mode being the standard mode (which was elaborated on at the
    start of this chapter). Autopilot removes the need to perform **do-it-yourself**
    (**DIY**) actions during cluster creation and instead creates a cluster with the
    industry-standard recommendations regarding networking and security. In addition,
    Autopilot removes the need to configure node pools or estimate the size of the
    cluster upfront. Nodes are automatically provisioned based on the types of deployed
    workloads and the user is essentially charged for the running workloads.'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '**GKE 自动驾驶或自动驾驶模式**是 GKE 支持的两种操作模式之一。另一种模式是标准模式（在本章开头有详细说明）。自动驾驶模式消除了在集群创建过程中执行
    **DIY**（**自助**）操作的需求，取而代之的是根据行业标准的网络和安全建议创建集群。此外，自动驾驶模式还消除了配置节点池或预估集群大小的需求。节点会根据已部署工作负载的类型自动配置，用户基本上是根据运行中的工作负载来收费。'
- en: 'Autopilot is not only managed but is also a serverless K8s offering from GKE.
    Autopilot, however, does not offer all cluster configuration choices offered by
    the standard mode. The following table represents the configuration choices offered
    by Autopilot in comparison to the standard mode:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 自动驾驶模式不仅是托管的，而且是 GKE 提供的无服务器 K8s 解决方案。然而，自动驾驶模式并未提供标准模式下的所有集群配置选项。下表展示了自动驾驶模式与标准模式在配置选项方面的对比：
- en: '![](img/Table_01.jpg)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Table_01.jpg)'
- en: 'The following is a step-by-step guide to creating a GKE cluster in Autopilot
    mode:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是创建 GKE 集群的逐步指南，采用自动驾驶模式：
- en: Navigate to the GCP Console and select the compute Service – **Kubernetes Engine**.
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 GCP 控制台并选择计算服务 – **Kubernetes 引擎**。
- en: Select the option to create a cluster and choose **Autopilot** mode. Refer to
    *Figure 8.21*:![Figure 8.21 – Select Autopilot mode during cluster creation
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择创建集群的选项，并选择 **自动驾驶** 模式。请参见 *图 8.21*：![图 8.21 – 在集群创建期间选择自动驾驶模式
- en: '](img/B15587_08_21.jpg)'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_21.jpg)'
- en: Figure 8.21 – Select Autopilot mode during cluster creation
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.21 – 在集群创建期间选择自动驾驶模式
- en: Enter the name for the cluster as `my-autopilot-cluster`. Leave the default
    selections for the rest of the options and select the **CREATE** action. Refer
    to *Figure 8.22*:![Figure 8.22 – Creating a cluster in Autopilot mode
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入集群名称为`my-autopilot-cluster`。其余选项保持默认选择，并选择**创建**操作。参见*图 8.22*：![图 8.22 – 在自动驾驶模式下创建集群
- en: '](img/B15587_08_22.jpg)'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_22.jpg)'
- en: Figure 8.22 – Creating a cluster in Autopilot mode
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.22 – 在自动驾驶模式下创建集群
- en: 'This will initiate the cluster creation process but in Autopilot mode. Once
    the cluster is created, the cluster will be listed on the cluster list page as
    shown in *Figure 8.23*:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将启动集群创建过程，但以自动驾驶模式进行。一旦集群创建完成，该集群将在集群列表页面上列出，如*图 8.23*所示：
- en: '![Figure 8.23 – New cluster created in Autopilot mode'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.23 – 在自动驾驶模式下创建的新集群'
- en: '](img/B15587_08_23.jpg)'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_23.jpg)'
- en: Figure 8.23 – New cluster created in Autopilot mode
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.23 – 在自动驾驶模式下创建的新集群
- en: 'Here are some observations from the newly created Autopilot cluster. These
    observations differentiate the Autopilot cluster from a Standard mode cluster:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从新创建的自动驾驶集群中观察到的一些情况。这些观察结果将自动驾驶集群与标准模式集群区分开来：
- en: An autopilot cluster is created without pre-assigning any nodes upfront.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动驾驶集群创建时不会预先分配任何节点。
- en: An autopilot cluster is always created as a regional cluster.
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动驾驶集群始终作为区域集群创建。
- en: The release channel for an autopilot cluster is the *Regular channel*.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动驾驶集群的发布通道是*常规通道*。
- en: Node auto-provisioning and vertical Pod autoscaling are enabled by default.
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下启用了节点自动配置和垂直Pod自动扩展。
- en: Advanced networking options such as intranode visibility, NodeLocal DNSCache,
    and HTTP load balancing are enabled by default.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下启用了高级网络选项，如节点间可见性、NodeLocal DNSCache和HTTP负载均衡。
- en: Security options such as Workload Identity and shielded GKE nodes are enabled
    by default. These security options are discussed in [*Chapter 9*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201),
    *Securing the Cluster Using GKE Security Constructs*.
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全选项，如工作负载身份和受保护的GKE节点，默认启用。这些安全选项在[*第9章*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201)《使用GKE安全结构保护集群》中有讨论。
- en: 'Once a cluster is created in Autopilot mode, workloads can be deployed to the
    Autopilot cluster in the exact same way that workloads were previously deployed
    to a cluster in Standard mode. *Figure 8.24* refers to a Deployment created on
    the Autopilot cluster:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在自动驾驶模式下创建了集群，工作负载可以以与在标准模式下部署工作负载完全相同的方式部署到自动驾驶集群中。*图 8.24*指的是在自动驾驶集群上创建的部署：
- en: '![Figure 8.24 – Deployment details in an Autopilot cluster'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.24 – 自动驾驶集群中的部署细节'
- en: '](img/B15587_08_24.jpg)'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_24.jpg)'
- en: Figure 8.24 – Deployment details in an Autopilot cluster
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.24 – 自动驾驶集群中的部署细节
- en: 'The resources required to run the workloads are allocated to the Autopilot
    cluster. *Figure 8.25* displays the cluster list page with resources allocated
    to `my-autopilot-cluster`. In this specific case, 0.5 vCPUs and 2 GB memory are
    allocated to run a single Pod. So, the user is only charged for this workload:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 运行工作负载所需的资源被分配给自动驾驶集群。*图 8.25*显示了分配给`my-autopilot-cluster`的资源。在这个特定的案例中，分配了0.5
    vCPU和2 GB内存来运行一个Pod。因此，用户只需为这个工作负载付费：
- en: '![Figure 8.25 – Resource allocation for the Autopilot cluster after deploying
    a workload'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.25 – 部署工作负载后自动驾驶集群的资源分配'
- en: '](img/B15587_08_25.jpg)'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_25.jpg)'
- en: Figure 8.25 – Resource allocation for the Autopilot cluster after deploying
    a workload
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.25 – 部署工作负载后自动驾驶集群的资源分配
- en: This completes the hands-on lab related to GKE Autopilot. This lab provides
    insights into the Autopilot configuration and how resources are allocated to the
    cluster after the deployment of workloads. This also brings us to the end of the
    chapter.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 本实验完成了与GKE自动驾驶相关的实践内容。本实验提供了关于自动驾驶配置的见解，以及工作负载部署后如何将资源分配给集群。这也标志着本章的结束。
- en: Summary
  id: totrans-396
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Given that open source Kubernetes or K8s involves a lot of setup and upkeep,
    we deep-dived into Google Kubernetes Engine or GKE, a GCP compute Service that
    runs containerized applications. The Kubernetes concepts learned in [*Chapter
    7*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154), *Understanding Kubernetes
    Essentials to Deploy Containerized Applications*, apply to GKE. We additionally
    explored GKE core features such as GKE node pools, GKE cluster configurations,
    autoscaling, and GKE's ability to integrate with other GCP services across networking
    and operations. The next chapter focuses on security-specific features related
    to the Google Kubernetes Engine, with the goal of hardening a cluster's security.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 由于开源 Kubernetes 或 K8s 涉及大量的设置和维护，我们深入研究了 Google Kubernetes Engine（GKE），这是 Google
    Cloud Platform（GCP）的一项计算服务，专门用于运行容器化应用。[*第7章*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154)
    中学到的 Kubernetes 基础知识——*理解 Kubernetes 基础以部署容器化应用*——同样适用于 GKE。我们还探索了 GKE 的核心特性，如
    GKE 节点池、GKE 集群配置、自动缩放以及 GKE 与其他 GCP 服务在网络和操作方面的集成。下一章将重点介绍与 Google Kubernetes
    Engine 相关的安全特性，目的是加强集群的安全性。
- en: Points to remember
  id: totrans-398
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记住要点
- en: 'The following are some important points to remember:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些重要的记住要点：
- en: GKE is fully managed, uses a container-optimized OS, and supports autoscaling,
    the auto-repair of nodes, and auto-upgrades.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE 是完全托管的，使用优化的容器操作系统，并支持自动缩放、节点自动修复和自动升级。
- en: GKE supports two modes of operations – Standard and Autopilot.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE 支持两种操作模式——标准模式和自动驾驶模式。
- en: GKE Standard mode supports VPC-native traffic routing and HTTP load balancing
    as default options.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE 标准模式支持 VPC 原生流量路由和 HTTP 负载均衡作为默认选项。
- en: Cloud operations for GKE are enabled as a default setting.
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE 的云操作默认启用。
- en: A private Kubernetes engine cluster cannot be accessed publicly.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 私有 Kubernetes 引擎集群无法公开访问。
- en: A node pool represents a group of nodes with the same configuration.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点池代表具有相同配置的节点组。
- en: By default, a new node pool runs the latest Kubernetes version and can be configured
    for auto-upgrade or can be manually upgraded.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下，新的节点池运行最新的 Kubernetes 版本，可以配置为自动升级，也可以手动升级。
- en: Node pools in a regional or multi-zonal cluster are replicated to multiple zones.
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区域集群或多区域集群中的节点池会复制到多个区域。
- en: A multi-zonal cluster will only have a single replica of the control plane.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多区域集群将仅有一个控制平面副本。
- en: A regional cluster has multiple replicas of the control plane running across
    multiple zones in a region.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区域集群在多个区域中运行多个控制平面副本。
- en: A release channel is used to fix known issues or add new features or address
    any security risks or concerns.
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布渠道用于修复已知问题、添加新功能或解决安全风险和关注点。
- en: GKE creates a cluster with the default version if a specific version or release
    channel is not specified.
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有指定特定版本或发布渠道，GKE 会使用默认版本创建集群。
- en: Alpha features are only available in special GKE alpha clusters and are not
    available as part of release channels.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alpha 功能仅在特定的 GKE alpha 集群中可用，不能作为发布渠道的一部分使用。
- en: Options to autoscale in GKE include the cluster autoscaler, HPA, VPA, and MPA
    (pre-GA).
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE 中的自动缩放选项包括集群自动缩放器、HPA、VPA 和 MPA（预发布阶段）。
- en: The cluster autoscaler automatically resizes a node pool in a GKE cluster.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群自动缩放器会自动调整 GKE 集群中节点池的大小。
- en: The HPA indicates when application instances should be scaled based on the current
    utilization.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HPA 根据当前的资源利用情况指示何时应该扩展应用实例。
- en: The HPA is not supported for DaemonSets.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HPA 不支持 DaemonSets。
- en: The VPA suggests recommended resources for a Pod based on the current utilization.
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VPA 根据当前的资源利用情况建议 Pod 的推荐资源配置。
- en: The VPA can automatically update workloads if the `updateMode` attribute is
    set to *On*.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 `updateMode` 属性设置为 *On*，VPA 可以自动更新工作负载。
- en: MPA allows you to horizontally scale based on CPU and vertically scale based
    on memory at the same time. This is a pre-GA feature.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MPA 允许同时基于 CPU 水平扩展和基于内存垂直扩展。这是预发布功能。
- en: 'Autoscaler provides two profile options to scale down: balanced and optimize-utilization.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动缩放器提供两种缩小的配置选项：平衡型和优化利用率型。
- en: Kubernetes' native option to avoid double hop is to set `externalTrafficPolicy`
    to `local`.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 的原生选项避免双跳的方法是将 `externalTrafficPolicy` 设置为 `local`。
- en: GKE avoids double hop using GCP HTTP(S) Load Balancer and an NEG.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE 使用 GCP HTTP(S) 负载均衡器和 NEG 避免双跳。
- en: An NEG is a set of network endpoints representing IP to port pairs.
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NEG 是一组网络端点，表示 IP 与端口的配对。
- en: GKE runs Linux's log rotate utility to clean up log files. Any log files older
    than a day or more than 100 MB will be automatically compressed and copied into
    an archive file.
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE运行Linux的日志旋转工具来清理日志文件。任何超过一天或超过100MB的日志文件将自动压缩并复制到归档文件中。
- en: GKE only stores the five most recently archived log files on the nodes and will
    delete the previously archived log files.
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE只在节点上存储最近归档的五个日志文件，并会删除之前归档的日志文件。
- en: GKE streams to Cloud Logging by using FluentD logging agents.
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE通过使用FluentD日志代理将流式数据传输到Cloud Logging。
- en: Event logs refers to logs from operations that take place on a cluster.
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件日志是指来自集群上发生的操作的日志。
- en: Events are stored as API objects on the cluster master. GKE uses an event exporter
    to push events to Cloud Logging.
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件作为API对象存储在集群主节点上。GKE使用事件导出器将事件推送到Cloud Logging。
- en: GKE cluster-specific logs are available in Cloud Logging for 30 days.
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE特定的集群日志在Cloud Logging中保留30天。
- en: For longer retention, Cloud Logging can export logs using log sinks.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于较长时间的日志保存，Cloud Logging可以通过日志接收器导出日志。
- en: GKE Autopilot mode supports cluster configurations where the availability type
    is *Regional*, the version is *Release Channel*, network isolation is *Private*
    or *Public*, and Kubernetes features are *Production*.
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE自动驾驶模式支持以下集群配置：可用性类型为*区域性*，版本为*发布渠道*，网络隔离为*私有*或*公共*，Kubernetes功能为*生产*。
- en: Further reading
  id: totrans-432
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information on GCP''s approach to DevOps, read the following articles:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 有关GCP在DevOps方面的更多信息，请阅读以下文章：
- en: '**Kubernetes**: [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/
    )'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubernetes**: [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/)'
- en: '**Google Kubernetes Engine**: [https://cloud.google.com/kubernetes-engine](https://cloud.google.com/kubernetes-engine
    )'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Kubernetes Engine**: [https://cloud.google.com/kubernetes-engine](https://cloud.google.com/kubernetes-engine)'
- en: Practice test
  id: totrans-436
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习测试
- en: 'Answer the following questions:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 回答以下问题：
- en: How do you create control plane components in GKE?
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何在GKE中创建控制平面组件？
- en: a) Create worker nodes and then create control plane components on the worker
    nodes.
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 创建工作节点，然后在工作节点上创建控制平面组件。
- en: b) A GKE cluster does not mandate the creation of control plane components.
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) GKE集群不要求创建控制平面组件。
- en: c) Create control plane components on a node group called `master` and the worker
    nodes are placed in a node group called `worker`.
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 在名为`master`的节点组上创建控制平面组件，工作节点放在名为`worker`的节点组中。
- en: d) The control plane components are automatically created and managed by GKE
    on behalf of the user.
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 控制平面组件由GKE自动创建并由GKE代表用户管理。
- en: 'Pod `p1` has three containers – `c1`, `c2`, and `c3`. The user wants to view
    the logs of container `c2`. Select the option that represents the appropriate
    CLI command to view the logs:'
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pod `p1`包含三个容器——`c1`、`c2`和`c3`。用户希望查看容器`c2`的日志。请选择表示适当CLI命令的选项来查看日志：
- en: a) `kubectl logs -p p1 -c c2`
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `kubectl logs -p p1 -c c2`
- en: b) `kubectl logs p1 -c c2`
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `kubectl logs p1 -c c2`
- en: c) `kubectl logs pod=p1 container=c2`
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `kubectl logs pod=p1 container=c2`
- en: d) `kubectl logs p1 container=c2`
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `kubectl logs p1 container=c2`
- en: 'The company *Alpha* is about to launch a stateless web application to offer
    a new e-commerce Service. The web application will have steady traffic with occasional
    peaks, especially when special offers are announced for customers. Select the
    option that depicts an appropriate cluster design in this case:'
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 公司*Alpha*即将推出一款无状态的Web应用程序，提供全新的电子商务服务。该Web应用程序将有稳定的流量，并在宣布特别优惠时出现高峰流量。请选择适合此情况的集群设计选项：
- en: a) Deploy a standard cluster and use a Deployment with the HPA.
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 部署一个标准集群，并使用带有HPA的Deployment。
- en: b) Deploy a cluster with autoscaling and use a Deployment with the HPA.
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 部署一个带有自动扩展的集群，并使用带有HPA的Deployment。
- en: c) Deploy a standard cluster and use a Deployment with the VPA.
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 部署一个标准集群，并使用带有VPA的Deployment。
- en: d) Deploy a cluster with autoscaling and use a Deployment with the VPA.
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 部署一个带有自动扩展的集群，并使用带有VPA的Deployment。
- en: 'Choose the cluster configuration that could withstand it if there was a loss
    of a GCP zone:'
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个能够承受GCP区域丢失的集群配置：
- en: a) Create a regional cluster.
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 创建一个区域性集群。
- en: b) Create a Redis cluster that can cache the resource information of the zone
    where cluster resources are hosted.
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 创建一个Redis集群，用于缓存集群资源所在区域的资源信息。
- en: c) Create two clusters in separate zones and create a load balancer between
    them.
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 在不同区域创建两个集群，并在它们之间创建负载均衡器。
- en: d) None of the above.
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 以上都不是。
- en: Select the Google Cloud Service where private GKE clusters can use Docker images
    from?
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择可以使用 Docker 镜像的 Google Cloud 服务，私有 GKE 集群可以使用：
- en: a) Cloud Source Repositories
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) Cloud Source Repositories
- en: b) Container Registry
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 容器注册表
- en: c) Cloud Build
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) Cloud Build
- en: d) All of the above
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 以上全部
- en: 'Select the allowed maximum clusters per zone:'
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择每个区域允许的最大集群数：
- en: a) 25
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 25
- en: b) 50
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 50
- en: c) 100
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 100
- en: d) Unlimited
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 无限
- en: 'Select the command to get authentication credentials to interact with a cluster
    named `my-cluster`:'
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择获取与名为 `my-cluster` 的集群交互的身份验证凭据的命令：
- en: a) `gcloud containers clusters get-credentials my-cluster`
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `gcloud containers clusters get-credentials my-cluster`
- en: b) `gcloud container clusters get-credentials my-cluster`
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `gcloud container clusters get-credentials my-cluster`
- en: c) `gcloud container cluster get-credentials my-cluster`
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `gcloud container cluster get-credentials my-cluster`
- en: d) `gcloud containers cluster get-credentials my-cluster`
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `gcloud containers cluster get-credentials my-cluster`
- en: 'Select the command that can retrieve pods in a cluster:'
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择可以检索集群中 Pod 的命令：
- en: a) `gcloud get pods`
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `gcloud get pods`
- en: b) `kubectl list pods`
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `kubectl list pods`
- en: c) `gcloud list pods`
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `gcloud list pods`
- en: d) `kubectl get pods`
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `kubectl get pods`
- en: 'The company *Real World* decides to use a third-party monitoring solution to
    monitor an application deployed in a GKE cluster. Select the best approach to
    deploy the third-party monitoring solution:'
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 公司 *Real World* 决定使用第三方监控解决方案来监控部署在 GKE 集群中的应用程序。选择部署第三方监控解决方案的最佳方法：
- en: a) It is not possible to use a third-party monitoring solution in GKE.
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 无法在 GKE 中使用第三方监控解决方案。
- en: b) Download the monitoring solution for Cloud Marketplace.
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 从 Cloud Marketplace 下载监控解决方案。
- en: c) Deploy the monitoring solution in a Pod as a DaemonSet.
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 将监控解决方案部署为 Pod，作为 DaemonSet。
- en: d) Deploy the monitoring solution in a Pod as a ReplicaSet.
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 将监控解决方案部署为 Pod，作为 ReplicaSet。
- en: 'A VPC on Google Cloud is a:'
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Google Cloud 上的 VPC 是：
- en: a) Zonal resource
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 区域资源
- en: b) Global resource
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 全球资源
- en: c) Regional resource
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 区域资源
- en: d) Multi-Regional resource
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 多区域资源
- en: 'An application called *my-app* in GKE needs access to a managed MySQL database.
    Select the most appropriate option:'
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 GKE 中名为 *my-app* 的应用程序需要访问一个托管的 MySQL 数据库。请选择最合适的选项：
- en: a) Run MySQL as an application in the cluster. The *my-app* application will
    connect with the MySQL application through the ClusterIP Service.
  id: totrans-489
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 在集群中将 MySQL 作为应用程序运行。*my-app* 应用程序将通过 ClusterIP 服务连接到 MySQL 应用程序。
- en: b) Use Cloud SQL to run MySQL database. Run the Cloud SQL proxy as a side-car
    container insider the application's Pod.
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 使用 Cloud SQL 运行 MySQL 数据库。将 Cloud SQL 代理作为应用程序 Pod 内的边车容器运行。
- en: c) Run MySQL as an application in the cluster. The *my-app* application will
    connect with the MySQL application through the `LoadBalancer` Service.
  id: totrans-491
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 在集群中将 MySQL 作为应用程序运行。*my-app* 应用程序将通过 `LoadBalancer` 服务连接到 MySQL 应用程序。
- en: d) Use Cloud SQL for running MySQL Database. Run the Cloud SQL proxy as a ClusterIP
    Service.
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 使用 Cloud SQL 运行 MySQL 数据库。将 Cloud SQL 代理作为 ClusterIP 服务运行。
- en: 'Google Network Load Balancing distributes the following traffic:'
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Google 网络负载均衡分配以下流量：
- en: a) TCP
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) TCP
- en: b) UDP
  id: totrans-495
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) UDP
- en: c) TCP or UDP
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) TCP 或 UDP
- en: d) None of the above
  id: totrans-497
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 以上皆非
- en: 'From an availability-type point of view, a cluster created in *Autopilot* mode
    is:'
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从可用性角度来看，*Autopilot* 模式下创建的集群是：
- en: a) Zonal
  id: totrans-499
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 区域
- en: b) Multi-zonal
  id: totrans-500
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 多区域
- en: c) Regional
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 区域
- en: d) Zonal and regional
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 区域和区域
- en: 'Select the option that is not a supported release channel in GKE:'
  id: totrans-503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个在 GKE 中不受支持的发布通道：
- en: a) Regular
  id: totrans-504
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 常规
- en: b) Alpha
  id: totrans-505
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) Alpha
- en: c) Rapid
  id: totrans-506
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 快速
- en: d) Stable
  id: totrans-507
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 稳定
- en: 'Select the possible cluster configurations based on network isolation:'
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择基于网络隔离的可能集群配置：
- en: a) Standard and Private
  id: totrans-509
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 标准和私有
- en: b) Standard and Public
  id: totrans-510
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 标准和公共
- en: c) Standard and Default
  id: totrans-511
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 标准和默认
- en: d) Private and Public
  id: totrans-512
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 私有和公共
- en: Answers
  id: totrans-513
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 答案
- en: (d) – The control plane components such as the `kube-api` server, scheduler,
    and so on form the cluster master and are set up and managed by GKE.
  id: totrans-514
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (d) – 控制平面组件，如 `kube-api` 服务器、调度器等，构成集群主控，并由 GKE 设置和管理。
- en: (b) – `kubectl logs p1 -c c2`
  id: totrans-515
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b) – `kubectl logs p1 -c c2`
- en: (b) – Deploy a cluster with autoscaling and use Deployment with HPA.
  id: totrans-516
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b) – 创建一个具有自动扩展的集群，并使用带 HPA 的 Deployment。
- en: (a) – Create a regional cluster as the workload is spread across multiple zones
    in one region.
  id: totrans-517
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a) – 创建一个区域集群，因为工作负载分布在一个区域内的多个区域中。
- en: (b) – Container Registry
  id: totrans-518
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b) – 容器注册表
- en: (b) – 50
  id: totrans-519
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b) – 50
- en: (b) - `gcloud container clusters get-credentials my-cluster`
  id: totrans-520
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b) - `gcloud container clusters get-credentials my-cluster`
- en: (d) - `kubectl get pods`
  id: totrans-521
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (d) - `kubectl get pods`
- en: (c) - Deploy the monitoring solution in a Pod as a DaemonSet.
  id: totrans-522
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (c) - 将监控解决方案部署为 Pod，作为 DaemonSet。
- en: (b) – Global resource
  id: totrans-523
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b) – 全球资源
- en: (c)
  id: totrans-524
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (c)
- en: (c) – TCP or UDP
  id: totrans-525
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (c) – TCP 或 UDP
- en: (c) – Regional
  id: totrans-526
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (c) – 区域
- en: (b) – Alpha
  id: totrans-527
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b) – Alpha
- en: (d) – Private and Public
  id: totrans-528
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (d) – 私有和公共
