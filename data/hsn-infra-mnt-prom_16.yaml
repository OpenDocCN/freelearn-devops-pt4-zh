- en: Choosing the Right Service Discovery
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择合适的服务发现方式
- en: When tackling dynamic environments, manually maintaining a file of targets is
    not an option. Service discovery handles the complexity of an ever-changing infrastructure
    for you, making sure that no service or host slips through the cracks. This chapter
    focuses on how to take advantage of Prometheus service discovery to decrease the
    infrastructure management toil regarding coping with constant change.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理动态环境时，手动维护目标文件是不可行的。服务发现会为您处理复杂的不断变化的基础设施，确保没有任何服务或主机被遗漏。本章重点介绍如何利用 Prometheus
    服务发现来减少在应对不断变化的基础设施管理工作中的繁琐工作。
- en: 'In brief, the following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，本章将涵盖以下主题：
- en: Test environment for this chapter
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章节的测试环境
- en: Running through the service discovery options
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行服务发现选项
- en: Using a built-in service discovery
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内建的服务发现
- en: Building a custom service discovery
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建自定义服务发现
- en: Test environment for this chapter
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本章节的测试环境
- en: In this chapter, we'll be focusing on service discovery. For this, we'll be
    deploying two new instances to simulate a scenario where Prometheus generates
    targets dynamically using a popular service discovery software. This approach
    will allow us to not only expose the required configurations, but also validate
    how everything works together.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点介绍服务发现。为此，我们将部署两个新的实例，以模拟一个场景，其中 Prometheus 使用流行的服务发现软件动态生成目标。这个方法不仅能暴露所需的配置，还能验证所有内容如何协同工作。
- en: 'The setup we''ll be using resembles the following diagram:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的设置类似于以下图示：
- en: '![](img/0046acd0-7265-423c-aab8-96f281292177.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0046acd0-7265-423c-aab8-96f281292177.png)'
- en: 'Figure 12.1: Test environment for this chapter'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.1：本章节的测试环境
- en: The usual deployment pattern for Consul is to have an agent running in client
    mode on every node in the infrastructure, which will then contact Consul instances
    running in server mode. Furthermore, client instances act as API proxies, so it
    is common practice for Prometheus Consul service discovery to be configured using
    the localhost. However, to make their different responsibilities clear, we've
    opted to just have a Prometheus instance in one VM and a Consul running as a server
    in another in our test environment.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Consul 的常见部署模式是在基础设施的每个节点上以客户端模式运行一个代理，然后与以服务器模式运行的 Consul 实例进行通信。此外，客户端实例充当
    API 代理，因此 Prometheus Consul 服务发现通常会使用本地主机进行配置。然而，为了使各自的职责更加明确，我们在测试环境中选择仅在一台虚拟机上运行
    Prometheus 实例，并在另一台虚拟机上运行作为服务器的 Consul。
- en: In the next section, we will explain how to get the test environment up and
    running.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将解释如何启动并运行测试环境。
- en: Deployment
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: 'To launch a new test environment, move into this chapter''s path, relative
    to the repository root:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动一个新的测试环境，请进入本章节的路径，相对于仓库根目录：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Ensure that no other test environments are running and spin up this chapter''s
    environment:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 确保没有其他测试环境在运行，并启动本章节的环境：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can validate the successful deployment of the test environment using the
    following command:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令验证测试环境的成功部署：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will provide you with the following output:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为您提供以下输出：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When the deployment tasks end, you''ll be able to validate the following endpoints
    on your host machine using your favorite JavaScript-enabled web browser:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 部署任务结束后，您将能够使用您最喜欢的启用了 JavaScript 的网页浏览器，在主机机器上验证以下端点：
- en: '| **Service** | **Endpoint** |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| **服务** | **端点** |'
- en: '| Prometheus | `http://192.168.42.10:9090` |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| Prometheus | `http://192.168.42.10:9090` |'
- en: '| Consul | `http://192.168.42.11:8500` |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| Consul | `http://192.168.42.11:8500` |'
- en: 'You should be able to access the desired instance by using one of the following
    commands:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该能够通过以下命令之一访问所需的实例：
- en: '| **Instance** | **Command** |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| **实例** | **命令** |'
- en: '| Prometheus | `vagrant ssh prometheus` |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| Prometheus | `vagrant ssh prometheus` |'
- en: '| Consul | `vagrant ssh consul` |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| Consul | `vagrant ssh consul` |'
- en: Cleanup
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清理
- en: 'When you''ve finish testing, just make sure you''re inside `./chapter12/` and
    execute the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 测试完成后，只需确保您位于 `./chapter12/` 目录中并执行以下命令：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Don't worry too much – you can easily spin up the environment again if you need
    to.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 不用太担心——如果需要，您可以轻松地重新启动环境。
- en: Running through the service discovery options
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行服务发现选项
- en: Prometheus comes with several discovery integrations available out of the box.
    These cover most of the mainstream data sources for application and machine inventories,
    such as public and private cloud compute APIs, VM and container orchestration
    systems, standalone service registration and discovery systems, among others.
    For those discovery mechanisms that aren't directly supported by Prometheus, integration
    can be done through a generic discovery system using the filesystem and some glue
    code, as we'll see later in this chapter.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 开箱即用地提供了多个发现集成。这些集成覆盖了大多数主流数据源，用于应用和机器清单，例如公共和私有云计算 API、虚拟机和容器编排系统、独立的服务注册和发现系统等。对于
    Prometheus 不直接支持的发现机制，可以通过通用的发现系统进行集成，利用文件系统和一些粘合代码，就像我们在本章稍后看到的那样。
- en: Every integration works in the same way – by setting all the discovered addresses
    as targets and their associated metadata as temporary labels (not persisted without
    some relabeling to keep them). For each discovered target, the `__address__` label
    is usually set to the service address and port. This is relevant, because this label
    is the one Prometheus uses to connect to the scrape target; the `instance` label
    defaults to use the `__address__` value when not explicitly defined, but it can
    be set to anything else that makes it easier to identify the target.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 每个集成都以相同的方式工作——通过将所有发现的地址作为目标，并将其相关的元数据作为临时标签（在没有某些重新标签的情况下，这些标签不会持久化）。对于每个被发现的目标，`__address__`
    标签通常被设置为服务地址和端口。这一点很重要，因为这个标签是 Prometheus 用来连接抓取目标的标签；`instance` 标签在没有显式定义时默认使用
    `__address__` 的值，但它可以设置为任何其他便于识别目标的值。
- en: Metadata labels provided by service discovery integrations follow the pattern
    of `__meta_<service discovery name>_<key>`. There are also some labels added by
    Prometheus, such as `__scheme__` and `__metrics_path__`, which define whether
    the scrape should be performed using HTTP or HTTPS and the configured endpoint
    to scrape, respectively.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 服务发现集成提供的元数据标签遵循 `__meta_<service discovery name>_<key>` 的模式。还有一些标签是 Prometheus
    添加的，例如 `__scheme__` 和 `__metrics_path__`，它们分别定义是否应使用 HTTP 或 HTTPS 执行抓取，以及配置的抓取端点。
- en: URL parameters are not supported in the `metrics_path` scrape configuration.
    Instead, these need to be set in the `params` configuration.  This is covered
    in [Chapter 5](12e775c2-bee9-4ebe-ad73-2f9313eeeeee.xhtml), *Running a Prometheus
    Server*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `metrics_path` 抓取配置中不支持 URL 参数。相反，这些参数需要在 `params` 配置中设置。相关内容将在 [第5章](12e775c2-bee9-4ebe-ad73-2f9313eeeeee.xhtml)
    中介绍，*运行 Prometheus 服务器*。
- en: The following sections provide an overview of the available discovery options,
    and also present some examples on how to configure them, accompanied by screenshots
    of their generated data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 以下章节提供了可用的发现选项概述，并展示了如何配置它们的一些示例，附带生成数据的截图。
- en: Cloud providers
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云提供商
- en: 'With the rise of cloud infrastructure, it is increasingly common to have workloads
    running in these environments. This brings new sets of challenges; for example,
    ephemeral and highly dynamic infrastructure provisioning. The ease of scalability
    is also something to keep in mind: in the past, it might have taken months to
    negotiate, agree on support contracts, buy, deploy, and configure new hardware;
    nowadays, it''s a matter of seconds to have a new fleet of instances up and running.
    With technology such as auto-scaling, which deploys new instances without you
    even knowing, change is hard to keep up with. To ease the burden of keeping tabs
    on this cloud-native dynamic infrastructure, Prometheus integrates out of the
    box with some of the big players in the **Infrastructure as a Service** (**IaaS**)
    market, such as Amazon Web Services, Microsoft Azure Cloud, Google Cloud Platform,
    OpenStack, and Joyent.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 随着云基础设施的崛起，在这些环境中运行工作负载变得越来越常见。这带来了新的挑战，例如短暂且高度动态的基础设施配置。可扩展性易于实现也是需要考虑的因素：过去，可能需要几个月的时间来协商、达成支持合同、购买、部署和配置新硬件；而现在，只需几秒钟即可启动并运行一组新的实例。随着像自动扩展这样的技术出现，它可以在你甚至不知道的情况下部署新实例，变化的速度让人难以跟上。为了减轻对这种云原生动态基础设施的监控负担，Prometheus
    开箱即用地与一些 **基础设施即服务** (**IaaS**) 市场中的大玩家进行了集成，例如 Amazon Web Services、Microsoft
    Azure Cloud、Google Cloud Platform、OpenStack 和 Joyent。
- en: 'Using Amazon **Elastic Compute **(**EC2**) as an example for virtual machine
    discovery, the scrape job configuration can be as simple as the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以 Amazon **弹性计算** (**EC2**) 为虚拟机发现的例子，抓取任务的配置可以像下面这样简单：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Other cloud providers will have different settings, but the logic is pretty
    much the same. Basically, we need to set the appropriate level of credentials
    to query the cloud provider API so that Prometheus discovery integration can consume
    all the data required to produce our targets, as well as their associated metadata.
    The following screenshot illustrates how a configuration similar to the one listed
    previously but with actual credentials translates into a set of targets:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 其他云服务提供商的设置可能有所不同，但逻辑基本相同。基本上，我们需要设置适当的凭据级别来查询云服务提供商的API，以便Prometheus发现集成能够获取生成目标所需的所有数据以及其相关的元数据。以下截图演示了如何将类似于之前列出的配置但带有实际凭据的设置转化为一组目标：
- en: '![](img/2fba1ca1-18c8-4268-8237-3f5ab2c62fbd.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2fba1ca1-18c8-4268-8237-3f5ab2c62fbd.png)'
- en: 'Figure 12.2: Prometheus */*service-discovery endpoint depicting ec2_sd data'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2：Prometheus */*service-discovery端点，展示ec2_sd数据
- en: As we can see in the preceding screenshot, EC2 discovery attaches a fair amount
    of metadata labels to each discovered target. These are available during the relabeling
    phase so that you can use them to only scrape targets that are running, change
    scraping from the private IP address to the public one, or rename the instance
    label to a friendlier name.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的截图中看到的，EC2发现将相当多的元数据标签附加到每个发现的目标。这些标签在重新标记阶段可用，您可以利用它们只抓取正在运行的目标，将抓取地址从私有IP地址更改为公共IP地址，或者将实例标签重命名为更友好的名称。
- en: This information, which is collected from the discovery process, is either periodically
    refreshed (the refresh interval is configurable at the service discovery level) or,
    automatically refreshed via watches, allowing Prometheus to become aware of targets
    being created or deleted.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从发现过程中收集的信息要么是定期刷新（刷新间隔可以在服务发现级别进行配置），要么通过监视自动刷新，使得Prometheus能够意识到目标的创建或删除。
- en: Container orchestrators
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器编排器
- en: Container orchestrators are a perfect place to extract what services are running
    and where, as it's their job to manage exactly that information. As such, the
    Prometheus discovery mechanism supports some of the most widely used container
    orchestration platforms, such as Kubernetes and Marathon, the container orchestration
    platform for Mesos and DC/OS. Since we've been using Kubernetes for most of our
    examples throughout this book, we're going to focus on this platform to explain
    how these types of systems work.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 容器编排器是提取正在运行的服务及其位置的完美场所，因为它们的工作正是管理这些信息。因此，Prometheus的发现机制支持一些最广泛使用的容器编排平台，如Kubernetes和Marathon，这是Mesos和DC/OS的容器编排平台。由于我们在本书的大部分示例中使用了Kubernetes，因此我们将重点介绍该平台，以解释这些系统是如何工作的。
- en: Like Prometheus, Kubernetes is a graduated project from the **Cloud Native Computing
    Foundation** (**CNCF**). While that doesn't mean one was created specifically
    to work with the other, the connection between the two is undeniable. Borg and
    Borgmon, Google's container orchestration and monitoring systems, are definitely
    the inspiration for Kubernetes and Prometheus, respectively. To tackle the monitoring
    of cloud-native platforms such as Kubernetes, where the rate of change is almost
    overwhelming, a special set of features is required. Prometheus fits these requirements,
    such as efficiently handling the ephemeral nature of containers.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 和Prometheus一样，Kubernetes也是**云原生计算基金会**（**CNCF**）的一个毕业项目。虽然这并不意味着一个是专门为了与另一个一起工作的，但二者之间的联系是不可否认的。Google的容器编排和监控系统Borg和Borgmon，分别是Kubernetes和Prometheus的灵感来源。为了应对Kubernetes等云原生平台的监控，其中变化的速度几乎令人难以承受，必须具备一套特别的功能。Prometheus符合这些需求，例如高效处理容器的短暂性。
- en: 'The Prometheus service discovery integration retrieves all the required data
    via the Kubernetes API, keeping up to date with the state of the cluster. Due
    to the number of API objects available to query, the discovery configuration for
    Prometheus has the concept of role, which can be either `node`, `service`, `pod`,
    `endpoint`, or `ingress`. While explaining Kubernetes core concepts is out of
    scope for this book, we can quickly go through what each of these roles is used
    to discover: `node` is used to collect the actual nodes that form the Kubernetes
    cluster (for example, the VMs that run the kubelet agent), and thus can be used
    to monitor the cluster itself, as well as its underlying infrastructure; the service
    object in Kubernetes acts like a load balancer, and `service` will give you just
    that – a single endpoint per port of each configured service, whether it is backed
    by one or several application instances – and is only used for blackbox monitoring;
    `pod` is used to discover individual pods, independently of whether they belong
    to a service or not; `endpoint` discovers the main process in a pod that is backing
    a given service; and finally, `ingress`, similar to `service`, returns the external-facing
    load balancer for a set of application instances and thus should only be used
    for end-to-end probing.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 服务发现集成通过 Kubernetes API 检索所有所需的数据，保持与集群状态的同步。由于可查询的 API 对象数量庞大，Prometheus
    的发现配置中引入了角色（role）概念，这些角色可以是 `node`、`service`、`pod`、`endpoint` 或 `ingress`。虽然解释
    Kubernetes 核心概念超出了本书的范围，但我们可以快速了解每个角色的用途：`node` 用于收集形成 Kubernetes 集群的实际节点（例如，运行
    kubelet 代理的虚拟机），因此可以用来监控集群本身以及其底层基础设施；Kubernetes 中的服务对象充当负载均衡器，`service` 将提供每个配置服务的每个端口的单个端点，无论它是由一个还是多个应用实例支持——并且仅用于黑盒监控；`pod`
    用于发现独立的 Pod，无论它们是否属于某个服务；`endpoint` 发现支持特定服务的 Pod 中的主要进程；最后，`ingress` 类似于 `service`，返回一个应用实例集合的外部负载均衡器，因此仅应在端到端探测中使用。
- en: 'The following code snippet provides an example of how to query pods, matching
    the ones that have a label, `app`, that matches the value `hey`:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段提供了一个查询 Pods 的示例，匹配具有标签 `app` 且值为 `hey` 的 Pods：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The preceding configuration generates the data depicted in the following screenshot,
    where we can see all the metadata that was gathered via the Kubernetes API:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的配置生成了以下截图中所示的数据，在其中我们可以看到通过 Kubernetes API 收集的所有元数据：
- en: '![](img/cd652109-78b2-4fea-9769-d636a2398e68.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cd652109-78b2-4fea-9769-d636a2398e68.png)'
- en: 'Figure 12.3: Prometheus /service-discovery endpoint depicting kubernetes_sd
    data'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.3：Prometheus /service-discovery 端点，展示 kubernetes_sd 数据
- en: This is a very small example of what can be done. Configurations that use the
    Kubernetes service discovery usually make extensive use of `relabel_configs` to
    filter targets, rewrite the `job` label to match container names, and to generally
    do clever auto-configuration based on conventions around Kubernetes annotations.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可以完成的非常小的示例。使用 Kubernetes 服务发现的配置通常广泛使用 `relabel_configs` 来过滤目标，重写 `job`
    标签以匹配容器名称，并且通常基于 Kubernetes 注解的约定进行巧妙的自动配置。
- en: Service discovery systems
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务发现系统
- en: As the number of services grows, it becomes harder and harder to tie everything
    together – both in terms of services being correctly configured to contact each
    other, as well as operators having visibility of how the system is behaving. A
    common solution to these problems is to implement a service discovery system that
    acts as registry and that can then be consulted by software clients, as well as
    the monitoring system.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 随着服务数量的增加，越来越难以将所有内容联系在一起——无论是在服务正确配置以相互通信方面，还是在操作员能看到系统行为的方面。解决这些问题的常见方法是实现一个服务发现系统，它充当注册表，软件客户端以及监控系统可以查询该注册表。
- en: Prometheus integrates seamlessly with a few mainstream service discovery systems
    and currently supports Consul, Nerve, and ServerSets. Integrating directly with
    discovery services allows Prometheus to always have an up-to-date view of what
    is running and where, allowing service instances to be monitored automatically
    as soon as they are created, up until they are destroyed.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 无缝集成了几个主流的服务发现系统，目前支持 Consul、Nerve 和 ServerSets。直接与发现服务集成使 Prometheus
    始终能够获取当前运行的服务及其位置，从而使服务实例在创建后能够被自动监控，直到它们被销毁。
- en: 'Consul is by far the most popular, as it provides a full set of features to
    implement service discovery and powerful yet simple-to-use command-line tools
    and APIs, and is easy to scale. Let''s use the following for our example:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Consul 目前是最受欢迎的，它提供了一整套功能来实现服务发现，并且拥有强大且易于使用的命令行工具和 API，且易于扩展。我们以以下内容作为示例：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding example translates into the following screenshot, where we can
    see not only the generated labels, but also the definitions of the targets:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的示例转换成如下截图，我们可以看到不仅是生成的标签，还有目标的定义：
- en: '![](img/1e139a67-bffa-4703-8efa-3715a6c9ad83.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1e139a67-bffa-4703-8efa-3715a6c9ad83.jpg)'
- en: 'Figure 12.4: Prometheus /service-discovery endpoint depicting consul_sd data'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.4：Prometheus /service-discovery 端点展示 consul_sd 数据
- en: The preceding example shows a working configuration for gathering data from
    all the available services registered within a Consul server, using `relabel_configs`
    to rewrite the target's `job` label to be the service name instead of the `job_name`.
    This means that every application instance registered in Consul would be automatically
    picked up as a scrape target and correctly assigned the proper job name. Additionally,
    the last relabel rule changes the target port to `9107` when the service is named
    Consul, thus changing the target from Consul itself to an exporter for it.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的示例展示了一个工作配置，用于从 Consul 服务器中所有可用服务收集数据，使用 `relabel_configs` 将目标的 `job` 标签重写为服务名称，而不是
    `job_name`。这意味着在 Consul 中注册的每个应用实例都会被自动拾取为抓取目标，并正确分配适当的作业名称。此外，最后的重标签规则会在服务名为
    Consul 时将目标端口更改为 `9107`，从而将目标从 Consul 本身更改为其导出器。
- en: DNS-based service discovery
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于 DNS 的服务发现
- en: 'This type of service discovery relies on DNS to gather data. It works by defining
    a list of domain names that will be queried regularly to obtain targets. The name
    servers that are used for resolution are looked up in `/etc/resolv.conf`. This
    discovery integration, besides supporting A and AAAA DNS records, is also able
    to query SRV records, which also provide the port for the service:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的服务发现依赖于 DNS 来收集数据。它通过定义一系列需要定期查询的域名来获取目标。用于解析的名称服务器会在 `/etc/resolv.conf`
    中查找。除了支持 A 和 AAAA DNS 记录外，该发现集成还能够查询 SRV 记录，SRV 记录还提供服务的端口：
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can see that, by querying the SRV record for `hey.service.example.inet` in
    this example, we get the service location `server01.node.example.inet` and port
    `8080`. We also get the A record with the service IP address and a TXT record
    with some metadata.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，通过查询 `hey.service.example.inet` 的 SRV 记录，在此示例中，我们得到服务位置 `server01.node.example.inet`
    和端口 `8080`。我们还得到了包含服务 IP 地址的 A 记录和包含一些元数据的 TXT 记录。
- en: 'The following snippet illustrates a sample scrape configuration using this
    DNS service discovery integration. It does this by using the domain `hey.service.example.inet`
    from before:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了使用此 DNS 服务发现集成的示例抓取配置。它通过使用之前提到的域名 `hey.service.example.inet` 来实现：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The returned SRV records will be converted into new targets. Prometheus doesn''t
    support the advanced DNS-SD specified in RFC 6763, which allows metadata to be
    transmitted in associated TXT records (as seen in the `dig` command previously).
    This means that only the service address and port can be discovered using this
    method. We can see what discovered labels are available in the following screenshot:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的 SRV 记录将转换为新的目标。Prometheus 不支持 RFC 6763 中指定的高级 DNS-SD，它允许通过相关的 TXT 记录传输元数据（如之前在
    `dig` 命令中看到的）。这意味着只能使用此方法发现服务地址和端口。我们可以在以下截图中看到发现的标签：
- en: '![](img/261b8bcc-e022-46fc-95dc-b4b0c45c0ab5.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/261b8bcc-e022-46fc-95dc-b4b0c45c0ab5.png)'
- en: 'Figure 12.5: Prometheus */service-discovery* endpoint depicting *dns_sd* data'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.5：Prometheus */service-discovery* 端点展示 *dns_sd* 数据
- en: From all the discovery integrations, this is the one with the low amount of
    provided metadata. Adding to that, using DNS for service discovery is hard to
    get right – planning for slow convergence, considering several different cache
    layers that may or may not respect record TTLs, among other concerns. This should
    only be considered for advanced cases.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有发现集成中，这是提供的元数据最少的一个。此外，使用 DNS 进行服务发现很难做到正确——需要规划慢速收敛，考虑多个不同的缓存层，这些缓存层可能会或可能不会尊重记录的
    TTL 等问题。这种方法应该仅在高级用例中考虑。
- en: File-based service discovery
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于文件的服务发现
- en: Similar to the webhook notifier being the solution for integrating with unsupported
    notification systems (as explained in [Chapter 11](db658650-14d2-4a7e-9ae0-1c003e63109c.xhtml),
    *Understanding and Extending Alertmanager*), file-based integration provides the
    same type of solution for service discovery. It works by loading a list of valid
    JSON or YAML files, which in turn are used to generate the required targets and
    their labels. Reloading or restarting Prometheus after discovery files change
    is not necessary as they are watched for changes and automatically reread, depending
    on the operating system. Additionally, and as a fallback, the discovery files
    are also read on a schedule (every 5 minutes, by default).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 webhook 通知器为集成不受支持的通知系统提供解决方案（如 [第 11 章](db658650-14d2-4a7e-9ae0-1c003e63109c.xhtml)《理解与扩展
    Alertmanager》中所解释的），基于文件的集成为服务发现提供了相同类型的解决方案。它的工作原理是加载有效的 JSON 或 YAML 文件列表，这些文件用于生成所需的目标及其标签。文件发现更改后不需要重载或重启
    Prometheus，因为它们会被监控并自动重新读取，具体取决于操作系统。此外，作为回退，发现文件也会按照预定计划（默认每 5 分钟）被读取。
- en: 'The following JSON snippet shows a valid Prometheus discovery file. As we can
    see, there is a label list and a targets array that the labels apply to:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 JSON 片段展示了一个有效的 Prometheus 服务发现文件。正如我们所看到的，它包含了标签列表和一个目标数组，这些标签适用于目标：
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following scrape configuration uses the `file_sd` discovery, which loads
    the `file_sd.json` that has the content we showed previously:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 以下抓取配置使用了 `file_sd` 服务发现，它加载了之前展示的 `file_sd.json` 文件：
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `files` list also allows globing on the last element of the path, at the
    file level.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`files` 列表还允许对路径的最后一个元素进行 glob 匹配，即对文件级别进行匹配。'
- en: 'The discovered target from this configuration can be seen in the following
    screenshot, where we can check the metadata provided by our file, as well as the
    labels that were generated automatically by Prometheus:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 从该配置中发现的目标可以在下图中看到，我们可以检查文件提供的元数据以及 Prometheus 自动生成的标签：
- en: '![](img/04711801-62dc-4225-8c1d-78288a7c1091.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/04711801-62dc-4225-8c1d-78288a7c1091.png)'
- en: 'Figure 12.6: Prometheus /service-discovery endpoint depicting file_sd data'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.6：Prometheus /service-discovery 端点展示 file_sd 数据
- en: 'It is easy to see how this integration opens up a world of possibilities: these
    files can be created through a daemon that''s constantly running or a cron job,
    using shell scripts (even a simple wget) or full-fledged programming languages,
    or simply put in place by configuration management. We will explore this topic
    later in this chapter when we discuss how to build a custom service discovery.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易看出，这种集成打开了无数可能性：这些文件可以通过一个常驻的守护进程或者一个定时任务（cron job）创建，使用 shell 脚本（甚至是简单的
    wget）或完备的编程语言，或者通过配置管理工具来部署。我们将在本章后面讨论如何构建自定义服务发现时，深入探讨这个话题。
- en: Using a built-in service discovery
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用内置的服务发现
- en: To understand how the integration between Prometheus and a service discovery
    provider works, we're going to rely on our test environment. Going even further,
    we'll provide a working example of Prometheus running in Kubernetes, relying on
    its native service discovery for this platform. These hands-on examples will showcase
    how everything ties together, helping you figure out not only the benefits but,
    above all, the simplicity of these mechanics.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解 Prometheus 和服务发现提供者之间的集成方式，我们将依赖于我们的测试环境。进一步来说，我们将提供一个在 Kubernetes 中运行的
    Prometheus 工作示例，依赖于该平台的原生服务发现。这些动手示例将展示如何将一切结合起来，帮助你不仅理解其优点，更重要的是理解这些机制的简单性。
- en: Using Consul service discovery
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Consul 服务发现
- en: For this chapter, we configured Consul as an example service discovery system
    in our virtual machine-based test environment – Consul is quite simple to set
    up, which makes it perfect for our example. The way it works is by having an agent
    running in client mode in each node and an odd number of agents running in server
    mode that maintain the service catalog. The services that are available on the
    client nodes are communicated to the server nodes directly, while cluster membership
    is propagated using a gossip protocol (random peer-to-peer message passing) between
    every node in the cluster. Since our main objective is to showcase the Prometheus
    service discovery using Consul, we configured our test environment with an agent
    running in development mode, which enables an in-memory server to play around
    with. This, of course, has complete disregard for security, scalability, data
    safety, and resilience; documentation regarding how to properly configure Consul
    can be found at [https://learn.hashicorp.com/consul/](https://learn.hashicorp.com/consul/),
    and should be taken into account when deploying and maintaining Consul in production
    environments.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将 Consul 配置为虚拟机基础的测试环境中的示例服务发现系统——Consul 的设置非常简单，这使得它非常适合我们的示例。它的工作方式是在每个节点上运行一个客户端模式的代理，以及在服务器模式下运行的一个奇数个代理，后者维护服务目录。客户端节点上可用的服务会直接传递给服务器节点，而集群成员身份则通过集群中每个节点之间使用的
    gossip 协议（随机点对点消息传递）进行传播。由于我们的主要目标是展示使用 Consul 进行 Prometheus 服务发现，我们将测试环境配置为在开发模式下运行的代理，从而启用一个内存中的服务器来进行实验。当然，这完全忽视了安全性、可扩展性、数据安全性和弹性；关于如何正确配置
    Consul 的文档可以在[https://learn.hashicorp.com/consul/](https://learn.hashicorp.com/consul/)找到，在部署和维护
    Consul 于生产环境中时应予以考虑。
- en: 'To poke around how this is set up in the test environment, we need to connect
    to the instance running Consul:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看测试环境中如何配置此项，我们需要连接到运行 Consul 的实例：
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'From here, we can start to explore how Consul is set up. For example, the following
    snippet shows the systemd unit file being used, where we can see the configuration
    flags being used – it''s configured to run as an agent in development mode, and
    has to bind its ports to the instance''s external-facing IP address:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们可以开始探索 Consul 是如何配置的。例如，以下片段展示了正在使用的 systemd 单元文件，在其中我们可以看到正在使用的配置标志——它被配置为在开发模式下以代理身份运行，并且必须将其端口绑定到实例的外部
    IP 地址：
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'If we run `ss` and filter its output to only show lines belonging to Consul,
    we can find all the ports it''s using:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行`ss`并过滤其输出，只显示属于 Consul 的行，我们可以找到它正在使用的所有端口：
- en: '[PRE14]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'As we can see, Consul listens on a lot of ports, both TCP and UDP. The port
    we''re interested in is the one serving the HTTP API, which defaults to TCP port
    `8500`. If we open a web browser to `http://192.168.42.11:8500`, we will see something
    similar to the following:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，Consul 监听了多个端口，包括 TCP 和 UDP。我们关心的端口是提供 HTTP API 的端口，默认是 TCP 端口`8500`。如果我们在浏览器中访问`http://192.168.42.11:8500`，我们将看到类似以下内容：
- en: '![](img/e34662e2-2048-4bba-b590-7753c24c4dec.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e34662e2-2048-4bba-b590-7753c24c4dec.png)'
- en: 'Figure 12.7: Consul web interface displaying its default configuration'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.7：Consul Web 界面显示其默认配置
- en: There's a single service configured by default, which is the Consul service
    itself.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 默认配置了一个服务，即 Consul 服务本身。
- en: 'To make this example more interesting, we also have `consul_exporter` (an exporter
    provided by the Prometheus project) deployed in the `consul` instance. This exporter
    doesn''t require any additional configuration on Consul''s side, so it should
    just work. We can find the configuration used to run this service in the systemd
    unit file, like so:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让这个示例更加有趣，我们还在`consul`实例中部署了`consul_exporter`（一个由 Prometheus 项目提供的导出器）。这个导出器无需在
    Consul 端进行任何额外配置，因此应该能够直接工作。我们可以在 systemd 单元文件中找到运行该服务所使用的配置，像这样：
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The source code and installation files for the `consul_exporter` are available
    at [https://github.com/prometheus/consul_exporter](https://github.com/prometheus/consul_exporter).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`consul_exporter`的源代码和安装文件可在[https://github.com/prometheus/consul_exporter](https://github.com/prometheus/consul_exporter)找到。'
- en: 'To validate that the exporter is correctly contacting Consul and parsing its
    metrics, we can run the following instruction:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证导出器是否正确地联系到 Consul 并解析其指标，我们可以运行以下指令：
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The exporter sets the `consul_up` metric to `1` when it can successfully connect
    and collect metrics from Consul. We can also see the `consul_catalog_services` metric,
    which is telling us that Consul knows about one service, matching what we've seen
    in the web interface.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 当 exporter 成功连接并从 Consul 收集指标时，它会将 `consul_up` 指标设置为 `1`。我们还可以看到 `consul_catalog_services`
    指标，它告诉我们 Consul 知道有一个服务，与我们在 Web 界面中看到的内容一致。
- en: 'We can now disconnect from the `consul` instance and connect to the `prometheus`
    one using the following commands:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以断开与 `consul` 实例的连接，并使用以下命令连接到 `prometheus` 实例：
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'If we take a look at the Prometheus server configuration, we will find the
    following:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看 Prometheus 服务器配置，我们将发现以下内容：
- en: '[PRE18]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This configuration allows Prometheus to connect to the Consul API address (available
    at `http://192.168.42.11:8500`) and, by means of `relabel_configs`, rewrite the
    `job` label so that it matches the service name (as exposed in the `__meta_consul_service`
    label). If we inspect the Prometheus web interface, we can find the following
    information:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 该配置允许 Prometheus 连接到 Consul API 地址（可通过 `http://192.168.42.11:8500` 访问），并通过 `relabel_configs`
    重写 `job` 标签，使其与服务名称（如 `__meta_consul_service` 标签中所示）匹配。如果我们检查 Prometheus 的 Web
    界面，我们可以看到以下信息：
- en: '![](img/2db261a5-76d8-4f3e-ad1f-30889debfefc.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2db261a5-76d8-4f3e-ad1f-30889debfefc.png)'
- en: 'Figure 12.8: Prometheus /service-discovery endpoint showing Consul default
    service'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.8：Prometheus `/service-discovery` 端点显示 Consul 默认服务
- en: 'Now, the fun part: let''s add a scrape target for `consul_exporter` automatically
    by defining it as a service in Consul. A JSON payload with a Consul service configuration
    is provided in this chapter''s resources, so we can add it via the Consul API.
    The payload can be found at the following path:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，到了有趣的部分：让我们通过将 `consul_exporter` 定义为 Consul 中的一个服务，自动添加一个抓取目标。该章节的资源中提供了一个包含
    Consul 服务配置的 JSON 有效负载，我们可以通过 Consul API 将其添加。有效负载位于以下路径：
- en: '[PRE19]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Using the following instruction, we''ll add this new service to Consul''s service
    catalogs via the HTTP API:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下指令，我们将通过 HTTP API 将此新服务添加到 Consul 的服务目录中：
- en: '[PRE20]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After running this command, we can validate that the new service was added
    by having a look at the Consul web interface, which will show something like the
    following:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此命令后，我们可以通过查看 Consul Web 界面来验证新服务是否已被添加，该界面将显示类似如下内容：
- en: '![](img/0250a371-7438-4945-b9b1-b19b321477d4.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0250a371-7438-4945-b9b1-b19b321477d4.png)'
- en: 'Figure 12.9: Consul web interface showing the consul-exporter service'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.9：Consul Web 界面显示 consul-exporter 服务
- en: 'Finally, we can inspect the Prometheus `/service-discovery` endpoint and check
    that we have a new target, proving that the Consul service discovery is working
    as expected:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以检查 Prometheus `/service-discovery` 端点，查看是否有一个新目标，从而证明 Consul 服务发现功能正常：
- en: '![](img/6953826d-6c14-489b-9767-5af2237bc548.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6953826d-6c14-489b-9767-5af2237bc548.png)'
- en: 'Figure 12.10: Prometheus /service-discovery endpoint showing consul-exporter
    target'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.10：Prometheus `/service-discovery` 端点显示 consul-exporter 目标
- en: 'If we consult the `consul_catalog_services` metric once again, we can see that
    it has changed to 2\. Since we''re now collecting the `consul_exporter` metrics
    in Prometheus, we can query its current value using `promtool`:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们再次查看 `consul_catalog_services` 指标，我们会发现它已经变为 2。由于我们现在正在 Prometheus 中收集 `consul_exporter`
    指标，我们可以使用 `promtool` 查询其当前值：
- en: '[PRE21]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Consul tags can be used to do scrape job configuration using `relabel_configs`
    for services that have different requirements, such as changing the metrics path
    when a given tag is present, or having a tag to mark whether to scrape using HTTPS.
    The `__meta_consul_tags` label value has the comma separator at the beginning
    and end to make matching easier; this way, you don''t need to special-case your
    regular expression, depending on the position in the string of the tag you''re
    trying to match. An example of this at work could be:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Consul 标签可以用于通过 `relabel_configs` 配置抓取任务，适用于有不同要求的服务，例如在某个标签存在时更改指标路径，或者使用一个标签来标记是否使用
    HTTPS 进行抓取。`__meta_consul_tags` 标签的值在开始和结束时有逗号分隔符，以便更容易进行匹配；这样，你就不需要根据你尝试匹配的标签在字符串中的位置来特别处理正则表达式。一个实际的例子如下：
- en: '[PRE22]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This would only keep services registered in Consul with the `exporter` tag,
    discarding everything else.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这将仅保留在 Consul 中注册的带有 `exporter` 标签的服务，丢弃其他所有服务。
- en: Using Kubernetes service discovery
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 服务发现
- en: 'In this example, we''re stepping away from the Prometheus Kubernetes Operator
    we''ve been using in previous chapters so that we can focus on the Prometheus
    native service discovery integration for this container orchestration platform.
    The manifests for getting Prometheus up and running in our Kubernetes test environment
    can be found, relative to the code repository root path, at the following path:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将不再使用前几章中的 Prometheus Kubernetes Operator，而是将重点放在 Prometheus 原生服务发现集成上，以便与这个容器编排平台配合使用。用于在
    Kubernetes 测试环境中启动 Prometheus 的清单文件可以在以下路径中找到，相对于代码仓库的根路径：
- en: '[PRE23]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The following steps will ensure a new Kubernetes environment with all the required
    software provisioned so that we can then focus on the service discovery component.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将确保在新 Kubernetes 环境中配置所有所需的软件，从而使我们能够专注于服务发现组件。
- en: 'Validate that no other environment is running:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 验证没有其他环境在运行：
- en: '[PRE24]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Start an empty Kubernetes environment:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 启动一个空的 Kubernetes 环境：
- en: '[PRE25]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The extra configuration we''re providing to minikube is needed so that Prometheus
    is able to interact with `kubelets` using service account tokens. When the previous
    command finishes, a new Kubernetes environment will be ready to be used. We can
    then proceed to deploy our configurations using the following instructions:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供给 minikube 的额外配置是必需的，以便 Prometheus 能够通过服务帐户令牌与 `kubelets` 进行交互。当前一个命令完成时，一个新的
    Kubernetes 环境将准备就绪。然后我们可以按照以下说明部署我们的配置：
- en: '[PRE26]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The previous command applies several manifests, which, among other things,
    create a namespace called `monitoring`, a ServiceAccount, and all the required
    RBAC configurations so that Prometheus can query the Kubernetes API. A `ConfigMap`
    with the Prometheus server configuration is also included, which can be found
    at `bootstrap/03_prometheus-configmap.yaml`. It defines several scrape jobs for
    Kubernetes components that are targeted through the use of service discovery,
    as we can see in the following snippet:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令应用了几个清单文件，其中包括创建一个名为 `monitoring` 的命名空间、一个 ServiceAccount，以及所有所需的 RBAC
    配置，以便 Prometheus 可以查询 Kubernetes API。还包括一个包含 Prometheus 服务器配置的 `ConfigMap`，该配置可以在
    `bootstrap/03_prometheus-configmap.yaml` 中找到。它定义了多个 Kubernetes 组件的抓取任务，这些任务通过服务发现功能进行目标定位，正如以下片段所示：
- en: '[PRE27]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We can open the Prometheus web interface by issuing the following command:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过执行以下命令打开 Prometheus Web 界面：
- en: '[PRE28]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'By moving into the service discovery section available on the `/service-discovery`
    endpoint, we can see that, even though several pods were discovered, none of them
    matched the label value `hey` for the `app` label, and as such are being dropped:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 通过进入 `/service-discovery` 端点的服务发现部分，我们可以看到，尽管发现了几个 pod，但没有一个匹配 `app` 标签的 `hey`
    标签值，因此它们被丢弃：
- en: '![](img/17bff879-85f8-4b7b-b064-e3584277df90.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/17bff879-85f8-4b7b-b064-e3584277df90.png)'
- en: 'Figure 12.11: Prometheus /service-discovery endpoint showing dropped targets
    for the kubernetes-pods job'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.11：Prometheus /service-discovery 端点显示 kubernetes-pods 任务丢弃的目标
- en: 'It''s now time to add some new pods with the correct label/value pair to trigger
    our service discovery configuration. We can proceed by running the following commands,
    which will be deploying the `hey` application, and then follow the status of the
    deployment:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候添加一些带有正确标签/值对的新 pod，以触发我们的服务发现配置。我们可以通过运行以下命令来继续部署 `hey` 应用程序，然后跟踪部署状态：
- en: '[PRE29]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'After a successful deployment, we can go, once again, to the Prometheus web
    interface at the `/service-discovery` endpoint, where we can see that there are
    now three active targets in the `kubernetes-pods` scrape job. The following screenshot
    depicts one of those targets and all the labels provided by the Kubernetes API:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功部署后，我们可以再次访问 Prometheus Web 界面，在 `/service-discovery` 端点查看，发现现在在 `kubernetes-pods`
    抓取任务中有三个活动目标。以下截图展示了其中一个目标及其所有由 Kubernetes API 提供的标签：
- en: '![](img/b49d8dc0-ea63-4617-a91c-9020c6e8b6d1.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b49d8dc0-ea63-4617-a91c-9020c6e8b6d1.png)'
- en: 'Figure 12.12: Prometheus /service-discovery endpoint showing the discovered
    targets for the kubernetes-pods job'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.12：Prometheus /service-discovery 端点显示为 kubernetes-pods 任务发现的目标
- en: 'When you''re finished testing, you can delete this Kubernetes-based environment
    by issuing the following command:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 测试完成后，您可以通过执行以下命令删除此 Kubernetes 环境：
- en: '[PRE30]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This approach to service discovery allows us to keep track of several Kubernetes
    objects automatically, without forcing us to change the Prometheus configuration
    manually. This environment allows us to test all sorts of settings and provides
    the basis for tailoring the Kubernetes service discovery to our specific needs.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这种服务发现方式使我们能够自动跟踪多个 Kubernetes 对象，而无需手动更改 Prometheus 配置。该环境使我们能够测试各种设置，并为定制
    Kubernetes 服务发现以满足我们的特定需求提供了基础。
- en: Building a custom service discovery
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建自定义服务发现
- en: 'Even with all the available service discovery options, there are numerous other
    systems/providers that are not supported out of the box. For those cases, we''ve
    got a couple of options:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 即便有许多现成的服务发现选项，仍有许多其他系统/提供者不被默认支持。在这些情况下，我们有几种选择：
- en: Open a feature request for Prometheus to support that particular service discovery,
    and rely on the community and/or maintainers to implement it.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提交一个功能请求，请求 Prometheus 支持该特定的服务发现，并依赖社区和/或维护者来实现它。
- en: Implement the service discovery integration yourself in Prometheus and either
    maintain a fork or contribute it back to the project.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Prometheus 中自行实现服务发现集成，并维护一个分支或将其贡献回项目。
- en: Figure out a way to get the targets you require into your Prometheus instances
    with minimal maintenance work and time cost, and without relying on the Prometheus
    roadmap to get the job done.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到一种方法，以最少的维护工作和时间成本将所需的目标导入 Prometheus 实例，并且无需依赖 Prometheus 路线图来完成这项工作。
- en: The first two options aren't great, as they are either outside of our control
    or are cumbersome to maintain. Furthermore, adding additional service discovery
    integrations to Prometheus without fairly large interest and backing communities
    places an undue support burden on the maintainers, who aren't currently accepting
    any new integrations. Luckily, there is a way to easily integrate with any type
    of service or instance catalog, without needing to maintain costly forks or creative
    hacks. In the following section, we'll be tackling how to integrate our own service
    discovery with Prometheus.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 前两种选项不太理想，因为它们要么超出了我们的控制范围，要么维护起来很麻烦。此外，在没有较大兴趣和支持社区的情况下将额外的服务发现集成到 Prometheus
    中，会给维护者带来过多的支持负担，而维护者目前并未接受任何新的集成。幸运的是，有一种方法可以轻松与任何类型的服务或实例目录进行集成，而无需维护昂贵的分支或创造性的黑客解决方案。在接下来的部分，我们将探讨如何将我们自己的服务发现与
    Prometheus 集成。
- en: Custom service discovery fundamentals
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义服务发现基础
- en: The recommended way to integrate a custom service discovery is by relying on
    the file-based service discovery, `file_sd`. The way this integration should be
    implemented is to have a process (local or remote, scheduled or permanently running)
    query a data source (catalogue/API/database/**configuration management database** (**CMDB**))
    and then write a JSON- or YAML-formatted file with all the targets and their respective
    labels on a path that's accessible by Prometheus. The file is then read by Prometheus
    either automatically through disk watches or on a schedule, which in turn allows
    you to dynamically update the targets that are available for scraping.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 集成自定义服务发现的推荐方式是依赖基于文件的服务发现`file_sd`。集成实现的方式是通过一个进程（本地或远程、定时或持续运行）查询数据源（目录/API/数据库/**配置管理数据库**（**CMDB**）），然后将所有目标及其相应标签写入一个
    Prometheus 可访问的路径上的 JSON 或 YAML 格式文件。然后，Prometheus 会通过磁盘监控或定时任务自动读取该文件，从而使你能够动态更新可供抓取的目标。
- en: 'The following diagram illustrates the aforementioned workflow:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了上述工作流程：
- en: '![](img/aedacf33-2fb8-4089-b3c2-81c1062d1ec8.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aedacf33-2fb8-4089-b3c2-81c1062d1ec8.png)'
- en: 'Figure 12.13: Custom service discovery flow'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.13：自定义服务发现流程
- en: This type of approach is generic enough to comply with most, if not all, required
    use cases, making it possible to build a custom service discovery mechanism in
    a straightforward manner.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法足够通用，可以满足大多数（如果不是全部）所需的用例，使得以简单明了的方式构建自定义服务发现机制成为可能。
- en: Community-driven `file_sd` integrations can be found at [https://prometheus.io/docs/operating/integrations/#file-service-discovery](https://prometheus.io/docs/operating/integrations/#file-service-discovery).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 社区驱动的`file_sd`集成可以在 [https://prometheus.io/docs/operating/integrations/#file-service-discovery](https://prometheus.io/docs/operating/integrations/#file-service-discovery)
    找到。
- en: Now that we know how this type of integration should work, let's dive right
    in and start building our own.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了这种集成方式的工作原理，接下来让我们直接动手，开始构建我们自己的服务发现。
- en: Recommended approach
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐方式
- en: As we've explained so far, building a custom service discovery seems like a
    manageable enough endeavor. We're required to query something for data and write
    that data into a file, following a standard format. To make our lives easier,
    the Prometheus team made an adapter available that removes a big chunk of the
    boilerplate for creating a new service discovery integration. This adapter is
    only provided for the Go programming language, as it reuses some code from Prometheus
    itself. The adapter was made this way so that some less-maintained service discovery
    integrations could be migrated out to standalone services without too much effort,
    as well as easing the migration into the main Prometheus binary of external discovery
    integrations that are built using the adapter, all of which have proven themselves.
    Note that nothing prevents you from using the language of your choice to build
    such integrations, but for the sake of following the recommended approach, we'll
    be sticking with Go and the discovery adapter. Explaining how to program in Go
    is outside the scope of this book.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，构建自定义服务发现似乎是一个可管理的任务。我们需要查询数据并将数据按照标准格式写入文件。为了简化我们的生活，Prometheus团队提供了一个适配器，可以消除创建新服务发现集成的大部分样板代码。这个适配器仅适用于Go编程语言，因为它重用了来自Prometheus本身的一些代码。这种设计使得一些维护较少的服务发现集成可以不太费力地迁移到独立服务中，同时也简化了使用适配器构建的外部发现集成迁移到主Prometheus二进制文件中的过程，这些集成都已经被证明是有效的。请注意，并没有阻止您使用您选择的语言来构建这样的集成，但出于遵循推荐方法的考虑，我们将坚持使用Go和这个发现适配器。关于如何在Go中编程的详细说明超出了本书的范围。
- en: In the main Prometheus repository, we can find the code for the adapter, as
    well as an example using Consul, which, curiously enough, we've already set up
    in our test environment. As we know by now, Consul integration is supported natively
    in Prometheus; however, let's pretend it's not and that we need to integrate with
    it. In the following topics, we'll go over how to put everything together and
    build a custom service discovery.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在主Prometheus代码库中，我们可以找到适配器的代码，以及一个使用Consul的示例，有趣的是，我们已经在我们的测试环境中设置了Consul。正如我们现在所知，Consul集成在Prometheus中得到了原生支持；然而，假装它没有得到支持，我们需要与之集成。在接下来的主题中，我们将详细讨论如何将所有内容整合在一起并构建一个自定义的服务发现。
- en: The code for the custom service discovery example is available at [https://github.com/prometheus/prometheus/tree/v2.9.1/documentation/examples/custom-sd](https://github.com/prometheus/prometheus/tree/v2.9.1/documentation/examples/custom-sd).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义服务发现示例的代码可在[https://github.com/prometheus/prometheus/tree/v2.9.1/documentation/examples/custom-sd](https://github.com/prometheus/prometheus/tree/v2.9.1/documentation/examples/custom-sd)找到。
- en: The service discovery adapter
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务发现适配器
- en: As a high-level overview, the adapter takes care of launching and managing our
    custom service discovery code, consuming the groups of targets it produces, converting
    them into `file_sd` format, and ensuring that the JSON data is written to a file
    when required. When writing a service discovery integration using this adapter,
    no change is needed in its code, and so it can just be imported as a library.
    To give a bit more context about what the adapter is doing, we're going to explain
    some of the lower-level details so that its behaviors are clear when we implement
    our own discovery using it.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 作为高层次概述，适配器负责启动和管理我们自定义服务发现代码，消费它生成的目标组，并将它们转换为`file_sd`格式，并确保在需要时将JSON数据写入文件。使用这个适配器编写服务发现集成时，不需要修改其代码，因此它可以作为一个库直接导入。为了更清楚地解释适配器的行为，我们将解释一些低级细节，以便在实现我们自己的发现时其行为变得清晰。
- en: 'The following snippet illustrates the `Run` function of the adapter that we
    will need to invoke from our code. This function will take care of starting a
    `discovery.Manager` in its own goroutine (`a.manager.Run`), instructing it to
    run our discovery implementation (`a.disc`), and, finally, running the adapter
    itself in another goroutine (`a.runCustomSD`):'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段说明了我们需要从我们的代码中调用的适配器的`Run`函数。这个函数将负责在它自己的goroutine中启动`discovery.Manager`（`a.manager.Run`），指示它运行我们的发现实现（`a.disc`），最后在另一个goroutine中运行适配器本身（`a.runCustomSD`）：
- en: '[PRE31]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: After starting, the adapter consumes from a channel provided by the `Manager`
    that updates the target groups that our code will produce. When an update arrives,
    it will convert the target groups into `file_sd` format and verify whether there
    were any changes since the last update. If there are changes, it will store the
    new target groups for future comparisons and write them out as JSON to the output
    file. This implies that the full list of target groups should be sent in every
    update; groups that are not sent through the channel will get removed from the
    produced discovery file.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 启动后，适配器从 `Manager` 提供的通道消费，更新我们的代码将生成的目标组。当有更新时，它将把目标组转换为 `file_sd` 格式，并验证自上次更新以来是否有任何更改。如果有更改，它将保存新的目标组以备将来比较，并将它们以
    JSON 格式写入输出文件。这意味着应该在每次更新中发送完整的目标组列表；没有通过通道发送的组将从生成的发现文件中删除。
- en: The `file_sd` adapter source code can be found at [https://github.com/prometheus/prometheus/blob/v2.9.2/documentation/examples/custom-sd/adapter/adapter.go](https://github.com/prometheus/prometheus/blob/v2.9.2/documentation/examples/custom-sd/adapter/adapter.go).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`file_sd` 适配器源代码可在 [https://github.com/prometheus/prometheus/blob/v2.9.2/documentation/examples/custom-sd/adapter/adapter.go](https://github.com/prometheus/prometheus/blob/v2.9.2/documentation/examples/custom-sd/adapter/adapter.go)
    找到。'
- en: Custom service discovery example
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义服务发现示例
- en: 'Now that we have an idea of how the adapter works, let''s take a look at what
    we need to implement to have our custom service discovery working. As we saw previously,
    the adapter uses a `discovery.Manager`, so we need to provide it with an implementation
    of the `Discoverer` interface so that it can run our discovery. The interface
    looks like this:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了适配器的工作原理，让我们看看我们需要实现哪些内容来使我们的自定义服务发现工作。正如我们之前看到的，适配器使用了 `discovery.Manager`，因此我们需要提供一个
    `Discoverer` 接口的实现，以便它可以运行我们的发现。该接口的样式如下：
- en: '[PRE32]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The `Discoverer` interface documentation can be found at [https://godoc.org/github.com/prometheus/prometheus/discovery#Discoverer](https://godoc.org/github.com/prometheus/prometheus/discovery#Discoverer).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`Discoverer` 接口文档可在 [https://godoc.org/github.com/prometheus/prometheus/discovery#Discoverer](https://godoc.org/github.com/prometheus/prometheus/discovery#Discoverer)
    找到。'
- en: This means that we only need to implement the `Run` function, where we will
    run the logic of our discovery on a loop, generating the appropriate target groups
    and sending them through the `up` channel to the adapter. The `ctx` context is
    there so that we know when we need to stop. The code we implement will then be
    regularly gathering all the available targets/metadata from our data source. In
    this example, we're using Consul, which requires us to get a list of services
    first and then, for each one of them, query which instances are backing it and
    their metadata to generate labels. If something fails, we won't be sending any
    updates via the channel, because it's better to serve stale data than incomplete
    or incorrect data.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们只需要实现 `Run` 函数，在其中我们将在循环中运行我们发现的逻辑，生成适当的目标组，并将它们通过 `up` 通道发送到适配器。`ctx`
    上下文存在是为了让我们知道何时需要停止。我们实现的代码将定期收集来自我们数据源的所有可用目标/元数据。在本例中，我们使用的是 Consul，它要求我们首先获取服务列表，然后针对每个服务查询支持它的实例及其元数据以生成标签。如果发生故障，我们不会通过通道发送任何更新，因为提供过时的数据比提供不完整或不正确的数据更好。
- en: 'Finally, in our `main` function, we just need to instantiate a new adapter,
    and feed it a background context, the name of the output file, the name of our
    discovery implementation, the discovery object that implements the `Discoverer`
    interface, and a `log.Logger` instance:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在我们的 `main` 函数中，我们只需要实例化一个新的适配器，并提供一个后台上下文、输出文件的名称、我们发现实现的名称、实现 `Discoverer`
    接口的发现对象，以及一个 `log.Logger` 实例：
- en: '[PRE33]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The working example of this adapter implementation can be found at [https://github.com/prometheus/prometheus/blob/v2.9.2/documentation/examples/custom-sd/adapter-usage/main.go](https://github.com/prometheus/prometheus/blob/v2.9.2/documentation/examples/custom-sd/adapter-usage/main.go).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 此适配器实现的工作示例可在 [https://github.com/prometheus/prometheus/blob/v2.9.2/documentation/examples/custom-sd/adapter-usage/main.go](https://github.com/prometheus/prometheus/blob/v2.9.2/documentation/examples/custom-sd/adapter-usage/main.go)
    找到。
- en: The next step is to deploy and integrate this newly created service discovery
    provider with Prometheus, so that's what we'll do in the following section.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是部署并集成这个新创建的服务发现提供者与 Prometheus，这是我们将在接下来的部分中完成的。
- en: Using the custom service discovery
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自定义服务发现
- en: To see for ourselves how a custom service discovery behaves, we'll rely on our
    test environment. The `custom-sd` binary, which recreates the Consul discovery
    integration as an example of a custom service discovery, is deployed alongside
    Prometheus and is ready to be used. Together with the Consul deployment, we have
    all the required components in the test environment to see how everything fits
    together.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 为了亲自观察自定义服务发现的表现，我们将依赖于我们的测试环境。`custom-sd` 二进制文件作为自定义服务发现的示例，重新创建了 Consul 服务发现集成，已经与
    Prometheus 一起部署并准备使用。加上 Consul 部署，我们在测试环境中具备了所有必要的组件，可以看到一切如何协同工作。
- en: '`custom-sd` can be built on a machine with a Go development environment set
    up by issuing the following command: `go get github.com/prometheus/prometheus/documentation/examples/custom-sd/adapter-usage`.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`custom-sd` 可以在配置了 Go 开发环境的机器上通过执行以下命令构建：`go get github.com/prometheus/prometheus/documentation/examples/custom-sd/adapter-usage`。'
- en: 'First, we need to ensure that we are connected to the `prometheus` instance.
    We can use the following command:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要确保我们已连接到 `prometheus` 实例。我们可以使用以下命令：
- en: '[PRE34]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We can then proceed to change the Prometheus configuration to use `file_sd`
    as our integration. For this, we must replace the scrape job configured to use
    `consul_sd` with a new one. To make things easier, we placed a configuration file
    with this change already made in `/etc/prometheus/`. To use it, you just need
    to replace the current configuration with the new one:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以修改 Prometheus 配置，使用 `file_sd` 作为我们的集成方式。为此，我们必须将原本配置为使用 `consul_sd`
    的抓取任务替换为新的任务。为了简化操作，我们已经将这个更改写入了 `/etc/prometheus/` 下的配置文件。要使用它，你只需要将当前配置替换为新的配置：
- en: '[PRE35]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The scrape job we are interested in is as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感兴趣的抓取任务如下：
- en: '[PRE36]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'To make Prometheus aware of these changes, we must reload it:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让 Prometheus 知道这些更改，我们必须重新加载它：
- en: '[PRE37]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We should also make sure that the Consul server has the configuration for `consul-exporter`,
    which we added previously. If, by any chance, you missed that step, you may add
    it now by simply running the following code:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该确保 Consul 服务器已配置了我们之前添加的 `consul-exporter`。如果你错过了这一步，可以通过运行以下代码来添加：
- en: '[PRE38]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'If we take a look in the Prometheus web interface, we will see something similar
    to the following:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看 Prometheus 的 Web 界面，我们会看到类似如下的内容：
- en: '![](img/c1006783-1072-469f-9c55-4cea4df74adf.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c1006783-1072-469f-9c55-4cea4df74adf.png)'
- en: '12.14: Prometheus /service-discovery endpoint without any file_sd targets'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 12.14：Prometheus /service-discovery 端点没有任何 file_sd 目标
- en: 'We''re now ready to try out the `custom-sd` application. We''ll need to specify
    the Consul API address and the path to the output file, which the Prometheus server
    is configured to read from. The following command will take care of that, and
    also ensure that the right user is creating the file, so that the Prometheus process
    is able to access it:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始尝试 `custom-sd` 应用程序了。我们需要指定 Consul API 地址和 Prometheus 配置为读取的输出文件路径。以下命令将完成这项工作，并确保正确的用户创建文件，以便
    Prometheus 进程能够访问它：
- en: '[PRE39]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We now have the custom service discovery running. If we go back to the web
    interface of Prometheus in the `/service-discovery` endpoint, we''ll be able to
    see the discovered target:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经启动了自定义服务发现。如果我们返回到 Prometheus 的 Web 界面，并访问 `/service-discovery` 端点，我们将能够看到已发现的目标：
- en: '![](img/63410416-ab64-4dd4-8180-69d269bc10dc.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/63410416-ab64-4dd4-8180-69d269bc10dc.png)'
- en: '12.15: Prometheus /service-discovery endpoint depicting the discovered target'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 12.15：Prometheus /service-discovery 端点显示已发现的目标
- en: 'We can also inspect the file that was created by our `custom-sd`, and validate
    its contents, as follows (the output has been made compact for brevity):'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以检查由 `custom-sd` 创建的文件，并验证其内容，如下所示（输出已被压缩以节省空间）：
- en: '[PRE40]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: And that's it! You now have a custom service discovery up and running, fully
    integrated with Prometheus using the file-based service discovery mechanism. A
    more serious deployment would have the `custom-sd` service running as a daemon.
    If you're more comfortable with a scripting language, you could choose to write
    a service discovery script that produces the discovery file and exits, in which
    case running it as a cron job would be an option. As a last suggestion, you could
    have your configuration management software produce the discovery file dynamically
    on a schedule.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！你现在已经成功搭建了一个自定义服务发现系统，并且与 Prometheus 完全集成，使用基于文件的服务发现机制。更为严谨的部署方式是将 `custom-sd`
    服务作为守护进程运行。如果你更喜欢使用脚本语言，可以选择编写一个生成发现文件并退出的服务发现脚本，在这种情况下，将其作为定时任务运行是一个可行的选择。最后的建议是，你可以让你的配置管理软件按计划动态生成发现文件。
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we had the opportunity to understand why service discovery
    is essential for managing ever-growing infrastructure in a sane way. Prometheus
    leverages several service discovery options out of the box, which can kick-start
    your adoption in a very quick and friendly manner. We went through the available
    options Prometheus provides for service discovery, and showed you what to expect
    from them. We then stepped into a couple of examples using Consul and Kubernetes
    to materialize the concepts we exposed previously. Finally, we went through how
    to integrate a custom service discovery with Prometheus by using the recommended
    approach and relying on `file_sd`.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们有机会了解为什么服务发现对于以合理的方式管理日益增长的基础设施至关重要。Prometheus 提供了几种开箱即用的服务发现选项，这些选项可以帮助你以非常快速和友好的方式开始使用。我们介绍了
    Prometheus 提供的可用服务发现选项，并向你展示了从中可以期待的内容。然后，我们通过使用 Consul 和 Kubernetes 的几个例子，具体化了之前介绍的概念。最后，我们介绍了如何通过使用推荐的方法和依赖
    `file_sd` 将自定义服务发现与 Prometheus 集成。
- en: In the next chapter, we'll go through how to scale and federate Prometheus.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍如何扩展和联邦 Prometheus。
- en: Questions
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Why should you use a service discovery mechanism in Prometheus?
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么在 Prometheus 中使用服务发现机制？
- en: When you're using a cloud provider service discovery, what is the major requirement
    for setting the integration?
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你使用云服务提供商的服务发现时，设置集成的主要要求是什么？
- en: What are the types of records supported by the DNS-based service discovery integration?
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于 DNS 的服务发现集成支持哪些类型的记录？
- en: What purpose does the concept of role serve in the Kubernetes service discovery
    integration?
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 服务发现集成中，角色概念的作用是什么？
- en: When you're building a custom service discovery, what available integration
    will you be relying upon?
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你构建自定义服务发现时，你将依赖哪些可用的集成？
- en: Do you need to reload Prometheus when a target file configured in `file_sd`
    is updated?
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当 `file_sd` 中配置的目标文件更新时，你需要重新加载 Prometheus 吗？
- en: What is the recommended way of building your own custom service discovery?
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建自定义服务发现的推荐方式是什么？
- en: Further reading
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '**Prometheus service discovery configuration**: [https://prometheus.io/docs/prometheus/latest/configuration/configuration](https://prometheus.io/docs/prometheus/latest/configuration/configuration)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus 服务发现配置**：[https://prometheus.io/docs/prometheus/latest/configuration/configuration](https://prometheus.io/docs/prometheus/latest/configuration/configuration)'
