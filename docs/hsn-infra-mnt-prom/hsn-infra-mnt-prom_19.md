# 第十六章：评估

# 第一章，监控基础

1.  对于监控的共识定义很难达成，因为它在行业甚至是特定工作领域的背景下会迅速发生变化。观点的多样性、构成监控系统的组件，甚至数据如何收集或使用，都是导致很难达成清晰定义的因素。

1.  系统管理员关注的是高分辨率、低延迟和高多样性的数据。在这个范围内，监控的主要目标是尽早发现问题，并尽快找出根本原因。

1.  低分辨率、高延迟和高多样性的数据。

1.  这取决于你希望监控定义的范围有多广。在本书的范围内，日志记录不被视为监控。

1.  监控服务的位置需要传播到所有目标。时效性是这种方法的一个大缺点：如果系统一段时间没有报告，是否意味着它有问题，还是被故意停用？此外，当你管理一个分布式的主机和服务集群，数据推送到中央点时，成群涌来的请求（由于大量同时到来的连接导致的超载）或配置错误导致的数据洪流的风险变得更加复杂和耗时，需要缓解。

1.  RED 方法是一个非常好的起点，选择速率、错误和持续时间指标。

1.  这是一种黑箱式的监控方法，应该依赖于直接或通过 exporter 仪表化该过程。

# 第二章，Prometheus 生态系统概述

1.  主要组件包括 Prometheus、Alertmanager、Pushgateway、原生仪表化应用程序、Exporters 和可视化解决方案。

1.  仅 Prometheus 和抓取目标（无论它们是原生仪表化的还是使用 exporters）是 Prometheus 部署所必需的。然而，为了实现警报路由和管理，你还需要 Alertmanager；Pushgateway 仅在某些特定用例中需要，比如批处理作业；虽然 Prometheus 自带基本的仪表盘功能，但可以将 Grafana 添加到堆栈中作为可视化选项。

1.  并非所有应用程序都采用 Prometheus 兼容的仪表化。某些情况下，根本没有暴露任何指标。在这些情况下，我们可以依赖 exporters。

1.  信息应该迅速收集并以同步操作方式暴露。

1.  如果可能，警报将从分区的两侧发送。

1.  最快捷的选项是使用 webhook 集成。

1.  Prometheus 服务器自带表达式浏览器和控制台。

# 第三章，设置测试环境

1.  虽然 Prometheus 堆栈几乎可以在所有主流操作系统中部署，因此它很可能在你的桌面环境中运行，但使用基于 Vagrant 的测试环境来模拟机器部署，以及使用 minikube 来模拟基于 Kubernetes 的生产环境，会更具可重复性。

1.  位于 `utils` 目录下的 `defaults.sh` 文件允许为基于虚拟机的示例更改软件版本。

1.  所有基于虚拟机的示例中的默认子网是 `192.168.42.0/24`。

1.  启动 Prometheus 实例的步骤如下：

    1.  确保软件版本与推荐版本匹配。

    1.  克隆提供的代码仓库。

    1.  进入章节目录。

    1.  运行 `vagrant up`。

    1.  完成后，运行 `vagrant destroy -f`。

1.  该信息可以在 Prometheus Web 界面的 `/targets` 下查看。

1.  位于 `./cache/alerting.log`。

1.  在任何章节中，当你完成测试环境后，只需在该章节的目录下运行 `vagrant destroy -f`。

# 第四章，Prometheus 指标基础

1.  时间序列数据可以定义为按时间顺序从同一来源收集的数值数据点序列——通常是以固定的间隔收集。因此，这种数据在图形化表示时，会描绘数据随时间的演变，其中 *x* 轴是时间，*y* 轴是数据值。

1.  一个时间戳，一个值，以及标签/标签。

1.  **预写日志**（**WAL**）。

1.  默认值是 2 小时，不应更改。

1.  一个 float64 值和具有毫秒精度的时间戳。

1.  直方图对于跟踪分桶的延迟和大小（例如，请求持续时间或响应大小）特别有用，因为它们可以跨不同维度自由聚合。另一个很好的用途是生成热图（直方图随时间的演变）。

    不带分位数的摘要生成、收集和存储的成本非常低。使用摘要分位数的主要原因是在需要准确的分位数估计时，无论观察到的事件的分布和范围如何。

1.  横向聚合通过聚合维度将多个时间序列合并为一个；纵向聚合则将来自单一时间序列的样本在时间范围内合并为一个数据点。

# 第五章，运行 Prometheus 服务器

1.  然后，`scrape_timeout` 将被设置为其默认值——10 秒。

1.  除了重启外，配置文件还可以通过向 Prometheus 进程发送 `SIGHUP` 信号或如果启动时使用了 `--web.enable-lifecycle`，通过向 `/-/reload` 端点发送 HTTP POST 请求来重新加载。

1.  Prometheus 默认会回溯最多五分钟，除非发现过时标记，在这种情况下，它会立即将该系列视为过时。

1.  当 `relabel_configs` 用于在抓取前重写目标列表时，`metric_relabel_configs` 用于在抓取后重写标签或丢弃样本。

1.  由于我们是通过 Kubernetes 服务（其功能类似于负载均衡器）进行抓取的，因此每次抓取仅会命中 *Hey* 应用程序的一个实例。

1.  由于 Kubernetes pod 的短暂性质，几乎不可能在没有额外自动化的情况下使用静态配置准确管理抓取目标。

1.  Prometheus Operator 利用 Kubernetes 自定义资源和自定义控制器声明特定领域的定义，这些定义可以用来自动管理 Prometheus 堆栈及其抓取任务。

# 第六章，导出器和集成

1.  文本文件收集器通过监视目录中的`.prom`扩展名文件，启用自定义指标的展示，这些文件包含 Prometheus 展示格式的指标。

1.  数据是从容器运行时守护进程和 Linux cgroups 中收集的。

1.  你可以限制启用的收集器数量（`--collectors`），或者使用指标白名单（`--metric-whitelist`）或黑名单（`--metric-blacklist`）标志。

1.  在调试探针时，你可以将 `&debug=true` 附加到 HTTP GET URL，以启用调试信息。

1.  我们可以使用 `mtail` 或 `grok_exporter` 从应用程序日志中提取指标。

1.  一个可能的问题是缺乏高可用性，导致其成为单点故障。这也影响了可扩展性，因为唯一的扩展方式是垂直扩展或分片。通过使用 Pushgateway，Prometheus 不直接抓取实例，这避免了将 `up` 指标作为健康监控的代理。此外，和 `node_exporter` 的文本文件收集器类似，指标需要通过 Pushgateway 的 API 手动删除，否则它们将永远暴露给 Prometheus。

1.  在这种特殊情况下，Node Exporter 的文本文件收集器可以是一个有效的解决方案，特别是当生成的指标的生命周期与实例的生命周期匹配时。

# 第七章，Prometheus 查询语言 - PromQL

1.  比较运算符包括 `<`（小于）、`>`（大于）、`==`（等于）、`!=`（不等于）、`=>`（大于或等于）和 `<=`（小于或等于）。

1.  当你想要丰富的时间序列位于 PromQL 表达式的右侧时。

1.  `topk` 已经对结果进行了排序。

1.  虽然 `rate()` 函数通过使用范围内的第一个和最后一个值，并按范围窗口缩放来提供指定时间间隔内每秒的平均变化率，但 `irate()` 函数则使用范围内的最后两个值进行计算，从而得出瞬时变化率。

1.  类型为 info 的指标名称以 `_info` 结尾，是常规的仪表，只有一个可能的值 `1`。这种特殊类型的指标被设计用来存储那些随着时间变化的标签值，例如版本（例如，导出器版本、语言版本和内核版本）、分配的角色或虚拟机元数据等信息。

1.  `rate` 函数期望一个计数器，但计数器的总和实际上是一个仪表，因为当计数器之一重置时，它可以下降；这在绘制图表时会导致看似随机的尖峰，因为 `rate` 会将任何下降视为计数器重置，但其他计数器的总和会被认为是从零到当前值的巨大增量。

1.  当 CPU 核心使用 100%时，它使用 1 个 CPU 秒。相反，当它处于空闲状态时，它将使用 0 个 CPU 秒。通过直接利用 CPU 秒，我们可以轻松计算使用百分比。虚拟机可能拥有多个核心，这意味着每秒可能使用超过 1 个 CPU 秒。以下表达式计算每个核心在过去 5 分钟内每秒空闲了多少 CPU 秒：

```
rate(node_cpu_seconds_total{job="node",mode="idle"}[5m])
```

计算过去五分钟内每个核心每秒的平均 CPU 空闲秒数的简单方法是对每个核心的值进行平均：

```
avg without (cpu, mode) (rate(node_cpu_seconds_total{job="node",mode="idle"}[5m]))
```

由于使用的 CPU 秒数加上空闲的 CPU 秒数应总计为每核心每秒`1`个 CPU 秒，为了获得 CPU 使用率，我们执行以下操作：

```
avg without (cpu, mode) (1 - rate(node_cpu_seconds_total{job="node",mode="idle"}[5m]))
```

为了获得百分比，我们只需将其乘以`100`：

```
avg without (cpu, mode) (1 - rate(node_cpu_seconds_total{job="node",mode="idle"}[5m])) * 100
```

# 第八章，故障排除与验证

1.  Prometheus 随附`promtool`，该工具具有其他功能，其中之一是检查配置文件中的问题：

```
promtool check config /etc/prometheus/prometheus.yml
```

1.  `promtool`工具还可以从`stdin`读取 Prometheus 展示格式的度量，并根据当前的 Prometheus 标准进行验证：

```
curl -s http://prometheus:9090/metrics | promtool check metrics
```

1.  `promtool`工具可以用来对 Prometheus 实例执行即时查询：

```
promtool query instant 'http://prometheus:9090' 'up == 1'
```

1.  你可以使用`promtool`查找给定标签名称的每个标签值。一个例子如下：

```
promtool query labels 'http://prometheus:9090' 'mountpoint'
```

1.  通过将`--log.level=debug`添加到启动参数中。

1.  `/-/healthy`端点将告诉你（或编排系统）实例是否有问题，需要重新部署，而`/-/ready`端点将告诉你（或实例的负载均衡器）是否准备好接收流量。

1.  当 Prometheus 数据库处于解锁状态时（例如，当没有 Prometheus 使用该目录时），你可以运行`tsdb`工具来分析特定的数据块，检查指标和标签的变化：

```
tsdb analyze /var/lib/prometheus/data 01D486GRJTNYJH1RM0F2F4Q9TR
```

# 第九章，定义告警与记录规则

1.  这种规则可以通过预先计算昂贵的查询、将原始数据聚合为时间序列并导出到外部系统，帮助减轻重型仪表板的负担，并协助创建复合范围向量查询。

1.  `instance_job:latency_seconds_bucket:rate30s`需要至少具有`instance`和`job`标签。它是通过对`latency_seconds_bucket_total`度量应用速率计算得出的，使用了 30 秒的范围向量。因此，源表达式可能是以下形式：

```
rate(latency_seconds_bucket_total[30s])
```

1.  随着该标签值的变化，警报的身份也会发生变化。

1.  当警报开始触发（其表达式开始返回结果）时，它进入*待处理*状态，但`for`时间间隔尚未过去，因此不会被视为*触发*。

1.  这将是即时的。当没有指定`for`子句时，只要表达式产生结果，警报就会被视为触发。

1.  `promtool`工具具有一个`test`子命令，可以为记录和告警规则运行单元测试。

# 第十章，发现与创建 Grafana 仪表板

1.  Grafana 支持通过在启动时从配置路径读取 YAML 定义来自动配置数据源。

1.  从 Grafana 画廊导入仪表盘的步骤如下：

    1.  从[grafana.com](https://grafana.com/dashboards)画廊中选择一个仪表盘 ID。

    1.  在目标 Grafana 实例中，点击左侧主菜单中的加号，然后从子菜单中选择**导入**。

    1.  将选定的 ID 粘贴到适当的文本字段中。

1.  变量允许仪表盘配置占位符，这些占位符可以用于表达式和标题字符串，并且这些占位符可以从静态或动态列表中填充值，通常以下拉菜单的形式展示给仪表盘用户。每当选择的值发生变化时，Grafana 会自动更新使用该变量的面板查询和标题字符串。

1.  在 Grafana 中，构建块是面板。

1.  不，实际上不会。仪表盘 ID 保持不变，但迭代次数会递增。

1.  控制台是直接从 Prometheus 实例提供的自定义仪表盘。

1.  它们是从控制台模板生成的，这些模板用原始的 HTML/CSS/JavaScript 编写，并利用 Go 模板语言的强大功能，使得它们具有无限的可定制性。由于模板运行在 Prometheus 内部，它可以直接访问 TSDB，而无需通过 HTTP API，这使得控制台生成速度惊人地快。

# 第十一章，理解和扩展 Alertmanager

1.  在网络分区的情况下，分区的每一方都会发送它们已知的告警通知：在集群故障场景下，收到重复的告警通知总比完全没有告警好。

1.  通过在路由上将`continue`设置为`true`，它会使匹配过程继续遍历路由树，直到找到下一个匹配，从而允许触发多个接收器。

1.  `group_interval`配置定义了在接收到新告警时，等待额外告警加入给定告警组（由`group_by`定义）多长时间，才会发送更新通知；`repeat_interval`定义了在没有变化的情况下，等待多长时间才会重新发送给定告警组的通知。

1.  顶级路由，也称为捕获所有路由或后备路由，在其他子路由未匹配到传入的告警时，会触发默认的接收器。

1.  Webhook 集成允许 Alertmanager 向一个可配置的端点发送 HTTP POST 请求，并带上通知的 JSON 有效负载。这允许你运行一个桥接程序，将 Alertmanager 的通知转换为你选择的通知提供商格式，然后转发给它。

1.  `CommonLabels`字段包含了所有通知中通用的告警标签。`CommonAnnotations`字段的作用完全相同，但适用于注释。

1.  一个好的方法是使用“死人开关”警报：创建一个始终会触发的警报，然后配置 Alertmanager 将该警报路由到一个（希望是）外部系统，该系统将负责通知你该警报是否停止接收通知。

# 第十二章，选择合适的服务发现

1.  在一个高度动态的环境中管理抓取目标，若没有自动发现机制，会变得十分艰巨。

1.  拥有一组具有足够权限的访问凭证，可以通过其 API 列出所有所需资源。

1.  它支持 A、AAAA 和 SRV DNS 记录。

1.  由于可查询的 API 对象数量庞大，Prometheus 的 Kubernetes 发现配置引入了*角色*的概念，角色可以是`node`、`service`、`pod`、`endpoint`或`ingress`。每个角色将提供相应的对象集以供目标发现。

1.  实现自定义服务发现的最佳机制是使用基于文件的发现集成，将目标注入到 Prometheus 中。

1.  不是的。Prometheus 会尝试使用文件系统监视自动检测何时发生变化，然后重新加载目标列表，如果监视不可用，则会回退到定期重新读取目标文件。

1.  推荐使用在 Prometheus 代码库中提供的适配器代码，因为它抽象了实现发现机制所需的大部分样板代码。此外，如果你打算将自定义的服务发现功能贡献给项目，适配器使得将服务发现代码轻松地集成到主 Prometheus 二进制文件中，假如它能够获得广泛支持和社区支持的话。

# 第十三章，Prometheus 的扩展与联邦

1.  当你确认单个实例不足以处理负载，而且无法通过增加资源来运行时，你应该考虑分片。

1.  垂直分片用于根据职责（例如按功能或团队）拆分抓取工作负载，每个 Prometheus 分片抓取不同的任务。水平分片则将单个抓取任务的负载拆分到多个 Prometheus 实例中。

1.  为了减少 Prometheus 实例的接收负载，你应该考虑通过使用`metric_relabel_configs`规则来丢弃不必要的指标，或者通过增加抓取间隔来减少总体抓取样本数量。

1.  实例级的 Prometheus 服务器应该联合作业级的聚合指标。作业级的 Prometheus 服务器应该联合数据中心级的聚合指标。

1.  你可能需要在记录和警报规则中使用其他 Prometheus 实例中才有的指标。

1.  使用的协议是 gRPC。

1.  你将失去使用 Thanos 去重功能的能力。

# 第十四章，Prometheus 与长期存储的集成

1.  将远程写入功能基于 WAL 的主要优点是：它使得指标流式传输成为可能，具有更小的内存占用，并且对崩溃更具恢复力。

1.  你可以通过使用`/api/v1/admin/tsdb/snapshot` API 端点请求 Prometheus 生成 TSDB 快照（仅在启用`--web.enable-admin-api`标志时可用），然后备份该快照。

1.  你可以通过使用`/api/v1/admin/tsdb/delete_series` API 端点从 TSDB 中删除时间序列，然后使用`/api/v1/admin/tsdb/clean_tombstones`来让 Prometheus 清理已删除的序列（这些端点仅在启用`--web.enable-admin-api`标志时可用）。

1.  对象存储通常提供 99.999999999% 的耐久性和 99.99% 的可用性服务水平协议，与块存储相比，它的费用非常低廉。

1.  是的。例如，保留原始数据对于缩放到过去的短时间范围非常有用。

1.  Thanos store 提供了 Thanos Querier 与对象存储之间的 API 网关。

1.  可以使用`thanos bucket`子命令检查对象存储中的数据，该命令还支持验证、修复、列出和检查存储桶。
