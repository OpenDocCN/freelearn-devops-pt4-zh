<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Test Design</h1>
                </header>
            
            <article>
                
<p>Having had a look at the testability framework, the Test Tool, and the standard tests and libraries, I have shown you what is available in the platform and the application that will allow you to create and execute automated tests. And that's what we are going to do in this part of this book. But let's step back and not just bluntly dive into creating code. Firstly, I would like to introduce a couple of concepts and design patterns that will allow you to conceive your tests more effectively and efficiently. At the same time, these concepts will make your tests not just a technical exercise and will help you to get your entire team involved.</p>
<p>I am surely not going to bother you with formal test documentation and the top-down approach with eight defined stages, from test plan, through test design/case specification to test summary report. That's way out of the scope of this book and, not in the least, beyond the daily practices of most Dynamics 365 Business Central implementations. Nevertheless, a couple of thoughts on design spent upfront will give you leverage in your work.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>No design, no test</li>
<li>Test case design patterns</li>
<li>Test data design patterns</li>
<li>Customer wish as test design</li>
</ul>
<div class="packt_infobox">If I have been overloading you with information and you want to get your hands on coding, you might want to jump to the next chapters. There, we will be exercising all of the things discussed so far and later in this chapter. However, if you find out you are missing background details, come back to this chapter and get yourself informed.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">No design, no test</h1>
                </header>
            
            <article>
                
<p class="mce-root"><strong>Goal: Understand why tests should be conceived before they are coded and executed.</strong></p>
<p>I guess I am not far off saying that most of the application testing done in our world falls under the term of exploratory testing. Manual testing is done by experienced resources that know the application under test and have a good understanding and feeling of how to <em>break the thing</em>. But this with no explicit design and no reproducible, shareable, and reusable scripts. Now, in this world, we typically don't want developers to test their own code as they, consciously or unconsciously, know how to use the software and evade issues. Their mindset is <em>how to make it</em> (work), not <em>how to break it</em>.</p>
<p>But with automated tests, it will be developers that will code them. And more often than not, it will be the same developer that did the application coding. So, they need a design of what tests to code. Tests that will cover a broad set of scenarios. Sunny and rainy ones. Headless and UI tests. <span>And what about unit and functional tests?</span></p>
<p>In my humble opinion, the test design, like any other deliverable, is owned by the team. It is a joint effort to agree upon the test design. It's an agreement between the product owner, tester, developer, functional consultant, and key user. And if there is <em>no design</em>, there will be <em>no test</em>. A test design is an object to help the team to discuss their test effort, to reveal the holes in their thoughts, and to let it mature while working on it. And as will be discussed as follows, it is a possible way of putting your requirements down that allows your team to efficiently get from requirements to test and<span> application code</span><span>.</span></p>
<p>A fully-fledged test design would describe the various kinds of tests that should be executed such as performance, application, and security; the conditions under which they must be performed; and the criteria that make them successful. Our test design will only address application tests, as that is the focus of this book: how to create application test automation. Once our test design holds a complete set of test cases, they need to be detailed out and that's what the next section is about.</p>
<div class="packt_infobox">If you want to learn more about formal test documentation, this Wikipedia article could be a first stepping stone: <a href="https://en.wikipedia.org/wiki/Software_test_documentation" target="_blank">https://en.wikipedia.org/wiki/Software_test_documentation</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding test case design patterns</h1>
                </header>
            
            <article>
                
<p class="mce-root"><strong>Goal: Learn the basic patterns for designing tests.</strong></p>
<p>If you have been testing software, you might know that each test has a similar overall structure. Before you can perform the action under test, for example, the posting of a document, first, the data needs to be <em>set up</em>. Then, the action will be <em>exercised</em>. And finally, the result of the action has to be <em>verified</em>. In some cases, a fourth phase applies, a so-called <em>teardown</em>, which is used to revert the system under test to its previous state.</p>
<p>The four phases<strong> </strong>of a test case design pattern are listed as follows:</p>
<ul>
<li>Set up</li>
<li>Exercise</li>
<li>Verify</li>
<li>Teardown</li>
</ul>
<div class="packt_tip">For a short and clear description of the four-phase design pattern, please refer to the following link:<br/>
<a href="http://robots.thoughtbot.com/four-phase-test">http://robots.thoughtbot.com/four-phase-test</a></div>
<p>This design pattern was typically the pattern used by Microsoft in the early years of C/SIDE test coding. Like the following test function example, taken from codeunit 137295 - <kbd>SCM Inventory Misc. III</kbd>, you will encounter it in a vast number of older test codeunits:</p>
<pre>[Test] PstdSalesInvStatisticsWithSalesPrice()<br/>// Verify Amount on Posted Sales Invoice Statistics<br/>//        after posting Sales Order.<br/><br/>// Setup: Create Sales Order, define Sales Price on Customer<br/>Initialize();<br/>CreateSalesOrderWithSalesPriceOnCustomer(SalesLine, WorkDate());<br/>LibraryVariableStorage.Enqueue(SalesLine."Line Amount");<br/>          // Enqueue for SalesInvoiceStatisticsPageHandler.<br/><br/>// Exercise: Post Sales Order.<br/>DocumentNo := PostSalesDocument(SalesLine, true);<br/>          // TRUE for Invoice.<br/><br/>// Verify: Verify Amount on Posted Sales Invoice Statistics.<br/>//         Verification done in SalesInvoiceStatisticsPageHandler<br/>PostedSalesInvoice.OpenView;<br/>PostedSalesInvoice.Filter.SetFilter("No.", DocumentNo);<br/>PostedSalesInvoice.Statistics.Invoke();</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Acceptance Test-Driven Development</h1>
                </header>
            
            <article>
                
<p>Nowadays, Microsoft uses the <strong>Acceptance Test-Driven Development</strong> (<strong>ATDD</strong>)<strong> </strong>design pattern. This is a more complete structure and closer to the customer as tests are described from the user's perspective. The pattern is defined by the following so-called tags:</p>
<ul>
<li><kbd>FEATURE</kbd>: Defines what feature(s) the test or collection of test cases is testing</li>
<li><kbd>SCENARIO</kbd>: Defines for a single test the scenario being tested</li>
<li><kbd>GIVEN</kbd>: Defines what data setup is needed; a test case can have multiple <kbd>GIVEN</kbd> tags when data setup is more complex</li>
<li><kbd>WHEN</kbd>: Defines the action under test; each test case should have only one <kbd>WHEN</kbd> tag</li>
<li><kbd>THEN</kbd>: Defines the result of the action, or more specifically the verification of the result; if multiple results apply, multiple <kbd>THEN</kbd> tags will be needed</li>
</ul>
<p>The following test example, taken from test codeunit 134141 - <kbd>ERM Bank Reconciliation</kbd> displays an ATDD design pattern-based test:</p>
<pre>[Test] VerifyDimSetIDOfCustLedgerEntryAfterPostingBankAccReconLine()<br/>// [FEATURE] [Customer]<br/>// [SCENARIO 169462] "Dimension set ID" of Cust. Ledger Entry<br/>//                   should be equal "Dimension Set ID" of Bank<br/>//                   Acc. Reconciliation Line after posting<br/>Initialize();<br/><br/>// [GIVEN] Posted sales invoice for a customer<br/>CreateAndPostSalesInvoice(<br/>  CustomerNo,CustLedgerEntryNo,StatementAmount);<br/><br/>// [GIVEN] Default dimension for the customer<br/>CreateDefaultDimension(CustomerNo,DATABASE::Customer);<br/><br/>// [GIVEN] Bank Acc. Reconciliation Line with "Dimension Set ID" =<br/>//         "X" and "Account No." = the customer<br/>CreateApplyBankAccReconcilationLine(<br/>  BankAccReconciliation,BankAccReconciliationLine,<br/>  BankAccReconciliationLine."Account Type"::Customer,<br/>  CustomerNo,StatementAmount,LibraryERM.CreateBankAccountNo);<br/>DimSetID :=<br/>  ApplyBankAccReconcilationLine(<br/>    BankAccReconciliationLine,<br/>    CustLedgerEntryNo,<br/>    BankAccReconciliationLine."Account Type"::Customer,<br/>    '');<br/><br/>// [WHEN] Post Bank Acc. Reconcilation Line<br/>LibraryERM.PostBankAccReconciliation(BankAccReconciliation);<br/><br/>// [THEN] "Cust. Ledger Entry"."Dimension Set ID" = "X"<br/>VerifyCustLedgerEntry(<br/>  CustomerNo,BankAccReconciliation."Statement No.", DimSetID);</pre>
<p>Before any test coding is done, the test case design should already have been conceived. In the case of the preceding example, this is what would have been handed off to the developer before writing the test code:</p>
<pre>[FEATURE] [Customer]<br/>[SCENARIO 169462] "Dimension set ID" of Cust. Ledger Entry<br/>                  should be equal "Dimension Set ID" of Bank<br/>                  Acc. Reconcilation Line after posting<br/>[GIVEN] Posted sales invoice for a customer<br/>[GIVEN] Default dimension for the customer<br/>[GIVEN] Bank Acc. Reconcilation Line with "Dimension Set ID" =<br/>        "X" and "Account No." = the customer<br/>[WHEN] Post Bank Acc. Reconcilation Line<br/>[THEN] "Cust. Ledger Entry"."Dimension Set ID" = "X"</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A note on test verification</h1>
                </header>
            
            <article>
                
<p>In my workshops, it is mainly developers that participate. For them, when working on test automation, one of the hurdles to take is the verification part. It makes perfect sense to all of them that data setup, the <kbd>GIVEN</kbd> part, has to be accounted for, not to mention the action under test in the <kbd>WHEN</kbd> part. The <kbd>THEN</kbd> part, however, is something easily neglected, especially if their assignment is to come up with the <kbd>GIVEN</kbd>-<kbd>WHEN</kbd>-<kbd>THEN</kbd> design <span>themselves</span>. Some might ask: why should I need verification if the code executes successfully?</p>
<p>Because you need to check if:</p>
<ul>
<li>The data created is the right data, that is, the expected data</li>
<li>The error thrown, in case of a positive-negative test, is the expected error</li>
<li>The confirm handled is indeed the expected confirm</li>
</ul>
<p>Sufficient verification will make sure your tests will stand the test of time. You might want to put the next phrase as a poster on the wall:</p>
<div class="packt_quote">A test without verification is no test at all!</div>
<p>You may add a bunch of exclamation marks.</p>
<div class="packt_infobox">You might have noticed that the ATDD design pattern has no equivalent of the teardown phase in the four-phase test design patterns. As mentioned, ATDD is user-oriented and the teardown is a more technical exercise. But of course, if needed, a teardown section should be coded at the end of a test.</div>
<div class="mce-root packt_tip">For more information on ATDD you can go to the following links:<br/>
<a href="https://en.wikipedia.org/wiki/Acceptance_test%E2%80%93driven_development">https://en.wikipedia.org/wiki/Acceptance_test%E2%80%93driven_development</a> or <a href="https://docs.microsoft.com/en-us/dynamics365/business-central/dev-itpro/developer/devenv-extension-advanced-example-test#describing-your-tests">https://docs.microsoft.com/en-us/dynamics365/business-central/dev-itpro/developer/devenv-extension-advanced-example-test#describing-your-tests</a>.<a href="https://docs.microsoft.com/en-us/dynamics365/business-central/dev-itpro/developer/devenv-extension-advanced-example-test#describing-your-tests"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding test data setup design patterns</h1>
                </header>
            
            <article>
                
<p class="mce-root"><strong>Goal: Learn the basic patterns for setting up test data.</strong></p>
<p>When you carry out your manual tests, you know that most of the time is consumed by setting up the right data. Being a real IT pro, you will think up ways of doing this as efficiently as possible. You might have thought of making sure of the following:</p>
<ul>
<li><span>A basic setup of data is available, which will be the foundation for all of the tests you are going to execute</span></li>
<li>For each feature under test, additional test data exists upfront</li>
<li>Test specific data will be created on the fly</li>
</ul>
<p>This way you created yourself a number of patterns that help you efficiently get your test data setup done. These are what we call <strong>test data setup</strong> design patterns, or <strong>fixture</strong> or <strong>test fixture</strong> design patterns, and each has its own name:</p>
<ul>
<li>The first one is what we call a <strong>prebuilt fixture</strong>. This is test data that is created before any of the tests are run. In the context of Dynamics 365 Business Central, this will be a prepared database, such as <kbd>CRONUS</kbd>, the demo company that Microsoft provides.</li>
<li>The second pattern is known as <strong>shared fixture</strong>, or lazy setup. This concerns the setup of data shared by a group of tests. In our Dynamics 365 Business Central context, this concerns generic master data, supplemental data, and setup data, such as customer and currency data and a rounding precision, all needed to run a group of tests.</li>
<li>The third and last pattern is <strong>fresh fixture</strong>, or fresh setup. This entails data particularly needed for a single test, such as an empty location, a specific sales price, or a document to be posted.</li>
</ul>
<p>When automating tests, we will make use of these patterns for the following reasons:</p>
<ul>
<li class="mce-root"><strong>Efficient test execution</strong><span>: Even though an automated test seems to run at the speed of light, building up a test collateral over the years will increase the total execution time, which might easily run into hours; the shorter the automated test run will be, the more it will be used</span></li>
<li class="mce-root"><strong>Effective data setup</strong><span>: When designing test cases, it is straight away clear what data will be needed and at what stage; this will speed up the coding of the tests</span></li>
</ul>
<div class="packt_infobox">Read more on fixture patterns here:<br/>
<a href="http://xunitpatterns.com/Fixture%20Setup%20Patterns.html">http://xunitpatterns.com/Fixture Setup Patterns.html</a><br/>
Note that there is much more to formalize in the test data setup. In our test coding in the next chapters, we will utilize a couple more of the patterns mentioned.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Test fixture, data agnostics, and prebuilt fixture</h1>
                </header>
            
            <article>
                
<p>As stated in the introductory chapter, automated tests are <em>reproducible</em>, <em>fast</em>, and <em>objective</em>. They are reproducible in their execution as the code is always the same. But this does not guarantee whether the outcome is reproducible. If each time a test is run, the input to the test, that is, the data setup, is different, then presumably the output of the test will also be different. The following three things help to ensure your tests are reproducible:</p>
<ol>
<li>Make a test run on the same fixture</li>
<li>Make a test follow the same code execution path</li>
<li>Make a test verify the outcome based on the same and sufficient set of criteria</li>
</ol>
<p>To have full control on the fixture, it is highly preferable to let your automated tests create the data they need anew, with each run. In other words, do not rely on the data present in the system before tests are run. Automated tests should be agnostic of any data residing in the system under test. Consequently, running your tests in Dynamics 365 Business Central should not rely on the data present in the database, be it <kbd>CRONUS</kbd>, your own demo data, or customer-specific data. Yes, you might need customer specific data to reproduce a reported issue, but once fixed and the test automation is updated, it should be able to run data agnostically. Because of this, we will not use the prebuilt fixture pattern in any of our tests.</p>
<div class="packt_infobox">If you've ever run the standard tests, you might have noticed that quite a number of them are not data agnostic. They highly rely on the data present in <kbd>CRONUS</kbd>. You might also have noticed that this applies to the older tests. At present, standard tests strive to be data agnostic.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Test fixture and test isolation</h1>
                </header>
            
            <article>
                
<p>To start each set of tests with the same fixture, we will take advantage of the test isolation feature of the test runner codeunit, as discussed in <a href="1e679d13-4037-48e2-b8ae-f550f507f8c9.xhtml" target="_blank">Chapter 2</a>, <em>The Testability Framework</em>, in the <em>Pillar 4 - test runner and test isolation</em> section. Using the test isolation value codeunit of the standard test runner and putting a coherent set of tests in one test codeunit, a generic <em>teardown</em> for the whole test codeunit is set. It will assure that, at the termination of each test codeunit, the fixture is reverted to its initial state. If the test runner utilizes the <em>Function</em> test isolation, it would add a generic teardown to each test function.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Shared fixture implementation</h1>
                </header>
            
            <article>
                
<p>You might have observed in the two Microsoft test functions used as examples for the four-phase and ATDD patterns that each test starts with a call to a function named <kbd>Initialize</kbd>, right after the scenario description. <kbd>Initialize</kbd> contains the standard implementation of the shared fixture pattern (next to a generic fresh fixture pattern we will elaborate on) as follows:</p>
<pre>local Initialize()<br/>// Generic Fresh Setup<br/>LibraryTestInitialize.OnTestInitialize(&lt;codeunit id&gt;);<br/><br/>&lt;generic fresh data initialization&gt;<br/><br/>// Lazy Setup<br/>if isInitialized then<br/>  exit();<br/><br/>LibraryTestInitialize.OnBeforeTestSuiteInitialize(&lt;codeunit id&gt;);<br/><br/>&lt;shared data initialization&gt;<br/><br/>isInitialized := true;<br/>Commit();<br/>LibraryTestInitialize.OnAfterTestSuiteInitialize(&lt;codeunit id&gt;);</pre>
<p class="mce-root"/>
<p>When calling <kbd>Initialize</kbd> at the start of each test function in the same test codeunit, the lazy setup part will just be executed once, since only with the first call to <kbd>Initialize</kbd> will the Boolean variable be <kbd>false</kbd>. Note that <kbd>Initialize</kbd> also incorporates three hooks, that is event publishers, to allow extending <kbd>Initialize</kbd> by linking subscriber functions to it:</p>
<ul>
<li><kbd>OnTestInitialize</kbd></li>
<li><kbd>OnBeforeTestSuiteInitialize</kbd></li>
<li><kbd>OnAfterTestSuiteInitialize</kbd></li>
</ul>
<p>In <a href="1e679d13-4037-48e2-b8ae-f550f507f8c9.xhtml" target="_blank">Chapter 9</a>, <em>Getting Business Central Standard Tests Working on Your Code</em>, we will specifically make use of these publishers.</p>
<div class="packt_infobox">The lazy setup part of <kbd>Initialize</kbd> is what xUnit patterns call SuiteFixture setup.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fresh fixture implementation</h1>
                </header>
            
            <article>
                
<p>A fresh fixture can be (partly) set up in a generic way as per the implementation in the <kbd>Initialize</kbd> function as discussed previously. This is for data that needs to be created or cleaned out at the start of each test. A fresh setup specifically needed for one test only is what is to be found inline in the test function that implements the test, defined by the <kbd>GIVEN</kbd> tags.</p>
<div class="packt_infobox">The generic fresh setup part of <kbd>Initialize</kbd> is what xUnit patterns call Implicit Setup. The test specific fresh setup is called inline setup.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using customer wish as test design</h1>
                </header>
            
            <article>
                
<p class="mce-root"><strong>Goal: Learn why to describe requirements in the form of a test design.<br/></strong></p>
<p class="mce-root">A past ideal of development was a staged one, where each phase would finish before the next started. Just like a waterfall, with water flowing from one level to the other. From requirements gathering to analyses, to design, coding, testing, and finally, operation and maintenance, each phase would have its deadlines, and documented deliverables handed off to the next phase. One of the major drawbacks of this system is its responsiveness to changing insights, resulting in changing requirements. Another is the significant overhead of documents produced. In the recent decade or two, agile methodologies have become a general practice for tackling these drawbacks.</p>
<p class="mce-root">Introducing a test design, an extra document, to your development practice is maybe not what you have been waiting for, even though I can guarantee that your development practices will get leveraged. But what if your test design could be a kind of unified document? Being the input for each discipline in your project? The same truth shared at each level? <em>What if you could kill five birds with one stone</em>? If you could write your requirements in one format as input for all implementation tasks?</p>
<p>It's a common practice to define your requirements as user stories or use cases. But I personally think a major omission of both is that they tend to only define the sunny path and have no explicit description of the rainy scenarios. How should your feature behave under non-typical input? How should it error out? As mentioned before, this is where a tester's mind deviates from a developer's mind: how to make it break versus how to make it work. This would definitely be part of a test design. So, why not promote the test design to become the requirements. Or inside-out: write your requirements like a test design using the ATDD pattern.</p>
<p>This is what we are trying at my main employer now. This is what I am advocating in my workshops and what implementation partners are picking up. Break down each wish and each feature into a list of tests like the following, and make this our primary vehicle of communication:</p>
<ol>
<li>Detailing of your <strong>customer wish</strong></li>
<li>Implementation of your <strong>application code</strong></li>
<li>Structured execution of your <strong>manual tests</strong></li>
<li>Coding of your <strong>test automation</strong></li>
<li>Up-to-date <strong>documentation</strong> of your solution</li>
</ol>
<p>Through this, your test automation will be a logical result of previous work. New insights, resulting in requirement updates, will be reflected in this list and accordingly in your test automation. Whereas your current requirement documentation might not always be in sync with the latest version of the implementation, they will be, when promoting your test design to requirements, as your automated tests will have to reflect the latest version of your app code. In this manner, your test automation is your up-to-date documentation. Killing five birds with one stone, indeed.</p>
<p>As we will be doing in the next chapters, we will specify our requirements as a test design, initially at the feature and scenario level, using the <kbd>FEATURE</kbd> and <kbd>SCENARIO</kbd> tags. Then, this will be followed by a detailed specification using the <kbd>GIVEN</kbd>, <kbd>WHEN</kbd>, and <kbd>THEN</kbd> tags. Have a peek preview of how this looks in the following example, being one scenario for the <kbd>LookupValue</kbd> extensions that we are going to work on in the next chapters:</p>
<pre><strong>[FEATURE]</strong> LookupValue UT Sales Document<br/><strong>[SCENARIO #0006</strong>] Assign lookup value on sales quote document page<br/><strong>[GIVEN]</strong> A lookup value<br/><strong>[GIVEN]</strong> A sales quote document page<br/><strong>[WHEN]</strong> Set lookup value on sales quote document<br/><strong>[THEN]</strong> Sales quote has lookup value code field populate</pre>
<div class="packt_infobox">The full ATDD test design is stored as an Excel sheet <kbd>LookupValue</kbd> on GitHub.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Test automation will profit from a structured approach and, for this, we introduced a set of concepts and test patterns, such as the ATDD pattern and test fixture patterns.</p>
<p>Now, in the next chapter, <a href="56634efe-664c-421a-9582-b2a6ae69722a.xhtml" target="_blank"/><a href="56634efe-664c-421a-9582-b2a6ae69722a.xhtml" target="_blank">Chapter 5</a>, <em>From Customer Wish to Test Automation – The Basics</em>, we will utilize these patterns to finally implement test code.</p>


            </article>

            
        </section>
    </body></html>