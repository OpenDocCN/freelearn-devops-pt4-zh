<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer088">
			<h1 id="_idParaDest-162"><a id="_idTextAnchor166"/>Chapter 6: Understanding CI/CD and the SDLC</h1>
			<p>The <strong class="bold">software development life cycle</strong> (<strong class="bold">SDLC</strong>) section of the exam is the heaviest weighted of all the sections. Understanding the concept of SDLC, as well as <strong class="bold">continuous integration</strong> (<strong class="bold">CI</strong>) and <strong class="bold">continuous deployment</strong> (<strong class="bold">CD</strong>), is paramount for passing the <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>) <strong class="bold">development-operations</strong> (<strong class="bold">DevOps</strong>) exam. There are multiple stages in the SDLC, and there are specific AWS and third-party services that map to these stages. </p>
			<p>Knowing the role that the AWS services play—along with key third-party tools—is also essential, not only to pass the exam but also to know for your day-to-day duties as a DevOps engineer. </p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Introduction to the SDLC</li>
				<li>Development teams</li>
				<li>Understanding the different types of deployments</li>
			</ul>
			<h1 id="_idParaDest-163"><a id="_idTextAnchor167"/>Introduction to the SDLC</h1>
			<p>The SDLC<a id="_idIndexMarker589"/> consists of the following six basic cycles or stages:</p>
			<ul>
				<li>Source</li>
				<li>Build</li>
				<li>Test</li>
				<li>Deploy (for release)</li>
				<li>Monitor</li>
				<li>Plan</li>
			</ul>
			<p>These stages are depicted in the following diagram:</p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="Images/Figure_6.1_B17405.jpg" alt="Figure 6.1 – Phases of CI/CD &#13;&#10;" width="774" height="117"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.1 – Phases of CI/CD </p>
			<p>The first four of these stages fall on the development side of DevOps. The fifth falls on the operations side, and the final stage is done as a team exercise. You may notice in the preceding diagram that the planning phase is absent. Once again, this is a <a id="_idIndexMarker590"/>phase that, although a vital part of the SDLC, is not part of either the CI or CD process. </p>
			<p>One of the initial things we need to understand in the context of this session is the use of the acronym <em class="italic">CI/CD</em>. As we think about the CI stage, we are talking about the first three steps of the pipeline. </p>
			<h2 id="_idParaDest-164"><a id="_idTextAnchor168"/>CI</h2>
			<p>CI is a <a id="_idIndexMarker591"/>software<a id="_idIndexMarker592"/> development practice through which developers regularly merge their code changes into a central repository. After this, one or more automated builds are initiated, and tests are run against both the code that was committed and the previously existing code base. </p>
			<h3>AWS native tools for CI</h3>
			<p>Next, we <a id="_idIndexMarker593"/>will look at some of the tools that AWS offers within its ecosystem to help with CI. </p>
			<h4>AWS CodeCommit </h4>
			<p><strong class="bold">AWS CodeCommit</strong> allows<a id="_idIndexMarker594"/> you<a id="_idIndexMarker595"/> to host private source control repositories in a highly scalable fashion.</p>
			<p>These are the main benefits of CodeCommit:</p>
			<ul>
				<li><strong class="bold">Ability to collaborate</strong>: Software <a id="_idIndexMarker596"/>teams can work together on a code base using known Git functions such as pull requests, branches, and merging. </li>
				<li><strong class="bold">Encryption</strong>: CodeCommit <a id="_idIndexMarker597"/>repositories are automatically <a id="_idIndexMarker598"/>encrypted at<a id="_idIndexMarker599"/> rest using AWS <strong class="bold">Key Management Service</strong> (<strong class="bold">KMS</strong>). Code transfers to and from the repository are also encrypted via either <strong class="bold">HyperText Transfer Protocol Secure</strong> (<strong class="bold">HTTPS</strong>) or <strong class="bold">Secure Shell</strong> (<strong class="bold">SSH</strong>). </li>
				<li><strong class="bold">Access control</strong>: Being fully<a id="_idIndexMarker600"/> integrated with the AWS <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) service allows you to specify which users have access to which repositories, without having to navigate through a third-party system. </li>
				<li><strong class="bold">High availability</strong>: AWS <a id="_idIndexMarker601"/>CodeCommit <a id="_idIndexMarker602"/>is backed by <strong class="bold">Amazon Simple Storage Service</strong> (<strong class="bold">Amazon S3</strong>) and <strong class="bold">Amazon DynamoDB</strong> for code-and-commit storage. This is a highly redundant and scalable setup to ensure that your repositories are accessible. </li>
				<li><strong class="bold">Notifications</strong>: CodeCommit <a id="_idIndexMarker603"/>can be integrated with <strong class="bold">Amazon Simple Notification Service</strong> (<strong class="bold">Amazon SNS</strong>) so that events significant to the repository can be broadcast to the correct channels. Notifications sent by CodeCommit include a status <a id="_idIndexMarker604"/>message and a link to the corresponding repository. </li>
			</ul>
			<h4>AWS CodeBuild </h4>
			<p>As you <a id="_idIndexMarker605"/>look to compile <a id="_idIndexMarker606"/>the code you have committed in your source control repository and create software packages for deployment, <strong class="bold">AWS CodeBuild</strong> allows<a id="_idIndexMarker607"/> teams to customize their build-and-test process using the <strong class="bold">YAML Ain't Markup Language</strong> (<strong class="bold">YAML</strong>) language. </p>
			<p>These are the main benefits of AWS CodeBuild:</p>
			<ul>
				<li><strong class="bold">Fully managed</strong>: With<a id="_idIndexMarker608"/> CodeBuild, there is no need to set up a separate build server. This means that there are no more software patches or updates, and nothing to manage. Jobs are set up and submitted, and then run. </li>
				<li><strong class="bold">Secure</strong>: CodeBuild is integrated with the IAM service and, hence, users can be assigned to specific build projects only. Any artifacts that CodeBuild produces are encrypted with AWS KMS.</li>
				<li><strong class="bold">Scalable</strong>: CodeBuild scales automatically according to the number of jobs that have been submitted at any one time. There is no need to think about vertical or horizontal scaling when a big burst of build jobs or tests is about to happen, as CodeBuild handles all this automatically.</li>
				<li><strong class="bold">Enables CI and CD</strong>: As part of the <strong class="bold">AWS Developer</strong> services, CodeBuild naturally<a id="_idIndexMarker609"/> integrates<a id="_idIndexMarker610"/> into other CI/CD tools offered, such as <strong class="bold">CodeCommit</strong> and <strong class="bold">CodePipeline</strong>. Integration has also been done with other tools in the ecosystem—<strong class="bold">Jenkins</strong>, for example, has the ability to use CodeBuild as a scalable worker node. </li>
			</ul>
			<h4>AWS CodeArtifact </h4>
			<p>As <a id="_idIndexMarker611"/>software <a id="_idIndexMarker612"/>builds get more regimented, companies and teams start to look for a way to ensure that everyone is using the same approved packages and versions of packages. This is where the managed artifact repository <strong class="bold">CodeArtifact</strong> comes into play.</p>
			<p>If you are interested in the security of your build process, then CodeArtifact offers a number of features that help your development teams create a safer environment. Firstly, packages and artifacts needed in the build process can be accessed <a id="_idIndexMarker613"/>from a <strong class="bold">virtual private cloud</strong> (<strong class="bold">VPC</strong>) using AWS PrivateLink endpoints. This means that if you have the necessary libraries and items needed for the build stored on your CodeArtifact service, then these files can be transferred to your functions and instances without a need to traverse the public internet.</p>
			<p>Secondly, with the CodeArtifact service, you as an account administrator have the ability to approve packages for use. This approval process can also be automated using <a id="_idIndexMarker614"/>a combination of the CodeArtifact <strong class="bold">application programming interfaces</strong> (<strong class="bold">APIs</strong>) and the Amazon EventBridge service. </p>
			<p>Thirdly, many package repositories have recently been placing download limits on their servers. Having a deployment or build fail due to the fact that the repository is not currently <a id="_idIndexMarker615"/>taking download requests from the current <strong class="bold">Internet Protocol</strong> (<strong class="bold">IP</strong>) address is not only frustrating—it can also become a real impediment for deployment. For example, if you are building <a id="_idIndexMarker616"/>your instances in real time versus <a id="_idIndexMarker617"/>having pre-built <strong class="bold">Amazon Machine Images</strong> (<strong class="bold">AMIs</strong>) and you have the need for certain node packages from public <strong class="bold">Node Package Manager</strong> (<strong class="bold">npm</strong>) servers, then if you are in an autoscaling state and are trying to scale to meet the traffic demands of your customers, this can become more than just a nuisance. However, if you have your packages stored on AWS CodeArtifact, then you are not limited by any third-party servers and can build your functions and instances, pulling down the required packag<a id="_idTextAnchor169"/>es as many times as required, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="Images/Figure_6.2_B17405.jpg" alt="Figure 6.2 – AWS CodeArtifact with connection to external repositories&#13;&#10;" width="1627" height="1062"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.2 – AWS CodeArtifact with connection to external repositories</p>
			<p>You can <a id="_idIndexMarker618"/>configure <a id="_idIndexMarker619"/>CodeArtifact to go out to public repositories and fetch popular packages for storage and versioning for your teams. CodeArtifact can work with package managers many developers are both familiar and comfortable with, including <strong class="source-inline">pip</strong>, <strong class="source-inline">yarn</strong>, <strong class="source-inline">npm</strong>, <strong class="source-inline">Maven</strong>, and <strong class="source-inline">Gradle</strong>. </p>
			<p>These are the main benefits of CodeArtifact:</p>
			<ul>
				<li><strong class="bold">Store and share artifacts securely</strong>: If integrated with the KMS service, the <a id="_idIndexMarker620"/>artifacts you store in CodeArtifact can be encrypted. </li>
				<li><strong class="bold">Reduce operational overhead</strong>: CodeArtifact quashes the need for the setup and maintenance of an artifact server. It is a highly available service that scales automatically to the number of artifacts stored.</li>
				<li><strong class="bold">Publish and share packages</strong>: CodeArtifact allows you a central place to publish the packages your team creates, eliminating the need to hunt around on the internet.</li>
				<li><strong class="bold">Consume packages from public repositories</strong>: CodeArtifact can be set up to <a id="_idIndexMarker621"/>automatically download packages from public repositories such as the <strong class="source-inline">npm</strong> registry, <strong class="source-inline">NuGet.org</strong>, and <strong class="bold">Maven Central</strong> with a couple of clicks instead of complex scripting.</li>
			</ul>
			<h2 id="_idParaDest-165"><a id="_idTextAnchor170"/>Continuous delivery</h2>
			<p>If the <a id="_idIndexMarker622"/>deployment <a id="_idIndexMarker623"/>to production occurs with continuous delivery, there will most likely be a manual approval process rather than an automated deployment. </p>
			<h3>AWS native tools for continuous delivery </h3>
			<p>Let's take <a id="_idIndexMarker624"/>a brief look at some of the AWS tools used in continuous delivery.</p>
			<h4>AWS CodeDeploy</h4>
			<p>These <a id="_idIndexMarker625"/>are the main <a id="_idIndexMarker626"/>benefits of CodeDeploy:</p>
			<ul>
				<li><strong class="bold">Automated deployments</strong>: CodeDeploy<a id="_idIndexMarker627"/> totally automates software deployments.</li>
				<li><strong class="bold">Ease of adoption</strong>: CodeDeploy can easily be integrated into your existing deployment tooling, such as Jenkins, GitHub, or AWS CodePipeline. </li>
				<li><strong class="bold">Consolidated control</strong>: In one view, CodeDeploy can both show you the status of your deployment and provide the ability to send push notifications to one or multiple members of your team, letting them know the pass or fail status of builds. </li>
				<li><strong class="bold">Minimize downtime</strong>: In allowing you to introduce your changes incrementally, CodeDeploy helps preserve the availability of your application. It<a id="_idIndexMarker628"/> can also help the process of rolling back to a previous version should an issue be discovered. </li>
			</ul>
			<h4>AWS CodePipeline </h4>
			<p>AWS <a id="_idIndexMarker629"/>CodePipeline <a id="_idIndexMarker630"/>allows you to automate the building, testing, and deploying steps and phases that you go through while you produce your <a id="_idIndexMarker631"/>software and <strong class="bold">Infrastructure as Code</strong> (<strong class="bold">IaC</strong>). It can be integrated with third-party services such as GitHub. </p>
			<p>These are the main benefits of CodePipeline:</p>
			<ul>
				<li><strong class="bold">Rapid delivery</strong>: CodePipeline provides quick feedback to you and your team as you<a id="_idIndexMarker632"/> move your code through a structured process to deployment. Flaws can be found and fixed without too much effort. </li>
				<li><strong class="bold">Easy to integrate</strong>: If you have existing pieces already in use for your CI/CD process, then CodePipeline allows you to incorporate those items without any hassle. This can include a Jenkins server that is already set up to run tests running in the cloud or on-premises or even a third-party source code repository such as GitHub.</li>
				<li><strong class="bold">Configurable workflow</strong>: Each software release has a slightly different process depending on the tests configured or the service that it is being deployed. CodePipeline provides you the ability to customize your steps in a variety <a id="_idIndexMarker633"/>of ways, including <a id="_idIndexMarker634"/>with the <strong class="bold">AWS Management Console</strong> interface, using<a id="_idIndexMarker635"/> the <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>) or one of the available AWS <strong class="bold">software development kits</strong> (<strong class="bold">SDKs</strong>), or even <a id="_idIndexMarker636"/>by crafting your pipeline in a <strong class="bold">CloudFormation template</strong>.</li>
				<li><strong class="bold">Improved quality</strong>: CodePipeline allows you to automate all your processes in an easy-to-follow flow so that steps are not missed when doing a<a id="_idIndexMarker637"/> deployment. Having tests run automatically allows for consistency in your code and provides developers with instant feedback. </li>
			</ul>
			<h2 id="_idParaDest-166"><a id="_idTextAnchor171"/>CD</h2>
			<p>With CD, there <a id="_idIndexMarker638"/>is no manual approval process<a id="_idIndexMarker639"/> as the code revisions are pushed into the production environment. Instead, testing practices and guidelines are relied on in order to ensure the integrity of code meets quality checks before being automatically deployed to the production environment. Any revisions that don't meet these guidelines then get failed as a build process, and feedback is given to either the individual developer or the development team. This initial feedback can be simple in nature, such as<a id="_idIndexMarker640"/> a notification that a build has failed, and can be in the form of an email or a <strong class="bold">Short Message Service</strong> (<strong class="bold">SMS</strong>) message that could be sent using the <strong class="bold">SNS service</strong>. An alternative to this could even be posted to a messaging service such as <strong class="bold">Slack</strong> or <strong class="bold">Microsoft Teams</strong>, using a combination of SNS and <strong class="bold">AWS Lambda</strong> to post the message.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Continuous delivery is <em class="italic">not</em> CD. This is a common mistake that many make. You need to understand, however, that with continuous delivery every commit that passes a set of automated tests is then pushed into the production environment. </p>
			<p>Let's take a look at how the SDLC translates into the different developer tools provided by AWS. You can see from the following diagram that almost every stage has its own dedicated service. The exceptions are the build and test stages, where AWS CodeBuild can perform both of these tasks: </p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="Images/Figure_6.3_B17405.jpg" alt="Figure 6.3 – AWS tools used in CI/CD &#13;&#10;" width="789" height="361"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.3 – AWS tools used in CI/CD </p>
			<p>As we look at CI <a id="_idIndexMarker641"/>and continuous delivery from an <strong class="bold">Amazon code tools</strong> point of view, there are several tools that can help you achieve these tasks. </p>
			<h2 id="_idParaDest-167"><a id="_idTextAnchor172"/>Testing</h2>
			<p>Testing plays<a id="_idIndexMarker642"/> a vital role in the SDLC. It can help you improve the reliability, scalability, performance, and security of your application. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">Did you notice how many of the things that testing provides are pillars of AWS? Although it may seem faster to leave testing out of your initial pipeline design, it's a vital part of ensuring the stability, safety, and capabilities of your workload. </p>
			<p>If you have potential weaknesses in your code, testing is one of the ways that you can discover many of them. This can prevent you from deploying a fatal flaw into your production environment. As you automate this process as a DevOps engineer, the initial outlay to build the pipelines can be a bit of an effort. Once the pipeline and tests have been established, then multiple types of code—including both <a id="_idIndexMarker643"/>IaC and application code—can be both tested and deployed in a rapid and repeatable fashion. </p>
			<h3>Types of affiliated tests </h3>
			<p>There <a id="_idIndexMarker644"/>are a variety <a id="_idIndexMarker645"/>of different types of tests available to ensure that your code base is functioning as it should. Each type of test performs a specific task, and some take more time to run than others. Here's a diagram showing the different testing stages:</p>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="Images/Figure_6.4_B17405.jpg" alt="Figure 6.4 – Different stages of testing&#13;&#10;" width="364" height="241"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.4 – Different stages of testing</p>
			<p>Looking at the stages in <em class="italic">Figure 6.4</em>, we can see the relative speed at which tests can be performed. We can now examine each of the testing types in more detail. </p>
			<h3>Unit tests</h3>
			<p><strong class="bold">Unit tests</strong> are <a id="_idIndexMarker646"/>small<a id="_idIndexMarker647"/> in the amount of code they span but provide developers instant feedback, especially since they can be run directly from a developer's individual machine. They can be added to a CI/CD pipeline, where they can be used to proactively prevent any known defects from entering into the code base.</p>
			<h3>Service integration and component tests </h3>
			<p><strong class="bold">Integration tests</strong> are <a id="_idIndexMarker648"/>used <a id="_idIndexMarker649"/>to<a id="_idIndexMarker650"/> check <a id="_idIndexMarker651"/>that all the different components in a system work together. These tests can also include tests of any third-party services or APIs. Examples of integration tests would be having the web layer insert a test value into a database to ensure connectivity or send a notification after an event. </p>
			<h3>Performance and compliance tests </h3>
			<p>Once<a id="_idIndexMarker652"/> you<a id="_idIndexMarker653"/> have<a id="_idIndexMarker654"/> built<a id="_idIndexMarker655"/> your application, you need to know that it will handle your estimated traffic effectively. This includes scaling out and in with your resources as need be and checking the system while it is under sizable load. <strong class="bold">Performance tests</strong> will help accomplish this task, exposing a lack of performance or bottlenecks that the system might display under normal usage or high usage. Two of the most popular types of performance tests are <strong class="bold">stress</strong> tests and <strong class="bold">soak</strong> tests. A stress test will simulate many users on the resources for a small duration of time or for a set number of routines, such as playing back web server logs to emulate past users. A soak test, on the other hand, gives a steady stream of users over a much longer period of time such as a week or more, trying to expose items such as memory leaks or bad routines that don't show up under short durations. </p>
			<p>Adding <a id="_idIndexMarker656"/>security and compliance tests <a id="_idIndexMarker657"/>such as <strong class="bold">static application security testing</strong> (<strong class="bold">SAST</strong>) and <strong class="bold">dynamic application security testing</strong> (<strong class="bold">DAST</strong>) allows<a id="_idIndexMarker658"/> known vulnerabilities that have been reported and discovered to be <a id="_idIndexMarker659"/>exposed. Adding<a id="_idIndexMarker660"/> these<a id="_idIndexMarker661"/> types <a id="_idIndexMarker662"/>of tests to your CI/CD pipeline is part of the <strong class="bold">development-security-operations</strong> (<strong class="bold">DevSecOps</strong>) umbrella. </p>
			<h3>User interface tests </h3>
			<p>At the<a id="_idIndexMarker663"/> top<a id="_idIndexMarker664"/> of the pyramid are <strong class="bold">user interface</strong> (<strong class="bold">UI</strong>) tests. These tests are not just testing the <strong class="bold">graphical UI</strong> (<strong class="bold">GUI</strong>), but the system as a whole. Tests can encompass routines such as ensuring users can log in correctly or reset a password. They may contain activities such as uploading and downloading files or visiting specific pages that touch datastores and middleware components. </p>
			<p>Although manual testing may be introduced out of necessity during this stage, it's better to keep manual tests to a minimum. </p>
			<h2 id="_idParaDest-168"><a id="_idTextAnchor173"/>Maturing throughout the process </h2>
			<p>When initially<a id="_idIndexMarker665"/> starting to build your CI system, you may only have a few steps, such as pulling code from a source code repository and deploying to a test server. </p>
			<p>As time goes on, the code base will gain a greater amount of test coverage and settings will be tuned so that team members will have much more confidence in the deployment process, so much so that they come to rely on it as just another day-to-day tool. </p>
			<p>As you mature, you<a id="_idIndexMarker666"/> will find that you are starting to gain the following benefits:</p>
			<ul>
				<li><strong class="bold">Speed</strong>: Teams become much more self-sufficient with automated pipelines and release processes. There is no more waiting for a particular person or team to install developed software packages or updates.</li>
				<li><strong class="bold">Reliability</strong>: Automating your process eliminates dependency on a single person who knows the process. Any team member who starts the process will feel confident that it will run the same each and every time it is invoked. </li>
				<li><strong class="bold">Consistency</strong>: Creating a pipeline with standard steps for your deployments makes for a consistent process each time a process is initiated. This prevents any steps such as testing from being forgotten or skipped. </li>
				<li><strong class="bold">Scalability</strong>: The frequency of updates can—and usually does—increase as your organization begins to scale. Automated pipelines that have steps to build, test, and deploy out to different environments help you scale without adding additional staff. </li>
				<li><strong class="bold">Efficiency</strong>: Moving your testing from a manual to an automated process allows you to not only speed up the testing process but also allows the testing team<a id="_idIndexMarker667"/> to concentrate on developing new and improved tests versus spending their time manually testing the system. </li>
			</ul>
			<p>Now that we have looked at the actual SDLC process, we will now look at optimizing the setup of teams for the CI/CD process. </p>
			<h1 id="_idParaDest-169"><a id="_idTextAnchor174"/>Development teams </h1>
			<p>It's a<a id="_idIndexMarker668"/> recommendation from AWS to have three development teams for implementing a CI/CD environment: <strong class="bold">an application team</strong>, <strong class="bold">an infrastructure team</strong>, and <strong class="bold">a tools team</strong>. Amazon preaches the concept of two-pizza teams, meaning that no team should be larger than could be fed by two pizzas. Smaller teams lead to better collaboration, have full ownership of their features or application, have full accountability, and—last but not least—this all aligns with the DevOps model of agility. </p>
			<h2 id="_idParaDest-170"><a id="_idTextAnchor175"/>The application team</h2>
			<p><strong class="bold">Application team</strong> members <a id="_idIndexMarker669"/>are the ones<a id="_idIndexMarker670"/> responsible for creating an application itself. Members of this team are skilled in one or more programming languages, but also have (or come to have) a deep understanding of the platform and system configuration. </p>
			<p>Application team members have responsibility for creating a backlog of items that need to be worked on, as well as creating a task for working on stories. In addition to having the programming skills to create and maintain an application, this team should also become skilled in automation to allow members to create their own pieces of the pipeline once the tooling has been created. </p>
			<h2 id="_idParaDest-171"><a id="_idTextAnchor176"/>The infrastructure team </h2>
			<p>In order <a id="_idIndexMarker671"/>for<a id="_idIndexMarker672"/> the application team members to run their applications, they need some infrastructure to run them on. Even if an application is of a serverless nature, it still needs to have permissions created in IAM. If it's not a serverless setup, then there are servers to provision and manage. </p>
			<p>With the <strong class="bold">infrastructure team</strong>, this is done via IaC either via CloudFormation, using scripts with the<a id="_idIndexMarker673"/> AWS CLI, or with the AWS <strong class="bold">Cloud Development Kit</strong> (<strong class="bold">CDK</strong>). </p>
			<p>Many times, this <a id="_idIndexMarker674"/>team<a id="_idIndexMarker675"/> will also be responsible for things such as <strong class="bold">Active Directory (AD) servers</strong> and <strong class="bold">single sign-on (SSO) integration</strong>, especially because they are tightly coupled with the IAM permissions. </p>
			<h2 id="_idParaDest-172"><a id="_idTextAnchor177"/>The tools team</h2>
			<p>The <strong class="bold">tools team</strong> both<a id="_idIndexMarker676"/> builds and manages the CI/CD <a id="_idIndexMarker677"/>pipeline. This team must be proficient in building and integrating all of the different pieces and components of the pipeline so that the dependent application teams have a smooth process. Although the tools team is not part of the two-pizza team, it is responsible for creating tooling and systems that enable the other teams to perform their jobs. </p>
			<p>The team may choose to implement tools and services such as AWS CodeCommit, CodePipeline, CodeBuild, and CodeDeploy, along with other third-party tools such as Jenkins, GitHub, Bitbucket, Artifactory, and other related tools. </p>
			<p>Many organizations will classify the tools team as the DevOps team, but this is a misnomer as DevOps is more of a practice of people and processes versus the use of tools. </p>
			<p>Not every tools team is ready to make a complete buy-in to the AWS toolset, and AWS understands this. There is even an entire whitepaper around the automation <a id="_idIndexMarker678"/>server Jenkins. Having an understanding of how third-party tools interact and complement the AWS ecosystem is essential knowledge for the DevOps professional exam.</p>
			<p>With our team members now having areas they can concentrate on to maximize their effectiveness, we will move on to the types of deployments and see how to choose a deployment strategy that best fits our needs. </p>
			<h1 id="_idParaDest-173"><a id="_idTextAnchor178"/>Understanding the different types of deployments</h1>
			<p>When you<a id="_idIndexMarker679"/> think about deployments, especially as we have been talking about the SDLC, you may think we are talking about application code. However, as you move to automate more and more of your systems in AWS, deployments can take on multiple meanings. Deployments can mean application code, but they could also mean infrastructure code, configuration code, or other layers. </p>
			<p>There are five main types of deployment strategies to consider when dealing with deployments on AWS. Each method has its own advantages and disadvantages. </p>
			<p>When choosing a deployment strategy, these are the main things you need to consider:</p>
			<ul>
				<li>How quickly can you deploy?</li>
				<li>Are<a id="_idIndexMarker680"/> any <strong class="bold">Domain Name System</strong> (<strong class="bold">DNS</strong>) changes needed?</li>
				<li>Would there be any impact with a failed deployment?</li>
				<li>What<a id="_idIndexMarker681"/> would the rollback process be?</li>
				<li>Where would the code be linked to? (New or existing instances?)</li>
			</ul>
			<p>With this in mind, let's look at the five different deployment strategies in depth.</p>
			<h2 id="_idParaDest-174"><a id="_idTextAnchor179"/>In-place deployments </h2>
			<p>When you <a id="_idIndexMarker682"/>perform an <strong class="bold">in-place deployment</strong>, you are<a id="_idIndexMarker683"/> updating instances that have already been deployed to an environment. A load balancer can be used to deregister each instance while doing the deployment, perform a health check, and then place the healthy instance back into service. In-place deployments can be done all at once or they can be done as a rolling deployment. </p>
			<p>Let's take<a id="_idIndexMarker684"/> a look at <a id="_idIndexMarker685"/>the pros and cons of in-place deployments, as follows: </p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="Images/012.jpg" alt="Table 6.1 – In-place deployment pros and cons&#13;&#10;" width="1524" height="445"/>
				</div>
			</div>
			<p class="figure-caption">Table 6.1 – In-place deployment pros and cons</p>
			<h2 id="_idParaDest-175"><a id="_idTextAnchor180"/>Immutable and blue-green deployments </h2>
			<p>In the <a id="_idIndexMarker686"/>case of <strong class="bold">blue-green deployments</strong>, a<a id="_idIndexMarker687"/> whole new set of infrastructure is created and often tested before doing a DNS switch to the new environment. This is the safest type of deployment method, but it takes time and is also the costliest since you are bringing up two full environments for a period of time until you do the DNS switchover. You then have an option to take down the secondary environment once it is not being used at that moment to save on costs, or you can keep it running in the background to save on deployment time and use it as a failover environment. In the case of a deployment failure, your customers would never even know, since when using blue-green deployments you only switch the DNS once your second (or green) environment is up and healthy. </p>
			<p><strong class="bold">Immutable deployments</strong> refer to deploying code for a whole new set of resources using new configurations or new application code. This task is made much simpler in the cloud versus on-premises hardware as resources can be provisioned using simple API calls.</p>
			<p>The following table<a id="_idIndexMarker688"/> shows both <a id="_idIndexMarker689"/>the <a id="_idIndexMarker690"/>pros and cons of immutable deployments:</p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="Images/02.jpg" alt="Table 6.2 – Blue-green deployment pros and cons &#13;&#10;" width="1524" height="405"/>
				</div>
			</div>
			<p class="figure-caption">Table 6.2 – Blue-green deployment pros and cons </p>
			<p>See <a href="B17405_13_Final_JM_ePub.xhtml#_idTextAnchor338"><em class="italic">Chapter 13</em></a>, <em class="italic">Blue Green Deployments</em>, for a much deeper look at blue-green deployments.</p>
			<h2 id="_idParaDest-176"><a id="_idTextAnchor181"/>Canary deployments</h2>
			<p>A <strong class="bold">canary deployment</strong> is a<a id="_idIndexMarker691"/> type of blue-green<a id="_idIndexMarker692"/> deployment strategy where a predetermined number of instances are initially upgraded with either the updated application code or operating system updates. At that point, a portion of the traffic is then shifted—for example, 20% of the traffic or customers with a certain cookie who have been chosen for the canary deployment. This initial traffic is then watched over a period of time to see if any issues arise. If the deployment has no major issues, the rest of the instance or application fleet is then upgraded. At that point, all of the traffic has been shifted to the new application or operating system upgrades. If there do seem to be any issues with the initial deployment, then the traffic can easily be routed back to the instances that do not have the upgrades, either by setting the routing policy in Route 53 to <strong class="source-inline">0</strong>% on the new instance <strong class="bold">Canonical Names</strong> (<strong class="bold">CNAMEs</strong>) or by taking the new instances out of the load balancer. At that point, the new instances are taken down out of service, and any launch configurations that were previously updated can be updated to use a previous version of a working AMI. </p>
			<p>In the<a id="_idIndexMarker693"/> following<a id="_idIndexMarker694"/> table, we compare the pros and cons of using a canary deployment method: </p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="Images/03.jpg" alt="Table 6.3 – Canary deployment pros and cons&#13;&#10;" width="1650" height="688"/>
				</div>
			</div>
			<p class="figure-caption">Table 6.3 – Canary deployment pros and cons</p>
			<h2 id="_idParaDest-177"><a id="_idTextAnchor182"/>Rolling deployments </h2>
			<p>When<a id="_idIndexMarker695"/> using a <strong class="bold">rolling deployment</strong>, not <a id="_idIndexMarker696"/>all of the instances are updated at the same time. This strategy prevents any downtime since if a process fails, only a portion of the group is upgraded at any one particular time. As the initial instances are sent to the deployments, they must come back both healthy and online before further instances will be engaged in the new deployment. </p>
			<p>It's important to note that since not all members of the group are deployed at the same time with either the application code or system upgrades, then there could be multiple versions running for a user to experience. Using sticky sessions can help, but not eliminate, trying to provide a seamless experience to a customer during a single session while deployment is happening. </p>
			<p>Although it's not a long list of pros and cons, take a look at the following table to see the <a id="_idIndexMarker697"/>benefits <a id="_idIndexMarker698"/>and drawbacks of using a rolling deployment method: </p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="Images/04.jpg" alt="Table 6.4 – Rolling deployment pros and cons &#13;&#10;" width="1494" height="231"/>
				</div>
			</div>
			<p class="figure-caption">Table 6.4 – Rolling deployment pros and cons </p>
			<h2 id="_idParaDest-178"><a id="_idTextAnchor183"/>Linear deployments </h2>
			<p>In a linear <a id="_idIndexMarker699"/>deployment, traffic is shifted <a id="_idIndexMarker700"/>equally in increments across resources over a set number of predefined increments. A linear deployment is a subset of the blue-green deployment type. Instead of deploying to the instances or resources that your application is currently running on, you are first standing up a new set of infrastructure and then over time shifting your traffic from the old code base to a new one, using a service such as <strong class="bold">Route 53</strong> and weighted routing. This way, you can keep a close eye on your new environment, and if any issues arise then you can quickly shift all traffic back to the original environment, with no downtime. </p>
			<p>Linear deployments can also be done with Lambda aliases and Fargate containers in order to shift a percentage of your traffic to a new version of your code. </p>
			<p>For example, if your deployment window is 1 hour and you want to spread 100% of your traffic in equal increments to new resources in that hour, then your linear strategy may go something like this:</p>
			<ul>
				<li>Minimum 0-16% of traffic shifted over to the new resources </li>
				<li>Minimum 10-32% of traffic shifted over to the new resources </li>
				<li>Minimum 20-48% of traffic shifted over to the new resources</li>
				<li>Minimum 30-64% of traffic shifted over to the new resources </li>
				<li>Minimum 40-80% of traffic shifted over to the new resources </li>
				<li>Minimum 50-96% of traffic shifted over to the new resources </li>
				<li>Minimum 60-100% of traffic<a id="_idIndexMarker701"/> shifted over to the new resources </li>
			</ul>
			<p>There are <a id="_idIndexMarker702"/>both <a id="_idIndexMarker703"/>pros and cons to using a linear deployment method, so let's compare them here:</p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="Images/05.jpg" alt="Table 6.5 – Linear deployment pros and cons &#13;&#10;" width="1650" height="542"/>
				</div>
			</div>
			<p class="figure-caption">Table 6.5 – Linear deployment pros and cons </p>
			<p>We will be<a id="_idIndexMarker704"/> covering Lambda in depth in <a href="B17405_12_Final_JM_ePub.xhtml#_idTextAnchor307"><em class="italic">Chapter 12</em></a>, <em class="italic">Lambda Deployments and Versioning. </em></p>
			<h2 id="_idParaDest-179"><a id="_idTextAnchor184"/>All-at-once deployments</h2>
			<p>In this <a id="_idIndexMarker705"/>type of deployment, all the traffic<a id="_idIndexMarker706"/> is shifted from the original environment to a new environment at the same time. This is the fastest of all deployment methods. This also means that any rollbacks that need to happen would also take the most amount of time, as the code would need to be redeployed to all instances. You <em class="italic">can have downtime</em> with this type of deployment if yo<a id="_idIndexMarker707"/>u have an issue as you wait for your rollback to come back online. </p>
			<p>The advantages and disadvantages of using an <em class="italic">all-at-once deployment method</em> are outlined <a id="_idIndexMarker708"/>in the<a id="_idIndexMarker709"/> following table: </p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="Images/06.jpg" alt="Table 6.6 – All-at-once deployment pros and cons&#13;&#10;" width="1540" height="401"/>
				</div>
			</div>
			<p class="figure-caption">Table 6.6 – All-at-once deployment pros and cons</p>
			<p class="callout-heading">Note</p>
			<p class="callout">An all-at-once deployment can also be called an in-place deployment. Be familiar with both <a id="_idIndexMarker710"/>terms as either can show up on test questions. </p>
			<h1 id="_idParaDest-180"><a id="_idTextAnchor185"/>Review questions</h1>
			<ol>
				<li>A medium-sized software company has hired you as a DevOps consultant to help set up its deployment pipeline. The staff want to be able to push their tested code into their production environment in a quick manner but do not want the possibility of dealing with downtime for their customers. Their DNS is hosted on a third-party service, and changes to the DNS would require a change ticket. Which deployment method would you recommend implementing?<p>a. Blue-green deployment</p><p>b. In-place deployment </p><p>c. All-at-once deployment</p><p>d. Rolling deployment </p></li>
				<li>A medical device company is looking to set up its development pipeline using Jenkins to deploy its code base in an automated fashion. Since this is only the development environment, they want to keep costs to a minimum and would be fine if the application team needed to redeploy in case of a failed deployment. Which strategy should they use?<p>a. Blue-green deployment </p><p>b. In-place deployment </p><p>c. All-at-once deployment </p><p>d. Rolling deployment </p></li>
				<li>A mobile gaming company is trying to speed up its production time with all the new enhancements it has been developing for its most popular game. Staff have noticed on social media that around the dates of the last two releases, users complained of an increased number of glitches. Some of the glitches reported were known issues to teams that were working on the development of the game. The gaming company already has an automated deployment pipeline set up with AWS CodePipeline, and its code is stored in AWS CodeCommit. What is the most cost-effective way to reduce the number of glitches being deployed in each release?<p>a. Spin up a new environment and run full UI tests before releasing the code to the production environment.</p><p>b. Add a step in the current CodePipeline to spin up an EC2 instance that runs the Jenkins software and can use <strong class="bold">Simple Systems Manager</strong> (<strong class="bold">SSM</strong>) <strong class="bold">Parameter Store</strong> to download the current CodeCommit repository, after which it runs unit tests to pass or fail the build.</p><p>c. Add a CodeDeploy step to the current AWS pipeline that runs the current set of unit tests connected to an AWS SNS topic so that on failure, the current build is failed and the development team is notified.</p><p>d. Add a CodeBuild step to the current AWS pipeline that runs the current set of unit tests connected to an AWS SNS topic so that on failure, the current build is failed and the development team is notified.</p></li>
				<li>A research company is working on a confidential project and the management team wants to be aware of any progress made as soon as it happens. The developers are using AWS CodeCommit for their source code versioning, along with CodeBuild to run unit tests. Which measures can you put in place to allow the management team to get the updates they desire? (Choose all that apply) <p>a. Create an SNS topic for the management team and add all their emails. </p><p>b. Have AWS CodeCommit push notifications to an SNS topic any time that either a commit has been made or a feature branch has been merged with the master.</p><p>c. Have CodeCommit create a daily report of commit activity and then push the report to S3 so that the management team can view it from a bucket to which they have access. </p><p>d. Enable notifications on AWS CodeBuild to an SNS topic for when a job passes or fails.</p></li>
				<li>A growing company currently has a Jenkins server that runs on EC2. Developers are complaining that they are waiting too long for their builds to get started and complete. You have been asked to help the tools team in coming up with a solution that can scale with the growth and speed of the development team but can also be implemented in the quickest and most cost-effective manner possible. Which solution will least need to be managed by the tools team? <p>a. Create an AMI from the Jenkins server and use the AMI to create three additional worker nodes, using the current Jenkins system as the master. </p><p>b. Rebuild the Jenkins server as a containerized system using <strong class="bold">Elastic Kubernetes Service</strong> (<strong class="bold">EKS</strong>) Fargate and worker-node plugins to scale as needed.</p><p>c. Integrate AWS CodeBuild into Jenkins to allow for automatic worker-node creation once the queue gets over a level of <strong class="source-inline">1</strong>. </p><p>d. Create an AMI from the Jenkins server and use the AMI to create a launch configuration for an autoscaling group that will launch a new Jenkins instance when the queue gets over a level of <strong class="source-inline">1</strong>. </p></li>
			</ol>
			<h1 id="_idParaDest-181"><a id="_idTextAnchor186"/>Review answers</h1>
			<ol>
				<li value="1">d</li>
				<li>b</li>
				<li>d</li>
				<li>a, b, d </li>
				<li>c</li>
			</ol>
			<h1 id="_idParaDest-182"><a id="_idTextAnchor187"/>Summary</h1>
			<p>In this chapter, we looked at the <strong class="bold">SDLC</strong>, <strong class="bold">CI</strong>, <strong class="bold">continuous delivery</strong>, and <strong class="bold">CD</strong>. We also started to look at the tools AWS offers that can help us with these different stages of the SDLC. Then, we took a look at the different types of teams and what their job responsibilities consist of. Finally, we reviewed the different types of deployment strategies available in AWS and how they can best be used. </p>
			<p>In the next chapter, we will be taking a deeper dive into AWS's CloudFormation IaC service. We will see how to create reusable resources, along with the scripting methods available in CloudFormation templates. </p>
		</div>
	</div></body></html>