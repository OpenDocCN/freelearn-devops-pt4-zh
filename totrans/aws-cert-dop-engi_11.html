<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer143">
			<h1 id="_idParaDest-231"><a id="_idTextAnchor237"/>Chapter 9: Deploying Workloads with CodeDeploy and CodePipeline</h1>
			<p>Teams are looking for an easy-to-use tool that allows the automation of the release process and gives a consistent release process. We will look at incorporating <strong class="bold">CodePipeline</strong> and the third-party tool Jenkins to automate our deployments' release cycle, which can then integrate into <strong class="bold">CodeDeploy</strong> for the actual code deployments. </p>
			<p>In this chapter, we're going to cover the following main topics:  </p>
			<ul>
				<li>About AWS CodePipeline</li>
				<li>Setting up a code pipeline</li>
				<li>Using Jenkins to build your workloads</li>
				<li>About AWS CodeDeploy</li>
				<li>Use cases for AWS CodeDeploy</li>
			</ul>
			<h1 id="_idParaDest-232"><a id="_idTextAnchor238"/>Technical requirements</h1>
			<p>If you plan to follow along with the exercises in this chapter, there are some dependencies in the previous chapter, <a href="B17405_08_Final_JM_ePub.xhtml#_idTextAnchor212"><em class="italic">Chapter 8</em></a>, <em class="italic">Creating Workloads with CodeCommit and CodeBuild</em>. Just as in the real world, we are building on what we have previously started in earlier chapters. Hence, if you have not created a developer user from the previous chapter, you will need to do so with the corresponding <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) permissions in their group. </p>
			<h1 id="_idParaDest-233"><a id="_idTextAnchor239"/>About AWS CodePipeline</h1>
			<p>AWS CodePipeline can be thought of as a conductor in an orchestra. Using either code or the AWS console, you can put together your software development life cycle process in a visual representation that is either fully automated or has manual checks along the way for certain <a id="_idIndexMarker839"/>stages to be passed. This whole process is then laid out visually for your team members (including developers, testers, and others) to see which deployments happened and which deployments failed. </p>
			<p>AWS CodePipeline helps you automate the steps you require to release your software and infrastructure changes in a continuous manner, as illustrated in the following diagram: </p>
			<div>
				<div id="_idContainer127" class="IMG---Figure">
					<img src="Images/Figure_9.1_B17405.jpg" alt="Figure 9.1 – CodePipeline and its integration with other AWS developer tools  &#13;&#10;" width="729" height="269"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.1 – CodePipeline and its integration with other AWS developer tools  </p>
			<p>The different AWS developer services, which CodePipeline is one of, are depicted in <em class="italic">Figure 9.1</em> and shown <a id="_idIndexMarker840"/>underneath their respected stages in the <strong class="bold">Systems Development Life Cycle</strong> (<strong class="bold">SDLC</strong>). </p>
			<h2 id="_idParaDest-234"><a id="_idTextAnchor240"/>CodePipeline structure for actions</h2>
			<p>CodePipeline <a id="_idIndexMarker841"/>is structured into several different categories that allow either native AWS services to act or allow a supported third-party service to be integrated and perform the necessary action. </p>
			<p>There are six valid action categories, as listed here:</p>
			<ul>
				<li>Source </li>
				<li>Build </li>
				<li>Test</li>
				<li>Deploy</li>
				<li>Approval</li>
				<li>Invoke</li>
			</ul>
			<p>Each of the <a id="_idIndexMarker842"/>action categories has its own set of providers that can invoke actions or have actions invoked from that resource, as outlined in the following table: </p>
			<div>
				<div id="_idContainer128" class="IMG---Figure">
					<img src="Images/014.jpg" alt="Table 9.1 – CodePipeline source actions and action providers&#13;&#10;" width="1100" height="1363"/>
				</div>
			</div>
			<p class="figure-caption">Table 9.1 – CodePipeline source actions and action providers</p>
			<p>In addition <a id="_idIndexMarker843"/>to the action integrations, a few other AWS services integrate without any specific action category, as follows: </p>
			<ul>
				<li><strong class="bold">Amazon CloudWatch</strong>: CloudWatch can monitor your resources that are built with <a id="_idIndexMarker844"/>the pipeline or are being tested and integrated into the pipeline. </li>
				<li><strong class="bold">Amazon CloudWatch Events</strong>: CloudWatch Events can detect changes to your <a id="_idIndexMarker845"/>pipeline as a whole or even at certain stages of your pipeline. CloudWatch Events can even listen to other outside services and then trigger a CodePipeline run if specific scenarios happen, such as if someone updated a CloudFormation stack. This would then create a need for the software to be redeployed.  </li>
				<li><strong class="bold">AWS Cloud9</strong>: Cloud9 is <a id="_idIndexMarker846"/>the cloud-based <strong class="bold">integrated development environment</strong> (<strong class="bold">IDE</strong>) that is <a id="_idIndexMarker847"/>accessible via a web browser. </li>
				<li><strong class="bold">AWS CloudTrail</strong>: If the <a id="_idIndexMarker848"/>CloudTrail service is active for the <a id="_idIndexMarker849"/>particular region, any <strong class="bold">application programming interface</strong> (<strong class="bold">API</strong>) actions <a id="_idIndexMarker850"/>that happen <a id="_idIndexMarker851"/>via the AWS console, <strong class="bold">software development kits</strong> (<strong class="bold">SDKs</strong>), or <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>) are captured and recorded.</li>
				<li><strong class="bold">AWS KMS</strong>: <strong class="bold">Key Management Service</strong> (<strong class="bold">KMS</strong>) can be integrated with AWS CodePipeline <a id="_idIndexMarker852"/>for source S3 buckets and artifacts, which either are encrypted or need to be encrypted. Suppose the artifacts are <a id="_idIndexMarker853"/>coming from an account other than the one where the CodePipeline is being executed. In that case, the key that is encrypting the bucket and objects will need to be a customer-managed key. </li>
			</ul>
			<p>Looking at <em class="italic">Table 9.1</em>, you can see that there is a combination of both native AWS services and specialized third-party partner tools that you may already be using to integrate into your code pipeline stages. </p>
			<p>We have just looked at the different actions along with their corresponding AWS services and third-party services that can help perform those actions. Next, we will look at some of the use cases for AWS CodePipeline, including real-world use cases. </p>
			<h2 id="_idParaDest-235"><a id="_idTextAnchor241"/>Use cases for AWS CodePipeline</h2>
			<p>When thinking <a id="_idIndexMarker854"/>about what you can do with CodePipeline, there are specific scenarios that have already identified that CodePipeline is an optimal fit as a tool. Let's take a look at some of these next.</p>
			<h3>Automation of your build and release process</h3>
			<p>CodePipeline allows your developers to concentrate on the code they are working on and then <a id="_idIndexMarker855"/>commit that code to <a id="_idIndexMarker856"/>either an Amazon-hosted repository or a third-party repository such as GitHub or Bitbucket Cloud. The push of a new code commit by a developer can then trigger the build process. </p>
			<h3>Creating a consistent toolset for developers to use </h3>
			<p>One of the most challenging parts of getting a new developer up and productive quickly in an <a id="_idIndexMarker857"/>organization is the onboarding process. CodePipeline helps with this process by presenting a consistent toolset no matter which time zone a team member is in or the operating system that they are using. </p>
			<h3>Using CodePipeline to integrate with third-party providers</h3>
			<p>Suppose your team currently uses third-party tools such as Jenkins for the code build or testing <a id="_idIndexMarker858"/>process, BlazeMeter for the load testing process, or StormRunner for the testing process. In that case, CodePipeline can help present a unified orchestration front for all of these tools. </p>
			<p>There can also be a cost-savings aspect in using only one service account called from the CodePipeline service rather than each individual or individual team requesting their own license. </p>
			<h3>Continuously deploy your web applications with Elastic Beanstalk and CodePipeline</h3>
			<p>Although Elastic Beanstalk is many times looked upon as a service which helps developers who minimal exposure to AWS infrastructure items to get their code up and running quickly, those items of code can become successful items in an organization. The incorporation of CodePipeline allows to take the reliance away from the Elastic Beanstalk CLI or try to track down deployments in the AWS Management Console and allow for a more structured and trackable approach. </p>
			<p>Now that we have examined a few of the various use cases where CodePipeline can be used successfully, we can now go on to our hands-on example. This is where we will go through the steps of setting up our own AWS CodePipeline that utilizes a CodeCommit repository. </p>
			<h1 id="_idParaDest-236"><a id="_idTextAnchor242"/>Setting up a code pipeline</h1>
			<p>One of the best ways to get a feel for AWS CodePipeline is to go through the exercise of setting <a id="_idIndexMarker859"/>up a code pipeline. Many times, it will be those designated tools' team members who will set up the pipelines. These <strong class="bold">tools</strong> team members have a unique set of permissions that differ from that of developers. </p>
			<p>We will need to set up our tools team group and assign them the correct permission set. After this, we can create a tools team member and associate them with the tools team IAM group. Then, we can log in as that tools team member and have them build out the pipeline.  </p>
			<h2 id="_idParaDest-237"><a id="_idTextAnchor243"/>Creating our code base prior to setting up the pipeline</h2>
			<p>We are going to set up a brand new CodeCommit repository before setting up our code pipeline. Creating <a id="_idIndexMarker860"/>the repository beforehand will allow us to have a fresh set of code to use to run through the steps of our pipeline. </p>
			<p>In the <strong class="source-inline">chapter9</strong> section of our GitHub repository, there will be a folder named <strong class="source-inline">code</strong>. This folder will hold the source code that we will need to upload to the CodeCommit repository we are about to create using the following steps: </p>
			<ol>
				<li>Open your browser to the AWS CodeCommit home page, <a href="https://console.aws.amazon.com/codesuite/codecommit/home">https://console.aws.amazon.com/codesuite/codecommit/home</a>, and sign in if prompted. </li>
				<li>Click the orange <strong class="bold">Create repository</strong> button on the top right-hand side of the screen. </li>
				<li>On the <strong class="bold">Create repository</strong> screen, under <strong class="bold">Repository settings</strong>, use <strong class="source-inline">chapt9</strong> for the name of the repository. We will add a description that this repository is for <strong class="source-inline">CodePipeline</strong> to distinguish it from the <strong class="source-inline">chapt8</strong> repository, which we created as a test in the previous chapter, <a href="B17405_08_Final_JM_ePub.xhtml#_idTextAnchor212"><em class="italic">Chapter 8</em></a>, <em class="italic">Creating Workloads with CodeCommit and CodeBuild</em>, as illustrated in the following screenshot: <div id="_idContainer129" class="IMG---Figure"><img src="Images/Figure_9.2_B17405.jpg" alt="Figure 9.2 – CodeCommit repository settings for chapt9 repository &#13;&#10;" width="627" height="499"/></div><p class="figure-caption">Figure 9.2 – CodeCommit repository settings for chapt9 repository </p></li>
				<li>Click the orange <strong class="bold">Create</strong> button. </li>
				<li>Since we <a id="_idIndexMarker861"/>have already created a user that can upload files in <a href="B17405_08_Final_JM_ePub.xhtml#_idTextAnchor212"><em class="italic">Chapter 8</em></a>, <em class="italic">Creating Workloads with CodeCommit and CodeBuild</em>, simply click on the <strong class="bold">Repositories</strong> menu item in the left-hand menu, as illustrated in the following screenshot. This will bring up the names of all the repositories that we have in CodeCommit and will allow us to copy the link we need to clone the repository locally to our workstation: <div id="_idContainer130" class="IMG---Figure"><img src="Images/Figure_9.3_B17405.jpg" alt="Figure 9.3 – The side menu on CodeCommit with Repositories highlighted&#13;&#10;" width="245" height="157"/></div><p class="figure-caption">Figure 9.3 – The side menu on CodeCommit with Repositories highlighted</p></li>
				<li>Now, click on the link labeled <strong class="source-inline">SSH</strong>, to the right of the <strong class="source-inline">chapt9</strong> repository, as illustrated in the following screenshot. This will pop up a small dialog box confirming that the link has been copied and you are ready to clone the repository to your local workstation:<div id="_idContainer131" class="IMG---Figure"><img src="Images/Figure_9.4_B17405.jpg" alt="Figure 9.4 – SSH cloning Uniform Resource Locator (URL) copied to clipboard&#13;&#10;" width="338" height="162"/></div><p class="figure-caption">Figure 9.4 – SSH cloning Uniform Resource Locator (URL) copied to clipboard</p><p>At this point, we are done with the AWS console for the moment, and we will move on for the next set of commands to the terminal on your local workstation. </p></li>
				<li>Now, with <a id="_idIndexMarker862"/>your terminal open, go to the root of your home directory. In Linux, you can get there quickly with the <strong class="source-inline">$cd ~</strong> command. Next, perform the following command to clone the repository locally. Now, we can use the URL on our clipboard to clone into the repository:<p class="source-code"><strong class="bold">$ git clone ssh://git-codecommit.us-east-2.amazonaws.com/v1/repos/chapt9</strong></p><p>Once you have successfully cloned into the repository, then you should get a confirmation message stating that you have cloned into an empty repository. </p></li>
				<li>Even though we have an empty repository, we are going to take the example code from the GitHub repository in the <strong class="source-inline">/code</strong> directory and then copy (or move it if you don't want two copies of the code on your local machine) to this new local <strong class="source-inline">CodeCommit</strong> repository so that we can push it up to <strong class="source-inline">CodeCommit</strong>. <p>Make sure that you are starting from the directory where you have cloned the example code from GitHub, as illustrated in the following code snippet:</p><p class="source-code"><strong class="bold">$ cp -R * ~/chapt9/</strong></p><p>If you don't want to copy the files via the command line you could also use either File Explorer or Finder to make a copy of the files into your new git repository.</p></li>
				<li>Now that we have copied the files over to the <strong class="source-inline">CodeCommit</strong> local directory, we need to add all of them to the commit. After adding them and the <strong class="source-inline">commit</strong> message, we will push the files up to the repository. We can do all of this in just a few simple commands. First, we will need to change directories from where we cloned the example code to our local <strong class="source-inline">CodeCommit</strong> repository, as follows:<p class="source-code"><strong class="bold">$ cd ~/chapt9</strong></p></li>
				<li>Since we <a id="_idIndexMarker863"/>are in our local directory, we can now add all of the files and then push them up to the remote <strong class="source-inline">CodeCommit</strong> repository. We do this by using the <strong class="source-inline">git add</strong>, <strong class="source-inline">git commit</strong>, and <strong class="source-inline">git push</strong> commands, like this:<p class="source-code"><strong class="bold">$ git add * </strong></p><p class="source-code"><strong class="bold">$ git commit -m "adding sample code to CodeCommit"</strong></p><p class="source-code"><strong class="bold">[master (root-commit) f85e8f2] adding sample code to CodeCommit</strong></p><p class="source-code"><strong class="bold"> 2 files changed, 52 insertions(+)</strong></p><p class="source-code"><strong class="bold"> create mode 100644 buildspec.yml</strong></p><p class="source-code"><strong class="bold"> create mode 100644 src/app.py</strong></p><p class="source-code"><strong class="bold">$ git push </strong></p><p class="source-code"><strong class="bold">Enumerating objects: 5, done.</strong></p><p class="source-code"><strong class="bold">Counting objects: 100% (5/5), done.</strong></p><p class="source-code"><strong class="bold">Delta compression using up to 8 threads</strong></p><p class="source-code"><strong class="bold">Compressing objects: 100% (4/4), done.</strong></p><p class="source-code"><strong class="bold">Writing objects: 100% (5/5), 825 bytes | 825.00 KiB/s, done.</strong></p><p class="source-code"><strong class="bold">Total 5 (delta 0), reused 0 (delta 0), pack-reused 0</strong></p><p class="source-code"><strong class="bold">To ssh://git-codecommit.us-east-2.amazonaws.com/v1/repos/chapt9</strong></p><p class="source-code"><strong class="bold"> * [new branch]      master -&gt; master</strong></p></li>
			</ol>
			<p>Now, with our sample code ready, we are prepared to move on to the next step, which is creating our tools team member. Our tools team member is the person on our team who focuses <a id="_idIndexMarker864"/>on creating and managing the pipelines and processes more than the code itself.  </p>
			<h2 id="_idParaDest-238"><a id="_idTextAnchor244"/>Creating our tools team member </h2>
			<p>Just as we had previously created our development group and member, we will need to do the <a id="_idIndexMarker865"/>same thing for our tools team member. It is important to separate the duties of our team members and give each person only the privileges they need to perform their job duties. After creating our tools member, we will then log in as that tools teams member and then run the CloudFormation template named <strong class="source-inline">pipeline1.yml</strong> as this tools team member to construct the pipeline. </p>
			<p>Let's go ahead and set up the group for our tools team member, as follows: </p>
			<ol>
				<li value="1">Open up your terminal and type the following commands so that we can create our new group: <p class="source-code"><strong class="bold">$aws iam create-group --group-name Tools</strong></p><p>After running the command, you should see a confirmation like the one shown next:</p><p class="source-code"><strong class="bold">{</strong></p><p class="source-code"><strong class="bold">    "Group": {</strong></p><p class="source-code"><strong class="bold">        "Path": "/",</strong></p><p class="source-code"><strong class="bold">        "GroupName": "tools",</strong></p><p class="source-code"><strong class="bold">        "GroupId": "AGPAW24Q7QQFSHYZHE6N6",</strong></p><p class="source-code"><strong class="bold">        "Arn": "arn:aws:iam::470066103307:group/tools",</strong></p><p class="source-code"><strong class="bold">        "CreateDate": "2021-05-14T01:25:58+00:00"</strong></p><p class="source-code"><strong class="bold">    }</strong></p><p class="source-code"><strong class="bold">}</strong></p><p>Take note of the ARN which is returned for the group name. You will either need to save this to a note pad or scroll up to copy and paste this when we attach the policy which we create next to this group</p></li>
				<li>Next, we will need to create our policy using the pre-made policy document that you should have downloaded from the GitHub repository in the <strong class="source-inline">Chapter9</strong> folder named <strong class="source-inline">IAM_Tools.json</strong>, as follows:<p class="source-code"><strong class="bold">aws iam create-policy --policy-name Tools_Members --policy-document file://IAM_Tools.json</strong></p><p>This should <a id="_idIndexMarker866"/>return the <strong class="bold">Amazon Resource Name</strong> (<strong class="bold">ARN</strong>) of <a id="_idIndexMarker867"/>our policy in our success <strong class="source-inline">JSON</strong> after creation, as in the following statement:</p><p class="source-code"><strong class="bold">{</strong></p><p class="source-code"><strong class="bold">    "Policy": {</strong></p><p class="source-code"><strong class="bold">        "PolicyName": "Tools_Members",</strong></p><p class="source-code"><strong class="bold">        "PolicyId": "ANPAW24Q7QQF6FPOCHV5V",</strong></p><p class="source-code"><strong class="bold">        "Arn": "arn:aws:iam::470066103307:policy/Tools_Members",</strong></p><p class="source-code"><strong class="bold">        "Path": "/",</strong></p><p class="source-code"><strong class="bold">        "DefaultVersionId": "v1",</strong></p><p class="source-code"><strong class="bold">        "AttachmentCount": 0,</strong></p><p class="source-code"><strong class="bold">        "PermissionsBoundaryUsageCount": 0,</strong></p><p class="source-code"><strong class="bold">        "IsAttachable": true,</strong></p><p class="source-code"><strong class="bold">        "CreateDate": "2021-05-16T19:32:41+00:00",</strong></p><p class="source-code"><strong class="bold">        "UpdateDate": "2021-05-16T19:32:41+00:00"</strong></p><p class="source-code"><strong class="bold">    }</strong></p><p class="source-code"><strong class="bold">}</strong></p></li>
				<li>After creating our policy, we will then attach our policy to our group, like this:<p class="source-code"><strong class="bold">aws iam attach-group-policy \</strong></p><p>In the <strong class="source-inline">policy-arn</strong> field use the value which was returned to you in step 1:</p><p class="source-code"><strong class="bold">  --policy-arn arn:aws:iam::470066103307:policy/Tools_Members \</strong></p><p class="source-code"><strong class="bold">  --group-name tools</strong></p><p>If the policy attachment is successful, then there will be no confirmation message. </p></li>
				<li>Now that we have created our <strong class="source-inline">tools</strong> group, we can create a user to be part of the tools team. This tools team member will be the user that we will use to create the actual code pipeline. Let's go ahead and make our new user, as follows: <p class="source-code"><strong class="bold">aws iam create-user --user-name peter </strong></p></li>
				<li>Now, we <a id="_idIndexMarker868"/>can take our new user and add them to the <strong class="source-inline">tools</strong> group so that they have the group permissions, as follows:<p class="source-code"><strong class="bold">aws iam add-user-to-group --user-name peter --group-name Tools</strong></p></li>
				<li>And just like the developer user we created in <a href="B17405_08_Final_JM_ePub.xhtml#_idTextAnchor212"><em class="italic">Chapter 8</em></a>, <em class="italic">Creating Workloads with CodeCommit and CodeBuild</em>, we will need to set an initial password that the tools user will need to reset on the first login, as follows:<p class="source-code"><strong class="bold">aws iam create-login-profile --user-name peter --password Dev0psPRO --password-reset-required</strong></p></li>
			</ol>
			<p>At this point, we have created our tools user and are ready to log in to the AWS console as the tools user and build out our AWS pipeline. </p>
			<h2 id="_idParaDest-239"><a id="_idTextAnchor245"/>Creating a pipeline</h2>
			<p>With our tools user (Peter, in our case) created, we will make a context switch from using the <a id="_idIndexMarker869"/>AWS CLI to the browser and the management console and act as if we were performing these acts as the tools user. Before we start, you need to be sure to download the <strong class="source-inline">pipeline1.yml</strong> file from the <strong class="source-inline">Chapter9</strong> folder in the GitHub repository for the book. </p>
			<p>Let's open up a fresh web browser that doesn't have cookies or a session attached so that we can log in to the AWS console as Peter. You may need to either open up an incognito window or a different browser than the one you have been using. For example, if you have been running the administrator in Chrome, then you would open up a new session in Firefox or Edge using the following steps: </p>
			<ol>
				<li value="1">Sign in to the AWS console using your account number or account alias and the user's name, <strong class="source-inline">peter</strong>, and the <strong class="source-inline">Dev0psPRO</strong> password, as we created previously. </li>
				<li>You will instantly be prompted to change the password for the user <strong class="source-inline">peter</strong>. Change this password to anything you like, but either write it down or keep it something you can remember as you may need to access this user later. The process is shown in the following screenshot: <div id="_idContainer132" class="IMG---Figure"><img src="Images/Figure_9.5_B17405.jpg" alt="Figure 9.5 – Password change for tools user peter&#13;&#10;" width="567" height="333"/></div><p class="figure-caption">Figure 9.5 – Password change for tools user peter</p></li>
				<li>Once you <a id="_idIndexMarker870"/>have changed the password, the AWS console will bring you to the main console page. Use the top unified search box to <a id="_idIndexMarker871"/>search for the <strong class="bold">CloudFormation</strong> service. Once the CloudFormation service appears, click on the service icon to be taken to the main CloudFormation page, as illustrated in the following screenshot: <div id="_idContainer133" class="IMG---Figure"><img src="Images/Figure_9.6_B17405.jpg" alt="Figure 9.6 – CloudFormation service icon&#13;&#10;" width="506" height="165"/></div><p class="figure-caption">Figure 9.6 – CloudFormation service icon</p></li>
				<li>Once on the main <strong class="bold">CloudFormation</strong> service page, click the orange <strong class="bold">Create stack</strong> button.</li>
				<li>On the <strong class="bold">Create stack</strong> page, use the following options: <p>a. <strong class="bold">Prepare stack</strong>—Keep this selected on <strong class="bold">Template is ready</strong> </p><p>b. <strong class="bold">Specify template</strong>—Choose the checkbox that is labeled <strong class="bold">Upload a template file</strong> </p></li>
				<li>Then, click the <strong class="bold">Choose file</strong> button and find the <strong class="source-inline">pipeline1.yml</strong> file and open this file. Once <a id="_idIndexMarker872"/>this file has been selected, click the orange <strong class="bold">Next</strong> button at the bottom of the screen, as illustrated in the following screenshot: <p class="figure-caption"> </p><div id="_idContainer134" class="IMG---Figure"><img src="Images/Figure_9.7_B17405.jpg" alt="Figure 9.7 – Creating a CodePipeline stack &#13;&#10;" width="1040" height="578"/></div><p class="figure-caption">Figure 9.7 – Creating a CodePipeline stack </p></li>
				<li>Once you click the <strong class="bold">Next</strong> button, it will take you to the <strong class="bold">Specify stack details</strong> screen. Everything should already be filled out for you using CloudFormation default parameter values except for <strong class="bold">CloudFormation Stack name</strong>—use <strong class="source-inline">C9-demo</strong> and your email address where you would like to receive notifications about the stack. You can leave this blank for the email address, or you can put in your own email address. If the branch you created was named <strong class="source-inline">main</strong>, then you do not need to make any changes; however, if the branch you created was named <strong class="source-inline">master</strong> as in our example, then you will need to change the default value in the <strong class="bold">Branch name</strong> field to <strong class="source-inline">master</strong> before moving on or the pipeline will not execute right away. Once you have filled in these values, click the orange <strong class="bold">Next</strong> button <a id="_idIndexMarker873"/>at the bottom of the screen, as illustrated in the following screenshot: <div id="_idContainer135" class="IMG---Figure"><img src="Images/Figure_9.8_B17405.jpg" alt="Figure 9.8 – Adding values to the Specify stack details screen&#13;&#10;" width="857" height="935"/></div><p class="figure-caption">Figure 9.8 – Adding values to the Specify stack details screen</p></li>
				<li>On the <strong class="bold">Configure stack options</strong> screen, we will not be adding any tags. Simply go to the bottom of the page and click the orange <strong class="bold">Next</strong> button. </li>
				<li>Now, on the <strong class="bold">Review C9-demo</strong> page, scroll down to the bottom of the page and check the box in the blue area that acknowledges that this stack will create an IAM role under the heading of <strong class="bold">Capabilities</strong>. After you have checked the box, you can <a id="_idIndexMarker874"/>press the orange button that is labeled <strong class="bold">Create stack</strong>, as illustrated in the following screenshot:<div id="_idContainer136" class="IMG---Figure"><img src="Images/Figure_9.9_B17405.jpg" alt="Figure 9.9 – Checking the acknowledgment in the Capabilities section on the review&#13;&#10;" width="1314" height="319"/></div><p class="figure-caption">Figure 9.9 – Checking the acknowledgment in the Capabilities section on the review</p></li>
				<li>Once pressed, you will be taken to the <strong class="bold">Stacks</strong> page in CloudFormation. The stack itself will show the status of <strong class="source-inline">CREATE_IN_PROGRESS</strong> until it has finished creating our code pipeline. Once the status has been completed, then we can move on to the next step.   </li>
				<li>After the CloudFormation process completes, we will then be able to go back up to the unified search and search for the <strong class="source-inline">CodePipeline</strong> service. Once the icon for <strong class="bold">CodePipeline</strong> appears, as illustrated in the following screenshot, click on it to be taken to the current pipelines: <div id="_idContainer137" class="IMG---Figure"><img src="Images/Figure_9.10_B17405.jpg" alt="Figure 9.10 – CodePipeline from the unified search bar&#13;&#10;" width="482" height="166"/></div><p class="figure-caption">Figure 9.10 – CodePipeline from the unified search bar</p></li>
				<li>You should see the pipeline that you just created, named <strong class="source-inline">C9-demo</strong>. Click on this name to view the details of the pipeline. </li>
			</ol>
			<p>We can see from the pipeline we created that we now have a pipeline created with three stages: <strong class="bold">Source</strong>, <strong class="bold">Build</strong>, and <strong class="bold">Deploy</strong>. There are integrated processes including manual approval processes on the deploy stage along with the CloudFormation creation..</p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you failed to complete the previous exercise of creating the CodeCommit repository named <strong class="source-inline">chapt9</strong>, you would run into problems with the pipeline. This <strong class="source-inline">chapt9</strong> repository is the code source for our AWS code pipeline. If you named your repository something different, you would need to either modify the CloudFormation template or go into the AWS console and modify your source stage. </p>
			<p>Now, with <a id="_idIndexMarker875"/>our AWS code pipeline built, we can move forward with our developer testing a commit and seeing the stages of the pipeline in action, just as it would work in real life. Before we do that, however, we need to give our developer users more IAM permissions since when they were initially created, they only had permissions for CodeCommit and to modify their own password. </p>
			<h2 id="_idParaDest-240"><a id="_idTextAnchor246"/>Updating our developer users</h2>
			<p>In the previous chapter, <a href="B17405_08_Final_JM_ePub.xhtml#_idTextAnchor212"><em class="italic">Chapter 8</em></a>, <em class="italic">Creating Workloads with CodeCommit and CodeBuild</em>, we created a <a id="_idIndexMarker876"/>group for developers. We gave them a scoped set of permissions that was limited to AWS CodeCommit and CodeBuild. Since we are now adding CodePipeline and CodeBuild to the mix, we will now have to expand their permissions so that they can use these services as well. In the GitHub <strong class="source-inline">Chapter9</strong> repository, there is a file named <strong class="source-inline">IAM_Developers.json</strong>—be sure to download this file so that you can update the permissions for your developer. While updating the commands, you will need to use your administrative user. We'll proceed as follows: </p>
			<p class="callout-heading">Note</p>
			<p class="callout">Before you start to perform these commands, make sure that you have downloaded the <strong class="source-inline">IAM_Developers.json</strong> file from the <strong class="source-inline">Chapter9</strong> folder in the GitHub repository and are in the same directory where you downloaded the file. </p>
			<ol>
				<li value="1">The first thing that we need to do is find the ARN of the policy attached to our developers. We created this policy in the exercise in <a href="B17405_08_Final_JM_ePub.xhtml#_idTextAnchor212"><em class="italic">Chapter 8</em></a>, <em class="italic">Creating Workloads with CodeCommit and CodeBuild</em>. Log in to your terminal and run the following command to extract the ARN for the developer group:<p class="source-code"><strong class="bold">aws iam list-policies --query 'Policies[?PolicyName==`CC_Developers`].Arn' --output text</strong></p><p>After we run this command, we should get a return of the current ARN being used for our Code Commit developers' group. This ARN is going to be needed in the following step so that we can update our policy. </p></li>
				<li>After we <a id="_idIndexMarker877"/>have the ARN, we can then create a new policy version and set that version as <strong class="source-inline">default</strong>, as follows: <p class="source-code"><strong class="bold">aws iam create-policy-version \</strong></p><p class="source-code"><strong class="bold">--policy-arn arn:aws:iam::470066103307:policy/CC_Developers \</strong></p><p class="source-code"><strong class="bold">--policy-document file://IAM_Developers.json --set-as-default</strong></p><p>If this is <a id="_idIndexMarker878"/>successful, we will be returned a <strong class="bold">JavaScript Object Notation</strong> (<strong class="bold">JSON</strong>) message showing that we are now on the second version of our policy, as illustrated in the following code snippet: </p><p class="source-code"><strong class="bold">{</strong></p><p class="source-code"><strong class="bold">    "PolicyVersion": {</strong></p><p class="source-code"><strong class="bold">        "VersionId": "v2",</strong></p><p class="source-code"><strong class="bold">        "IsDefaultVersion": true,</strong></p><p class="source-code"><strong class="bold">        "CreateDate": "2021-05-16T19:01:09+00:00"</strong></p><p class="source-code"><strong class="bold">    }</strong></p><p class="source-code"><strong class="bold">}</strong></p></li>
			</ol>
			<p>Updating our developer user group to allow for CodePipeline access permits the developers to see the pipelines previously created when running, along with any errors that may <a id="_idIndexMarker879"/>have been encountered during individual steps of the pipeline. These permissions have been scoped in such a manner so as not to allow developers to create or modify any new or existing pipelines. </p>
			<h2 id="_idParaDest-241"><a id="_idTextAnchor247"/>CodePipeline concepts  </h2>
			<p>There are <a id="_idIndexMarker880"/>several basic concepts and terms to understand when using AWS CodePipeline, as depicted in the following diagram:</p>
			<div>
				<div id="_idContainer138" class="IMG---Figure">
					<img src="Images/Figure_9.11_B17405.jpg" alt="Figure 9.11 – CodePipeline transition representation &#13;&#10;" width="431" height="481"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.11 – CodePipeline transition representation </p>
			<h3>Understanding the CodePipeline and stage requirements </h3>
			<p>As you start to build pipelines, there are some rules and requirements that should be known as this can help you avoid headaches in trying to debug errors. Look through the list stated <a id="_idIndexMarker881"/>next for best practices as you build your AWS code pipelines along with the knowledge to remember during exam time: </p>
			<ul>
				<li>All stage names in a pipeline must be unique.</li>
				<li>Only the first stage in a pipeline can contain source actions.</li>
				<li>A pipeline must have at least two stages. </li>
				<li>All actions within a single stage must be unique.</li>
				<li>The input action of a stage must match the output action of the preceding stage exactly.</li>
				<li>Output artifact names must be unique to a pipeline. If a stage has an output artifact named <strong class="source-inline">TestPackage</strong>, no other stage may have another output artifact named <strong class="source-inline">TestPackage</strong> in that pipeline. </li>
				<li>For all supported action types, the only valid owner strings are <strong class="source-inline">AWS</strong>, <strong class="source-inline">ThirdParty</strong>, or <strong class="source-inline">Custom</strong>. </li>
			</ul>
			<p>There are other more complex requirements; however, if you understand these requirements, then you have a solid foundation for using the CodePipeline service along with an understanding of the nuances of stages for the DevOps professional exam. </p>
			<p>Now that we have looked at the stages as a whole in an AWS code pipeline, let's look at one aspect that is not automated: approval actions. </p>
			<h2 id="_idParaDest-242"><a id="_idTextAnchor248"/>Approval actions in a code pipeline </h2>
			<p>In a code pipeline, there is an opportunity to pause between stages using approval actions. Approval <a id="_idIndexMarker882"/>actions allow for the manual review of an action before proceeding to the next stage of the pipeline. </p>
			<p>Actions that are approved by the reviewer move on to the next stage of the pipeline. If an approval is rejected, then the pipeline does not continue to the next stage. You also have 7 days to approve a pipeline action, or it will result in the pipeline failing. </p>
			<p>There are a few common reasons why you would use approval actions in an AWS code pipeline, outlined as follows: </p>
			<ul>
				<li>To perform <a id="_idIndexMarker883"/>manual <strong class="bold">Quality Assurance</strong> (<strong class="bold">QA</strong>) testing before moving on to the next stage</li>
				<li>To allow <a id="_idIndexMarker884"/>for a code review or change management review before proceeding</li>
				<li>To allow for manual review of a web page before publishing to production</li>
			</ul>
			<h1 id="_idParaDest-243"><a id="_idTextAnchor249"/>Using Jenkins to build your workloads </h1>
			<p>The developer tools provided by AWS can give you just about all the functionality that you need <a id="_idIndexMarker885"/>without any extra configuration or setup. There <a id="_idIndexMarker886"/>are instances where teams have already built parts of their <strong class="bold">Continuous Integration/Continuous Deployment</strong> (<strong class="bold">CI/CD</strong>) process around existing tooling and may want to retain some of the work that they have already poured time and effort into refining. </p>
			<p>Teams that use the Jenkins server can be one of those cases. Along with its vast ecosystem of plugins, Jenkins can provide an extreme amount of functionality in the CI/CD process. </p>
			<p>Many teams use Jenkins for the build stage of the CI process since, in Jenkins, it can feel easier to build the steps in shell scripts without a need to create additional <strong class="source-inline">buildspec</strong> files.</p>
			<p>The following diagram depicts Jenkins being used in conjunction with CodePipeline:</p>
			<div>
				<div id="_idContainer139" class="IMG---Figure">
					<img src="Images/Figure_9.12_B17405.jpg" alt="Figure 9.12 – Using Jenkins in conjunction with CodePipeline&#13;&#10;" width="502" height="252"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.12 – Using Jenkins in conjunction with CodePipeline</p>
			<p>Jenkins itself has plugins that will work with many of the AWS services, including the developers' suite of services. </p>
			<p>Now that <a id="_idIndexMarker887"/>we have looked at the CodePipeline service, including how to incorporate third-party tools such as the Jenkins build server, let's look at how we can use AWS CodeDeploy to deploy our workloads either by themselves or as part of a pipeline. </p>
			<h1 id="_idParaDest-244"><a id="_idTextAnchor250"/>About AWS CodeDeploy</h1>
			<p>AWS CodeDeploy is a service that assists in automating deployments of application code and files <a id="_idIndexMarker888"/>to EC2 instances, on-premises servers, Lambda functions, and containers running on AWS ECS. </p>
			<p>CodeDeploy is <a id="_idIndexMarker889"/>a service that makes the following things easier:</p>
			<ul>
				<li>Update Lambda functions and create new versions </li>
				<li>Avoid downtime during application deployments </li>
				<li>Swiftly release new features </li>
				<li>Promptly roll back to a known good version in case of deployment failure</li>
			</ul>
			<p>AWS CodeDeploy <a id="_idIndexMarker890"/>is focused on the following three platforms for deployments:</p>
			<ul>
				<li>EC2/on-premises instances </li>
				<li>Lambda functions </li>
				<li>ECS containerized applications </li>
			</ul>
			<p>Using <a id="_idIndexMarker891"/>these three platforms as a basis, you describe your deployments in a file named <strong class="source-inline">appspec</strong>. This file can be written in either JSON or <strong class="bold">YAML Ain't Markup Language</strong> (<strong class="bold">YAML</strong>) format. </p>
			<p>There are multiple types of files and components that CodeDeploy can distribute, including <a id="_idIndexMarker892"/>the following:</p>
			<ul>
				<li>Executables </li>
				<li>Packages </li>
				<li>Scripts </li>
				<li>Multimedia files </li>
			</ul>
			<p>Now that we have a grasp of the basics of CodeDeploy, let's look at the basic concepts we need to understand when using the CodeDeploy service. </p>
			<h2 id="_idParaDest-245"><a id="_idTextAnchor251"/>Basic CodeDeploy concepts to understand</h2>
			<p>As we start <a id="_idIndexMarker893"/>to employ the CodeDeploy service, there are some components that should be understood first and foremost. </p>
			<h3>Application</h3>
			<p>This is a name that is unique, and CodeDeploy uses it to identify the application which you want <a id="_idIndexMarker894"/>to deploy. It uses this unique name to make sure that the correct version of deployment, deployment group, revision, or rollback is referenced during a particular deployment. </p>
			<h3>Compute platform </h3>
			<p>This is the actual platform where CodeDeploy deploys an application. There are quite a few choices <a id="_idIndexMarker895"/>for CodeDeploy deployments. Deployments can happen to EC2 instances or on-premises servers as long as they meet operating system requirements. These deployments can consist of configuration files, images, and executable files, along with other types of files. </p>
			<p>CodeDeploy can also be used to update Lambda functions. CodeDeploy also has the ability to shift traffic from one version of a Lambda function to a newer function in a multitude of deployment options, including <strong class="bold">canary</strong>, <strong class="bold">linear</strong>, and <strong class="bold">all-at-once</strong> deployments. </p>
			<p>If you are using containers on the ECS platform, then CodeDeploy can be used to update the tasks using a <strong class="bold">blue/green deployment</strong> strategy by first installing a new version of the task set and then shifting the traffic over to the latest version of the task set. As with Lambda deployments, these deployments can be done in a canary, linear, or all-at-once fashion. </p>
			<h3>Deployment configuration </h3>
			<p>Using a set of success or failure criteria along with deployment rules, CodeDeploy is guided by <a id="_idIndexMarker896"/>a deployment configuration for each deployment. Inside of the deployment configuration, especially in the case of EC2 or on-premises deployments, you can set the minimum number of healthy instances that need to succeed for the deployment to be a success. If you are targeting either a Lambda application or ECS tasks, then your deployment configuration can specify how the traffic is routed during the deployment. The following deployments are available:</p>
			<ul>
				<li><strong class="bold">Canary</strong>: Traffic is shifted <a id="_idIndexMarker897"/>in two separate increments, and you have the ability to specify the percentage of the traffic shifted initially before the rest of the traffic is shifted at a time specified in minutes. </li>
				<li><strong class="bold">Linear</strong>: Traffic is <a id="_idIndexMarker898"/>shifted in equal increments. You have predefined options for percentages that can be shifted and for the intervals between shifts. </li>
				<li><strong class="bold">All-at-once</strong>: All the traffic is <a id="_idIndexMarker899"/>shifted from the original Lambda function or ECS task at the same time. </li>
			</ul>
			<h3>Deployment groups </h3>
			<p>Deployment <a id="_idIndexMarker900"/>groups pertain to EC2 instances, either <a id="_idIndexMarker901"/>individually or in <strong class="bold">Auto Scaling Groups</strong> (<strong class="bold">ASGs</strong>), and are explicitly tagged for targeting a deployment.</p>
			<p>Deployment groups can be as straightforward as using a single tag to designate the deployment group, or you can become elaborate as using up to 10 different tags in a deployment group.</p>
			<h3>Deployment type </h3>
			<p>The deployment type is the technique used by CodeDeploy to place the most up-to-date version of an <a id="_idIndexMarker902"/>application into a deployment group. There are two different types of deployment types: <strong class="bold">in-place</strong> and <strong class="bold">blue/green</strong>. </p>
			<p>With in-place deployments, although possibly more cost-effective, the application on the current <a id="_idIndexMarker903"/>instances in the deployment group is stopped while the latest version of the application is installed. The new version of the application is restarted and then validated. In-place deployments are only available for EC2 instances or on-premises deployments. </p>
			<p>Blue/green <a id="_idIndexMarker904"/>deployments provision a new set of resources. This can consist of creating a new version of a Lambda function, a new task set in the case of ECS, or a whole new instance in the case of EC2. </p>
			<p>Blue/green deployments do not work with on-premises deployments. </p>
			<h3>Revision </h3>
			<p>A revision for an AWS Lambda deployment is either a file in YAML or JSON format that states <a id="_idIndexMarker905"/>information about the Lambda function to deploy. Revisions for Lambda are stored in an S3 bucket. </p>
			<p>In the case of an EC2 or on-premises deployment revision, this is not just one file but a collection of files that contain the components (such as web pages, executable files, source code, and deployment scripts) along with a specification for the application, which is then packaged up into archive format. Revisions for EC2 or on-premises instances can be stored in an S3 bucket or GitHub repositories. </p>
			<h3>Target revision </h3>
			<p>This is the <a id="_idIndexMarker906"/>most recent version of an application that has been uploaded to the code repository, which is going to be targeted for deployment.</p>
			<h2 id="_idParaDest-246"><a id="_idTextAnchor252"/>Installing the CodeDeploy agent file</h2>
			<p>When using <a id="_idIndexMarker907"/>CodeDeploy with EC2 instances, an agent file is placed on those instances, making it viable for the instance to achieve deployments from the CodeDeploy service. A configuration file is also placed on the instance with an agent, and this file specifies how the agent will work. These instances not only have to be in the AWS cloud but can also be on a specific operating system of an on-premises data center. </p>
			<p>Take a glance at the following lists to see which operating systems have been tested using the AWS CodeDeploy agent: </p>
			<div>
				<div id="_idContainer140" class="IMG---Figure">
					<img src="Images/021.jpg" alt="Table 9.2 – Tested operating systems to use the AWS CodeDeploy agent&#13;&#10;" width="1518" height="465"/>
				</div>
			</div>
			<p class="figure-caption">Table 9.2 – Tested operating systems to use the AWS CodeDeploy agent</p>
			<p>Any EC2 instance <a id="_idIndexMarker908"/>that you wish to use with CodeDeploy will also need to have a service role attached that gives it enough permissions so that the CodeDeploy service can perform its duties. </p>
			<h2 id="_idParaDest-247"><a id="_idTextAnchor253"/>Understanding the appspec file </h2>
			<p>The application specification file, or <strong class="source-inline">appspec</strong> file, as it is most commonly called, is a YAML file in <a id="_idIndexMarker909"/>the majority of cases (although it may be formatted in JSON format) that has a specific number of sections along with some optional sections depending on which type of deployment you are trying to perform. </p>
			<p>The <strong class="source-inline">appspec</strong> file details the deployment actions that you want to take during the deployment. </p>
			<p>There are different types of <strong class="source-inline">appspec</strong> files if you are doing an ECS deployment for containers, for EC2, or on-premises instances, and then if you are trying to deploy to Lambda instances. </p>
			<p>The following <a id="_idIndexMarker910"/>is an example <strong class="source-inline">appspec</strong> file:</p>
			<p class="source-code">version: 0.0</p>
			<p class="source-code">Resources:</p>
			<p class="source-code">  - myLambdaFunction:</p>
			<p class="source-code">      Type: AWS::Lambda::Function</p>
			<p class="source-code">      Properties:</p>
			<p class="source-code">        Name: "myTestFunction"</p>
			<p class="source-code">        Alias: "myTestFunctionAlias"</p>
			<p class="source-code">        CurrentVersion: "1"</p>
			<p class="source-code">        TargetVersion: "2"</p>
			<p class="source-code">Hooks:</p>
			<p class="source-code">  - BeforeAllowTraffic: "LambdaFunctionToValidateBeforeTrafficShift"</p>
			<p class="source-code">  - AfterAllowTraffic: "LambdaFunctionToValidateAfterTrafficShift"</p>
			<p>Important items to note in our example <strong class="source-inline">appspec</strong> file are the version, the resources, and the hooks. </p>
			<h2 id="_idParaDest-248"><a id="_idTextAnchor254"/>Deployment rollbacks and content redeployment</h2>
			<p>AWS CodeDeploy can roll back a deployment that has either been stopped manually or that has <a id="_idIndexMarker911"/>failed during the deployment process. Properly <a id="_idIndexMarker912"/>speaking, these rollbacks are <a id="_idIndexMarker913"/>new deployments and receive new deployment <strong class="bold">identifiers</strong> (<strong class="bold">IDs</strong>). The rollbacks do restore previous versions of a set of code. There are two different ways that rollbacks can happen, via automated rollbacks or via a manual process. </p>
			<h3>Automated rollbacks </h3>
			<p>Your deployment group can be configured to automatically roll back either on failure during a deployment or if certain monitoring thresholds are met during a deployment. If one of these <a id="_idIndexMarker914"/>limits has been set and then triggered during the deployment for a case of automated rollback, then the deployment will go back to the last known good configuration. </p>
			<p>You may also choose to override the automated rollback option if it has previously been put in place when starting a new deployment by configuring one of the advanced configuration options for the deployment group. </p>
			<h3>Manual rollbacks </h3>
			<p>Even if you have not set up your deployment to roll back automatically, using AWS CodeDeploy, you can <a id="_idIndexMarker915"/>push out a previous version of a deployment. This would create a new deployment version. You could do this if your deployment failed or if your instances have got into an unknown state, and they might be fixed by pushing updates to the application and configuration. </p>
			<h3>Rollback and redeployment workflow </h3>
			<p>If a rollback has been induced either automatically or manually, then CodeDeploy will start to try to <a id="_idIndexMarker916"/>remove all of the files that were successfully installed during the deployment. </p>
			<p>The cleanup file, if it exists, is a type of log file that CodeDeploy keeps so that it knows which files <a id="_idIndexMarker917"/>have been installed and can remove these files before starting a new deployment.</p>
			<p>During deployment, the CodeDeploy agent will write out the filenames that are being deployed so that it has a record in case a rollback is necessary. </p>
			<p>In the case of a rollback, CodeDeploy will refer to the cleanup file so that it knows which files to remove. It can then proceed with the previous version of the deployment in case of automatic rollback.</p>
			<p>Knowing now how deployments and rollbacks work, let's take a look at some of the use cases for AWS CodeDeploy.  </p>
			<h1 id="_idParaDest-249"><a id="_idTextAnchor255"/>Use cases for AWS CodeDeploy </h1>
			<p>As we have <a id="_idIndexMarker918"/>looked at the AWS CodeDeploy service, let's think about some of the situations where this service would serve us best. </p>
			<h2 id="_idParaDest-250"><a id="_idTextAnchor256"/>Deploying application updates to servers in an on-premises data center</h2>
			<p>If you <a id="_idIndexMarker919"/>are running a compatible operating system on your on-premises hardware, then you use AWS CodeDeploy to coordinate the deployments as well as have a single pane of glass to see successes and failures. Installing the AWS CodeDeploy agent is a required prerequisite. These operating systems include Windows Server, Ubuntu Server, or RHEL. </p>
			<h2 id="_idParaDest-251"><a id="_idTextAnchor257"/>Deploying application updates to Windows or Linux servers in the AWS cloud</h2>
			<p>If you <a id="_idIndexMarker920"/>are deploying to an NGINX or Apache server on a Linux EC2 instance or an <strong class="bold">Internet Information Services</strong> (<strong class="bold">IIS</strong>) instance on a Windows server, then you <a id="_idIndexMarker921"/>can use the CodeDeploy agent to choreograph the placement of files and restart any necessary services needed to update files on these instances. </p>
			<h2 id="_idParaDest-252"><a id="_idTextAnchor258"/>Deploying application updates to multiple regions with one deployment push </h2>
			<p>When <a id="_idIndexMarker922"/>you are looking for a way to build a solution that will create <a id="_idIndexMarker923"/>an automated <strong class="bold">End-to-End</strong> (<strong class="bold">E2E</strong>) release flow for deployments in multiple regions, then AWS CodeDeploy can help do this with help from AWS CodePipeline. This is especially true in the case of trying to keep Lambda deployments in sync for either <strong class="bold">High-Availability</strong> (<strong class="bold">HA</strong>) purposes or a <strong class="bold">Disaster Recovery</strong> (<strong class="bold">DR</strong>) strategy. In the following diagram, you can see CodeDeploy being used to deploy to multiple regions:</p>
			<div>
				<div id="_idContainer141" class="IMG---Figure">
					<img src="Images/Figure_9.13_B17405.jpg" alt="Figure 9.13 – Using CodePipeline and CodeDeploy to deploy to multiple regions&#13;&#10;" width="577" height="479"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.13 – Using CodePipeline and CodeDeploy to deploy to multiple regions</p>
			<p>Using S3 as the origin for the source code will kick off the deployment via the AWS code pipeline. If the pipeline is successful, then it will move on to an invoke stage where a Lambda <a id="_idIndexMarker924"/>function will copy the source code to an S3 bucket in the replicated region. </p>
			<p>This replication of the source code to the S3 bucket in the <strong class="bold">B</strong> region will start the process again on another pipeline that has been set up in the second region. </p>
			<h2 id="_idParaDest-253"><a id="_idTextAnchor259"/>Deploying a new task to ECS in blue/green fashion</h2>
			<p>CodeDeploy can give you the ability to seamlessly switch between task sets that are behind <a id="_idIndexMarker925"/>a network or application load balancer. It does this by deploying the new version of the task set and then switching the listener to the new version at the load balancer level, as illustrated in the following diagram: </p>
			<div>
				<div id="_idContainer142" class="IMG---Figure">
					<img src="Images/Figure_9.14_B17405.jpg" alt="Figure 9.14 – Blue/green deployment using CodeDeploy&#13;&#10;" width="579" height="416"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.14 – Blue/green deployment using CodeDeploy</p>
			<p class="callout-heading">Note </p>
			<p class="callout">We will go more in-depth into blue/green deployments in <a href="B17405_13_Final_JM_ePub.xhtml#_idTextAnchor338"><em class="italic">Chapter 13</em></a>, <em class="italic">Blue Green Deployments</em>.</p>
			<h2 id="_idParaDest-254"><a id="_idTextAnchor260"/>Deploying a task to Amazon ECS and using Lambda to validate before switching traffic over</h2>
			<p>With the <a id="_idIndexMarker926"/>use of CodeDeploy deployment groups, along with the assistance of a Lambda function, you can create <a id="_idIndexMarker927"/>a test to ensure that your new task is up and running successfully. This Lambda function can be specified in the deployment <strong class="source-inline">appspec</strong> file, and if the validation fails, then the deployment is stopped and rolled back. If the validation succeeds, then the deployment continues. </p>
			<h2 id="_idParaDest-255"><a id="_idTextAnchor261"/>Monitoring CodeDeploy jobs </h2>
			<p>Whether <a id="_idIndexMarker928"/>your CodeDeploy jobs are running standalone with the CodeDeploy service or as part of a deployment pipeline, monitoring their status and being notified promptly when there is a failure can be critical for solving issues in a timely fashion.  </p>
			<p>Partnering CodeDeploy with the monitoring abilities of CloudWatch allows you to monitor specific metrics during deployments. Using these metrics, you can create CloudWatch alarms. Up to 10 CloudWatch alarms can be associated with a CodeDeploy deployment group. Triggering any one of the alarms will cause the deployment to stop and the status of the deployment to be reflected as <strong class="source-inline">Stopped</strong>. In order to monitor CodeDeploy with the CloudWatch service, you must grant your CodeDeploy service role permissions to use the CloudWatch service. </p>
			<p>CloudWatch events can be used to help not only detect but also react to failures of CodeDeploy jobs based on rules that you create. Once these rules are created, CloudWatch events will initiate actions on specific targets. The following targets will work from CloudWatch events with rules from CodeDeploy jobs:</p>
			<ul>
				<li>AWS <strong class="bold">Lambda</strong> functions</li>
				<li>Kinesis <a id="_idIndexMarker929"/>streams </li>
				<li>Amazon <strong class="bold">Simple Queue Service</strong> (<strong class="bold">SQS</strong>) queues </li>
				<li><strong class="bold">CloudWatch</strong> <a id="_idIndexMarker930"/>alarm actions </li>
				<li>Amazon <strong class="bold">Simple Notification Service</strong> (<strong class="bold">SNS</strong>) topics (and notifications) </li>
			</ul>
			<h3>CodeDeploy monitoring use cases</h3>
			<p>If your team <a id="_idIndexMarker931"/>uses Slack as a communication channel, then you can integrate a Slack notification via a Lambda function whenever a CodeDeploy deployment fails. </p>
			<p>CloudWatch alarm actions can be used to programmatically reboot, stop, or terminate EC2 instances if a specific event occurs during deployment. </p>
			<p>Now that we have looked at the abilities to monitor our CodeDeploy deployments, let's recap what we have learned in this chapter. </p>
			<h1 id="_idParaDest-256"><a id="_idTextAnchor262"/>Summary</h1>
			<p>In this chapter, we looked at the other pieces of the AWS developer tools we are going to cover in depth in this book. We learned about deploying our software to different environments, both in the cloud and on-premises, using AWS CodeDeploy. We examined how CodeDeploy can be used to not only push out new versions of an application but also to control traffic during deployments. We also studied the AWS CodePipeline orchestration tool and how it as a service can incorporate not only all of the other three services we have been looking at from a development perspective but also other third-party partner tools as well. </p>
			<p>In the next chapter, we will look at the AWS OpsWorks service and how this can be helpful for managing infrastructure and application services using stacks, especially if your team members are well versed in Chef or Puppet. </p>
			<h1 id="_idParaDest-257"><a id="_idTextAnchor263"/>Review questions </h1>
			<ol>
				<li value="1">One of the team of developers at a company has made multiple deployments. The last deployment with overwrite content failed. You have been tasked with rolling back to the previously working version with all the files necessary for the application. Which option would you choose to fulfill this requirement in the most expedient way possible? <p>a. Manually roll back to the last known application version, which will add files required for application revision. </p><p>b. Manually roll back to the previous deployment and then manually add files for the application revision.</p><p>c. Automatically roll back to the last known version, which will add files required for application revision.</p><p>d. Automatically roll back to the last known application version and manually add files for application revision. </p></li>
				<li>You have constructed an AWS code pipeline that carries out a code release process. There are two stages to this pipeline: a source stage and a deploy stage. The source stage is using the third-party provider GitHub to source the code for the deployments. AWS CodeDeploy is being used to deploy the new versions of the application to multiple EC2 instances in a target group. The last few deployments have not gone successfully, and failures appear during the CodeDeploy stage. You need the ability to increase monitoring and notifications for deployments in order to cut down your Mean Time to Resolution (MTTR). How can you create notifications as soon as an issue is detected?<p>a. Set up CloudWatch events for both CodeDeploy and CodePipeline. Use Amazon Inspector to create an assessment target to assess code deployment issues and create an SNS topic so that you can be notified of deployment issues. </p><p>b. Set up CloudWatch events for both CodeDeploy and CodePipeline. Use an AWS Lambda function to help assess code deployment issues and create an SNS topic so that you can be notified of deployment issues. </p><p>c. Set up a new AWS CloudTrail trail for the region that the pipeline is running in. Use AWS Config to assess any code deployment issues and create an SNS topic so that you can be notified of any deployment issues. </p><p>d. Set up a new AWS CloudTrail to capture API events from CodeDeploy and CodePipeline. Use an AWS Lambda function to help assess code deployment issues and create an SNS topic so that you can be notified of deployment issues.</p></li>
			</ol>
			<h1 id="_idParaDest-258"><a id="_idTextAnchor264"/>Review answers </h1>
			<ol>
				<li value="1">d</li>
				<li>b</li>
			</ol>
		</div>
	</div></body></html>