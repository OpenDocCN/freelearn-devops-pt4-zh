<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer236">
			<h1 id="_idParaDest-390"><a id="_idTextAnchor400"/>Chapter 16: Various Logs Generated (VPC Flow Logs, Load Balancer Logs, CloudTrail Logs)</h1>
			<p>Logs are a river of information, and they flow from various sources. The logs that come from the Load Balancer can be a valuable source of data or a resource for troubleshooting. Knowing how to enable these resources can be vital when setting up or running your environment. Any action taken in the AWS environment, either via the AWS Management Console, the CLI, or an SDK, is recorded via the underlying API call to CloudTrail. As a DevOps engineer, it's essential to know who and what is making changes to your environment and be able to retrieve that data, especially when requested. </p>
			<p>In this chapter, we're going to cover the following main topics: </p>
			<ul>
				<li>The power of AWS CloudTrail</li>
				<li>Enabling Elastic Load Balancer logs </li>
				<li>Using VPC Flow Logs </li>
				<li>Cleaning up the resources</li>
			</ul>
			<h1 id="_idParaDest-391"><a id="_idTextAnchor401"/>Previous logs discussed</h1>
			<p>So far, we have <a id="_idIndexMarker1361"/>mainly been discussing logs that are generated from the application itself. Also included in some of those earlier exercises with CloudWatch Logs were some logs that AWS gives us as wrappers around those logs; however, these are still, for the most part, just application and AWS service logs. </p>
			<p>When we want to understand how users are interacting with our environment, be it our network environment or how they are adding and removing resources within our account, then we would not be able to find that information in the application logs. Instead, we must look at some of the other logs available in AWS. </p>
			<p>Knowing which <a id="_idIndexMarker1362"/>logs to use for which purpose can also help us when it comes to other services to protect our<a id="_idIndexMarker1363"/> environment, such as <strong class="bold">GuardDuty</strong>. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">We will discuss GuardDuty in <a href="B17405_22_Final_JM_ePub.xhtml#_idTextAnchor486"><em class="italic">Chapter 22</em></a>, <em class="italic">Other Policy and Standards Services to Know About</em>. </p>
			<p>Now that we've looked at where we have been and where we are going, let's start with our first set of logs – CloudTrail logs. </p>
			<h1 id="_idParaDest-392">The power <a id="_idTextAnchor402"/>of AWS CloudTrail </h1>
			<p><strong class="bold">CloudTrail</strong> enables<a id="_idIndexMarker1364"/> governance, compliance, risk auditing, and operational auditing with either your AWS account or multiple accounts using AWS organizations. </p>
			<p>In AWS, every action is performed by an API call. This is true if you are using the AWS Management Console, the Amazon CLI, or any of the available SDKs. All <a id="_idIndexMarker1365"/>of these use API calls to perform the necessary actions, then those API actions are recorded by the CloudTrail service if it has been turned on: </p>
			<div>
				<div id="_idContainer226" class="IMG---Figure">
					<img src="Images/Figure_16.1_B17405.jpg" alt="Figure 16.1 – The flow of actions to logs via the CloudTrail service&#13;&#10;" width="533" height="250"/>
				</div>
			</div>
			<p class="figure-caption">Figure 16.1 – The flow of actions to logs via the CloudTrail service</p>
			<p>These<a id="_idIndexMarker1366"/> include recording calls to start and stop EC2 instances, uploading and deleting objects from S3, adding or removing security groups from a VPC, adding or dropping indexing from a DynamoDB table, and many more. When an activity occurs within your account, CloudTrail will capture and record that activity as a CloudTrail event. This CloudTrail event <a id="_idIndexMarker1367"/>contains the following details:</p>
			<ul>
				<li>Who performed the request </li>
				<li>The date and time that the request was made</li>
				<li>The source IP of the request </li>
				<li>How the request was made </li>
				<li>What action is being performed </li>
				<li>The region the action is being conducted in</li>
				<li> The response to the request</li>
			</ul>
			<p>It's also important to note that CloudTrail logs <a id="_idIndexMarker1368"/>are not pushed in real-time to the S3 bucket that they are stored in. Instead, the CloudTrail service publishes<a id="_idIndexMarker1369"/> updated log files every 5 minutes with a batch of events it has collected. </p>
			<p>When it comes to securing the CloudTrail logs themselves, by default, the service encrypts the files, which<a id="_idIndexMarker1370"/> it stores in Amazon S3 with <strong class="bold">S3 server-side encryption</strong> (<strong class="bold">SSE</strong>). You <a id="_idIndexMarker1371"/>also have the option to create an encryption key using the <strong class="bold">KMS</strong> service and encrypt the CloudTrail logs with that key. </p>
			<p>The CloudTrail service offers <a id="_idIndexMarker1372"/>several benefits. The first is that it records user and resource activity. Using these recordings, you can identify who did what and when they performed an action on a resource in your AWS account. Secondly, since event logs are automatically stored and recorded, compliance reporting becomes much more manageable. Third, you gain the ability to monitor, alarm, and react to the events that are happening by sending the CloudTrail events to CloudWatch Logs. The fourth and final benefit that we will mention here is the ability to search through the logs using the CloudWatch service using a SQL-like syntax. This enables you to perform powerful queries on the large amounts of data that CloudTrail produces. </p>
			<p>Now that we know about the CloudTrail service, we will set up CloudTrail in our account. </p>
			<h2 id="_idParaDest-393"><a id="_idTextAnchor403"/>Setting up CloudTrail </h2>
			<p>We are going<a id="_idIndexMarker1373"/> to set up CloudTrail before we look at the logs that CloudTrail has recorded. We're doing this so that as we perform other exercises in this chapter, we are sure that the CloudTrail service is on and recording our actions. This will also ensure that we have a comprehensive set of recordings to search through when we perform the CloudTrail exercise later. </p>
			<p>Amazon has updated the default way that it creates CloudTrail trails so that all the regions are included when it's initialized. In this section, we want to create a trail that will be specific to the region that we are working in. This is still possible, but only if we use the AWS CLI:</p>
			<ol>
				<li>Open your terminal so that you have access to the AWS CLI. First, we will need to create an S3 bucket so that our CloudTrail logs can be captured and placed. Use the following <em class="italic">example</em> command, remembering that each S3 bucket name is unique and that you will need to create your own S3 bucket:<p class="source-code"><strong class="bold">aws s3 mb s3://devopsproandbeyond-trail --region us-east-2</strong></p></li>
				<li>For the CloudTrail service to be able to put logs into the S3 bucket, we need to attach a bucket policy to our bucket. Cut and paste the following bucket policy into a local<a id="_idIndexMarker1374"/> file (where you are performing your terminal commands) called <strong class="source-inline">cloudtrail_s3.json</strong>. Look for the two instances of the word <strong class="source-inline">BucketName</strong>; you will need to replace those with the name of the bucket that you created in the previous step. A copy of this file can be downloaded from the <strong class="source-inline">Chapter-16</strong> folder of this book's GitHub repository:<p class="source-code"><strong class="bold">{</strong></p><p class="source-code"><strong class="bold">    "Version": "2012-10-17",</strong></p><p class="source-code"><strong class="bold">    "Statement": [</strong></p><p class="source-code"><strong class="bold">        {</strong></p><p class="source-code"><strong class="bold">            "Sid": "AWSCloudTrailAclCheck20150319",</strong></p><p class="source-code"><strong class="bold">            "Effect": "Allow",</strong></p><p class="source-code"><strong class="bold">            "Principal": {"Service": "cloudtrail.amazonaws.com"},</strong></p><p class="source-code"><strong class="bold">            "Action": "s3:GetBucketAcl",</strong></p><p class="source-code"><strong class="bold">            "Resource": "arn:aws:s3:::BucketName"</strong></p><p class="source-code"><strong class="bold">        },</strong></p><p class="source-code"><strong class="bold">        {</strong></p><p class="source-code"><strong class="bold">            "Sid": "AWSCloudTrailWrite20150319",</strong></p><p class="source-code"><strong class="bold">            "Effect": "Allow",</strong></p><p class="source-code"><strong class="bold">            "Principal": {"Service": "cloudtrail.amazonaws.com"},</strong></p><p class="source-code"><strong class="bold">            "Action": "s3:PutObject",</strong></p><p class="source-code"><strong class="bold">            "Resource": "arn:aws:s3:::BucketName/*",</strong></p><p class="source-code"><strong class="bold">            "Condition": {"StringEquals": {"s3:x-amz-acl": "bucket-owner-full-control"}}</strong></p><p class="source-code"><strong class="bold">        }</strong></p><p class="source-code"><strong class="bold">    ]</strong></p><p class="source-code"><strong class="bold">}</strong></p></li>
				<li>Once you have created the policy file, you can attach it to your bucket using the following command. Be sure to change your bucket name so that the policy attaches to your bucket:<p class="source-code"><strong class="bold">aws s3api put-bucket-policy \</strong></p><p class="source-code"><strong class="bold">  --bucket devopsproandbeyond-trail \</strong></p><p class="source-code"><strong class="bold">  --policy file://cloudtrail_s3.json</strong></p></li>
				<li>With <a id="_idIndexMarker1375"/>our S3 bucket attached, we can create our single-region trail. Use the following command to create your trail, remembering to switch out the name of the S3 bucket in the command for the bucket that you created in <em class="italic">step 1</em> of this exercise. Note how we named our trail <strong class="source-inline">sixteen</strong>. We will be referencing this trail name later in this chapter:<p class="source-code"><strong class="bold">aws cloudtrail create-trail \</strong></p><p class="source-code"><strong class="bold">  --name sixteen \</strong></p><p class="source-code"><strong class="bold">  --s3-bucket-name devopsproandbeyond-trail \</strong></p><p class="source-code"><strong class="bold">  --region us-east-2</strong></p></li>
			</ol>
			<p>If the trail was created successfully, then you should see JSON returned, similar to the following:</p>
			<p class="source-code"><strong class="bold">{</strong></p>
			<p class="source-code"><strong class="bold">    "Name": "sixteen",</strong></p>
			<p class="source-code"><strong class="bold">    "S3BucketName": "devopsproandbeyond-trail",</strong></p>
			<p class="source-code"><strong class="bold">    "IncludeGlobalServiceEvents": true,</strong></p>
			<p class="source-code"><strong class="bold">    "IsMultiRegionTrail": false,</strong></p>
			<p class="source-code"><strong class="bold">    "TrailARN": "arn:aws:cloudtrail:us-east-2:470066103307:trail/sixteen",</strong></p>
			<p class="source-code"><strong class="bold">    "LogFileValidationEnabled": false,</strong></p>
			<p class="source-code"><strong class="bold">    "IsOrganizationTrail": false</strong></p>
			<p class="source-code"><strong class="bold">}</strong></p>
			<ol>
				<li value="1">Now, it's time to start the trail. Just because we created the trail doesn't make it automatically start recording events. Use the following command to start the trail so that it captures all the API calls in the region:<p class="source-code"><strong class="bold">aws cloudtrail start-logging --name sixteen --region us-east-2</strong></p></li>
				<li>Next, to <a id="_idIndexMarker1376"/>stream our logs to CloudWatch Logs (so that we can search for them later), we will need to log into the AWS Management Console and make a quick edit to our trail. After logging into the console, navigate to the CloudTrail service. When you are brought to the CloudTrail dashboard, you should see the trail that we created named <strong class="bold">sixteen</strong>. Click on this trail's name:<div id="_idContainer227" class="IMG---Figure"><img src="Images/Figure_16.2_B17405.jpg" alt="Figure 16.2 – The sixteen CloudTrail trail on the Dashboard&#13;&#10;" width="451" height="94"/></div><p class="figure-caption">Figure 16.2 – The sixteen CloudTrail trail on the dashboard</p></li>
				<li>When you are in the sixteen cloud trail, you should see a section named <strong class="bold">CloudTrail logs</strong>. Click the button to the right of the section labeled <strong class="bold">Edit</strong>.</li>
				<li>On the <strong class="bold">CloudWatch Logs – Optional</strong> screen, check the <strong class="bold">Enabled</strong> box. Keep the setting for creating a new log group as-is but rename the log group to <em class="italic">CloudWatch</em>. This will make it easier to find later. Allow the CloudTrail service to create a new IAM role for you and name it <strong class="source-inline">CloudTrailRole-sixteen</strong>. Then, click the orange <strong class="bold">Save changes</strong> button at the bottom of the screen.</li>
			</ol>
			<p>Now that we have set up the CloudTrail service to record the API actions that we will perform going forward, we will look at Elastic Load Balancer logs. </p>
			<h1 id="_idParaDest-394"><a id="_idTextAnchor404"/>Enabling Elastic Load Balancer logs </h1>
			<p>The <strong class="bold">Elastic Load Balancing</strong> service<a id="_idIndexMarker1377"/> lets you capture more data about your environment. This can help with troubleshooting, especially regarding latency. Elastic Load Balancer access logs can also let you see the path that a user or service took from an originating address to the destination service. Sometimes, this information is not captured on application logs since the originating address that is captured is the Elastic Load Balancer address. The Elastic Load Balancer access logs<a id="_idIndexMarker1378"/> include the following information:</p>
			<ul>
				<li>The client's IP address </li>
				<li>Request paths taken </li>
				<li>The time and date that the request was received </li>
				<li>Server responses (in numerical format) </li>
			</ul>
			<p>We looked at how load balancing helps spread the load between both instances and services when we examined in-depth services such as Elastic Beanstalk and OpsWorks. At this point, we should also understand that Elastic Load Balancing can be used to attach multiple instances and even instances that are part of an auto-scaling group:</p>
			<div>
				<div id="_idContainer228" class="IMG---Figure">
					<img src="Images/Figure_16.3_B17405.jpg" alt="Figure 16.3 – The flow of the access logs from an Elastic Load Balancer to an S3 bucket &#13;&#10;" width="383" height="287"/>
				</div>
			</div>
			<p class="figure-caption">Figure 16.3 – The flow of the access logs from an Elastic Load Balancer to an S3 bucket </p>
			<p>Once you have enabled access logs for your Elastic Load Balancer, there is no additional charge for logging. There is a charge, however, for storing the logs in S3. </p>
			<h2 id="_idParaDest-395"><a id="_idTextAnchor405"/>Setting up an Elastic Load Balancer and enabling logging</h2>
			<p>In our <a id="_idIndexMarker1379"/>first hands-on example for this chapter, we will use two cross-referenced CloudFormation templates to stand up a VPC; the second template will stand up an Elastic Load Balancer with two EC2 instances serving a simple website. The child template will also create an S3 bucket for capturing our access logs. Once we have stood up our test environment, we will need to go into the AWS Management Console and turn on logging for our Elastic Load Balancer. Once logging has been turned on, we can try to access the website a few times. Doing this should put some records in our S3 bucket that we can access and analyze. The templates referenced in this exercise are located in the <strong class="source-inline">Chapter-16</strong> directory of this book's GitHub repository. You should download all the templates before starting. Let's get started:</p>
			<ol>
				<li value="1">Log into <strong class="bold">AWS Management Console</strong> and navigate to the <strong class="bold">CloudFormation</strong> service. </li>
				<li>Once you're on the <strong class="bold">CloudFormation</strong> page, if you are brought to the main CloudFormation service page, then click on the orange <strong class="bold">Create stack</strong> button. Otherwise, if you are brought to a listing of your current stacks, then click on the <strong class="bold">Create stack</strong> button at the top right of the main window and choose the <strong class="bold">With new resources (standard)</strong> option:<div id="_idContainer229" class="IMG---Figure"><img src="Images/Figure_16.4_B17405.jpg" alt="Figure 16.4 – The Create stack button from the stacks listing page in CloudFormation&#13;&#10;" width="629" height="201"/></div><p class="figure-caption">Figure 16.4 – The Create stack button from the stacks listing page in CloudFormation</p></li>
				<li>Whichever way you got here, we should now be on the <strong class="bold">Create stack</strong> page in CloudFormation. On the second heading of the page, labeled <strong class="bold">Specify template</strong>, click on <strong class="bold">Upload a template from a file</strong>. When the <strong class="bold">Choose file</strong> button appears, select the <strong class="source-inline">vpc.yaml</strong> template to upload it. Then, click the <strong class="bold">Open</strong> button in the dialog box. Once the file has been uploaded, you can click the orange <strong class="bold">Next</strong> button.</li>
				<li>This will <a id="_idIndexMarker1380"/>bring you to the <strong class="bold">Specify stack details</strong> page. Use <strong class="source-inline">Chapter16-VPC</strong> when naming your stack. This name will be important as this stack will create some of the resources that will be used by the next stack, and it will reference those resources by the name of the stack. Once <a id="_idIndexMarker1381"/>you have entered the name, click the orange <strong class="bold">Next</strong> button at the bottom of the page. </li>
				<li>On the <strong class="bold">Configure stack options</strong> page, scroll down to the bottom and hit the orange <strong class="bold">Next</strong> button. </li>
				<li>At this point, we will be on the <strong class="bold">Review</strong> page for the first <strong class="source-inline">Chapter16-VPC</strong> stack. Scroll down to the bottom of the page and fill in the box under the <strong class="bold">Capabilities</strong> section, acknowledging that this template will create an IAM role. After this, you can click the orange <strong class="bold">Create stack</strong> button so that our initial stack can be initialized and created. </li>
				<li>Clicking on the <strong class="bold">Create stack</strong> button should take you to the <strong class="source-inline">Chapter16-VPC</strong> stacks page of the CloudFormation service. Once the stack has been created, go to <strong class="bold">Outputs</strong> via the horizontal menu. At this point, you should see the six outputs that the VPC stack has created, including the VPCid, two private subnets, and two public subnets:<div id="_idContainer230" class="IMG---Figure"><img src="Images/Figure_16.5_B17405.jpg" alt="Figure 16.5 – The outputs from the initial stack creation&#13;&#10;" width="870" height="585"/></div><p class="figure-caption">Figure 16.5 – The outputs from the initial stack creation</p></li>
				<li>With <a id="_idIndexMarker1382"/>our VPC template created and showing the outputs, we can move on to our next template. This next template will set up the Load Balancer, along with two EC2 instances running the Apache web server. Each server is running a static web page, but you will know the difference if you are being directed to instance number one or instance number two based on the page displayed. </li>
				<li>Since we are already on the <strong class="bold">CloudFormation</strong> page of the <strong class="bold">Outputs</strong> section, we can simply go to the top right-hand corner and click on the white <strong class="bold">Create stack</strong> button. When the drop-down list appears, choose the <strong class="bold">With new resources (standard)</strong> option. </li>
				<li>Now, back on the <strong class="bold">Create Stack</strong> page, under the <strong class="bold">Specify Template</strong> section, choose <strong class="bold">Upload a template file</strong>. Then, click on the <strong class="bold">Choose File</strong> button that appears and select the <strong class="source-inline">cross-stack-website.yaml</strong> template to upload it. Once the template has been uploaded, click on the orange <strong class="bold">Next</strong> button at the bottom of the page. </li>
				<li>You should now be on the <strong class="bold">Specify stack details</strong> page. It's time to name our new stack. The suggested name for this stack is <strong class="source-inline">Chapter16-Elastic Load Balancer</strong>. Enter this value in the <strong class="bold">Stack name</strong> box.</li>
				<li>You will <a id="_idIndexMarker1383"/>also see a box for parameters. It should already be filled out with <strong class="source-inline">Chapter16-VPC</strong>. You won't need to change this value if you named your previous stack <strong class="source-inline">Chapter16-VPC</strong>. If you named it something other than this, then you will need to provide the name here, as this is the value that drives all intake for the outputs we saw earlier. Once you have filled in your values, click the orange <strong class="bold">Next</strong> button at the bottom of the page: <div id="_idContainer231" class="IMG---Figure"><img src="Images/Figure_16.6_B17405.jpg" alt="Figure 16.6 – The Stack name and Parameters fields on the Specify stack details page&#13;&#10;" width="1049" height="404"/></div><p class="figure-caption">Figure 16.6 – The Stack name and Parameters fields on the Specify stack details page</p></li>
				<li>At this point, you will be taken to the <strong class="bold">Configure stack options</strong> page. There is nothing to configure on this page, so we will scroll down to the bottom of the page and click the orange <strong class="bold">Next</strong> button. </li>
				<li>Finally, we will be on the <strong class="bold">Review stack</strong> page. Briefly look over the options you have chosen for your stack. If you don't see any errors, then click on the orange <strong class="bold">Create stack</strong> button at the bottom of the page. </li>
				<li>It will take a few minutes for our stack to be created as it is creating the two EC2 instances and installing the software and web page. It is also creating a classic Load Balancer, registering those instances with that Load Balancer, and performing the initial health checks. </li>
				<li>Once the stack has completed, click on <strong class="bold">Outputs</strong> from the horizontal menu, as we did with the previous stack. This time, you will find the URL of a key there and the value of the public URL for the Elastic Load Balancer. Right-click on the URL to open it in a new tab. </li>
				<li>Now, click on the <strong class="bold">Resources</strong> menu item in the same horizontal menu where you found <strong class="bold">Outputs</strong>. Click on the <strong class="bold">Physical ID</strong> link for the Elastic Load Balancer so that you are taken directly to the Elastic Load Balancer's details page:<div id="_idContainer232" class="IMG---Figure"><img src="Images/Figure_16.7_B17405.jpg" alt="Figure 16.7 – The resource listing of the ELB shown in CloudFormation&#13;&#10;" width="1176" height="157"/></div><p class="figure-caption">Figure 16.7 – The resource listing of the Elastic Load Balancer shown in CloudFormation</p></li>
				<li>Now, scroll down to the bottom half of the screen until you find the <strong class="bold">Attributes</strong> heading. Under this heading, you will find the <strong class="bold">Access logs</strong> section. It should have a value next to it that is currently set to <strong class="bold">Disabled</strong>. Click the gray button labeled <strong class="bold">Configure Access logs</strong>.</li>
				<li>When the <a id="_idIndexMarker1384"/>dialog box appears, you will need to fill in the following values:<ul><li>Check the <strong class="bold">Enable Access logs</strong> box.</li><li>Change the interval in which the logs are being pushed to <strong class="bold">5 minutes</strong>.</li><li>Choose a name for a <strong class="bold">NEW</strong> S3 bucket where the Elastic Load Balancer access logs can be stored.</li><li>Check the box to have the S3 bucket created for you:</li></ul></li>
			</ol>
			<div>
				<div id="_idContainer233" class="IMG---Figure">
					<img src="Images/Figure_16.8_B17405.jpg" alt="Figure 16.8 – Configure access logs&#13;&#10;" width="782" height="447"/>
				</div>
			</div>
			<p class="figure-caption">Figure 16.8 – Configure access logs</p>
			<p>Once you have <a id="_idIndexMarker1385"/>filled out all the values, click on the blue <strong class="bold">Save</strong> button. </p>
			<ol>
				<li value="1">Now, with the logs turned on, it is time to go back to the browser tab that you opened previously that contained the URL for the Elastic Load Balancer. Refresh the page multiple times; if both servers came up healthy for the Elastic Load Balancer, then you should see a mix of server one and server two appear on the screen. </li>
				<li>Once you have generated some traffic, we can start to navigate to the S3 bucket that we created for our Elastic Load Balancer access log storage. However, remember that the logs are only pushed once every 5 minutes, so you might need to be a bit patient as you wait for the logs to appear. </li>
				<li>At this point, it's time to navigate to the S3 service and find the name of the bucket you created to store your Elastic Load Balancer access logs. Click the name of the bucket. You should see a <em class="italic">folder</em> named <strong class="source-inline">AWSLogs</strong> and then a <em class="italic">subfolder</em> underneath that is numerically named based on an account number. In that account folder, there should be further subfolders named <strong class="source-inline">elasticloadbalancing</strong> and then subfolders based on region, year, month, and day. Finally, you will get to the log files. Click on one of the log files, download it, and open it in Textpad or Notepad.</li>
			</ol>
			<p>With that, we've learned how to enable logs and see the traffic patterns coming from our Elastic Load Balancers. Don't take down this set of CloudFormation templates just yet, however. We <a id="_idIndexMarker1386"/>are going to use the VPC that we created here in the next section to examine VPC Flow Logs. But first, let's look at the use cases for Elastic Load Balancer logs. </p>
			<h2 id="_idParaDest-396"><a id="_idTextAnchor406"/>Use cases for Elastic Load Balancer logs </h2>
			<p>You may be <a id="_idIndexMarker1387"/>wondering why you would be interested in turning on Elastic Load Balancer logs when you could get information such as a client's address from your application's log files? Let's look at a few use cases in detail:</p>
			<ul>
				<li>Understanding the latency from requests – how long it takes to respond to a request.</li>
				<li>Monitoring access requests – where the requests are coming from and going to.</li>
				<li>Measuring how efficient the operation is between the client and the resources – are there any bottlenecks in the process that can be detected easily?</li>
			</ul>
			<p>Now that we understand when we would use Elastic Load Balancer logs, let's look at VPC Flow Logs. </p>
			<h1 id="_idParaDest-397"><a id="_idTextAnchor407"/>Using VPC Flow Logs </h1>
			<p>Flow logs <a id="_idIndexMarker1388"/>help you capture information regarding the IP traffic going in and out of the network interfaces <a id="_idIndexMarker1389"/>of your <strong class="bold">Virtual Private Cloud</strong> (<strong class="bold">VPC</strong>). Once this data has been captured, it can be written to either an S3 bucket or pushed out to a CloudWatch log group. </p>
			<p>Once a flog log group has been created and has started writing logs, the logs do not appear immediately. It can take up to 5 minutes for the logs to appear in either the S3 bucket or the log group: </p>
			<div>
				<div id="_idContainer234" class="IMG---Figure">
					<img src="Images/Figure_16.9_B17405.jpg" alt="Figure 16.9 – VPC Flow Logs traveling to and from different sources &#13;&#10;" width="529" height="371"/>
				</div>
			</div>
			<p class="figure-caption">Figure 16.9 – VPC Flow Logs traveling to and from different sources </p>
			<p>Flow logs can<a id="_idIndexMarker1390"/> be created for network interfaces. These include the network interface of a VPC itself or even other services that contain network interfaces, such as <a id="_idIndexMarker1391"/>the following:</p>
			<ul>
				<li>Elastic Load Balancers </li>
				<li>Amazon RDS databases </li>
				<li>Amazon ElastiCache caches</li>
				<li>Amazon Redshift databases</li>
				<li>Amazon WorkSpaces </li>
				<li>Transit Gateway </li>
				<li>NAT Gateway</li>
			</ul>
			<p>Now that we understand what VPC Flow Logs are and what they can be attached to, let's see what kind of limitations they have before we set up the flow logs on the VPC we stood up earlier. </p>
			<h2 id="_idParaDest-398"><a id="_idTextAnchor408"/>Limitations regarding VPC Flow Logs </h2>
			<p>Although <a id="_idIndexMarker1392"/>VPC Flow Logs allow you to capture most traffic either coming from or going to the different network interfaces in your <strong class="bold">VPC</strong>, there <a id="_idIndexMarker1393"/>are cases where this isn't possible. Let's take a quick look at those. In this case, if one of these scenarios comes up either in the DevOps professional exam or in real life, we know that flow logs would not be the optimal solution. An example of this is when flow logs cannot be enabled for peered VPCs unless the VPCs have been peered within the same account. Another thing to note is that Flow Logs do not capture all IP traffic. There is specific traffic that is <em class="italic">dropped</em> and specifically not captured by the flow log files:</p>
			<ul>
				<li>Any traffic from instances trying to contact the Amazon DNS server.</li>
				<li>Any traffic from a Windows instance for Amazon Windows license registration.</li>
				<li>All traffic to and from <strong class="source-inline">169.254.169.254</strong> for metadata information</li>
				<li>All traffic to and from <strong class="source-inline">169.254.169.123</strong> for the Amazon Time Sync service</li>
				<li>Any DHCP traffic</li>
				<li>Any traffic to the VPC router that travels on a reserved IP address</li>
				<li>All traffic between an endpoint network interface and a Network Load Balancer interface</li>
			</ul>
			<h2 id="_idParaDest-399"><a id="_idTextAnchor409"/>Enabling VPC Flow Logs </h2>
			<p>As we<a id="_idIndexMarker1394"/> mentioned previously in our previous hands-on exercise, we are going to use the same <strong class="bold">VPC</strong> that we stood up in this hands-on exercise to capture the VPC Flow Logs. </p>
			<p>When you create a flow log, you need to specify the following items:</p>
			<ul>
				<li>The AWS resource that you want to have</li>
				<li>If you wish to capture accepted traffic, rejected traffic, or all the traffic in the flow log</li>
				<li> Where you want the data to be published to (an S3 bucket or CloudWatch Logs)</li>
			</ul>
			<p>Let's get started: </p>
			<ol>
				<li value="1">Start by<a id="_idIndexMarker1395"/> going to the <strong class="bold">CloudWatch</strong> service. On the left-hand menu, find <strong class="bold">Logs</strong> and click on <strong class="bold">Log groups</strong>. </li>
				<li>At the top right, click on the orange <strong class="bold">Create log group</strong> button. </li>
				<li>Create a log group called <strong class="source-inline">FlowLogs</strong>. You can change the retention settings to allow the logs to expire after 7 days (1 week). Once you have updated these settings, scroll to the bottom of the page and click the orange <strong class="bold">Create</strong> button. </li>
				<li>Navigate back to the <strong class="bold">CloudFormation Service</strong> page. From your stacks listing, find the stack that we created called <strong class="screen-inline">Chapter16-VPC</strong>. Click on this stack name to get to the details of this stack.</li>
				<li>Then, from the top horizontal menu of the stack, click on the <strong class="bold">Resources</strong> menu item. Once the table of resources appears, scroll down until you find the listing for the VPC (it might be near the bottom since it was one of the first resources we created). Click on the blue <strong class="bold">Physical ID</strong> link for the VPC to be taken to the VPC. (Make a note of the physical ID before you click it; remember the last 4 alphanumeric characters of the VPC).</li>
				<li> Once you are on the  <strong class="bold">Your VPCs</strong> page, <em class="italic">check</em> the box to the right of the name of the VPC. Once the box has been checked, click on the white button named <strong class="bold">Actions</strong> at the top right of the screen. Once you've done this, a drop-down menu should appear. Select the <strong class="bold">Create flow log</strong> menu item.</li>
				<li>At this point, you will be brought to the <strong class="bold">Create flow log</strong> page. Use the following settings to fill out the flow log options:<ul><li><strong class="bold">Filter</strong>: <strong class="source-inline">All</strong> </li><li><strong class="bold">Maximum aggregation interval</strong>: <strong class="source-inline">1 minute</strong></li><li><strong class="bold">Destination</strong>: <strong class="screen-inline">Send to CloudWatch Logs</strong> </li><li><strong class="bold">Destination Log Group</strong>: <strong class="source-inline">FlowLogs</strong> </li><li><strong class="bold">IAM Role</strong>: (search for <strong class="source-inline">VpcFlowLogRole</strong>)</li></ul></li>
				<li>After you have filled out all these settings, click the orange <strong class="bold">Create flow log</strong> button. </li>
				<li>Now, it's time<a id="_idIndexMarker1396"/> to go back to your Elastic Load Balancer URL and send some traffic to the websites that have been loaded on the EC2 instances. Doing this will generate logs for the VPC Flow Logs. Once you have generated some traffic, go back to the CloudWatch Log group called <strong class="screen-inline">FlowLogs</strong> and look at the records that it generated.</li>
			</ol>
			<p>We just learned how to create a custom CloudWatch log group and turn on VPC Flow Logs so that we could capture traffic from our VPC. Next, we will look at some use cases when it makes sense to turn VPC Flow Logs on. </p>
			<h2 id="_idParaDest-400"><a id="_idTextAnchor410"/>Use cases for VPC Flow Logs </h2>
			<p>With so many<a id="_idIndexMarker1397"/> types of logs available, let's look at some clear use cases for using VPC Flow Logs. </p>
			<h3>Using VPC Flow Logs to monitor remote logins</h3>
			<p>Remotely<a id="_idIndexMarker1398"/> logging in to instances on your cloud infrastructure should only be done through authorized personnel, as well as trusted addresses. You can use VPC Flow Logs to see what users and IP <a id="_idIndexMarker1399"/>addresses are gaining access to or trying to gain access to via protocols<a id="_idIndexMarker1400"/> such as <strong class="bold">Remote Desktop Protocol</strong> (<strong class="bold">RDP</strong>) or <strong class="bold">Secure Shell Access</strong> (<strong class="bold">SSH</strong>).</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You can connect to AWS Mac instances<a id="_idIndexMarker1401"/> using a <strong class="bold">Virtual Network Connection</strong> (<strong class="bold">VNC</strong>) client; however, this type of connection is insecure. To make the connection secure, you can wrap the connection in an SSH tunnel, as mentioned <a id="_idIndexMarker1402"/>here: <a href="https://aws.amazon.com/premiumsupport/knowledge-center/ec2-mac-instance-gui-access/">https://aws.amazon.com/premiumsupport/knowledge-center/ec2-mac-instance-gui-access/</a>.</p>
			<h3>Detecting threats with VPC Flow Logs </h3>
			<p>If you <a id="_idIndexMarker1403"/>choose to capture all events, both ingress and egress, with VPC Flow Logs, then you can detect threats to your environment such as port scans being performed on your network, network scans, someone trying to look for weakness or entry points into your system, or data being pushed out to unauthorized sources. </p>
			<p>If you find that your system has been impacted by an event, then you can use VPC Flow Logs to trace the path that the offender took through the network. </p>
			<h3>Diagnosing and troubleshooting network issues</h3>
			<p>With layered <a id="_idIndexMarker1404"/>security, there will be times <a id="_idIndexMarker1405"/>where you are trying to figure out why access to a particular instance or service is not being allowed, which is troublesome. </p>
			<h3>Gaining an understanding of your network traffic</h3>
			<p>You can <a id="_idIndexMarker1406"/>use VPC Flow Logs to analyze how the users of your network and AWS account are behaving and generate reports of any unsafe behavior that might be occurring. This can include using unprotected ports or allowing access from the world, rather than restricting access to origin assets to specific IP addresses and leaving world access to content delivery servers such as CloudFront. </p>
			<p>Now that we've looked at the various use cases for VPC Flow Logs, we will turn our attention to the initial logs that we looked at – CloudTrail logs.</p>
			<h2 id="_idParaDest-401"><a id="_idTextAnchor411"/>Going back to our CloudTrail logs</h2>
			<p>Now that we have <a id="_idIndexMarker1407"/>created some resources through the exercises we have performed in the chapter, as well as several different API calls, we can go back to our CloudTrail logs and see how they have been populated with events. </p>
			<h2 id="_idParaDest-402"><a id="_idTextAnchor412"/>Searching through CloudTrail logs </h2>
			<p>Since we <a id="_idIndexMarker1408"/>have performed enough activities to generate CloudTrail logs at this point, we will start to search through our logs to see what we have captured: </p>
			<ol>
				<li value="1">Navigate back to the <strong class="bold">CloudWatch</strong> service. From the left-hand menu, find <strong class="bold">Logs</strong>, but this time click on the submenu named <strong class="bold">Log Insights</strong>. </li>
				<li>From the drop-down menu for selecting log groups, choose the <strong class="bold">CloudTrail</strong> log group. </li>
				<li>Place the following query in the query box and then press the orange <strong class="bold">Run query</strong> button:<p class="source-code"><strong class="bold">filter eventSource="ec2.amazonaws.com"</strong></p><p class="source-code"><strong class="bold">| stats count(*) as eventCount by eventName, awsRegion</strong></p><p class="source-code"><strong class="bold">| sort eventCount desc</strong></p></li>
				<li>You should see a graphic similar to the following: <div id="_idContainer235" class="IMG---Figure"><img src="Images/Figure_16.10_B17405.jpg" alt="Figure 16.10 – The CloudWatch logs insights visualization graph&#13;&#10;" width="1163" height="264"/></div><p class="figure-caption">Figure 16.10 – The CloudWatch Logs insights visualization graph</p></li>
				<li>You can try and see what other things you can find in your CloudTrail log if you like. </li>
			</ol>
			<p>With that, we've learned how to query CloudTrail logs using CloudWatch Log Insights. Now, let's clean up the resources we created before we summarize this chapter. </p>
			<h1 id="_idParaDest-403"><a id="_idTextAnchor413"/>Cleaning up the resources</h1>
			<p>We created<a id="_idIndexMarker1409"/> a lot of resources in this chapter that, if left up and running, may leave you with a higher AWS bill than you may expect. After completing this chapter, be sure to delete the CloudFormation templates that were used to create the instances and Elastic Load Balancer. </p>
			<h1 id="_idParaDest-404"><a id="_idTextAnchor414"/>Summary</h1>
			<p>In this chapter, we looked at three different sources of logs that can provide information for your AWS accounts that are not CloudTrail or application logs. Initially, we learned how to set up a CloudTrail trail to record all the API calls that happen inside of an account. Next, we looked at Elastic Load Balancer access logs and how they record the IP addresses, time, and responses coming into an Elastic Load Balancer. Finally, we looked at how VPC Flow Logs can capture network traffic from a variety of network interfaces. </p>
			<p>In the next chapter, we will wrap up our discussion on logging by going over how enterprises complement the AWS services that capture logs. Then, we'll learn how log storage and advance searching are handled. </p>
			<h1 id="_idParaDest-405"><a id="_idTextAnchor415"/>Review questions </h1>
			<ol>
				<li value="1">You are working as a DevOps engineer at a company that has implemented multiple CI/CD pipelines. One pipeline is used to push out the application code and its features. Another pipeline is used to update the underlying infrastructure and security settings of the account. After the last set of security group updates for the application, all the users at one of the company's remote offices can no longer access the instances in the autoscaling group. These users can still access the application from the web protocol via the Elastic Load Balancer. These users contain members of multiple IAM groups, including developers, power users, and even an administrator. Where can you go for information to try and find out where the issue is occurring?<p>a. Gather the IAM usernames that have been denied access. Use these usernames to search through the IAM log group in CloudWatch. </p><p>b. Make sure that VPC Flow Logs have been turned on. Search the VPC Flow Logs for both the internal and external IP addresses for the remote office. </p><p>c. Gather the IAM usernames that have been denied access. Go to the CloudTrail service and search for the usernames to find denial. </p><p>d. Turn on logging to the application's Elastic Load Balancer. Check the Elastic Load Balancer logs for both the internal and external IP addresses for the remote office.</p></li>
				<li>You have been brought into a company that is about to make a major production push and release of their application. As part of this release, they are implementing a new governing model that requires all activity on the AWS account to be monitored. How can you quickly and effectively help the company achieve this goal?<p>a. Set up the Amazon Inspector service to constantly inspect all of the activity happening on the account. </p><p>b. Turn on VPC Flow Logs for all the VPCs, making sure that you are capturing both inbound and outbound traffic. </p><p>c. Set up the AWS CloudTrail service to monitor and record all the activity in all regions. </p><p>d. Create a designated CloudWatch Logs log group so that any creation or termination events can be filtered specifically to this log group. </p></li>
			</ol>
			<h1 id="_idParaDest-406"><a id="_idTextAnchor416"/>Review answers </h1>
			<ol>
				<li value="1">b </li>
				<li>c</li>
			</ol>
		</div>
	</div></body></html>