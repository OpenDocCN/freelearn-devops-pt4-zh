- en: 'Chapter 18: Autoscaling and Lifecycle Hooks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the critical features of automation is taking advantage of autoscaling.
    Although many use this **Amazon Web Services** (**AWS**) service in its essential
    capacity, the educated **Development Operations** (**DevOps**) professional understands
    and takes advantage of some of the more advanced capabilities that Auto Scaling
    can provide. Insight into these components will not only help you pass the certification
    exam but will also allow you to manage your AWS environment more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding AWS Auto Scaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying **Elastic Compute Cloud** (**EC2**) instances with Auto Scaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Auto Scaling lifecycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Auto Scaling lifecycle hooks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding AWS Auto Scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Auto Scaling, which is a subset of the **Amazon EC2 service**, revolves around
    automatically provisioning and managing your EC2 instances without the need for
    any manual intervention. The Auto Scaling service can be used to constantly maintain
    a fixed number of servers at any one time across one or more **Availability Zones**
    (**AZs**) within an Amazon Region. The service also provides you elasticity in
    that it can scale up to meet spikes of demand that your customers or applications
    present without constantly monitoring the system.
  prefs: []
  type: TYPE_NORMAL
- en: It does this by tapping into the power of a complementary service, Amazon CloudWatch.
    It watches a metric such as **Central Processing Unit** (**CPU**) utilization
    on an instance and makes sure that if it rises above 80 percent, meaning that
    80 percent of the available CPU of the instance is being used for a specific time,
    such as 5 minutes, a scale-out event will then occur. This helps ease the load
    on this particular instance and should bring the total percent of CPU utilization
    back under that 80 percent threshold once the new instance comes online.
  prefs: []
  type: TYPE_NORMAL
- en: The Auto Scaling service is constantly performing periodic health checks on
    the instances in its **Auto Scaling Group** (**ASG**). The time between health
    checks can be configured, but the default setting is 300 seconds (5 minutes).
    You also configure how many health checks an instance can fail before it is taken
    out of the ASG for being unhealthy. On a similar note, whichever number of health
    checks that an instance must fail in order to be removed from the ASG is the same
    number of health checks that it must pass before being added as a healthy instance
    to the ASG.
  prefs: []
  type: TYPE_NORMAL
- en: Auto Scaling also plays a key component in infrastructure event planning. If
    you know that you are about to have an increase in customer traffic, such as the
    marketing department has bought a television spot on a popular television show
    or there is a special sale about to happen, then you can simply increase both
    the desired capacity and the maximum capacity of your ASG to ensure that your
    customers not only have a good experience but also that your servers do not get
    overloaded.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a basic understanding of the Auto Scaling service, let's look
    at the key components that make up this service.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the differences between vertical and horizontal scaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we discuss the Auto Scaling service throughout this chapter, we will be talking
    about how to horizontally scale your instances in and out to meet the demands
    of your workload. This is usually a more cost-efficient way to scale and gain
    resources as you can benchmark your workload and know how much memory and CPU
    that your workload actually needs. This leads to a number of benefits, including
    your workload having a much higher availability since there are multiple instances
    or containers running the application at the same time. This prevents the instance
    (or container) that was scaled up vertically from becoming a **Single Point of
    Failure** (**SPoF**). You also don't have a limit on hardware. With vertical scaling,
    there comes a point in time when you will hit a resource limit. Although there
    are instances in AWS that have massive amounts of **Random-Access Memory** (**RAM**)
    and large numbers of CPUs, this is not a way to correctly construct and deploy
    your application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The processes of horizontal and vertical scaling are depicted in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.1 – Horizontal scaling versus vertical scaling'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_18.1_B17405.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 18.1 – Horizontal scaling versus vertical scaling
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know the differences between horizontal and vertical scaling, let's
    take a look at the key components of AWS Auto Scaling.
  prefs: []
  type: TYPE_NORMAL
- en: The key components of Auto Scaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the main components of Auto Scaling is the ASG. This ASG is a logical
    group of instances for your application or service. You set three main variables
    for the ASG: the minimum number of instances, the maximum number of instances,
    and the desired number of instances. The minimum number of instances tells the
    ASG what is the lowest number of instances that can be running at any one time
    in a combination of all AZs specified. The maximum number of instances tells the
    ASG what is the greatest number of instances that it can allocate in that region.
    These maximums must stay within the service limits. Finally, the desired capacity
    is the number of running instances at any given moment in time if there are no
    scheduled actions or scaling events driven by scaling policies.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see a depiction of an ASG in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.2 – ASG visualization'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_18.2_B17405.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 18.2 – ASG visualization
  prefs: []
  type: TYPE_NORMAL
- en: Another key component of Auto Scaling is the **launch template**. The launch
    template determines which properties the instances inside the ASG will launch
    with. These properties are provided inside of the launch template. You can determine
    items such as the instance size, image **Identifier** (**ID**), **Virtual Private
    Cloud** (**VPC**) ID, along with others, when crafting your launch template.
  prefs: []
  type: TYPE_NORMAL
- en: If you have used ASGs in the past, then you may be familiar with launch configurations.
    Launch configurations are very similar to launch templates, but launch templates
    replaced launch configurations in a few respects. Firstly, launch configurations
    are immutable. Each time that you want to make a change to your launch configuration,
    you need to clone your launch configuration, make the change, and then attach
    it to the ASG. This is in contrast to launch templates. Launch templates allow
    for versioning. Launch templates also allow for the latest EC2 features, such
    as the use of unlimited T2 instances and **Elastic Block Store** (**EBS**) tagging.
  prefs: []
  type: TYPE_NORMAL
- en: ASGs are fully integrated with **Elastic Load Balancing** (**ELB**). It doesn't
    matter which one of the three types of ELBs that you use; ASGs fully integrate
    without issues. This means that if an ASG is associated with a load balancer,
    whenever an instance is provisioned, it will automatically get registered with
    the load balancer. Conversely, when an instance is either de-provisioned or terminated,
    the load balancer will drain the traffic from the instance and deregister the
    instance from the load balancer before terminating the instance.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have old launch configurations but would like to take advantage of the
    latest EC2 technology, then AWS has a documentation page on how to convert a launch
    configuration to a launch template. It can be found here: [https://docs.aws.amazon.com/autoscaling/ec2/userguide/copy-launch-config.html](https://docs.aws.amazon.com/autoscaling/ec2/userguide/copy-launch-config.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The final key component that we are going to discuss is going to be the **scaling
    plan**. A scaling plan can be set to use either predictive scaling or dynamic
    scaling. If you put your scaling plan to use predictive scaling, the ASG will
    use **Machine Learning** (**ML**) to look at how taxed your workload is, especially
    in respect to certain hours and days of the week, and then generates scheduled
    scaling actions so that your application has the capacity to meet those needs,
    as illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.3 – How predictive scaling works to schedule resources in Auto
    Scaling'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_18.3_B17405.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 18.3 – How predictive scaling works to schedule resources in Auto Scaling
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic scaling policies are the component that you configure when using dynamic
    scaling with a scaling plan.
  prefs: []
  type: TYPE_NORMAL
- en: It's important to note that even if your scaling calculation states that you
    should go beyond the maximum number of instances that you have set, that maximum
    is a hard limit and will not be surpassed by the scaling policy. You can raise
    the maximum number of instances if you hit the ceiling while scaling, or you may
    want to create a new version of your launch configuration to account for a different
    type or family of instances that may handle the type of traffic your application
    is receiving in a better fashion.
  prefs: []
  type: TYPE_NORMAL
- en: There is an old saying when it comes to Auto Scaling that you should *scale
    up like a rocket and down like a feather*. This is due to the fact that scaling
    up instances is expensive from a time perspective. If you are starting one or
    three instances based on a scaling event, they should all take the same amount
    of time to come online. Bringing in three instances will allow you to have a bit
    more capacity rather than scaling up a single instance at a time. If that capacity
    is unjustified, then you can scale down a single instance at a time in order to
    keep your spending at an appropriate level using Auto Scaling.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you plan out your ASG, you want to take into consideration the following
    factors:'
  prefs: []
  type: TYPE_NORMAL
- en: How long does it take to launch and configure a server that will be part of
    the ASG?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which metrics would be most applicable when monitoring your workload's performance?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do you want the ASG to span multiple AZs? If so, how many?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What type of role should Auto Scaling play in your application?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the key components of Auto Scaling under our belt, let's look at the main
    use cases for AWS Auto Scaling.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the different types of Auto Scaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon's EC2 Auto Scaling gives you a number of options on how you can scale
    your instances to meet both the demand of your business and the goals of your
    budget.
  prefs: []
  type: TYPE_NORMAL
- en: If you wanted total control of how to scale your instances, then you can use
    **manual scaling**. With the use of manual scaling, you would set the minimum,
    maximum, and desired capacity to what you desire for your workload, and your ASG
    will adjust accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: There are also times when the traffic that is coming to your workload is rather
    predictable. These may be cases where your customers are more active during normal
    business hours, or you may have business workloads that you use internally, and
    your staff that uses the workloads are all in one or two particular time zones.
    These are perfect cases for the use of **scheduled scaling**. With the use of
    scheduled scaling, your ASG will scale in and out automatically based on the times
    and dates that you set.
  prefs: []
  type: TYPE_NORMAL
- en: If you want your ASG to automatically scale out when there is a high demand
    for the application's services along with scaling back in when that same demand
    has diminished, then this is a case for **dynamic scaling**. Dynamic scaling allows
    you to choose a specific metric that matters to your application and set a percentage
    whereby once that percentage has been reached, the associated CloudWatch alarm
    on the metric will be triggered and one or more instances will be launched so
    that they can be added to the ASG. In the same vein, if you have previously scaled
    up capacity in response to a particular metric and that metric has fallen to a
    level where it is being underutilized, then the scaling policy will look at which
    one of the instances it should start to put in a terminating state. Based on your
    configuration, this could be the oldest instance, the newest instance, or even
    the instance that is closest to the next billing hour.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic scaling also allows you to put in **step scaling**. These step adjustments
    can vary based on the type of metric alarm breach, meaning that you can scale
    up to multiple instances at once if you have a large spike in traffic if your
    maximum capacity allows.
  prefs: []
  type: TYPE_NORMAL
- en: Taking the properties of dynamic scaling one step further is **predictive scaling**.
    Predicative scaling analyses your traffic over time and then increases and decreases
    the number of EC2 instances in your ASG based on these trends. Predictive scaling
    is a good choice when you can't decide exactly which metric would be best suited
    to your application's needs or you have applications that take a long time to
    initialize. It can also be a wise choice if you have workloads that seem to come
    up and down, such as batch processing. The predictive scaling analysis can analyze
    these workloads and decide when it would be best to bring on more capacity.
  prefs: []
  type: TYPE_NORMAL
- en: We have just looked at the different ways in which ASGs can be set and adjusted
    to accommodate the influx of traffic for our workloads. Now, let's look at the
    primary use cases for Auto Scaling.
  prefs: []
  type: TYPE_NORMAL
- en: The four primary use cases for AWS Auto Scaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are four popular use cases that Auto Scaling solves for customers, outlined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It automates the provisioning of servers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It reduces paging frequency.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It makes it easier to use spot instances.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It allows you to scale your cloud infrastructure up and down and save costs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we know some of the main use cases for using Auto Scaling, let's look
    at how we can put ASGs into action by creating our own launch template.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying EC2 instances with Auto Scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The best way to get a full understanding of a service is to jump in hands-on
    to see how it performs, and the Auto Scaling service is no different. In this
    hands-on exercise, we will create a launch template for our ASG. We will then
    create an ASG. Follow these next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Log on to the **Amazon Management Console** using your administrative user account.
    Once logged in, navigate to the EC2 service. Once on the EC2 service, locate and
    click on the **Launch Templates** sub-menu item on the left-hand menu, which is
    located under the **Instances** menu heading.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you are on the EC2 **Launch Templates** main screen, click on the orange
    **Create launch template** button in the main window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We should now be on a screen labeled `chapter18`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`version 1`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Auto Scaling guidance**—Check the box, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.4 – The first section of the launch template completed'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_18.4_B17405.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 18.4 – The first section of the launch template completed
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, scroll down the page for the next box of selection criteria. We will
    fill out the rest of the fields using the following values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`t2.micro`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Key pair (login)**—Don''t include this in the launch template.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network settings**—**VPC**.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Go to Network settings** | **Security groups** and choose your default security
    group.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you have completed filling out all of the values, we can then click the
    orange **Create launch template** button. You should see that you have successfully
    created a launch template at this time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the link in the middle of the page under the **Create an Auto Scaling group
    from your template** heading to be brought to the **Auto Scaling** section where
    we can create our new ASG, as illustrated in the following screenshot:![Figure
    18.5 – Create an Auto Scaling group section once you have completed your launch
    template
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_18.5_B17405.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 18.5 – Create an Auto Scaling group section once you have completed your
    launch template
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You should now be at the `eighteen`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the next box, labeled `chapter18`) from the drop-down list. Click the orange
    **Next** button at the bottom of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the **Configure settings** screen, just leave all the default options, including
    the default VPC. We will not be using any spot instances or extra VPCs in this
    exercise. In the **Network** box, add all three subnets in your default VPC by
    selecting one after the other until all three appear underneath the selection
    dropdown. After all the subnets have been added, click on the orange **Next**
    button at the bottom of the page, as illustrated in the following screenshot:![Figure
    18.6 – Adding the three subnets from the default VPC to the ASG
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_18.6_B17405.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 18.6 – Adding the three subnets from the default VPC to the ASG
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, at the `300` to `30` seconds. Once you have made this change, click the
    orange **Next** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the `1`, `1`, and `3`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scroll down to the `18 ASG Policy`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Average network in (bytes)`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`5000`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following screenshot illustrates this process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.7 – The scaling policy with metric for our ASG'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_18.7_B17405.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 18.7 – The scaling policy with metric for our ASG
  prefs: []
  type: TYPE_NORMAL
- en: Once you have filled out the values for the scaling policies, scroll down to
    the bottom of the page and click the white button labeled **Skip to review**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the **Review** page, scroll down to the bottom of the page and click the
    orange **Create Auto Scaling group** button to create our ASG.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you click the button, you should be taken to the **EC2** | **Auto Scaling
    groups** page where you will see the status of your group is initially **Updating
    capacity** as the first instance is being brought online.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you want to see your instance scale out, then you can do so by taking the
    following steps. In the `eighteen`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the horizontal menu bar, click on the `eighteen` ASG policy. Once this is
    selected, then using the **Actions** drop-down, choose **Edit**:![Figure 18.8
    – The horizontal menu bar on a single ASG highlighting Automatic scaling
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_18.8_B17405.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 18.8 – The horizontal menu bar on a single ASG highlighting Automatic
    scaling
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On the `5000` to `100`. Once you have changed this value, then click the orange
    **Update** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go back to the main **Auto Scaling groups** page and refresh as you see the
    instances come online to meet the *demand* of the incoming traffic.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have seen how to create both a launch configuration and an ASG in
    the real world, let's move on to gaining a fuller understanding of the Auto Scaling
    lifecycle and how it differs from just launching an EC2 instance.
  prefs: []
  type: TYPE_NORMAL
- en: The Auto Scaling lifecycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you put an **EC2 instance** into an ASG, it follows a particular path that
    a normal EC2 instance you initiate via the command line or the AWS Management
    Console does not follow. The instance starts by being launched by the ASG. If
    this is part of a **scale-out** event, then the instance has an opportunity to
    have special commands be performed on it via a **lifecycle hook**. Lifecycle hooks
    allow you to add custom actions when either launching or terminating instances
    that are part of an ASG. Once the instance becomes healthy, it is then **InService**
    and is part of the ASG. If that instance fails the set number of health checks,
    the instance can then go to a **Terminating** state. Moving to a Terminating state
    can also happen if there is not enough traffic or metric data to support having
    the number of instances currently running, in which case there could be a **scale-in**
    event. Once again, just as with a scale-out event, this scale-in event allows
    us to use a lifecycle hook.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Auto Scaling lifecycle process is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.9 – The Auto Scaling lifecycle process'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_18.9_B17405.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 18.9 – The Auto Scaling lifecycle process
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an understanding of the lifecycle of ASGs, let's take a deeper
    look at lifecycle hooks and when it would be most appropriate to use them.
  prefs: []
  type: TYPE_NORMAL
- en: Using Auto Scaling lifecycle hooks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we just looked at the Auto Scaling lifecycle, there are two states when an
    instance enters these states that allow for extra actions to occur. These two
    states are the `Terminating:Wait` state, you can have the instance pause for up
    to 30 minutes before moving on to the `Terminating:Proceed` state and then on
    to `Terminated`.
  prefs: []
  type: TYPE_NORMAL
- en: Use cases for lifecycle hooks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You may want to know some of the use cases for lifecycle hooks. Let's take a
    quick look at a few.
  prefs: []
  type: TYPE_NORMAL
- en: The first one is using the launching state to invoke a Lambda function. Once
    our instance has passed the pending state and gone on to the `Pending:Wait` state,
    we can use this event to call a specific Lambda function for our application.
    A good use for this would be if we had Windows instances and we needed to join
    each instance as it came up to a specific **Active Directory** (**AD**) domain
    and name server. As the instance entered in the initial lifecycle hook, it could
    run a script to get its **Domain Name System** (**DNS**) name as well as join
    the domain.
  prefs: []
  type: TYPE_NORMAL
- en: The same is true when we start the termination process of an instance. When
    you are terminating an instance, there are some cases where to want to be sure
    to capture all of the data from that set of applications before allowing the instances
    to proceed to the termination state.
  prefs: []
  type: TYPE_NORMAL
- en: As a word of caution, using complex scripts in lifecycle hooks can cause an
    extra amount of time between the time we have either requested a new instance
    to come online and join our ASG or be terminated and allow us to have more elasticity
    when we need it. Instances in the wait states still take up an instance worth
    of capacity when calculated against the total maximum size capacity of the ASG.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As with many of our other exercises, it is suggested that you terminate any
    running instances and clean up the ASG once you are done with this chapter so
    that you don't incur any unwanted charges on your AWS account.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at Auto Scaling and how it can automatically manage
    the demand that is presented to us by both internal and external customers. We
    took a look at the different ways in which ASGs could be configured using different
    scaling policies, and even went through the hands-on exercise of deploying an
    ASG. Lastly, we looked at the Auto Scaling lifecycle and how lifecycle hooks can
    help perform more complex tasks than just simple scaling.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will be starting the first of a few chapters focused
    on securing your environment and your pipeline by talking about protecting your
    data both in transit and at rest. This will especially cover the **Key Management
    Service** (**KMS**) and using **Amazon Certificate Manager** (**ACM**) for server-side
    certificates.
  prefs: []
  type: TYPE_NORMAL
- en: Review questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have been brought into a company that is running a business-critical workload
    using ELB and Auto Scaling. This workload is a two-tier application that consists
    of an application tier and a database tier. Both tiers are currently deployed
    across two AZs in the `us-east-1` region. The database needs to be replicated
    in a synchronous fashion from the application. The chief technical officer (CTO)
    has told you that the application must stay fully available even if a single AZ
    becomes unavailable and Auto Scaling cannot launch new instances in the remaining
    AZ. How can you establish this through AWS-specific services and architecture?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the configuration in ELB to deploy in three AZs with Auto Scaling set to
    deploy to handle 33 percent of the load per zone at peak.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the configuration in ELB to deploy in three AZs with Auto Scaling set to
    deploy to handle 50 percent of the load per zone at peak.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the configuration in ELB to deploy in two regions using the Round Robin
    algorithm with Auto Scaling set to deploy to handle 50 percent of the load per
    zone at peak.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the configuration in ELB to deploy in two regions using the Round Robin
    algorithm with Auto Scaling set to deploy to handle 100 percent of the load per
    zone at peak.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You have created a DevOps pipeline for an application that is running on EC2
    instances. Customers interact with this application via an application load balancer
    that is attached to an ASG. Since releasing the latest version of both the application
    and the launch template, the application seems to be scaling up and down multiple
    times each hour of the day. Which fixes should you and your team make in order
    to stabilize the ASG, preserve elasticity, and optimize costs? (Choose two answers)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify the application's ASG so that it uses scheduled scaling actions.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify the application's ASG termination policy to terminate the oldest instance
    first.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify the application's ASG cooldown timers so that they are bigger.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify the CloudWatch alarm associated with the application's ASG group so that
    there is a longer alarm period associated with the scale-down policy.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The company you work for has an application that consists of EC2 instances that
    are launched using an ASG. It has come to your attention that the EC2 instances
    are not scaling up as more demand is needed. How should you check and remedy the
    situation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check to make sure that the ASG is placing instances across multiple regions.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Check to make sure that the ASG is placing instances across multiple AZs.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Check to make sure that the ELB health checks are being utilized.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Check to make sure that the correct metrics are being measured to trigger the
    scale-out event.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Review answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: c, d
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: d
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
