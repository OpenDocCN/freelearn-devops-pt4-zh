- en: 'Chapter 24: Practice Exam 1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will have sample questions that are similar to the test so that
    you can become familiar with how to read and answer questions in the allotted
    time.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: SDLC automation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuration management and infrastructure as code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring and logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Policies and standards automation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incident and event response
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High availability, fault tolerance, and disaster recovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before you start to answer the following questions, it is suggested that you
    use a timer of some kind to keep track of how long it is taking you to answer
    each question. None of the questions are actual AWS test questions. They are,
    however, made to be in the format that the test appears in. This includes long
    scenario-type questions along with multiple-choice answers that are very similar.
    Small details can mean the difference between the correct answer and one of the
    incorrect answers.
  prefs: []
  type: TYPE_NORMAL
- en: Both the questions and answers are long. Many of the answers have the same components
    in them as well, which makes this different than some of the associate tests where
    you can just eliminate a few of the answers that you know are wrong and then pick
    the answer from the one or two that are left.
  prefs: []
  type: TYPE_NORMAL
- en: Test questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have developed a set of CloudFormation templates that can be used by your
    current company to deploy its middleware solution for processing files. This application
    is deployed to a number of EC2 spot instances, and there is a user data component
    of CloudFormation that downloads a number of scripts, including an initialization
    shell script from an S3 bucket to help configure those instances. The S3 bucket
    that holds the scripts has versioning enabled. The only known copy of the scripts
    at the company is located in that S3 bucket. A new intern accidentally deletes
    the script when trying to upload a different static asset to the bucket. What
    is the quickest way to restore the script so that the servers may be redeployed
    using the CloudFormation templates?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. You will need to recreate the script and upload it with the same name to
    the S3 bucket. With file versioning enabled, you can only see the differences
    between files, not recovered deleted files.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. You will need to make a modification to the CloudFormation scripts so that
    they use the previous version ID of the script, which got deleted in the S3 bucket.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. You will need to go into the AWS Management Console, navigate to the S3 bucket
    that holds your deployment scripts, and then choose the List versions option.
    You can then find the script that was deleted and remove the delete marker.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. You will need to go into the AWS Management Console, navigate to the S3 bucket
    that holds your deployment script, and then choose the List versions option. You
    can then download the previous version of the script, which was deleted. After
    the script has been downloaded, you can then upload it back up to the bucket and
    rename it the original script name so that the EC2 instances can find it from
    the CloudFormation template.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You are part of a team that has recently developed a Spring Boot application
    and is ready to deploy it to the AWS cloud. Because the traffic to the application
    varies, you have configured the application to be launched in an Auto Scaling
    group. It is important to make sure that the application is running, so you have
    created a Bash script that will run on each EC2 instance and check the application's
    health periodically. If the instance is unhealthy, then it should be marked as
    such, and that instance should be replaced by a new, healthy one. What is the
    best way to construct the Bash script to perform this task?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Construct the script to reboot the instance if the health check fails. Run
    the script as the root user. Once the Auto Scaling group detects the reboot, it
    will terminate the instance and then create a new instance in its place.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Construct the script to use the AWS CLI. Have the instance use the `autoscaling
    set-instance-health` command, letting the Auto Scaling group know that the instance
    is unhealthy. The Auto Scaling group will then terminate the instance and create
    a new one in its place.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Construct the script to use the AWS CLI. Have the instance use the `autoscaling
    put-notification-configuration` command to notify the Auto Scaling group that
    the instance is unhealthy. The Auto Scaling group will then terminate the instance
    and create a new one in its place.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Construct the script to use the AWS CLI. Have the instance use the `autoscaling
    enter-standby` command, letting the Auto Scaling group know that the instance
    is unhealthy. The Auto Scaling group will then terminate the instance and create
    a new one in its place.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have been brought into a company that has recently established configuration
    and tagging standards for the infrastructure resources that it is running on AWS.
    You have been asked to design and build a near-real-time dashboard showing the
    compliance standpoint that will emphasize any violations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Define the tagging and resource requirements in Amazon Inspector. Create
    a Simple Notification Service (SNS) topic to be notified if anomalies are found.
    Have Inspector check periodically for the compliance requirements and then send
    a notification to the SNS topic if found. Use AWS Security Hub to quickly visualize
    the violations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Create a customized CloudWatch metric to track all the resource and tagging
    standards. Use the CloudWatch service to create a dashboard to visually track
    any resources that do not meet the tagging standards.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Enable the AWS Config service and use the configuration recorder to record
    all resources that are created and deleted. Have the configuration changes sent
    to an S3 bucket. Use Amazon QuickSight to create turn the data in the S3 bucket
    into visual information and dashboards for analysis so non-compliant resources
    can be easily spotted.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Define multiple resource configurations in AWS Service Catalog. Use Amazon
    CloudWatch to monitor any compliance violations from Service Catalog. Use the
    CloudWatch service to create a dashboard to visually track any resources that
    do not meet the tagging standards.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have joined an application team that is moving their MySQL database from
    on-premises to the AWS cloud. This is a critical application, and therefore it
    needs more stability than the single on-premises server can give it. The application
    is read-intensive and has a 10/1 read-to-write ratio. Cost is the main objective,
    yet they do need to be aware of the project's budget. None of the current members
    of the team are skilled as DBAs, and all would rather focus on application development.
    What setup would you suggest to keep their database running should an Availability
    Zone fail in their current Region?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Create a MySQL RDS instance. When setting up the instance, choose the Multi-AZ
    feature. Once the data has been imported, then create a read replica and program
    the application to utilized the read replica for the heavy reads.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Create a MySQL RDS instance. Once the data has been imported, create a read
    replica in the alternate Region and program the application to utilized the read
    replica for the heavy reads.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Create a CloudFormation template that stands up an Auto Scaling group and,
    in the launch template, configures the MySQL server on each of the two EC2 instances
    in different Regions. Have the configuration make the MySQL service run in a Master-Master
    setup so that any of the servers could be pointed to in case of failure.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Create a CloudFormation template that stands up an Auto Scaling group and,
    in the launch template, configures the MySQL server on each of the two EC2 instances
    in different regions. Have a third smaller EC2 instance stood up as part of the
    template as a MySQL proxy so that the application servers can point to the proxy.
    The proxy will switch automatically between the current master and the slave.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have previously built a CI/CD pipeline in AWS CodePipeline for your team's
    application. With the current pipeline, there were automated stages for code checkout,
    build, test, deploy to dev, and deploy to test. You are now updating CodePipeline
    to add a new stage to Deploy to Prod and adding a manual approval for the product
    owner before the code is released into the production environment. On the initial
    test of the new stage, the product owner informed you that after logging into
    the AWS Management Console to the CodePipeline pipeline with their IAM user, they
    found that she did not have permission to approve the build. How can you remedy
    this issue?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Create a new SNS topic for the Deploy to Prod stage. Add the product owner
    to the topic. Have the product owner click the approval link in the SNS message
    when it is sent.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. From the AWS Management Console, go to the specific CodePipeline and add
    the product owner's IAM user as an approver for that pipeline.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. From the AWS Management Console, go to the IAM service. Create a new group
    called `CodePipeline Approvers`. Attach the `AWSCodePipelineFullAccess` managed
    IAM policy to the group. Add the product owner to the group.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. From the AWS Management Console, go to the IAM service. Create a new group
    called `CodePipeline Approvers`. Attach the `AWSCodePipelineApproverAccess` managed
    IAM policy to the group. Add the product owner to the group.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: An organization has moved its code versioning system for its developers to AWS
    CodeCommit. Teams of developers create and work on feature branches while testing
    and then create a pull request when ready to merge into the main branch. The organization
    has set guidelines that no one should be able to directly commit to the main branch.
    Any team member who is a developer is part of the IAM group developers. This group
    was recently modified to add the `AWSCodeCommitPowerUser` managed policy and now
    all members of this group are able to commit to the main branch of any repository
    in the organization's AWS CodeCommit. What steps need to be taken to prevent this
    and enforce the organization's guidelines?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Create an added IAM policy that would allow the `codecommit:GitPush` action.
    Add a condition to the policy that specifies the CodeCommit repositories in the
    resource statement.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Create an added IAM policy that would deny the `codecommit:GitPush` action.
    Add a condition to the policy that specifies the CodeCommit repositories in the
    resource statement.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Alter the IAM policy and remove the `codecommit:GitPush` action.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Alter the IAM policy and add a deny rule for `codecommit:GitPush` that specifies
    the specific repositories where push is not allowed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have configured AWS CodeDeploy to automate deployments to both EC2 instances
    in your development and test environments located in your AWS account, along with
    a few RHEL servers that are still located on-premises. There is a deployment group
    configured that defines each of the specific instances that are included for deployment.
    There has been an announcement stating that there will be a hardware refresh on-premises
    for one of the instances in the deployment group, which will take 2 weeks to complete.
    During this period, no new deployments should be pushed to these instances. Which
    method is the most suitable for enacting this 2-week freeze for the specific on-premises
    server?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Create a new deployment group with a tag that is only used by the user.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Verify the tags used by both the deployment groups. Use the AWS CLI to remove
    the specific instance that will be in service with the `aws deploy` `remove-tags-from-on-premises-instances`
    command.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Use the AWS CLI to deregister the on-premises instance from the CodeDeploy
    deployment using `deploy deregister`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Use the AWS CLI to uninstall the CodeDeploy agent from the on-premises instance
    using `deploy uninstall`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A DevOps engineer on your team has submitted the following `buildspec.yaml`
    file for security review. The security review failed. You have been tasked with
    helping the junior engineer to review the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 24.1 – The security review file
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 24.1 – The security review file'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_24.1_B17405.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What changes would you recommend that the junior DevOps engineer make so that
    the `buildspec` file complies with security best practices (choose three)?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a. Add permissions to the CodeBuild role so that the necessary actions can be
    performed during the build process. Remove the access key and secret key from
    the file.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Use KMS encryption for the environment variables so that they don't appear
    in plaintext on the file.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Write all environment variables to a file. Store the file in S3 and pull
    the file down at execution time so that the variables don't appear in plaintext
    on the file.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Use AWS Secrets Manager to store the `DB_PASSWORD` value. Remove the DB value
    from the environment values once stored and then retrieve them when needed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: e. Create a run command in Systems Manager that would perform the commands.
    Use System Manager instead of SSH and SCP directly from the instance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have been brought into a company that is expanding its presence on the AWS
    cloud. They want to build out their footprint using CloudFormation. However, they
    would like to use common components and patterns throughout their various applications.
    Many of the underlying components such as the infrastructure and networking will
    not be modified frequently after being generated. The company would like to manage
    all of the common component items independently and allow other application stacks
    to reuse the components when they need to. How can you achieve this objective?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Create a CloudFormation stack to hold all of the common resources. Other
    CloudFormation stacks will be able to use its resources by importing the resources
    from the AWS Management Console.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Create a CloudFormation stack to generate all of the common resources. Export
    the output values so that other CloudFormation stacks can import the values using
    the `GetAttribute` function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Construct a CloudFormation stack to generate all of the common resources.
    Export the output values so that other CloudFormation stacks can import the values
    using the `ImportValue` function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Create a CloudFormation stack to generate all of the common resources. Any
    application stack can be created as a nested stack from this stack to use all
    of the common resources.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A company has just launched a new booking service that has both a website and
    a mobile application. Thanks in part to the marketing team's effort, the service
    has been a smash hit with customers that have tried it and it keeps growing in
    popularity. The CTO has implemented a new directive for the upcoming quarter to
    make the application as efficient as possible and make any necessary tweaks to
    the performance. In order to achieve this, the development team will need to monitor
    all the different details of the application to see the root causes of any issues,
    errors, and latency issues. How can they achieve this using native AWS tools and
    services?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Configure Amazon Inspector to view the application. Periodically read the
    Inspector assessment reports for any latency issues found along with errors. Use
    timestamps to trace logs in CloudWatch Logs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Configure Amazon Elasticsearch to subscribe to the CloudWatch log groups
    for the application. Use Kibana to graph out the latency times from user click
    to application response. Create a custom Kibana visualization to count the number
    of errors.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Configure a custom metric in Amazon CloudWatch to track latency. Create a
    dashboard on CloudWatch to track the metric.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Configure the AWS X-Ray SDK for the application. Send the segments to X-Ray
    for processing. View the service graphs and traces in the X-Ray service console.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have set up AWS CodeCommit for your company to use as the code versioning
    service. The main application team is developing a mobile phone app and submits
    the source code in one CodeCommit repository (repository A) in the AWS account
    (account A). The company has just acquired another company that had its own AWS
    account (account B) and some of the developers have been tasked to help the development
    of a new feature of the mobile phone app. What actions should you take to configure
    cross-account access so that the new developers who have accounts and IAM users
    in account B have the ability to access repository A in account A (choose two)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Go to the AWS CodeCommit service in the AWS Management Console in account
    A. Share repository A with account B so that users in account B will have access
    to the repository.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Go to the AWS CodeCommit service in the AWS Management Console in account
    A. Add the IAM users of account B to the repository as users.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. In AWS account A, go to the IAM console and create an IAM policy that allows
    access to CodeCommit's repository A. Then create an IAM role that can be assumed
    by another account and attach this policy. Allow users in account B to assume
    this role.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. In AWS account B, go to the IAM console and create an IAM policy that allows
    full access to the CodeCommit service and is connected to the repository A ARN
    resource. Attach this new policy to all users that need access to repository A
    in AWS account A.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: e. In AWS account B, create an IAM policy that allows for Security Token Service
    to assume role action so that a cross-account role can be assumed. Attach this
    new policy to all users that need access to repository A in AWS account A.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The company you are working for has just undergone an audit. The corrections
    that came back included the need to retain and store all system logs for 6 years.
    The development and operations teams need 30–60 days' worth of logs for troubleshooting
    purposes. The marketing department needs at least 6 months of web traffic logs
    for their analytics analysis. The management wants to make sure that the solution
    you come up with is cost-effective as well as meeting the auditor's requirements.
    How can you satisfy both management and the auditor's needs?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Put the logs onto an EBS volume. Create monthly EBS snapshots for long-term
    storage of the logs after 60 days.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Put the logs into Amazon S3 Glacier.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Put the logs into the Amazon CloudWatch Logs service and set the retention
    policy on the log groups to 6 years.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Put the logs into an Amazon S3 bucket. Create a bucket policy that moves
    the logs to infrequent access after 60 days and then to Amazon Glacier after 1
    year.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Your company runs a .NET application in AWS that relies on around 50 Windows
    servers for the underlying infrastructure. The company has a policy that all of
    the servers in the development, test, and production environments must be kept
    up to date with the latest security patches. These Window servers have all been
    built from a master AMI image. The DevOps team that is responsible for the patching
    of the instances only consists of yourself and one other team member, so creating
    an automated way to perform this process is imperative; otherwise, you will be
    pressed to complete all of the updates in the allotted time window of 1 A.M.–4
    A.M. on Saturday morning when there is very little customer traffic. How can you
    automate this process using native AWS services?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Create a Lambda function that can download and run the updates in PowerShell.
    Schedule the Lambda to run every week at 1 A.M. using CloudWatch Events.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Apply AWS Systems Manager Patch Manager to the Windows instance fleet. Use
    System Manager run commands to install the updates.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Apply AWS System Manager Patch Manager to the Windows instance fleet. Use
    System Manager Maintenance Windows to schedule the updates to run every week at
    1 A.M.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Create custom Chef scripts in OpsWorks to download and install the updates
    in PowerShell. Create a task in OpsWorks to schedule and run the updates every
    week at 1 A.M.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The CTO has recently approached you, concerned about the security of the company's
    AWS account. They would like you to implement monitoring for any possible attacks
    that could be coming in against the company's AWS resources. They specifically
    emphasized monitoring against port scans, brute force attacks, or any SSH attacks.
    If an attack was detected, they would like it posted to the company's Microsoft
    Teams security channel. How can you go about achieving this?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Set up Amazon GuardDuty. If suspicious activity is detected, trigger a Lambda
    function that will post to the Microsoft Teams channel.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Create a Lambda function that will scan the CloudTrail logs for suspicious
    activity. If suspicious activity is found, it will post it to the Microsoft Teams
    channel.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Set up Amazon Inspector. If suspicious activity is detected, trigger a Lambda
    function that will post to the Microsoft Teams channel.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Create a Lambda function that will scan the VPC flow logs. If suspicious
    activity is found, it will post it to the Microsoft Teams channel.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The CEO has visited the DevOps team personally, stating that the company is
    promising six 9s of uptime to customers or the company would be giving large refunds.
    This leaves you and your team only 31.56 % of downtime per year. The main workload
    comprises multiple EC2 instances that are configured in Auto Scaling groups, running
    behind Application Load Balancers. How can you configure the workload to ensure
    that the company maintains that uptime promise even in the case of regional failure?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Configure Amazon CloudFront in front of the load balancers and instances.
    CloudFront will cache the workload for customers in case of failure.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Set up a Route 53 geoproximity routing record. Make sure that the Auto Scaling
    groups are set to utilize two Availability Zones. Have the Route 53 routing record
    point to the Application Load Balancers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Set up a Route 53 weighted routing record. Make sure that the Auto Scaling
    groups are set to utilize two Availability Zones. Have the Route 53 routing record
    point to the Application Load Balancers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Set up a Route 53 latency routing record. Implement your workload EC2 instances,
    Auto Scaling groups, and load balancers in two different regions. Have the Route
    53 routing record point to the Application Load Balancers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Your company wants to implement the Apache Cassandra NoSQL database on AWS.
    There is no managed service for Cassandra, so you will have to build this on EC2
    instances. Your team is looking for you to choose the correct type of EBS volume
    so that they get the optimum performance for this high-performance NoSQL database.
    Which type of volume should you choose when building the EC2 instances in the
    cluster?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Use IO1 EBS volumes when creating the instances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Use standard EBS volumes when creating the instances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Use GPL EBS volumes when creating the instances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Use GP2 EBS volumes when creating the instances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have been brought into an organization to help create a new AWS CodePipeline
    pipeline so that the team can implement continuous integration. The pipeline needs
    to pull the source code and then have a test stage run by AWS CodeBuild. The test
    includes extracting data from a database that requires a username and password.
    You will need to put these in the test stage using environment variables. How
    can you securely configure these variables in the CodeBuild stage of the pipeline?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Use the CodeBuild environment variable options to store the secrets. Select
    the `Plaintext` type when storing the values and use a KMS key to encrypt the
    values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Use the CodeBuild environment variable options to store the secrets. Select
    the `SecureString` type when storing the values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Use AWS Secrets Manager to store the values. Update your CodeBuild environment
    values for the variables and use the names of the secrets as the values in `Plaintext`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Use AWS Systems Manager Parameter Store to store the values. Update your
    CodeBuild environment values for the variables and use the parameter names as
    the values as `Parameter` types.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have been asked to help a team that is using OpsWorks to enhance the monitoring
    of their stack. This team is rather skilled in developing automations using Chef
    but just seems to know the basics to run their services in AWS. Which of the following
    will not help them enhance the monitoring of their application being deployed
    in OpsWorks?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Utilize Amazon CloudWatch metrics and create a custom metric to track the
    application.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Utilize Amazon Cloud Trail to make sure that only authorized calls are being
    made to the application.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Utilize Amazon CloudWatch Logs to gather the logs from the application.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Utilize AWS Config to gather the application's configuration changes.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have been brought into a small start-up whose marketing website is nothing
    but static content. The marketing department has been complaining that load times
    are currently too long, and this is affecting their search engine rating. They
    have only a limited budget for upgrades and would like to make the most effective
    use of their money. The start-up is also in the process of moving all digital
    assets to their new AWS account. They also want to make their site as fast as
    possible. Which of the following suggestions would best meet their needs?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Serve their website using an EC2 server. Add Amazon CloudFront in front as
    the content delivery network.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Move all static assets to S3\. Serve the website on EC2 spot instances. Add
    Amazon CloudFront in front as the content delivery network.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Move the entire website to S3\. Add Amazon CloudFront in front as the content
    delivery network.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Serve their website on EC2 spot instances. Add Amazon ElastiCache for content
    caching to speed up page load times.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: An organization is running a successful room booking mobile application on AWS.
    They are using DynamoDB to store all the records of the transactions and confirmation
    codes obtained from credit card companies once the reservations have been made.
    They chose DynamoDB for its ability to quickly autoscale and handle any type of
    capacity that is needed without much management. These transactional records are
    of vital importance to the company and must not be lost lost due to any server
    failures. The organization has a policy that the financial transactions must be
    stored for 3 years in case of any customer disputes. What is the most cost-effective
    and reliable way to accomplish this?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Use CloudWatch Logs to capture the records from DynamoDB. Set the retention
    period in CloudWatch Logs to 3 years.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Use DynamoDB Streams to stream transition records to a Lambda function. Have
    the Lambda function write the record to an S3 bucket. Use a life cycle policy
    to move objects to S3 Glacier storage for cost savings.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Use DynamoDB global tables to replicate the data to a secondary region. Create
    a Lambda function that trims records based on the creation date of the record
    minus 3 years and runs on a nightly basis.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Use DynamoDB Streams to stream transition records to an S3 bucket. Use a
    life cycle policy to move objects to S3 Glacier storage for cost savings.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A company has set up multiple accounts using AWS organizations. They have just
    started implementing event-driven automation and are taking the first steps to
    have notifications being sent from the CloudWatch event bus located in the master
    account via SNS to topics. How can they set up their master account and grant
    access to all child accounts so that the events can be sent to the event bus located
    in the master account?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Create an IAM policy that allows for sending CloudWatch events. Attach that
    policy to a role in the master account that can be assumed by all child accounts
    in the organization.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Create an IAM policy in each of the child accounts that allows for sending
    CloudWatch events and specifies the ARN of the event bus in the master account.
    Attach this policy for any service-based role that needs to send events to the
    master account.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. In the master account, go to the CloudWatch Events console and then choose
    your event bus. Go to add permission and then choose to add the entire organization
    by entering the ID of the organization.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. In the master account, go to the CloudWatch Events console and then choose
    your event bus. Go to add permission and then add the ID for each of the child
    accounts that need permission to send events to the event bus.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You are working with a development team that is trying to track the performance
    of an application that they build and are running on a group of EC2 instances.
    This team is especially interested in any error messages that are being generated
    from their Java code and would like the full team to be notified if more than
    5 error messages occur in a 5-minute time period. Which of the following solutions
    could you implement to fulfill the team's requirements?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Configure the instances to have all the Java logs write to the syslog on
    the EC2 instances in the user-data script. Use Kinesis Data Firehose to pull the
    syslog data for the instances and count the number of error messages. Create an
    SNS topic for the group of developers. Have Kinesis send a notification to the
    topic if there are more than 5 error logs in a 5-minute period.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Configure the instances to write to a single log group in Amazon CloudWatch
    Logs. Use Amazon Elasticsearch to subscribe to the log group. Build a Kibana dashboard
    so that the developers can see how many error logs are being generated on a minute-by-minute
    basis.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Configure the instance to install AWS Systems Manager Agent. Have the agent
    pull the logs to Amazon EventBridge. Create an SNS topic for the group of developers.
    Create a Lambda function that will send a notification to the SNS topic if there
    are more than 5 error logs in a 5-minute period.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Configure the instance to install the unified CloudWatch agent. Create a
    custom metric to count the number of errors in the Java logs. Create an SNS topic
    for the group of developers. Push the logs and the custom metric to Amazon CloudWatch.
    Create a CloudWatch alarm that will send a notification to the SNS topic if the
    custom metric reaches a value greater than 5 in a 5-minute period.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: All of the developers in your organization currently have the ability to start
    and stop any of the EC2 instances that are currently running in the development
    account simply by logging onto the AWS Management Console and choosing to stop
    the instance under the Instance State settings. Some teams have been complaining
    that their workloads have been disrupted by other developers mistakenly stopping
    the wrong EC2 instances. How can you implement security measures so that only
    members from a particular team can start and stop their own EC2 instances using
    native AWS features?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. For each development team in the company, create a policy that restricts
    the starting and stopping of instances to the `${aws:Principal/Team}` tag as the
    resource.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Add a `Team` tag to all the EC2 instances that can help restrict access by
    comparing the `${aws:Principal/Team}` tag attached by the individual developer
    to the `ec2:ResourceTag/Team` tag on the instance and seeing whether they match.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Add a `Team` tag to all the EC2 instances. Restrict access to each team in
    the developer policy by seeing whether the EC2 instance matches the team tag.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. In the IAM developer role, remove the ability to start and stop instances.
    Create a CodePipeline job for each team that will allow them to see, start, and
    stop all of the instances for their development team.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You have an Extract, Transform, and Load (ETL) application that is sending
    its logs to CloudWatch Logs. The logs are landing in a CloudWatch log group and
    are formatted in JSON. The following is a sample of the log file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How can you create a metric filter so you can find all events where the error
    code was `"CorruptFile"`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a. Filter Pattern: `{ $.errorCode = "CorruptFile" }`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b. Filter Pattern: `{ $.errorCode == "CorruptFile" }`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Filter Pattern `{ errorCode = "CorruptFile" }`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Filter Pattern `{ errorCode == "CorruptFile" }`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Your company has requested that you create a reliable and durable logging solution
    for their three AWS accounts so that they can track the changes being made to
    their AWS resources. Which of the following options would help you successfully
    do this?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Create a new CloudTrail with an existing bucket to store the logs. Select
    the global services option when creating the trail. Use IAM roles on the S3 bucket
    and S3 encryption to secure the bucket.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Create three new CloudTrails with a single new bucket to store the logs.
    One trail will be for the AWS Management Console, one will be for SDK commands,
    and one will be for the AWS CLI. Use multi-factor authentication for any delete
    actions and S3 encryption on the buckets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Create a new CloudTrail with a new bucket to store the logs. Select the global
    services option when creating the trail. Use multi-factor authentication for any
    delete actions and S3 encryption on the bucket.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Create three new CloudTrails with three new buckets to store the logs. One
    trail will be for the AWS Management Console, one will be for SDK commands, and
    one will be for the AWS CLI. Use IAM roles on the S3 bucket and S3 encryption
    to secure the buckets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Your company has used AWS Organizations to both create and manage their AWS
    account. There are multiple accounts, which include child accounts that contain
    organizational units that have been created using AWS Organizations. As the company
    grows, there is now a need to add uniform roles to each of the accounts. What
    is the most effective way to add all of the roles throughout the organization?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. In the master account, use CloudFormation to deploy a template with which
    to create the new roles. Use CloudFormation StackSets to replicate the changes
    across the whole organization's child accounts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. In the master account of the organization, create a Service Control Policy
    (SCP), which will then add the roles to all the child accounts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. In the master account, use CloudFormation to deploy a template with which
    to create the new roles. Use CloudFormation change sets to replicate the changes
    across the whole organization's child accounts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. In the master account, create a run command in Systems Manager to create
    the new IAM roles. Have Systems Manager perform the command on all of the child
    accounts to create the new role.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Members of your DevOps team have come to you because they have noticed a problem
    with one of the Auto Scaling groups that has just been updated. Instead of reaching
    a steady state and serving traffic, the application is constantly scaling up and
    down numerous times an hour. Using the native features of CloudFormation, which
    settings could you help your team tune in order to stabilize the application?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Examine the current Auto Scaling group termination policy and change the
    value to terminate the oldest instance first so that newer instances stay online.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Examine the current Auto Scaling group termination policy and change the
    value to terminate to `ClosestToNextInstanceHour` so that the instances become
    more stabilized.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Find the previous version of the Auto Scaling launch template and deploy
    that version to stabilize the application.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Examine the current Auto Scaling group Health Check grace period and expand
    the time currently allocated for the instances to come online and become healthy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A medium-sized software company has hired you as a DevOps consultant to help
    set up their deployment pipeline. They want to be able to push their tested code
    into their production environment in a quick manner but do not want the possibility
    of dealing with any downtime for their customers. You have worked with the application
    team to configure their application to run on containers and be deployed to Amazon
    Elastic Container Service (ECS). Their DNS is hosted on a third-party service
    and changes for the DNS would require a change ticket. What deployment method
    would you implement?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. In the service settings of ECS, set the `minimumHealthyPercent` and `maximumHealthyPercent`
    values of tasks before you begin your rolling update to the service.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Create a CodeDeploy job for your updates. Use a blue/green deployment type.
    Set the configuration of the blue/green deployment to all-at-once.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Create a CodeDeploy job for your updates. Use a blue/green deployment type.
    Set the configuration of the blue/green deployment to linear.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Create a CodeDeploy job for your updates. Use a blue/green deployment type.
    Set the configuration of the blue/green deployment to canary.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Your team has recently been subject to a code audit and there were multiple
    findings of plaintext database usernames and passwords in the application code.
    This has been flagged by the company as unacceptable and the team has been given
    30 days to remedy the problem. According to the company guidelines, the team needs
    to be able to store the secrets securely in an encrypted manner using a native
    AWS service that also has the ability to rotate the secret automatically every
    60 days. How can you and your team remedy this issue?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Remove the database values that were previously set in the code base. Add
    environment variables to the deployment process. Insert the username and password
    as the corresponding deployment variables.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Remove the database values that were previously set in the code base. Store
    the username and values in AWS Systems Manager Parameter Store. Update your IAM
    role to allow access to retrieve the secret from Parameter Store.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Remove the database values that were previously set in the code base. Store
    the username and password in AWS Secrets Manager. Update your IAM role to allow
    access to retrieve the secret from Secrets Manager.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Use KMS to encrypt the values for the username and password for the database.
    Replace the previous values in the code with the newly encrypted values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Your developers have created a DynamoDB table and seem to find that the performance
    always slows down after 20–25 minutes of their testing process. They can see from
    the basic monitoring on the AWS Management Console that their requests are being
    throttled. What can you do to help pinpoint the issue?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Increase the Read Capacity Units (RCUs) on the table so that the queries
    are no longer throttled.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Add enhanced CloudWatch monitoring with alarms whenever throttling occurs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Enable Contributor Insights on the table so that the keys that are being
    throttled the most are shown.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Add adaptive capacity to the table so that the extra RCUs are spread evenly
    across partitions that are becoming hot.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Test answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since the bucket had versioning turned on, removing the delete marker restores
    the object, and any current or future deployments using that script will be able
    to find it.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can use the AWS CLI and the `autoscaling set-instance-health` command along
    with the `--health-status Unhealthy` flag to have the instance be out of service.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'More information can be found on the documentation page for the AWS CLI at
    the following link: [https://docs.aws.amazon.com/cli/latest/reference/autoscaling/set-instance-health.html](https://docs.aws.amazon.com/cli/latest/reference/autoscaling/set-instance-health.html).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With the configuration recorder, AWS Config can evaluate new resources being
    created in an account. Items are recorded as JSON snapshots to an S3 bucket declared
    in the setup.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: RDS uses DNS to switch over to the standby replica for a seamless transition
    in a Multi-AZ implementation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Although the `AWSCodePipeline_FullAccess` policy would give approval access,
    it doesn't follow the AWS principle of least privilege. This policy would give
    the product owner more privileges than they need. Hence `AWSCodePipelineApproverAccess`
    would add the access that they were missing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You cannot modify a managed AWS policy, and hence this disqualifies both answers
    c and d. You are trying to prevent the action of users directly pushing to the
    master branch.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You remove an on-premises instance tag from an on-premises instance when that
    tag is no longer being used, or if you want to remove the on-premises instance
    from any deployment groups that rely on that tag.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a, d, and e
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Writing all the values to a file in S3 would not guarantee their integrity.
    It is a much more secure practice to use roles and to have database values stored
    in a credential store, such as Secrets Manager or Systems Manager Parameter Store.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `Fn::ImportValue` intrinsic function returns the value of an exported value
    of a previously created stack. This is used to create cross-stack references.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Inspector is a security service and would not find latencies in an application.
    The X-Ray service helps developers identify the root cause of performance issues
    and errors.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c and e
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In order to gain access to resources in another AWS account, a cross-account
    IAM role needs to be created so that it can be assumed by the other AWS account.
    Likewise, the other account's users must have a policy attached to them that will
    allow for the assumption of the role.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The use of Amazon S3 life cycle policies will allow you and your team to have
    both immediate access to the current logs and the ability to store them on the
    low-cost option in Amazon Glacier as the auditor requires.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using AWS Systems Manager, you can use the combination of Patch Manager and
    Maintenance Windows to successfully automate this task in the recommended way
    by AWS.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon GuardDuty can detect all of the different types of events that the CTO
    was concerned about. Adding a Lambda function that will post to the company's
    Microsoft Teams channel will satisfy the request.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Only by deploying to multiple regions can you make sure that you are protected
    against a regional failure. Using a latency-based record in Route 53 will automatically
    point to the set of servers that is responding the quickest to a request in case
    of a failure.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: io1 volumes are crafted for workloads that require sustained IOPS performance
    and I/O-intensive database workloads.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sensitive values should be stored in either Systems Manager Parameter Store
    or Secrets Manager. If Secrets Manager is used for CodeBuild, then the variable
    type should be selected as Secrets Manager and not `Plaintext`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Config is not a service used for monitoring and metrics.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since the full site is made of static content, and S3 is the least expensive
    and reliable solution, this is the most optimum choice. Using S3 as the origin
    and being fronted by Amazon CloudFront will allow for assets to be served faster
    to the end user via edge locations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: DynamoDB Streams cannot directly stream to S3 as a source, so a Lambda Function
    would need to first `GetRecords` and then put them to the specified S3 bucket
    with the life cycle policy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A CloudWatch event bus allows you to add permissions on an organizational level.
    This also helps if your organization grows, as you don't have to keep track of
    which accounts you have added to the event bus or remember to take the extra step
    of adding the account to the event bus permissions when it is created.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using tags on EC2 instances can be the first part of differentiating the ownership
    of EC2 instances between teams. `ec2:ResourceTag` is a tag that exists on an EC2
    resource and can be verified against an IAM policy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The syntax of the metric filter would be `{ $.errorCode = "CorruptFile" }`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The use of the global option will send all of the API actions recorded to a
    single S3 bucket. Adding in MFA will prevent any unauthorized deletions of the
    logs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS CloudFormation StackSets extends the functionality of CloudFormation stacks,
    allowing you to create, update, or delete stacks across multiple accounts and
    regions with a single operation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Although you may be able to roll back with a code versioning system, adjusting
    the current health check of the Auto Scaling group will allow your instances to
    come online and become healthy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A rolling type of deployment would be the most optimal type of deployment, especially
    when the DNS is hosted on a third-party provider.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Although both Systems Manager Parameter Store and AWS Secrets Manager will safely
    secure secrets according to the new guidelines in this scenario, only Secrets
    Manager will automatically rotate the database secrets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon CloudWatch Contributor Insights integrates with DynamoDB to provide information
    about the most accessed and throttled items in a table or global secondary index.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Question breakdown
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you are interested in how you are performing in a particular domain, then
    we have how the sample test questions would be grouped based on the test domains,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Domain 1 – SDLC automation**:'
  prefs: []
  type: TYPE_NORMAL
- en: Question 6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain 2 – Configuration management and infrastructure as code:**'
  prefs: []
  type: TYPE_NORMAL
- en: Question 5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain 3 – Monitoring and logging:**'
  prefs: []
  type: TYPE_NORMAL
- en: Question 10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain 4 – Policies and standards automation:**'
  prefs: []
  type: TYPE_NORMAL
- en: Question 3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain 5 – Incident and event response:**'
  prefs: []
  type: TYPE_NORMAL
- en: Question 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain 6 – High availability, fault tolerance, and disaster recovery:**'
  prefs: []
  type: TYPE_NORMAL
- en: Question 4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question 25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are missing questions particularly in a specific area, then go back and
    reread those chapters, look to the end of [*Chapter 23*](B17405_23_Final_JM_ePub.xhtml#_idTextAnchor501),
    *Overview of the DevOps Professional Certification Test*, for one of the AWS Whitepapers
    that could give you more insight into that topic, or even watch some of the past
    re:Invent talks or AWS TechTalk videos to gain a better understanding of the domain.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's have one final summary of our journey to certification.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have been presented with a number of sample DevOps professional
    exam questions so that you can practice all of the items that you have learned
    up to this point, as well as reading and comprehending the question and answer
    format that will be on the test.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, at this point, you feel confident to take and pass the DevOps Professional
    certification exam. Once you pass, you will join the small subset of individuals
    who can be quickly recognized for their skill in not only DevOps but also AWS
    and cloud technologies.
  prefs: []
  type: TYPE_NORMAL
