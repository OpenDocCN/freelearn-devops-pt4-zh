<html><head></head><body>
		<div id="_idContainer015" class="Content">
			<h1 id="_idParaDest-34">2. <a id="_idTextAnchor036"/>Azure solution availability, scalability, and monitoring</h1>
		</div>
		<div>
			<div id="_idContainer016" class="Content">
			</div>
		</div>
		<div id="_idContainer037" class="Content">
			<p>Architectural concerns, such as high availability and scalability, are some of the highest-priority items for any architect. This is common across many projects and solutions. However, this becomes even more important when deploying applications to the cloud because of the complexity involved. Most of the time, the complexity does not come from the application, but from the choices available in terms of similar resources on the cloud. The other complex issue that arises from the cloud is the constant availability of new features. These new features can almost make an architect's decisions completely redundant in hindsight.</p>
			<p>In this chapter, we will look at an architect's perspective in terms of deploying highly available and scalable applications on Azure.</p>
			<p>Azure is a mature platform that provides a number of options for implementing high availability and scalability at multiple levels. It is vital for an architect to know about them, including the differences between them and the costs involved, and finally, be in a position to choose an appropriate solution that meets the best solution requirements. There is no one solution for everything, but there is a good one for each project.</p>
			<p>Running applications and systems that are available to users for consumption whenever they need them is one of the topmost priorities for organizations. They want their applications to be operational and functional, and to continue to be available to their customers even when some untoward events occur. High availability is the primary theme of this chapter. <em class="italics">Keeping the lights on</em> is the common metaphor that is used for high availability. Achieving high availability for applications is not an easy task, and organizations have to spend considerable time, energy, resources, and money in doing so. Additionally, there is still the risk that an organization's implementation will not produce the desired results. Azure provides a lot of high-availability features for <strong class="bold">virtual machines</strong> (<strong class="bold">VMs</strong>) and the <strong class="bold">Platform as a Service</strong> (<strong class="bold">PaaS</strong>) service. In this chapter, we will go through the architectural and design features that are provided by Azure to ensure high availability for running applications and services.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>High availability</li>
				<li>Azure high availability</li>
				<li>Architectural considerations for high availability</li>
				<li>Scalability</li>
				<li>Upgrades and maintenance</li>
			</ul>
			<h2 id="_idParaDest-35"><a id="_idTextAnchor037"/>High availability</h2>
			<p>High availability forms one of the core non-functional technical requirements for any business-critical service and its deployment. High availability refers to the feature of a service or application that keeps it operational on a continuous basis; it does so by meeting or surpassing its promised <strong class="bold">service level agreement</strong> (<strong class="bold">SLA</strong>). Users are promised a certain SLA based on the service type. The service should be available for consumption based on its SLA. For example, an SLA can define 99% availability for an application for the entire year. This means that it should be available for consumption by users for 361.35 days. If it fails to remain available for this period, that constitutes a breach of the SLA. Most mission-critical applications define their high-availability SLA as 99.999% for a year. This means the application should be up, running, and available throughout the year, but it can only be down and unavailable for 5.2 hours. If the downtime goes beyond that, you are eligible for credit, which will be calculated based on the total uptime percentage. </p>
			<p>It is important to note here that high availability is defined in terms of time (yearly, monthly, weekly, or a combination of these).</p>
			<p>A service or application is made up of multiple components and these components are deployed on separate tiers and layers. Moreover, a service or application is deployed on an <strong class="bold">operating system</strong> (<strong class="bold">OS</strong>) and hosted on a physical machine or VM. It consumes network and storage services for various purposes. It might even be dependent on external systems. For these services or applications to be highly available, it is important that networks, storage, OSes, VMs or physical machines, and each component of the application is designed with the SLA and high availability in mind. A definite application life cycle process is used to ensure that high availability should be baked in from the start of application planning until its introduction to operations. This also involves introducing redundancy. Redundant resources should be included in the overall application and deployment architecture to ensure that if one resource goes down, another takes over and serves the requests of the customer.</p>
			<p>Some of the major factors affecting the high availability of an application are as follows:</p>
			<ul>
				<li>Planned maintenance</li>
				<li>Unplanned maintenance</li>
				<li>Application deployment architecture</li>
			</ul>
			<p>We will be looking into each of these factors in the following sections. Let's take a closer look at how high availability is ensured for deployments in Azure.</p>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor038"/>Azure high availability</h2>
			<p>Achieving high availability and meeting high SLA requirements is tough. Azure provides lots of features that enable high availability for applications, from the host and guest OS to applications using its PaaS. Architects can use these features to get high availability in their applications using configuration instead of building these features from scratch or depending on third-party tools.</p>
			<p>In this section, we will look at the features and capabilities provided by Azure to make applications highly available. Before we get into the architectural and configuration details, it is important to understand concepts related to Azure's high availability.</p>
			<h3 id="_idParaDest-37"><a id="_idTextAnchor039"/>Concepts</h3>
			<p>The fundamental concepts provided by Azure to attain high availability are as follows:</p>
			<ul>
				<li>Availability sets</li>
				<li>The fault domain</li>
				<li>The update domain</li>
				<li>Availability zones</li>
			</ul>
			<p>As you know, it's very important that we design solutions to be highly available. The workloads might be mission-critical and require highly available architecture. We will take a closer look at each of the concepts of high availability in Azure now. Let's start with availability sets.</p>
			<p><strong class="bold">Availability sets</strong></p>
			<p>High availability in Azure is primarily achieved through redundancy. Redundancy means that there is more than one resource instance of the same type that takes control in the event of a primary resource failure. However, just having more similar resources does not make them highly available. For example, there could be multiple VMs provisioned within a subscription, but simply having multiple VMs does not make them highly available. Azure provides a resource known as an availability set, and having multiple VMs associated with it makes them highly available. A minimum of two VMs should be hosted within the availability set to make them highly available. All VMs in the availability set become highly available because they are placed on separate physical racks in the Azure datacenter. During updates, these VMs are updated one at a time, instead of all at the same time. Availability sets provide a fault domain and an update domain to achieve this, and we will discuss this more in the next section. In short, availability sets provide redundancy at the datacenter level, similar to locally redundant storage.</p>
			<p>It is important to note that availability sets provide high availability within a datacenter. If an entire datacenter is down, then the availability of the application will be impacted. To ensure that applications are still available when a datacenter goes down, Azure has introduced a new feature known as availability zones, which we will learn about shortly.</p>
			<p>If you recall the list of fundamental concepts, the next one in the list is the fault domain. The fault domain is often denoted by the acronym FD. In the next section, we will discuss what the FD is and how it is relevant while designing highly available solutions.</p>
			<p><strong class="bold">The fault domain</strong></p>
			<p><strong class="bold">Fault domains</strong> (<strong class="bold">FDs</strong>) represent a group of VMs that share a common power source and network switch. When a VM is provisioned and assigned to an availability set, it is hosted within an FD. Each availability set has either two or three FDs by default, depending on the Azure region. Some regions provide two, while others provide three FDs in an availability set. FDs are non-configurable by users. </p>
			<p>When multiple VMs are created, they are placed on separate FDs. If the number of VMs is more than the FDs, the additional VMs are placed on existing FDs. For example, if there are five VMs, there will be FDs hosted on more than one VM. </p>
			<p>FDs are related to physical racks in the Azure datacenter. FDs provide high availability in the case of unplanned downtime due to hardware, power, and network failure. Since each VM is placed on a different rack with different hardware, a different power supply, and a different network, other VMs continue running if a rack snaps off.</p>
			<p>The next one in the list is the update domain.</p>
			<p><strong class="bold">The update domain</strong></p>
			<p>An FD takes care of unplanned downtime, while an update domain handles downtime from planned maintenance. Each VM is also assigned an update domain and all the VMs within that update domain will reboot together. There can be as many as 20 update domains in a single availability set. Update domains are non-configurable by users. When multiple VMs are created, they are placed on separate update domains. If more than 20 VMs are provisioned on an availability set, they are placed in a round-robin fashion on these update domains. Update domains take care of planned maintenance. From <strong class="bold">Service Health</strong> in the Azure portal, you can check the planned maintenance details and set alerts.</p>
			<p>In the next section, we will be covering availability zones.</p>
			<p><strong class="bold">Availability zones</strong></p>
			<p>This is a relatively new concept introduced by Azure and is very similar to zone redundancy for storage accounts. Availability zones provide high availability within a region by placing VM instances on separate datacenters within the region. Availability zones are applicable to many resources in Azure, including VMs, managed disks, VM scale sets, and load balancers. The complete list of resources that are supported by availability zones can be found at <a href="https://docs.microsoft.com/azure/availability-zones/az-overview#services-that-support-availability-zones">https://docs.microsoft.com/azure/availability-zones/az-overview#services-that-support-availability-zones</a>. Being unable to configure availability across zones was a gap in Azure for a long time, and it was eventually fixed with the introduction of availability zones.</p>
			<p>Each Azure region comprises multiple datacenters equipped with independent power, cooling, and networking. Some regions have more datacenters, while others have less. These datacenters within the region are known as zones. To ensure resiliency, there's a minimum of three separate zones in all enabled regions. Deploying VMs in an availability zone ensures that these VMs are in different datacenters and are on different racks and networks. These datacenters in a region relate to high-speed networks and there is no lag in communication between these VMs. <em class="italics">Figure 2.1</em> shows how availability zones are set up in a region:</p>
			<div>
				<div id="_idContainer017" class="IMG---Figure">
					<img src="image/B15432_02_01.jpg" alt="Availability zones in an Azure region"/>
				</div>
			</div>
			<h6>Figure 2.1: Availability zones in a region</h6>
			<p>You can find more information about availability zones at <a href="https://docs.microsoft.com/azure/availability-zones/az-overview">https://docs.microsoft.com/azure/availability-zones/az-overview</a>.</p>
			<p>Zone-redundant services replicate your applications and data across availability zones to protect from single points of failure. </p>
			<p>If an application needs higher availability and you want to ensure that it is available even if an entire Azure region is down, the next rung of the ladder for availability is the Traffic Manager feature, which will be discussed later in this chapter. Let's now move on to understanding Azure's take on load balancing for VMs.</p>
			<h3 id="_idParaDest-38"><a id="_idTextAnchor040"/>Load balancing</h3>
			<p>Load balancing, as the name suggests, refers to the process of balancing a load among VMs and applications. With one VM, there is no need for a load balancer because the entire load is on a single VM and there is no other VM to share the load. However, with multiple VMs containing the same application and service, it is possible to distribute the load among them through load balancing. Azure provides a few resources to enable load balancing:</p>
			<ul>
				<li><strong class="bold">Load balancers</strong>: The Azure load balancer helps to design solutions with high availability. Within the <strong class="bold">Transmission Control Protocol</strong> (<strong class="bold">TCP</strong>) stack, it is a layer 4 transport-level load balancer. This is a layer 4 load balancer that distributes incoming traffic among healthy instances of services that are defined in a load-balanced set. Level 4 load balancers work at the transport level and have network-level information, such as an IP address and port, to decide the target for the incoming request. Load balancers are discussed in more detail later in this chapter.</li>
				<li><strong class="bold">Application gateways</strong>: An Azure Application Gateway delivers high availability to your applications. They are layer 7 load balancers that distribute the incoming traffic among healthy instances of services. Level 7 load balancers can work at the application level and have application-level information, such as cookies, HTTP, HTTPS, and sessions for the incoming request. Application gateways are discussed in more detail later in this chapter. Application gateways are also used when deploying Azure Kubernetes Service, specifically for scenarios in which ingress traffic from the internet should be routed to the Kubernetes services in the cluster.</li>
				<li><strong class="bold">Azure Front Door</strong>: Azure Front Door is very similar to application gateways; however, it does not work at the region or datacenter level. Instead, it helps in routing requests across regions globally. It has the same feature set as that provided by application gateways, but at the global level. It also provides a web application firewall for the filtering of requests and provides other security-related protection. It provides session affinity, TLS termination, and URL-based routing as some of its features.</li>
				<li><strong class="bold">Traffic Manager</strong>: Traffic Manager helps in the routing of requests at the global level across multiple regions based on the health and availability of regional endpoints. It supports doing so using DNS redirect entries. It is highly resilient and has no service impact during region failures as well.</li>
			</ul>
			<p>Since we've explored the methods and services that can be used to achieve load balancing, we'll go ahead and discuss how to make VMs highly available.</p>
			<h3 id="_idParaDest-39"><a id="_idTextAnchor041"/>VM high availability</h3>
			<p>VMs provide compute capabilities. They provide processing power and hosting for applications and services. If an application is deployed on a single VM and that machine is down, then the application will not be available. If the application is composed of multiple tiers and each tier is deployed in its own single instance of a VM, even downtime for a single instance of VM can render the entire application unavailable. Azure tries to make even single VM instances highly available for 99.9% of the time, particularly if these single-instance VMs use premium storage for their disks. Azure provides a higher SLA for those VMs that are grouped together in an availability set. It provides a 99.95% SLA for VMs that are part of an availability set with two or more VMs. The SLA is 99.99% if VMs are placed in availability zones. In the next section, we will be discussing high availability for compute resources.</p>
			<h3 id="_idParaDest-40"><a id="_idTextAnchor042"/>Compute high availability</h3>
			<p>Applications demanding high availability should be deployed on multiple VMs in the same availability set. If applications are composed of multiple tiers, then each tier should have a group of VMs on their dedicated availability set. In short, if there are three tiers of an application, there should be three availability sets and a minimum of six VMs (two in each availability set) to make the entire application highly available.</p>
			<p>So, how does Azure provide an SLA and high availability to VMs in an availability set with multiple VMs in each availability set? This is the question that might come to mind for you.</p>
			<p>Here, the use of concepts that we considered before comes into play—that is, the fault and update domains. When Azure sees multiple VMs in an availability set, it places those VMs on a separate FD. In other words, these VMs are placed on separate physical racks instead of the same rack. This ensures that at least one VM continues to be available even if there is a power, hardware, or rack failure. There are two or three FDs in an availability set and, depending on the number of VMs in an availability set, the VMs are placed in separate FDs or repeated in a round-robin fashion. This ensures that high availability is not impacted because of the failure of the rack.</p>
			<p>Azure also places these VMs on a separate update domain. In other words, Azure tags these VMs internally in such a way that these VMs are patched and updated one after another, such that any reboot in an update domain does not affect the availability of the application. This ensures that high availability is not impacted because of the VM and host maintenance. It is important to note that Azure is not responsible for OS-level and application maintenance.</p>
			<p>With the placement of VMs in separate fault and update domains, Azure ensures that all VMs are never down at the same time and that they are alive and available for serving requests, even though they might be undergoing maintenance or facing physical downtime challenges:</p>
			<div>
				<div id="_idContainer018" class="IMG---Figure">
					<img src="image/B15432_02_02.jpg" alt="VM distribution across update and fault domains"/>
				</div>
			</div>
			<h6>Figure 2.2: VM distribution across fault and update domains</h6>
			<p><em class="italics">Figure 2.2</em> shows four VMs (two have <strong class="bold">Internet Information Services</strong> (<strong class="bold">IIS</strong>) and the other two have SQL Server installed on them). Both the IIS and SQL VMs are part of availability sets. The IIS and SQL VMs are in separate FDs and different racks in the datacenter. They are also in separate update domains.</p>
			<p><em class="italics">Figure 2.3</em> shows the relationship between fault and update domains: </p>
			<div>
				<div id="_idContainer019" class="IMG---Figure">
					<img src="image/B15432_02_03.jpg" alt="Layout of update and fault domains in an availability set"/>
				</div>
			</div>
			<h6>Figure 2.3: Layout of update domains and FDs in an availability set</h6>
			<p>So far, we have discussed achieving high availability for compute resources. In the next section, you will learn how high availability can be implemented for PaaS.</p>
			<h3 id="_idParaDest-41"><a id="_idTextAnchor043"/>High-availability platforms</h3>
			<p>Azure has provided a lot of new features to ensure high availability for PaaS. Some of them are listed here:</p>
			<ul>
				<li>Containers in app services</li>
				<li>Azure Container Instances groups</li>
				<li>Azure Kubernetes Service</li>
				<li>Other container orchestrators, such as DC/OS and Swarm</li>
			</ul>
			<p>Another important platform that brings high availability is <strong class="bold">Service Fabric</strong>. Both Service Fabric and container orchestrators that include Kubernetes ensure that the desired number of application instances are always up and running in an environment. What this means is that even if one of the instances goes down in the environment, the orchestrator will know about it by means of active monitoring and will spin up a new instance on a different node, thereby maintaining the ideal and desired number of instances. It does this without any manual or automated interference from the administrator.</p>
			<p>While Service Fabric allows any type of application to become highly available, orchestrators such as Kubernetes, DC/OS, and Swarm are specific to containers. Also, it is important to understand that these platforms provide features that help in rolling updates, rather than a big bank update that might affect the availability of the application.</p>
			<p>When we were discussing high availability for VMs, we took a brief look at what load balancing is. Let's take a closer look at it to better understand how it works in Azure.</p>
			<h3 id="_idParaDest-42"><a id="_idTextAnchor044"/>Load balancers in Azure</h3>
			<p>Azure provides two resources that have the functionality of a load balancer. It provides a level 4 load balancer, which works at the transport layer within the TCP OSI stack, and a level 7 load balancer (application gateway), which works at the application and session levels.</p>
			<p>Although both application gateways and load balancers provide the basic features of balancing a load, they serve different purposes. There are a number of use cases in which it makes more sense to deploy an application gateway than a load balancer.</p>
			<p>An application gateway provides the following features that are not available with Azure load balancers:</p>
			<ul>
				<li><strong class="bold">Web application firewall</strong>: This is an additional firewall on top of the OS firewall and it gives the ability to peek into incoming messages. This helps in identifying and preventing common web-based attacks, such as SQL injection, cross-site scripting attacks, and session hijacks.</li>
				<li><strong class="bold">Cookie-based session affinity</strong>: Load balancers distribute incoming traffic to service instances that are healthy and relatively free. A request can be served by any service instance. However, there are applications that need advanced features in which all subsequent requests following the first request should be processed by the same service instance. This is known as cookie-based session affinity. An application gateway provides cookie-based session affinity to keep a user session on the same service instance using cookies.</li>
				<li><strong class="bold">Secure Sockets Layer (SSL) offload</strong>: The encryption and decryption of request and response data is performed by SSL and is generally a costly operation. Web servers should ideally be spending their resources on processing and serving requests, rather than the encryption and decryption of traffic. SSL offload helps in transferring this cryptography process from the web server to the load balancer, thereby providing more resources to web servers serving users. The request from the user is encrypted but gets decrypted at the application gateway instead of the web server. The request from the application gateway to the web server is unencrypted.</li>
				<li><strong class="bold">End-to-end SSL</strong>: While SSL offload is a nice feature for certain applications, there are certain mission-critical secure applications that need complete SSL encryption and decryption even if traffic passes through load balancers. An application gateway can be configured for end-to-end SSL cryptography as well.</li>
				<li><strong class="bold">URL-based content routing</strong>: Application gateways are also useful for redirecting traffic to different servers based on the URL content of incoming requests. This helps in hosting multiple services alongside other applications.</li>
			</ul>
			<p><strong class="bold">Azure load balancers</strong></p>
			<p>An Azure load balancer distributes incoming traffic based on the transport-level information that is available to it. It relies on the following features:</p>
			<ul>
				<li>An originating IP address</li>
				<li>A target IP address</li>
				<li>An originating port number</li>
				<li>A target port number</li>
				<li>A type of protocol—either TCP or HTTP</li>
			</ul>
			<p>An Azure load balancer can be a private load balancer or a public load balancer. A private load balancer can be used to distribute traffic within the internal network. As this is internal, there won't be any public IPs assigned and they cannot be accessed from the internet. A public load balancer has an external public IP attached to it and can be accessed via the internet. In <em class="italics">Figure 2.4</em>, you can see how internal (private) and public load balancers are incorporated into a single solution to handle internal and external traffic, respectively:</p>
			<div>
				<div id="_idContainer020" class="IMG---Figure">
					<img src="image/B15432_02_04.jpg" alt="Distributing traffic using Azure load balancers"/>
				</div>
			</div>
			<h6>Figure 2.4: Distributing traffic using Azure load balancers</h6>
			<p>In <em class="italics">Figure 2.4</em>, you can see that external users are accessing the VMs via the public load balancer, and then the traffic from the VM is distributed across another set of VMs using an internal load balancer.</p>
			<p>We have done a comparison of how Azure load balancers differ from Application Gateways. In the next section, we will discuss application gateways in more detail.</p>
			<h3 id="_idParaDest-43"><a id="_idTextAnchor045"/>The Azure Application Gateway</h3>
			<p>An Azure load balancer helps us to enable solutions at the infrastructure level. However, there are times when using a load balancer requires advanced services and features. These advanced services include SSL termination, sticky sessions, advanced security, and more. An Azure application gateway provides these additional features; the Azure application gateway is a level 7 load balancer that works with the application and session payload in a TCP OSI stack.</p>
			<p>Application gateways have more information compared to Azure load balancers in order to make decisions on request routing and load balancing between servers. Application gateways are managed by Azure and are highly available.</p>
			<p>An application gateway sits between the users and the VMs, as shown in <em class="italics">Figure 2.5</em>:</p>
			<div>
				<div id="_idContainer021" class="IMG---Figure">
					<img src="image/B15432_02_05.jpg" alt="Connecting users and VMs through Azure Application Gateway"/>
				</div>
			</div>
			<h6>Figure 2.5: An Azure application gateway</h6>
			<p>Application gateways are a managed service. They use <strong class="bold">Application Request Routing</strong> (<strong class="bold">ARR</strong>) to route requests to different services and endpoints. Creating an application gateway requires a private or public IP address. The application gateway then routes the HTTP/HTTPS traffic to configured endpoints.</p>
			<p>An application gateway is similar to an Azure load balancer from a configuration perspective, with additional constructs and features. Application gateways can be configured with a front-end IP address, a certificate, a port configuration, a back-end pool, session affinity, and protocol information.</p>
			<p>Another service that we discussed in relation to high availability for VMs was Azure Traffic Manager. Let's try to understand more about this service in the next section.</p>
			<h3 id="_idParaDest-44"><a id="_idTextAnchor046"/>Azure Traffic Manager</h3>
			<p>After gaining a good understanding of both Azure load balancers and application gateways, it's time to get into the details of Traffic Manager. Azure load balancers and application gateways are much-needed resources for high availability within a datacenter or region; however, to achieve high availability across regions and datacenters, there is a need for another resource, and Traffic Manager helps us in this regard.</p>
			<p>Traffic Manager helps us to create highly available solutions that span multiple geographies, regions, and datacenters. Traffic Manager is not similar to load balancers. It uses the <strong class="bold">Domain Name Service</strong> (<strong class="bold">DNS</strong>) to redirect requests to an appropriate endpoint determined by the health and configuration of the endpoint. Traffic Manager is not a proxy or a gateway, and it does not see the traffic passing between the client and the service. It simply redirects requests based on the most appropriate endpoints.</p>
			<p>Azure Traffic Manager helps to control the traffic that is distributed across application endpoints. An endpoint can be termed as any internet-facing service hosted inside or outside of Azure.</p>
			<p>Endpoints are internet-facing, reachable public URLs. Applications are provisioned within multiple geographies and Azure regions. Applications deployed to each region have a unique endpoint referred to by <strong class="bold">DNS CNAME</strong>. These endpoints are mapped to the Traffic Manager endpoint. When a Traffic Manager instance is provisioned, it gets an endpoint by default with a <strong class="inline">.trafficmanager.net</strong> URL extension.</p>
			<p>When a request arrives at the Traffic Manager URL, it finds the most appropriate endpoint in its list and redirects the request to it. In short, Azure Traffic Manager acts as a global DNS to identify the region that will serve the request.</p>
			<p>However, how does Traffic Manager know which endpoints to use and redirect client requests to? There are two aspects that Traffic Manager considers to determine the most appropriate endpoint and region.</p>
			<p>Firstly, Traffic Manager actively monitors the health of all endpoints. It can monitor the health of VMs, cloud services, and app services. If it determines that the health of an application deployed to a region is not suitable for redirecting traffic, it redirects the requests to a healthy endpoint.</p>
			<p>Secondly, Traffic Manager can be configured with routing information. There are six traffic routing methods available in Traffic Manager, which are as follows:</p>
			<ul>
				<li><strong class="bold">Priority</strong>: This should be used when all traffic should go to a default endpoint, and backups are available in case the primary endpoints are unavailable.</li>
				<li><strong class="bold">Weighted</strong>: This should be used to distribute traffic across endpoints evenly, or according to defined weights.</li>
				<li><strong class="bold">Performance</strong>: This should be used for endpoints in different regions, and users should be redirected to the closest endpoint based on their location. This has a direct impact on network latency.</li>
				<li><strong class="bold">Geographic</strong>: This should be used to redirect users to an endpoint (Azure, external, or nested) based on the nearest geographical location. This can help in adhering to compliance related to data protection, localization, and region-based traffic collection.</li>
				<li><strong class="bold">Subnet</strong>: This is a new routing method and it helps in providing clients with different endpoints based on their IP addresses. In this method, a range of IP addresses are assigned to each endpoint. These IP address ranges are mapped to the client IP address to determine an appropriate returning endpoint. Using this routing method, it is possible to provide different content to different people based on their originating IP address. </li>
				<li><strong class="bold">Multivalue</strong>: This is also a new method added in Azure. In this method, multiple endpoints are returned to the client and any of them can be used. This ensures that if one endpoint is unhealthy, then other endpoints can be used instead. This helps in increasing the overall availability of the solution.</li>
			</ul>
			<p>It should be noted that after Traffic Manager determines a valid healthy endpoint, clients connect directly to the application. Let's now move on to understand Azure's capabilities in routing user requests globally.</p>
			<p>In the next section, we will be discussing another service, called Azure Front Door. This service is like Azure Application Gateway; however, there is a small difference that makes this service distinct. Let's go ahead and learn more about Azure Front Door.</p>
			<h3 id="_idParaDest-45"><a id="_idTextAnchor047"/>Azure Front Door</h3>
			<p>Azure Front Door is the latest offering in Azure that helps route requests to services at a global level instead of a local region or datacenter level, as in the case of Azure Application Gateway and load balancers. Azure Front Door is like Application Gateway, with the difference being in the scope. It is a layer 7 load balancer that helps in routing requests to the nearest best-performing service endpoint deployed in multiple regions. It provides features such as TLS termination, session affinity, URL-based routing, and multiple site hosting, along with a web application firewall. It is similar to Traffic Manager in that it is, by default, resilient to entire region failures and it provides routing capabilities. It also conducts endpoint health probes periodically to ensure that requests are routed to healthy endpoints only.</p>
			<p>It provides four different routing methods:</p>
			<ul>
				<li><strong class="bold">Latency</strong>: Requests will route to endpoints that will have the least latency end to end.</li>
				<li><strong class="bold">Priority</strong>: Requests will route to a primary endpoint and to a secondary endpoint in the case of the failure of the primary.</li>
				<li><strong class="bold">Weighted</strong>: Requests will route based on weights assigned to the endpoints.</li>
				<li><strong class="bold">Session Affinity</strong>: Requests in a session will end up with the same endpoint to make use of session data from prior requests. The original request can end up with any available endpoint.</li>
			</ul>
			<p>Deployments looking for resilience at the global level should include Azure Front Door in their architecture, alongside application gateways and load balancers. In the next section, you will see some of the architectural considerations that you should account for while designing highly available solutions.</p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor048"/>Architectural considerations for high availability</h2>
			<p>Azure provides high availability through various means and at various levels. High availability can be at the datacenter level, the region level, or even across Azure. In this section, we will go through some of the architectures for high availability.</p>
			<h3 id="_idParaDest-47"><a id="_idTextAnchor049"/>High availability within Azure regions</h3>
			<p>The architecture shown in <em class="italics">Figure 2.6</em> shows a high-availability deployment within a single Azure region. High availability is designed at the individual resource level. In this architecture, there are multiple VMs at each tier connected through either an application gateway or a load balancer, and they are each part of an availability set. Each tier is associated with an availability set. These VMs are placed on separate fault and update domains. While the web servers are connected to application gateways, the rest of the tiers, such as the application and database tiers, have internal load balancers:</p>
			<div>
				<div id="_idContainer022" class="IMG---Figure">
					<img src="image/B15432_02_06.jpg" alt="High-availability deployment within a single Azure region"/>
				</div>
			</div>
			<h6>Figure 2.6: Designing high availability within a region</h6>
			<p>Now that you know how to design highly available solutions in the same region, let's discuss how an architecture that is similar, but spread across Azure regions, can be designed.</p>
			<h3 id="_idParaDest-48"><a id="_idTextAnchor050"/>High availability across Azure regions</h3>
			<p>This architecture shows similar deployments in two different Azure regions. As shown in <em class="italics">Figure 2.7</em>, both regions have the same resources deployed. High availability is designed at the individual resource level within these regions. There are multiple VMs at each tier, connected through load balancers, and they are part of an availability set. These VMs are placed on separate fault and update domains. While the web servers are connected to external load balancers, the rest of the tiers, such as the application and database tiers, have internal load balancers. It should be noted that application load balancers can be used for web servers and the application tier (instead of Azure load balancers) if there is a need for advanced services, such as session affinity, SSL termination, advanced security using a <strong class="bold">web application firewall</strong> (<strong class="bold">WAF</strong>), and path-based routing. The databases in both regions are connected to each other using virtual network peering and gateways. This is helpful in configuring log shipping, SQL Server Always On, and other data synchronization techniques.</p>
			<p>The endpoints of the load balancers from both regions are used to configure Traffic Manager endpoints, and traffic is routed based on the priority load-balancing method. Traffic Manager helps in routing all requests to the East US region and, after failover, to West Europe in the case of the non-availability of the first region:</p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="image/B15432_02_07.jpg" alt="High-availability deployment across two Azure regions"/>
				</div>
			</div>
			<h6>Figure 2.7: Designing high availability across Azure regions</h6>
			<p>In the next section, we will be exploring scalability, which is another advantage of the cloud.</p>
			<h2 id="_idParaDest-49"><a id="_idTextAnchor051"/>Scalability</h2>
			<p>Running applications and systems that are available to users for consumption is important for architects of any business-critical application. However, there is another equally important application feature that is one of the top priorities for architects, and this is the scalability of the application.</p>
			<p>Imagine a situation in which an application is deployed and obtains great performance and availability with a few users, but both availability and performance decrease as the number of users begin to increase. There are times when an application performs well under a normal load, but suffers a drop in performance with an increase in the number of users. This can happen if there is a sudden increase in the number of users and the environment is not built for such a large number of users.</p>
			<p>To accommodate such spikes in the number of users, you might provision the hardware and bandwidth for handling spikes. The challenge with this is that the additional capacity is not used for the majority of the year, and so does not provide any return on investment. It is provisioned for use only during the holiday season or sales. I hope that by now you are becoming familiar with the problems that architects are trying to solve. All these problems are related to capacity sizing and the scalability of an application. The focus of this chapter is to understand scalability as an architectural concern and to check out the services that are provided by Azure for implementing scalability.</p>
			<p>Capacity planning and sizing are a couple of the top priorities for architects and their applications and services. Architects must find a balance between buying and provisioning too many resources and buying and provisioning too few resources. Having too few resources can lead to you not being able to serve all users, resulting in them turning to a competitor. On the other hand, having too many resources can hurt your budget and return on investment because most of the resources will remain unused most of the time. Moreover, the problem is amplified by the varying level of demand at different times. It is almost impossible to predict the number of users of an application over a day, let alone a year. However, it is possible to find an approximate number using past information and continuous monitoring.</p>
			<p>Scalability refers to the ability to handle a growing number of users and provide them with the same level of performance as when there are fewer users utilizing resources for application deployment, processes, and technology. Scalability might mean serving more requests without a decrease in performance, or it might mean handling larger and more time-consuming work without any loss of performance in both cases.</p>
			<p>Capacity planning and sizing exercises should be undertaken by architects at the very beginning of a project and during the planning phase to provide scalability to applications.</p>
			<p>Some applications have stable demand patterns, while it is difficult to predict others. Scalability requirements are known for stable-demand applications, while discerning them can be a more involved process for variable-demand applications. Autoscaling, a concept that we will review in the next section, should be used for applications whose demands cannot be predicted.</p>
			<p>People often tend to confuse scalability with performance. In the next section, you will see a quick comparison of these two terms.</p>
			<h3 id="_idParaDest-50"><a id="_idTextAnchor052"/>Scalability versus performance</h3>
			<p>It is quite easy to get confused between scalability and performance when it comes to architectural concerns, because scalability is all about ensuring that irrespective of the number of users consuming the application, all users receive the same predetermined level of performance.</p>
			<p>Performance relates to ensuring that an application caters to predefined response times and throughput. Scalability refers to having provisions for more resources when needed in order to accommodate more users without sacrificing performance.</p>
			<p>It is better to understand this using an analogy: the speed of a train directly relates to the performance of a railway network. However, getting more trains to run in parallel at the same or at higher speeds represents the scalability of the railway network.</p>
			<p>Now that you know what the difference between scalability and performance is, let's discuss how Azure provides scalability.</p>
			<h3 id="_idParaDest-51"><a id="_idTextAnchor053"/>Azure scalability</h3>
			<p>In this section, we will look at the features and capabilities provided by Azure to make applications highly available. Before we get into the architecture and configuration details, it is important to understand Azure's high-availability concepts, in other words, scaling.</p>
			<p>Scaling refers to either increasing or decreasing the amount of resources that are used to serve requests from users. Scaling can be automatic or manual. Manual scaling requires an administrator to manually initiate the scaling process, while automatic scaling refers to an automatic increase or decrease in resources based on the events available from the environment and ecosystem, such as memory and CPU availability. Resources can be scaled up or down, or out and in, which will be explained later in this section.</p>
			<p>In addition to rolling updates, the fundamental constructs provided by Azure to achieve high availability are as follows:</p>
			<ul>
				<li>Scaling up and down</li>
				<li>Scaling out and in</li>
				<li>Autoscaling</li>
			</ul>
			<p><strong class="bold">Scaling up</strong></p>
			<p>Scaling a VM or service up entails the addition of further resources to existing servers, such as CPU, memory, and disks. It aims to increase the capacity of existing physical hardware and resources.</p>
			<p><strong class="bold">Scaling down</strong></p>
			<p>Scaling a VM or service down entails the removal of existing resources from existing servers, such as CPU, memory, and disks. It aims to decrease the capacity of existing physical and virtual hardware and resources.</p>
			<p><strong class="bold">Scaling out</strong></p>
			<p>Scaling out entails adding further hardware, such as additional servers and capacity. This typically involves adding new servers, assigning them IP addresses, deploying applications on them, and making them part of the existing load balancers such that traffic can be routed to them. Scaling out can be automatic or manual as well. However, for better results, automation should be used:</p>
			<div>
				<div id="_idContainer024" class="IMG---Figure">
					<img src="image/B15432_02_08.jpg" alt="Scaling out"/>
				</div>
			</div>
			<h6>Figure 2.8: Scaling out</h6>
			<p><strong class="bold">Scaling in</strong></p>
			<p>Scaling in refers to the process of removing the existing hardware in terms of existing servers and capacity. This typically involves removing existing servers, deallocating their IP addresses, and removing them from the existing load balancer configuration such that traffic cannot be routed to them. Like scaling out, scaling in can be automatic or manual.</p>
			<p><strong class="bold">Autoscaling</strong></p>
			<p>Autoscaling refers to the process of either scaling up/down or scaling out/in dynamically based on application demand, and this happens using automation. Autoscaling is useful because it ensures that a deployment always consists of an ideal number of server instances. Autoscaling helps in building applications that are fault tolerant. It not only supports scalability, but also makes applications highly available. Finally, it provides the best cost management. Autoscaling makes it possible to have the optimal configuration for server instances based on demand. It helps in not over-provisioning servers, only for them to end up being underutilized, and removes servers that are no longer required after scaling out. </p>
			<p>So far, we've discussed scalability in Azure. Azure offers scalability options for most of its services. Let's explore scalability for PaaS in Azure in the next section.</p>
			<h3 id="_idParaDest-52"><a id="_idTextAnchor054"/>PaaS scalability</h3>
			<p>Azure provides App Service for hosting managed applications. App Service is a PaaS offering from Azure. It provides services for the web and mobile platforms. Behind the web and mobile platforms is a managed infrastructure that is managed by Azure on behalf of its users. Users do not see or manage any infrastructure; however, they have the ability to extend the platform and deploy their applications on top of it. In doing so, architects and developers can concentrate on their business problems instead of worrying about the base platform and infrastructure provisioning, configuration, and troubleshooting. Developers have the flexibility to choose any language, OS, and framework to develop their applications. App Service provides multiple plans and, based on the plans chosen, various degrees of scalability are available. App Service provides the following five plans:</p>
			<ul>
				<li><strong class="bold">Free</strong>: This uses shared infrastructure. It means that multiple applications will be deployed on the same infrastructure from the same or multiple tenants. It provides 1 GB of storage free of charge. However, there is no scaling facility in this plan.</li>
				<li><strong class="bold">Shared</strong>: This also uses shared infrastructure and provides 1 GB of storage free of charge. Additionally, custom domains are also provided as an extra feature. However, there is no scaling facility in this plan.</li>
				<li><strong class="bold">Basic</strong>: This has three different <strong class="bold">stock keeping units</strong> (<strong class="bold">SKUs</strong>): B1, B2, and B3. They each have increasing units of resources available to them in terms of CPU and memory. In short, they provide improved configuration of the VMs backing these services. Additionally, they provide storage, custom domains, and SSL support. The basic plan provides basic features for manual scaling. There is no autoscaling available in this plan. A maximum of three instances can be used to scale out an application.</li>
				<li><strong class="bold">Standard</strong>: This also has three different SKUs: S1, S2, and S3. They each have increasing units of resources available to them in terms of CPU and memory. In short, they provide improved configuration of the VMs backing these services. Additionally, they provide storage, custom domains, and SSL support that is similar to that of the basic plan. This plan also provides a Traffic Manager instance, staging slots, and one daily backup as an additional feature on top of the basic plan. The standard plan provides features for automatic scaling. A maximum of 10 instances can be used to scale out the application.</li>
				<li><strong class="bold">Premium</strong>: This also has three different SKUs: P1, P2, and P3. They each have increasing units of resources available to them in terms of CPU and memory. In short, they provide improved configuration of the VMs backing these services. Additionally, they provide storage, custom domains, and SSL support that is similar to the basic plan. This plan also provides a Traffic Manager instance, staging slots, and 50 daily backups as an additional feature on top of the basic plan. The standard plan provides features for autoscaling. A maximum of 20 instances can be used to scale out the application.</li>
			</ul>
			<p>We have explored the scalability tiers available for PaaS services. Now, let's see how scaling can be done in the case of an App Service plan.</p>
			<p><strong class="bold">PaaS – scaling up and down</strong></p>
			<p>Scaling up and down services that are hosted by App Service is quite simple. The Azure app services Scale Up menu opens a new pane with all plans and their SKUs listed. Choosing a plan and SKU will scale a service up or down, as shown in <em class="italics">Figure 2.9</em>:</p>
			<div>
				<div id="_idContainer025" class="IMG---Figure">
					<img src="image/B15432_02_09.jpg" alt="Different plans with their SKUs"/>
				</div>
			</div>
			<h6>Figure 2.9: Different plans with their SKUs</h6>
			<p><strong class="bold">PaaS – scaling out and in</strong></p>
			<p>Scaling out and in services hosted in App Service is also quite simple. The Azure app services Scale Out menu item opens a new pane with scaling configuration options.</p>
			<p>By default, autoscaling is disabled for both premium and standard plans. It can be enabled using the <strong class="bold">Scale Out</strong> menu item and by clicking on the <strong class="bold">Enable autoscale</strong> button, as shown in <em class="italics">Figure 2.10</em>:</p>
			<div>
				<div id="_idContainer026" class="IMG---Figure">
					<img src="image/B15432_02_10.jpg" alt="Enabling autoscale in scale out "/>
				</div>
			</div>
			<h6>Figure 2.10: Enabling the autoscale option</h6>
			<p>Manual scaling does not require configuration, but autoscaling helps in configuring with the aid of the following properties:</p>
			<ul>
				<li><strong class="bold">Mode of scaling</strong>: This is based on a performance metric such as CPU or memory usage, or users can simply specify a number of instances for scaling.</li>
				<li><strong class="bold">When to scale</strong>: Multiple rules can be added that determine when to scale out and in. Each rule can determine criteria such as CPU or memory consumption, whether to increase or decrease the number of instances, and how many instances to increase or decrease to at a time. At least one rule for scaling out and one rule for scaling in should be configured. Threshold definitions help in defining the upper and lower limits that should trigger the autoscale—by either increasing or decreasing the number of instances.</li>
				<li><strong class="bold">How to scale</strong>: This specifies how many instances to create or remove in each scale-out or scale-in operation:<div id="_idContainer027" class="IMG---Figure"><img src="image/B15432_02_11.jpg" alt="Setting the instance limits for scalling"/></div></li>
			</ul>
			<h6>Figure 2.11: Setting the instance limits</h6>
			<p>This is quite a good feature to enable in any deployment. However, you should enable both scaling out and scaling in together to ensure that your environment is back to normal capacity after scaling out.</p>
			<p>Since we have covered the scalability in PaaS, let's move on and discuss scalability in IaaS next.</p>
			<h3 id="_idParaDest-53"><a id="_idTextAnchor055"/>IaaS scalability</h3>
			<p>There are users who will want to have complete control over their base infrastructure, platform, and application. They will prefer to consume IaaS solutions rather than PaaS solutions. When such customers create VMs, they are also responsible for capacity sizing and scaling. There is no out-of-the-box configuration for manually scaling or autoscaling VMs. These customers will have to write their own automation scripts, triggers, and rules to achieve autoscaling. With VMs comes the responsibility of maintaining them. The patching, updating, and upgrading of VMs is the responsibility of owners. Architects should think about both planned and unplanned maintenance. How these VMs should be patched, the order, grouping, and other factors must be considered to ensure that neither the scalability nor the availability of an application is compromised. To help alleviate such problems, Azure provides <strong class="bold">VM scale sets</strong> (<strong class="bold">VMSS</strong>) as a solution, which we will discuss next. </p>
			<h2 id="_idParaDest-54"><a id="_idTextAnchor056"/>VM scale sets</h2>
			<p>VMSSes are Azure compute resources that you can use to deploy and manage a set of identical VMs. With all VMs configured in the same way, scale sets are designed to support true autoscaling, and no pre-provisioning of VMs is required. It helps in provisioning multiple identical VMs that are connected to each other through a virtual network and subnet.</p>
			<p>A VMSS consists of multiple VMs, but they are managed at the VMSS level. All VMs are part of this unit and any changes made are applied to the unit, which, in turn, applies it to those VMs that are using a predetermined algorithm:</p>
			<div>
				<div id="_idContainer028" class="IMG---Figure">
					<img src="image/B15432_02_12.jpg" alt="A VM Scale set"/>
				</div>
			</div>
			<h6>Figure 2.12: A VM scale set</h6>
			<p>This enables these VMs to be load balanced using an Azure load balancer or an application gateway. The VMs could be either Windows or Linux VMs. They can run automated scripts using a PowerShell extension and they can be managed centrally using a state configuration. They can be monitored as a unit, or individually using Log Analytics.</p>
			<p>VMSSes can be provisioned from the Azure portal, the Azure CLI, Azure Resource Manager templates, REST APIs, and PowerShell cmdlets. It is possible to invoke REST APIs and the Azure CLI from any platform, environment, or OS, and in any language.</p>
			<p>Many of Azure's services already use VMSSes as their underlying architecture. Among them are Azure Batch, Azure Service Fabric, and Azure Container Service. Azure Container Service, in turn, provisions Kubernetes and DC/OS on these VMSSes.</p>
			<h3 id="_idParaDest-55"><a id="_idTextAnchor057"/>VMSS architecture</h3>
			<p>VMSSes allow the creation of up to 1,000 VMs in a scale set when using a platform image, and 100 VMs if using a custom image. If the number of VMs is less than 100 in a scale set, they are placed in a single availability set; however, if the number is greater than 100, multiple availability sets are created (known as placement groups), and VMs are distributed among these availability sets. We know from <em class="italics">Chapter 1, Getting started with Azure</em>, that VMs in an availability set are placed on separate fault and update domains. Availability sets related to VMSSes have five fault and update domains by default. VMSSes provide a model that holds metadata information for the entire set. Changing this model and applying changes impacts all VM instances. This information includes the maximum and minimum number of VM instances, the OS SKU and version, the current number of VMs, fault and update domains, and more. This is demonstrated in <em class="italics">Figure 2.13</em>: </p>
			<div>
				<div id="_idContainer029" class="IMG---Figure">
					<img src="image/B15432_02_13.jpg" alt="Metadata information for an availability set"/>
				</div>
			</div>
			<h6>Figure 2.13: VMs in an availability set</h6>
			<h3 id="_idParaDest-56"><a id="_idTextAnchor058"/>VMSS scaling</h3>
			<p>Scaling refers to increasing or decreasing compute and storage resources. A VMSS is a feature-rich resource that makes scaling easy and efficient. It provides autoscaling, which helps in scaling up or down based on external events and data such as CPU and memory usage. Some of the VMSS scaling features are given here.</p>
			<p><strong class="bold">Horizontal versus vertical scaling</strong></p>
			<p>Scaling can be horizontal or vertical, or both. Horizontal scaling is another name for scaling out and in, while vertical scaling refers to scaling up and down.</p>
			<p><strong class="bold">Capacity</strong></p>
			<p>VMSSes have a <strong class="inline">capacity</strong> property that determines the number of VMs in a scale set. A VMSS can be deployed with zero as a value for this property. It will not create a single VM; however, if you provision a VMSS by providing a number for the <strong class="inline">capacity</strong> property, that number of VMs are created.</p>
			<p><strong class="bold">Autoscaling</strong></p>
			<p>The autoscaling of VMs in a VMSS refers to the addition or removal of VM instances based on the configured environment in order to meet the performance and scalability demands of an application. Generally, in the absence of a VMSS, this is achieved using automation scripts and runbooks.</p>
			<p>VMSSes help in this automation process with the support of configuration. Instead of writing scripts, a VMSS can be configured for autoscaling up and down.</p>
			<p>Autoscaling uses multiple integrated components to achieve its end goal. Autoscaling entails continuously monitoring VMs and collecting telemetry data about them. This data is stored, combined, and then evaluated against a set of rules to determine whether autoscaling should be triggered. The trigger could be to scale out or scale in. It could also be to scale up or down. </p>
			<p>The autoscaling mechanism uses diagnostic logs for collecting telemetry data from VMs. These logs are stored in storage accounts as diagnostic metrics. The autoscaling mechanism also uses the Application Insights monitoring service, which reads these metrics, combines them, and stores them in a storage account.</p>
			<p>Background autoscaling jobs run continually to read Application Insights' storage data, evaluate it based on all the rules configured for autoscaling, and, if any of the rules or combination of rules are met, run the process of autoscaling. The rules can take into consideration the metrics from guest VMs and the host server.</p>
			<p>The rules defined using the property descriptions are available at <a href="https://docs.microsoft.com/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-autoscale-overview">https://docs.microsoft.com/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-autoscale-overview</a>.</p>
			<p>The VMSS autoscale architecture is shown in <em class="italics">Figure 2.14</em>:</p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B15432_02_14.jpg" alt="VMSS autoscale architecture"/>
				</div>
			</div>
			<h6>Figure 2.14: VMSS autoscale architecture</h6>
			<p>Autoscaling can be configured for scenarios that are more complex than general metrics available from environments. For example, scaling could be based on any of the following:</p>
			<ul>
				<li>A specific day</li>
				<li>A recurring schedule such as weekends</li>
				<li>Weekdays versus weekends</li>
				<li>Holidays and one-off events</li>
				<li>Multiple resource metrics</li>
			</ul>
			<p>These can be configured using the <strong class="inline">schedule</strong> property of Application Insights resources, which help in registering rules.</p>
			<p>Architects should ensure that at least two actions—scale out and scale in—are configured together. Scaling a configuration in or out will not help in achieving the scaling benefits provided by VMSSes.</p>
			<p>To summarize, we have covered the scalability options in Azure and the detailed scaling features in the case of IaaS and PaaS to meet your business requirements. If you recall the shared responsibility model, you'll remember that platform upgrades and maintenance should be done by the cloud provider. In this case, Microsoft takes care of upgrades and maintenance related to the platform. Let's see how this is achieved in the next section.</p>
			<h2 id="_idParaDest-57"><a id="_idTextAnchor059"/>Upgrades and maintenance</h2>
			<p>After a VMSS and applications are deployed, they need to be actively maintained. Planned maintenance should be conducted periodically to ensure that both the environment and application are up to date with the latest features, from a security and resilience point of view.</p>
			<p>Upgrades can be associated with applications, the guest VM instance, or the image itself. Upgrades can be quite complex because they should happen without affecting the availability, scalability, and performance of environments and applications. To ensure that updates can take place one instance at a time using rolling upgrade methods, it is important that a VMSS supports and provides capabilities for these advanced scenarios.</p>
			<p>There is a utility provided by the Azure team to manage updates for VMSSes. It's a Python-based utility that can be downloaded from <a href="https://github.com/gbowerman/vmssdashboard">https://github.com/gbowerman/vmssdashboard</a>. It makes REST API calls to Azure to manage scale sets. This utility can be used to start, stop, upgrade, and reimage VMs on in an FD or group of VMs, as shown in <em class="italics">Figure 2.15</em>:</p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B15432_02_15.jpg" alt="Utility for managing VMSS updates"/>
				</div>
			</div>
			<h6>Figure 2.15: Utility for managing VMSS updates</h6>
			<p>Since you have a basic understanding of upgrade and maintenance, let's see how application updates are done in VMSSes.</p>
			<h3 id="_idParaDest-58"><a id="_idTextAnchor060"/>Application updates</h3>
			<p>Application updates in VMSSes should not be executed manually. They must be run as part of the release management and pipelines that use automation. Moreover, an update should happen one application instance at a time and not affect the overall availability and scalability of an application. Configuration management tools, such as <strong class="bold">Desired State Configuration</strong> (<strong class="bold">DSC</strong>), should be deployed to manage application updates. The DSC pull server can be configured with the latest version of the application configuration and it should be applied on a rolling basis to each instance.</p>
			<p>In the next section, we will focus on how the updates are done on the guest OS.</p>
			<h3 id="_idParaDest-59"><a id="_idTextAnchor061"/>Guest updates</h3>
			<p>Updates to VMs are the responsibility of the administrator. Azure is not responsible for patching guest VMs. Guest updates are in preview mode and users should control patching manually or use custom automation methods, such as runbooks and scripts. However, rolling patch upgrades are in preview mode and can be configured in the Azure Resource Manager template using an upgrade policy, as follows:</p>
			<p class="snippet">"upgradePolicy": {"mode": "Rolling","automaticOSUpgrade": "true" or "false",  "rollingUpgradePolicy": {    "batchInstancePercent": 20,    "maxUnhealthyUpgradedInstanceCount": 0,    "pauseTimeBetweenBatches": "PT0S"  }}</p>
			<p>Now that we know how guest updates are managed in Azure, let's see how image updates are accomplished.</p>
			<h3 id="_idParaDest-60"><a id="_idTextAnchor062"/>Image updates</h3>
			<p>A VMSS can update the OS version without any downtime. OS updates involve changing the version or SKU of the OS or changing the URI of a custom image. Updating without downtime means updating VMs one at a time or in groups (such as one FD at a time) rather than all at once. By doing so, any VMs that are not being upgraded can keep running.</p>
			<p>So far, we have discussed updates and maintenance. Let's now examine what the best practices of scaling for VMSSes are.</p>
			<h3 id="_idParaDest-61"><a id="_idTextAnchor063"/>Best practices of scaling for VMSSes</h3>
			<p>In this section, we will go through some of the best practices that applications should implement to take advantage of the scaling capability provided by VMSSes.</p>
			<p><strong class="bold">The preference for scaling out</strong></p>
			<p>Scaling out is a better scaling solution than scaling up. Scaling up or down means resizing VM instances. When a VM is resized, it generally needs to be restarted, which has its own disadvantages. First, there is downtime for the machine. Second, if there are active users connected to the application on that instance, they might face a lack of availability of the application, or they might even lose transactions. Scaling out does not impact existing VMs; rather, it provisions newer machines and adds them to the group.</p>
			<p><strong class="bold">New instances versus dormant instances</strong></p>
			<p>Scaling new instances can take two broad approaches: creating the new instance from scratch, which requires installing applications, configuring, and testing them; or starting the dormant, sleeping instances when they are needed due to scalability pressure on other servers.</p>
			<p><strong class="bold">Configuring the maximum and minimum number of instances appropriately</strong></p>
			<p>Setting a value of two for both the minimum and maximum instance counts, with the current instance count being two, means no scaling action can occur. There should be an adequate difference between the maximum and minimum instance counts, which are inclusive. Autoscaling always scales between these limits.</p>
			<p><strong class="bold">Concurrency</strong></p>
			<p>Applications are designed for scalability to focus on concurrency. Applications should use asynchronous patterns to ensure that client requests do not wait indefinitely to acquire resources if resources are busy serving other requests. Implementing asynchronous patterns in code ensures that threads do not wait for resources and that systems are exhausted of all available threads. Applications should implement the concept of timeouts if intermittent failures are expected.</p>
			<p><strong class="bold">Designing stateless applications</strong></p>
			<p>Applications and services should be designed to be stateless. Scalability can become a challenge to achieve with stateful services, and it is quite easy to scale stateless services. With states comes the requirement for additional components and implementations, such as replication, centralized or decentralized repository, maintenance, and sticky sessions. All these are impediments on the path to scalability. Imagine a service maintaining an active state on a local server. Irrespective of the number of requests on the overall application or the individual server, the subsequent requests must be served by the same server. Subsequent requests cannot be processed by other servers. This makes scalability implementation a challenge.</p>
			<p><strong class="bold">Caching and the Content Distribution Network</strong> (<strong class="bold">CDN</strong>)</p>
			<p>Applications and services should take advantage of caching. Caching helps eliminate multiple subsequent calls to either databases or filesystems. This helps in making resources available and free for more requests. The CDN is another mechanism that is used to cache static files, such as images and JavaScript libraries. They are available on servers across the globe. They also make resources available and free for additional client requests—this makes applications highly scalable.</p>
			<p><strong class="bold">N+1 design</strong></p>
			<p><strong class="bold">N+1 design</strong> refers to building redundancy within the overall deployment for each component. It means to plan for some redundancy even when it is not required. This could mean additional VMs, storage, and network interfaces.</p>
			<p>Considering the preceding best practices while designing workloads using VMSSes will improve the scalability of your applications. In the next section, we will explore monitoring.</p>
			<h2 id="_idParaDest-62"><a id="_idTextAnchor064"/>Monitoring</h2>
			<p>Monitoring is an important architectural concern that should be part of any solution, big or small, mission-critical or not, cloud-based or not—it should not be neglected.</p>
			<p>Monitoring refers to the act of keeping track of solutions and capturing various telemetry information, processing it, identifying the information that qualifies for alerts based on rules, and raising them. Generally, an agent is deployed within the environment and monitors it, sending telemetry information to a centralized server, where the rest of the processing of generating alerts and notifying stakeholders takes place.</p>
			<p>Monitoring takes both proactive and reactive actions and measures against a solution. It is also the first step toward auditing a solution. Without the ability to monitor log records, it is difficult to audit a system from various perspectives, such as security, performance, and availability.</p>
			<p>Monitoring helps us identify availability, performance, and scalability issues before they arise. Hardware failure, software misconfiguration, and patch update challenges can be discovered well before they impact users through monitoring, and performance degradation can be fixed before it happens.</p>
			<p>Monitoring reactively logs pinpoint areas and locations that are causing issues, identifies the issues, and enables faster and better repairs.</p>
			<p>Teams can identify patterns of issues using monitoring telemetry information and eliminate them by innovating new solutions and features.</p>
			<p>Azure is a rich cloud environment that provides multiple rich monitoring features and resources to monitor not only cloud-based deployment but also on-premises deployment.</p>
			<h3 id="_idParaDest-63"><a id="_idTextAnchor065"/>Azure monitoring</h3>
			<p>The first question that should be answered is, "What must we monitor?" This question becomes more important for solutions that are deployed on the cloud because of the constrained control over them.</p>
			<p>There are some important components that should be monitored. They include the following:</p>
			<ul>
				<li>Custom applications</li>
				<li>Azure resources</li>
				<li>Guest OSes (VMs)</li>
				<li>Host OSes (Azure physical servers)</li>
				<li>Azure infrastructure</li>
			</ul>
			<p>There are different Azure logging and monitoring services for these components, and they are discussed in the following sections.</p>
			<h3 id="_idParaDest-64"><a id="_idTextAnchor066"/>Azure activity logs</h3>
			<p>Previously known as audit logs and operational logs, activity logs are control-plane events on the Azure platform. They provide information and telemetry information at the subscription level, instead of the individual resource level. They track information about all changes that happen at the subscription level, such as creating, deleting, and updating resources using <strong class="bold">Azure Resource Manager</strong> (<strong class="bold">ARM</strong>). Activity logs help us discover the identity of (such as service principal, users, or groups), and perform actions on (such as write or update), resources (for example, storage, virtual machines, or SQL databases) at any given point in time. They provide information about resources that are modified in their configuration, but not their inner workings and execution. For example, you can get the logs for starting a VM, resizing a VM, or stopping a VM.</p>
			<p>The next topic that we are going to discuss is diagnostic logs.</p>
			<h3 id="_idParaDest-65"><a id="_idTextAnchor067"/>Azure diagnostic logs</h3>
			<p>The information originating within the inner workings of Azure resources is captured in what are known as <strong class="bold">diagnostic logs</strong>. They provide telemetry information about the operations of resources that are inherent to the resources. Not every resource provides diagnostic logs, and resources that provide logs on their own content are completely different from other resources. Diagnostic logs are configured individually for each resource. Examples of diagnostic logs include storing a file in a container in a blob in a storage account.</p>
			<p>The next type of log that we are going to discuss is application logs.</p>
			<h3 id="_idParaDest-66"><a id="_idTextAnchor068"/>Azure application logs</h3>
			<p>Application logs can be captured by Application Insights resources and can be managed centrally. They get information about the inner workings of custom applications, such as their performance metrics and availability, and users can get insights from them in order to manage them better.</p>
			<p>Lastly, we have guest and host OS logs. Let's understand what these are.</p>
			<h3 id="_idParaDest-67"><a id="_idTextAnchor069"/>Guest and host OS logs</h3>
			<p>Both guest and host OS logs are offered to users using Azure Monitor. They provide information about the statuses of host and guest OSes:</p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B15432_02_16.jpg" alt="Different types of logs in Azure"/>
				</div>
			</div>
			<h6>Figure 2.16: Logging in Azure</h6>
			<p>The important Azure resources related to monitoring are Azure Monitor, Azure Application Insights, and Log Analytics, previously known as <strong class="bold">Operational Insights</strong>.</p>
			<p>There are other tools, such as <strong class="bold">System Center Operations Manager</strong> (<strong class="bold">SCOM</strong>), that are not part of the cloud feature but can be deployed on IaaS-based VMs to monitor any workload on Azure or an on-premises datacenter. Let's discuss the three monitoring resources in the following section.</p>
			<h3 id="_idParaDest-68"><a id="_idTextAnchor070"/>Azure Monitor</h3>
			<p>Azure Monitor is a central tool and resource that provides complete management features that allow you to monitor an Azure subscription. It provides management features for activity logs, diagnostic logs, metrics, Application Insights, and Log Analytics. It should be treated as a dashboard and management resource for all other monitoring capabilities.</p>
			<p>Our next topic is Azure Application Insights.</p>
			<h3 id="_idParaDest-69"><a id="_idTextAnchor071"/>Azure Application Insights</h3>
			<p>Azure Application Insights provides centralized, Azure-scale monitoring, logs, and metrics capabilities to custom applications. Custom applications can send metrics, logs, and other telemetry information to Azure Application Insights. It also provides rich reporting, dashboarding, and analytics capabilities to get insights from incoming data and act on them.</p>
			<p>Now that we have covered Application Insights, let's look at another similar service called Azure Log Analytics.</p>
			<h3 id="_idParaDest-70"><a id="_idTextAnchor072"/>Azure Log Analytics</h3>
			<p>Azure Log Analytics enables the centralized processing of logs and generates insights and alerts from them. Activity logs, diagnostic logs, application logs, event logs, and even custom logs can send information to Log Analytics, which can further provide rich reporting, dashboarding, and analytics capabilities to get insights from incoming data and act on them.</p>
			<p>Now that we know the purpose of Log Analytics, let's discuss how logs are stored in a Log Analytics workspace and how they can be queried.</p>
			<p><strong class="bold">Logs</strong></p>
			<p>A Log Analytics workspace provides search capabilities to search for specific log entries, export all telemetry data to Excel and/or Power BI, and search a query language called <strong class="bold">Kusto Query Language</strong> (<strong class="bold">KQL</strong>), which is similar to SQL.</p>
			<p>The <strong class="bold">Log Search</strong> screen is shown here:</p>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/B15432_02_17.jpg" alt="Log search in a Log Analytics workspace"/>
				</div>
			</div>
			<h6>Figure 2.17: Log search in a Log Analytics workspace</h6>
			<p>In the next section, we will be covering Log Analytics solutions, which are like additional capabilities in a Log Analytics workspace.</p>
			<h3 id="_idParaDest-71"><a id="_idTextAnchor073"/>Solutions</h3>
			<p>Solutions in Log Analytics are further capabilities that can be added to a workspace, capturing additional telemetry data that is not captured by default. When these solutions are added to a workspace, appropriate management packs are sent to all the agents connected to the workspace so that they can configure themselves to capture solution-specific data from VMs and containers and then send it to the Log Analytics workspace. Monitoring solutions from Microsoft and partners are available from Azure Marketplace.</p>
			<p>Azure provides lots of Log Analytics solutions for tracking and monitoring different aspects of environments and applications. At a minimum, a set of solutions that are generic and applicable to almost any environment should be added to the workspace:</p>
			<ul>
				<li>Capacity and performance</li>
				<li>Agent health</li>
				<li>Change tracking</li>
				<li>Containers</li>
				<li>Security and audit</li>
				<li>Update management</li>
				<li>Network performance monitoring</li>
			</ul>
			<p>Another key aspect of monitoring is alerts. Alerts help to notify the right people during any monitored event. In the next section, we will cover alerts.</p>
			<h3 id="_idParaDest-72"><a id="_idTextAnchor074"/>Alerts</h3>
			<p>Log Analytics allows us to generate alerts in relation to ingested data. It does so by running a pre-defined query composed of conditions for incoming data. If it finds any records that fall within the ambit of the query results, it generates an alert. Log Analytics provides a highly configurable environment for determining the conditions for generating alerts, time windows in which the query should return the records, time windows in which the query should be executed, and actions to be taken when the query returns an alert:</p>
			<div>
				<div id="_idContainer034" class="IMG---Figure">
					<img src="image/B15432_02_18.jpg" alt="Configuring alerts through Log Analytics"/>
				</div>
			</div>
			<h6>Figure 2.18: Configuring alerts through Log Analytics</h6>
			<p>Let's go through the steps for configuring alerts through Log Analytics:</p>
			<ol>
				<li>The first step in configuring an alert is to add a new alert rule from the Azure portal or automation from the alert menu of the Log Analytics resource.</li>
				<li>The first step in configuring an alert is to add a new alert rule from the Azure portal or automation from the alert menu of the Log Analytics resource.</li>
				<li>From the resultant panel, select a scope for the alert rule. The scope determines which resource should be monitored for alerts—it could be a resource instance, such as an Azure storage account, a resource type, such as an Azure VM, a resource group, or a subscription:<div id="_idContainer035" class="IMG---Figure"><img src="image/B15432_02_19.jpg" alt="Selecting a resource for creating the alert"/></div><p> </p><h6>Figure 2.19: Selecting a resource for the alert</h6></li>
				<li>Following resource selection, conditions must be set for the alert. The condition determines the rule that is evaluated against the logs and metrics on the selected resource, and only after the condition turns true is an alert generated. There are a ton of metrics and logs available for generating conditions. In the following example, an alert is created with a static threshold value of 80% for <strong class="bold">Percentage</strong> <strong class="bold">CPU</strong> (<strong class="bold">Avg</strong>) and the data is to be collected every five minutes and evaluated every minute:<div id="_idContainer036" class="IMG---Figure"><img src="image/B15432_02_20.jpg" alt="Creating an alert for Percentage CPU (Avg)"/></div><h6>Figure 2.20: Creating an alert for Percentage CPU (Avg)</h6><p>Alerts also support dynamic thresholds, which use machine learning to learn the historical behavior of metrics and detect irregularities that could indicate service issues. </p></li>
				<li>Finally, create an action group or reuse an existing group that determines notifications regarding alerts to stakeholders. The <strong class="bold">Action Groups</strong> section allows you to configure things that should follow an alert. Generally, there should be a remedial and/or notification action. Log Analytics provides eight different ways to create a new action. They can be combined in any way you like. An alert will execute any or all of the following configured actions:<ul><li><strong class="bold">Email/SMS/push/voice notification</strong>: This sends an email/SMS/push/voice notification to the configured recipients.</li><li><strong class="bold">Webhooks</strong>: A webhook runs an arbitrary external process using an HTTP POST mechanism. For example, a REST API can be executed, or the Service Manager/ServiceNow APIs can be invoked to create a ticket.</li><li><strong class="bold">Azure Functions</strong>: This runs an Azure function, passing the necessary payload and running the logic that the payload contains.</li><li><strong class="bold">Logic Apps</strong>: This executes a custom Logic Apps workflow.</li><li><strong class="bold">Email Azure Resource Manager Role</strong>: This emails a holder of an Azure Resource Manager role, such as an owner, contributor, or reader. </li><li><strong class="bold">Secure webhook</strong>: A webhook runs an arbitrary external process using an HTTP POST mechanism. Webhooks are protected using an identity provider, such as Azure Active Directory.</li><li><strong class="bold">Automation runbooks</strong>: This action executes Azure Automation runbooks. </li><li><strong class="bold">ITSM</strong>: ITSM solutions should be provisioned before using this option. It helps with connecting and sending information to ITSM systems.</li></ul></li>
				<li>After all of this configuration, you need to provide the <strong class="bold">Name</strong>, <strong class="bold">Description</strong>, and <strong class="bold">Severity</strong> values for the alert rule to generate it.</li>
			</ol>
			<p>As mentioned at the beginning of this section, alerts play a vital role in monitoring that helps authorized personnel to take necessary actions based on the alert that's triggered.</p>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor075"/>Summary</h2>
			<p>High availability and scalability are crucially important architectural concerns. Almost every application and every architect try to implement high availability. Azure is a mature platform that understands the need for these architectural concerns in applications and provides resources to implement them at multiple levels. These architectural concerns are not an afterthought, and they should be part of the application development life cycle, starting from the planning phase itself. </p>
			<p>Monitoring is an important architectural aspect of any solution. It is also the first step toward being able to audit an application properly. It enables operations to manage a solution, both reactively and proactively. It provides the necessary records for troubleshooting and fixing the issues that might arise from platforms and applications. There are many resources in Azure that are specific to implementing monitoring for Azure, other clouds, and on-premises datacenters. Application Insights and Log Analytics are two of the most important resources in this regard. Needless to say, monitoring is a must for making your solutions and products better by innovating based on insights derived from monitoring data. </p>
			<p>This chapter was purely about the availability, scalability, and monitoring of solutions; the next chapter is about design patterns related to virtual networks, storage accounts, regions, availability zones, and availability sets. While designing solutions in the cloud, these principles are very important in building cost-effective solutions with increased productivity and availability.</p>
		</div>
	</body></html>