- en: 2\. Azure solution availability, scalability, and monitoring
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. Azure解决方案的可用性、可扩展性和监控
- en: Architectural concerns, such as high availability and scalability, are some of
    the highest-priority items for any architect. This is common across many projects
    and solutions. However, this becomes even more important when deploying applications
    to the cloud because of the complexity involved. Most of the time, the complexity
    does not come from the application, but from the choices available in terms of
    similar resources on the cloud. The other complex issue that arises from the cloud
    is the constant availability of new features. These new features can almost make
    an architect's decisions completely redundant in hindsight.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 架构上的关注点，如高可用性和可扩展性，是任何架构师最高优先级的任务之一。这在许多项目和解决方案中都很常见。然而，在将应用程序部署到云端时，这些问题变得尤为重要，因为云端的复杂性。在大多数情况下，复杂性并不是来自应用程序本身，而是来自云中类似资源的多样性。云端带来的另一个复杂问题是新功能的不断涌现。这些新功能几乎使得架构师的决策在回顾时完全显得多余。
- en: In this chapter, we will look at an architect's perspective in terms of deploying
    highly available and scalable applications on Azure.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将从架构师的角度，探讨如何在Azure上部署高度可用和可扩展的应用程序。
- en: Azure is a mature platform that provides a number of options for implementing
    high availability and scalability at multiple levels. It is vital for an architect
    to know about them, including the differences between them and the costs involved,
    and finally, be in a position to choose an appropriate solution that meets the
    best solution requirements. There is no one solution for everything, but there
    is a good one for each project.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Azure是一个成熟的平台，提供了多个级别的高可用性和可扩展性的实现选项。架构师必须了解这些选项，包括它们之间的差异、所涉及的成本，并最终能够选择一个符合最佳需求的解决方案。没有一个适合所有场景的解决方案，但每个项目都有一个合适的方案。
- en: Running applications and systems that are available to users for consumption
    whenever they need them is one of the topmost priorities for organizations. They
    want their applications to be operational and functional, and to continue to be
    available to their customers even when some untoward events occur. High availability
    is the primary theme of this chapter. *Keeping the lights on* is the common metaphor
    that is used for high availability. Achieving high availability for applications
    is not an easy task, and organizations have to spend considerable time, energy,
    resources, and money in doing so. Additionally, there is still the risk that an
    organization's implementation will not produce the desired results. Azure provides
    a lot of high-availability features for **virtual machines** (**VMs**) and the **Platform
    as a Service** (**PaaS**) service. In this chapter, we will go through the architectural
    and design features that are provided by Azure to ensure high availability for
    running applications and services.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 对于组织来说，能够随时向用户提供可用的应用程序和系统，是最重要的优先事项之一。它们希望自己的应用程序能够持续运行且具备功能，即使在发生一些不利事件时，仍能继续为客户提供服务。高可用性是本章的主要主题。*保持系统运行*
    是高可用性的常用比喻。实现应用程序的高可用性并非易事，组织必须投入大量的时间、精力、资源和金钱。此外，仍然存在组织的实施方案无法达到预期结果的风险。Azure为**虚拟机**（**VMs**）和**平台即服务**（**PaaS**）服务提供了许多高可用性功能。本章将介绍Azure提供的架构和设计功能，以确保正在运行的应用程序和服务的高可用性。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: High availability
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高可用性
- en: Azure high availability
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure高可用性
- en: Architectural considerations for high availability
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高可用性的架构考虑因素
- en: Scalability
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展性
- en: Upgrades and maintenance
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 升级和维护
- en: High availability
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高可用性
- en: High availability forms one of the core non-functional technical requirements
    for any business-critical service and its deployment. High availability refers
    to the feature of a service or application that keeps it operational on a continuous
    basis; it does so by meeting or surpassing its promised **service level agreement** (**SLA**).
    Users are promised a certain SLA based on the service type. The service should
    be available for consumption based on its SLA. For example, an SLA can define
    99% availability for an application for the entire year. This means that it should
    be available for consumption by users for 361.35 days. If it fails to remain available
    for this period, that constitutes a breach of the SLA. Most mission-critical applications
    define their high-availability SLA as 99.999% for a year. This means the application
    should be up, running, and available throughout the year, but it can only be down
    and unavailable for 5.2 hours. If the downtime goes beyond that, you are eligible
    for credit, which will be calculated based on the total uptime percentage.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 高可用性是任何业务关键服务及其部署的核心非功能性技术要求之一。高可用性是指一个服务或应用程序保持持续运行的特性；它通过满足或超越其承诺的**服务级别协议**（**SLA**）来实现这一点。用户根据服务类型会被承诺一定的SLA。服务应该根据其SLA可供用户使用。例如，SLA可以定义一个应用程序在一年内的可用性为99%。这意味着它应该可以供用户使用361.35天。如果它未能在此期间保持可用，则构成违反SLA。大多数关键任务应用程序将它们的高可用性SLA定义为99.999%（每年）。这意味着该应用程序应该全年都能保持运行并可供使用，但它的停机时间不能超过5.2小时。如果停机时间超过这一限度，您将有资格获得信用，信用金额将根据总的正常运行时间百分比来计算。
- en: It is important to note here that high availability is defined in terms of time
    (yearly, monthly, weekly, or a combination of these).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，高可用性是根据时间来定义的（可以是按年、按月、按周，或这些的组合）。
- en: A service or application is made up of multiple components and these components
    are deployed on separate tiers and layers. Moreover, a service or application
    is deployed on an **operating system** (**OS**) and hosted on a physical machine or
    VM. It consumes network and storage services for various purposes. It might even
    be dependent on external systems. For these services or applications to be highly
    available, it is important that networks, storage, OSes, VMs or physical machines,
    and each component of the application is designed with the SLA and high availability
    in mind. A definite application life cycle process is used to ensure that high
    availability should be baked in from the start of application planning until its
    introduction to operations. This also involves introducing redundancy. Redundant
    resources should be included in the overall application and deployment architecture
    to ensure that if one resource goes down, another takes over and serves the requests
    of the customer.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一个服务或应用程序由多个组件组成，这些组件部署在不同的层级和层次上。此外，服务或应用程序部署在**操作系统**（**OS**）上，并托管在物理机器或虚拟机（VM）上。它消耗网络和存储服务来满足各种需求，甚至可能依赖于外部系统。为了确保这些服务或应用程序具备高可用性，网络、存储、操作系统、虚拟机或物理机器以及应用程序的每个组件都必须考虑SLA和高可用性。为了确保高可用性，从应用程序规划开始直到投入运营，都需要采用明确的应用程序生命周期流程。这也涉及到冗余的引入。冗余资源应该包括在整个应用程序和部署架构中，以确保如果一个资源出现故障，另一个资源能够接管并继续为客户提供服务。
- en: 'Some of the major factors affecting the high availability of an application
    are as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 影响应用程序高可用性的一些主要因素如下：
- en: Planned maintenance
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计划性维护
- en: Unplanned maintenance
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非计划性维护
- en: Application deployment architecture
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序部署架构
- en: We will be looking into each of these factors in the following sections. Let's
    take a closer look at how high availability is ensured for deployments in Azure.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中详细探讨这些因素。让我们仔细看看Azure如何确保部署的高可用性。
- en: Azure high availability
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Azure高可用性
- en: Achieving high availability and meeting high SLA requirements is tough. Azure
    provides lots of features that enable high availability for applications, from
    the host and guest OS to applications using its PaaS. Architects can use these
    features to get high availability in their applications using configuration instead
    of building these features from scratch or depending on third-party tools.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 实现高可用性并满足高SLA要求是非常困难的。Azure提供了许多功能，能够为应用程序实现高可用性，从主机和来宾操作系统到使用其PaaS的应用程序。架构师可以通过这些功能，通过配置来实现应用程序的高可用性，而不必从头开始构建这些功能或依赖第三方工具。
- en: In this section, we will look at the features and capabilities provided by Azure
    to make applications highly available. Before we get into the architectural and
    configuration details, it is important to understand concepts related to Azure's
    high availability.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨 Azure 提供的使应用程序高可用的功能和能力。在深入架构和配置细节之前，理解与 Azure 高可用性相关的概念非常重要。
- en: Concepts
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 概念
- en: 'The fundamental concepts provided by Azure to attain high availability are
    as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 提供的实现高可用性的基本概念如下：
- en: Availability sets
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用性集
- en: The fault domain
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故障域
- en: The update domain
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新域
- en: Availability zones
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用性区域
- en: As you know, it's very important that we design solutions to be highly available.
    The workloads might be mission-critical and require highly available architecture.
    We will take a closer look at each of the concepts of high availability in Azure
    now. Let's start with availability sets.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，设计高可用性解决方案非常重要。工作负载可能是关键任务，并且需要高可用架构。我们现在将仔细查看 Azure 中高可用性的每个概念。我们从可用性集开始。
- en: '**Availability sets**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**可用性集**'
- en: High availability in Azure is primarily achieved through redundancy. Redundancy
    means that there is more than one resource instance of the same type that takes
    control in the event of a primary resource failure. However, just having more
    similar resources does not make them highly available. For example, there could
    be multiple VMs provisioned within a subscription, but simply having multiple
    VMs does not make them highly available. Azure provides a resource known as an
    availability set, and having multiple VMs associated with it makes them highly
    available. A minimum of two VMs should be hosted within the availability set to
    make them highly available. All VMs in the availability set become highly available
    because they are placed on separate physical racks in the Azure datacenter. During
    updates, these VMs are updated one at a time, instead of all at the same time.
    Availability sets provide a fault domain and an update domain to achieve this,
    and we will discuss this more in the next section. In short, availability sets
    provide redundancy at the datacenter level, similar to locally redundant storage.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 中的高可用性主要通过冗余来实现。冗余意味着有多个相同类型的资源实例，在主资源发生故障时接管控制。然而，仅仅拥有更多相似的资源并不能使它们具备高可用性。例如，在一个订阅中可能会配置多个虚拟机，但仅仅有多个虚拟机并不意味着它们具备高可用性。Azure
    提供了一个名为可用性集的资源，将多个虚拟机与其关联可以使它们具备高可用性。为了实现高可用性，至少应将两台虚拟机托管在可用性集中。由于所有虚拟机都被放置在 Azure
    数据中心的不同物理机架上，它们都会具备高可用性。在更新时，这些虚拟机会逐一更新，而不是同时更新。可用性集提供了故障域和更新域来实现这一点，我们将在下一部分详细讨论。简而言之，可用性集在数据中心级别提供冗余，类似于本地冗余存储。
- en: It is important to note that availability sets provide high availability within
    a datacenter. If an entire datacenter is down, then the availability of the application
    will be impacted. To ensure that applications are still available when a datacenter
    goes down, Azure has introduced a new feature known as availability zones, which
    we will learn about shortly.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，可用性集仅在数据中心内部提供高可用性。如果整个数据中心发生故障，应用程序的可用性将受到影响。为了确保在数据中心故障时应用程序仍然可用，Azure
    引入了一个名为可用性区域的新特性，我们将在稍后学习。
- en: If you recall the list of fundamental concepts, the next one in the list is
    the fault domain. The fault domain is often denoted by the acronym FD. In the
    next section, we will discuss what the FD is and how it is relevant while designing
    highly available solutions.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你回顾基本概念列表，接下来是故障域。故障域通常用缩写 **FD** 表示。在下一部分中，我们将讨论故障域是什么，以及它在设计高可用性解决方案时的相关性。
- en: '**The fault domain**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**故障域**'
- en: '**Fault domains** (**FDs**) represent a group of VMs that share a common power
    source and network switch. When a VM is provisioned and assigned to an availability
    set, it is hosted within an FD. Each availability set has either two or three
    FDs by default, depending on the Azure region. Some regions provide two, while
    others provide three FDs in an availability set. FDs are non-configurable by users.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**故障域**（**FDs**）表示一组共享相同电源和网络交换机的虚拟机（VM）。当一台 VM 被配置并分配到可用性集时，它将被托管在一个故障域中。每个可用性集默认有两个或三个故障域，这取决于
    Azure 区域。有些区域提供两个故障域，而其他区域则提供三个故障域。故障域无法由用户配置。'
- en: When multiple VMs are created, they are placed on separate FDs. If the number
    of VMs is more than the FDs, the additional VMs are placed on existing FDs. For
    example, if there are five VMs, there will be FDs hosted on more than one VM.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当多个虚拟机被创建时，它们会被放置在不同的 FDs 上。如果虚拟机的数量超过了 FDs 的数量，多余的虚拟机会被放置在现有的 FDs 上。例如，如果有五个虚拟机，则这些虚拟机会托管在多个虚拟机上。
- en: FDs are related to physical racks in the Azure datacenter. FDs provide high
    availability in the case of unplanned downtime due to hardware, power, and network
    failure. Since each VM is placed on a different rack with different hardware,
    a different power supply, and a different network, other VMs continue running
    if a rack snaps off.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: FDs 与 Azure 数据中心中的物理机架相关。FDs 在由于硬件、电力和网络故障导致的计划外停机情况下提供高可用性。由于每个虚拟机（VM）都被放置在不同的机架上，具有不同的硬件、不同的电源和不同的网络，因此如果某个机架出现故障，其他虚拟机将继续运行。
- en: The next one in the list is the update domain.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 列表中的下一个是更新域。
- en: '**The update domain**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**更新域**'
- en: An FD takes care of unplanned downtime, while an update domain handles downtime
    from planned maintenance. Each VM is also assigned an update domain and all the
    VMs within that update domain will reboot together. There can be as many as 20
    update domains in a single availability set. Update domains are non-configurable
    by users. When multiple VMs are created, they are placed on separate update domains.
    If more than 20 VMs are provisioned on an availability set, they are placed in
    a round-robin fashion on these update domains. Update domains take care of planned
    maintenance. From **Service Health** in the Azure portal, you can check the planned
    maintenance details and set alerts.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: FD 处理计划外停机，而更新域（update domain）则处理来自计划维护的停机。每个虚拟机也会被分配一个更新域，该更新域中的所有虚拟机将一起重启。一个可用性集最多可以有
    20 个更新域。更新域是用户无法配置的。当多个虚拟机被创建时，它们会被放置在不同的更新域中。如果在一个可用性集中配置了超过 20 个虚拟机，它们将以轮询方式分布到这些更新域中。更新域处理计划维护。通过
    Azure 门户中的**服务健康**，你可以查看计划维护的详细信息并设置警报。
- en: In the next section, we will be covering availability zones.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将介绍可用性区域（availability zones）。
- en: '**Availability zones**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**可用性区域**'
- en: This is a relatively new concept introduced by Azure and is very similar to
    zone redundancy for storage accounts. Availability zones provide high availability
    within a region by placing VM instances on separate datacenters within the region. Availability
    zones are applicable to many resources in Azure, including VMs, managed disks,
    VM scale sets, and load balancers. The complete list of resources that are supported
    by availability zones can be found at [https://docs.microsoft.com/azure/availability-zones/az-overview#services-that-support-availability-zones](https://docs.microsoft.com/azure/availability-zones/az-overview#services-that-support-availability-zones).
    Being unable to configure availability across zones was a gap in Azure for a long
    time, and it was eventually fixed with the introduction of availability zones.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Azure 引入的一个相对较新的概念，与存储帐户的区域冗余非常相似。可用性区域通过将虚拟机实例放置在区域内不同的数据中心中，提供区域内的高可用性。可用性区域适用于
    Azure 中的许多资源，包括虚拟机、托管磁盘、虚拟机规模集和负载均衡器。支持可用性区域的资源的完整列表可以在 [https://docs.microsoft.com/azure/availability-zones/az-overview#services-that-support-availability-zones](https://docs.microsoft.com/azure/availability-zones/az-overview#services-that-support-availability-zones)
    中找到。长时间以来，无法跨区域配置可用性是 Azure 的一个缺口，直到引入可用性区域后才得以解决。
- en: 'Each Azure region comprises multiple datacenters equipped with independent
    power, cooling, and networking. Some regions have more datacenters, while others
    have less. These datacenters within the region are known as zones. To ensure resiliency,
    there''s a minimum of three separate zones in all enabled regions. Deploying VMs
    in an availability zone ensures that these VMs are in different datacenters and
    are on different racks and networks. These datacenters in a region relate to high-speed
    networks and there is no lag in communication between these VMs. *Figure 2.1*
    shows how availability zones are set up in a region:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 Azure 区域由多个配备独立电力、冷却和网络设施的数据中心组成。一些区域的数据中心较多，而另一些区域的数据中心较少。该区域内的数据中心被称为区域。在所有启用的区域中，至少有三个独立的区域以确保弹性。将虚拟机部署在可用性区域中，确保这些虚拟机位于不同的数据中心，并且位于不同的机架和网络上。这些区域内的数据中心之间具有高速网络，这些虚拟机之间的通信不会出现延迟。*图
    2.1* 显示了在区域中如何设置可用性区域：
- en: '![Availability zones in an Azure region](img/B15432_02_01.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![Azure 区域中的可用性区域](img/B15432_02_01.jpg)'
- en: 'Figure 2.1: Availability zones in a region'
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.1：区域中的可用性区域
- en: You can find more information about availability zones at [https://docs.microsoft.com/azure/availability-zones/az-overview](https://docs.microsoft.com/azure/availability-zones/az-overview).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://docs.microsoft.com/azure/availability-zones/az-overview](https://docs.microsoft.com/azure/availability-zones/az-overview)找到有关可用性区域的更多信息。
- en: Zone-redundant services replicate your applications and data across availability
    zones to protect from single points of failure.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 区域冗余服务将您的应用程序和数据复制到可用性区域，以防止单点故障。
- en: If an application needs higher availability and you want to ensure that it is
    available even if an entire Azure region is down, the next rung of the ladder
    for availability is the Traffic Manager feature, which will be discussed later
    in this chapter. Let's now move on to understanding Azure's take on load balancing
    for VMs.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果应用程序需要更高的可用性，并且您希望确保即使整个 Azure 区域宕机，也可用，可用性的下一个层次是Traffic Manager功能，这将在本章后面讨论。现在让我们继续了解
    Azure VM 负载平衡的工作原理。
- en: Load balancing
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 负载均衡
- en: 'Load balancing, as the name suggests, refers to the process of balancing a
    load among VMs and applications. With one VM, there is no need for a load balancer
    because the entire load is on a single VM and there is no other VM to share the
    load. However, with multiple VMs containing the same application and service,
    it is possible to distribute the load among them through load balancing. Azure
    provides a few resources to enable load balancing:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 负载均衡，顾名思义，是指在VM和应用程序之间平衡负载的过程。如果只有一个VM，则无需负载均衡器，因为整个负载位于单个VM上，没有其他VM可以共享负载。然而，通过包含相同应用程序和服务的多个VM，可以通过负载均衡器在它们之间分发负载。Azure
    提供了几种资源来实现负载均衡：
- en: '**Load balancers**: The Azure load balancer helps to design solutions with
    high availability. Within the **Transmission Control Protocol** (**TCP**) stack,
    it is a layer 4 transport-level load balancer. This is a layer 4 load balancer
    that distributes incoming traffic among healthy instances of services that are
    defined in a load-balanced set. Level 4 load balancers work at the transport level
    and have network-level information, such as an IP address and port, to decide
    the target for the incoming request. Load balancers are discussed in more detail
    later in this chapter.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载均衡器**：Azure 负载均衡器有助于设计具有高可用性的解决方案。在传输控制协议（TCP）堆栈内，它是第4层传输级别的负载均衡器。这是一个第4层负载均衡器，将传入的流量分发到负载平衡集中定义的健康服务实例之间。第4层负载均衡器在传输级别工作，并具有网络级别的信息，如
    IP 地址和端口，以决定传入请求的目标。负载均衡器将在本章后面详细讨论。'
- en: '**Application gateways**: An Azure Application Gateway delivers high availability
    to your applications. They are layer 7 load balancers that distribute the incoming
    traffic among healthy instances of services. Level 7 load balancers can work at
    the application level and have application-level information, such as cookies,
    HTTP, HTTPS, and sessions for the incoming request. Application gateways are discussed
    in more detail later in this chapter. Application gateways are also used when
    deploying Azure Kubernetes Service, specifically for scenarios in which ingress
    traffic from the internet should be routed to the Kubernetes services in the cluster.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用程序网关**：Azure 应用程序网关为您的应用程序提供高可用性。它们是第7层负载均衡器，将传入的流量分发到服务的健康实例之间。第7层负载均衡器可以在应用程序级别工作，并具有应用程序级别的信息，如
    cookie、HTTP、HTTPS 和会话等。应用程序网关将在本章后面详细讨论。在部署 Azure Kubernetes 服务时，特别是需要将来自互联网的入口流量路由到集群中的
    Kubernetes 服务的场景中，也会使用应用程序网关。'
- en: '**Azure Front Door**: Azure Front Door is very similar to application gateways;
    however, it does not work at the region or datacenter level. Instead, it helps
    in routing requests across regions globally. It has the same feature set as that
    provided by application gateways, but at the global level. It also provides a
    web application firewall for the filtering of requests and provides other security-related
    protection. It provides session affinity, TLS termination, and URL-based routing
    as some of its features.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure Front Door**：Azure Front Door与应用程序网关非常相似；但是，它不在区域或数据中心级别工作。相反，它在全球范围内帮助路由请求。它具有与应用程序网关相同的功能集，但是在全局级别提供。它还提供网页应用程序防火墙以过滤请求并提供其他安全相关的保护。它提供会话亲和性、TLS
    终止和基于 URL 的路由作为其部分功能。'
- en: '**Traffic Manager**: Traffic Manager helps in the routing of requests at the
    global level across multiple regions based on the health and availability of regional
    endpoints. It supports doing so using DNS redirect entries. It is highly resilient
    and has no service impact during region failures as well.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流量管理器**：流量管理器帮助根据区域端点的健康状况和可用性，在多个区域之间对请求进行全局路由。它支持通过 DNS 重定向条目来实现这一点。它具有高度的弹性，并且在区域故障期间不会影响服务。'
- en: Since we've explored the methods and services that can be used to achieve load
    balancing, we'll go ahead and discuss how to make VMs highly available.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经探讨了可以用于实现负载均衡的方法和服务，接下来我们将讨论如何使虚拟机具备高可用性。
- en: VM high availability
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 虚拟机高可用性
- en: VMs provide compute capabilities. They provide processing power and hosting
    for applications and services. If an application is deployed on a single VM and
    that machine is down, then the application will not be available. If the application
    is composed of multiple tiers and each tier is deployed in its own single instance
    of a VM, even downtime for a single instance of VM can render the entire application
    unavailable. Azure tries to make even single VM instances highly available for
    99.9% of the time, particularly if these single-instance VMs use premium storage
    for their disks. Azure provides a higher SLA for those VMs that are grouped together
    in an availability set. It provides a 99.95% SLA for VMs that are part of an availability
    set with two or more VMs. The SLA is 99.99% if VMs are placed in availability
    zones. In the next section, we will be discussing high availability for compute
    resources.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机提供计算能力。它们为应用程序和服务提供处理能力和托管支持。如果应用程序部署在单个虚拟机上，而该虚拟机出现故障，则应用程序将无法使用。如果应用程序由多个层组成，并且每个层都部署在各自的单个虚拟机实例上，那么即使是单个虚拟机实例的停机也可能导致整个应用程序不可用。Azure
    尝试使单个虚拟机实例的可用性达到 99.9%，特别是当这些单实例虚拟机使用高级存储作为磁盘时。对于那些在可用性集中分组在一起的虚拟机，Azure 提供了更高的服务级别协议（SLA）。对于包含两个或更多虚拟机的可用性集，提供
    99.95% 的 SLA。如果虚拟机部署在可用性区域中，SLA 可达 99.99%。在下一节中，我们将讨论计算资源的高可用性。
- en: Compute high availability
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算高可用性
- en: Applications demanding high availability should be deployed on multiple VMs
    in the same availability set. If applications are composed of multiple tiers,
    then each tier should have a group of VMs on their dedicated availability set.
    In short, if there are three tiers of an application, there should be three availability
    sets and a minimum of six VMs (two in each availability set) to make the entire
    application highly available.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 需要高可用性的应用程序应部署在同一可用性集中的多个虚拟机（VM）上。如果应用程序由多个层组成，那么每个层应有一组虚拟机，部署在其专用的可用性集中。简而言之，如果一个应用程序有三个层，那么应有三个可用性集，并且至少需要六个虚拟机（每个可用性集两个虚拟机），以确保整个应用程序具有高可用性。
- en: So, how does Azure provide an SLA and high availability to VMs in an availability
    set with multiple VMs in each availability set? This is the question that might
    come to mind for you.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，Azure 是如何通过在每个可用性集中部署多个虚拟机来提供服务级别协议（SLA）和高可用性的呢？这个问题可能会浮现在你的脑海中。
- en: Here, the use of concepts that we considered before comes into play—that is,
    the fault and update domains. When Azure sees multiple VMs in an availability
    set, it places those VMs on a separate FD. In other words, these VMs are placed
    on separate physical racks instead of the same rack. This ensures that at least
    one VM continues to be available even if there is a power, hardware, or rack failure.
    There are two or three FDs in an availability set and, depending on the number
    of VMs in an availability set, the VMs are placed in separate FDs or repeated
    in a round-robin fashion. This ensures that high availability is not impacted
    because of the failure of the rack.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们之前考虑的概念起到了关键作用——即故障域（FD）和更新域。当 Azure 发现可用性集中有多个虚拟机时，它会将这些虚拟机放置在不同的故障域中。换句话说，这些虚拟机会被放置在不同的物理机架上，而不是同一个机架上。这确保了即使发生电源、硬件或机架故障，至少有一台虚拟机可以继续使用。一个可用性集中有两个或三个故障域，并且根据可用性集中的虚拟机数量，这些虚拟机会被放置在不同的故障域中，或者以循环方式重复放置。这确保了即使机架发生故障，高可用性也不会受到影响。
- en: Azure also places these VMs on a separate update domain. In other words, Azure
    tags these VMs internally in such a way that these VMs are patched and updated
    one after another, such that any reboot in an update domain does not affect the
    availability of the application. This ensures that high availability is not impacted because
    of the VM and host maintenance. It is important to note that Azure is not responsible
    for OS-level and application maintenance.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 还将这些虚拟机放置在不同的更新域中。换句话说，Azure 内部为这些虚拟机打上标签，使得这些虚拟机按照顺序进行修补和更新，以确保在某个更新域中的任何重启都不会影响应用程序的可用性。这确保了虚拟机和主机维护不会影响高可用性。需要注意的是，Azure
    不负责操作系统级别和应用程序的维护。
- en: 'With the placement of VMs in separate fault and update domains, Azure ensures
    that all VMs are never down at the same time and that they are alive and available
    for serving requests, even though they might be undergoing maintenance or facing
    physical downtime challenges:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将虚拟机放置在不同的故障域和更新域中，Azure 确保所有虚拟机不会同时宕机，并且即使它们正在进行维护或面临物理停机问题，也能保持在线并能够处理请求：
- en: '![VM distribution across update and fault domains](img/B15432_02_02.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![虚拟机在更新和故障域中的分布](img/B15432_02_02.jpg)'
- en: 'Figure 2.2: VM distribution across fault and update domains'
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.2：虚拟机在故障域和更新域中的分布
- en: '*Figure 2.2* shows four VMs (two have **Internet Information Services** (**IIS**) and
    the other two have SQL Server installed on them). Both the IIS and SQL VMs are
    part of availability sets. The IIS and SQL VMs are in separate FDs and different
    racks in the datacenter. They are also in separate update domains.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.2* 显示了四个虚拟机（其中两个安装了**Internet 信息服务**（**IIS**），另两个安装了 SQL Server）。IIS 和
    SQL 虚拟机都属于可用性集的一部分。IIS 和 SQL 虚拟机位于数据中心的不同故障域（FD）和机架中，并且它们也处于不同的更新域中。'
- en: '*Figure 2.3* shows the relationship between fault and update domains:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.3* 显示了故障域和更新域之间的关系：'
- en: '![Layout of update and fault domains in an availability set](img/B15432_02_03.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![可用性集中更新和故障域的布局](img/B15432_02_03.jpg)'
- en: 'Figure 2.3: Layout of update domains and FDs in an availability set'
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.3：可用性集中更新域和故障域的布局
- en: So far, we have discussed achieving high availability for compute resources.
    In the next section, you will learn how high availability can be implemented for
    PaaS.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论了如何实现计算资源的高可用性。在接下来的章节中，您将学习如何为 PaaS 实现高可用性。
- en: High-availability platforms
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高可用性平台
- en: 'Azure has provided a lot of new features to ensure high availability for PaaS.
    Some of them are listed here:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 提供了许多新功能，以确保 PaaS 的高可用性。以下是其中的一些功能：
- en: Containers in app services
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用服务中的容器
- en: Azure Container Instances groups
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure 容器实例组
- en: Azure Kubernetes Service
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure Kubernetes 服务
- en: Other container orchestrators, such as DC/OS and Swarm
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他容器协调器，如 DC/OS 和 Swarm
- en: Another important platform that brings high availability is **Service Fabric**. Both
    Service Fabric and container orchestrators that include Kubernetes ensure that
    the desired number of application instances are always up and running in an environment.
    What this means is that even if one of the instances goes down in the environment,
    the orchestrator will know about it by means of active monitoring and will spin
    up a new instance on a different node, thereby maintaining the ideal and desired
    number of instances. It does this without any manual or automated interference
    from the administrator.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个提供高可用性的重要平台是**Service Fabric**。Service Fabric 和包含 Kubernetes 的容器协调器都能确保在环境中始终有所需数量的应用实例在运行。这意味着即使环境中的某个实例宕机，协调器也能通过主动监控得知，并会在另一个节点上启动新的实例，从而保持理想的应用实例数量。它这样做不需要管理员的手动或自动干预。
- en: While Service Fabric allows any type of application to become highly available,
    orchestrators such as Kubernetes, DC/OS, and Swarm are specific to containers.
    Also, it is important to understand that these platforms provide features that
    help in rolling updates, rather than a big bank update that might affect the availability
    of the application.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Service Fabric 允许任何类型的应用程序实现高可用性，但 Kubernetes、DC/OS 和 Swarm 等协调器特定于容器。同时，需要理解的是，这些平台提供的功能有助于进行滚动更新，而不是可能影响应用程序可用性的整体更新。
- en: When we were discussing high availability for VMs, we took a brief look at what
    load balancing is. Let's take a closer look at it to better understand how it
    works in Azure.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们讨论虚拟机的高可用性时，我们简要介绍了负载均衡的概念。让我们进一步深入了解，以便更好地理解它在 Azure 中是如何工作的。
- en: Load balancers in Azure
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Azure 中的负载均衡器
- en: Azure provides two resources that have the functionality of a load balancer.
    It provides a level 4 load balancer, which works at the transport layer within
    the TCP OSI stack, and a level 7 load balancer (application gateway), which works
    at the application and session levels.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 提供了两种具有负载均衡器功能的资源。它提供了一个 4 层负载均衡器，在 TCP OSI 协议栈的传输层工作；以及一个 7 层负载均衡器（应用程序网关），它在应用层和会话层工作。
- en: Although both application gateways and load balancers provide the basic features
    of balancing a load, they serve different purposes. There are a number of use
    cases in which it makes more sense to deploy an application gateway than a load
    balancer.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然应用程序网关和负载均衡器都提供负载均衡的基本功能，但它们的用途不同。在许多使用场景中，部署应用程序网关比负载均衡器更合适。
- en: 'An application gateway provides the following features that are not available
    with Azure load balancers:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序网关提供以下 Azure 负载均衡器所不具备的功能：
- en: '**Web application firewall**: This is an additional firewall on top of the
    OS firewall and it gives the ability to peek into incoming messages. This helps
    in identifying and preventing common web-based attacks, such as SQL injection,
    cross-site scripting attacks, and session hijacks.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Web 应用防火墙**：这是操作系统防火墙之上的一个附加防火墙，它能深入查看传入的消息。这有助于识别和防止常见的基于 Web 的攻击，如 SQL
    注入、跨站脚本攻击和会话劫持。'
- en: '**Cookie-based session affinity**: Load balancers distribute incoming traffic
    to service instances that are healthy and relatively free. A request can be served
    by any service instance. However, there are applications that need advanced features
    in which all subsequent requests following the first request should be processed
    by the same service instance. This is known as cookie-based session affinity.
    An application gateway provides cookie-based session affinity to keep a user session
    on the same service instance using cookies.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于 Cookie 的会话保持**：负载均衡器将传入流量分配给健康且相对空闲的服务实例。一个请求可以由任何服务实例处理。然而，一些应用程序需要更高级的功能，要求所有后续请求都由同一服务实例处理。这被称为基于
    Cookie 的会话保持。应用程序网关通过使用 Cookie 提供基于 Cookie 的会话保持，从而将用户会话保持在同一服务实例上。'
- en: '**Secure Sockets Layer (SSL) offload**: The encryption and decryption of request
    and response data is performed by SSL and is generally a costly operation. Web
    servers should ideally be spending their resources on processing and serving requests,
    rather than the encryption and decryption of traffic. SSL offload helps in transferring
    this cryptography process from the web server to the load balancer, thereby providing
    more resources to web servers serving users. The request from the user is encrypted
    but gets decrypted at the application gateway instead of the web server. The request
    from the application gateway to the web server is unencrypted.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全套接字层（SSL）卸载**：请求和响应数据的加密与解密由 SSL 执行，这通常是一个昂贵的操作。Web 服务器理应将其资源用于处理和响应请求，而不是加密和解密流量。SSL
    卸载有助于将这一加密过程从 Web 服务器转移到负载均衡器，从而为处理用户请求的 Web 服务器提供更多资源。用户的请求经过加密后，在应用程序网关处解密，而不是在
    Web 服务器处解密。来自应用程序网关到 Web 服务器的请求则保持未加密。'
- en: '**End-to-end SSL**: While SSL offload is a nice feature for certain applications,
    there are certain mission-critical secure applications that need complete SSL
    encryption and decryption even if traffic passes through load balancers. An application
    gateway can be configured for end-to-end SSL cryptography as well.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端到端 SSL**：虽然 SSL 卸载是某些应用程序的一个不错功能，但有些关键任务的安全应用程序仍然需要完全的 SSL 加密和解密，即使流量经过负载均衡器。应用程序网关也可以配置为进行端到端
    SSL 加密。'
- en: '**URL-based content routing**: Application gateways are also useful for redirecting
    traffic to different servers based on the URL content of incoming requests. This
    helps in hosting multiple services alongside other applications.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于 URL 的内容路由**：应用程序网关对于根据传入请求的 URL 内容将流量重定向到不同的服务器也很有用。这有助于在托管多个服务和其他应用程序时进行流量管理。'
- en: '**Azure load balancers**'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**Azure 负载均衡器**'
- en: 'An Azure load balancer distributes incoming traffic based on the transport-level
    information that is available to it. It relies on the following features:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 负载均衡器根据可用的传输层信息分配传入的流量。它依赖于以下特性：
- en: An originating IP address
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源 IP 地址
- en: A target IP address
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标 IP 地址
- en: An originating port number
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源端口号
- en: A target port number
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标端口号
- en: A type of protocol—either TCP or HTTP
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种协议类型——TCP 或 HTTP
- en: 'An Azure load balancer can be a private load balancer or a public load balancer.
    A private load balancer can be used to distribute traffic within the internal
    network. As this is internal, there won''t be any public IPs assigned and they
    cannot be accessed from the internet. A public load balancer has an external public
    IP attached to it and can be accessed via the internet. In *Figure 2.4*, you can
    see how internal (private) and public load balancers are incorporated into a single
    solution to handle internal and external traffic, respectively:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 负载均衡器可以是私有负载均衡器或公共负载均衡器。私有负载均衡器可用于在内部网络中分配流量。由于这是内部使用，因此不会分配公共 IP 地址，并且不能通过互联网访问。公共负载均衡器具有附加的外部公共
    IP 地址，可以通过互联网访问。在*图2.4*中，您可以看到如何将内部（私有）和公共负载均衡器集成到一个解决方案中，分别处理内部和外部流量：
- en: '![Distributing traffic using Azure load balancers](img/B15432_02_04.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Azure 负载均衡器分配流量](img/B15432_02_04.jpg)'
- en: 'Figure 2.4: Distributing traffic using Azure load balancers'
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.4：使用 Azure 负载均衡器分配流量
- en: In *Figure 2.4*, you can see that external users are accessing the VMs via the
    public load balancer, and then the traffic from the VM is distributed across another
    set of VMs using an internal load balancer.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图2.4*中，您可以看到外部用户通过公共负载均衡器访问虚拟机（VM），然后来自虚拟机的流量通过内部负载均衡器分配到另一组虚拟机。
- en: We have done a comparison of how Azure load balancers differ from Application
    Gateways. In the next section, we will discuss application gateways in more detail.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经对 Azure 负载均衡器与应用程序网关的区别进行了比较。在下一节中，我们将更详细地讨论应用程序网关。
- en: The Azure Application Gateway
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Azure 应用程序网关
- en: An Azure load balancer helps us to enable solutions at the infrastructure level.
    However, there are times when using a load balancer requires advanced services
    and features. These advanced services include SSL termination, sticky sessions,
    advanced security, and more. An Azure application gateway provides these additional
    features; the Azure application gateway is a level 7 load balancer that works
    with the application and session payload in a TCP OSI stack.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 负载均衡器帮助我们在基础设施层面启用解决方案。然而，有时使用负载均衡器需要高级服务和功能。这些高级服务包括 SSL 终止、粘性会话、高级安全性等。Azure
    应用程序网关提供了这些附加功能；Azure 应用程序网关是一个第七层负载均衡器，能够处理应用程序和会话负载，在 TCP OSI 堆栈中运行。
- en: Application gateways have more information compared to Azure load balancers
    in order to make decisions on request routing and load balancing between servers.
    Application gateways are managed by Azure and are highly available.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Azure 负载均衡器相比，应用程序网关拥有更多的信息，用于在服务器之间做出请求路由和负载均衡的决策。应用程序网关由 Azure 管理，并具有高可用性。
- en: 'An application gateway sits between the users and the VMs, as shown in *Figure
    2.5*:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图2.5*所示，应用程序网关位于用户和虚拟机之间：
- en: '![Connecting users and VMs through Azure Application Gateway](img/B15432_02_05.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![通过 Azure 应用程序网关连接用户和虚拟机](img/B15432_02_05.jpg)'
- en: 'Figure 2.5: An Azure application gateway'
  id: totrans-107
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2.5：Azure 应用程序网关
- en: Application gateways are a managed service. They use **Application Request Routing** (**ARR**)
    to route requests to different services and endpoints. Creating an application gateway requires
    a private or public IP address. The application gateway then routes the HTTP/HTTPS
    traffic to configured endpoints.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序网关是一种托管服务。它们使用**应用程序请求路由**（**ARR**）将请求路由到不同的服务和端点。创建应用程序网关需要一个私有或公共 IP 地址。然后，应用程序网关将
    HTTP/HTTPS 流量路由到配置的端点。
- en: An application gateway is similar to an Azure load balancer from a configuration
    perspective, with additional constructs and features. Application gateways can
    be configured with a front-end IP address, a certificate, a port configuration,
    a back-end pool, session affinity, and protocol information.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置的角度来看，应用程序网关与 Azure 负载均衡器相似，但具有额外的结构和功能。应用程序网关可以配置前端 IP 地址、证书、端口配置、后端池、会话亲和性和协议信息。
- en: Another service that we discussed in relation to high availability for VMs was
    Azure Traffic Manager. Let's try to understand more about this service in the
    next section.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在讨论虚拟机高可用性时提到了另一个服务——Azure 流量管理器。让我们在下一节中进一步了解该服务。
- en: Azure Traffic Manager
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Azure 流量管理器
- en: After gaining a good understanding of both Azure load balancers and application
    gateways, it's time to get into the details of Traffic Manager. Azure load balancers
    and application gateways are much-needed resources for high availability within
    a datacenter or region; however, to achieve high availability across regions and
    datacenters, there is a need for another resource, and Traffic Manager helps us
    in this regard.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在充分了解 Azure 负载均衡器和应用程序网关之后，是时候深入了解 Traffic Manager 了。Azure 负载均衡器和应用程序网关是数据中心或区域内高可用性所需的资源；然而，要实现跨区域和跨数据中心的高可用性，还需要另一种资源，而
    Traffic Manager 就在这方面为我们提供了帮助。
- en: Traffic Manager helps us to create highly available solutions that span multiple
    geographies, regions, and datacenters. Traffic Manager is not similar to load
    balancers. It uses the **Domain Name Service** (**DNS**) to redirect requests
    to an appropriate endpoint determined by the health and configuration of the endpoint.
    Traffic Manager is not a proxy or a gateway, and it does not see the traffic passing
    between the client and the service. It simply redirects requests based on the
    most appropriate endpoints.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Traffic Manager 帮助我们创建跨多个地理位置、区域和数据中心的高可用解决方案。Traffic Manager 不同于负载均衡器。它使用**域名服务**（**DNS**）将请求重定向到由端点的健康状况和配置决定的适当端点。Traffic
    Manager 不是代理或网关，它无法看到客户端与服务之间传递的流量。它仅根据最合适的端点重定向请求。
- en: Azure Traffic Manager helps to control the traffic that is distributed across
    application endpoints. An endpoint can be termed as any internet-facing service
    hosted inside or outside of Azure.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Traffic Manager 有助于控制分配到应用程序端点的流量。端点可以被定义为任何面向互联网的服务，无论是在 Azure 内部还是外部托管。
- en: Endpoints are internet-facing, reachable public URLs. Applications are provisioned
    within multiple geographies and Azure regions. Applications deployed to each region
    have a unique endpoint referred to by `.trafficmanager.net` URL extension.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 端点是面向互联网的、可访问的公共 URL。应用程序被部署在多个地理位置和 Azure 区域。部署到每个区域的应用程序有一个唯一的端点，通过`.trafficmanager.net`的
    URL 扩展来引用。
- en: When a request arrives at the Traffic Manager URL, it finds the most appropriate
    endpoint in its list and redirects the request to it. In short, Azure Traffic
    Manager acts as a global DNS to identify the region that will serve the request.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当请求到达 Traffic Manager 的 URL 时，它会在列表中找到最合适的端点，并将请求重定向到该端点。简而言之，Azure Traffic
    Manager 充当全球 DNS 来识别将处理请求的区域。
- en: However, how does Traffic Manager know which endpoints to use and redirect client
    requests to? There are two aspects that Traffic Manager considers to determine
    the most appropriate endpoint and region.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Traffic Manager 如何知道使用哪些端点并将客户端请求重定向到它们呢？Traffic Manager 考虑两个方面来确定最合适的端点和区域。
- en: Firstly, Traffic Manager actively monitors the health of all endpoints. It can
    monitor the health of VMs, cloud services, and app services. If it determines
    that the health of an application deployed to a region is not suitable for redirecting
    traffic, it redirects the requests to a healthy endpoint.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，Traffic Manager 会积极监控所有端点的健康状况。它可以监控虚拟机、云服务和应用服务的健康状况。如果它确定部署在某个区域的应用程序健康状况不适合重定向流量，它会将请求重定向到健康的端点。
- en: 'Secondly, Traffic Manager can be configured with routing information. There
    are six traffic routing methods available in Traffic Manager, which are as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，Traffic Manager 可以配置路由信息。Traffic Manager 提供了六种流量路由方法，具体如下：
- en: '**Priority**: This should be used when all traffic should go to a default endpoint,
    and backups are available in case the primary endpoints are unavailable.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优先级**：当所有流量应发送到默认端点，并且当主端点不可用时需要备份端点时，应使用此选项。'
- en: '**Weighted**: This should be used to distribute traffic across endpoints evenly,
    or according to defined weights.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加权**：当需要在端点之间均匀分配流量，或根据定义的权重分配流量时，应使用此选项。'
- en: '**Performance**: This should be used for endpoints in different regions, and
    users should be redirected to the closest endpoint based on their location. This
    has a direct impact on network latency.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能**：当端点位于不同区域时，应使用此选项，并根据用户的位置将其重定向到最接近的端点。这直接影响网络延迟。'
- en: '**Geographic**: This should be used to redirect users to an endpoint (Azure,
    external, or nested) based on the nearest geographical location. This can help
    in adhering to compliance related to data protection, localization, and region-based
    traffic collection.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地理**：这应当用于根据最近的地理位置将用户重定向到一个端点（Azure、外部或嵌套）。这有助于遵守与数据保护、地域化和基于区域的流量收集相关的合规要求。'
- en: '**Subnet**: This is a new routing method and it helps in providing clients
    with different endpoints based on their IP addresses. In this method, a range
    of IP addresses are assigned to each endpoint. These IP address ranges are mapped
    to the client IP address to determine an appropriate returning endpoint. Using
    this routing method, it is possible to provide different content to different
    people based on their originating IP address.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子网**：这是一种新的路由方法，帮助根据客户端的 IP 地址提供不同的端点。在此方法中，每个端点会分配一系列 IP 地址。这些 IP 地址范围与客户端的
    IP 地址映射，以确定合适的返回端点。通过这种路由方法，可以根据用户的源 IP 地址向不同的人提供不同的内容。'
- en: '**Multivalue**: This is also a new method added in Azure. In this method, multiple
    endpoints are returned to the client and any of them can be used. This ensures
    that if one endpoint is unhealthy, then other endpoints can be used instead. This
    helps in increasing the overall availability of the solution.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多值**：这也是 Azure 中新增的一种方法。在这种方法中，多个端点会返回给客户端，客户端可以使用其中任何一个端点。这确保了如果一个端点不可用，其他端点可以作为替代使用，从而提升了解决方案的整体可用性。'
- en: It should be noted that after Traffic Manager determines a valid healthy endpoint,
    clients connect directly to the application. Let's now move on to understand Azure's
    capabilities in routing user requests globally.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，在流量管理器确定有效且健康的端点后，客户端将直接连接到应用程序。接下来，让我们继续了解 Azure 在全球范围内路由用户请求的能力。
- en: In the next section, we will be discussing another service, called Azure Front
    Door. This service is like Azure Application Gateway; however, there is a small
    difference that makes this service distinct. Let's go ahead and learn more about
    Azure Front Door.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将讨论另一项服务，叫做 Azure Front Door。该服务类似于 Azure 应用程序网关；然而，它有一个小的区别，使得该服务与众不同。让我们继续深入了解
    Azure Front Door。
- en: Azure Front Door
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Azure Front Door
- en: Azure Front Door is the latest offering in Azure that helps route requests to
    services at a global level instead of a local region or datacenter level, as in
    the case of Azure Application Gateway and load balancers. Azure Front Door is
    like Application Gateway, with the difference being in the scope. It is a layer
    7 load balancer that helps in routing requests to the nearest best-performing
    service endpoint deployed in multiple regions. It provides features such as TLS
    termination, session affinity, URL-based routing, and multiple site hosting, along
    with a web application firewall. It is similar to Traffic Manager in that it is,
    by default, resilient to entire region failures and it provides routing capabilities.
    It also conducts endpoint health probes periodically to ensure that requests are
    routed to healthy endpoints only.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Front Door 是 Azure 提供的最新服务，它帮助将请求路由到全球服务，而不是像 Azure 应用程序网关和负载均衡器那样将请求路由到本地区域或数据中心级别。Azure
    Front Door 类似于应用程序网关，不同之处在于它的范围。它是一个第七层负载均衡器，帮助将请求路由到在多个区域中部署的最近的、性能最优的服务端点。它提供诸如
    TLS 终止、会话亲和性、基于 URL 的路由和多站点托管等功能，并带有 Web 应用防火墙。它与流量管理器相似，默认情况下对整个区域的故障具有弹性，并提供路由能力。它还定期进行端点健康探测，确保请求仅路由到健康的端点。
- en: 'It provides four different routing methods:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 它提供了四种不同的路由方法：
- en: '**Latency**: Requests will route to endpoints that will have the least latency
    end to end.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延迟**：请求将路由到具有最小端到端延迟的端点。'
- en: '**Priority**: Requests will route to a primary endpoint and to a secondary
    endpoint in the case of the failure of the primary.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优先级**：请求将路由到主端点，如果主端点失败，则路由到备用端点。'
- en: '**Weighted**: Requests will route based on weights assigned to the endpoints.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加权**：请求将根据分配给端点的权重进行路由。'
- en: '**Session Affinity**: Requests in a session will end up with the same endpoint
    to make use of session data from prior requests. The original request can end
    up with any available endpoint.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**会话亲和性**：会话中的请求将始终指向相同的端点，以便利用先前请求的会话数据。原始请求可以指向任何可用的端点。'
- en: Deployments looking for resilience at the global level should include Azure
    Front Door in their architecture, alongside application gateways and load balancers.
    In the next section, you will see some of the architectural considerations that
    you should account for while designing highly available solutions.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 寻求全球级别弹性的部署应在其架构中包括 Azure Front Door，并结合应用程序网关和负载均衡器。在接下来的章节中，你将看到在设计高可用解决方案时应考虑的一些架构要点。
- en: Architectural considerations for high availability
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高可用性的架构考虑因素
- en: Azure provides high availability through various means and at various levels.
    High availability can be at the datacenter level, the region level, or even across
    Azure. In this section, we will go through some of the architectures for high
    availability.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 通过多种方式和不同级别提供高可用性。高可用性可以在数据中心级别、区域级别，甚至跨 Azure 实现。在本节中，我们将介绍一些高可用性的架构。
- en: High availability within Azure regions
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Azure 区域内的高可用性
- en: 'The architecture shown in *Figure 2.6* shows a high-availability deployment
    within a single Azure region. High availability is designed at the individual
    resource level. In this architecture, there are multiple VMs at each tier connected
    through either an application gateway or a load balancer, and they are each part
    of an availability set. Each tier is associated with an availability set. These
    VMs are placed on separate fault and update domains. While the web servers are
    connected to application gateways, the rest of the tiers, such as the application
    and database tiers, have internal load balancers:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 2.6*所示，该架构展示了在单一 Azure 区域内的高可用性部署。高可用性在单个资源级别进行设计。在该架构中，每一层都有多个虚拟机（VM），这些虚拟机通过应用程序网关或负载均衡器连接，并且它们都属于一个可用性集。每一层都与一个可用性集关联。这些虚拟机被放置在不同的故障和更新域上。虽然
    Web 服务器连接到应用程序网关，但其他层次（如应用程序层和数据库层）使用内部负载均衡器：
- en: '![High-availability deployment within a single Azure region](img/B15432_02_06.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![单一 Azure 区域内的高可用性部署](img/B15432_02_06.jpg)'
- en: 'Figure 2.6: Designing high availability within a region'
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.6：在一个区域内设计高可用性
- en: Now that you know how to design highly available solutions in the same region,
    let's discuss how an architecture that is similar, but spread across Azure regions,
    can be designed.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道如何在同一区域内设计高度可用的解决方案，接下来我们来讨论如何设计一个类似的架构，且跨多个 Azure 区域进行部署。
- en: High availability across Azure regions
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跨 Azure 区域的高可用性
- en: This architecture shows similar deployments in two different Azure regions.
    As shown in *Figure 2.7*, both regions have the same resources deployed. High
    availability is designed at the individual resource level within these regions.
    There are multiple VMs at each tier, connected through load balancers, and they
    are part of an availability set. These VMs are placed on separate fault and update
    domains. While the web servers are connected to external load balancers, the rest
    of the tiers, such as the application and database tiers, have internal load balancers.
    It should be noted that application load balancers can be used for web servers
    and the application tier (instead of Azure load balancers) if there is a need
    for advanced services, such as session affinity, SSL termination, advanced security
    using a **web application firewall** (**WAF**), and path-based routing. The databases
    in both regions are connected to each other using virtual network peering and
    gateways. This is helpful in configuring log shipping, SQL Server Always On, and
    other data synchronization techniques.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 该架构展示了在两个不同 Azure 区域中的类似部署。如*图 2.7*所示，两个区域都部署了相同的资源。高可用性在这些区域内的单个资源级别进行设计。每一层都有多个虚拟机，虚拟机通过负载均衡器连接，并且它们属于一个可用性集。这些虚拟机被放置在不同的故障和更新域上。Web
    服务器连接到外部负载均衡器，而其他层次（如应用程序层和数据库层）则使用内部负载均衡器。需要注意的是，如果需要高级服务（如会话保持、SSL 终止、使用**Web
    应用防火墙**（**WAF**）的高级安全性以及基于路径的路由），则可以使用应用程序负载均衡器来替代 Azure 负载均衡器，部署在 Web 服务器和应用程序层。两个区域中的数据库通过虚拟网络对等连接和网关互相连接。这对于配置日志传输、SQL
    Server Always On 和其他数据同步技术非常有用。
- en: 'The endpoints of the load balancers from both regions are used to configure
    Traffic Manager endpoints, and traffic is routed based on the priority load-balancing
    method. Traffic Manager helps in routing all requests to the East US region and,
    after failover, to West Europe in the case of the non-availability of the first
    region:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 来自两个区域的负载均衡器端点用于配置流量管理器端点，流量根据优先级负载均衡方法进行路由。流量管理器帮助将所有请求路由到东美国区域，在故障转移的情况下，如果第一个区域不可用，则路由到西欧区域：
- en: '![High-availability deployment across two Azure regions](img/B15432_02_07.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![跨两个 Azure 区域的高可用性部署](img/B15432_02_07.jpg)'
- en: 'Figure 2.7: Designing high availability across Azure regions'
  id: totrans-147
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.7：跨 Azure 区域设计高可用性
- en: In the next section, we will be exploring scalability, which is another advantage
    of the cloud.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将探讨可扩展性，这是云计算的另一个优势。
- en: Scalability
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展性
- en: Running applications and systems that are available to users for consumption
    is important for architects of any business-critical application. However, there
    is another equally important application feature that is one of the top priorities
    for architects, and this is the scalability of the application.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 运行对用户开放的应用程序和系统对于任何业务关键应用程序的架构师来说都非常重要。然而，另一个同样重要的应用程序特性，也是架构师的首要任务之一，就是应用程序的可扩展性。
- en: Imagine a situation in which an application is deployed and obtains great performance
    and availability with a few users, but both availability and performance decrease
    as the number of users begin to increase. There are times when an application
    performs well under a normal load, but suffers a drop in performance with an increase
    in the number of users. This can happen if there is a sudden increase in the number
    of users and the environment is not built for such a large number of users.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一种情况，应用程序已经部署，并且在少量用户下能够获得良好的性能和可用性，但随着用户数量的增加，可用性和性能都会下降。应用程序在正常负载下表现良好，但在用户数量增加时性能下降。这可能发生在用户数量突然增加且环境未针对如此大量用户进行构建时。
- en: To accommodate such spikes in the number of users, you might provision the hardware
    and bandwidth for handling spikes. The challenge with this is that the additional
    capacity is not used for the majority of the year, and so does not provide any
    return on investment. It is provisioned for use only during the holiday season or
    sales. I hope that by now you are becoming familiar with the problems that architects
    are trying to solve. All these problems are related to capacity sizing and the
    scalability of an application. The focus of this chapter is to understand scalability
    as an architectural concern and to check out the services that are provided by
    Azure for implementing scalability.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对用户数量的激增，您可能会为应对高峰期配置硬件和带宽。问题在于，额外的容量在大部分年份都未被使用，因此无法提供投资回报。它仅为假期或促销期间使用。我希望到现在为止，您已经开始熟悉架构师正在努力解决的问题。所有这些问题都与容量配置和应用程序的可扩展性相关。本章的重点是将可扩展性视为架构上的一个问题，并了解
    Azure 提供的用于实现可扩展性的服务。
- en: Capacity planning and sizing are a couple of the top priorities for architects
    and their applications and services. Architects must find a balance between buying
    and provisioning too many resources and buying and provisioning too few resources.
    Having too few resources can lead to you not being able to serve all users, resulting
    in them turning to a competitor. On the other hand, having too many resources
    can hurt your budget and return on investment because most of the resources will
    remain unused most of the time. Moreover, the problem is amplified by the varying
    level of demand at different times. It is almost impossible to predict the number
    of users of an application over a day, let alone a year. However, it is possible
    to find an approximate number using past information and continuous monitoring.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 容量规划和资源配置是架构师及其应用程序和服务的几个首要任务。架构师必须在购买和配置过多资源与购买和配置过少资源之间找到平衡。资源过少会导致无法满足所有用户需求，从而导致他们转向竞争对手。另一方面，资源过多则会损害预算和投资回报率，因为大多数资源大部分时间处于未使用状态。此外，问题会因需求水平在不同时间的波动而加剧。几乎不可能预测一天内的应用用户数，更别说一年的用户数了。然而，通过过去的信息和持续的监控，找到一个大致的数字是可能的。
- en: Scalability refers to the ability to handle a growing number of users and provide
    them with the same level of performance as when there are fewer users utilizing
    resources for application deployment, processes, and technology. Scalability might
    mean serving more requests without a decrease in performance, or it might mean
    handling larger and more time-consuming work without any loss of performance in
    both cases.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性指的是处理日益增长的用户数量，并为他们提供与较少用户时相同水平的性能，即使在应用程序部署、进程和技术使用资源时。可扩展性可能意味着在性能不下降的情况下处理更多请求，或者意味着处理更大、更耗时的工作而不损失性能，在这两种情况下都是如此。
- en: Capacity planning and sizing exercises should be undertaken by architects at
    the very beginning of a project and during the planning phase to provide scalability
    to applications.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 容量规划和大小调整练习应由架构师在项目初期和规划阶段进行，以便为应用程序提供可扩展性。
- en: Some applications have stable demand patterns, while it is difficult to predict
    others. Scalability requirements are known for stable-demand applications, while
    discerning them can be a more involved process for variable-demand applications.
    Autoscaling, a concept that we will review in the next section, should be used
    for applications whose demands cannot be predicted.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 一些应用程序具有稳定的需求模式，而另一些应用程序则难以预测需求。对于稳定需求的应用程序，可扩展性要求是已知的，而对于需求变化较大的应用程序，识别其需求可能是一个更复杂的过程。自动扩展是我们在下一节将要讨论的概念，应该应用于那些无法预测需求的应用程序。
- en: People often tend to confuse scalability with performance. In the next section,
    you will see a quick comparison of these two terms.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 人们常常把可扩展性和性能混为一谈。在接下来的章节中，你将看到这两个术语的简要对比。
- en: Scalability versus performance
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可扩展性与性能
- en: It is quite easy to get confused between scalability and performance when it
    comes to architectural concerns, because scalability is all about ensuring that
    irrespective of the number of users consuming the application, all users receive
    the same predetermined level of performance.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在架构问题上，很多人容易将可扩展性与性能混淆，因为可扩展性完全是为了确保无论有多少用户使用应用程序，所有用户都能获得预定的性能水平。
- en: Performance relates to ensuring that an application caters to predefined response
    times and throughput. Scalability refers to having provisions for more resources
    when needed in order to accommodate more users without sacrificing performance.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 性能与确保应用程序满足预定义的响应时间和吞吐量相关。可扩展性指的是在需要时提供更多资源，以容纳更多用户而不牺牲性能。
- en: 'It is better to understand this using an analogy: the speed of a train directly
    relates to the performance of a railway network. However, getting more trains
    to run in parallel at the same or at higher speeds represents the scalability
    of the railway network.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 通过类比来理解这一点会更好：火车的速度与铁路网络的性能直接相关。然而，增加更多的火车以平行运行在相同或更高的速度下，代表着铁路网络的可扩展性。
- en: Now that you know what the difference between scalability and performance is,
    let's discuss how Azure provides scalability.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了可扩展性与性能之间的区别，接下来我们来讨论 Azure 如何提供可扩展性。
- en: Azure scalability
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Azure 可扩展性
- en: In this section, we will look at the features and capabilities provided by Azure
    to make applications highly available. Before we get into the architecture and
    configuration details, it is important to understand Azure's high-availability
    concepts, in other words, scaling.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将探讨 Azure 提供的功能和能力，以使应用程序具备高可用性。在深入了解架构和配置细节之前，理解 Azure 的高可用性概念，即可扩展性，是非常重要的。
- en: Scaling refers to either increasing or decreasing the amount of resources that
    are used to serve requests from users. Scaling can be automatic or manual. Manual
    scaling requires an administrator to manually initiate the scaling process, while
    automatic scaling refers to an automatic increase or decrease in resources based
    on the events available from the environment and ecosystem, such as memory and
    CPU availability. Resources can be scaled up or down, or out and in, which will
    be explained later in this section.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展指的是增加或减少用于处理用户请求的资源量。扩展可以是自动的，也可以是手动的。手动扩展需要管理员手动启动扩展过程，而自动扩展指的是根据环境和生态系统中可用的事件（如内存和
    CPU 可用性）自动增加或减少资源。资源可以向上或向下扩展，也可以向外或向内扩展，这将在本节后面解释。
- en: 'In addition to rolling updates, the fundamental constructs provided by Azure
    to achieve high availability are as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 除了滚动更新，Azure 提供的实现高可用性的基本构造如下：
- en: Scaling up and down
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展上下调节
- en: Scaling out and in
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向外扩展与向内收缩
- en: Autoscaling
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动伸缩
- en: '**Scaling up**'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**向上扩展**'
- en: Scaling a VM or service up entails the addition of further resources to existing
    servers, such as CPU, memory, and disks. It aims to increase the capacity of existing
    physical hardware and resources.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 对虚拟机或服务进行向上扩展意味着向现有服务器添加更多资源，如 CPU、内存和磁盘。其目的是增加现有物理硬件和资源的容量。
- en: '**Scaling down**'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**向下扩展**'
- en: Scaling a VM or service down entails the removal of existing resources from
    existing servers, such as CPU, memory, and disks. It aims to decrease the capacity
    of existing physical and virtual hardware and resources.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 对虚拟机或服务进行向下扩展意味着从现有服务器中移除资源，如 CPU、内存和磁盘。其目的是减少现有物理和虚拟硬件及资源的容量。
- en: '**Scaling out**'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**向外扩展**'
- en: 'Scaling out entails adding further hardware, such as additional servers and
    capacity. This typically involves adding new servers, assigning them IP addresses,
    deploying applications on them, and making them part of the existing load balancers
    such that traffic can be routed to them. Scaling out can be automatic or manual
    as well. However, for better results, automation should be used:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 向外扩展意味着添加更多硬件，如额外的服务器和容量。这通常包括新增服务器、分配 IP 地址、在其上部署应用程序，并将其纳入现有的负载均衡器，以便流量可以路由到这些服务器。向外扩展既可以是自动的，也可以是手动的。然而，为了获得更好的效果，应该使用自动化：
- en: '![Scaling out](img/B15432_02_08.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![向外扩展](img/B15432_02_08.jpg)'
- en: 'Figure 2.8: Scaling out'
  id: totrans-177
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2.8：向外扩展
- en: '**Scaling in**'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '**向内扩展**'
- en: Scaling in refers to the process of removing the existing hardware in terms
    of existing servers and capacity. This typically involves removing existing servers,
    deallocating their IP addresses, and removing them from the existing load balancer
    configuration such that traffic cannot be routed to them. Like scaling out, scaling
    in can be automatic or manual.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 向内扩展指的是移除现有硬件的过程，具体来说就是现有的服务器和容量。这通常包括移除现有服务器，取消分配它们的 IP 地址，并将它们从现有的负载均衡器配置中移除，以确保流量不能路由到它们。像向外扩展一样，向内扩展也可以是自动的或手动的。
- en: '**Autoscaling**'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**自动伸缩**'
- en: Autoscaling refers to the process of either scaling up/down or scaling out/in
    dynamically based on application demand, and this happens using automation. Autoscaling
    is useful because it ensures that a deployment always consists of an ideal number
    of server instances. Autoscaling helps in building applications that are fault
    tolerant. It not only supports scalability, but also makes applications highly
    available. Finally, it provides the best cost management. Autoscaling makes it
    possible to have the optimal configuration for server instances based on demand.
    It helps in not over-provisioning servers, only for them to end up being underutilized,
    and removes servers that are no longer required after scaling out.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 自动伸缩指的是根据应用程序需求动态地进行向上/向下或向外/向内扩展的过程，并且这一过程是通过自动化实现的。自动伸缩非常有用，因为它确保部署始终由理想数量的服务器实例组成。自动伸缩有助于构建具有容错性的应用程序。它不仅支持可伸缩性，还使应用程序具有高可用性。最后，它提供了最佳的成本管理。自动伸缩使得根据需求配置服务器实例的最优配置成为可能。它帮助避免过度配置服务器，以免服务器最终被闲置，并且能够在向外扩展后移除不再需要的服务器。
- en: So far, we've discussed scalability in Azure. Azure offers scalability options
    for most of its services. Let's explore scalability for PaaS in Azure in the next
    section.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了 Azure 中的可伸缩性。Azure 为其大多数服务提供了可伸缩性选项。接下来，我们将探索 Azure 中 PaaS 的可伸缩性。
- en: PaaS scalability
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PaaS 可伸缩性
- en: 'Azure provides App Service for hosting managed applications. App Service is
    a PaaS offering from Azure. It provides services for the web and mobile platforms.
    Behind the web and mobile platforms is a managed infrastructure that is managed
    by Azure on behalf of its users. Users do not see or manage any infrastructure;
    however, they have the ability to extend the platform and deploy their applications on
    top of it. In doing so, architects and developers can concentrate on their business
    problems instead of worrying about the base platform and infrastructure provisioning,
    configuration, and troubleshooting. Developers have the flexibility to choose
    any language, OS, and framework to develop their applications. App Service provides
    multiple plans and, based on the plans chosen, various degrees of scalability
    are available. App Service provides the following five plans:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Azure提供了App Service来托管托管应用程序。App Service是Azure的PaaS服务。它为Web和移动平台提供服务。在这些Web和移动平台背后，有一套由Azure代表用户管理的托管基础设施。用户无需查看或管理任何基础设施；然而，他们可以扩展平台并在其上部署应用程序。通过这种方式，架构师和开发人员可以专注于他们的业务问题，而无需担心基础平台和基础设施的配置、部署和故障排除。开发人员可以灵活选择任何语言、操作系统和框架来开发应用程序。App
    Service提供了多个计划，用户可以根据选择的计划享受不同程度的可扩展性。App Service提供以下五种计划：
- en: '**Free**: This uses shared infrastructure. It means that multiple applications
    will be deployed on the same infrastructure from the same or multiple tenants.
    It provides 1 GB of storage free of charge. However, there is no scaling facility
    in this plan.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**免费**：此计划使用共享基础设施。这意味着多个应用程序将部署在相同的基础设施上，可以是来自同一租户或多个租户。它提供1 GB的免费存储。然而，此计划不支持扩展功能。'
- en: '**Shared**: This also uses shared infrastructure and provides 1 GB of storage
    free of charge. Additionally, custom domains are also provided as an extra feature.
    However, there is no scaling facility in this plan.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**共享**：此计划也使用共享基础设施，并提供1 GB的免费存储。此外，还提供定制域名作为额外功能。然而，此计划不支持扩展功能。'
- en: '**Basic**: This has three different **stock keeping units** (**SKUs**): B1,
    B2, and B3\. They each have increasing units of resources available to them in
    terms of CPU and memory. In short, they provide improved configuration of the
    VMs backing these services. Additionally, they provide storage, custom domains,
    and SSL support. The basic plan provides basic features for manual scaling. There
    is no autoscaling available in this plan. A maximum of three instances can be
    used to scale out an application.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础**：该计划有三个不同的**库存单位**（**SKU**）：B1、B2和B3。它们在CPU和内存方面有逐渐增加的资源配置。简而言之，它们提供了更好的虚拟机配置，以支持这些服务。此外，还提供存储、定制域名和SSL支持。基础计划提供了手动扩展的基本功能。此计划不支持自动扩展。最多可以使用三个实例来扩展应用程序。'
- en: '**Standard**: This also has three different SKUs: S1, S2, and S3\. They each
    have increasing units of resources available to them in terms of CPU and memory.
    In short, they provide improved configuration of the VMs backing these services.
    Additionally, they provide storage, custom domains, and SSL support that is similar
    to that of the basic plan. This plan also provides a Traffic Manager instance,
    staging slots, and one daily backup as an additional feature on top of the basic
    plan. The standard plan provides features for automatic scaling. A maximum of
    10 instances can be used to scale out the application.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准**：该计划也有三个不同的SKU：S1、S2和S3。它们在CPU和内存方面有逐渐增加的资源配置。简而言之，它们提供了更好的虚拟机配置，以支持这些服务。此外，它们还提供类似基础计划的存储、定制域名和SSL支持。该计划还提供一个Traffic
    Manager实例、预发布插槽和每天一次的备份，作为基础计划的额外功能。标准计划提供了自动扩展功能。最多可以使用10个实例来扩展应用程序。'
- en: '**Premium**: This also has three different SKUs: P1, P2, and P3\. They each
    have increasing units of resources available to them in terms of CPU and memory.
    In short, they provide improved configuration of the VMs backing these services.
    Additionally, they provide storage, custom domains, and SSL support that is similar
    to the basic plan. This plan also provides a Traffic Manager instance, staging
    slots, and 50 daily backups as an additional feature on top of the basic plan.
    The standard plan provides features for autoscaling. A maximum of 20 instances
    can be used to scale out the application.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have explored the scalability tiers available for PaaS services. Now, let's
    see how scaling can be done in the case of an App Service plan.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '**PaaS – scaling up and down**'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'Scaling up and down services that are hosted by App Service is quite simple.
    The Azure app services Scale Up menu opens a new pane with all plans and their
    SKUs listed. Choosing a plan and SKU will scale a service up or down, as shown
    in *Figure 2.9*:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '![Different plans with their SKUs](img/B15432_02_09.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.9: Different plans with their SKUs'
  id: totrans-194
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**PaaS – scaling out and in**'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Scaling out and in services hosted in App Service is also quite simple. The
    Azure app services Scale Out menu item opens a new pane with scaling configuration
    options.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, autoscaling is disabled for both premium and standard plans. It
    can be enabled using the **Scale Out** menu item and by clicking on the **Enable
    autoscale** button, as shown in *Figure 2.10*:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '![Enabling autoscale in scale out ](img/B15432_02_10.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.10: Enabling the autoscale option'
  id: totrans-199
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Manual scaling does not require configuration, but autoscaling helps in configuring
    with the aid of the following properties:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '**Mode of scaling**: This is based on a performance metric such as CPU or memory
    usage, or users can simply specify a number of instances for scaling.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**When to scale**: Multiple rules can be added that determine when to scale
    out and in. Each rule can determine criteria such as CPU or memory consumption,
    whether to increase or decrease the number of instances, and how many instances
    to increase or decrease to at a time. At least one rule for scaling out and one
    rule for scaling in should be configured. Threshold definitions help in defining
    the upper and lower limits that should trigger the autoscale—by either increasing
    or decreasing the number of instances.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**How to scale**: This specifies how many instances to create or remove in
    each scale-out or scale-in operation:![Setting the instance limits for scalling](img/B15432_02_11.jpg)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Figure 2.11: Setting the instance limits'
  id: totrans-204
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This is quite a good feature to enable in any deployment. However, you should
    enable both scaling out and scaling in together to ensure that your environment
    is back to normal capacity after scaling out.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Since we have covered the scalability in PaaS, let's move on and discuss scalability
    in IaaS next.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: IaaS scalability
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are users who will want to have complete control over their base infrastructure,
    platform, and application. They will prefer to consume IaaS solutions rather than
    PaaS solutions. When such customers create VMs, they are also responsible for
    capacity sizing and scaling. There is no out-of-the-box configuration for manually
    scaling or autoscaling VMs. These customers will have to write their own automation
    scripts, triggers, and rules to achieve autoscaling. With VMs comes the responsibility
    of maintaining them. The patching, updating, and upgrading of VMs is the responsibility
    of owners. Architects should think about both planned and unplanned maintenance.
    How these VMs should be patched, the order, grouping, and other factors must be
    considered to ensure that neither the scalability nor the availability of an application
    is compromised. To help alleviate such problems, Azure provides **VM scale sets** (**VMSS**) as
    a solution, which we will discuss next.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: VM scale sets
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: VMSSes are Azure compute resources that you can use to deploy and manage a set
    of identical VMs. With all VMs configured in the same way, scale sets are designed
    to support true autoscaling, and no pre-provisioning of VMs is required. It helps
    in provisioning multiple identical VMs that are connected to each other through
    a virtual network and subnet.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: 'A VMSS consists of multiple VMs, but they are managed at the VMSS level. All
    VMs are part of this unit and any changes made are applied to the unit, which,
    in turn, applies it to those VMs that are using a predetermined algorithm:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '![A VM Scale set](img/B15432_02_12.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.12: A VM scale set'
  id: totrans-213
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This enables these VMs to be load balanced using an Azure load balancer or an
    application gateway. The VMs could be either Windows or Linux VMs. They can run
    automated scripts using a PowerShell extension and they can be managed centrally
    using a state configuration. They can be monitored as a unit, or individually
    using Log Analytics.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: VMSSes can be provisioned from the Azure portal, the Azure CLI, Azure Resource
    Manager templates, REST APIs, and PowerShell cmdlets. It is possible to invoke
    REST APIs and the Azure CLI from any platform, environment, or OS, and in any
    language.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Many of Azure's services already use VMSSes as their underlying architecture.
    Among them are Azure Batch, Azure Service Fabric, and Azure Container Service.
    Azure Container Service, in turn, provisions Kubernetes and DC/OS on these VMSSes.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: VMSS architecture
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'VMSSes allow the creation of up to 1,000 VMs in a scale set when using a platform
    image, and 100 VMs if using a custom image. If the number of VMs is less than
    100 in a scale set, they are placed in a single availability set; however, if
    the number is greater than 100, multiple availability sets are created (known
    as placement groups), and VMs are distributed among these availability sets. We
    know from *Chapter 1, Getting started with Azure*, that VMs in an availability
    set are placed on separate fault and update domains. Availability sets related
    to VMSSes have five fault and update domains by default. VMSSes provide a model
    that holds metadata information for the entire set. Changing this model and applying
    changes impacts all VM instances. This information includes the maximum and minimum
    number of VM instances, the OS SKU and version, the current number of VMs, fault
    and update domains, and more. This is demonstrated in *Figure 2.13*:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '![Metadata information for an availability set](img/B15432_02_13.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.13: VMs in an availability set'
  id: totrans-220
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: VMSS scaling
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Scaling refers to increasing or decreasing compute and storage resources. A
    VMSS is a feature-rich resource that makes scaling easy and efficient. It provides
    autoscaling, which helps in scaling up or down based on external events and data
    such as CPU and memory usage. Some of the VMSS scaling features are given here.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '**Horizontal versus vertical scaling**'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Scaling can be horizontal or vertical, or both. Horizontal scaling is another
    name for scaling out and in, while vertical scaling refers to scaling up and down.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '**Capacity**'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: VMSSes have a `capacity` property that determines the number of VMs in a scale
    set. A VMSS can be deployed with zero as a value for this property. It will not
    create a single VM; however, if you provision a VMSS by providing a number for
    the `capacity` property, that number of VMs are created.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '**Autoscaling**'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: The autoscaling of VMs in a VMSS refers to the addition or removal of VM instances
    based on the configured environment in order to meet the performance and scalability
    demands of an application. Generally, in the absence of a VMSS, this is achieved
    using automation scripts and runbooks.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: VMSSes help in this automation process with the support of configuration. Instead
    of writing scripts, a VMSS can be configured for autoscaling up and down.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Autoscaling uses multiple integrated components to achieve its end goal. Autoscaling
    entails continuously monitoring VMs and collecting telemetry data about them.
    This data is stored, combined, and then evaluated against a set of rules to determine
    whether autoscaling should be triggered. The trigger could be to scale out or
    scale in. It could also be to scale up or down.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: The autoscaling mechanism uses diagnostic logs for collecting telemetry data
    from VMs. These logs are stored in storage accounts as diagnostic metrics. The
    autoscaling mechanism also uses the Application Insights monitoring service, which
    reads these metrics, combines them, and stores them in a storage account.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Background autoscaling jobs run continually to read Application Insights' storage
    data, evaluate it based on all the rules configured for autoscaling, and, if any
    of the rules or combination of rules are met, run the process of autoscaling.
    The rules can take into consideration the metrics from guest VMs and the host
    server.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: The rules defined using the property descriptions are available at [https://docs.microsoft.com/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-autoscale-overview](https://docs.microsoft.com/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-autoscale-overview).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 'The VMSS autoscale architecture is shown in *Figure 2.14*:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '![VMSS autoscale architecture](img/B15432_02_14.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.14: VMSS autoscale architecture'
  id: totrans-236
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Autoscaling can be configured for scenarios that are more complex than general
    metrics available from environments. For example, scaling could be based on any
    of the following:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: A specific day
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A recurring schedule such as weekends
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weekdays versus weekends
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Holidays and one-off events
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple resource metrics
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These can be configured using the `schedule` property of Application Insights
    resources, which help in registering rules.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Architects should ensure that at least two actions—scale out and scale in—are
    configured together. Scaling a configuration in or out will not help in achieving
    the scaling benefits provided by VMSSes.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, we have covered the scalability options in Azure and the detailed
    scaling features in the case of IaaS and PaaS to meet your business requirements.
    If you recall the shared responsibility model, you'll remember that platform upgrades
    and maintenance should be done by the cloud provider. In this case, Microsoft
    takes care of upgrades and maintenance related to the platform. Let's see how
    this is achieved in the next section.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Upgrades and maintenance
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After a VMSS and applications are deployed, they need to be actively maintained.
    Planned maintenance should be conducted periodically to ensure that both the environment
    and application are up to date with the latest features, from a security and resilience
    point of view.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Upgrades can be associated with applications, the guest VM instance, or the
    image itself. Upgrades can be quite complex because they should happen without
    affecting the availability, scalability, and performance of environments and applications.
    To ensure that updates can take place one instance at a time using rolling upgrade
    methods, it is important that a VMSS supports and provides capabilities for these
    advanced scenarios.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a utility provided by the Azure team to manage updates for VMSSes.
    It''s a Python-based utility that can be downloaded from [https://github.com/gbowerman/vmssdashboard](https://github.com/gbowerman/vmssdashboard).
    It makes REST API calls to Azure to manage scale sets. This utility can be used
    to start, stop, upgrade, and reimage VMs on in an FD or group of VMs, as shown
    in *Figure 2.15*:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '![Utility for managing VMSS updates](img/B15432_02_15.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.15: Utility for managing VMSS updates'
  id: totrans-251
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Since you have a basic understanding of upgrade and maintenance, let's see how
    application updates are done in VMSSes.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: Application updates
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Application updates in VMSSes should not be executed manually. They must be
    run as part of the release management and pipelines that use automation. Moreover,
    an update should happen one application instance at a time and not affect the
    overall availability and scalability of an application. Configuration management
    tools, such as **Desired State Configuration** (**DSC**), should be deployed to
    manage application updates. The DSC pull server can be configured with the latest
    version of the application configuration and it should be applied on a rolling
    basis to each instance.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will focus on how the updates are done on the guest
    OS.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: Guest updates
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Updates to VMs are the responsibility of the administrator. Azure is not responsible
    for patching guest VMs. Guest updates are in preview mode and users should control
    patching manually or use custom automation methods, such as runbooks and scripts.
    However, rolling patch upgrades are in preview mode and can be configured in the
    Azure Resource Manager template using an upgrade policy, as follows:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now that we know how guest updates are managed in Azure, let's see how image
    updates are accomplished.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: Image updates
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A VMSS can update the OS version without any downtime. OS updates involve changing
    the version or SKU of the OS or changing the URI of a custom image. Updating without
    downtime means updating VMs one at a time or in groups (such as one FD at a time)
    rather than all at once. By doing so, any VMs that are not being upgraded can
    keep running.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have discussed updates and maintenance. Let's now examine what the
    best practices of scaling for VMSSes are.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: Best practices of scaling for VMSSes
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will go through some of the best practices that applications should
    implement to take advantage of the scaling capability provided by VMSSes.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '**The preference for scaling out**'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: Scaling out is a better scaling solution than scaling up. Scaling up or down
    means resizing VM instances. When a VM is resized, it generally needs to be restarted,
    which has its own disadvantages. First, there is downtime for the machine. Second,
    if there are active users connected to the application on that instance, they
    might face a lack of availability of the application, or they might even lose
    transactions. Scaling out does not impact existing VMs; rather, it provisions
    newer machines and adds them to the group.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '**New instances versus dormant instances**'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: 'Scaling new instances can take two broad approaches: creating the new instance
    from scratch, which requires installing applications, configuring, and testing
    them; or starting the dormant, sleeping instances when they are needed due to
    scalability pressure on other servers.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '**Configuring the maximum and minimum number of instances appropriately**'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: Setting a value of two for both the minimum and maximum instance counts, with
    the current instance count being two, means no scaling action can occur. There
    should be an adequate difference between the maximum and minimum instance counts,
    which are inclusive. Autoscaling always scales between these limits.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '**Concurrency**'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: Applications are designed for scalability to focus on concurrency. Applications
    should use asynchronous patterns to ensure that client requests do not wait indefinitely
    to acquire resources if resources are busy serving other requests. Implementing
    asynchronous patterns in code ensures that threads do not wait for resources and
    that systems are exhausted of all available threads. Applications should implement
    the concept of timeouts if intermittent failures are expected.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '**Designing stateless applications**'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Applications and services should be designed to be stateless. Scalability can
    become a challenge to achieve with stateful services, and it is quite easy to
    scale stateless services. With states comes the requirement for additional components
    and implementations, such as replication, centralized or decentralized repository,
    maintenance, and sticky sessions. All these are impediments on the path to scalability.
    Imagine a service maintaining an active state on a local server. Irrespective
    of the number of requests on the overall application or the individual server,
    the subsequent requests must be served by the same server. Subsequent requests
    cannot be processed by other servers. This makes scalability implementation a
    challenge.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '**Caching and the Content Distribution Network** (**CDN**)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: Applications and services should take advantage of caching. Caching helps eliminate
    multiple subsequent calls to either databases or filesystems. This helps in making resources available
    and free for more requests. The CDN is another mechanism that is used to cache
    static files, such as images and JavaScript libraries. They are available on servers
    across the globe. They also make resources available and free for additional client
    requests—this makes applications highly scalable.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '**N+1 design**'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '**N+1 design** refers to building redundancy within the overall deployment
    for each component. It means to plan for some redundancy even when it is not required.
    This could mean additional VMs, storage, and network interfaces.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Considering the preceding best practices while designing workloads using VMSSes
    will improve the scalability of your applications. In the next section, we will
    explore monitoring.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Monitoring is an important architectural concern that should be part of any
    solution, big or small, mission-critical or not, cloud-based or not—it should
    not be neglected.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring refers to the act of keeping track of solutions and capturing various
    telemetry information, processing it, identifying the information that qualifies
    for alerts based on rules, and raising them. Generally, an agent is deployed within
    the environment and monitors it, sending telemetry information to a centralized
    server, where the rest of the processing of generating alerts and notifying stakeholders
    takes place.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring takes both proactive and reactive actions and measures against a
    solution. It is also the first step toward auditing a solution. Without the ability
    to monitor log records, it is difficult to audit a system from various perspectives,
    such as security, performance, and availability.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring helps us identify availability, performance, and scalability issues
    before they arise. Hardware failure, software misconfiguration, and patch update
    challenges can be discovered well before they impact users through monitoring,
    and performance degradation can be fixed before it happens.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring reactively logs pinpoint areas and locations that are causing issues,
    identifies the issues, and enables faster and better repairs.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: Teams can identify patterns of issues using monitoring telemetry information
    and eliminate them by innovating new solutions and features.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Azure is a rich cloud environment that provides multiple rich monitoring features
    and resources to monitor not only cloud-based deployment but also on-premises
    deployment.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Azure monitoring
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first question that should be answered is, "What must we monitor?" This
    question becomes more important for solutions that are deployed on the cloud because
    of the constrained control over them.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some important components that should be monitored. They include
    the following:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: Custom applications
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure resources
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guest OSes (VMs)
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Host OSes (Azure physical servers)
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure infrastructure
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are different Azure logging and monitoring services for these components,
    and they are discussed in the following sections.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: Azure activity logs
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Previously known as audit logs and operational logs, activity logs are control-plane
    events on the Azure platform. They provide information and telemetry information
    at the subscription level, instead of the individual resource level. They track
    information about all changes that happen at the subscription level, such as creating,
    deleting, and updating resources using **Azure Resource Manager** (**ARM**). Activity
    logs help us discover the identity of (such as service principal, users, or groups),
    and perform actions on (such as write or update), resources (for example, storage,
    virtual machines, or SQL databases) at any given point in time. They provide information
    about resources that are modified in their configuration, but not their inner
    workings and execution. For example, you can get the logs for starting a VM, resizing
    a VM, or stopping a VM.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: The next topic that we are going to discuss is diagnostic logs.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Azure diagnostic logs
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The information originating within the inner workings of Azure resources is
    captured in what are known as **diagnostic logs**. They provide telemetry information
    about the operations of resources that are inherent to the resources. Not every
    resource provides diagnostic logs, and resources that provide logs on their own
    content are completely different from other resources. Diagnostic logs are configured individually for
    each resource. Examples of diagnostic logs include storing a file in a container
    in a blob in a storage account.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: The next type of log that we are going to discuss is application logs.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Azure application logs
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Application logs can be captured by Application Insights resources and can be
    managed centrally. They get information about the inner workings of custom applications,
    such as their performance metrics and availability, and users can get insights
    from them in order to manage them better.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we have guest and host OS logs. Let's understand what these are.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: Guest and host OS logs
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Both guest and host OS logs are offered to users using Azure Monitor. They
    provide information about the statuses of host and guest OSes:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '![Different types of logs in Azure](img/B15432_02_16.jpg)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.16: Logging in Azure'
  id: totrans-309
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The important Azure resources related to monitoring are Azure Monitor, Azure
    Application Insights, and Log Analytics, previously known as **Operational Insights**.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: There are other tools, such as **System Center Operations Manager** (**SCOM**),
    that are not part of the cloud feature but can be deployed on IaaS-based VMs to
    monitor any workload on Azure or an on-premises datacenter. Let's discuss the
    three monitoring resources in the following section.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Azure Monitor
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure Monitor is a central tool and resource that provides complete management
    features that allow you to monitor an Azure subscription. It provides management
    features for activity logs, diagnostic logs, metrics, Application Insights, and
    Log Analytics. It should be treated as a dashboard and management resource for
    all other monitoring capabilities.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Our next topic is Azure Application Insights.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: Azure Application Insights
  id: totrans-315
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure Application Insights provides centralized, Azure-scale monitoring, logs,
    and metrics capabilities to custom applications. Custom applications can send
    metrics, logs, and other telemetry information to Azure Application Insights.
    It also provides rich reporting, dashboarding, and analytics capabilities to get
    insights from incoming data and act on them.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have covered Application Insights, let's look at another similar
    service called Azure Log Analytics.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: Azure Log Analytics
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure Log Analytics enables the centralized processing of logs and generates
    insights and alerts from them. Activity logs, diagnostic logs, application logs,
    event logs, and even custom logs can send information to Log Analytics, which
    can further provide rich reporting, dashboarding, and analytics capabilities to
    get insights from incoming data and act on them.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know the purpose of Log Analytics, let's discuss how logs are stored
    in a Log Analytics workspace and how they can be queried.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '**Logs**'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: A Log Analytics workspace provides search capabilities to search for specific
    log entries, export all telemetry data to Excel and/or Power BI, and search a
    query language called **Kusto Query Language** (**KQL**), which is similar to
    SQL.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Log Search** screen is shown here:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '![Log search in a Log Analytics workspace](img/B15432_02_17.jpg)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.17: Log search in a Log Analytics workspace'
  id: totrans-325
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the next section, we will be covering Log Analytics solutions, which are
    like additional capabilities in a Log Analytics workspace.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: Solutions
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Solutions in Log Analytics are further capabilities that can be added to a workspace,
    capturing additional telemetry data that is not captured by default. When these
    solutions are added to a workspace, appropriate management packs are sent to all
    the agents connected to the workspace so that they can configure themselves to
    capture solution-specific data from VMs and containers and then send it to the
    Log Analytics workspace. Monitoring solutions from Microsoft and partners are
    available from Azure Marketplace.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure provides lots of Log Analytics solutions for tracking and monitoring
    different aspects of environments and applications. At a minimum, a set of solutions
    that are generic and applicable to almost any environment should be added to the
    workspace:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: Capacity and performance
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agent health
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change tracking
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security and audit
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update management
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network performance monitoring
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another key aspect of monitoring is alerts. Alerts help to notify the right
    people during any monitored event. In the next section, we will cover alerts.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: Alerts
  id: totrans-338
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Log Analytics allows us to generate alerts in relation to ingested data. It
    does so by running a pre-defined query composed of conditions for incoming data.
    If it finds any records that fall within the ambit of the query results, it generates
    an alert. Log Analytics provides a highly configurable environment for determining
    the conditions for generating alerts, time windows in which the query should return
    the records, time windows in which the query should be executed, and actions to
    be taken when the query returns an alert:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: '![Configuring alerts through Log Analytics](img/B15432_02_18.jpg)'
  id: totrans-340
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.18: Configuring alerts through Log Analytics'
  id: totrans-341
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let''s go through the steps for configuring alerts through Log Analytics:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: The first step in configuring an alert is to add a new alert rule from the Azure
    portal or automation from the alert menu of the Log Analytics resource.
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first step in configuring an alert is to add a new alert rule from the Azure
    portal or automation from the alert menu of the Log Analytics resource.
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the resultant panel, select a scope for the alert rule. The scope determines
    which resource should be monitored for alerts—it could be a resource instance,
    such as an Azure storage account, a resource type, such as an Azure VM, a resource
    group, or a subscription:![Selecting a resource for creating the alert](img/B15432_02_19.jpg)
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 2.19: Selecting a resource for the alert'
  id: totrans-346
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Following resource selection, conditions must be set for the alert. The condition
    determines the rule that is evaluated against the logs and metrics on the selected
    resource, and only after the condition turns true is an alert generated. There
    are a ton of metrics and logs available for generating conditions. In the following
    example, an alert is created with a static threshold value of 80% for **Percentage**
    **CPU** (**Avg**) and the data is to be collected every five minutes and evaluated
    every minute:![Creating an alert for Percentage CPU (Avg)](img/B15432_02_20.jpg)
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 2.20: Creating an alert for Percentage CPU (Avg)'
  id: totrans-348
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Alerts also support dynamic thresholds, which use machine learning to learn
    the historical behavior of metrics and detect irregularities that could indicate
    service issues.
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, create an action group or reuse an existing group that determines
    notifications regarding alerts to stakeholders. The **Action Groups** section
    allows you to configure things that should follow an alert. Generally, there should
    be a remedial and/or notification action. Log Analytics provides eight different
    ways to create a new action. They can be combined in any way you like. An alert
    will execute any or all of the following configured actions:'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Email/SMS/push/voice notification**: This sends an email/SMS/push/voice notification
    to the configured recipients.'
  id: totrans-351
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Webhooks**: A webhook runs an arbitrary external process using an HTTP POST
    mechanism. For example, a REST API can be executed, or the Service Manager/ServiceNow
    APIs can be invoked to create a ticket.'
  id: totrans-352
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Functions**: This runs an Azure function, passing the necessary payload
    and running the logic that the payload contains.'
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logic Apps**: This executes a custom Logic Apps workflow.'
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Email Azure Resource Manager Role**: This emails a holder of an Azure Resource
    Manager role, such as an owner, contributor, or reader.'
  id: totrans-355
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secure webhook**: A webhook runs an arbitrary external process using an HTTP
    POST mechanism. Webhooks are protected using an identity provider, such as Azure
    Active Directory.'
  id: totrans-356
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automation runbooks**: This action executes Azure Automation runbooks.'
  id: totrans-357
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ITSM**: ITSM solutions should be provisioned before using this option. It
    helps with connecting and sending information to ITSM systems.'
  id: totrans-358
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: After all of this configuration, you need to provide the **Name**, **Description**,
    and **Severity** values for the alert rule to generate it.
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As mentioned at the beginning of this section, alerts play a vital role in monitoring
    that helps authorized personnel to take necessary actions based on the alert that's
    triggered.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-361
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: High availability and scalability are crucially important architectural concerns.
    Almost every application and every architect try to implement high availability. Azure
    is a mature platform that understands the need for these architectural concerns
    in applications and provides resources to implement them at multiple levels. These
    architectural concerns are not an afterthought, and they should be part of the application
    development life cycle, starting from the planning phase itself.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring is an important architectural aspect of any solution. It is also
    the first step toward being able to audit an application properly. It enables
    operations to manage a solution, both reactively and proactively. It provides
    the necessary records for troubleshooting and fixing the issues that might arise
    from platforms and applications. There are many resources in Azure that are specific
    to implementing monitoring for Azure, other clouds, and on-premises datacenters.
    Application Insights and Log Analytics are two of the most important resources
    in this regard. Needless to say, monitoring is a must for making your solutions
    and products better by innovating based on insights derived from monitoring data.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: This chapter was purely about the availability, scalability, and monitoring
    of solutions; the next chapter is about design patterns related to virtual networks,
    storage accounts, regions, availability zones, and availability sets. While designing
    solutions in the cloud, these principles are very important in building cost-effective
    solutions with increased productivity and availability.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
