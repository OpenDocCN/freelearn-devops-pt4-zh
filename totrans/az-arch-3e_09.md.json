["```\n    spark.conf.set(\"fs.azure.account.key.coronadatastorage.blob.core.windows.net\",\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx==\")\n    ```", "```\n    coviddata = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"wasbs://coviddata@coronadatastorage.blob.core.windows.net/owid-covid-data.csv\")\n    ```", "```\n    coviddata.show()\n    ```", "```\n    coviddata.printSchema()\n    ```", "```\n    coviddata.count()\n    ```", "```\n    CovidDataSmallSet = coviddata.select(\"location\",\"date\", \"new_cases\", \"new_deaths\")\n    CovidDataSmallSet.show()\n    ```", "```\n    CovidDataSmallSet.filter(\" location == 'United States' \").show()\n    ```", "```\n    CovidDataSmallSet.filter((CovidDataSmallSet.location == 'United States') | (CovidDataSmallSet.location == 'Aruba')).show()\n    ```", "```\n    CovidDataSmallSet.describe().show()\n    ```", "```\n    from pyspark.sql.functions import  col\n    (coviddata.where(col(\"diabetes_prevalence\").isNull()).count() * 100)/coviddata.count()\n    ```", "```\n    coviddatanew=coviddata.drop(\"iso_code\").drop(\"total_tests\").drop(\"total_tests\").drop(\"new_tests\").drop(\"total_tests_per_thousand\").drop(\"new_tests_per_thousand\").drop(\"new_tests_smoothed\").drop(\"new_tests_smoothed_per_thousand \")\n    ```", "```\n    coviddatanew = coviddata.groupBy('location').agg({'date': 'max'})\n    ```", "```\n    coviddatauniquecountry = coviddata.filter(\"date='2020-05-23 00:00:00'\")\n    coviddatauniquecountry.show()\n    ```", "```\n    coviddatauniquecountry.rdd.saveAsTextFile(\"dbfs:/mnt/coronadatastorage/uniquecountry.csv\")\n    ```", "```\n    %fs ls /mnt/coronadatastorage/\n    ```", "```\n    coviddatauniquecountry.createOrReplaceTempView(\"corona\")\n    ```", "```\n    spark.sql(\"select * from corona\").show()\n    ```", "```\n    spark.sql(\"select * from corona where location in ('India','Angola') order by location\").show()\n    ```"]