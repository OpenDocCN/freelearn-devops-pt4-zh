<html><head></head><body>
		<div>
			<div id="_idContainer333" class="Content">
			</div>
		</div>
		<div id="_idContainer334" class="Content">
			<h1 id="_idParaDest-298">13. <a id="_idTextAnchor312"/>Integrating Azure DevOps</h1>
		</div>
		<div id="_idContainer369" class="Content">
			<p>In the previous chapter, you learned about big data eventing and its relationship with Azure's Event Hubs and Stream Analytics services. Software development is a complex undertaking comprising multiple processes and tools, and involving people from different departments. They all need to come together and work in a cohesive manner. With so many variables, the risks are high when you are delivering to end customers. One small omission or misconfiguration might lead to the application coming crashing down. This chapter is about adopting and implementing practices that reduce this risk considerably and ensure that high-quality software can be delivered to the customer over and over again.</p>
			<p>Before getting into the details of DevOps, here is a list of the problems faced by software companies that DevOps addresses:</p>
			<ul>
				<li>Rigid organizations that don't welcome change</li>
				<li>Time-consuming processes</li>
				<li>Isolated teams working in silos</li>
				<li>Monolithic design and big bang deployments</li>
				<li>Manual execution</li>
				<li>A lack of innovation</li>
			</ul>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>DevOps</li>
				<li>DevOps practices</li>
				<li>Azure DevOps</li>
				<li>DevOps preparation</li>
				<li>DevOps for PaaS solutions</li>
				<li>DevOps for virtual machine-based (IaaS) solutions</li>
				<li>DevOps for container-based (IaaS) solutions</li>
				<li>Azure DevOps and Jenkins</li>
				<li>Azure Automation</li>
				<li>Azure tools for DevOps</li>
			</ul>
			<h2 id="_idParaDest-299"><a id="_idTextAnchor313"/>DevOps</h2>
			<p>There's currently no industry-wide consensus regarding the definition of DevOps. Organizations have formulated their own definition of DevOps and tried to implement it. They have their own perspective and think they've implemented DevOps once they implement automation and configuration management, and use Agile processes.</p>
			<p>Based on my experience working on DevOps projects in industry, I have defined DevOps as the following: DevOps is about the delivery mechanism of software systems. It's about bringing people together, making them collaborate and communicate, working together toward a common goal and vision. It's about taking joint responsibility, accountability, and ownership. It's about implementing processes that foster collaboration and a service mindset. It enables delivery mechanisms that bring agility and flexibility to the organization. Contrary to popular belief, DevOps isn't about tools, technology, and automation. These are enablers that help with collaboration, the implementation of Agile processes, and faster and better delivery to the customer.</p>
			<p>There are multiple definitions available on the internet for DevOps, and they aren't wrong. DevOps doesn't provide a framework or methodology. It's a set of principles and practices that, when employed within an organization, engagement, or project, achieve the goal and vision of both DevOps and the organization. These principles and practices don't mandate any specific processes, tools and technologies, or environments. DevOps provides guidance that can be implemented through any tool, technology, or process, although some of the technology and processes might be more applicable than others to achieve the vision of DevOps' principles and practices.</p>
			<p>Although DevOps practices can be implemented in any organization that provides services and products to customers, going forward in this book, we'll look at DevOps from the perspective of software development and the operations department of any organization.</p>
			<p>So, what is DevOps? DevOps is defined as a set of principles and practices bringing all teams, including developers and operations, together from the start of the project for faster, quicker, and more efficient end-to-end delivery of value to the end customer again and again, in a consistent and predictable manner, reducing time to market, thereby gaining a competitive advantage.</p>
			<p>The preceding definition of DevOps doesn't indicate or refer to any specific processes, tools, or technology. It doesn't prescribe any methodology or environment.</p>
			<p>The goal of implementing DevOps principles and practices in any organization is to ensure that the demands of stakeholders (including customers) and expectations are met efficiently and effectively.</p>
			<p>Customer demands and expectations are met when the following happens:</p>
			<ul>
				<li>The customer gets the features they want</li>
				<li>The customer gets the features they want when they want them</li>
				<li>The customer gets faster updates on features</li>
				<li>The quality of delivery is high</li>
			</ul>
			<p>When an organization can meet these expectations, customers are happy and remain loyal. This, in turn, increases the market competitiveness of the organization, which results in a bigger brand and market valuation. It has a direct impact on the top and bottom lines of the organization. The organization can invest further in innovation and customer feedback, bringing about continuous changes to its systems and services in order to stay relevant.</p>
			<p>The implementation of DevOps principles and practices in any organization is guided by its surrounding ecosystem. This ecosystem is made up of the industry and domains the organization belongs to.</p>
			<p>DevOps is based on a set of principles and practices. We'll look into the details of these principles and practices later in this chapter. The core principles of DevOps are: </p>
			<ul>
				<li><strong class="bold">Agility</strong>: Being Agile increases the overall flexibility to changes and ensures that adaptability increases to every changing environment and being productive. Agile processes have a shorter work duration and it's easy to find issues earlier in the development life cycle rather than much later, thereby reducing the technical debt.</li>
				<li><strong class="bold">Automation</strong>: The adoption of tools and automation increases the overall efficiency and predictability of the process and end product. It helps in doing things faster and in an easier and cheaper manner.</li>
				<li><strong class="bold">Collaboration</strong>: Collaboration refers to a common repository, the rotation of work responsibilities, the sharing of data and information, and other aspects that improve the productivity of each member of the team, thereby supporting the overall effective delivery of the product.</li>
				<li><strong class="bold">Feedback</strong>: This refers to quick and early feedback loops between multiple teams about things that work and things that don't work. It helps teams to prioritize issues and fix them in subsequent releases.</li>
			</ul>
			<p>The core DevOps practices are:</p>
			<ul>
				<li><strong class="bold">Continuous integration</strong>: This refers to the process of validating and verifying the quality and correctness of the code pushed within the repository by developers. It can be scheduled, manual, or continuous. Continuous means that the process will check for various quality attributes each time a developer pushes the code, while scheduled means on a given time schedule, the checks will be conducted. Manual refers to manual execution by an administrator or developer.</li>
				<li><strong class="bold">Configuration management</strong>: This is an important facet of DevOps and provides guidance for configuring infrastructure and applications either by pulling configurations from configuration management servers or by pushing these configurations on a schedule. Configuration management should bring back the environment to the expected desired state every time it gets executed.</li>
				<li><strong class="bold">Continuous delivery</strong>: Continuous delivery refers to the state of readiness of an application to be able to be deployed in any existing, as well as a new, environment. It is generally executed by means of a release definition in lower environments like development and testing.</li>
				<li><strong class="bold">Continuous deployment</strong>: Continuous deployment refers to the ability to deploy the environment and application in production automatically. It is generally executed by means of a release definition in the production environment.</li>
				<li><strong class="bold">Continuous learning</strong>: This refers to the process of understanding the issues faced by operations and customers and ensuring that they get communicated to development and testing teams such that they can fix those issues in subsequent releases to improve the overall health and usability of the application.</li>
			</ul>
			<h2 id="_idParaDest-300"><a id="_idTextAnchor314"/>The essence of DevOps</h2>
			<p>DevOps is not a new paradigm; however, it's gaining a lot of popularity and traction. Its adoption is at its highest level, and more and more companies are undertaking this journey. I purposely mentioned DevOps as a journey because there are different levels of maturity within DevOps. While successfully implementing continuous deployment and delivery are considered the highest level of maturity in this journey, adopting source code control and Agile software development are considered the first step in the DevOps journey.</p>
			<p>One of the first things DevOps talks about is breaking down the barriers between the development and the operations teams. It brings about close collaboration between multiple teams. It's about breaking the mindset that the developer is responsible for writing the code only and passing it on to operations for deployment once it's tested. It's also about breaking the mindset that operations have no role to play in development activities. Operations should influence the planning of the product and should be aware of the features coming up as releases. They should also continually provide feedback to the developers on operational issues such that they can be fixed in subsequent releases. They should influence the design of the system to improve the operational working of the system. Similarly, developers should help the operations team to deploy the system and solve incidents when they arise.</p>
			<p>The definition of DevOps talks about faster and more efficient end-to-end delivery of systems to stakeholders. It doesn't talk about how fast or efficient the delivery should be. It should be fast enough for the organization's domain, industry, customer segmentation, and needs. For some organizations, quarterly releases are good enough, while for others it could be weekly. Both are valid from a DevOps point of view, and these organizations can deploy relevant processes and technologies to achieve their target release deadlines. DevOps doesn't mandate any specific time frame for <strong class="bold">continuous integration/continuous deployment</strong> (<strong class="bold">CI/CD</strong>). Organizations should identify the best implementation of DevOps principles and practices based on their overall project, engagement, and organizational vision.</p>
			<p>The definition also talks about end-to-end delivery. This means that everything from the planning and delivery of the system through to the services and operations should be part of DevOps adoption. Processes should allow greater flexibility, modularity, and agility in the application development life cycle. While organizations are free to use the best fitting process—Waterfall, Agile, Scrum, or another—typically, organizations tend to favor Agile processes with iteration-based delivery. This allows faster delivery in smaller units, which are far more testable and manageable compared to a large delivery.</p>
			<p>DevOps repeatedly talks about end customers in a consistent and predictable manner. This means that organizations should continually deliver to customers with newer and upgraded features using automation. We can't achieve consistency and predictability without the use of automation. Manual work should be non-existent to ensure a high level of consistency and predictability. Automation should also be end-to-end, to avoid failures. This also indicates that the system design should be modular, allowing faster delivery on systems that are reliable, available, and scalable. Testing plays a big role in consistent and predictable delivery.</p>
			<p>The end result of implementing these practices and principles is that the organization is able to meet the expectations and demands of customers. The organization is able to grow faster than the competition, and further increase the quality and capability of their product and services through continuous innovation and improvement.</p>
			<p>Now that you understand the idea behind DevOps, it's time to look into core DevOps practices.</p>
			<h2 id="_idParaDest-301"><a id="_idTextAnchor315"/>DevOps practices</h2>
			<p>DevOps consists of multiple practices, each providing a distinct functionality to the overall process. The following diagram shows the relationship between them. Configuration management, continuous integration, and continuous deployment form the core practices that enable DevOps. When we deliver software services that combine these three services, we achieve continuous delivery. Continuous delivery is the capability and level of maturity of an organization that's dependent on the maturity of configuration management, continuous integration, and continuous deployment. Continuous feedback, at all stages, forms the feedback loop that helps to provide superior services to customers. It runs across all DevOps practices. Let's deep dive into each of these capabilities and DevOps practices:</p>
			<div>
				<div id="_idContainer335" class="IMG---Figure">
					<img src="image/B15432_13_01.jpg" alt="DevOps capabilities and practices"/>
				</div>
			</div>
			<h6>Figure 13.1:  DevOps practices</h6>
			<h3 id="_idParaDest-302"><a id="_idTextAnchor316"/>Configuration management</h3>
			<p>Business applications and services need an environment in which they can be deployed. Typically, the environment is an infrastructure composed of multiple servers, computers, network, storage, containers, and many more services working together such that business applications can be deployed on top of them. Business applications are decomposed into multiple services running on multiple servers, either on-premises or on the cloud, and each service has its own configuration along with requirements related to the infrastructure's configuration. In short, both the infrastructure and the application are needed to deliver systems to customers, and both of them have their own configuration. If the configuration drifts, the application might not work as expected, leading to downtime and failure. Moreover, as the <strong class="bold">Application Lifecycle Management</strong> (<strong class="bold">ALM</strong>) process dictates the use of multiple stages and environments, an application would be deployed to multiple environments with different configurations. The application would be deployed to the development environment for developers to see the result of their work. It would then be deployed to multiple test environments with different configurations for functional tests, load and stress tests, performance tests, integration tests, and more; it would also be deployed to the preproduction environment to conduct user-acceptance tests, and finally into the production environment. It's important that an application can be deployed to multiple environments without undertaking any manual changes to its configuration.</p>
			<p>Configuration management provides a set of processes and tools and they help to ensure that each environment and application gets its own configuration. Configuration management tracks configuration items, and anything that changes from environment to environment should be treated as a configuration item. Configuration management also defines the relationships between configuration items and how changes in one configuration item will impact other configuration items.</p>
			<p><strong class="bold">Usage of configuration management</strong></p>
			<p>Configuration management helps in the following places:</p>
			<ul>
				<li><strong class="bold">Infrastructure as Code</strong>: When the process of provisioning infrastructure and its configuration is represented through code, and the same code goes through the application life cycle process, it's known as <strong class="bold">Infrastructure as Code</strong> (<strong class="bold">IaC</strong>). IaC helps to automate the provisioning and configuration of infrastructure. It also represents the entire infrastructure in code that can be stored in a repository and version-controlled. This allows users to employ the previous environment's configurations when needed. It also enables the provisioning of an environment multiple times in a consistent and predictable manner. All environments provisioned in this way are consistent and equal in all ALM stages. There are many tools that help in achieving IaC, including ARM templates, Ansible, and Terraform.</li>
				<li><strong class="bold">Deploying and configuring the application</strong>: The deployment of an application and its configuration is the next step after provisioning the infrastructure. Examples include deploying a <strong class="inline">webdeploy</strong> package on a server, deploying a SQL server schema and data (<strong class="inline">bacpac</strong>) on another server, and changing the SQL connection string on the web server to represent the appropriate SQL server. Configuration management stores values for the application's configuration for each environment on which it is deployed.</li>
			</ul>
			<p>The configuration applied should also be monitored. The expected and desired configuration should be consistently maintained. Any drift from this expected and desired configuration would render the application unavailable. Configuration management is also capable of finding the drift and re-configuring the application and environment to its desired state.</p>
			<p>With automated configuration management in place, nobody on the team has to deploy and configure environments and applications in production. The operations team isn't reliant on the development team or long deployment documentation.</p>
			<p>Another aspect of configuration management is source code control. Business applications and services comprise code and other artifacts. Multiple team members work on the same files. The source code should always be up to date and should be accessible by only authenticated team members. The code and other artifacts by themselves are configuration items. Source control helps in collaboration and communication within the team since everybody is aware of what everyone else is doing and conflicts are resolved at an early stage.</p>
			<p>Configuration management can be broadly divided into two categories:</p>
			<ul>
				<li>Inside the virtual machine</li>
				<li>Outside the virtual machine</li>
			</ul>
			<h3 id="_idParaDest-303"><a id="_idTextAnchor317"/>Configuration management tools</h3>
			<p>The tools available for configuration management inside the virtual machine are discussed next.</p>
			<p><strong class="bold">Desired State Configuration</strong></p>
			<p><strong class="bold">Desired State Configuration</strong> (<strong class="bold">DSC</strong>) is a configuration-management platform from Microsoft, built as an extension to PowerShell. DSC was originally launched as part of <strong class="bold">Windows Management Framework</strong> (<strong class="bold">WMF</strong>) 4.0. It's available as part of WMF 4.0 and 5.0 for all Windows Server operating systems before Windows 2008 R2. WMF 5.1 is available out of the box on Windows Server 2016/2019 and Windows 10.</p>
			<p><strong class="bold">Chef, Puppet, and Ansible</strong></p>
			<p>Apart from DSC, there's a host of configuration-management tools, such as Chef, Puppet, and Ansible, supported by Azure. Details about these tools aren't covered in this book. Read more about them here: <a href="https://docs.microsoft.com/azure/virtual-machines/windows/infrastructure-automation">https://docs.microsoft.com/azure/virtual-machines/windows/infrastructure-automation</a>.</p>
			<p>The tools available for configuration management outside of a virtual machine are mentioned next.</p>
			<p><strong class="bold">ARM templates</strong></p>
			<p>ARM templates are the primary means of provisioning resources in ARM. ARM templates provide a declarative model through which resources and their configuration, scripts, and extensions are specified. ARM templates are based on <strong class="bold">JavaScript Object Notation</strong> (<strong class="bold">JSON</strong>) format. It uses JSON syntax and conventions to declare and configure resources. JSON files are text-based, user friendly, and easily readable. They can be stored in a source code repository and have version control on them. They are also a means to represent infrastructure as code that can be used to provision resources in Azure resource groups over and over again, predictably, consistently, and uniformly. </p>
			<p>Templates provide the flexibility to be generic and modular in their design and implementation. Templates give us the ability to accept parameters from users, declare internal variables, help define dependencies between resources, link resources within the same or different resource groups, and execute other templates. They also provide scripting language-type expressions and functions that make them dynamic and customizable at runtime. There are two chapters dedicated to ARM templates in this book: <em class="italics">Chapters 15, Cross Subscription Deployments Using ARM Templates</em>, and <em class="italics">Chapter 16, ARM Templates Modular Design and Implementation</em>.</p>
			<p>Now, it's time to focus on the next important DevOps principle: continuous integration.</p>
			<h3 id="_idParaDest-304"><a id="_idTextAnchor318"/>Continuous integration</h3>
			<p>Multiple developers write code that's eventually stored in a common repository. The code is normally checked in or pushed to the repository when the developers have finished developing their features. This can happen in a day or might take days or weeks. Some of the developers might be working on the same feature, and they might also follow the same practices of pushing/checking in code in days or weeks. This can create issues with the quality of the code. One of the tenets of DevOps is to fail fast. Developers should check in/push their code to the repository often and compile the code to check whether they've introduced bugs and that the code is compatible with the code written by their colleagues. If a developer doesn't follow this practice, the code on their machine will grow too large and will be difficult to integrate with other code. Moreover, if the compile fails, it's difficult and time-consuming to fix the issues that arise.</p>
			<p><strong class="bold">Code integration</strong></p>
			<p>Continuous integration solves these kinds of challenges. Continuous integration helps in compiling and validating the code pushed/checked in by a developer by taking it through a series of validation steps. Continuous integration creates a process flow that consists of multiple steps. Continuous integration is composed of continuous automated builds and continuous automated tests. Normally, the first step is compiling the code. After the successful compilation, each step is responsible for validating the code from a specific perspective. For example, unit tests can be executed on the compiled code, and then code coverage can be executed to check which code paths are executed by unit tests. These could reveal whether comprehensive unit tests are written or whether there's scope to add further unit tests. The end result of continuous integration is deployment packages that can be used by continuous deployment to deploy them to multiple environments.</p>
			<p><strong class="bold">Frequent code push</strong></p>
			<p>Developers are encouraged to check in their code multiple times a day, instead of doing so after days or weeks. Continuous integration initiates the execution of the entire pipeline as soon as the code is checked in or pushed. If compilation succeeds, code tests, and other activities that are part of the pipeline, are executed without error; the code is deployed to a test environment and integration tests are executed on it.</p>
			<p><strong class="bold">Increased productivity</strong></p>
			<p>Continuous integration increases developer productivity. They don't have to manually compile their code, run multiple types of tests one after another, and then create packages out of it. It also reduces the risk of getting bugs introduced in the code and the code doesn't get stale. It provides early feedback to the developers about the quality of their code. Overall, the quality of deliverables is high and they are delivered faster by adopting continuous integration practices. A sample continuous integration pipeline is shown here:</p>
			<div>
				<div id="_idContainer336" class="IMG---Figure">
					<img src="image/B15432_13_02.jpg" alt="A sample Continuous Integration pipeline"/>
				</div>
			</div>
			<h6>Figure 13.2: Continuous integration pipeline</h6>
			<p><strong class="bold">Build automation</strong></p>
			<p>Build automation consists of multiple tasks executing in sequence. Generally, the first task is responsible for fetching the latest source code from the repository. The source code might comprise multiple projects and files. They are compiled to generate artifacts, such as executables, dynamic link libraries, and assemblies. Successful build automation reflects that there are no compile-time errors in the code.</p>
			<p>There could be more steps to build automation, depending on the nature and type of the project.</p>
			<p><strong class="bold">Test automation</strong></p>
			<p>Test automation consists of tasks that are responsible for validating different aspects of code. These tasks are related to testing code from a different perspective and are executed in sequence. Generally, the first step is to run a series of unit tests on the code. Unit testing refers to the process of testing the smallest denomination of a feature by validating its behavior in isolation from other features. It can be automated or manual; however, the preference is toward automated unit testing.</p>
			<p>Code coverage is another type of automated testing that can be executed on code to find out how much of the code is executed when running unit tests. It's generally represented as a percentage and refers to how much code is testable through unit testing. If the code coverage isn't close to 100%, it's either because the developer hasn't written unit tests for that behavior or the uncovered code isn't required at all.</p>
			<p>The successful execution of test automation, resulting in no significant code failure, should start executing the packaging tasks. There could be more steps to test automation depending on the nature and type of the project.</p>
			<p><strong class="bold">Packaging</strong></p>
			<p>Packaging refers to the process of generating deployable artifacts, such as <strong class="inline">MSI</strong>, <strong class="inline">NuGet</strong>, and <strong class="inline">webdeploy</strong> packages, and database packages; versioning them; and then storing them in a location such that they can be consumed by other pipelines and processes.</p>
			<p>Once the process of continuous integration completes, the process of continuous deployment starts, and that will be the focus of the next section.</p>
			<h3 id="_idParaDest-305"><a id="_idTextAnchor319"/>Continuous deployment</h3>
			<p>By the time the process reaches continuous deployment, continuous integration has ensured that we have fully working bits of an application that can now be taken through different continuous deployment activities. Continuous deployment refers to the capability of deploying business applications and services to preproduction and production environments through automation. For example, continuous deployment could provision and configure the preproduction environment, deploy applications to it, and configure the applications. After conducting multiple validations, such as functional tests and performance tests on the preproduction environment, the production environment is provisioned, configured, and the application is deployed through automation. There are no manual steps in the deployment process. Every deployment task is automated. Continuous deployment can provision the environment and deploy the application from scratch, while it can just deploy delta changes to an existing environment if the environment already exists.</p>
			<p>All environments are provisioned through automation using IaC. This ensures that all environments, whether development, test, preproduction, or production, are the same. Similarly, the application is deployed through automation, ensuring that it's also deployed uniformly across all environments. The configuration across these environments could be different for the application.</p>
			<p>Continuous deployment is generally integrated with continuous integration. When continuous integration has done its work, by generating the final deployable packages, continuous deployment kicks in and starts its own pipeline. This pipeline is called the release pipeline. The release pipeline consists of multiple environments, with each environment consisting of tasks responsible for provisioning the environment, configuring the environment, deploying applications, configuring applications, executing operational validation on environments, and testing the application on multiple environments.</p>
			<p>Employing continuous deployment provides immense benefits. There is a high level of confidence in the overall deployment process, which helps with faster and risk-free releases on production. The chances of anything going wrong decrease drastically. The team will be less stressed, and rollback to the previous working environment is possible if there are issues with the current release:</p>
			<div>
				<div id="_idContainer337" class="IMG---Figure">
					<img src="image/B15432_13_03.jpg" alt="A standard Continuous Deployment pipeline"/>
				</div>
			</div>
			<h6>Figure 13.3: Continuous deployment pipeline</h6>
			<p>Although every system demands its own configuration of the release pipeline, an example of continuous deployment is shown in the preceding diagram. It's important to note that, generally, provisioning and configuring multiple environments is part of the release pipeline, and approvals should be sought before moving to the next environment. The approval process might be manual or automated, depending on the maturity of the organization.</p>
			<p>Next, we will look into aspects related to the test environment.</p>
			<p><strong class="bold">Test environment deployment</strong></p>
			<p>The release pipeline starts once the drop is available from continuous integration and the first step it should take is to get all the artifacts from the drop. After this, the release pipeline might create a completely new bare-metal test environment or reuse an existing one. This is again dependent on the type of project and the nature of the testing planned to be executed in this environment. The environment is provisioned and configured. The application artifacts are deployed and configured.</p>
			<p><strong class="bold">Test automation</strong></p>
			<p>After deploying an application, a series of tests can be performed on the environment. One of the tests executed here is a functional test. Functional tests are primarily aimed at validating the feature completeness and functionality of the application. These tests are written from requirements gathered from the customer. Another set of tests that can be executed is related to the scalability and availability of the application. This typically includes load tests, stress tests, and performance tests. It should also include an operational validation of the infrastructure environment.</p>
			<p><strong class="bold">Staging environment deployment</strong></p>
			<p>This is very similar to the test environment deployment, the only difference being that the configuration values for the environment and application would be different.</p>
			<p><strong class="bold">Acceptance tests</strong></p>
			<p>Acceptance tests are generally conducted by application stakeholders, and these can be manual or automated. This step is a validation from the customer's point of view about the correctness and completeness of the application's functionality.</p>
			<p><strong class="bold">Deployment to production</strong></p>
			<p>Once the customer gives their approval, the same steps as that of the test and staging environment deployment are executed, the only difference being that the configuration values for the environment and application are specific to the production environment. A validation is conducted after deployment to ensure that the application is running according to expectations.</p>
			<p>Continuous delivery is an important DevOps principle and closely resembles continuous deployment; however, there are a few differences. In the next section, we will look into continuous delivery.</p>
			<h3 id="_idParaDest-306"><a id="_idTextAnchor320"/>Continuous delivery</h3>
			<p>Continuous delivery and continuous deployment might sound similar to you; however, they aren't the same. While continuous deployment talks about deployment to multiple environments and finally to the production environment through automation, continuous delivery is the ability to generate application packages that are readily deployable in any environment. To generate artifacts that are readily deployable, continuous integration should be used to generate the application artifacts; a new or existing environment should be used to deploy these artifacts and conduct functional tests, performance tests, and user-acceptance tests through automation. Once these activities are successfully executed without any errors, the application package is considered readily deployable. Continuous delivery includes continuous integration and deployment to an environment for final validations. It helps get feedback more quickly from both the operations and the end user. This feedback can then be used to implement subsequent iterations.</p>
			<p>In the next section, we will look into continuous learning.</p>
			<h3 id="_idParaDest-307"><a id="_idTextAnchor321"/>Continuous learning</h3>
			<p>With all the previously mentioned DevOps practices, it's possible to create great business applications and deploy them automatically to the production environment; however, the benefits of DevOps won't last for long if continuous improvement and feedback principles are not in place. It's of the utmost importance that real-time feedback about the application behavior is passed on as feedback to the development team from both end users and the operations team.</p>
			<p>Feedback should be passed to the teams, providing relevant information about what's going well and what isn't.</p>
			<p>An application's architecture and design should be built with monitoring, auditing, and telemetry in mind. The operations team should collect telemetry information from the production environment, capturing any bugs and issues, and pass it on to the development team so that it can be fixed for subsequent releases.</p>
			<p>Continuous learning helps to make the application robust and resilient to failure. It helps in making sure that the application is meeting consumer requirements. <em class="italics">Figure 13.4 </em> shows the feedback loop that should be implemented between different teams:</p>
			<div>
				<div id="_idContainer338" class="IMG---Figure">
					<img src="image/B15432_13_04.jpg" alt="Monitoring and feedback practices in DevOps"/>
				</div>
			</div>
			<h6>Figure 13.4: Feedback loop</h6>
			<p>After going through the important practices related to DevOps, now it's time to get into tools and services that make these possible. </p>
			<h2 id="_idParaDest-308"><a id="_idTextAnchor322"/>Azure DevOps</h2>
			<p>Let's look at another top-of-the-line online service that enables continuous integration, continuous deployment, and continuous delivery seamlessly: Azure DevOps. In fact, it would be more appropriate to call it a suite of services available under a single name. Azure DevOps is a PaaS provided by Microsoft and hosted on the cloud. The same service is available as <strong class="bold">Team Foundation Services</strong> (<strong class="bold">TFS</strong>) on-premises. All examples shown in this book use Azure DevOps.</p>
			<p>According to Microsoft, Azure DevOps is a cloud-based collaboration platform that helps teams to share code, track work, and ship software. Azure DevOps is a new name; earlier, it was known as <strong class="bold">Visual Studio Team Services</strong> (<strong class="bold">VSTS</strong>). Azure DevOps is an enterprise software-development tool and service that enables organizations to provide automation facilities to their end-to-end application life cycle management process, from planning to deploying applications, and getting real-time feedback from software systems. This increases the maturity and capability of an organization to deliver high-quality software systems to their customers.</p>
			<p>Successful software delivery involves efficiently bringing numerous processes and activities together. These include executing and implementing various Agile processes, increasing collaboration among teams, the seamless and automatic transition of artifacts from one phase of the ALM to another phase, and deployments to multiple environments. It's important to track and report on these activities to measure and improve delivery processes. Azure DevOps makes this simple and easy. It provides a whole suite of services that enables the following:</p>
			<ul>
				<li>Collaboration among every team member by providing a single interface for the entire application life cycle management</li>
				<li>Collaboration among development teams using source-code-management services</li>
				<li>Collaboration among test teams using test-management services</li>
				<li>Automatic validation of code and packaging through continuous integration using build-management services</li>
				<li>Automatic validation of application functionality, deployment, and configuration of multiple environments through continuous deployment and delivery using release-management services</li>
				<li>Tracking and work-item management using work-management services</li>
			</ul>
			<p>The following table shows all the services available to a typical project from the <strong class="bold">Azure DevOps</strong> left navigation bar:</p>
			<div>
				<div id="_idContainer339" class="IMG---Figure">
					<img src="image/Table_13_01.jpg" alt="A list of Azure DevOps services"/>
				</div>
			</div>
			<h6>Table 13.1: A list of Azure DevOps services</h6>
			<p>An organization in Azure DevOps serves as a security boundary and logical container that provides all the services that are needed to implement a DevOps strategy. Azure DevOps allows the creation of multiple projects within a single organization. By default, a repository is created with the creation of a project; however, Azure DevOps allows the creation of additional repositories within a single project. The relationship between an <strong class="bold">Azure DevOps Organization</strong>, <strong class="bold">Projects</strong>, and a <strong class="bold">Repository</strong> is shown in <em class="italics">Figure 13.5</em>:</p>
			<div>
				<div id="_idContainer340" class="IMG---Figure">
					<img src="image/B15432_13_05.jpg" alt="Projects and repositories in a DevOps implementation"/>
				</div>
			</div>
			<h6>Figure 13.5: Relationship between Azure DevOps Organization, Projects, and Repository</h6>
			<p>Azure DevOps provides two types of repositories:</p>
			<ul>
				<li>Git</li>
				<li>Team Foundation Version Control (TFVC)</li>
			</ul>
			<p>It also provides the flexibility to choose between the Git or TFVC source-control repository. There can be a combination of TFS and TFVC repositories available within a single project.</p>
			<h3 id="_idParaDest-309"><a id="_idTextAnchor323"/>TFVC</h3>
			<p>TFVC is the traditional and centralized way of implementing version control, where there's a central repository and developers work on it directly in connected mode to check in their changes. If the central repository is offline or unavailable, developers can't check in their code and have to wait for it to be online and available. Other developers can see only the checked-in code. Developers can group multiple changes into a single changeset for checking in code changes that are logically grouped to form a single change. TFVC locks the code files that are undergoing edits. Other developers can read a locked file, but they can't edit it. They must wait for the prior edit to complete and release the lock before they can edit. The history of check-ins and changes is maintained on the central repository, while the developers have the working copy of the files but not the history.</p>
			<p>TFVC works very well with large teams that are working on the same projects. This enables control over the source code at a central location. It also works best for long-duration projects since the history can be managed at a central location. TFVC has no issues working with large and binary files.</p>
			<h3 id="_idParaDest-310"><a id="_idTextAnchor324"/>Git</h3>
			<p>Git, on the other hand, is a modern, distributed way of implementing version control, where developers can work on their own local copies of code and history in offline mode. Developers can work offline on their local clone of code. Each developer has a local copy of code and its entire history, and they work on their changes with this local repository. They can commit their code to the local repository. They can connect to the central repository for the synchronization of their local repository on a per-need basis. This allows every developer to work on any file since they would be working on their local copy. Branching in Git doesn't create another copy of the original code and is extremely fast to create.</p>
			<p>Git works well with both small and large teams. Branching and merging is a breeze with the advanced options that Git has.</p>
			<p>Git is the recommended way of using source control because of the rich functionality it provides. We'll use Git as the repository for our sample application in this book. In the next section, we will have a detailed overview of implementing automation through DevOps.</p>
			<h2 id="_idParaDest-311"><a id="_idTextAnchor325"/>Preparing for DevOps</h2>
			<p>Going forward, our focus will be on process and deployment automation using different patterns in Azure. These include the following:</p>
			<ul>
				<li>DevOps for IaaS solutions</li>
				<li>DevOps for PaaS solutions</li>
				<li>DevOps for container-based solutions</li>
			</ul>
			<p>Generally, there are shared services that aren't unique to any one application. These services are consumed by multiple applications from different environments, such as development, testing, and production. The life cycle of these shared services is different for each application. Therefore, they have different version-control repositories, a different code base, and build and release management. They have their own cycle of plan, design, build, test, and release.</p>
			<p>The resources that are part of this group are provisioned using ARM templates, PowerShell, and DSC configurations.</p>
			<p>The overall flow for building these common components is shown here:</p>
			<div>
				<div id="_idContainer341" class="IMG---Figure">
					<img src="image/B15432_13_06.jpg" alt="Flow for building common components in a DevOps project"/>
				</div>
			</div>
			<h6>Figure 13.6: Overall flow for building common components</h6>
			<p>The release process is shown in <em class="italics">Figure 13.7</em>:</p>
			<div>
				<div id="_idContainer342" class="IMG---Figure">
					<img src="image/B15432_13_07.jpg" alt="A standard DevOps release process"/>
				</div>
			</div>
			<h6>Figure 13.7: Release process</h6>
			<p>On the DevOps journey, it's important to understand and provision the common components and services before starting any software engagement, product, or service.</p>
			<p>The first step in getting started with Azure DevOps is to provision an organization.</p>
			<h3 id="_idParaDest-312"><a id="_idTextAnchor326"/>Azure DevOps organizations</h3>
			<p>A version-control system is needed to collaborate at the code level. Azure DevOps provides both centralized and decentralized versions of control systems. Azure DevOps also provides orchestration services for building and executing build and release pipelines. It's a mature platform that organizes all DevOps-related version control and builds and releases work-item-related artifacts. After an organization is provisioned in Azure DevOps, an Azure DevOps project should be created to hold all project-related artifacts.</p>
			<p>An Azure DevOps organization can be provisioned by visiting <a href="https://dev.azure.com">https://dev.azure.com</a>.</p>
			<p>An Azure DevOps organization is the top-level administrative and management boundary that provides security, access, and collaboration between team members belonging to an organization. There can be multiple projects within an organization and each project comprises multiple teams.</p>
			<h3 id="_idParaDest-313"><a id="_idTextAnchor327"/>Provisioning Azure Key Vault</h3>
			<p>It isn't advisable to store secrets, certificates, credentials, or other sensitive information in code configuration files, databases, or any other general storage system. It's advised to store this important data in a vault that's specifically designed for storing secrets and credentials. Azure Key Vault provides such a service. Azure Key Vault is available as a resource and service from Azure. Now, let's move on to exploring the storage options for configurations.</p>
			<h3 id="_idParaDest-314"><a id="_idTextAnchor328"/>Provisioning a configuration-management server/service</h3>
			<p>A configuration-management server/service that provides storage for configurations and applies those configurations to different environments is always a good strategy for automating deployments. DSC on custom virtual machines and DSC from Azure Automation, Chef, Puppet, and Ansible are some options and can be used on Azure seamlessly for both Windows as well as Linux environments. This book uses DSC as a configuration-management tool for all purposes, and it provides a pull server that holds all configuration documents (MOF files) for the sample application. It also maintains the database of all virtual machines and containers that are configured and registered with the pull server to pull configuration documents from it. The local configuration manager on these targets virtual machines, and containers periodically check the availability of new configurations as well as drifts in the current configuration and report back to the pull server. It also has built-in reporting capabilities that provide information about nodes that are compliant, as well as those that are non-compliant, within a virtual machine. A pull server is a general web application that hosts the DSC pull server endpoint. In the next topic, we will discuss a technique to monitor processes in real time with Log Analytics.</p>
			<h3 id="_idParaDest-315"><a id="_idTextAnchor329"/>Log Analytics</h3>
			<p>Log Analytics is an audit and monitoring service provided by Azure to get real-time information about all changes, drifts, and events occurring within virtual machines and containers. It provides a centralized workspace and dashboard for IT administrators for viewing, searching, and conducting drill-down searches on all changes, drifts, and events that occur on these virtual machines. It also provides agents that are deployed on target virtual machines and containers. Once deployed, these agents start sending all changes, events, and drifts to the centralized workspace. Let's check out the storage options for deploying multiple applications. </p>
			<h3 id="_idParaDest-316"><a id="_idTextAnchor330"/>Azure Storage accounts</h3>
			<p>Azure Storage is a service provided by Azure to store files as blobs. All scripts and code for automating the provisioning, deployment, and configuration of the infrastructure and sample application are stored in the Azure DevOps Git repository and are packaged and deployed in an Azure Storage account. Azure provides PowerShell script-extension resources that can automatically download DSC and PowerShell scripts and execute them on virtual machines during the execution of ARM templates. This storage acts as common storage across all deployments for multiple applications. Storing scripts and templates in a Storage account ensures that they can be used across projects irrespective of projects in Azure DevOps. Let's move on to exploring the importance of images in the next section.</p>
			<h3 id="_idParaDest-317"><a id="_idTextAnchor331"/>Docker and OS images</h3>
			<p>Both virtual machine and container images should be built as part of the common services build-and-release pipeline. Tools such as Packer and Docker Build can be used to generate these images.</p>
			<h3 id="_idParaDest-318"><a id="_idTextAnchor332"/>Management tools</h3>
			<p>All management tools, such as Kubernetes, DC/OS, Docker Swarm, and ITIL tools, should be provisioned before building and deploying the solution.</p>
			<p>We'll conclude this section on DevOps preparation with management tools. There are multiple choices for each activity within a DevOps ecosystem and we should enable them as part of the DevOps journey—it should not be an afterthought, but rather part of DevOps planning.</p>
			<h2 id="_idParaDest-319"><a id="_idTextAnchor333"/>DevOps for PaaS solutions</h2>
			<p>The typical architecture for Azure PaaS app services is based on <em class="italics">Figure 13.8</em>:</p>
			<div>
				<div id="_idContainer343" class="IMG---Figure">
					<img src="image/B15432_13_08.jpg" alt="A typical Azure PaaS App Service architecture"/>
				</div>
			</div>
			<h6>Figure 13.8: A typical Azure PaaS app service architecture</h6>
			<p>The architecture shows some of the important components—such as Azure SQL, Storage accounts, and the version control system—that participate in the Azure App Service-based cloud solution architecture. These artifacts should be created using ARM templates. These ARM templates should be part of the overall configuration management strategy. It can have its own build and release management pipelines, similar to the one shown in <em class="italics">Figure 13.9</em>:</p>
			<div>
				<div id="_idContainer344" class="IMG---Figure">
					<img src="image/B15432_13_09.jpg" alt="Choosing deployment options for the sample app service"/>
				</div>
			</div>
			<h6>Figure 13.9: Choosing deployment options for the app service</h6>
			<p>Now that we have explored the various deployment source options, let's go ahead and dive into understanding how to deploy cloud solutions on Azure.</p>
			<h3 id="_idParaDest-320"><a id="_idTextAnchor334"/>Azure App Service</h3>
			<p>Azure App Service provides managed hosting services for cloud solutions. It's a fully-managed platform that provisions and deploys cloud solutions. Azure App Service takes away the burden of creating and managing infrastructure and provides minimum <strong class="bold">service-level agreements</strong> (<strong class="bold">SLAs</strong>) for hosting your cloud solutions.</p>
			<h3 id="_idParaDest-321"><a id="_idTextAnchor335"/>Deployment slots</h3>
			<p>Azure App Service provides deployment slots that make deployment to them seamless and easy. There are multiple slots, and swapping between slots is done at a DNS level. It means anything in the production slot can be swapped with a staging slot by just swapping the DNS entries. This helps in deploying the custom cloud solution to staging and, after all checks and tests, they can be swapped to production if found satisfactory. However, in the event of any issue in production after swapping, the previous good values from the production environment can be reinstated by swapping again. Let's move on to understanding Azure's database offering and some of its key features.</p>
			<h3 id="_idParaDest-322"><a id="_idTextAnchor336"/>Azure SQL</h3>
			<p>Azure SQL is a SQL PaaS service provided by Azure to host databases. Azure provides a secure platform to host databases and takes complete ownership to manage the availability, reliability, and scalability of the service. With Azure SQL, there's no need to provision custom virtual machines, deploy a SQL server, and configure it. Instead, the Azure team does this behind the scenes and manages it on your behalf. It also provides a firewall service that enables security; only an IP address allowed by the firewall can connect the server and access the database. The virtual machines provisioned to host web applications have distinct public IP addresses assigned to them and they're added to Azure SQL firewall rules dynamically. Azure SQL Server and its database is created upon executing the ARM template. Next, we will cover build and release pipelines.</p>
			<h3 id="_idParaDest-323"><a id="_idTextAnchor337"/>The build and release pipelines</h3>
			<p>In this section, a new build pipeline is created that compiles and validates an ASP.NET MVC application, and then generates packages for deployment. After package generation, a release definition ensures that deployment to the first environment happens in an App Service and Azure SQL as part of continuous deployment.</p>
			<p>There are two ways to author build and release pipelines:</p>
			<ol>
				<li>Using the classic editor</li>
				<li>Using YAML files</li>
			</ol>
			<p>YAML files provide more flexibility for authoring build and release pipelines.</p>
			<p>The project structure of the sample application is shown in <em class="italics">Figure 13.10</em>:</p>
			<div>
				<div id="_idContainer345" class="IMG---Figure">
					<img src="image/B15432_13_10.jpg" alt="Project structure of a sample application"/>
				</div>
			</div>
			<h6>Figure 13.10: Project structure of a sample application</h6>
			<p>In this project, there's an ASP.NET MVC application—the main application—and it consists of application pages. Web Deploy packages will be generated out of this project from build pipelines and they will eventually be on Web Apps. There are other projects that are also part of the solution, as mentioned next:</p>
			<ul>
				<li><strong class="bold">Unit test project</strong>: Code for unit-testing the ASP.NET MVC application. Assemblies from this project will be generated and executed in the build execution.</li>
				<li><strong class="bold">SQL Database project</strong>: Code related to the SQL database schema, structure, and master data. <strong class="inline">DacPac</strong> files will be generated out of this project using the build definition.</li>
				<li><strong class="bold">Azure resource group project</strong>: ARM templates and parameter code to provision the entire Azure environment on which the ASP.NET MVC application and the SQL tables are created.</li>
			</ul>
			<p>The build pipeline is shown in <em class="italics">Figure 13.11</em>:</p>
			<div>
				<div id="_idContainer346" class="IMG---Figure">
					<img src="image/B15432_13_11.jpg" alt="Build pipeline of the ASP.NET MVC application"/>
				</div>
			</div>
			<h6>Figure 13.11: Build pipeline of the ASP.NET MVC application</h6>
			<p>The configuration of each task is shown in <em class="italics">Table 13.2</em>:</p>
			<div>
				<div id="_idContainer347" class="IMG---Figure">
					<img src="image/13.2_29.jpg" alt="Configuration of the build pipeline tasks"/>
				</div>
			</div>
			<div>
				<div id="_idContainer348" class="IMG---Figure">
					<img src="image/13.2_30.jpg" alt="Configuration of the build pipeline tasks"/>
				</div>
			</div>
			<div>
				<div id="_idContainer349" class="IMG---Figure">
					<img src="image/13.2_31.jpg" alt="Configuration of the build pipeline tasks"/>
				</div>
			</div>
			<div>
				<div id="_idContainer350" class="IMG---Figure">
					<img src="image/13.2_32.jpg" alt="Configuration of the build pipeline tasks"/>
				</div>
			</div>
			<h6>Table 13.2: Configuration of the build pipeline tasks</h6>
			<p>The build pipeline is configured to execute automatically as part of continuous integration, as shown in <em class="italics">Figure 13.12</em>:</p>
			<div>
				<div id="_idContainer351" class="IMG---Figure">
					<img src="image/B15432_13_12.jpg" alt="Enabling continuous integration in the build pipeline"/>
				</div>
			</div>
			<h6>Figure 13.12: Enabling continuous integration in the build pipeline</h6>
			<p>The release definition consists of multiple environments, such as development, testing, <strong class="bold">System Integration Testing</strong> (<strong class="bold">SIT</strong>), <strong class="bold">User Acceptance Testing</strong> (<strong class="bold">UAT</strong>), preproduction, and production. The tasks are pretty similar in each environment, with the addition of tasks specific to that environment. For example, a test environment has additional tasks related to the UI, and functional and integration testing, compared to a development environment.</p>
			<p>The release definition for such an application is shown in <em class="italics">Figure 13.13</em>:</p>
			<div>
				<div id="_idContainer352" class="IMG---Figure">
					<img src="image/B15432_13_13.jpg" alt="Stages in the release definition of the ASP.NET-CI application"/>
				</div>
			</div>
			<h6>Figure 13.13: Release definition</h6>
			<p>The release tasks for a single environment are shown in <em class="italics">Figure 13.14</em>:</p>
			<div>
				<div id="_idContainer353" class="IMG---Figure">
					<img src="image/B15432_13_14.jpg" alt="Release tasks for a single environment"/>
				</div>
			</div>
			<h6>Figure 13.14: Release tasks for a single environment</h6>
			<p>The configuration for each of the tasks is listed here:</p>
			<div>
				<div id="_idContainer354" class="IMG---Figure">
					<img src="image/13.3_34.jpg" alt="Configuration of the release pipeline tasks"/>
				</div>
			</div>
			<div>
				<div id="_idContainer355" class="IMG---Figure">
					<img src="image/13.3_35.jpg" alt="Configuration of the release pipeline tasks"/>
				</div>
			</div>
			<div>
				<div id="_idContainer356" class="IMG---Figure">
					<img src="image/13.3_36.jpg" alt="Configuration of the release pipeline tasks"/>
				</div>
			</div>
			<div>
				<div id="_idContainer357" class="IMG---Figure">
					<img src="image/13.3_37.jpg" alt="Configuration of the release pipeline tasks"/>
				</div>
			</div>
			<h6>Table 13.3: Configuration of the release pipeline tasks</h6>
			<p>In this section, you saw ways to configure build and release pipelines in Azure DevOps. In the next section onward, the focus will be on different architectures, such as IaaS, containers, and different scenarios.</p>
			<h2 id="_idParaDest-324"><a id="_idTextAnchor338"/>DevOps for IaaS</h2>
			<p>IaaS involves the management and administration of base infrastructure and applications together and there are multiple resources and components that need to be provisioned, configured, and deployed on multiple environments. It is important to understand the architecture before going ahead.</p>
			<p>The typical architecture for an IaaS virtual machine-based solution is shown here:</p>
			<div>
				<div id="_idContainer358" class="IMG---Figure">
					<img src="image/B15432_13_15.jpg" alt="Architecture for an IaaS virtual machine-based solution"/>
				</div>
			</div>
			<h6>Figure 13.15: Architecture for an IaaS virtual machine-based solution</h6>
			<p>Each of the components listed in the architecture is discussed from the next section onward.</p>
			<h3 id="_idParaDest-325"><a id="_idTextAnchor339"/>Azure virtual machines</h3>
			<p>Azure virtual machines that host web applications, application servers, databases, and other services are provisioned using ARM templates. They're attached to a virtual network and have a private IP address from the same network. The public IP for virtual machines is optional since they're attached to a public load balancer. Operational Insights agents are installed on virtual machines to monitor the virtual machines. PowerShell scripts are also executed on these virtual machines, downloaded from a Storage account available in another resource group to open relevant firewall ports, download appropriate packages, and install local certificates to secure access through PowerShell. The web application is configured to run on the provided port on these virtual machines. The port number for the web application and all its configuration is pulled from the DSC pull server and dynamically assigned.</p>
			<h3 id="_idParaDest-326"><a id="_idTextAnchor340"/>Azure public load balancers</h3>
			<p>A public load balancer is attached to some of the virtual machines for sending requests to them in a round-robin fashion. This is generally needed for front-end web applications and APIs. A public IP address and DNS name can be assigned to a load balancer such that it can serve internet requests. It accepts HTTP web requests on a different port and routes them to the virtual machines. It also probes certain ports on HTTP protocols with some provided application paths. <strong class="bold">Network Address Translation</strong> (<strong class="bold">NAT</strong>) rules can also be applied such that they can be used to log into the virtual machines using remote desktops.</p>
			<p>An alternative resource to the Azure public Load Balancer is the Azure Application Gateway. Application gateways are layer-7 load balancers and provide features such as SSL termination, session affinity, and URL-based routing. Let's discuss the build pipeline in the next section.</p>
			<h3 id="_idParaDest-327"><a id="_idTextAnchor341"/>The build pipeline</h3>
			<p>A typical build pipeline for an IaaS virtual machine-based solution is shown next. A release pipeline starts when a developer pushes their code to the repository. The build pipeline starts automatically as part of continuous integration. It compiles and builds the code, executes unit tests on it, checks code quality, and generates documentation from code comments. It deploys the new binaries into the development environment (note that the development environment is not newly created), changes configuration, executes integration tests, and generates build labels for easy identification. It then drops the generated artifacts into a location accessible by the release pipeline. If there are issues during the execution of any step in this pipeline, this is communicated to the developer as part of the build pipeline feedback so that they can rework and resubmit their changes. The build pipeline should fail or pass based on the severity of issues found, and that varies from organization to organization. A typical build pipeline is shown in <em class="italics">Figure 13.16</em>:</p>
			<div>
				<div id="_idContainer359" class="IMG---Figure">
					<img src="image/B15432_13_16.jpg" alt="A typical IaaS build pipeline"/>
				</div>
			</div>
			<h6>Figure 13.16: A typical IaaS build pipeline</h6>
			<p>Similar to the build pipeline, let's learn about the implementation of a release pipeline.</p>
			<h3 id="_idParaDest-328"><a id="_idTextAnchor342"/>The release pipeline</h3>
			<p>A typical release pipeline for an IaaS virtual machine-based deployment is shown next. A release pipeline starts after the completion of the build pipeline. The first step in the release pipeline is to gather the artifacts generated by the build pipeline. They are generally deployable assemblies, binaries, and configuration documents. The release pipeline executes and creates or updates the first environment, which generally is a test environment. It uses ARM templates to provision all IaaS and PaaS services and resources on Azure and configures them as well. They also help in executing scripts and DSC configuration after virtual machines are created as post-creation steps. This helps to configure the environment within the virtual machine and the operating system. At this stage, application binaries from the build pipeline are deployed and configured. Different automated tests are performed to check the solution and, if found satisfactory, the pipeline moves the deployment to the next environment after obtaining the necessary approvals. The same steps are executed in the next environment, including the production environment. Finally, the operational validation tests are executed in production to ensure that the application is working as expected and there are no deviations.</p>
			<p>At this stage, if there are any issues or bugs, they should be rectified and the entire cycle should be repeated; however, if this doesn't happen within a stipulated time frame, the last-known snapshot should be restored in the production environment to minimize downtime. A typical release pipeline is shown in <em class="italics">Figure 13.17</em>:</p>
			<div>
				<div id="_idContainer360" class="IMG---Figure">
					<img src="image/B15432_13_17.jpg" alt="A typical IaaS release pipeline"/>
				</div>
			</div>
			<h6>Figure 13.17: A typical IaaS release pipeline</h6>
			<p>This section concludes the DevOps process for IaaS solutions and the next chapter will focus on containers on virtual machines. Please note that containers can also run on PaaS like App Service and Azure Functions. </p>
			<h2 id="_idParaDest-329"><a id="_idTextAnchor343"/>DevOps with containers</h2>
			<p>In a typical architecture, container runtimes are deployed on virtual machines and containers are run within them. The typical architecture for IaaS container-based solutions is shown here:</p>
			<div>
				<div id="_idContainer361" class="IMG---Figure">
					<img src="image/B15432_13_18.jpg" alt="IaaS container-based solution architecture"/>
				</div>
			</div>
			<h6>Figure 13.18: Architecture for IaaS container-based solutions</h6>
			<p>These containers are managed by container orchestrators such as Kubernetes. Monitoring services are provided by Log Analytics and all secrets and keys are stored in Azure Key Vault. There is also a pull server, which could be on a virtual machine or Azure Automation, providing configuration information to the virtual machines.</p>
			<h3 id="_idParaDest-330"><a id="_idTextAnchor344"/>Containers</h3>
			<p>Containers are a virtualization technology; however, they don't virtualize physical servers. Instead, containers are an operating system-level virtualization. This means that containers share the operating system kernel provided by their host among themselves and with the host. Running multiple containers on a host (physical or virtual) shares the host operating system kernel. There's a single operating system kernel provided by the host and used by all containers running on top of it.</p>
			<p>Containers are also completely isolated from their host and other containers, much like a virtual machine. Containers use operating system namespaces, control groups on Linux, to provide the perception of a new operating system environment, and use specific operating system virtualization techniques on Windows. Each container gets its own copy of the operating system resources.</p>
			<p><strong class="bold">Docker</strong></p>
			<p>Docker provides management features to containers. It comprises two executables:</p>
			<ul>
				<li>The Docker daemon</li>
				<li>The Docker client</li>
			</ul>
			<p>The Docker daemon is the workhorse for managing containers. It's a management service that's responsible for managing all activities on the host related to containers. The Docker client interacts with the Docker daemon and is responsible for capturing inputs and sending them to the Docker daemon. The Docker daemon provides the runtime; libraries; graph drivers; the engines to create, manage, and monitor containers; and images on the host server. It can also create custom images that are used for building and shipping applications to multiple environments.</p>
			<p><strong class="bold">The Dockerfile</strong></p>
			<p>The <strong class="inline">Dockerfile</strong> is the primary building block for creating container images. It's a simple text-based human-readable file without an extension and is even named <strong class="inline">Dockerfile</strong>. Although there's a mechanism to name it differently, generally it is named <strong class="inline">Dockerfile</strong>. The Dockerfile contains instructions to create a custom image using a base image. These instructions are executed sequentially from top to bottom by the Docker daemon. The instructions refer to the command and its parameters, such as <strong class="inline">COPY</strong>, <strong class="inline">ADD</strong>, <strong class="inline">RUN</strong>, and <strong class="inline">ENTRYPOINT</strong>. The Dockerfile enables IaC practices by converting the application deployment and configuration into instructions that can be versioned and stored in a source code repository. Let's check out the build steps in the following section.</p>
			<h3 id="_idParaDest-331"><a id="_idTextAnchor345"/>The build pipeline</h3>
			<p>There's no difference, from the build perspective, between the container and a virtual-machine-based solution. The build step remains the same. A typical release pipeline for an IaaS container-based deployment is shown next. </p>
			<h3 id="_idParaDest-332"><a id="_idTextAnchor346"/>The release pipeline</h3>
			<p>The only difference between a typical release pipeline for an IaaS container-based deployment and the release pipeline is the container-image management and the creation of containers using Dockerfile and Docker Compose. Advanced container-management utilities, such as Docker Swarm, DC/OS, and Kubernetes, can also be deployed and configured as part of release management. However, note that these container management tools should be part of the shared services release pipeline, as discussed earlier. <em class="italics">Figure 13.19</em> shows a typical release pipeline for a container-based solution:</p>
			<div>
				<div id="_idContainer362" class="IMG---Figure">
					<img src="image/B15432_13_19.jpg" alt="A typical container-based release pipeline"/>
				</div>
			</div>
			<h6>Figure 13.19: Container-based release pipeline</h6>
			<p>The focus of the next section is integration with other toolsets, such as Jenkins.</p>
			<h2 id="_idParaDest-333"><a id="_idTextAnchor347"/>Azure DevOps and Jenkins</h2>
			<p>Azure DevOps is an open platform orchestrator that integrates with other orchestrator tools seamlessly. It provides all the necessary infrastructure and features that integrate well with Jenkins, as well. Organizations with well-established CI/CD pipelines built on Jenkins can reuse them with the advanced but simple features of Azure DevOps to orchestrate them.</p>
			<p>Jenkins can be used as a repository and can execute CI/CD pipelines in Azure DevOps, while it's also possible to have a repository in Azure DevOps and execute CI/CD pipelines in Jenkins.</p>
			<p>The Jenkins configuration can be added in Azure DevOps as service hooks, and whenever any code change is committed to the Azure DevOps repository, it can trigger pipelines in Jenkins. <em class="italics">Figure 13.20</em> shows the configuration of Jenkins from the Azure DevOps service hook configuration section:</p>
			<div>
				<div id="_idContainer363" class="IMG---Figure">
					<img src="image/B15432_13_20.jpg" alt="Jenkins configuration as service hooks in Azure DevOps"/>
				</div>
			</div>
			<h6>Figure 13.20: Configuration of Jenkins</h6>
			<p>There are multiple triggers that execute the pipelines in Jenkins; one of them is <strong class="bold">Code pushed</strong>, as shown in <em class="italics">Figure 13.21</em>:</p>
			<div>
				<div id="_idContainer364" class="IMG---Figure">
					<img src="image/B15432_13_21.jpg" alt="Executing a Jenkins pipeline through a code-pushed trigger"/>
				</div>
			</div>
			<h6>Figure 13.21: Code pushed trigger executed</h6>
			<p>It's also possible to deploy to Azure VM and execute Azure DevOps release pipelines, as explained here: <a href="https://docs.microsoft.com/azure/virtual-machines/linux/tutorial-build-deploy-jenkins">https://docs.microsoft.com/azure/virtual-machines/linux/tutorial-build-deploy-jenkins</a>.</p>
			<p>Jenkins should already be deployed before using it in any scenario. The deployment process on Linux can be found at <a href="https://docs.microsoft.com/azure/virtual-machines/linux/tutorial-jenkins-github-docker-cicd">https://docs.microsoft.com/azure/virtual-machines/linux/tutorial-jenkins-github-docker-cicd</a>.</p>
			<p>The next section will be more focused on tools and services related to configuration management. Azure automation provides DSC-related services such as the pull server.</p>
			<h2 id="_idParaDest-334"><a id="_idTextAnchor348"/>Azure Automation</h2>
			<p>Azure Automation is Microsoft's platform for all automation implementation with regard to cloud, on-premises, and hybrid deployments. Azure Automation is a mature automation platform that provides rich capabilities in terms of the following:</p>
			<ul>
				<li>Defining assets, such as variables, connections, credentials, certificates, and modules</li>
				<li>Implementing runbooks using Python, PowerShell scripts, and PowerShell workflows</li>
				<li>Providing UIs to create runbooks</li>
				<li>Managing the full runbook life cycle, including building, testing, and publishing</li>
				<li>Scheduling runbooks</li>
				<li>The ability to run runbooks anywhere—on cloud or on-premises</li>
				<li>DSC as a configuration-management platform</li>
				<li>Managing and configuring environments—Windows and Linux, applications, and deployment</li>
				<li>The ability to extend Azure Automation by importing custom modules</li>
			</ul>
			<p>Azure Automation provides a DSC pull server that helps to create a centralized configuration management server that consists of configurations for nodes/virtual machines and their constituents.</p>
			<p>It implements the hub and spoke pattern wherein nodes can connect to the DSC pull server and download configurations assigned to them, and reconfigure themselves to reflect their desired state. Any changes or deviations within these nodes are autocorrected by DSC agents the next time they run. This ensures that administrators don't need to actively monitor the environment to find any deviations.</p>
			<p>DSC provides a declarative language in which you define the intent and configuration, but not how to run and apply those configurations. These configurations are based on the PowerShell language and ease the process of configuration management.</p>
			<p>In this section, we'll look into a simple implementation of using Azure Automation DSC to configure a virtual machine to install and configure the web server (IIS) and create an <strong class="inline">index.htm</strong> file that informs users that the website is under maintenance.</p>
			<p>Next, you will learn how to provision an Azure Automation account.</p>
			<h3 id="_idParaDest-335"><a id="_idTextAnchor349"/>Provisioning an Azure Automation account</h3>
			<p>Create a new Azure Automation account from the Azure portal or PowerShell within an existing or new resource group. You may notice in <em class="italics">Figure 13.22</em> that Azure Automation provides menu items for DSC:</p>
			<div>
				<div id="_idContainer365" class="IMG---Figure">
					<img src="image/B15432_13_22.jpg" alt="The state configuration menu in Azure Automation"/>
				</div>
			</div>
			<h6>Figure 13.22: DSC in an Azure Automation account</h6>
			<p>It provides the following:</p>
			<ul>
				<li><strong class="bold">DSC nodes</strong>: These list all the virtual machines and containers that are enlisted with the current Azure Automation DSC pull server. These virtual machines and containers are managed using configurations from the current DSC pull server.</li>
				<li><strong class="bold">DSC configurations</strong>: These list all the raw PowerShell configurations imported and uploaded to the DSC pull server. They are in human-readable format and aren't in a compiled state.</li>
				<li><strong class="bold">DSC node configurations</strong>: These list all compiles of DSC configurations available on the pull server to be assigned to nodes—virtual machines and containers. A DSC configuration produces MOF files after compilations and they're eventually used to configure nodes.</li>
			</ul>
			<p>After provisioning an Azure Automation account, we can create a sample DSC configuration, as shown in the next section.</p>
			<h3 id="_idParaDest-336"><a id="_idTextAnchor350"/>Creating a DSC configuration</h3>
			<p>The next step is to write a DSC configuration using any PowerShell editor to reflect the intent of the configuration. For this sample, a single configuration, <strong class="inline">ConfigureSiteOnIIS</strong>, is created. It imports the base DSC module, <strong class="inline">PSDesiredStateConfiguration</strong>, which consists of resources used within the configuration. It also declares a node web server. When this configuration is uploaded and compiled, it will generate a DSC configuration named <strong class="inline">ConfigureSiteOnIISwebserver</strong>. This configuration can then be applied to nodes.</p>
			<p>The configuration consists of a few resources. These resources configure the target node. The resources install a web server, ASP.NET, and framework, and create an <strong class="inline">index.htm</strong> file within the <strong class="inline">inetpub\wwwroot</strong> directory with content to show that the site is under maintenance. For more information about writing DSC configuration, refer to <a href="https://docs.microsoft.com/powershell/scripting/dsc/getting-started/wingettingstarted?view=powershell-7">https://docs.microsoft.com/powershell/scripting/dsc/getting-started/wingettingstarted?view=powershell-7</a>.</p>
			<p>The next code listing shows the entire configuration described in the previous paragraph. This configuration will be uploaded to the Azure Automation account:</p>
			<p class="snippet">Configuration ConfigureSiteOnIIS {   </p>
			<p class="snippet">    Import-DscResource -ModuleName 'PSDesiredStateConfiguration'   </p>
			<p class="snippet">    Node WebServer {   </p>
			<p class="snippet">      WindowsFeature IIS  </p>
			<p class="snippet">        {  </p>
			<p class="snippet">            Name = "Web-Server"  </p>
			<p class="snippet">            Ensure = "Present"  </p>
			<p class="snippet">        }         </p>
			<p class="snippet">        WindowsFeature AspDotNet  </p>
			<p class="snippet">        {  </p>
			<p class="snippet">            Name = "net-framework-45-Core"  </p>
			<p class="snippet">            Ensure = "Present"  </p>
			<p class="snippet">            DependsOn = "[WindowsFeature]IIS"  </p>
			<p class="snippet">        }            </p>
			<p class="snippet">        WindowsFeature AspNet45  </p>
			<p class="snippet">        {  </p>
			<p class="snippet">            Ensure          = "Present"  </p>
			<p class="snippet">            Name            = "Web-Asp-Net45"  </p>
			<p class="snippet">            DependsOn = "[WindowsFeature]AspDotNet"  </p>
			<p class="snippet">        }   </p>
			<p class="snippet">        File IndexFile  </p>
			<p class="snippet">        {  </p>
			<p class="snippet">            DestinationPath = "C:\inetpub\wwwroot\index.htm"  </p>
			<p class="snippet">            Ensure = "Present"  </p>
			<p class="snippet">            Type = "File"  </p>
			<p class="snippet">            Force = $true  </p>
			<p class="snippet">            Contents = "&lt;HTML&gt;&lt;HEAD&gt;&lt;Title&gt; Website under construction.&lt;/Title&gt;&lt;/HEAD&gt;&lt;BODY&gt; '  </p>
			<p class="snippet">             &lt;h1&gt;If you are seeing this page, it means the website is under maintenance and DSC Rocks !!!!!&lt;/h1&gt;&lt;/BODY&gt;&lt;/HTML&gt;"  </p>
			<p class="snippet">        }  </p>
			<p class="snippet">   }  </p>
			<p class="snippet">}   </p>
			<p>After creating a sample DSC configuration, it should be imported within Azure Automation as shown in the next section.</p>
			<h3 id="_idParaDest-337"><a id="_idTextAnchor351"/>Importing the DSC configuration</h3>
			<p>The DSC configuration still isn't known to Azure Automation. It's available on some local machines. It should be uploaded to Azure Automation DSC configurations. Azure Automation provides the <strong class="inline">Import-AzureRMAutomationDscConfiguration</strong> cmdlet to import the configuration to Azure Automation:</p>
			<p class="snippet">Import-AzureRmAutomationDscConfiguration -SourcePath "C:\DSC\AA\DSCfiles\ConfigureSiteOnIIS.ps1" -ResourceGroupName "omsauto" -AutomationAccountName "datacenterautomation" -Published -Verbose     </p>
			<p>The commands will import the configuration within Azure Automation. After importing, the DSC configuration should be compiled so that it can be assigned to servers for compliance checks and autoremediation.</p>
			<h3 id="_idParaDest-338"><a id="_idTextAnchor352"/>Compiling the DSC configuration</h3>
			<p>After the DSC configuration is available in Azure Automation, it can be asked to compile. Azure Automation provides another cmdlet for this. Use the <strong class="inline">Start-AzureRmAutomationDscCompilationJob</strong> cmdlet to compile the imported configuration. The configuration name should match the name of the uploaded configuration. Compilation creates an MOF file named after the configuration and node name together, which in this case is the <strong class="inline">ConfigureSiteOnIIS</strong> web server. The execution of the command is shown here:</p>
			<p class="snippet">Start-AzureRmAutomationDscCompilationJob -ConfigurationName ConfigureSiteOnIIS -ResourceGroupName "omsauto" -AutomationAccountName "datacenterautomation" -Verbose      </p>
			<p>Now you have accomplished DSC node configuration. In the next section, you will learn to assign configurations to nodes. </p>
			<h3 id="_idParaDest-339"><a id="_idTextAnchor353"/>Assigning configurations to nodes</h3>
			<p>The compiled DSC configurations can be applied to nodes. Use <strong class="inline">Register-AzureRmAutomationDscNode</strong> to assign the configuration to a node. The <strong class="inline">NodeConfigurationName</strong> parameter identifies the configuration name that should be applied to the node. This is a powerful cmdlet that can also configure the DSC agent, which is <strong class="inline">localconfigurationmanager</strong>, on nodes before they can download configurations and apply them. There are multiple <strong class="inline">localconfigurationmanager</strong> parameters that can be configured—details are available at <a href="https://devblogs.microsoft.com/powershell/understanding-meta-configuration-in-windows-powershell-desired-state-configuration">https://devblogs.microsoft.com/powershell/understanding-meta-configuration-in-windows-powershell-desired-state-configuration</a>.</p>
			<p>Let's heck out the configuration below:</p>
			<p class="snippet">Register-AzureRmAutomationDscNode -ResourceGroupName "omsauto" -AutomationAccountName "datacenterautomation" -AzureVMName testtwo -ConfigurationMode ApplyAndAutocorrect -ActionAfterReboot ContinueConfiguration -AllowModuleOverwrite $true -AzureVMResourceGroup testone -AzureVMLocation "West Central US" -NodeConfigurationName "ConfigureSiteOnIIS.WebServer" -Verbose </p>
			<p>Now, we can test whether the configuration has been applied to the servers by browsing the newly deployed website using a browser. After the testing has completed successfully, let's move on to validating the connections.</p>
			<h3 id="_idParaDest-340"><a id="_idTextAnchor354"/>Validation</h3>
			<p>If appropriate, network security groups and firewalls are opened and enabled for port 80, and a public IP is assigned to the virtual machine. The default website can be browsed using the IP address. Otherwise, log into the virtual machine that's used to apply the DSC configuration and navigate to <strong class="inline">http://localhost</strong>.</p>
			<p>It should show the following page:</p>
			<div>
				<div id="_idContainer366" class="IMG---Figure">
					<img src="image/B15432_13_23.jpg" alt="Validating the connection through Localhost"/>
				</div>
			</div>
			<h6>Figure 13.23: Localhost</h6>
			<p>This is the power of configuration management: without writing any significant code, authoring a configuration once can be applied multiple times to the same and multiple servers, and you can be assured that they will run in the desired state without any manual intervention. In the next section, we will check out the various tools available for Azure DevOps. </p>
			<h2 id="_idParaDest-341"><a id="_idTextAnchor355"/>Tools for DevOps</h2>
			<p>As mentioned before, Azure is a rich and mature platform that supports the following:</p>
			<ul>
				<li>Multiple choices of languages</li>
				<li>Multiple choices of operating systems</li>
				<li>Multiple choices of tools and utilities</li>
				<li>Multiple patterns for deploying solutions (such as virtual machines, app services, containers, and microservices)</li>
			</ul>
			<p>With so many options and choices, Azure offers the following:</p>
			<ul>
				<li><strong class="bold">Open cloud</strong>: It is open to open source, Microsoft, and non-Microsoft products, tools, and services.</li>
				<li><strong class="bold">Flexible cloud</strong>: It is easy enough for both end users and developers to use it with their existing skills and knowledge.</li>
				<li><strong class="bold">Unified management</strong>: It provides seamless monitoring and management features.</li>
			</ul>
			<p>All the services and capabilities mentioned here are important for the successful implementation of DevOps. <em class="italics">Figure 13.24</em> shows the open source tools and utilities that can be used for different phases of managing the application life cycle and DevOps in general:</p>
			<div>
				<div id="_idContainer367" class="IMG---Figure">
					<img src="image/B15432_13_24.jpg" alt="Open source tools and utilities for managing the application lifecycle"/>
				</div>
			</div>
			<h6>Figure 13.24: Open source tools and utilities</h6>
			<p><em class="italics">Figure 13.24</em> shows the Microsoft tools and utilities that can be used for different phases of managing the application life cycle and DevOps in general. Again, this is just a small representation of all the tools and utilities—there are many more options available, such as the following:</p>
			<ul>
				<li>Azure DevOps build orchestration for constructing a build pipeline</li>
				<li>Microsoft Test Manager and Pester for testing</li>
				<li>DSC, PowerShell, and ARM templates for deployment or configuration management</li>
				<li>Log Analytics, Application Insights, and <strong class="bold">System Center Operations Manager</strong> (<strong class="bold">SCOM</strong>) for alerting and monitoring</li>
				<li>Azure DevOps and System Center Service Manager for managing processes:</li>
			</ul>
			<div>
				<div id="_idContainer368" class="IMG---Figure">
					<img src="image/B15432_13_25.jpg" alt="Microsoft tools and utilities for managing the application lifecycle"/>
				</div>
			</div>
			<h6>Figure 13.25: Microsoft tools and utilities</h6>
			<p>There are many tools available for each of the DevOps practices and in this section, you saw some of the tools and the way to configure them.</p>
			<h2 id="_idParaDest-342"><a id="_idTextAnchor356"/>Summary</h2>
			<p>DevOps is gaining a lot of traction and momentum in the industry. Most organizations have realized its benefits and are looking to implement DevOps. This is happening while most of them are moving to the cloud. Azure, as a cloud platform, provides rich and mature DevOps services, making it easy for organizations to implement DevOps. </p>
			<p>In this chapter, we discussed DevOps along with its core practices, such as configuration management, continuous integration, continuous delivery, and deployment. We also discussed different cloud solutions based on PaaS, a virtual machine IaaS, and a container IaaS, along with their respective Azure resources, the build and release pipelines. </p>
			<p>Configuration management was also explained in the chapter, along with DSC services from Azure Automation and using pull servers to configure virtual machines automatically. Finally, we covered Azure's openness and flexibility regarding the choice of languages, tools, and operating systems. </p>
			<p>In the next chapter, we will go through the details of Kubernetes and its components and interactions, in addition to application design and deployment considerations on Kubernetes.</p>
		</div>
	</body></html>