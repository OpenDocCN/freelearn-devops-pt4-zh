- en: 14\. Architecting Azure Kubernetes solutions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14. 设计 Azure Kubernetes 解决方案
- en: Containers are one of the most talked-about infrastructure components of the
    last decade. Containers are not a new technology; they have been around for quite
    some time. They have been prevalent in the Linux world for more than two decades.
    Containers were not well known in the developer community due to their complexity
    and the fact that there was not much documentation regarding them. However, around
    the beginning of this decade, in 2013, a company was launched known as Docker
    that changed the perception and adoption of containers within the developer world.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 容器是过去十年中最受讨论的基础设施组件之一。容器并不是新技术，它们已经存在了一段时间。它们在 Linux 世界中已经流行了超过二十年。由于其复杂性以及相关文档的匮乏，容器曾在开发者社区中不太为人知。然而，在本世纪初，即2013年，一家名为
    Docker 的公司推出了改变开发者世界对容器认知和采纳的局面。
- en: Docker wrote a robust API wrapper on top of existing Linux LXC containers and
    made it easy for developers to create, manage, and destroy containers from the
    command-line interface. When containerizing applications, the number of containers
    we have can increase drastically over time, and we can reach a point where we
    need to manage hundreds or even thousands of containers. This is where container
    orchestrators play a role, and Kubernetes is one of them. Using Kubernetes, we
    can automate the deployment, scaling, networking, and management of containers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 在现有的 Linux LXC 容器之上编写了一个强大的 API 封装，简化了开发者从命令行界面创建、管理和销毁容器的过程。当容器化应用时，容器的数量会随着时间大幅增加，可能达到需要管理数百个甚至数千个容器的程度。这时，容器编排工具就发挥了作用，而
    Kubernetes 就是其中之一。使用 Kubernetes，我们可以自动化容器的部署、扩展、网络配置和管理。
- en: 'In this chapter, we will look at:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将讨论：
- en: The introductory concepts of containers
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器的基本概念
- en: The concepts of Kubernetes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 的概念
- en: The important elements that make Kubernetes work
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使 Kubernetes 能够正常工作的关键要素
- en: Architecting solutions using Azure Kubernetes Service
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Azure Kubernetes 服务构建解决方案
- en: Now that you know what Kubernetes is used for, let's start from scratch and
    discuss what containers are, how they are orchestrated using Kubernetes, and more.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道 Kubernetes 的用途，我们从头开始讨论容器是什么，如何使用 Kubernetes 对它们进行编排等内容。
- en: Introduction to containers
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器简介
- en: Containers are referred to as operating system–level virtualization systems.
    They are hosted on an operating system running either on a physical server or
    a virtual server. The nature of the implementation depends on the host operating
    system. For example, Linux containers are inspired by cgroups; on the other hand,
    Windows containers are almost lightweight virtual machines with a small footprint.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 容器被称为操作系统级虚拟化系统。它们托管在运行于物理服务器或虚拟服务器上的操作系统中。实现的性质取决于宿主操作系统。例如，Linux 容器受 cgroups
    启发；而 Windows 容器几乎是轻量级虚拟机，具有小巧的占用空间。
- en: Containers are truly cross-platform. Containerized applications can run on any
    platform, such as Linux, Windows, or Mac, uniformly without any changes being
    needed, which makes them highly portable. This makes them a perfect technology
    for organizations to adopt as they are platform-agnostic.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 容器真正实现了跨平台。容器化应用可以在任何平台上运行，如 Linux、Windows 或 Mac，且无需任何修改，这使得它们具有高度的可移植性。这使得它们成为组织采用的完美技术，因为它们与平台无关。
- en: In addition, containers can run in any cloud environment or on-premises environment
    without changes being needed. This means that organizations are also not tied
    to a single cloud provider if they implement containers as their hosting platform
    on the cloud. They can move their environment from on-premises and lift and shift
    to the cloud.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，容器可以在任何云环境或本地环境中运行，无需修改。这意味着如果组织将容器作为其云托管平台，它们也不会被束缚于单一云提供商。它们可以将环境从本地迁移并直接迁移到云端。
- en: Containers provide all the benefits that are typically available with virtual
    machines. They have their own IP addresses, DNS names, identities, networking
    stacks, filesystems, and other components that give users the impression of using
    a pristine new operating system environment. Under the hood, the Docker runtime
    virtualizes multiple operating system kernel–level components to provide that
    impression.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 容器提供了虚拟机通常具备的所有优势。它们有自己的 IP 地址、DNS 名称、身份、网络堆栈、文件系统以及其他组件，这些都使得用户有使用全新操作系统环境的错觉。在后台，Docker
    运行时通过虚拟化多个操作系统内核级别的组件来提供这种错觉。
- en: All these benefits provide immense benefits for organizations adopting container
    technology, and Docker is one of the forerunners in this regard. There are other
    container runtime options available, such as CoreOS Rkt (pronounced as Rocket,
    out of production), Mesos Containerizer, and LXC containers. Organizations can
    adopt the technology that they feel comfortable with.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些优势为采用容器技术的组织提供了巨大的好处，而 Docker 在这方面是先行者之一。还有其他容器运行时选项可供选择，如 CoreOS Rkt（发音为
    Rocket，已停产）、Mesos Containerizer 和 LXC 容器。组织可以选择他们感到舒适的技术。
- en: Containers were previously not available in the Windows world, only becoming
    available for Windows 10 and Windows Server 2016\. However, containers are now
    first-class citizens in the Windows world.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 容器在 Windows 系统中之前是不可用的，仅在 Windows 10 和 Windows Server 2016 中才开始支持。然而，现在容器已经成为
    Windows 系统中的一等公民。
- en: As mentioned in the introduction, containers should be monitored, governed,
    and managed well, just like any other infrastructural component within an ecosystem.
    It's necessary to deploy an orchestrator, such as Kubernetes, that can help you
    to do so easily. In the next section, you will learn about the fundamentals of
    Kubernetes, including what its advantages are.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如介绍中所述，容器应像生态系统中的任何其他基础设施组件一样，进行监控、治理和管理。必须部署一个编排工具，如 Kubernetes，帮助你轻松实现这一点。在接下来的章节中，你将了解
    Kubernetes 的基础知识，包括它的优势。
- en: Kubernetes fundamentals
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 基础知识
- en: Many organizations still ask, "*Do we need Kubernetes, or indeed any container
    orchestrator?*" When we think about container management on a large scale, we
    need to think about several points, such as scaling, load balancing, life cycle
    management, continuous delivery, logging and monitoring, and more.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 许多组织仍然问，“*我们需要 Kubernetes，还是需要任何容器编排工具？*” 当我们考虑大规模容器管理时，我们需要考虑多个方面，比如扩展、负载均衡、生命周期管理、持续交付、日志记录和监控等。
- en: You might ask, "*Aren't containers supposed to do all that?*" The answer is
    that containers are only a low-level piece of the puzzle. The real benefits are
    gained through the tools that sit on top of the containers. At the end of the
    day, we need something to help us with orchestration.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，“*容器不应该完成这些工作吗？*” 答案是，容器只是这一拼图的低级组成部分。真正的好处是通过那些位于容器之上的工具获得的。最终，我们需要一些工具来帮助我们进行编排。
- en: Kubernetes is a Greek word, κυβερνήτης, which means "helmsman" or "captain of
    the ship." Keeping the maritime theme of Docker containers, Kubernetes is the
    captain of the ship. Kubernetes is often denoted as K8s, where 8 represents the
    eight letters between "K" and "s" in the word "Kubernetes."
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个希腊词，κυβερνήτης，意思是“舵手”或“船长”。延续 Docker 容器的海洋主题，Kubernetes 就是这艘船的船长。Kubernetes
    通常缩写为 K8s，其中 8 代表单词 "Kubernetes" 中 "K" 和 "s" 之间的八个字母。
- en: As mentioned before, containers are more agile than virtual machines. They can
    be created within seconds and destroyed equally quickly. They have a similar life
    cycle to virtual machines; however, they need to be monitored, governed, and managed
    actively within an environment.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，容器比虚拟机更具灵活性。它们可以在几秒钟内创建，并且同样可以快速销毁。它们的生命周期与虚拟机类似；然而，它们需要在环境中主动进行监控、治理和管理。
- en: 'It is possible to manage them using your existing toolset; even so, specialized
    tools, such as Kubernetes, can provide valuable benefits:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用你现有的工具集来管理容器是可行的；尽管如此，像 Kubernetes 这样的专用工具能够提供宝贵的好处：
- en: Kubernetes is self-healing in nature. When a Pod (read as "container" for now)
    goes down within a Kubernetes environment, Kubernetes will ensure that a new Pod
    is created elsewhere either on the same node or on another node, to respond to
    requests on behalf of the application.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 本质上是自愈的。当 Kubernetes 环境中的一个 Pod（现在可以理解为“容器”）故障时，Kubernetes 会确保在同一节点或另一个节点上创建一个新的
    Pod 来响应应用程序的请求。
- en: Kubernetes also eases the process of upgrading an application. It provides out-of-the-box
    features to help you perform multiple types of upgrades with the original configuration.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 还简化了应用程序升级的过程。它提供了开箱即用的功能，帮助你在保留原始配置的情况下执行多种类型的升级。
- en: It helps to enable blue-green deployments. In this type of deployment, Kubernetes
    will deploy the new version of the application alongside the old one, and once
    it is confirmed that the new application works as expected, a DNS switch will
    be made to switch to the new version of the application. The old application deployment
    can continue to exist for rollback purposes.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它有助于实现蓝绿部署。在这种部署方式中，Kubernetes 会将新版本的应用程序与旧版本一起部署，一旦确认新应用程序按预期工作，就会进行 DNS 切换，切换到新版本的应用程序。旧的应用程序部署可以继续存在，以便回滚使用。
- en: Kubernetes also helps to implement a rolling-upgrade deployment strategy. Here,
    Kubernetes will deploy the new version of the application one server at a time,
    and tear down the old deployment one server at a time. It will carry on this activity
    until there are no more servers left from the old deployment.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 还帮助实施滚动升级部署策略。在这种策略中，Kubernetes 会逐个服务器地部署新版本的应用程序，并逐个服务器地拆除旧版本部署。它会一直执行此操作，直到旧版本的部署没有服务器为止。
- en: Kubernetes can be deployed on an on-premises data center or on the cloud using
    the **infrastructure as a service** (**IaaS**) paradigm. This means that developers
    first create a group of virtual machines and deploy Kubernetes on top of it. There
    is also the alternative approach of using Kubernetes as a **platform as a service**
    (**PaaS**) offering. Azure provides a PaaS service known as **Azure Kubernetes
    Service** (**AKS**), which provides an out-of-the-box Kubernetes environment to
    developers.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 可以通过 **基础设施即服务**（**IaaS**）模式在本地数据中心或云上进行部署。这意味着开发人员首先创建一组虚拟机并在其上部署
    Kubernetes。还有一种替代方法是将 Kubernetes 用作 **平台即服务**（**PaaS**）提供。Azure 提供了一项名为 **Azure
    Kubernetes 服务**（**AKS**）的 PaaS 服务，提供了一个开箱即用的 Kubernetes 环境，供开发人员使用。
- en: 'When it comes to Deployment, Kubernetes can be deployed in two ways:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署方面，Kubernetes 可以通过两种方式进行部署：
- en: '**Unmanaged clusters**: Unmanaged clusters can be created by installing Kubernetes
    and any other relevant packages on a bare–metal machine or a virtual machine.
    In an unmanaged cluster, there will be master and worker nodes, formerly known
    as minions. The master and worker nodes work hand–in–hand to orchestrate the containers.
    If you are wondering how this is achieved, later in this chapter, we will be exploring
    the complete architecture of Kubernetes. Right now, just know that there are master
    and worker nodes.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非托管集群**：非托管集群可以通过在裸机或虚拟机上安装 Kubernetes 及其他相关软件包来创建。在非托管集群中，将有主节点和工作节点，前身叫做从节点。主节点和工作节点共同协作管理容器。如果你想知道这是如何实现的，接下来我们将在本章中探索
    Kubernetes 的完整架构。现在，你只需要知道有主节点和工作节点即可。'
- en: '**Managed clusters**: Managed clusters are normally provided by the cloud provider;
    the cloud provider manages the infrastructure for you. In Azure, this service
    is called AKS. Azure will provide active support regarding patching and managing
    the infrastructure. With IaaS, organizations have to ensure the availability and
    scalability of the nodes and the infrastructure on their own. In the case of AKS,
    the master component will not be visible as it is managed by Azure. However, the
    worker nodes (minions) will be visible and will be deployed to a separate resource
    group, so you can access the nodes if needed.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**托管集群**：托管集群通常由云服务提供商提供；云服务提供商为你管理基础设施。在 Azure 中，这项服务被称为 AKS。Azure 将提供关于补丁和基础设施管理的主动支持。使用
    IaaS 时，组织必须自行确保节点和基础设施的可用性和可扩展性。在 AKS 中，主组件不可见，因为它由 Azure 管理。然而，工作节点（从节点）是可见的，并且会被部署到单独的资源组中，因此你可以在需要时访问这些节点。'
- en: 'Some of the key benefits of using AKS over unmanaged clusters are:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 AKS 而不是非托管集群的一些关键好处包括：
- en: If you are using unmanaged clusters, you need to work to make the solution highly
    available and scalable. In addition to that, you need to have proper update management
    in place to install updates and patches. On the other hand, in AKS, Azure manages
    this completely, enabling developers to save time and be more productive.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你使用的是非托管集群，你需要努力使解决方案具有高可用性和可扩展性。除此之外，你还需要有合适的更新管理机制来安装更新和补丁。另一方面，在 AKS 中，Azure
    完全管理这一切，使得开发人员可以节省时间，更加高效。
- en: Native integration with other services, such as Azure Container Registry to
    store your container images securely, Azure DevOps to integrate CI/CD pipelines,
    Azure Monitor for logging, and Azure Active Directory for security.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他服务的原生集成，例如 Azure 容器注册表用于安全存储容器镜像，Azure DevOps 用于集成 CI/CD 管道，Azure Monitor
    用于日志记录，Azure Active Directory 用于安全性。
- en: Scalability and faster startup speed.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展性和更快的启动速度。
- en: Support for virtual machine scale sets.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持虚拟机规模集。
- en: While there is no difference in terms of the basic functionality of these two
    deployments, the IaaS form of deployment provides the flexibility to add new plugins
    and configuration immediately that might take some time for the Azure team to
    make available with AKS. Also, newer versions of Kubernetes are available within
    AKS quite quickly, without much delay.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这两种部署方式在基本功能上没有差异，但 IaaS 部署形式提供了灵活性，可以立即添加新的插件和配置，而这可能需要 Azure 团队在 AKS 中推出一段时间才能实现。此外，Kubernetes
    的新版本在 AKS 中发布也相对迅速，几乎没有延迟。
- en: We have covered the basics of Kubernetes. At this point, you might be wondering
    how Kubernetes achieves all this. In the next section, we will be looking at the
    components of Kubernetes and how they work hand–in–hand.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经涵盖了 Kubernetes 的基础内容。此时，您可能会想，Kubernetes 是如何实现这一切的。在接下来的章节中，我们将探讨 Kubernetes
    的组件以及它们是如何协同工作的。
- en: Kubernetes architecture
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 架构
- en: The first step in understanding Kubernetes is understanding its architecture.
    We will go into the details of each component in the next section, but getting
    a high-level overview of the architecture will help you to understand the interaction
    between the components.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 的第一步是了解它的架构。我们将在下一节详细讲解每个组件，但先了解架构的高级概览将有助于您理解各个组件之间的互动。
- en: Kubernetes clusters
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes 集群
- en: 'Kubernetes needs physical or virtual nodes for installing two types of components:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 需要物理或虚拟节点来安装两种类型的组件：
- en: Kubernetes control plane components, or master components
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 控制平面组件，或主控组件
- en: Kubernetes worker nodes (minions), or non-master components
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 工作节点（从属节点），或非主控组件
- en: '*Figure 14.1* is a diagram that offers a high-level overview of Kubernetes''
    architecture. We will get into the components in more detail later on:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 14.1* 是一个提供 Kubernetes 架构高级概览的图表。稍后我们将详细介绍各个组件：'
- en: '![A block diagram giving an overview of the Kubernetes cluster and showing
    the relationship between the Kubernetes Master, Nodes, and Pods.](img/B15432_14_01.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![一个方块图，概述了 Kubernetes 集群，并展示了 Kubernetes Master、节点和 Pod 之间的关系。](img/B15432_14_01.jpg)'
- en: 'Figure 14.1: Kubernetes cluster overview'
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.1：Kubernetes 集群概览
- en: The control plane components are responsible for managing and governing the
    Kubernetes environment and Kubernetes minions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 控制平面组件负责管理和治理 Kubernetes 环境以及 Kubernetes 从属节点。
- en: All nodes together—the master as well as the minions—form the cluster. A cluster,
    in other words, is a collection of nodes. They are virtual or physical, connected
    to each other, and reachable using the TCP networking stack. The outside world
    will have no clue about the size or capability of your cluster, or even the names
    of the worker nodes. The only thing the nodes are aware of is the address of the
    API server through which they interact with the cluster. For them, the cluster
    is one large computer that runs their applications.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 所有节点——包括主控节点和从属节点——共同构成了集群。换句话说，集群是节点的集合。它们可以是虚拟的或物理的，彼此连接，并通过 TCP 网络栈相互访问。外部世界无法得知您的集群的大小、能力，甚至工作节点的名称。节点唯一知道的是与集群互动的
    API 服务器的地址。对它们来说，集群就是运行其应用程序的一台大计算机。
- en: It is Kubernetes that internally decides an appropriate strategy, using controllers,
    to choose a valid, healthy node that can run the application smoothly.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 正是 Kubernetes 内部决定了一个合适的策略，通过控制器来选择一个有效、健康的节点，以便平稳地运行应用程序。
- en: The control plane components can be installed in a high-availability configuration.
    So far, we have discussed clusters and how they work. In the next section, we
    will be taking a look at the components of a cluster.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 控制平面组件可以安装在高可用配置中。到目前为止，我们已经讨论了集群及其工作原理。在接下来的章节中，我们将深入了解集群的组件。
- en: Kubernetes components
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes 组件
- en: 'Kubernetes components are divided into two categories: master components and
    node components. The master components are also known as the control plane of
    the cluster. The control plane is responsible for managing the worker nodes and
    the Pods in the cluster. The decision-making authority of a cluster is the control
    plane, and it also takes care of detection and responses related to cluster events.
    *Figure 14.2* describes the complete architecture of a Kubernetes cluster:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 组件分为两类：主组件和节点组件。主组件也被称为集群的控制平面。控制平面负责管理集群中的工作节点和 Pod。集群的决策权由控制平面掌控，它还负责集群事件的检测和响应。*图
    14.2* 描述了 Kubernetes 集群的完整架构：
- en: '![The Kubernetes architecture showing the connection between the Master components
    and the Node components, where the Master components consist of the Master Node
    while the Node components consist of the Worker nodes.](img/B15432_14_02.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![展示 Kubernetes 架构的图，显示主组件和节点组件之间的连接，其中主组件由主节点组成，而节点组件由工作节点组成](img/B15432_14_02.jpg)'
- en: 'Figure 14.2: Kubernetes architecture'
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.2：Kubernetes 架构
- en: 'You need to understand each of these components to administer a cluster correctly.
    Let''s go ahead and discuss what the master components are:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要理解每一个组件，才能正确地管理一个集群。接下来，让我们讨论一下主组件：
- en: '**API server**: The API server is undoubtedly the brain of Kubernetes. It is
    the central component that enables all activities within Kubernetes. Every client
    request, with few exceptions, ends up with the API server, which decides the flow
    for the request. It is solely responsible for interacting with the etcd server.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API 服务器**：API 服务器无疑是 Kubernetes 的大脑。它是启用 Kubernetes 内部所有活动的核心组件。每个客户端请求（少数例外）最终都会由
    API 服务器处理，API 服务器决定请求的流向。它唯一负责与 etcd 服务器进行交互。'
- en: '**etcd**: etcd is the data store for Kubernetes. Only the API server is allowed
    to communicate with etcd, and the API server can perform **Create**, **Read**,
    **Update** and **Delete** (**CRUD**) activities on etcd. When a request ends up
    with the API server, after validation, the API server can perform any CRUD operations,
    depending on the etcd request. etcd is a distributed, highly available data store.
    There can be multiple installations of etcd, each with a copy of the data, and
    any of them can serve the requests from the API server. In *Figure 14.3*, you
    can see that there are multiple instances running in the control plane to provide
    high availability:![A block diagram showing how the load balancer works with the
    worker nodes, and the control plane nodes to improve the availability.](img/B15432_14_03.jpg)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**etcd**：etcd 是 Kubernetes 的数据存储。只有 API 服务器被允许与 etcd 进行通信，API 服务器可以对 etcd 执行
    **创建**、**读取**、**更新** 和 **删除**（**CRUD**）操作。当请求最终到达 API 服务器时，经过验证后，API 服务器可以根据 etcd
    请求执行任何 CRUD 操作。etcd 是一个分布式、高可用的数据存储。可以有多个 etcd 实例，每个实例都有一份数据副本，它们中的任何一个都可以为 API
    服务器的请求提供服务。在 *图 14.3* 中，你可以看到在控制平面中运行多个实例来提供高可用性：![展示负载均衡器如何与工作节点和控制平面节点一起提高可用性的框图](img/B15432_14_03.jpg)'
- en: 'Figure 14.3: Making the control plane highly available'
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.3：使控制平面高度可用
- en: '**Controller manager**: The controller manager is the workhorse of Kubernetes.
    While the API server receives the requests, the actual work in Kubernetes is done
    by the controller manager. The controller manager, as the name suggests, is the
    manager of the controllers. There are multiple controllers in a Kubernetes master
    node, and each is responsible for managing a single controller.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制器管理器**：控制器管理器是 Kubernetes 的工作马车。API 服务器接收请求时，Kubernetes 中的实际工作由控制器管理器完成。顾名思义，控制器管理器是控制器的管理者。Kubernetes
    主节点中有多个控制器，每个控制器负责管理一个单一的资源。'
- en: The main responsibility of a controller is managing a single resource in a Kubernetes
    environment. For example, there is a replication controller manager for managing
    replication controller resources, and a ReplicaSet controller to manage ReplicaSets
    in a Kubernetes environment. The controller keeps a watch on the API server, and
    when it receives a request for a resource managed by it, the controller performs
    its job.
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 控制器的主要职责是管理 Kubernetes 环境中的单一资源。例如，有一个用于管理副本控制器资源的副本控制器管理器，以及一个用于管理 Kubernetes
    环境中 ReplicaSets 的 ReplicaSet 控制器。控制器监控 API 服务器，当它收到一个请求来管理某个资源时，控制器就会执行相应的操作。
- en: One of the main responsibilities of controllers is to keep running in a loop
    and ensure that Kubernetes is in the desired state. If there is any deviation
    from the desired state, the controllers should bring it back to the desired state.
    A deployment controller watches for any new deployment resources created by the
    API server. If a new deployment resource is found, the deployment controller creates
    a new ReplicaSet resource and ensures that the ReplicaSet is always in the desired
    state. A replication controller keeps running in a loop and checks whether the
    actual number of Pods in the environment matches the desired number of Pods. If
    a Pod dies for any reason, the replication controller will find that the actual
    count has gone down by one and it will schedule a new Pod in the same or another
    node.
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 控制器的主要职责之一是保持循环运行，并确保 Kubernetes 处于所需状态。如果与所需状态出现任何偏差，控制器应该将其恢复到所需状态。部署控制器监视
    API 服务器创建的任何新的部署资源。如果发现新的部署资源，部署控制器将创建一个新的 ReplicaSet 资源，并确保 ReplicaSet 始终处于所需状态。复制控制器会一直运行，并检查环境中实际的
    Pods 数量是否与所需的 Pods 数量匹配。如果某个 Pod 因为某种原因死亡，复制控制器会发现实际数量减少了一个，并会在相同或其他节点上调度一个新的
    Pod。
- en: '**Scheduler**: The job of a scheduler is to schedule the Pods on Kubernetes
    minion nodes. It is not responsible for creating Pods. It is purely responsible
    for assigning Pods to Kubernetes minion nodes. It does so by taking into account
    the current state of nodes, how busy they are, their available resources, and
    also the definition of the Pod. A Pod might have a preference regarding a specific
    node, and the scheduler will keep these requests in consideration while scheduling
    Pods to nodes.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调度器**：调度器的工作是将 Pods 调度到 Kubernetes 工作节点上。它不负责创建 Pods，仅负责将 Pods 分配到 Kubernetes
    工作节点。它会根据节点的当前状态、节点的繁忙程度、可用资源以及 Pod 的定义来进行调度。Pod 可能会对特定节点有偏好，调度器在将 Pods 调度到节点时会考虑这些请求。'
- en: 'We will now explore the node components that are deployed in each of the worker
    nodes in the cluster:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将探索在集群中每个工作节点上部署的节点组件：
- en: '**Kubelet**: While the API server, scheduler, controllers, and etcd are deployed
    on master nodes, kubelets are deployed on minion nodes. They act as agents for
    the Kubernetes master components and are responsible for managing Pods locally
    on the nodes. There is one kubelet on each node. A kubelet takes commands from
    the master components and also provides health, monitoring, and update information
    about nodes and Pods to the master components, such as the API server and the
    controller manager. They are the conduit for administrative communication between
    the master and minion nodes.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubelet**：API 服务器、调度器、控制器和 etcd 部署在主节点上，而 kubelet 部署在工作节点上。它们充当 Kubernetes
    主组件的代理，并负责在节点上本地管理 Pods。每个节点上都有一个 kubelet。kubelet 接收来自主组件的命令，同时还向主组件（如 API 服务器和控制器管理器）提供有关节点和
    Pods 的健康状况、监控信息和更新信息。它们是主节点与工作节点之间管理通信的中介。'
- en: '**kube-proxy**: kube-proxy, just like kubelets, is deployed on minion nodes.
    It is responsible for monitoring Pods and Services, as well as updating the local
    iptables and netfilter firewall rules with any change in the availability of Pods
    and Services. This ensures that the routing information on nodes is updated as
    and when new Pods and Services are created or existing Pods and Services are deleted.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kube-proxy**：kube-proxy 就像 kubelet 一样，部署在工作节点上。它负责监控 Pods 和 Services，并在 Pods
    和 Services 的可用性发生变化时更新本地的 iptables 和 netfilter 防火墙规则。这确保了节点上的路由信息在创建新的 Pods 和
    Services 或删除现有 Pods 和 Services 时能够及时更新。'
- en: '**Container runtime**: There are many container vendors and providers in the
    ecosystem today. Docker is the most famous of them all, though others are also
    gaining popularity. That''s why, in our architecture, we denoted the container
    runtime with the Docker logo. Kubernetes is a generic container orchestrator.
    It cannot be tightly coupled with any single container vendor, such as Docker.
    It should be possible to use any container runtime on the minion nodes to manage
    the life cycle of containers.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容器运行时**：如今，生态系统中有许多容器供应商和提供商。Docker 是其中最著名的，尽管其他容器运行时也在逐渐获得人气。因此，在我们的架构中，我们用
    Docker 的标志来表示容器运行时。Kubernetes 是一个通用的容器调度器，它不能与任何单一的容器供应商（如 Docker）紧密耦合。它应该能够在工作节点上使用任何容器运行时来管理容器的生命周期。'
- en: To run containers in Pods, an industry-based standard known as a **container
    runtime interface** (**CRI**) has been developed and is used by all leading companies.
    The standard provides rules that should be followed to achieve interoperability
    with orchestrators such as Kubernetes. Kubelets do not know which container binaries
    are installed on the nodes. They could be Docker binaries or any other binaries.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在 Pod 中运行容器，已经开发了一种基于行业标准的 **容器运行时接口** (**CRI**)，并被所有领先公司使用。该标准提供了与 Kubernetes
    等调度器互操作时应遵循的规则。Kubelet 不知道节点上安装了哪些容器二进制文件。它们可以是 Docker 二进制文件，也可以是任何其他二进制文件。
- en: As these container runtimes are developed with a common industry-based standard,
    irrespective of which runtime you are using, kubelets will be able to communicate
    with the container runtime. This decouples container management from Kubernetes
    cluster management. The responsibilities of the container runtime include the
    creation of containers, managing the networking stack of the containers, and managing
    the bridge network. Since the container management is separate from the cluster
    management, Kubernetes will not interfere in the responsibilities of the container
    runtime.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些容器运行时是基于行业标准开发的，无论你使用的是哪种运行时，kubelet 都能与容器运行时进行通信。这将容器管理与 Kubernetes 集群管理解耦。容器运行时的职责包括创建容器、管理容器的网络栈以及管理桥接网络。由于容器管理与集群管理是分离的，Kubernetes
    不会干扰容器运行时的职责。
- en: The components we discussed are applicable to both unmanaged as well as managed
    AKS clusters. However, the master components are not exposed to the end user,
    as Azure manages all that in the case of AKS. Later in this chapter, we will cover
    the architecture of AKS. You will learn about unmanaged clusters and come to understand
    the differences between these systems more clearly.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论的组件适用于无管理的集群以及 AKS 管理的集群。然而，主组件不会暴露给最终用户，因为在 AKS 的情况下，Azure 会管理所有这些内容。本章稍后将介绍
    AKS 的架构。你将了解无管理集群，并更清晰地理解这些系统之间的区别。
- en: Next, you will learn about some of the most important Kubernetes resources,
    also known as the primitives, knowledge that is applicable to both unmanaged and
    AKS clusters.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将学习一些最重要的 Kubernetes 资源，也称为原语，这些知识适用于无管理的集群和 AKS 集群。
- en: Kubernetes primitives
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 原语
- en: You have learned that Kubernetes is an orchestration system used to deploy and
    manage containers. Kubernetes defines a set of building blocks, which are also
    known as primitives. These primitives together can help us to deploy, maintain,
    and scale containerized applications. Let's take a look at each of the primitives
    and understand their roles.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经了解 Kubernetes 是一个用于部署和管理容器的调度系统。Kubernetes 定义了一组构建块，也称为原语。这些原语一起可以帮助我们部署、维护和扩展容器化应用程序。让我们逐一了解这些原语及其角色。
- en: Pod
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pod
- en: Pods are the most basic unit of Deployment in Kubernetes. The immediate question
    that arises to a curious mind is how is a Pod different to a container? Pods are
    wrappers on top of containers. In other words, containers are contained within
    Pods. There can be multiple containers within a Pod; however, best practice is
    to have a one-Pod-one-container relationship. This does not mean we cannot have
    more than one container in a Pod. Multiple containers in a Pod is also fine, as
    long as there is one main container and the rest are ancillary containers. There
    are also patterns, such as sidecar patterns, that can be implemented with multi-container
    Pods.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 是 Kubernetes 中最基本的部署单元。一个好奇的心灵自然会产生一个问题：Pod 和容器有什么区别？Pod 是容器的封装。换句话说，容器是包含在
    Pod 内的。一个 Pod 内可以包含多个容器；然而，最佳实践是保持一个 Pod 对应一个容器。这并不意味着一个 Pod 里不能有多个容器。一个 Pod 中有多个容器也是可以的，只要有一个主容器，其他都是辅助容器。也有一些模式，比如
    sidecar 模式，可以在多容器 Pod 中实现。
- en: Each Pod has its own IP address and networking stack. All containers share the
    network interface and the stack. All containers within a Pod can be reached locally
    using the hostname.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 Pod 都有自己的 IP 地址和网络栈。所有容器共享同一网络接口和栈。Pod 内的所有容器可以通过主机名在本地访问。
- en: 'A simple Pod definition in YAML format is shown in the following lines of code:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 YAML 格式的一个简单 Pod 定义示例：
- en: '[PRE0]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The Pod definition shown has a name and defines a few labels, which can be used
    by the Service resource to expose to other Pods, nodes and external custom resources.
    It also defines a single container based on a custom image stored in Azure Container
    Registry and opens port `80` for the container.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 显示的 Pod 定义有一个名称，并定义了几个标签，这些标签可以由服务资源用来暴露给其他 Pods、节点和外部自定义资源。它还定义了一个基于 Azure
    容器注册表中存储的自定义镜像的单个容器，并为该容器打开端口 `80`。
- en: Services
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务
- en: Kubernetes allows creating Pods with multiple instances. These Pods should be
    reachable from any Pod or node within a cluster. It is possible to use the IP
    address of a Pod directly and access the Pod. However, this is far from ideal.
    Pods are ephemeral and they might get a new IP address if the previous Pod has
    gone down. In such cases, the application will break easily. Kubernetes provides
    Services, which decouple Pod instances from their clients. Pods may get created
    and torn down, but the IP address of a Kubernetes Service remains constant and
    stable. Clients can connect to the Service IP address, which in turn has one endpoint
    for each Pod it can send requests to. If there are multiple Pod instances, each
    of their IP addresses will be available to the Service as an endpoint object.
    When a Pod goes down, the endpoints are updated to reflect the current Pod instances
    along with their IP addresses.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 允许创建多个实例的 Pods。这些 Pods 应该可以从集群中的任何 Pod 或节点访问。可以直接使用 Pod 的 IP 地址访问
    Pod。然而，这远非理想做法。Pods 是短暂的，如果先前的 Pod 已经崩溃，它们可能会获得一个新的 IP 地址。在这种情况下，应用程序容易出现故障。Kubernetes
    提供了 Services，将 Pod 实例与其客户端解耦。Pods 可以创建或销毁，但 Kubernetes 服务的 IP 地址保持不变和稳定。客户端可以连接到服务的
    IP 地址，该服务为每个 Pod 提供一个端点，用于发送请求。如果有多个 Pod 实例，每个 Pod 的 IP 地址都将作为端点对象提供给服务。当 Pod
    崩溃时，端点会更新，以反映当前的 Pod 实例及其 IP 地址。
- en: Services are highly decoupled with Pods. The main intention of Services is to
    queue for Pods that have labels in their Service selector definitions. A Service
    defines label selectors, and based on label selectors, Pod IP addresses are added
    to the Service resource. Pods and Services can be managed independently of each
    other.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 服务与 Pods 之间有很高的解耦。服务的主要目的是为那些在其服务选择器定义中具有标签的 Pods 排队。服务定义了标签选择器，根据标签选择器，Pod
    的 IP 地址被添加到服务资源中。Pods 和服务可以独立管理。
- en: 'A Service provides multiple types of IP address schemes. There are four types
    of Services: ClusterIP, NodePort, LoadBalancer, and Ingress Controller using Application
    Gateway.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 服务提供多种类型的 IP 地址方案。有四种类型的服务：ClusterIP、NodePort、LoadBalancer 和使用应用程序网关的 Ingress
    Controller。
- en: 'The most fundamental scheme is known as ClusterIP, and it is an internal IP
    address that can be reached only from within the cluster. The ClusterIP scheme
    is shown in *Figure 14.4*:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的方案称为 ClusterIP，它是一个只能从集群内部访问的内部 IP 地址。ClusterIP 方案如 *图 14.4* 所示：
- en: '![A block diagram showing the workings of the ClusterIP, where the internal
    traffic is routed to the ClsuterIP and then it is sent to the respective Pods.](img/B15432_14_04.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![一个展示 ClusterIP 工作原理的框图，其中内部流量被路由到 ClusterIP，然后发送到相应的 Pods。](img/B15432_14_04.jpg)'
- en: 'Figure 14.4: The workings of ClusterIP'
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.4：ClusterIP 的工作原理
- en: 'ClusterIP also allows the creation of NodePort, using which it gets a ClusterIP.
    However, it can also open a port on each of the nodes within a cluster. The Pods
    can be reached using ClusterIP addresses as well as by using a combination of
    the node IP and node port:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ClusterIP 还允许创建 NodePort，通过 NodePort，它会获得一个 ClusterIP。然而，它也可以在集群中的每个节点上打开一个端口。Pods
    可以通过 ClusterIP 地址访问，也可以通过节点 IP 和节点端口的组合来访问：
- en: '![The workings of NodePort, where traffic is routed to the AKS node, NodePort,
    and finally to the Pods.](img/B15432_14_05.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![NodePort 的工作原理，其中流量被路由到 AKS 节点、NodePort，然后最终到达 Pods。](img/B15432_14_05.jpg)'
- en: 'Figure 14.5: The workings of NodePort'
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.5：NodePort 的工作原理
- en: 'Services can refer not only to Pods but to external endpoints as well. Finally,
    Services also allow the creation of a load balancer–based service that is capable
    of receiving requests externally and redirecting them to a Pod instance using
    ClusterIP and NodePort internally:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 服务不仅可以指向 Pods，还可以指向外部端点。最后，服务还允许创建基于负载均衡器的服务，能够接收外部请求并通过 ClusterIP 和 NodePort
    内部将请求重定向到 Pod 实例：
- en: '![A block diagram showing the workings of the LoadBalancer. Here, the incoming
    traffic is routed through the load balancer and then reaches the Pods through
    the AKS nodes.](img/B15432_14_06.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![显示负载均衡器工作原理的框图。在这里，传入流量通过负载均衡器路由，然后通过 AKS 节点到达 Pods。](img/B15432_14_06.jpg)'
- en: 'Figure 14.6: The workings of Load Balancer'
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.6：负载均衡器的工作原理
- en: 'There is one final type of service known as Ingress Controller, which provides
    advanced functionalities such as URL-based routing, as shown in *Figure 14.7*:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种最终类型的服务被称为 Ingress 控制器，它提供了诸如基于 URL 的路由等高级功能，如*图 14.7*所示：
- en: '![A block diagram showing the workings of the Ingress Controller; the incoming
    traffic is routed through Ingress, and the Blog service, and finally, it reaches
    the Pods.](img/B15432_14_07.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![显示 Ingress 控制器工作原理的框图；传入流量通过 Ingress 路由到 Blog 服务，最后到达 Pods。](img/B15432_14_07.jpg)'
- en: 'Figure 14.7: The workings of Ingress Controller'
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.7：Ingress 控制器的工作原理
- en: 'A service definition in YAML format is shown here:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了一个 YAML 格式的服务定义：
- en: '[PRE1]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This service definition creates a load balancer–based service using label selectors.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 此服务定义使用标签选择器创建基于负载均衡器的服务。
- en: Deployments
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署
- en: Kubernetes Deployments are higher-level resources in comparison to ReplicaSets
    and Pods. Deployments provide functionality related to the upgrading and release
    of an application. Deployment resources create a ReplicaSet, and the ReplicaSet
    manages the Pod. It is important to understand the need for deployment resources
    when ReplicaSets already exist.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 与 ReplicaSets 和 Pods 相比，Kubernetes 的 Deployment 是更高级的资源。Deployment 提供了与应用程序升级和发布相关的功能。Deployment
    资源会创建一个 ReplicaSet，而 ReplicaSet 管理 Pods。理解当 ReplicaSets 已经存在时，为什么还需要 Deployment
    资源是非常重要的。
- en: 'Deployments play a significant role in upgrading applications. If an application
    is already in production and a new version of the application needs to be deployed,
    there are a few choices for you:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 部署在应用程序升级中起着重要作用。如果应用程序已经投入生产并且需要部署新版本的应用程序，你有几种选择：
- en: Delete existing Pods and create new Pods – in this method, there is downtime
    for the application, so this method should only be used if downtime is acceptable.
    There is a risk of increased downtime if the Deployment contains bugs and you
    have to roll back to a previous version.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除现有的 Pods 并创建新的 Pods——这种方法会导致应用程序的停机，因此只有在可以接受停机的情况下才应使用此方法。如果 Deployment 中存在错误并且需要回滚到先前的版本，则停机时间可能会增加。
- en: Blue-green deployment – In this method, the existing Pods continue to run and
    a new set of Pods is created with the new version of the application. The new
    Pods are not reachable externally. Once the tests have successfully completed,
    Kubernetes starts pointing to the new set of Pods. The old Pods can stay as-is
    or can be subsequently deleted.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 蓝绿部署——在此方法中，现有的 Pods 继续运行，并且创建一组新版本的 Pods。这些新 Pods 对外不可访问。一旦测试成功完成，Kubernetes
    开始指向这一组新的 Pods。旧的 Pods 可以保持不变，或者可以随后删除。
- en: Rolling upgrades – In this method, existing Pods are deleted one at a time while
    new Pods for the new application version are created one at a time. The new Pods
    are incrementally deployed while the old Pods are incrementally reduced, until
    they reach a count of zero.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动升级——在此方法中，现有的 Pods 会逐个删除，同时为新应用版本创建新的 Pods。新 Pods 会逐步部署，而旧 Pods 会逐步减少，直到它们的数量为零。
- en: All these approaches would have to be carried out manually without a Deployment
    resource. A Deployment resource automates the entire release and upgrade process.
    It can also help to automatically roll back to a previous version if there are
    any issues with the current Deployment.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有 Deployment 资源，所有这些方法都必须手动执行。Deployment 资源自动化了整个发布和升级过程。如果当前的 Deployment
    出现问题，它还可以帮助自动回滚到先前的版本。
- en: 'A Deployment definition is shown in the following code listing:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码列出了 Deployment 定义：
- en: '[PRE2]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: It is important to note that a Deployment has a `strategy` property, which determines
    whether the `recreate` or `RollingUpdate` strategy is used. `recreate` will delete
    all existing Pods and create new Pods. It also contains configuration details
    related to `RollingUpdate` by providing the maximum number of Pods that can be
    created and destroyed in a single execution.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，Deployment 具有一个 `strategy` 属性，该属性决定是使用 `recreate` 还是 `RollingUpdate`
    策略。`recreate` 会删除所有现有的 Pods 并创建新的 Pods。它还通过提供一次执行中可以创建和销毁的最大 Pods 数量，包含与 `RollingUpdate`
    相关的配置细节。
- en: Replication controller and ReplicaSet
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 副本控制器和 ReplicaSet
- en: Kubernetes' replication controller resource ensures that a specified desired
    number of Pod instances are always running within a cluster. Any deviation from
    the desired state is watched for by the replication controller, and it creates
    new Pod instances to meet the desired state.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的复制控制器资源确保集群内始终有指定数量的 Pod 实例在运行。复制控制器监控任何与期望状态的偏差，并创建新的 Pod 实例以满足期望状态。
- en: ReplicaSets are the new version of the replication controller. ReplicaSets provide
    the same functionality as that of replication controllers, with a few advanced
    functionalities. The main one among these is the rich capability for defining
    the selectors associated with Pods. With ReplicaSets, it is possible to define
    the dynamic expressions that were missing with replication controllers.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSets 是复制控制器的新版本。ReplicaSets 提供与复制控制器相同的功能，并增加了一些高级功能。其中最主要的功能是可以丰富地定义与
    Pod 相关的选择器。使用 ReplicaSets，可以定义复制控制器中没有的动态表达式。
- en: It is recommended to use ReplicaSets rather than replication controllers.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐使用 ReplicaSets 而不是复制控制器。
- en: 'The next code listing shows an example of defining a `ReplicaSet` resource:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个代码示例展示了如何定义一个 `ReplicaSet` 资源：
- en: '[PRE3]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: It is important to note that ReplicaSets have a `replicas` property, which determines
    the count of Pod instances, a `selector` property, which defines the Pods that
    should be managed by ReplicaSet, and finally the `template` property, which defines
    the Pod itself.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，ReplicaSets 有一个 `replicas` 属性，决定 Pod 实例的数量，`selector` 属性，定义哪些 Pods 应该由
    ReplicaSet 管理，最后是 `template` 属性，定义 Pod 本身。
- en: ConfigMaps and Secrets
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ConfigMaps 和 Secrets
- en: Kubernetes provides two important resources to store configuration data. ConfigMaps
    are used to store general configuration data that is not security-sensitive. Generic
    application configuration data, such as folder names, volume names, and DNS names,
    can be stored in ConfigMaps. On the other hand, sensitive data, such as credentials,
    certificates, and secrets, should be stored within Secrets resources. This Secrets
    data is encrypted and stored within the Kubernetes etcd data store.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 提供了两种重要的资源来存储配置信息。ConfigMaps 用于存储不涉及安全的普通配置信息。诸如文件夹名、卷名和 DNS 名称等通用应用配置数据可以存储在
    ConfigMaps 中。另一方面，敏感数据，如凭证、证书和机密，应存储在 Secrets 资源中。这些 Secrets 数据会加密并存储在 Kubernetes
    的 etcd 数据存储中。
- en: Both ConfigMaps and Secrets data can be made available as environment variables
    or volumes within Pods.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ConfigMaps 和 Secrets 数据可以作为环境变量或在 Pods 中的卷提供。
- en: The definition of the Pod that wants to consume these resources should include
    a reference to them. We have now covered the Kubernetes primitives and the roles
    of each of the building blocks. Next, you will be learning about the architecture
    of AKS.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 想要使用这些资源的 Pod 定义应该包括对它们的引用。我们现在已经介绍了 Kubernetes 的基本构件以及每个构件的角色。接下来，你将学习 AKS
    的架构。
- en: AKS architecture
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AKS 架构
- en: In the previous section, we discussed the architecture of an unmanaged cluster.
    Now, we will be exploring the architecture of AKS. When you have read this section,
    you will be able to point out the major differences between the architecture of
    unmanaged and managed (AKS, in this case) clusters.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了无管理集群的架构。现在，我们将探讨 AKS 的架构。当你阅读完这一节后，你将能够指出无管理集群与管理集群（在此案例中为 AKS）架构之间的主要区别。
- en: 'When an AKS instance is created, the worker nodes only are created. The master
    components are managed by Azure. The master components are the API server, the
    scheduler, etcd, and the controller manager, which we discussed earlier. The kubelets
    and kube-proxy are deployed on the worker nodes. Communication between the nodes
    and master components happens using kubelets, which act as agents for the Kubernetes
    clusters for the node:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建 AKS 实例时，只会创建工作节点。主控组件由 Azure 管理。主控组件包括 API 服务器、调度器、etcd 和控制器管理器，这些我们之前已经讨论过。kubelets
    和 kube-proxy 部署在工作节点上。节点与主控组件之间的通信通过 kubelets 实现，kubelets 充当 Kubernetes 集群的代理：
- en: '![The AKS architecture consisting of the Control plane, which is Azure-managed,
    and the Node, which is Customer-managed.](img/B15432_14_08.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![AKS 架构，包括由 Azure 管理的控制平面和由客户管理的节点。](img/B15432_14_08.jpg)'
- en: 'Figure 14.8: AKS architecture'
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.8：AKS 架构
- en: When a user requests a Pod instance, the user request lands with the API server.
    The API server checks and validates the request details and stores in etcd (the
    data store for the cluster) and also creates the deployment resource (if the Pod
    request is wrapped around a deployment resource). The deployment controller keeps
    a watch on the creation of any new deployment resources. If it sees one, it creates
    a ReplicaSet resource based on the definition provided in the user request.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户请求一个 Pod 实例时，用户请求会到达 API 服务器。API 服务器检查并验证请求的详细信息，将其存储在 etcd（集群的数据存储）中，并且还会创建部署资源（如果
    Pod 请求是围绕部署资源包装的）。部署控制器监视任何新部署资源的创建。如果它发现新资源，它会根据用户请求中提供的定义创建一个 ReplicaSet 资源。
- en: The ReplicaSet controller keeps a watch on the creation of any new ReplicaSet
    resources, and upon seeing a resource being created, it asks the scheduler to
    schedule the Pods. The scheduler has its own procedure and rules for finding an
    appropriate node for hosting the Pods. The scheduler informs the kubelet of the
    node and the kubelet then fetches the definition for the Pod and creates the Pods
    using the container runtime installed on the nodes. The Pod finally creates the
    containers within its definition.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSet 控制器监视任何新 ReplicaSet 资源的创建，并在看到资源被创建时，要求调度器调度 Pods。调度器有自己的过程和规则，用于找到合适的节点来托管
    Pods。调度器将节点信息通知 kubelet，kubelet 然后获取 Pod 的定义并使用节点上安装的容器运行时创建 Pods。最终，Pod 在其定义中创建容器。
- en: kube-proxy helps in maintaining the list of IP addresses of Pod and Service
    information on local nodes, as well as updating the local firewall and routing
    rules. To do a quick recap of what we have discussed so far, we started off with
    the Kubernetes architecture and then moved on to primitives, followed by the architecture
    of AKS. Since you are clear on the concepts, let's go ahead and create an AKS
    cluster in the next section.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: kube-proxy 帮助维护本地节点上 Pod 和 Service 信息的 IP 地址列表，并更新本地防火墙和路由规则。为了快速回顾我们到目前为止讨论的内容，我们从
    Kubernetes 架构开始，然后转向基本组件，接着讨论了 AKS 的架构。既然你已经清楚这些概念，我们接下来在下一部分创建 AKS 集群。
- en: Deploying an AKS cluster
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署 AKS 集群
- en: AKS can be provisioned using the Azure portal, the Azure **CLI** (**command-line
    interface**), Azure PowerShell cmdlets, ARM templates, **SDKs** (**software development
    kits**) for supported languages, and even Azure ARM REST APIs.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: AKS 可以通过 Azure 门户、Azure **CLI**（**命令行界面**）、Azure PowerShell cmdlets、ARM 模板、支持语言的
    **SDKs**（**软件开发工具包**）甚至 Azure ARM REST API 来进行配置。
- en: The Azure portal is the simplest way of creating an AKS instance; however, to
    enable DevOps, it is better to create an AKS instance using ARM templates, the
    CLI, or PowerShell.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 门户是创建 AKS 实例最简单的方法；然而，为了启用 DevOps，最好使用 ARM 模板、CLI 或 PowerShell 来创建 AKS
    实例。
- en: Creating an AKS cluster
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建 AKS 集群
- en: 'Let''s create a resource group to deploy our AKS cluster. From the Azure CLI,
    use the `az group create` command:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个资源组来部署我们的 AKS 集群。从 Azure CLI 使用 `az group create` 命令：
- en: '[PRE4]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here, `-n` denotes the name of the resource group and `-l` denotes the location.
    If the request was successful, you will see a similar response to this:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`-n` 表示资源组的名称，`-l` 表示位置。如果请求成功，你将看到类似下面的响应：
- en: '![The output of the az group create command showing that the resource group
    has been created.](img/B15432_14_09.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![az group create 命令的输出，显示资源组已创建。](img/B15432_14_09.jpg)'
- en: 'Figure 14.9: Resource group creation'
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.9：资源组创建
- en: 'Now that we have the resource group ready, we will go ahead and create the
    AKS cluster using the `az aks create` command. The following command will create
    a cluster named `AzureForArchitects-AKS` in the `AzureForArchitects` resource
    group with a node count of `2`. The `--generate-ssh-keys` parameter will allow
    the creation of **RSA** (**Rivest–Shamir–Adleman**) key pairs, a public-key cryptosystem:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了资源组，我们将使用 `az aks create` 命令继续创建 AKS 集群。以下命令将在 `AzureForArchitects`
    资源组中创建一个名为 `AzureForArchitects-AKS` 的集群，节点数为 `2`。`--generate-ssh-keys` 参数将允许创建
    **RSA**（**Rivest–Shamir–Adleman**）密钥对，这是一个公钥加密系统：
- en: '[PRE5]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If the command succeeded, you will be able to see a similar output to this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果命令成功，你将能够看到类似的输出：
- en: '![The output of the az aks create command showing that the cluster has been
    created.](img/B15432_14_10.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![az aks create 命令的输出，显示集群已创建。](img/B15432_14_10.jpg)'
- en: 'Figure 14.10: Creating the cluster'
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.10：创建集群
- en: 'Going through the cluster, you will see a line item that says `"nodeResourceGroup":
    "MC_AzureForArchitects_AzureForArchitects-AKS_southeastasia"`. When creating an
    AKS cluster, a second resource is automatically created to store the node resources.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '在查看集群时，你会看到一行项，内容是 `"nodeResourceGroup": "MC_AzureForArchitects_AzureForArchitects-AKS_southeastasia"`。创建
    AKS 集群时，会自动创建第二个资源来存储节点资源。'
- en: Our cluster is provisioned. Now we need to connect to the cluster and interact
    with it. To control the Kubernetes cluster manager, we will be using kubectl.
    In the next section, we will take a quick look at kubectl.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的集群已经配置好。现在我们需要连接到集群并与其互动。为了控制 Kubernetes 集群管理器，我们将使用 kubectl。在接下来的章节中，我们将快速了解一下
    kubectl。
- en: Kubectl
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubectl
- en: Kubectl is the main component through which developers and infrastructure consultants
    can interact with AKS. Kubectl helps in creating a REST request containing the
    HTTP header and body, and submitting it to the API server. The header contains
    the authentication details, such as a token or username/password combination.
    The body contains the actual payload in JSON format.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Kubectl 是开发人员和基础设施顾问与 AKS 互动的主要工具。Kubectl 帮助创建一个包含 HTTP 头和正文的 REST 请求，并将其提交到
    API 服务器。头部包含认证信息，如令牌或用户名/密码组合。正文包含实际的 JSON 格式有效负载。
- en: The kubectl command provides rich log details when used along with the verbose
    switch. The switch takes an integer input that can range from 0 to 9, which can
    be viewed from the details logs.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: kubectl 命令提供了丰富的日志细节，当与详细开关一起使用时，开关会接受一个从 0 到 9 的整数输入，可以从详细日志中查看。
- en: Connecting to the cluster
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 连接到集群
- en: To connect to the cluster locally, we need to install kubectl. Azure Cloud Shell
    has kubectl already installed. If you want to connect locally, use `az aks install-cli`
    to install kubectl.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 若要本地连接到集群，我们需要安装 kubectl。Azure Cloud Shell 已经预装了 kubectl。如果你想在本地连接，请使用 `az aks
    install-cli` 来安装 kubectl。
- en: 'In order to configure kubectl to connect to our Kubernetes cluster, we need
    to download the credentials and configure the CLI with them. This can be done
    using the `az aks get-credentials` command. Use the command as shown here:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了配置 kubectl 连接到我们的 Kubernetes 集群，我们需要下载凭证并用它们配置 CLI。可以使用 `az aks get-credentials`
    命令来完成。使用如下命令：
- en: '[PRE6]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, we need to verify whether we''re connected to the cluster. As mentioned
    earlier, we''ll be using kubectl to communicate with the cluster, and `kubectl
    get nodes` will show a list of nodes in the cluster. During creation, we set the
    node count to `2`, so the output should have two nodes. Also, we need to make
    sure that the status of the node is `Ready`. The output should be something like
    *Figure 14.11*:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要验证是否已连接到集群。如前所述，我们将使用 kubectl 与集群通信，`kubectl get nodes` 将显示集群中节点的列表。在创建时，我们将节点数量设置为
    `2`，所以输出应该有两个节点。同时，我们需要确保节点的状态为 `Ready`。输出应类似于*图 14.11*：
- en: '![The output of the kubectl get nodes command showing the Name, Status, Roles,
    Age, and Version of the nodes.](img/B15432_14_11.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![kubectl get nodes 命令的输出，显示节点的名称、状态、角色、年龄和版本。](img/B15432_14_11.jpg)'
- en: 'Figure 14.11: Getting the list of nodes'
  id: totrans-152
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.11：获取节点列表
- en: 'Since our node is in the `Ready` state, let''s go ahead and create a Pod. There
    are two ways in which you can create resources in Kubernetes. They are:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的节点处于 `Ready` 状态，让我们继续创建一个 Pod。在 Kubernetes 中创建资源有两种方法。它们是：
- en: '`kubectl run` and `kubectl expose` commands to create the resources.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `kubectl run` 和 `kubectl expose` 命令来创建资源。
- en: '`kubectl apply` command to create the resources, and the resources declared
    in the file will be created.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `kubectl apply` 命令来创建资源，文件中声明的资源将被创建。
- en: 'Let''s take the imperative approach first, to create a Pod with the name `webserver`,
    running an NGINX container with port `80` exposed:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先采用命令式方法，创建一个名为 `webserver` 的 Pod，运行一个暴露 `80` 端口的 NGINX 容器：
- en: '[PRE7]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Upon successful completion of the command, the CLI will let you know the status:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 命令成功完成后，CLI 将告知你状态：
- en: '![Creating a webserver with the kubectl run webserver command.](img/B15432_14_12.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![使用 kubectl run webserver 命令创建一个 Web 服务器。](img/B15432_14_12.jpg)'
- en: 'Figure 14.12: Creating a Pod'
  id: totrans-160
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.12：创建一个 Pod
- en: Now that we have tried the imperative method, let's follow the declarative method.
    You can use the structure of the YAML file we discussed in the *Pod* subsection
    of the *Kubernetes primitives* section and modify it as per your requirements.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经尝试了命令式方法，现在让我们采用声明式方法。你可以使用我们在 *Kubernetes 原语* 部分的 *Pod* 小节中讨论的 YAML 文件结构，并根据需求进行修改。
- en: We will be using the NGINX image, and the Pod will be named `webserver-2`.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use any text editor and create the file. The final file will look similar
    to this:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the `kubectl apply` command, we will pass the filename to the `-f` parameter,
    as shown in *Figure 14.13*, and you can see that the Pod has been created:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing the command kubectl apply –f nginx.yaml to create a Pod with the
    declarative method.](img/B15432_14_13.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.13: Creating a Pod using the declarative method.'
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Since we have created the Pods, we can use the `kubectl get pods` command to
    list all the Pods. Kubernetes uses the concept of namespaces for the logical isolation
    of resources. By default, all commands are pointing to the `default` namespace.
    If you want to perform an action on a specific namespace, you can pass the namespace
    name via the `-n` parameter. In *Figure 14.14*, you can see that `kubectl get
    pods` returns the Pods we created in the previous example, which reside in the
    default namespace. Also, when we use `--all-namespaces`, the output returns pods
    in all namespaces:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '![The output of the kubectl get pods command displaying the details of all
    the Pods in the container.](img/B15432_14_14.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.14: Listing all Pods'
  id: totrans-170
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now we will create a simple Deployment that runs NGINX and with a load balancer
    that exposes it to the internet. The `YAML` file will look like this:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We'll be using the `kubectl apply` command and passing the YAML file to the
    `-f` parameter.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'Upon success, all three Services will be created, and if you execute the `kubectl
    get deployment nginx-server` command, you will see six replicas running, as shown
    in *Figure 14.15*, to make the Service highly available:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing the kubectl get deployment nginx-server command to check the details
    of all the deployments.](img/B15432_14_15.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.15: Checking the deployment'
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Since our Deployment is provisioned, we need to check what the public IP of
    the load balancer that we created is. We can use the `kubectl get service nginx-lb
    --watch` command. When the load balancer is initializing, `EXTERNAL-IP` will show
    as `<pending>`, the `--wait` parameter will let the command run in the foreground,
    and when the public IP is allocated, we will be able to see a new line, as shown
    here:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '![Running the kubectl get service nginx-lb --watch command to get the Public
    IP of the load balancer.](img/B15432_14_16.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.16: Finding public IP of the load balancer'
  id: totrans-179
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now that we have the public IP, we can go to the browser and should see the
    NGINX landing page, as shown in *Figure 14.17*:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '![The browser pointing at the URL 52.187.70.177 and displaying the NGINX landing
    page.](img/B15432_14_17.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.17: NGINX landing page'
  id: totrans-182
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Similarly, you can use the `YAML` files we discussed in the *Kubernetes primitives*
    section to create different types of resources.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of commands, such as `logs`, `describe`, `exec`, and `delete`,
    that administrators need to use with the `kubectl` command. The objective of this
    section was to enable you to create an AKS cluster, connect to the cluster, and
    deploy a simple web application.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will be discussing AKS networking.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: AKS networking
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Networking forms a core component within a Kubernetes cluster. The master components
    should be able to reach the minion nodes and the Pods running on top of them,
    while the worker nodes should be able to communicate among themselves as well
    as with the master components.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: It might come as a surprise that core Kubernetes does not manage the networking
    stack at all. It is the job of the container runtime on the nodes.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes has prescribed three important tenets that any container runtime
    should adhere to. These are as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Pods should be able to communicate with other Pods without any transformation
    in their source or destination addresses, something that is performed using **network
    address translation** (**NAT**).
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agents such as kubelets should be able to communicate with Pods directly on
    the nodes.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pods that are directly hosted on the host network still should be able to communicate
    with all Pods in the cluster.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every Pod gets a unique IP address within the Kubernetes cluster, along with
    a complete network stack, similar to virtual machines. They all are connected
    to the local bridge network created by the **Container Networking Interface**
    (**CNI**) component. The CNI component also creates the networking stack of the
    Pod. The bridge network then talks to the host network and becomes the conduit
    for the flow of traffic from Pods to network and vice versa.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: CNI is a standard managed and maintained by the **Cloud Native Computing Foundation**
    (**CNCF**), and there are many providers that provide their own implementation
    of the interface. Docker is one of these providers. There are others, such as
    rkt (read as rocket), weave, calico, and many more. Each has its own capabilities
    and independently decides the network capabilities, while ensuring that the main
    tenets of Kubernetes networking are followed completely.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'AKS provides two distinct networking models:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Kubenet
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure CNI
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubenet
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Kubenet is the default networking framework in AKS. Under Kubenet, each node
    gets an IP address from the subnet of the virtual network they are connected with.
    The Pods do not get IP addresses from the subnet. Instead, a separate addressing
    scheme is used to provide IP addresses to Pods and Kubernetes Services. While
    creating an AKS instance, it is important to set the IP address range for Pods
    and Services. Since Pods are not on the same network as that of nodes, requests
    from Pods and to Pods are always NATed/routed to replace the source Pod IP with
    the node IP address and vice versa.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: 'In user-defined routing, Azure can support up to 400 routes, and you also cannot
    have a cluster larger than 400 nodes. *Figure 14.18* shows how the AKS node receives
    an IP address from the virtual network, but not the Pods created in the node:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在用户定义的路由中，Azure 可以支持最多 400 条路由，且集群中的节点数不能超过 400 个。*图 14.18* 显示了 AKS 节点如何从虚拟网络获取
    IP 地址，但不包括在节点中创建的 Pods：
- en: '![An architectural diagram illustrating the networking in AKS.](img/B15432_14_18.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![展示 AKS 中网络架构的示意图。](img/B15432_14_18.jpg)'
- en: 'Figure 14.18: Networking in AKS'
  id: totrans-202
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.18：AKS 中的网络
- en: By default, this Kubenet is configured with 110 Pods per node. This means there
    can be a maximum of 110 * 400 Pods in a Kubernetes cluster by default. The maximum
    number of Pods per node is 250.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，这个 Kubenet 配置为每个节点 110 个 Pods。这意味着默认情况下，在 Kubernetes 集群中最多可以有 *110 * 400*
    个 Pods。每个节点的最大 Pods 数量是 250。
- en: This scheme should be used when IP address availability and having user-defined
    routing are not a constraint.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 当 IP 地址的可用性和用户定义的路由不是限制条件时，应该使用此方案。
- en: 'In the Azure CLI, you can execute the following command to create an AKS instance
    using this networking stack:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Azure CLI 中，你可以执行以下命令来使用此网络堆栈创建 AKS 实例：
- en: '[PRE10]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Notice how all the IP addresses are explicitly provided for Service resources,
    Pods, nodes, and Docker bridges. These are non-overlapping IP address ranges.
    Also notice that Kubenet is used as a network plugin.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，所有的 IP 地址都明确地为服务资源、Pods、节点和 Docker 桥接提供。这些是非重叠的 IP 地址范围。同时请注意，Kubenet 被用作网络插件。
- en: Azure CNI (advanced networking)
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Azure CNI（高级网络）
- en: With Azure CNI, each node and Pod gets an IP address assigned from the network
    subnet directly. This means there can be as many Pods as there are unique IP addresses
    available on a subnet. This makes IP address range planning much more important
    under this networking strategy.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Azure CNI 时，每个节点和 Pod 会直接从网络子网分配一个 IP 地址。这意味着，可以根据子网中可用的唯一 IP 地址数量来拥有尽可能多的
    Pods。这使得在这种网络策略下，IP 地址范围规划变得更加重要。
- en: It is important to note that Windows hosting is only possible using the Azure
    CNI networking stack. Moreover, some of AKS components, such as virtual nodes
    and virtual kubelets, are also dependent on the Azure CNI stack. There is a need
    to reserve IP addresses in advance, depending on the number of Pods that will
    be created. There should always be extra IP addresses available on the subnet,
    to avoid exhaustion of IP addresses or to avoid the need to rebuild the cluster
    for a larger subnet due to application demand.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，Windows 主机仅能使用 Azure CNI 网络堆栈。此外，某些 AKS 组件，如虚拟节点和虚拟 kubelet，也依赖于 Azure
    CNI 堆栈。根据将要创建的 Pods 数量，可能需要提前预留 IP 地址。子网中应该始终有额外的 IP 地址，以避免 IP 地址耗尽，或者避免因应用需求而需要重新构建集群来支持更大的子网。
- en: By default, this networking stack is configured for 30 Pods per node and it
    can be configured with 250 Pods as the maximum number of Pods per node.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，此网络堆栈配置为每个节点 30 个 Pods，并且可以配置为每个节点最多支持 250 个 Pods。
- en: 'The command to execute to create an AKS instance using this networking stack
    is shown here:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 用于创建 AKS 实例的命令如下所示：
- en: '[PRE11]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Notice how all the IP addresses are explicitly provided for Service resources,
    Pods, nodes, and Docker bridges. These are non-overlapping IP address ranges.
    Also, notice that Azure is used as a network plugin.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，所有的 IP 地址都明确地为服务资源、Pods、节点和 Docker 桥接提供。这些是非重叠的 IP 地址范围。同时，注意 Azure 被用作网络插件。
- en: So far, you have learned how to deploy a solution and manage the networking
    of an AKS cluster. Security is another important factor that needs to be addressed.
    In the next section, we will be focusing on access and identity options for AKS.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经学习了如何部署解决方案并管理 AKS 集群的网络。安全性是另一个需要解决的重要因素。在下一部分，我们将重点介绍 AKS 的访问和身份验证选项。
- en: Access and identity for AKS
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AKS 的访问和身份验证
- en: Kubernetes clusters can be secured in multiple ways.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群可以通过多种方式进行安全保护。
- en: The service account is one of the primary user types in Kubernetes. The Kubernetes
    API manages the service account. Authorized Pods can communicate with the API
    server using the credentials of service accounts, which are stored as Kubernetes
    Secrets. Kubernetes does not have any data store or identity provider of its own.
    It delegates the responsibility of authentication to external software. It provides
    an authentication plugin that checks for the given credentials and maps them to
    available groups. If the authentication is successful, the request passes to another
    set of authorization plugins to check the permission levels of the user on the
    cluster, as well as the namespace-scoped resources.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 服务账户是 Kubernetes 中的主要用户类型之一。Kubernetes API 管理服务账户。授权的 Pod 可以使用服务账户的凭证与 API 服务器通信，这些凭证作为
    Kubernetes Secrets 存储。Kubernetes 没有自己的数据存储或身份提供者，它将认证的责任委托给外部软件。它提供了一个认证插件，用于检查给定的凭证并将其映射到可用的组。如果认证成功，请求会传递给另一组授权插件，以检查用户在集群上的权限级别，以及命名空间范围内的资源。
- en: 'For Azure, the best security integration would be to use Azure AD. Using Azure
    AD, you can also bring your on-premises identities to AKS to provide centralized
    management of accounts and security. The basic workflow of Azure AD integration
    is shown in *Figure 14.19*:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Azure，最佳的安全集成方式是使用 Azure AD。使用 Azure AD，您还可以将本地身份带入 AKS，以提供账户和安全的集中管理。Azure
    AD 集成的基本工作流程如 *图 14.19* 所示：
- en: '![A block diagram showing the basic workflow of Azure AD integration.](img/B15432_14_19.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![显示 Azure AD 集成基本工作流程的框图。](img/B15432_14_19.jpg)'
- en: 'Figure 14.19: Basic workflow of Azure AD integration'
  id: totrans-221
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 14.19：Azure AD 集成的基本工作流程
- en: Users or groups can be granted access to resources within a namespace or across
    a cluster. In the previous section, we used the `az aks get-credential` command
    to get the credentials and the kubectl configuration context. When the user tries
    to interact with kubectl, they are prompted to sign in using their Azure AD credentials.
    Azure AD validates the credentials and a token is issued for the user. Based on
    the access level they have, they can access the resources in the cluster or the
    namespace.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 用户或组可以被授予访问命名空间内或跨集群的资源的权限。在上一节中，我们使用了 `az aks get-credential` 命令来获取凭证和 kubectl
    配置上下文。当用户尝试与 kubectl 交互时，系统会提示他们使用 Azure AD 凭证进行登录。Azure AD 验证凭证并为用户发放令牌。根据他们的访问级别，他们可以访问集群或命名空间中的资源。
- en: Additionally, you can leverage Azure **Role-Based Access Control** (**RBAC**)
    to limit access to the resources in the resource group.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您可以利用 Azure **基于角色的访问控制** (**RBAC**) 来限制对资源组内资源的访问。
- en: In the next section, we will be discussing virtual kubelet, which is one of
    the quickest ways to scale out a cluster.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论虚拟 kubelet，它是扩展集群的最快方式之一。
- en: Virtual kubelet
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 虚拟 kubelet
- en: Virtual kubelet is currently in preview and is managed by the CNCF organization.
    It is quite an innovative approach that AKS uses for scalability purposes. Virtual
    kubelet is deployed on the Kubernetes cluster as a Pod. The container running
    within the Pod uses the Kubernetes SDK to create a new node resource and represents
    itself to the entire cluster as a node. The cluster components, including the
    API server, scheduler, and controllers, think of it and treat it as a node and
    schedule Pods on it.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟 kubelet 目前处于预览阶段，由 CNCF 组织管理。它是 AKS 用于扩展性目的的一种创新方法。虚拟 kubelet 作为一个 Pod 部署在
    Kubernetes 集群中。运行在 Pod 内的容器使用 Kubernetes SDK 创建一个新的节点资源，并将自己作为节点呈现给整个集群。集群组件，包括
    API 服务器、调度器和控制器，认为它是一个节点，并在其上调度 Pods。
- en: 'However, when a Pod is scheduled on this node that is masquerading as a node,
    it communicates to its backend components, known as providers, to create, delete,
    and update the Pods. One of the main providers on Azure is Azure Container Instances.
    Azure Batch can also be used as a provider. This means the containers are actually
    created on Container Instances or Azure Batch rather than on the cluster itself;
    however, they are managed by the cluster. The architecture of virtual kubelet
    is shown in *Figure 14.20*:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当一个 Pod 被调度到这个伪装成节点的节点上时，它会与其后端组件（称为提供者）进行通信，以创建、删除和更新 Pods。Azure 上的一个主要提供者是
    Azure 容器实例。Azure 批量处理也可以作为提供者使用。这意味着容器实际上是在容器实例或 Azure 批量处理上创建的，而不是在集群本身上；然而，它们仍由集群管理。虚拟
    kubelet 的架构如 *图 14.20* 所示：
- en: '![An architectural diagram of Virtual Kubelet showing how it is integrated
    with the Kubernetes API, nodes, and kubelets.](img/B15432_14_20.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.20: Virtual kubelet architecture'
  id: totrans-229
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Notice that virtual kubelet is represented as a node within the cluster and
    can help in hosting and managing Pods, just like a normal kubelet would. However,
    virtual kubelet has one limitation; this is what we are going to discuss in the
    next section.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Virtual nodes
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the limitations of virtual kubelet is that the Pods deployed on virtual
    kubelet providers are isolated and do not communicate with other Pods in the cluster.
    If there is a need for the Pods on these providers to talk to other Pods and nodes
    in the cluster and vice versa, then virtual nodes should be created. Virtual nodes
    are created on a different subnet on the same virtual network that is hosting
    Kubernetes cluster nodes, which can enable communication between Pods. Only the
    Linux operating system is supported, at the time of writing, for working with
    virtual nodes.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Virtual nodes give a perception of a node; however, the node does not exist.
    Anything scheduled on such a node actually gets created in Azure Container Instances.
    Virtual nodes are based on virtual kubelet but have the extra functionality of
    seamless to-and-fro communication between the cluster and Azure Container Instances.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 'While deploying Pods on virtual nodes, the Pod definition should contain an
    appropriate node selector to refer to virtual nodes, and also tolerations, as
    shown in next code snippet:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here, the node selector is using the `type` property to refer to virtual kubelet
    and the `tolerations` property to inform Kubernetes that nodes with taints, `virtual-kubelet.io/provider`,should
    allow the Deployment of these Pods on them.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes is the most widely used container orchestrator and works with different
    container and network runtimes. In this chapter, you learned about the basics
    of Kubernetes, its architecture, and some of the important infrastructure components,
    such as etcd, the API server, controller managers, and the scheduler, along with
    their purpose. Plus, we looked at important resources that can be deployed to
    manage applications, such as Pods, replication controllers, ReplicaSets, Deployments,
    and Services.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: AKS provides a couple of different networking stacks—Azure CNI and Kubenet.
    They provide different strategies for assigning IP addresses to Pods. While Azure
    CNI provides IP addresses to Pods from the underlying subnet, Kubenet uses virtual
    IP addresses only.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: We also covered some of the features provided exclusively by Azure, such as
    virtual nodes, and concepts around virtual kubelet. In the next chapter, we will
    learn about the provisioning and configuring resources with ARM templates.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
