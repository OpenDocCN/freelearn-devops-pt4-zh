<html><head></head><body>
		<div>
			<div id="_idContainer422" class="Content">
			</div>
		</div>
		<div id="_idContainer423" class="Content">
			<h1 id="_idParaDest-428">18. <a id="_idTextAnchor445"/>Azure Synapse Analytics for architects</h1>
		</div>
		<div id="_idContainer444" class="Content">
			<p>Azure Synapse Analytics is a groundbreaking evolution of Azure SQL Data Warehouse. Azure Synapse is a fully managed, integrated data analytics service that blends data warehousing, data integration, and big data processing with accelerating time to insight to form a single service.</p>
			<p>In this chapter, we will explore Azure Synapse Analytics by covering the following topics:</p>
			<ul>
				<li>An overview of Azure Synapse Analytics</li>
				<li>Introduction to Synapse workspaces and Synapse Studio</li>
				<li>Migrating from existing legacy systems to Azure Synapse Analytics</li>
				<li>Migrating existing data warehouse schemas and data to Azure Synapse Analytics</li>
				<li>Re-developing scalable ETL processes using Azure Data Factory</li>
				<li>Common migration issues and resolutions</li>
				<li>Security considerations</li>
				<li>Tools to help migrate to Azure Synapse Analytics</li>
			</ul>
			<h2 id="_idParaDest-429"><a id="_idTextAnchor446"/>Azure Synapse Analytics</h2>
			<p>Nowadays, with inexpensive storage and high elastic storage capacities, organizations are amassing more data than ever before. Architecting a solution to analyze such massive volumes of data to deliver meaningful insights about a business can be a challenge. One obstacle that many businesses face is the need to manage and maintain two types of analytics systems:</p>
			<ul>
				<li><strong class="bold">Data warehouses</strong>: These provide critical insights about the business.</li>
				<li><strong class="bold">Data lakes</strong>: These provide meaningful insights about customers, products, employees, and processes through various analytics methodologies.</li>
			</ul>
			<p>Both of these analytics systems are critical to businesses, yet they operate independently of one another. Meanwhile, businesses need to gain insights from all their organizational data in order to stay competitive and to innovate processes to obtain better results.</p>
			<p>For architects who need to build their own end-to-end data pipelines, the following steps must be taken:</p>
			<ol>
				<li>Ingest data from various data sources.</li>
				<li>Load all these data sources into a data lake for further processing.</li>
				<li>Perform data cleaning over a range of different data structures and types.</li>
				<li>Prepare, transform, and model the data.</li>
				<li>Serve the cleansed data to thousands of users through BI tools and applications.</li>
			</ol>
			<p>Until now, each of these steps has required a different tool. Needless to say, with so many different services, applications, and tools available on the market, choosing the best-suited ones can be a daunting task.</p>
			<p>There are numerous services available for ingesting, loading, preparing, and serving data. There are countless services for data cleansing based on the developer's language of choice. Furthermore, some developers might prefer to use SQL, some might want to use Spark, while others might prefer to use code-free environments to transform data.</p>
			<p>Even after the seemingly proper collection of tools has been selected, there is often a steep learning curve for these tools. Additionally, architects could encounter unexpected logistical challenges in maintaining a data pipeline over dissimilar platforms and languages due to incompatibilities. With such a range of issues, implementing and maintaining a cloud-based analytics platform can be a difficult task.</p>
			<p>Azure Synapse Analytics solves these problems and more. It simplifies the entire modern data warehouse pattern, allowing architects to focus on building end-to-end analytics solutions within a unified environment.</p>
			<h2 id="_idParaDest-430"><a id="_idTextAnchor447"/>A common scenario for architects</h2>
			<p>One of the most common scenarios that an architect faces is having to conjure up a plan for migrating existing legacy data warehouse solutions to a modern enterprise analytics solution. With its limitless scalability and unified experience, Azure Synapse has become one of the top choices for many architects to consider. Later in this chapter, we will also discuss common architectural considerations for migrating from an existing legacy data warehouse solution to Azure Synapse Analytics.</p>
			<p>In the next section, we will provide a technical overview of the key features of Azure Synapse Analytics. Architects who are new to the Azure Synapse ecosystem will gain the necessary knowledge about Synapse after reading this chapter.</p>
			<h2 id="_idParaDest-431"><a id="_idTextAnchor448"/>An overview of Azure Synapse Analytics</h2>
			<p>Azure Synapse Analytics enables data professionals to build end-to-end analytics solutions while leveraging a unified experience. It delivers rich functionalities for SQL developers, serverless on-demand querying, machine learning support, the ability to embed Spark natively, collaborative notebooks, and data integration within a single service. Developers can choose from a variety of supported languages (for example, C#, SQL, Scala, and Python) through different engines.</p>
			<p>Some of the main capabilities of Azure Synapse Analytics include:</p>
			<ul>
				<li>SQL Analytics with pools (fully provisioned) and on-demand (serverless).</li>
				<li>Spark with full support for Python, Scala, C#, and SQL.</li>
				<li>Data Flow with code-free big data transformation experience.</li>
				<li>Data integration and orchestration to integrate data and operationalize code development.</li>
				<li>A cloud-native version of <strong class="bold">Hybrid Transactional/Analytical Processing</strong> (<strong class="bold">HTAP</strong>), delivered by Azure Synapse Link.</li>
			</ul>
			<p>To access all of the aforementioned capabilities, Azure Synapse Studio provides a single unified web UI.</p>
			<p>This single integrated data service is advantageous to enterprises as it accelerates the delivery of BI, AI, machine learning, Internet of Things, and intelligent applications.</p>
			<p>Azure Synapse Analytics can derive and deliver insights from all your data residing in the data warehouse and big data analytics systems at lightning-fast speeds. It enables data professionals to use familiar languages, such as SQL, to query both relational and non-relational databases at petabyte scale. In addition, advanced features such as limitless concurrency, intelligent workload management, and workload isolation help optimize the performance of all queries for mission-critical workloads.</p>
			<h3 id="_idParaDest-432"><a id="_idTextAnchor449"/>What is workload isolation?</h3>
			<p>One of the key features of running enterprise data warehouses at scale is workload isolation. This is the ability to guarantee resource reservations within a compute cluster so that multiple teams can work on the data without getting in each other's way, as illustrated in <em class="italics">Figure 18.1</em>:</p>
			<div>
				<div id="_idContainer424" class="IMG---Figure">
					<img src="image/B15432_18_01.jpg" alt="Workload isolation in Azure"/>
				</div>
			</div>
			<h6>F<a id="_idTextAnchor450"/>igure 18.1: Example of workload isolation</h6>
			<p>You can create workload groups within a cluster by setting a couple of simple thresholds. These are automatically adjusted depending on the workload and the cluster, but they always guarantee a quality experience for users running the workloads. Refer to <a href="https://techcommunity.microsoft.com/t5/data-architecture-blog/configuring-workload-isolation-in-azure-synapse-analytics/ba-p/1201739">https://techcommunity.microsoft.com/t5/data-architecture-blog/configuring-workload-isolation-in-azure-synapse-analytics/ba-p/1201739</a> to read more about configuring workload isolation in Azure Synapse Analytics.</p>
			<p>To fully appreciate the benefits of Azure Synapse, we will first take a look at Synapse workspaces and Synapse Studio.</p>
			<h3 id="_idParaDest-433"><a id="_idTextAnchor451"/>Introduction to Synapse workspaces and Synapse Studio</h3>
			<p>At the heart of Azure Synapse is the workspace. The workspace is the top-level resource that comprises your analytics solution in a data warehouse. The Synapse workspace supports both relational and big data processing.</p>
			<p>Azure Synapse provides a unified web UI experience for data preparation, data management, data warehousing, big data analytics, BI, and AI tasks known as Synapse Studio. Together with Synapse workspaces, Synapse Studio is an ideal environment for data engineers and data scientists to share and collaborate their analytics solutions, as shown in <em class="italics">Figure 18.2</em>:</p>
			<div>
				<div id="_idContainer425" class="IMG---Figure">
					<img src="image/B15432_18_02.jpg" alt="The Azure Synapse workspace and its services"/>
				</div>
			</div>
			<h6>Figure 18.2: A Synapse workspace in Azure Synapse Studio</h6>
			<p>The following sections highlight the capabilities, key features, platform details, and end user services of Synapse workspaces and Synapse Studio:</p>
			<p><strong class="bold">Capabilities:</strong></p>
			<ul>
				<li>A fast, highly elastic, and secure data warehouse with industry-leading performance and security</li>
				<li>The ability to explore Azure Data Lake Storage and data warehouses using familiar T-SQL syntax using SQL on-demand (serverless) and SQL queries</li>
				<li>Apache Spark integrated with Azure Machine Learning</li>
				<li>Hybrid data integration to accelerate data ingestion and the operationalization of the analytics process (ingest, prepare, transform, and serve)</li>
				<li>Business report generation and serving with Power BI integration</li>
			</ul>
			<p><strong class="bold">Key features:</strong></p>
			<ul>
				<li>Create and operationalize pipelines for data ingestion and orchestration.</li>
				<li>Directly explore data in your Azure Data Lake Storage or data warehouse, as well as any external connections to the workspace, using Synapse Studio.</li>
				<li>Write code using notebooks and T-SQL query editors.</li>
				<li>Code-free data transformation tool, if you prefer not to write your own code.</li>
				<li>Monitor, secure, and manage your workspaces without leaving the environment.</li>
				<li>Web-based development experience for the entire analytics solution.</li>
				<li>The backup and restore feature in the Azure Synapse SQL pool allows restore points to be created to make it easy to recover or copy a data warehouse to a previous state.</li>
				<li>The ability to run concurrent T-SQL queries through SQL pools across petabytes of data to serve BI tools and applications.</li>
				<li>SQL on-demand provides serverless SQL queries for ease of exploration and data analysis in Azure Data Lake Storage without any setup or maintenance of infrastructure.</li>
				<li>Meets the full range of analytics needs, from data engineering to data science, using a variety of languages, such as Python, Scala, C#, and Spark SQL.</li>
				<li>Spark pools, which alleviate the complex setup and maintenance of clusters and simplify the development of Spark applications and usage of Spark notebooks.</li>
				<li>Offers deep integration between Spark and SQL, allowing data engineers to prepare data in Spark, write the processed results in SQL Pool, and use any combination of Spark with SQL for data engineering and analysis, with built-in support for Azure Machine Learning.</li>
				<li>Highly scalable, hybrid data integration capability that accelerates data ingestion and operationalization through automated data pipelines.</li>
				<li>Provides a friction-free integrated service with unified security, deployment, monitoring, and billing.</li>
			</ul>
			<p><strong class="bold">Platform</strong></p>
			<ul>
				<li>Supports both provisioned and serverless compute. Examples of provisioned compute include SQL compute and Spark compute.</li>
				<li>Provisioned compute allows teams to segment their compute resources so that they can control cost and usage to better align with their organizational structure.</li>
				<li>Serverless compute, on the other hand, allows teams to use the service on-demand without provisioning or managing any underlying infrastructure.</li>
				<li>Deep integration between Spark and SQL engines.</li>
			</ul>
			<p>In the following section, we will cover the other features of Azure Synapse, including Apache Spark for Synapse, Synapse SQL, SQL on-demand, Synapse pipelines, and Azure Synapse Link for Cosmos DB.</p>
			<h3 id="_idParaDest-434"><a id="_idTextAnchor452"/>Apache Spark for Synapse</h3>
			<p>For customers who want Apache Spark, Azure Synapse has first-party support through Azure Databricks and is fully managed by Azure. The latest version of Apache Spark will automatically be made available to users, along with all security patches. You can quickly create notebooks with your choice of language, such as Python, Scala, Spark SQL, and .NET for Spark.</p>
			<p>If you use Spark within Azure Synapse Analytics, it is provided as a Software as a Service offering. For example, you can use Spark without setting up or managing your own services, such as a virtual network. Azure Synapse Analytics will take care of the underlying infrastructure for you. This allows you to use Spark immediately in your Azure Synapse Analytics environment.</p>
			<p>In the next section, we will explore Synapse SQL.</p>
			<h3 id="_idParaDest-435"><a id="_idTextAnchor453"/>Synapse SQL</h3>
			<p>Synapse SQL allows the use of T-SQL to query and analyze data. There are two models to choose from:</p>
			<ol>
				<li value="1">Fully provisioned model</li>
				<li>SQL on-demand (serverless) model</li>
			</ol>
			<p><strong class="bold">SQL on-demand</strong></p>
			<p>SQL on-demand provides serverless SQL queries. This allows easier exploration and data analysis in Azure Data Lake Storage without any setup or infrastructure maintenance:</p>
			<div>
				<div id="_idContainer426" class="IMG---Figure">
					<img src="image/Table_18.1.jpg" alt="Comparing different IT infrastructures"/>
				</div>
			</div>
			<h6>Table 18.1: Comparison between different infrastructures</h6>
			<p><strong class="bold">Key Features:</strong></p>
			<ul>
				<li>Analysts can focus on analyzing the data without worrying about managing any infrastructure.</li>
				<li>Customers can benefit from a simple and flexible pricing model, as they only pay for what they use.</li>
				<li>It uses the familiar T-SQL language syntax and the best SQL Query Optimizer on the market. The SQL Query Optimizer is the brain behind the query engine.</li>
				<li>You can easily scale your compute and storage, independently of one another, as your needs grow.</li>
				<li>Seamlessly integrate with SQL Analytics Pool and Spark via metadata sync and native connectors.</li>
			</ul>
			<h3 id="_idParaDest-436"><a id="_idTextAnchor454"/>Synapse pipelines</h3>
			<p>Synapse pipelines allow developers to build end-to-end workflows for data movement and data processing scenarios. Azure Synapse Analytics uses the <strong class="bold">Azure Data Factory</strong> (<strong class="bold">ADF</strong>) technology to provide data integration features. The key features of ADF that are essential to the modern data warehouse pipeline are available in Azure Synapse Analytics. All these features are wrapped with a common security model, <strong class="bold">Role-Based Access Control</strong> (<strong class="bold">RBAC</strong>), in the Azure Synapse Analytics workspace.</p>
			<p><em class="italics">Figure 18.3</em> shows an example of a data pipeline and the activities from ADF that are directly integrated inside the Azure Synapse Analytics environment:</p>
			<div>
				<div id="_idContainer427" class="IMG---Figure">
					<img src="image/B15432_18_03.jpg" alt="Data pipeline and activities in Azure Synapse Analytics"/>
				</div>
			</div>
			<h6>Figure 18.3: Data pipelines in Azure Synapse Analytics</h6>
			<p><strong class="bold">Key Features:</strong></p>
			<ul>
				<li>Integrated platform services for management, security, monitoring, and metadata management.</li>
				<li>Native integration between Spark and SQL. Use a single line of code to read and write with Spark from/into SQL analytics.</li>
				<li>The ability to create a Spark table and query it instantaneously with SQL Analytics without defining a schema.</li>
				<li>"Key-free" environment. With Single Sign-On and Azure Active Directory pass-through, no key or login is needed to interact with <strong class="bold">Azure Data Lake Storage</strong> (<strong class="bold">ADLS</strong>)/databases.</li>
			</ul>
			<p>In the next section, we will cover Azure Synapse Link for Cosmos DB.</p>
			<h3 id="_idParaDest-437"><a id="_idTextAnchor455"/>Azure Synapse Link for Cosmos DB</h3>
			<p>Azure Synapse Link is a cloud-native version of HTAP. It is an extension of Azure Synapse. As we have learned earlier, Azure Synapse is a single managed service for performing analytics over data lakes and data warehouses, using both serverless and provisioned compute. With Azure Synapse Link, this reach can be extended to operational data sources as well.</p>
			<p>Azure Synapse Link eliminates the bottleneck that is found in traditional operational and analytical systems. Azure Synapse makes this possible by separating compute from storage across all of its data services. On the transactional side, Cosmos DB is a high-performance, geo-replicated, multi-model database service. On the analytics side, Azure Synapse provides limitless scalability. You can scale the resources for transactions and for analytics independently. Together, this makes cloud-native HTAP a reality. As soon as the user indicates what data in Cosmos DB they wish to make available for analytics, the data becomes available in Synapse. It takes the operational data you wish to analyze and automatically maintains an analytics-oriented columnar version of it. As a result, any changes to the operational data in Cosmos DB are continuously updated to the Link data and Synapse.</p>
			<p>The biggest benefit of using Azure Synapse Link is that it alleviates the need for scheduled batch processing or having to build and maintain operational pipelines.</p>
			<p>As mentioned previously, Azure Synapse is the most chosen platform by architects for migrating existing legacy data warehouse solutions to a modern enterprise analytics solution. In the next section, we will discuss common architectural considerations for migrating from an existing legacy data warehouse solution to Azure Synapse Analytics.</p>
			<h2 id="_idParaDest-438"><a id="_idTextAnchor456"/>Migrating from existing legacy systems to Azure Synapse Analytics</h2>
			<p>Today, many organizations are migrating their legacy data warehouse solutions to Azure Synapse Analytics to gain the benefits of the high availability, security, speed, scalability, cost savings, and performance of Azure Synapse.</p>
			<p>For companies running legacy data warehouse systems such as Netezza, the situation is even more dire because IBM has announced the end of support for Netezza (<a href="https://www.ibm.com/support/pages/end-support-dates-netezza-5200-netezza-8x50z-series-and-netezza-10000-series-appliances">https://www.ibm.com/support/pages/end-support-dates-netezza-5200-netezza-8x50z-series-and-netezza-10000-series-appliances</a>).</p>
			<p>Many decades ago, some companies chose Netezza to manage and analyze large volumes of data. Today, as technologies evolve, the benefits of having a cloud-based data warehouse solution far outweigh the on-premises counterparts. Azure Synapse is a limitless cloud-based analytics service with unmatched time to insight that accelerates the delivery of BI, AI, and intelligent applications for enterprises. With its multi-cluster and separate compute and storage architecture, Azure Synapse can be scaled instantly in ways not possible with legacy systems such as Netezza.</p>
			<p>This section covers the architectural considerations and high-level methodology for planning, preparing, and executing a successful migration of an existing legacy data warehouse system to Azure Synapse Analytics. Whenever appropriate, specific examples and references to Netezza will be given. This chapter is not intended to be a comprehensive step-by-step manual for migration, but rather a practical overview to help with your migration planning and project scoping.</p>
			<p>This chapter also identifies some of the common migration issues and possible resolutions. It also provides technical details on the differences between Netezza and Azure Synapse Analytics. They should be taken into consideration as part of your migration plan.</p>
			<h3 id="_idParaDest-439"><a id="_idTextAnchor457"/>Why you should migrate your legacy data warehouse to Azure Synapse Analytics</h3>
			<p>By migrating to Azure Synapse Analytics, companies with legacy data warehouse systems can take advantage of the latest innovations in cloud technologies and delegate tasks such as infrastructure maintenance and platform upgrading to Azure.</p>
			<p>Customers who have migrated to Azure Synapse are already reaping many of its benefits, including the following.</p>
			<p><strong class="bold">Performance</strong></p>
			<p>Azure Synapse Analytics offers best-of-breed relational database performance by using techniques such as <strong class="bold">Massively Parallel Processing</strong> (<strong class="bold">MPP</strong>) and automatic in-memory caching. For more information, please review the Azure Synapse Analytics architecture (<a href="https://docs.microsoft.com/azure/synapse-analytics/sql-data-warehouse/massively-parallel-processing-mpp-architecture">https://docs.microsoft.com/azure/synapse-analytics/sql-data-warehouse/massively-parallel-processing-mpp-architecture</a>).</p>
			<p><strong class="bold">Speed</strong></p>
			<p>Data warehousing is process intensive. It involves data ingestion, transforming data, cleansing data, aggregating data, integrating data, and producing data visualization and reports. The many processes involved in moving data from original sources to a data warehouse are complex and interdependent. A single bottleneck can slow the entire pipeline and an unexpected spike in data volume amplifies the need for speed. When timeliness of data matters, Azure Synapse Analytics meets the demand for fast processing.</p>
			<p><strong class="bold">Improved security and compliance</strong></p>
			<p>Azure is a globally available, highly scalable, secure cloud platform. It offers many security features, including Azure Active Directory, RBAC, managed identities, and managed private endpoints. Azure Synapse Analytics, which resides inside the Azure ecosystem, inherits all of the aforementioned benefits.</p>
			<p><strong class="bold">Elasticity and cost efficiencies</strong></p>
			<p>In a data warehouse, the demands for workload processing can fluctuate. At times, these fluctuations can vary drastically between peaks and valleys. For example, sudden spikes in sales data volumes can occur during holiday seasons. Cloud elasticity allows Azure Synapse to quickly increase and decrease its capacity according to demand with no impact upon infrastructure availability, stability, performance, and security. Best of all, you only pay for your actual usage.</p>
			<p><strong class="bold">Managed infrastructure</strong></p>
			<p>Eliminating the overhead of data center management and operations for the data warehouse allows companies to reallocate valuable resources to where value is produced and focus on using the data warehouse to deliver the best information and insight. This lowers the overall total cost of ownership and provides better cost control over your operating expenses.</p>
			<p><strong class="bold">Scalability</strong></p>
			<p>The volume of data in a data warehouse typically grows as time passes and as history is collected. Azure Synapse Analytics can scale to match this growth by incrementally adding resources as data and workload increase.</p>
			<p><strong class="bold">Cost savings</strong></p>
			<p>Running an on-premises legacy datacenter is expensive (considering the costs of servers and hardware, networking, physical room space, electricity, cooling, and staffing). These expenses can be substantially minimized with Azure Synapse Analytics. With the separation of the compute and storage layers, Azure Synapse offers a very lucrative price-performance ratio.</p>
			<p>Azure Synapse Analytics provides you with true pay-as-you-go cloud scalability without the need for complicated reconfiguration as your data or workloads grow.</p>
			<p>Now that you have learned why it is beneficial to migrate to Azure Synapse Analytics, we will begin our discussion of the migration process.</p>
			<h3 id="_idParaDest-440"><a id="_idTextAnchor458"/>The three-step migration process</h3>
			<p>A successful data migration project starts with a well-designed plan. An effective plan accounts for the many components that need to be considered, paying particular attention to architecture and data preparation. The following is the three-step migration process plan.</p>
			<p><strong class="bold">Preparation</strong></p>
			<ul>
				<li>Define the scope of what is to be migrated.</li>
				<li>Build an inventory of data and processes for migration.</li>
				<li>Define the data model changes (if any).</li>
				<li>Define the source data extraction mechanism.</li>
				<li>Identify suitable Azure (and third-party) tools and services to be used.</li>
				<li>Train staff early on the new platform.</li>
				<li>Set up the Azure target platform.</li>
			</ul>
			<p><strong class="bold">Migration</strong></p>
			<ul>
				<li>Start small and simple.</li>
				<li>Automate wherever possible.</li>
				<li>Leverage Azure built-in tools and features to reduce migration effort.</li>
				<li>Migrate metadata for tables and views.</li>
				<li>Migrate historical data to be maintained.</li>
				<li>Migrate or refactor stored procedures and business processes.</li>
				<li>Migrate or refactor ETL/ELT incremental load processes.</li>
			</ul>
			<p><strong class="bold">Post-migration</strong></p>
			<ul>
				<li>Monitor and document all stages of the process.</li>
				<li>Use the experience gained to build a template for future migrations.</li>
				<li>Re-engineer the data model if required.</li>
				<li>Test applications and query tools.</li>
				<li>Benchmark and optimize query performance.</li>
			</ul>
			<p>Next, we will talk about the two types of migration strategies.</p>
			<h3 id="_idParaDest-441"><a id="_idTextAnchor459"/>The two types of migration strategies</h3>
			<p>Architects should begin migration planning by assessing the existing data warehouse to determine which migration strategy works best for their situation. There are two types of migration strategies to consider.</p>
			<p><strong class="bold">Lift and Shift strategy</strong></p>
			<p>For the lift and shift strategy, the existing data model is migrated unchanged to the new Azure Synapse Analytics platform. This is done to minimize the risk and the time required for migration by reducing the scope of changes to the minimum.</p>
			<p>Lift and shift is a good strategy for legacy data warehouse environments such as Netezza where any one of the following conditions applies:</p>
			<ul>
				<li>A single data mart is to be migrated.</li>
				<li>The data is already in a well-designed star or snowflake schema.</li>
				<li>There are immediate time and cost pressures to move to a modern cloud environment.</li>
			</ul>
			<p><strong class="bold">Redesign strategy</strong></p>
			<p>In scenarios where the legacy data warehouse has evolved over time, it might be essential to re-engineer it to maintain the optimum performance levels or support new types of data. This could include a change in the underlying data model.</p>
			<p>To minimize risk, it is recommended to migrate first using the lift and shift strategy and then gradually modernize the data warehouse data model on Azure Synapse Analytics using the redesign strategy. A complete change in data model will increase risks because it will impact source-to-data warehouse ETL jobs and downstream data marts.</p>
			<p>In the next section, we will offer some recommendations on how to reduce the complexity of your existing legacy data warehouse before migrating.</p>
			<h3 id="_idParaDest-442"><a id="_idTextAnchor460"/>Reducing the complexity of your existing legacy data warehouse before migrating</h3>
			<p>In the previous section, we presented the two migration strategies. As a best practice, during the initial assessment step, be cognizant of any ways to simplify your existing data warehouse and document them. The goal is to reduce the complexity of your existing legacy data warehouse system before the migration to make the migration process easier.</p>
			<p>Here are some recommendations on how to reduce the complexity of your existing legacy data warehouse:</p>
			<ul>
				<li><strong class="bold">Remove and archive unused tables before migrating</strong>: Avoid migrating data that is no longer in use. This will help reduce the overall data volume to migrate.</li>
				<li><strong class="bold">Convert physical data marts to virtual data marts</strong>: Minimize what you have to migrate, reduce the total cost of ownership, and improve agility.</li>
			</ul>
			<p>In the next section, we will take a closer look at why you should consider converting a physical data mart to a virtual data mart.</p>
			<h3 id="_idParaDest-443"><a id="_idTextAnchor461"/>Converting physical data marts to virtual data marts</h3>
			<p>Prior to migrating your legacy data warehouse, consider converting your current physical data marts to virtual data marts. By using virtual data marts, you can eliminate physical data stores and ETL jobs for data marts without losing any functionality prior to migration. The goal here is to reduce the number of data stores to migrate, reduce copies of data, reduce the total cost of ownership, and improve agility. To achieve this, you will need to switch from physical to virtual data marts before migrating your data warehouse. We can consider this as a data warehouse modernization step prior to migration.</p>
			<p><strong class="bold">Disadvantages of physical data marts</strong></p>
			<ul>
				<li>Multiple copies of the same data</li>
				<li>Higher total cost of ownership</li>
				<li>Difficult to change as ETL jobs are impacted</li>
			</ul>
			<p><strong class="bold">Advantages of virtual data marts</strong></p>
			<ul>
				<li>Simplifies data warehouse architecture</li>
				<li>No need to store copies of data</li>
				<li>More agility</li>
				<li>Lower total cost of ownership</li>
				<li>Uses pushdown optimization to leverage the power of Azure Synapse Analytics</li>
				<li>Easy to change</li>
				<li>Easy to hide sensitive data</li>
			</ul>
			<p>In the next section, we will talk about how to migrate existing data warehouse schemas to Azure Synapse Analytics.</p>
			<h3 id="_idParaDest-444">Migr<a id="_idTextAnchor462"/>ating existing data warehouse schemas to Azure Synapse Analytics</h3>
			<p>Migrating the schemas of an existing legacy data warehouse involves the migration of existing staging tables, legacy data warehouse, and dependent data mart schemas.</p>
			<p>To help you understand the magnitude and scope of your schema migration, we recommend that you create an inventory of your existing legacy data warehouse and data mart.</p>
			<p>Here is a checklist to help you collect the necessary information:</p>
			<ul>
				<li>Row counts</li>
				<li>Staging, data warehouse, and data mart data size: tables and indexes</li>
				<li>Data compression ratios</li>
				<li>Current hardware configuration</li>
				<li>Tables (including partitions): identify small dimension tables</li>
				<li>Data types</li>
				<li>Views</li>
				<li>Indexes</li>
				<li>Object dependencies</li>
				<li>Object usage</li>
				<li>Functions: both out-of-the-box functions and <strong class="bold">User-Defined Functions</strong> (<strong class="bold">UDFs</strong>)</li>
				<li>Stored procedures</li>
				<li>Scalability requirements</li>
				<li>Growth projections</li>
				<li>Workload requirements: Concurrent users</li>
			</ul>
			<p>With your inventory completed, you can now make decisions on scoping what schema you want to migrate. Essentially, there are four options for scoping your legacy data warehouse schema migration:</p>
			<ol>
				<li value="1">Migr<a id="_idTextAnchor463"/>ate one data mart at a time:<div id="_idContainer428" class="IMG---Figure"><img src="image/B15432_18_04.jpg" alt="Migrate one data mart at a time"/></div><h6>Figure 18.4: Migrating one data mart at a time</h6></li>
				<li>Migrate all data marts at once, then the data warehouse:<div id="_idContainer429" class="IMG---Figure"><img src="image/B15432_18_05.jpg" alt="Migrate all data marts at once, then the legacy data warehouse"/></div><h6>Figure 18.5: Migrating all data marts at once, then the data warehouse</h6></li>
				<li>Migrate both the data warehouse and the staging area:<div id="_idContainer430" class="IMG---Figure"><img src="image/B15432_18_06.jpg" alt="Migrate both the data warehouse and the staging area"/></div><h6>Figure 18.6: Migrating both the data warehouse and the staging area</h6></li>
				<li>Migrate everything at once:<div id="_idContainer431" class="IMG---Figure"><img src="image/B15432_18_07.jpg" alt="Migrating everything at once"/></div></li>
			</ol>
			<h6>Figure 18.7: Migrating everything at once</h6>
			<p>Keep in mind when choosing your option that the goal is to achieve a physical database design that will match or exceed your current legacy data warehouse system in performance and preferably at a lower cost.</p>
			<p>To recap, here are some of the recommendations for the schema migration:</p>
			<ul>
				<li>Avoid migrating unnecessary objects or processes.</li>
				<li>Consider using virtual data marts to reduce or eliminate the number of physical data marts.</li>
				<li>Automate whenever possible. Implementation of DataOps should be considered alongside the migration to Azure Synapse.</li>
				<li>Use metadata from system catalog tables in the legacy data warehouse system to generate <strong class="bold">Data Definition Language</strong> (<strong class="bold">DDL</strong>) for Azure Synapse Analytics.</li>
				<li>Perform any required data model changes or data mapping optimizations on Azure Synapse Analytics.</li>
			</ul>
			<p>In the next section, we will talk about how to migrate historical data from a legacy data warehouse to Azure Synapse Analytics.</p>
			<h3 id="_idParaDest-445"><a id="_idTextAnchor464"/>Migrating historical data from your legacy data warehouse to Azure Synapse Analytics</h3>
			<p>Once the schema migration scope has been determined, we are now ready to make decisions on how to migrate the historical data.</p>
			<p>The steps for migrating historical data are as follows:</p>
			<ol>
				<li value="1">Create target tables on Azure Synapse Analytics.</li>
				<li>Migrate existing historical data.</li>
				<li>Migrate functions and stored procedures as required.</li>
				<li>Migrate incremental load (ETL/ELT) staging and processes for incoming data.</li>
				<li>Apply any performance tuning options that are required.</li>
			</ol>
			<p><em class="italics">Table 18.2</em> outlines the four data migration options and their pros and cons:</p>
			<div>
				<div id="_idContainer432" class="IMG---Figure">
					<img src="image/Table_18.2.jpg" alt="Four data migration options and their pros and cons"/>
				</div>
			</div>
			<h6>Table 18.2: Data migration options with their pros and cons</h6>
			<p>In the next section, we will talk about how to migrate existing ETL processes to Azure Synapse Analytics.</p>
			<h3 id="_idParaDest-446"><a id="_idTextAnchor465"/>Migrating existing ETL processes to Azure Synapse Analytics</h3>
			<p>There are a number of options available for migrating your existing ETL processes to Azure Synapse Analytics. <em class="italics">Table 18.3</em> outlines some of the ETL migration options based on how the existing ETL jobs are built:</p>
			<div>
				<div id="_idContainer433" class="IMG---Figure">
					<img src="image/Table_18.3.jpg" alt="Options for migration ETL jobs in Azure Synapse"/>
				</div>
			</div>
			<h6>Table 18.3: ETL migration options</h6>
			<p>In the next section, we will talk about how to re-develop scalable ETL processes using ADF.</p>
			<h3 id="_idParaDest-447"><a id="_idTextAnchor466"/>Re-developing scalable ETL processes using ADF</h3>
			<p><a id="_idTextAnchor467"/>Another option for handling your existing legacy ETL processes is by re-developing them using ADF. ADF is an Azure data integration service for creating data-driven workflows (known as pipelines) to orchestrate and automate data movement and data transformation. You can use ADF to create and schedule pipelines to ingest data from different data stores. ADF can process and transform data by using compute services such as Spark, Azure Machine Learning, Azure HDInsight Hadoop, and Azure Data Lake Analytics:</p>
			<div>
				<div id="_idContainer434" class="IMG---Figure">
					<img src="image/Image74376.jpg" alt="Re-developing scalable ETL processes using Azure Data Factory"/>
				</div>
			</div>
			<h6>Figure 18.8: Re-developing scalable ETL processes using ADF</h6>
			<p>The next section will offer some recommendations for migrating queries, BI reports, dashboards, and other visualizations.</p>
			<h3 id="_idParaDest-448"><a id="_idTextAnchor468"/>Recommendations for migrating queries, BI reports, dashboards, and other visualizations</h3>
			<p>Migrating queries, BI reports, dashboards, and other visualizations from your legacy data warehouse to Azure Synapse Analytics is straightforward if the legacy system uses standard SQL. </p>
			<p>However, often, this is not the case. In this situation, a different strategy must be taken:</p>
			<ul>
				<li>Identify the high-priority reports to migrate first.</li>
				<li>Use usage statistics to identify the reports that are never used. </li>
				<li>Avoid migrating anything that is no longer in use.</li>
				<li>Once you have produced the list of reports to migrate, their priorities, and the unused reports to be bypassed, confirm this list with the stakeholders.</li>
				<li>For reports that you are migrating, identify incompatibilities early to gauge the migration effort.</li>
				<li>Consider data virtualization to protect BI tools and applications from structural changes to the data warehouse and/or data mart data model that might occur during the migration.</li>
			</ul>
			<h3 id="_idParaDest-449"><a id="_idTextAnchor469"/>Common migration issues and resolutions</h3>
			<p>During the migration process, you might encounter certain issues that you need to overcome. In this section, we will highlight some of the common issues and provide you with resolutions that you can implement.</p>
			<p><strong class="bold">I<a id="_idTextAnchor470"/>ssue #1: Unsupported data types and workarounds</strong></p>
			<p><em class="italics">Table 18.4 </em>shows the data types from legacy data warehouse systems that are unsupported, as well as the suitable workarounds for Azure Synapse Analytics:</p>
			<div>
				<div id="_idContainer435" class="IMG---Figure">
					<img src="image/Table_18.4.jpg" alt="Unsupported data types and suitable workarounds in Azure Synapse Analytics"/>
				</div>
			</div>
			<h6><a id="_idTextAnchor471"/>Table 18.4: Unsupported data types and suitable workarounds in Azure Synapse Analytics</h6>
			<p><strong class="bold">Issue #2: Data type differences between Netezza and Azure Synapse</strong></p>
			<p><em class="italics">Table 18.5</em> maps the Netezza data types to their Azure Synapse equivalent data types:</p>
			<div>
				<div id="_idContainer436" class="IMG---Figure">
					<img src="image/Table_18.5.jpg" alt="Netezza data types and their Azure Synapse equivalents"/>
				</div>
			</div>
			<h6><a id="_idTextAnchor472"/>Table 18.5: Netezza data types and their Azure Synapse equivalents</h6>
			<p><strong class="bold">Issue #3: Integrity constraint differences</strong></p>
			<p>Pay close attention to the integrity constraint differences between your legacy data warehouse or data mart and Azure Synapse Analytics. In <em class="italics">Figure 18.9</em>, the left side represents the old legacy data warehouse system with primary key and foreign key constraints, and on the right side is the new Azure Synapse Analytics environment:</p>
			<div>
				<div id="_idContainer437" class="IMG---Figure">
					<img src="image/Image74470.jpg" alt="Integrity constraint differences between legacy data warehouse/data mart and Azure Synapse"/>
				</div>
			</div>
			<h6>Figure 18.9: Integrity constraint differences</h6>
			<p>T<a id="_idTextAnchor473"/>he next sections will provide comprehensive coverage on how to resolve other common SQL incompatibilities during the migration from a legacy data warehouse to Azure Synapse Analytics.</p>
			<h2 id="_idParaDest-450">C<a id="_idTextAnchor474"/>ommon SQL incompatibilities and resolutions</h2>
			<p>This section will provide technical details regarding common SQL incompatibilities and resolutions between legacy data warehouse systems and Azure Synapse Analytics. The section will explain and compare the differences and provide resolutions using a quick-reference table that you can refer to later on as you embark on your migration project.</p>
			<p>The topics that we will cover are as follows:</p>
			<ul>
				<li>SQL <strong class="bold">Data Definition Language</strong> (<strong class="bold">DDL</strong>) differences and resolutions</li>
				<li>SQL <strong class="bold">Data Manipulation Language</strong> (<strong class="bold">DML</strong>) differences and resolutions</li>
				<li>SQL <strong class="bold">Data Control Language</strong> (<strong class="bold">DCL</strong>) differences and resolutions</li>
				<li>Extended SQL differences and workarounds</li>
			</ul>
			<h3 id="_idParaDest-451">S<a id="_idTextAnchor475"/>QL DDL differences and resolutions</h3>
			<p>In this section, we will discuss the differences and resolutions for SQL DDL between legacy data warehouse systems and Azure Synapse Analytics.</p>
			<div>
				<div id="_idContainer438" class="IMG---Figure">
					<img src="image/Table_18.6.jpg" alt="SQL DDL differences between legacy systems and Azure Synapse"/>
				</div>
			</div>
			<h6>Table 18.6: SQL DDL differences between legacy systems and Azure Synapse</h6>
			<h3 id="_idParaDest-452"><a id="_idTextAnchor476"/>SQL DML differences and resolutions</h3>
			<p>In this section, we will discuss the differences and resolutions for SQL DML between legacy data warehouse systems and Azure Synapse Analytics:</p>
			<div>
				<div id="_idContainer439" class="IMG---Figure">
					<img src="image/Table_18.7.jpg" alt="SQL DML differences between Netezza and Azure Synapse"/>
				</div>
			</div>
			<h6>Table 18.7: SQL DML differences between Netezza and Azure Synapse</h6>
			<p>Next, we will talk about the differences and resolutions of SQL DCL between legacy data warehouse systems and Azure Synapse Analytics.</p>
			<h3 id="_idParaDest-453"><a id="_idTextAnchor477"/>SQL DCL differences and resolutions</h3>
			<p>In this section, we will discuss the differences and resolutions for SQL DCL between legacy data warehouse systems and Azure Synapse Analytics. Netezza supports two classes of access rights: admin and object. <em class="italics">Table 18.8</em> map the Netezza access rights and their corresponding Azure Synapse equivalents for quick reference.</p>
			<p><strong class="bold">Mapping Netezza admin privileges to the Azure Synapse equivalents</strong></p>
			<p><em class="italics">Table 18.8</em> maps the Netezza admin privileges to the Azure Synapse equivalents:</p>
			<div>
				<div id="_idContainer440" class="IMG---Figure">
					<img src="image/Table_18.8A.jpg" alt="Netezza Admin Privileges and its Azure Synapse equivalent"/>
				</div>
			</div>
			<div>
				<div id="_idContainer441" class="IMG---Figure">
					<img src="image/Table_18.8B.jpg" alt="Netezza Admin Privileges and its Azure Synapse equivalent"/>
				</div>
			</div>
			<h6>Table 18.8: Netezza admin privileges and their Azure Synapse equivalents</h6>
			<p><strong class="bold">Mapping Netezza object privileges to their Azure Synapse equivalent</strong></p>
			<p><em class="italics">Table 18.9</em> maps the Netezza object privileges to the Azure Synapse equivalents for quick reference:</p>
			<div>
				<div id="_idContainer442" class="IMG---Figure">
					<img src="image/Table_18.9.jpg" alt="Netezza Object Privileges and its Azure Synapse equivalent"/>
				</div>
			</div>
			<h6><a id="_idTextAnchor478"/>Table 18.9: Netezza object privileges and their Azure Synapse equivalents</h6>
			<h3 id="_idParaDest-454"><a id="_idTextAnchor479"/>Extended SQL differences and workarounds</h3>
			<p><em class="italics">Table 18.10</em> describes the extended SQL differences and possible workarounds when migrating to Azure Synapse Analytics:</p>
			<div>
				<div id="_idContainer443" class="IMG---Figure">
					<img src="image/Table_18.10.jpg" alt="Extended SQL differences and workarounds to migrate to Azure Synapse"/>
				</div>
			</div>
			<h6>Table 18.10: Extended SQL differences and workarounds</h6>
			<p>In this section, we talked about common migration issues that architects might encounter during a migration project and possible solutions. In the next section, we will take a look at security considerations that an architect should be mindful of.</p>
			<h2 id="_idParaDest-455"><a id="_idTextAnchor480"/>Security considerations</h2>
			<p>Protecting and securing your data assets is paramount in any data warehouse system. When planning a data warehouse migration project, security, user access management, backup, and restore must also be taken into consideration. For instance, data encryption may be mandatory for industry and government regulations, such as HIPAA, PCI, and FedRAMP, as well as in non-regulated industries.</p>
			<p>Azure includes many features and functions as standard that would traditionally have to be custom-built in legacy data warehouse products. Azure Synapse supports data encryption at rest and data in motion as standard.</p>
			<h3 id="_idParaDest-456"><a id="_idTextAnchor481"/>Data encryption at rest</h3>
			<ul>
				<li><strong class="bold">Transparent Data Encryption</strong> (<strong class="bold">TDE</strong>) can be enabled to dynamically encrypt and decrypt Azure Synapse data, logs, and associated backups.</li>
				<li>Azure Data Storage can also automatically encrypt non-database data.</li>
			</ul>
			<h3 id="_idParaDest-457"><a id="_idTextAnchor482"/>Data in motion</h3>
			<p>All connections to Azure Synapse Analytics are encrypted by default, using industry-standard protocols such as TLS and SSH.</p>
			<p>In addition, <strong class="bold">Dynamic Data Masking</strong> (<strong class="bold">DDM</strong>) can be used to obfuscate data for given classes of users based on data masking rules.</p>
			<p>As a best practice, if your legacy data warehouse contains a complex hierarchy of permissions, users and roles, consider using automation techniques in your migration process. You can use existing metadata from your legacy system to generate the necessary SQL to migrate users, groups, and privileges on Azure Synapse Analytics.</p>
			<p>In the final section of this chapter, we will review some of the tools that architects can choose to help migrate from legacy data warehouse systems to Azure Synapse Analytics.</p>
			<h2 id="_idParaDest-458"><a id="_idTextAnchor483"/>Tools to help migrate to Azure Synapse Analytics</h2>
			<p>Now that we have covered the planning and preparation and an overview of the migration process, let's have a look at the tools that you can use for migrating your legacy data warehouse to Azure Synapse Analytics. The tools that we will discuss are:</p>
			<ul>
				<li>ADF</li>
				<li>Azure Data Warehouse Migration Utility</li>
				<li>Microsoft Services for Physical Data Transfer</li>
				<li>Microsoft Services for Data Ingestion</li>
			</ul>
			<p>Let's get started. </p>
			<h3 id="_idParaDest-459"><a id="_idTextAnchor484"/>ADF</h3>
			<p>ADF is a fully managed, pay-as-you-use, hybrid data integration service for cloud-scale ETL processing. It offers the following features:</p>
			<ul>
				<li>Processes and analyzes data in memory and in parallel to scale and maximize throughput</li>
				<li>Creates data warehouse migration pipelines that orchestrate and automate data movement, data transformation, and data loading into Azure Synapse Analytics</li>
				<li>Can also be used to modernize your data warehouse by ingesting data into Azure Data Lake, processing and analyzing data at scale, and loading data into a data warehouse</li>
				<li>Supports role-based user interfaces for mapping data flows for IT professionals and self-service data wrangling for business users</li>
				<li>Can connect to multiple data stores spanning datacenters, clouds, and SaaS applications</li>
				<li>Over 90 natively built and maintenance-free connectors available (<a href="https://azure.microsoft.com/services/data-factory">https://azure.microsoft.com/services/data-factory</a>)</li>
				<li>Can mix and match wrangling and mapping data flows in the same pipeline to prepare data at scale</li>
				<li>ADF orchestration can control data warehouse migration to Azure Synapse Analytics</li>
				<li>Can execute SSIS ETL packages</li>
			</ul>
			<h3 id="_idParaDest-460"><a id="_idTextAnchor485"/>Azure Data Warehouse Migration Utility</h3>
			<p>Azure Data Warehouse Migration Utility can migrate data from an on-premises SQL Server–based data warehouse to Azure Synapse. It offers the following features:</p>
			<ul>
				<li>Uses a wizard-like approach to perform a lift and shift migration of schema and data from an on-premises, SQL Server–based data warehouse.</li>
				<li>You can select the on-premises database containing the table(s) that you want to export to Azure Synapse. Then, you can select the tables that you want to migrate and migrate the schema. </li>
				<li>Automatically generates T-SQL code needed to create an equivalent empty database and tables on Azure Synapse. Once you provide connection details to Azure Synapse you can run the generated T-SQL to migrate the schema. </li>
				<li>Following schema creation, you can use the utility to migrate the data. This exports the data from your on-premises SQL Server–based data warehouse and generates <strong class="bold">Bulk Copy Program</strong> (<strong class="bold">BCP</strong>) commands to load that data into Azure Synapse.</li>
			</ul>
			<h3 id="_idParaDest-461"><a id="_idTextAnchor486"/>Microsoft Services for Physical Data Transfer</h3>
			<p>In this section, we will look at common Microsoft services that can be used for physical data transfer, including Azure ExpressRoute, AzCopy, and Azure Databox.</p>
			<p><strong class="bold">Azure ExpressRoute</strong></p>
			<p>Azure ExpressRoute allows you to make private connections between your datacenters and Azure without going over the public Internet. It offers the following features:</p>
			<ul>
				<li>Bandwidth of up to 100 Gbps</li>
				<li>Low latency</li>
				<li>Connects directly to your <strong class="bold">Wide-Area Network</strong> (<strong class="bold">WAN</strong>)</li>
				<li>Private connections to Azure</li>
				<li>Increased speed and reliability</li>
			</ul>
			<p><strong class="bold">AzCopy</strong></p>
			<p>AzCopy is a command-line tool for copying files and blobs to/from storage accounts. It offers the following features:</p>
			<ul>
				<li>Ability to copy data to/from Azure via the Internet.</li>
				<li>A combination of AzCopy with the necessary ExpressRoute bandwidth could be an optimal solution for data transfer to Azure Synapse.</li>
			</ul>
			<p><strong class="bold">Azure Data Box</strong></p>
			<p>Azure Data Box allows you to transfer large volumes of data to Azure quickly, reliably, and cost-effectively. It offers the following features:</p>
			<ul>
				<li>Capable of transferring large volumes of data (tens of terabytes to hundreds to terabytes)</li>
				<li>No network connectivity restrictions</li>
				<li>Great for one-time migration and initial bulk transfer</li>
			</ul>
			<h3 id="_idParaDest-462"><a id="_idTextAnchor487"/>Microsoft Services for data ingestion</h3>
			<p>In this section, we will look at common Microsoft services that can be used for data ingestion, including:</p>
			<ul>
				<li>PolyBase</li>
				<li>BCP</li>
				<li>SqlBulkCopy API</li>
				<li>Standard SQL</li>
			</ul>
			<p><strong class="bold">PolyBase</strong> (<strong class="bold">recommended method</strong>)</p>
			<p>PolyBase provides the fastest and most scalable bulk data loading into Azure Synapse Analytics. It offers the following features:</p>
			<ul>
				<li>Uses parallel loading to give the fastest throughput</li>
				<li>Can read from flat files in Azure Blob storage or from external data sources via connectors</li>
				<li>Tightly integrated with ADF</li>
				<li>CREATE TABLE AS or INSERT … SELECT</li>
				<li>Can define a staging table as type HEAP for fast load</li>
				<li>Support rows up to 1 MB in length</li>
			</ul>
			<p><strong class="bold">BCP</strong></p>
			<p>BCP can be used to import and export data from any SQL Server environment, including Azure Synapse Analytics. It offers the following features:</p>
			<ul>
				<li>Supports rows larger than 1 MB in length</li>
				<li>Originally developed for earlier versions of Microsoft SQL Server</li>
			</ul>
			<p>Refer to <a href="https://docs.microsoft.com/sql/tools/bcp-utility">https://docs.microsoft.com/sql/tools/bcp-utility</a> to read more about the BCP utility.</p>
			<p><strong class="bold">SqlBulkCopy API</strong></p>
			<p>SqlBulkCopy API is the API equivalent of the BCP functionality. It offers the following features:</p>
			<ul>
				<li>Allows the implementation of load processes programmatically</li>
				<li>Ability to bulk load SQL Server tables with data from selected sources</li>
			</ul>
			<p>Refer to <a href="https://docs.microsoft.com/dotnet/api/system.data.sqlclient.sqlbulkcopy">https://docs.microsoft.com/dotnet/api/system.data.sqlclient.sqlbulkcopy</a> to read more about this API.</p>
			<p><strong class="bold">Standard SQL Support</strong></p>
			<p>Azure Synapse Analytics supports standard SQL, including the ability to:</p>
			<ul>
				<li>Load individual rows or results of <strong class="inline">SELECT</strong> statements into data warehouse tables.</li>
				<li>Bulk insert data from extracted data via external data sources into data warehouse tables using <strong class="inline">INSERT … SELECT</strong> statements within PolyBase.</li>
			</ul>
			<p>This section provided the architectural considerations and high-level methodology for planning, preparing, and executing a successful migration of an existing legacy data warehouse system to Azure Synapse Analytics. It contains a wealth of information that you can refer to later on as you embark on your migration project to Azure Synapse Analytics.</p>
			<h2 id="_idParaDest-463"><a id="_idTextAnchor488"/>Summary</h2>
			<p>Azure Synapse Analytics is a limitless analytics service with unmatched time to insight that accelerates the delivery of BI, AI, and intelligent applications for enterprises. You will gain a lot of benefits by migrating your legacy data warehouse to Azure Synapse Analytics, including performance, speed, improved security and compliance, elasticity, managed infrastructure, scalability, and cost savings.</p>
			<p>With Azure Synapse, data professionals of varying skillsets can collaborate, manage, and analyze their most important data with ease—all within the same service. From Apache Spark integration with the powerful and trusted SQL engine, to code-free data integration and management, Azure Synapse is built for every data professional.</p>
			<p>This chapter provided the architectural considerations and high-level methodology needed to prepare for and execute the migration of an existing legacy data warehouse system to Azure Synapse Analytics.</p>
			<p>Successful data migration projects start with a well-designed plan. An effective plan accounts for the many components that need to be considered, paying particular attention to architecture and data preparation.</p>
			<p>After you have successfully migrated to Azure Synapse, you can explore additional Microsoft technologies in the rich Azure analytical ecosystem to further modernize your data warehouse architecture.</p>
			<p>Here are some ideas to ponder:</p>
			<ul>
				<li>Offload your staging areas and ELT processing to Azure Data Lake and ADF.</li>
				<li>Build trusted data products once in common data model format and consume everywhere—not just in your data warehouse.</li>
				<li>Enable collaborative development of data preparation pipelines by business and IT using ADF mapping and wrangling data flows.</li>
				<li>Build analytical pipelines in ADF to analyze data in batch and real time.</li>
				<li>Build and deploy machine learning models to add additional insights to what you already know.</li>
				<li>Integrate your data warehouse with live streaming data.</li>
				<li>Simplify access to data and insights in multiple Azure analytical data stores by creating a logical data warehouse using PolyBase.</li>
			</ul>
			<p>In the next chapter, you will learn in detail about Azure Cognitive Services, with a focus on architecting solutions that include intelligence as their core engine.</p>
		</div>
	</body></html>