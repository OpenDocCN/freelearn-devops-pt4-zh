- en: 18\. Azure Synapse Analytics for architects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Azure Synapse Analytics is a groundbreaking evolution of Azure SQL Data Warehouse.
    Azure Synapse is a fully managed, integrated data analytics service that blends
    data warehousing, data integration, and big data processing with accelerating
    time to insight to form a single service.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will explore Azure Synapse Analytics by covering the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of Azure Synapse Analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to Synapse workspaces and Synapse Studio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Migrating from existing legacy systems to Azure Synapse Analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Migrating existing data warehouse schemas and data to Azure Synapse Analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Re-developing scalable ETL processes using Azure Data Factory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common migration issues and resolutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security considerations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tools to help migrate to Azure Synapse Analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Synapse Analytics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Nowadays, with inexpensive storage and high elastic storage capacities, organizations
    are amassing more data than ever before. Architecting a solution to analyze such
    massive volumes of data to deliver meaningful insights about a business can be
    a challenge. One obstacle that many businesses face is the need to manage and
    maintain two types of analytics systems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data warehouses**: These provide critical insights about the business.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data lakes**: These provide meaningful insights about customers, products,
    employees, and processes through various analytics methodologies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these analytics systems are critical to businesses, yet they operate
    independently of one another. Meanwhile, businesses need to gain insights from
    all their organizational data in order to stay competitive and to innovate processes
    to obtain better results.
  prefs: []
  type: TYPE_NORMAL
- en: 'For architects who need to build their own end-to-end data pipelines, the following
    steps must be taken:'
  prefs: []
  type: TYPE_NORMAL
- en: Ingest data from various data sources.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load all these data sources into a data lake for further processing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform data cleaning over a range of different data structures and types.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prepare, transform, and model the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Serve the cleansed data to thousands of users through BI tools and applications.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Until now, each of these steps has required a different tool. Needless to say,
    with so many different services, applications, and tools available on the market,
    choosing the best-suited ones can be a daunting task.
  prefs: []
  type: TYPE_NORMAL
- en: There are numerous services available for ingesting, loading, preparing, and
    serving data. There are countless services for data cleansing based on the developer's
    language of choice. Furthermore, some developers might prefer to use SQL, some
    might want to use Spark, while others might prefer to use code-free environments
    to transform data.
  prefs: []
  type: TYPE_NORMAL
- en: Even after the seemingly proper collection of tools has been selected, there
    is often a steep learning curve for these tools. Additionally, architects could
    encounter unexpected logistical challenges in maintaining a data pipeline over
    dissimilar platforms and languages due to incompatibilities. With such a range
    of issues, implementing and maintaining a cloud-based analytics platform can be
    a difficult task.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Synapse Analytics solves these problems and more. It simplifies the entire
    modern data warehouse pattern, allowing architects to focus on building end-to-end
    analytics solutions within a unified environment.
  prefs: []
  type: TYPE_NORMAL
- en: A common scenario for architects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the most common scenarios that an architect faces is having to conjure
    up a plan for migrating existing legacy data warehouse solutions to a modern enterprise
    analytics solution. With its limitless scalability and unified experience, Azure
    Synapse has become one of the top choices for many architects to consider. Later
    in this chapter, we will also discuss common architectural considerations for
    migrating from an existing legacy data warehouse solution to Azure Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will provide a technical overview of the key features
    of Azure Synapse Analytics. Architects who are new to the Azure Synapse ecosystem
    will gain the necessary knowledge about Synapse after reading this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: An overview of Azure Synapse Analytics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure Synapse Analytics enables data professionals to build end-to-end analytics
    solutions while leveraging a unified experience. It delivers rich functionalities
    for SQL developers, serverless on-demand querying, machine learning support, the
    ability to embed Spark natively, collaborative notebooks, and data integration
    within a single service. Developers can choose from a variety of supported languages
    (for example, C#, SQL, Scala, and Python) through different engines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the main capabilities of Azure Synapse Analytics include:'
  prefs: []
  type: TYPE_NORMAL
- en: SQL Analytics with pools (fully provisioned) and on-demand (serverless).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spark with full support for Python, Scala, C#, and SQL.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Flow with code-free big data transformation experience.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data integration and orchestration to integrate data and operationalize code
    development.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A cloud-native version of **Hybrid Transactional/Analytical Processing** (**HTAP**),
    delivered by Azure Synapse Link.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To access all of the aforementioned capabilities, Azure Synapse Studio provides
    a single unified web UI.
  prefs: []
  type: TYPE_NORMAL
- en: This single integrated data service is advantageous to enterprises as it accelerates
    the delivery of BI, AI, machine learning, Internet of Things, and intelligent
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Synapse Analytics can derive and deliver insights from all your data residing
    in the data warehouse and big data analytics systems at lightning-fast speeds.
    It enables data professionals to use familiar languages, such as SQL, to query
    both relational and non-relational databases at petabyte scale. In addition, advanced
    features such as limitless concurrency, intelligent workload management, and workload
    isolation help optimize the performance of all queries for mission-critical workloads.
  prefs: []
  type: TYPE_NORMAL
- en: What is workload isolation?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One of the key features of running enterprise data warehouses at scale is workload
    isolation. This is the ability to guarantee resource reservations within a compute
    cluster so that multiple teams can work on the data without getting in each other''s
    way, as illustrated in *Figure 18.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Workload isolation in Azure](img/B15432_18_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.1: Example of workload isolation'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can create workload groups within a cluster by setting a couple of simple
    thresholds. These are automatically adjusted depending on the workload and the
    cluster, but they always guarantee a quality experience for users running the
    workloads. Refer to [https://techcommunity.microsoft.com/t5/data-architecture-blog/configuring-workload-isolation-in-azure-synapse-analytics/ba-p/1201739](https://techcommunity.microsoft.com/t5/data-architecture-blog/configuring-workload-isolation-in-azure-synapse-analytics/ba-p/1201739)
    to read more about configuring workload isolation in Azure Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: To fully appreciate the benefits of Azure Synapse, we will first take a look
    at Synapse workspaces and Synapse Studio.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Synapse workspaces and Synapse Studio
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At the heart of Azure Synapse is the workspace. The workspace is the top-level
    resource that comprises your analytics solution in a data warehouse. The Synapse
    workspace supports both relational and big data processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure Synapse provides a unified web UI experience for data preparation, data
    management, data warehousing, big data analytics, BI, and AI tasks known as Synapse
    Studio. Together with Synapse workspaces, Synapse Studio is an ideal environment
    for data engineers and data scientists to share and collaborate their analytics
    solutions, as shown in *Figure 18.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Azure Synapse workspace and its services](img/B15432_18_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.2: A Synapse workspace in Azure Synapse Studio'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The following sections highlight the capabilities, key features, platform details,
    and end user services of Synapse workspaces and Synapse Studio:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Capabilities:**'
  prefs: []
  type: TYPE_NORMAL
- en: A fast, highly elastic, and secure data warehouse with industry-leading performance
    and security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to explore Azure Data Lake Storage and data warehouses using familiar
    T-SQL syntax using SQL on-demand (serverless) and SQL queries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Spark integrated with Azure Machine Learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hybrid data integration to accelerate data ingestion and the operationalization
    of the analytics process (ingest, prepare, transform, and serve)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Business report generation and serving with Power BI integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Key features:**'
  prefs: []
  type: TYPE_NORMAL
- en: Create and operationalize pipelines for data ingestion and orchestration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Directly explore data in your Azure Data Lake Storage or data warehouse, as
    well as any external connections to the workspace, using Synapse Studio.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write code using notebooks and T-SQL query editors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code-free data transformation tool, if you prefer not to write your own code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitor, secure, and manage your workspaces without leaving the environment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web-based development experience for the entire analytics solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The backup and restore feature in the Azure Synapse SQL pool allows restore
    points to be created to make it easy to recover or copy a data warehouse to a
    previous state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to run concurrent T-SQL queries through SQL pools across petabytes
    of data to serve BI tools and applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQL on-demand provides serverless SQL queries for ease of exploration and data
    analysis in Azure Data Lake Storage without any setup or maintenance of infrastructure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meets the full range of analytics needs, from data engineering to data science,
    using a variety of languages, such as Python, Scala, C#, and Spark SQL.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spark pools, which alleviate the complex setup and maintenance of clusters and
    simplify the development of Spark applications and usage of Spark notebooks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Offers deep integration between Spark and SQL, allowing data engineers to prepare
    data in Spark, write the processed results in SQL Pool, and use any combination
    of Spark with SQL for data engineering and analysis, with built-in support for
    Azure Machine Learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highly scalable, hybrid data integration capability that accelerates data ingestion
    and operationalization through automated data pipelines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provides a friction-free integrated service with unified security, deployment,
    monitoring, and billing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Platform**'
  prefs: []
  type: TYPE_NORMAL
- en: Supports both provisioned and serverless compute. Examples of provisioned compute
    include SQL compute and Spark compute.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provisioned compute allows teams to segment their compute resources so that
    they can control cost and usage to better align with their organizational structure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serverless compute, on the other hand, allows teams to use the service on-demand
    without provisioning or managing any underlying infrastructure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep integration between Spark and SQL engines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following section, we will cover the other features of Azure Synapse,
    including Apache Spark for Synapse, Synapse SQL, SQL on-demand, Synapse pipelines,
    and Azure Synapse Link for Cosmos DB.
  prefs: []
  type: TYPE_NORMAL
- en: Apache Spark for Synapse
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For customers who want Apache Spark, Azure Synapse has first-party support through
    Azure Databricks and is fully managed by Azure. The latest version of Apache Spark
    will automatically be made available to users, along with all security patches.
    You can quickly create notebooks with your choice of language, such as Python,
    Scala, Spark SQL, and .NET for Spark.
  prefs: []
  type: TYPE_NORMAL
- en: If you use Spark within Azure Synapse Analytics, it is provided as a Software
    as a Service offering. For example, you can use Spark without setting up or managing
    your own services, such as a virtual network. Azure Synapse Analytics will take
    care of the underlying infrastructure for you. This allows you to use Spark immediately
    in your Azure Synapse Analytics environment.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explore Synapse SQL.
  prefs: []
  type: TYPE_NORMAL
- en: Synapse SQL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Synapse SQL allows the use of T-SQL to query and analyze data. There are two
    models to choose from:'
  prefs: []
  type: TYPE_NORMAL
- en: Fully provisioned model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: SQL on-demand (serverless) model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**SQL on-demand**'
  prefs: []
  type: TYPE_NORMAL
- en: 'SQL on-demand provides serverless SQL queries. This allows easier exploration
    and data analysis in Azure Data Lake Storage without any setup or infrastructure
    maintenance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Comparing different IT infrastructures](img/Table_18.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 18.1: Comparison between different infrastructures'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Key Features:**'
  prefs: []
  type: TYPE_NORMAL
- en: Analysts can focus on analyzing the data without worrying about managing any
    infrastructure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customers can benefit from a simple and flexible pricing model, as they only
    pay for what they use.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It uses the familiar T-SQL language syntax and the best SQL Query Optimizer
    on the market. The SQL Query Optimizer is the brain behind the query engine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can easily scale your compute and storage, independently of one another,
    as your needs grow.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seamlessly integrate with SQL Analytics Pool and Spark via metadata sync and
    native connectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synapse pipelines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Synapse pipelines allow developers to build end-to-end workflows for data movement
    and data processing scenarios. Azure Synapse Analytics uses the **Azure Data Factory**
    (**ADF**) technology to provide data integration features. The key features of
    ADF that are essential to the modern data warehouse pipeline are available in
    Azure Synapse Analytics. All these features are wrapped with a common security
    model, **Role-Based Access Control** (**RBAC**), in the Azure Synapse Analytics
    workspace.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 18.3* shows an example of a data pipeline and the activities from ADF
    that are directly integrated inside the Azure Synapse Analytics environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Data pipeline and activities in Azure Synapse Analytics](img/B15432_18_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.3: Data pipelines in Azure Synapse Analytics'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Key Features:**'
  prefs: []
  type: TYPE_NORMAL
- en: Integrated platform services for management, security, monitoring, and metadata
    management.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Native integration between Spark and SQL. Use a single line of code to read
    and write with Spark from/into SQL analytics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to create a Spark table and query it instantaneously with SQL Analytics
    without defining a schema.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '"Key-free" environment. With Single Sign-On and Azure Active Directory pass-through,
    no key or login is needed to interact with **Azure Data Lake Storage** (**ADLS**)/databases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will cover Azure Synapse Link for Cosmos DB.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Synapse Link for Cosmos DB
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure Synapse Link is a cloud-native version of HTAP. It is an extension of
    Azure Synapse. As we have learned earlier, Azure Synapse is a single managed service
    for performing analytics over data lakes and data warehouses, using both serverless
    and provisioned compute. With Azure Synapse Link, this reach can be extended to
    operational data sources as well.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Synapse Link eliminates the bottleneck that is found in traditional operational
    and analytical systems. Azure Synapse makes this possible by separating compute
    from storage across all of its data services. On the transactional side, Cosmos
    DB is a high-performance, geo-replicated, multi-model database service. On the
    analytics side, Azure Synapse provides limitless scalability. You can scale the
    resources for transactions and for analytics independently. Together, this makes
    cloud-native HTAP a reality. As soon as the user indicates what data in Cosmos
    DB they wish to make available for analytics, the data becomes available in Synapse.
    It takes the operational data you wish to analyze and automatically maintains
    an analytics-oriented columnar version of it. As a result, any changes to the
    operational data in Cosmos DB are continuously updated to the Link data and Synapse.
  prefs: []
  type: TYPE_NORMAL
- en: The biggest benefit of using Azure Synapse Link is that it alleviates the need
    for scheduled batch processing or having to build and maintain operational pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, Azure Synapse is the most chosen platform by architects
    for migrating existing legacy data warehouse solutions to a modern enterprise
    analytics solution. In the next section, we will discuss common architectural
    considerations for migrating from an existing legacy data warehouse solution to
    Azure Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Migrating from existing legacy systems to Azure Synapse Analytics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Today, many organizations are migrating their legacy data warehouse solutions
    to Azure Synapse Analytics to gain the benefits of the high availability, security,
    speed, scalability, cost savings, and performance of Azure Synapse.
  prefs: []
  type: TYPE_NORMAL
- en: For companies running legacy data warehouse systems such as Netezza, the situation
    is even more dire because IBM has announced the end of support for Netezza ([https://www.ibm.com/support/pages/end-support-dates-netezza-5200-netezza-8x50z-series-and-netezza-10000-series-appliances](https://www.ibm.com/support/pages/end-support-dates-netezza-5200-netezza-8x50z-series-and-netezza-10000-series-appliances)).
  prefs: []
  type: TYPE_NORMAL
- en: Many decades ago, some companies chose Netezza to manage and analyze large volumes
    of data. Today, as technologies evolve, the benefits of having a cloud-based data
    warehouse solution far outweigh the on-premises counterparts. Azure Synapse is
    a limitless cloud-based analytics service with unmatched time to insight that
    accelerates the delivery of BI, AI, and intelligent applications for enterprises.
    With its multi-cluster and separate compute and storage architecture, Azure Synapse
    can be scaled instantly in ways not possible with legacy systems such as Netezza.
  prefs: []
  type: TYPE_NORMAL
- en: This section covers the architectural considerations and high-level methodology
    for planning, preparing, and executing a successful migration of an existing legacy
    data warehouse system to Azure Synapse Analytics. Whenever appropriate, specific
    examples and references to Netezza will be given. This chapter is not intended
    to be a comprehensive step-by-step manual for migration, but rather a practical
    overview to help with your migration planning and project scoping.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter also identifies some of the common migration issues and possible
    resolutions. It also provides technical details on the differences between Netezza
    and Azure Synapse Analytics. They should be taken into consideration as part of
    your migration plan.
  prefs: []
  type: TYPE_NORMAL
- en: Why you should migrate your legacy data warehouse to Azure Synapse Analytics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By migrating to Azure Synapse Analytics, companies with legacy data warehouse
    systems can take advantage of the latest innovations in cloud technologies and
    delegate tasks such as infrastructure maintenance and platform upgrading to Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Customers who have migrated to Azure Synapse are already reaping many of its
    benefits, including the following.
  prefs: []
  type: TYPE_NORMAL
- en: '**Performance**'
  prefs: []
  type: TYPE_NORMAL
- en: Azure Synapse Analytics offers best-of-breed relational database performance
    by using techniques such as **Massively Parallel Processing** (**MPP**) and automatic
    in-memory caching. For more information, please review the Azure Synapse Analytics
    architecture ([https://docs.microsoft.com/azure/synapse-analytics/sql-data-warehouse/massively-parallel-processing-mpp-architecture](https://docs.microsoft.com/azure/synapse-analytics/sql-data-warehouse/massively-parallel-processing-mpp-architecture)).
  prefs: []
  type: TYPE_NORMAL
- en: '**Speed**'
  prefs: []
  type: TYPE_NORMAL
- en: Data warehousing is process intensive. It involves data ingestion, transforming
    data, cleansing data, aggregating data, integrating data, and producing data visualization
    and reports. The many processes involved in moving data from original sources
    to a data warehouse are complex and interdependent. A single bottleneck can slow
    the entire pipeline and an unexpected spike in data volume amplifies the need
    for speed. When timeliness of data matters, Azure Synapse Analytics meets the
    demand for fast processing.
  prefs: []
  type: TYPE_NORMAL
- en: '**Improved security and compliance**'
  prefs: []
  type: TYPE_NORMAL
- en: Azure is a globally available, highly scalable, secure cloud platform. It offers
    many security features, including Azure Active Directory, RBAC, managed identities,
    and managed private endpoints. Azure Synapse Analytics, which resides inside the
    Azure ecosystem, inherits all of the aforementioned benefits.
  prefs: []
  type: TYPE_NORMAL
- en: '**Elasticity and cost efficiencies**'
  prefs: []
  type: TYPE_NORMAL
- en: In a data warehouse, the demands for workload processing can fluctuate. At times,
    these fluctuations can vary drastically between peaks and valleys. For example,
    sudden spikes in sales data volumes can occur during holiday seasons. Cloud elasticity
    allows Azure Synapse to quickly increase and decrease its capacity according to
    demand with no impact upon infrastructure availability, stability, performance,
    and security. Best of all, you only pay for your actual usage.
  prefs: []
  type: TYPE_NORMAL
- en: '**Managed infrastructure**'
  prefs: []
  type: TYPE_NORMAL
- en: Eliminating the overhead of data center management and operations for the data
    warehouse allows companies to reallocate valuable resources to where value is
    produced and focus on using the data warehouse to deliver the best information
    and insight. This lowers the overall total cost of ownership and provides better
    cost control over your operating expenses.
  prefs: []
  type: TYPE_NORMAL
- en: '**Scalability**'
  prefs: []
  type: TYPE_NORMAL
- en: The volume of data in a data warehouse typically grows as time passes and as
    history is collected. Azure Synapse Analytics can scale to match this growth by
    incrementally adding resources as data and workload increase.
  prefs: []
  type: TYPE_NORMAL
- en: '**Cost savings**'
  prefs: []
  type: TYPE_NORMAL
- en: Running an on-premises legacy datacenter is expensive (considering the costs
    of servers and hardware, networking, physical room space, electricity, cooling,
    and staffing). These expenses can be substantially minimized with Azure Synapse
    Analytics. With the separation of the compute and storage layers, Azure Synapse
    offers a very lucrative price-performance ratio.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Synapse Analytics provides you with true pay-as-you-go cloud scalability
    without the need for complicated reconfiguration as your data or workloads grow.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have learned why it is beneficial to migrate to Azure Synapse Analytics,
    we will begin our discussion of the migration process.
  prefs: []
  type: TYPE_NORMAL
- en: The three-step migration process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A successful data migration project starts with a well-designed plan. An effective
    plan accounts for the many components that need to be considered, paying particular
    attention to architecture and data preparation. The following is the three-step
    migration process plan.
  prefs: []
  type: TYPE_NORMAL
- en: '**Preparation**'
  prefs: []
  type: TYPE_NORMAL
- en: Define the scope of what is to be migrated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build an inventory of data and processes for migration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define the data model changes (if any).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define the source data extraction mechanism.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify suitable Azure (and third-party) tools and services to be used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Train staff early on the new platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up the Azure target platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Migration**'
  prefs: []
  type: TYPE_NORMAL
- en: Start small and simple.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automate wherever possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leverage Azure built-in tools and features to reduce migration effort.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Migrate metadata for tables and views.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Migrate historical data to be maintained.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Migrate or refactor stored procedures and business processes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Migrate or refactor ETL/ELT incremental load processes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Post-migration**'
  prefs: []
  type: TYPE_NORMAL
- en: Monitor and document all stages of the process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the experience gained to build a template for future migrations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Re-engineer the data model if required.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test applications and query tools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benchmark and optimize query performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we will talk about the two types of migration strategies.
  prefs: []
  type: TYPE_NORMAL
- en: The two types of migration strategies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Architects should begin migration planning by assessing the existing data warehouse
    to determine which migration strategy works best for their situation. There are
    two types of migration strategies to consider.
  prefs: []
  type: TYPE_NORMAL
- en: '**Lift and Shift strategy**'
  prefs: []
  type: TYPE_NORMAL
- en: For the lift and shift strategy, the existing data model is migrated unchanged
    to the new Azure Synapse Analytics platform. This is done to minimize the risk
    and the time required for migration by reducing the scope of changes to the minimum.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lift and shift is a good strategy for legacy data warehouse environments such
    as Netezza where any one of the following conditions applies:'
  prefs: []
  type: TYPE_NORMAL
- en: A single data mart is to be migrated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data is already in a well-designed star or snowflake schema.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are immediate time and cost pressures to move to a modern cloud environment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Redesign strategy**'
  prefs: []
  type: TYPE_NORMAL
- en: In scenarios where the legacy data warehouse has evolved over time, it might
    be essential to re-engineer it to maintain the optimum performance levels or support
    new types of data. This could include a change in the underlying data model.
  prefs: []
  type: TYPE_NORMAL
- en: To minimize risk, it is recommended to migrate first using the lift and shift
    strategy and then gradually modernize the data warehouse data model on Azure Synapse
    Analytics using the redesign strategy. A complete change in data model will increase
    risks because it will impact source-to-data warehouse ETL jobs and downstream
    data marts.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will offer some recommendations on how to reduce the
    complexity of your existing legacy data warehouse before migrating.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing the complexity of your existing legacy data warehouse before migrating
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous section, we presented the two migration strategies. As a best
    practice, during the initial assessment step, be cognizant of any ways to simplify
    your existing data warehouse and document them. The goal is to reduce the complexity
    of your existing legacy data warehouse system before the migration to make the
    migration process easier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some recommendations on how to reduce the complexity of your existing
    legacy data warehouse:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Remove and archive unused tables before migrating**: Avoid migrating data
    that is no longer in use. This will help reduce the overall data volume to migrate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Convert physical data marts to virtual data marts**: Minimize what you have
    to migrate, reduce the total cost of ownership, and improve agility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will take a closer look at why you should consider converting
    a physical data mart to a virtual data mart.
  prefs: []
  type: TYPE_NORMAL
- en: Converting physical data marts to virtual data marts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Prior to migrating your legacy data warehouse, consider converting your current
    physical data marts to virtual data marts. By using virtual data marts, you can
    eliminate physical data stores and ETL jobs for data marts without losing any
    functionality prior to migration. The goal here is to reduce the number of data
    stores to migrate, reduce copies of data, reduce the total cost of ownership,
    and improve agility. To achieve this, you will need to switch from physical to
    virtual data marts before migrating your data warehouse. We can consider this
    as a data warehouse modernization step prior to migration.
  prefs: []
  type: TYPE_NORMAL
- en: '**Disadvantages of physical data marts**'
  prefs: []
  type: TYPE_NORMAL
- en: Multiple copies of the same data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Higher total cost of ownership
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Difficult to change as ETL jobs are impacted
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Advantages of virtual data marts**'
  prefs: []
  type: TYPE_NORMAL
- en: Simplifies data warehouse architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No need to store copies of data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More agility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lower total cost of ownership
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uses pushdown optimization to leverage the power of Azure Synapse Analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy to change
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy to hide sensitive data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will talk about how to migrate existing data warehouse
    schemas to Azure Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Migrating existing data warehouse schemas to Azure Synapse Analytics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Migrating the schemas of an existing legacy data warehouse involves the migration
    of existing staging tables, legacy data warehouse, and dependent data mart schemas.
  prefs: []
  type: TYPE_NORMAL
- en: To help you understand the magnitude and scope of your schema migration, we
    recommend that you create an inventory of your existing legacy data warehouse
    and data mart.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a checklist to help you collect the necessary information:'
  prefs: []
  type: TYPE_NORMAL
- en: Row counts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Staging, data warehouse, and data mart data size: tables and indexes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data compression ratios
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Current hardware configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tables (including partitions): identify small dimension tables'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Views
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indexes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object dependencies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Functions: both out-of-the-box functions and **User-Defined Functions** (**UDFs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stored procedures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalability requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Growth projections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Workload requirements: Concurrent users'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With your inventory completed, you can now make decisions on scoping what schema
    you want to migrate. Essentially, there are four options for scoping your legacy
    data warehouse schema migration:'
  prefs: []
  type: TYPE_NORMAL
- en: Migrate one data mart at a time:![Migrate one data mart at a time](img/B15432_18_04.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.4: Migrating one data mart at a time'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Migrate all data marts at once, then the data warehouse:![Migrate all data marts
    at once, then the legacy data warehouse](img/B15432_18_05.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.5: Migrating all data marts at once, then the data warehouse'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Migrate both the data warehouse and the staging area:![Migrate both the data
    warehouse and the staging area](img/B15432_18_06.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.6: Migrating both the data warehouse and the staging area'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Migrate everything at once:![Migrating everything at once](img/B15432_18_07.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 18.7: Migrating everything at once'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Keep in mind when choosing your option that the goal is to achieve a physical
    database design that will match or exceed your current legacy data warehouse system
    in performance and preferably at a lower cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'To recap, here are some of the recommendations for the schema migration:'
  prefs: []
  type: TYPE_NORMAL
- en: Avoid migrating unnecessary objects or processes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider using virtual data marts to reduce or eliminate the number of physical
    data marts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automate whenever possible. Implementation of DataOps should be considered alongside
    the migration to Azure Synapse.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use metadata from system catalog tables in the legacy data warehouse system
    to generate **Data Definition Language** (**DDL**) for Azure Synapse Analytics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform any required data model changes or data mapping optimizations on Azure
    Synapse Analytics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will talk about how to migrate historical data from
    a legacy data warehouse to Azure Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Migrating historical data from your legacy data warehouse to Azure Synapse Analytics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the schema migration scope has been determined, we are now ready to make
    decisions on how to migrate the historical data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps for migrating historical data are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Create target tables on Azure Synapse Analytics.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Migrate existing historical data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Migrate functions and stored procedures as required.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Migrate incremental load (ETL/ELT) staging and processes for incoming data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply any performance tuning options that are required.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Table 18.2* outlines the four data migration options and their pros and cons:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Four data migration options and their pros and cons](img/Table_18.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 18.2: Data migration options with their pros and cons'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the next section, we will talk about how to migrate existing ETL processes
    to Azure Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Migrating existing ETL processes to Azure Synapse Analytics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are a number of options available for migrating your existing ETL processes
    to Azure Synapse Analytics. *Table 18.3* outlines some of the ETL migration options
    based on how the existing ETL jobs are built:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Options for migration ETL jobs in Azure Synapse](img/Table_18.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 18.3: ETL migration options'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the next section, we will talk about how to re-develop scalable ETL processes
    using ADF.
  prefs: []
  type: TYPE_NORMAL
- en: Re-developing scalable ETL processes using ADF
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another option for handling your existing legacy ETL processes is by re-developing
    them using ADF. ADF is an Azure data integration service for creating data-driven
    workflows (known as pipelines) to orchestrate and automate data movement and data
    transformation. You can use ADF to create and schedule pipelines to ingest data
    from different data stores. ADF can process and transform data by using compute
    services such as Spark, Azure Machine Learning, Azure HDInsight Hadoop, and Azure
    Data Lake Analytics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Re-developing scalable ETL processes using Azure Data Factory](img/Image74376.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.8: Re-developing scalable ETL processes using ADF'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The next section will offer some recommendations for migrating queries, BI reports,
    dashboards, and other visualizations.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendations for migrating queries, BI reports, dashboards, and other visualizations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Migrating queries, BI reports, dashboards, and other visualizations from your
    legacy data warehouse to Azure Synapse Analytics is straightforward if the legacy
    system uses standard SQL.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, often, this is not the case. In this situation, a different strategy
    must be taken:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify the high-priority reports to migrate first.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use usage statistics to identify the reports that are never used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid migrating anything that is no longer in use.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you have produced the list of reports to migrate, their priorities, and
    the unused reports to be bypassed, confirm this list with the stakeholders.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For reports that you are migrating, identify incompatibilities early to gauge
    the migration effort.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider data virtualization to protect BI tools and applications from structural
    changes to the data warehouse and/or data mart data model that might occur during
    the migration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common migration issues and resolutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: During the migration process, you might encounter certain issues that you need
    to overcome. In this section, we will highlight some of the common issues and
    provide you with resolutions that you can implement.
  prefs: []
  type: TYPE_NORMAL
- en: '**Issue #1: Unsupported data types and workarounds**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Table 18.4* shows the data types from legacy data warehouse systems that are
    unsupported, as well as the suitable workarounds for Azure Synapse Analytics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Unsupported data types and suitable workarounds in Azure Synapse Analytics](img/Table_18.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 18.4: Unsupported data types and suitable workarounds in Azure Synapse
    Analytics'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Issue #2: Data type differences between Netezza and Azure Synapse**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Table 18.5* maps the Netezza data types to their Azure Synapse equivalent
    data types:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Netezza data types and their Azure Synapse equivalents](img/Table_18.5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 18.5: Netezza data types and their Azure Synapse equivalents'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Issue #3: Integrity constraint differences**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pay close attention to the integrity constraint differences between your legacy
    data warehouse or data mart and Azure Synapse Analytics. In *Figure 18.9*, the
    left side represents the old legacy data warehouse system with primary key and
    foreign key constraints, and on the right side is the new Azure Synapse Analytics
    environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Integrity constraint differences between legacy data warehouse/data mart
    and Azure Synapse](img/Image74470.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.9: Integrity constraint differences'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The next sections will provide comprehensive coverage on how to resolve other
    common SQL incompatibilities during the migration from a legacy data warehouse
    to Azure Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Common SQL incompatibilities and resolutions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section will provide technical details regarding common SQL incompatibilities
    and resolutions between legacy data warehouse systems and Azure Synapse Analytics.
    The section will explain and compare the differences and provide resolutions using
    a quick-reference table that you can refer to later on as you embark on your migration
    project.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics that we will cover are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: SQL **Data Definition Language** (**DDL**) differences and resolutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQL **Data Manipulation Language** (**DML**) differences and resolutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQL **Data Control Language** (**DCL**) differences and resolutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extended SQL differences and workarounds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQL DDL differences and resolutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will discuss the differences and resolutions for SQL DDL
    between legacy data warehouse systems and Azure Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: '![SQL DDL differences between legacy systems and Azure Synapse](img/Table_18.6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 18.6: SQL DDL differences between legacy systems and Azure Synapse'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: SQL DML differences and resolutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will discuss the differences and resolutions for SQL DML
    between legacy data warehouse systems and Azure Synapse Analytics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![SQL DML differences between Netezza and Azure Synapse](img/Table_18.7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 18.7: SQL DML differences between Netezza and Azure Synapse'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Next, we will talk about the differences and resolutions of SQL DCL between
    legacy data warehouse systems and Azure Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: SQL DCL differences and resolutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will discuss the differences and resolutions for SQL DCL
    between legacy data warehouse systems and Azure Synapse Analytics. Netezza supports
    two classes of access rights: admin and object. *Table 18.8* map the Netezza access
    rights and their corresponding Azure Synapse equivalents for quick reference.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mapping Netezza admin privileges to the Azure Synapse equivalents**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Table 18.8* maps the Netezza admin privileges to the Azure Synapse equivalents:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Netezza Admin Privileges and its Azure Synapse equivalent](img/Table_18.8A.jpg)![Netezza
    Admin Privileges and its Azure Synapse equivalent](img/Table_18.8B.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 18.8: Netezza admin privileges and their Azure Synapse equivalents'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Mapping Netezza object privileges to their Azure Synapse equivalent**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Table 18.9* maps the Netezza object privileges to the Azure Synapse equivalents
    for quick reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Netezza Object Privileges and its Azure Synapse equivalent](img/Table_18.9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 18.9: Netezza object privileges and their Azure Synapse equivalents'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Extended SQL differences and workarounds
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Table 18.10* describes the extended SQL differences and possible workarounds
    when migrating to Azure Synapse Analytics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Extended SQL differences and workarounds to migrate to Azure Synapse](img/Table_18.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 18.10: Extended SQL differences and workarounds'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this section, we talked about common migration issues that architects might
    encounter during a migration project and possible solutions. In the next section,
    we will take a look at security considerations that an architect should be mindful
    of.
  prefs: []
  type: TYPE_NORMAL
- en: Security considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Protecting and securing your data assets is paramount in any data warehouse
    system. When planning a data warehouse migration project, security, user access
    management, backup, and restore must also be taken into consideration. For instance,
    data encryption may be mandatory for industry and government regulations, such
    as HIPAA, PCI, and FedRAMP, as well as in non-regulated industries.
  prefs: []
  type: TYPE_NORMAL
- en: Azure includes many features and functions as standard that would traditionally
    have to be custom-built in legacy data warehouse products. Azure Synapse supports
    data encryption at rest and data in motion as standard.
  prefs: []
  type: TYPE_NORMAL
- en: Data encryption at rest
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Transparent Data Encryption** (**TDE**) can be enabled to dynamically encrypt
    and decrypt Azure Synapse data, logs, and associated backups.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Data Storage can also automatically encrypt non-database data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data in motion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: All connections to Azure Synapse Analytics are encrypted by default, using industry-standard
    protocols such as TLS and SSH.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, **Dynamic Data Masking** (**DDM**) can be used to obfuscate data
    for given classes of users based on data masking rules.
  prefs: []
  type: TYPE_NORMAL
- en: As a best practice, if your legacy data warehouse contains a complex hierarchy
    of permissions, users and roles, consider using automation techniques in your
    migration process. You can use existing metadata from your legacy system to generate
    the necessary SQL to migrate users, groups, and privileges on Azure Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: In the final section of this chapter, we will review some of the tools that
    architects can choose to help migrate from legacy data warehouse systems to Azure
    Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Tools to help migrate to Azure Synapse Analytics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have covered the planning and preparation and an overview of the
    migration process, let''s have a look at the tools that you can use for migrating
    your legacy data warehouse to Azure Synapse Analytics. The tools that we will
    discuss are:'
  prefs: []
  type: TYPE_NORMAL
- en: ADF
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Data Warehouse Migration Utility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft Services for Physical Data Transfer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft Services for Data Ingestion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: ADF
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'ADF is a fully managed, pay-as-you-use, hybrid data integration service for
    cloud-scale ETL processing. It offers the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Processes and analyzes data in memory and in parallel to scale and maximize
    throughput
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creates data warehouse migration pipelines that orchestrate and automate data
    movement, data transformation, and data loading into Azure Synapse Analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can also be used to modernize your data warehouse by ingesting data into Azure
    Data Lake, processing and analyzing data at scale, and loading data into a data
    warehouse
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports role-based user interfaces for mapping data flows for IT professionals
    and self-service data wrangling for business users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can connect to multiple data stores spanning datacenters, clouds, and SaaS applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Over 90 natively built and maintenance-free connectors available ([https://azure.microsoft.com/services/data-factory](https://azure.microsoft.com/services/data-factory))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can mix and match wrangling and mapping data flows in the same pipeline to prepare
    data at scale
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ADF orchestration can control data warehouse migration to Azure Synapse Analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can execute SSIS ETL packages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Data Warehouse Migration Utility
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Azure Data Warehouse Migration Utility can migrate data from an on-premises
    SQL Server–based data warehouse to Azure Synapse. It offers the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Uses a wizard-like approach to perform a lift and shift migration of schema
    and data from an on-premises, SQL Server–based data warehouse.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can select the on-premises database containing the table(s) that you want
    to export to Azure Synapse. Then, you can select the tables that you want to migrate
    and migrate the schema.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatically generates T-SQL code needed to create an equivalent empty database
    and tables on Azure Synapse. Once you provide connection details to Azure Synapse
    you can run the generated T-SQL to migrate the schema.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Following schema creation, you can use the utility to migrate the data. This
    exports the data from your on-premises SQL Server–based data warehouse and generates
    **Bulk Copy Program** (**BCP**) commands to load that data into Azure Synapse.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft Services for Physical Data Transfer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will look at common Microsoft services that can be used
    for physical data transfer, including Azure ExpressRoute, AzCopy, and Azure Databox.
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure ExpressRoute**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure ExpressRoute allows you to make private connections between your datacenters
    and Azure without going over the public Internet. It offers the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Bandwidth of up to 100 Gbps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Low latency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connects directly to your **Wide-Area Network** (**WAN**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Private connections to Azure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increased speed and reliability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AzCopy**'
  prefs: []
  type: TYPE_NORMAL
- en: 'AzCopy is a command-line tool for copying files and blobs to/from storage accounts.
    It offers the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Ability to copy data to/from Azure via the Internet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A combination of AzCopy with the necessary ExpressRoute bandwidth could be an
    optimal solution for data transfer to Azure Synapse.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Data Box**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure Data Box allows you to transfer large volumes of data to Azure quickly,
    reliably, and cost-effectively. It offers the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Capable of transferring large volumes of data (tens of terabytes to hundreds
    to terabytes)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No network connectivity restrictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Great for one-time migration and initial bulk transfer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft Services for data ingestion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will look at common Microsoft services that can be used
    for data ingestion, including:'
  prefs: []
  type: TYPE_NORMAL
- en: PolyBase
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BCP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SqlBulkCopy API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Standard SQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PolyBase** (**recommended method**)'
  prefs: []
  type: TYPE_NORMAL
- en: 'PolyBase provides the fastest and most scalable bulk data loading into Azure
    Synapse Analytics. It offers the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Uses parallel loading to give the fastest throughput
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can read from flat files in Azure Blob storage or from external data sources
    via connectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tightly integrated with ADF
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CREATE TABLE AS or INSERT … SELECT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can define a staging table as type HEAP for fast load
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support rows up to 1 MB in length
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BCP**'
  prefs: []
  type: TYPE_NORMAL
- en: 'BCP can be used to import and export data from any SQL Server environment,
    including Azure Synapse Analytics. It offers the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Supports rows larger than 1 MB in length
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Originally developed for earlier versions of Microsoft SQL Server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to [https://docs.microsoft.com/sql/tools/bcp-utility](https://docs.microsoft.com/sql/tools/bcp-utility)
    to read more about the BCP utility.
  prefs: []
  type: TYPE_NORMAL
- en: '**SqlBulkCopy API**'
  prefs: []
  type: TYPE_NORMAL
- en: 'SqlBulkCopy API is the API equivalent of the BCP functionality. It offers the
    following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Allows the implementation of load processes programmatically
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ability to bulk load SQL Server tables with data from selected sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to [https://docs.microsoft.com/dotnet/api/system.data.sqlclient.sqlbulkcopy](https://docs.microsoft.com/dotnet/api/system.data.sqlclient.sqlbulkcopy)
    to read more about this API.
  prefs: []
  type: TYPE_NORMAL
- en: '**Standard SQL Support**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure Synapse Analytics supports standard SQL, including the ability to:'
  prefs: []
  type: TYPE_NORMAL
- en: Load individual rows or results of `SELECT` statements into data warehouse tables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bulk insert data from extracted data via external data sources into data warehouse
    tables using `INSERT … SELECT` statements within PolyBase.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This section provided the architectural considerations and high-level methodology
    for planning, preparing, and executing a successful migration of an existing legacy
    data warehouse system to Azure Synapse Analytics. It contains a wealth of information
    that you can refer to later on as you embark on your migration project to Azure
    Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure Synapse Analytics is a limitless analytics service with unmatched time
    to insight that accelerates the delivery of BI, AI, and intelligent applications
    for enterprises. You will gain a lot of benefits by migrating your legacy data
    warehouse to Azure Synapse Analytics, including performance, speed, improved security
    and compliance, elasticity, managed infrastructure, scalability, and cost savings.
  prefs: []
  type: TYPE_NORMAL
- en: With Azure Synapse, data professionals of varying skillsets can collaborate,
    manage, and analyze their most important data with ease—all within the same service.
    From Apache Spark integration with the powerful and trusted SQL engine, to code-free
    data integration and management, Azure Synapse is built for every data professional.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter provided the architectural considerations and high-level methodology
    needed to prepare for and execute the migration of an existing legacy data warehouse
    system to Azure Synapse Analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Successful data migration projects start with a well-designed plan. An effective
    plan accounts for the many components that need to be considered, paying particular
    attention to architecture and data preparation.
  prefs: []
  type: TYPE_NORMAL
- en: After you have successfully migrated to Azure Synapse, you can explore additional
    Microsoft technologies in the rich Azure analytical ecosystem to further modernize
    your data warehouse architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some ideas to ponder:'
  prefs: []
  type: TYPE_NORMAL
- en: Offload your staging areas and ELT processing to Azure Data Lake and ADF.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build trusted data products once in common data model format and consume everywhere—not
    just in your data warehouse.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable collaborative development of data preparation pipelines by business and
    IT using ADF mapping and wrangling data flows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build analytical pipelines in ADF to analyze data in batch and real time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build and deploy machine learning models to add additional insights to what
    you already know.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrate your data warehouse with live streaming data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simplify access to data and insights in multiple Azure analytical data stores
    by creating a logical data warehouse using PolyBase.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter, you will learn in detail about Azure Cognitive Services,
    with a focus on architecting solutions that include intelligence as their core
    engine.
  prefs: []
  type: TYPE_NORMAL
