- en: 19\. Architecting intelligent solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Cloud technology has changed a lot of things, including the creation of intelligent
    applications in an agile, scalable, and pay-as-you-go way. Applications prior
    to the rise of cloud technology generally did not incorporate intelligence within
    themselves, primarily because:'
  prefs: []
  type: TYPE_NORMAL
- en: It was time-consuming and error-prone.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It was difficult to write, test, and experiment with algorithms on an ongoing
    basis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There was a lack of sufficient data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It was immensely costly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Over the last decade, two things have changed that have led to the creation
    of significantly more intelligent applications than in the past. These two things
    are the cost-effective, on-demand unlimited scalability of the cloud along with
    the availability of data in terms of volume, variety, and velocity.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will look at architectures that can help build intelligent
    applications with Azure. Some of the topics covered in this chapter are:'
  prefs: []
  type: TYPE_NORMAL
- en: The evolution of AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure AI processes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Cognitive Services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building an optical character recognition service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a visual features service using the Cognitive Search .NET SDK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The evolution of AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'AI is not a new field of knowledge. In fact, the technology is a result of
    decades of innovation and research. However, its implementation in previous decades
    was a challenge for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cost**: AI experiments were costly in nature and there was no cloud technology.
    All the infrastructure was either purchased or hired from a third party. Experiments
    were also time-consuming to set up and immense skills were needed to get started.
    A large amount of storage and compute power was also required, which was generally
    missing in the community at large and held in the hands of just a few.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Lack of data**: There were hardly any smart handheld devices and sensors
    available generating data. Data was limited in nature and had to be procured,
    which again made AI applications costly. Data was also less reliable and there
    was a general lack of confidence in the data itself.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Difficulty**: AI algorithms were not documented enough and were primarily
    in the realms of mathematicians and statisticians. They were difficult to create
    and utilize within applications. Just imagine the creation of an **optical character
    recognition** (**OCR**) system 15 years ago. There were hardly any libraries,
    data, processing power, or the necessary skills to develop applications using
    OCR.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Although the influx of data increased with time, there was still a lack of tools
    for making sense of the data in a way that added business value. In addition,
    good AI models are based on sufficiently accurate data and trained with algorithms
    to be capable of resolving real-life problems. Both cloud technology and the large
    number of sensors and handheld devices have redefined this landscape.
  prefs: []
  type: TYPE_NORMAL
- en: With cloud technology, it is possible to provision on-demand storage and compute
    resources for AI-based applications. Cloud infrastructure provides lots of resources
    for data migration, storage, processing, and computation, as well as generating
    insights and eventually providing reports and dashboards. It does all this at
    a minimal cost in a faster way since there is nothing physical involved. Let's
    dive into understanding what goes on behind building an AI-based application.
  prefs: []
  type: TYPE_NORMAL
- en: Azure AI processes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Every AI-based project is required to go through a certain set of steps before
    being operational. Let''s explore these seven phases:'
  prefs: []
  type: TYPE_NORMAL
- en: Data ingestion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this phase, data is captured from various sources and stored such that it
    can be consumed in the next phase. The data is cleaned before being stored and
    any deviations from the norm are disregarded. This is part of the preparation
    of data. The data could have different velocity, variety, and volume. It can be
    structured similarly to relational databases, semi-structured like JSON documents,
    or unstructured like images, Word documents, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Data transformation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The data ingested is transformed into another format as it might not be consumable
    in its current format. The data transformation typically includes the cleaning
    and filtering of data, removing bias from the data, augmenting data by joining
    it with other datasets, creating additional data from existing data, and more.
    This is also part of the preparation of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The data from the last phase is reused for analysis. The analysis phase contains
    activities related to finding patterns within data, conducting exploratory data
    analysis, and generating further insights from it. These insights are then stored
    along with existing data for consumption in the next phase. This is part of the
    model packaging process.
  prefs: []
  type: TYPE_NORMAL
- en: Data modeling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the data is augmented and cleaned, appropriate and necessary data is made
    available to the AI algorithms to generate a model that is conducive to achieving
    the overall aim. It is an iterative process known as experimentation by using
    various combinations of data (feature engineering) to ensure that the data model
    is robust. This is also part of the model packaging process.
  prefs: []
  type: TYPE_NORMAL
- en: The data is fed into learning algorithms to identify patterns. This process
    is known as training the model. Later, test data is used on the model to check
    its effectiveness and efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Validating the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the model is created, a set of test data is used to find its effectiveness.
    If the analysis obtained from the test data is reflective of reality, then the
    model is sound and usable. Testing is an important aspect of the AI process.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The model is deployed to production so that real-time data can be fed into it
    to get the predicted output. This output can then be used within applications.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The model deployed to production is monitored on an ongoing basis for the future
    analysis of all incoming data and to retrain and improve the effectiveness models.
  prefs: []
  type: TYPE_NORMAL
- en: The AI stages and processes, by nature, are time-consuming and iterative. Thus,
    applications based on them have an inherent risk of being long-running, experimental,
    and resource-intensive, along with getting delayed with cost overruns and having
    low chances of success.
  prefs: []
  type: TYPE_NORMAL
- en: 'Keeping these things in mind, there should be out-of-the-box AI-based solutions
    that developers can use in their applications to make them intelligent. These
    AI solutions should be easily consumable from applications and should have the
    following features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cross-platform**: Developers using any platform should be able to consume
    these services. They should be deployed and consumed on Linux, Windows, or Mac
    without any compatibility problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cross-language**: Developers should be able to use any language to consume
    these solutions. Not only will the developers encounter a shorter learning curve
    but they also won''t need to change their preferred choice of language to consume
    these solutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These solutions should be deployed as services using industry standards and
    protocols. Generally, these services are available as HTTP REST endpoints that
    can be invoked using any programming language and platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many such types of service that can be modeled and deployed for developer
    consumption. Some examples include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Language translation**: In such services, the user provides text in one language
    and gets corresponding text in a different language as output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Character recognition**: These services accept images and return the text
    present in them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speech-to-text conversion**: These services can convert input speech to text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have gone through the details of building an AI/ML-based project,
    let's dive into the applications of various cognitive services offered by Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Cognitive Services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure provides an umbrella service known as Azure Cognitive Services. Azure
    Cognitive Services is a set of services that developers can consume within their
    applications to turn them into intelligent applications.
  prefs: []
  type: TYPE_NORMAL
- en: '![Set of Azure Cognitive Services](img/Table_19.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 19.1: Azure Cognitive Services'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The services have been divided into five main categories depending on their
    nature. These five categories are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Vision
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This API provides algorithms for image classification and helps in image processing
    by providing meaningful information. Computer vision can provide a variety of
    information from images on different objects, people, characters, emotions, and
    more.
  prefs: []
  type: TYPE_NORMAL
- en: Search
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: These APIs help in search-related applications. They help with search based
    on text, images, video, and providing custom search options.
  prefs: []
  type: TYPE_NORMAL
- en: Language
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: These APIs are based on natural language processing and help extract information
    about the intent of user-submitted text along with entity detection. They also
    help in text analytics and translation to different languages.
  prefs: []
  type: TYPE_NORMAL
- en: Speech
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: These APIs help in translating speech to text, text to speech, and in speech
    translation. They can be used to ingest audio files and take actions based on
    the content on behalf of users. Cortana is an example that uses similar services
    to take actions for users based on speech.
  prefs: []
  type: TYPE_NORMAL
- en: Decision
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: These APIs help in anomaly detection and content moderation. They can check
    for content within images, videos, and text and find out patterns that should
    be highlighted. An example of such an application is displaying a warning about
    adult content.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have an understanding of the core of Cognitive Services, let's
    discuss how they work in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Cognitive Services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure Cognitive Services consists of HTTP endpoints that accept requests and
    send responses back to the caller. Almost all requests are HTTP POST requests
    and consist of both a header and a body.
  prefs: []
  type: TYPE_NORMAL
- en: The provisioning of Cognitive Services generates two important artifacts that
    help a caller invoke an endpoint successfully. It generates an endpoint URL and
    a unique key.
  prefs: []
  type: TYPE_NORMAL
- en: 'The format of the URL is `https://{azure location}.api.cognitive.microsoft.com/{cognitive
    type}/{version}/{sub type of service}?{query parameters}`. An example URL is:'
  prefs: []
  type: TYPE_NORMAL
- en: '`https://eastus.api.cognitive.microsoft.com/vision/v2.0/ocr?language=en&detectOrientation=true`'
  prefs: []
  type: TYPE_NORMAL
- en: Cognitive Service is provisioned in the East US Azure region. The type of service
    is computer vision using version 2 and the subtype is OCR. There are generally
    a few subtypes for each top-level category. Lastly, there are a few query string
    parameters, such as `language` and `detectOrientation`. These query parameters
    are different for each service category and subcategory.
  prefs: []
  type: TYPE_NORMAL
- en: Either the header or the query parameters should provide the key value for the
    endpoint invocation to be successful.
  prefs: []
  type: TYPE_NORMAL
- en: The key value should be assigned to the `Ocp-Apim-Subscription-Key` header key
    with the request.
  prefs: []
  type: TYPE_NORMAL
- en: The content of the request body can be a simple string, a binary, or a combination
    of both. Depending on the value, the appropriate content-type header should be
    set in the request.
  prefs: []
  type: TYPE_NORMAL
- en: 'The possible header values are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Application/octet-stream`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`multipart/form-data`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`application/json`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `octet-stream` when sending binary data and `json` for sending string values.
    `form-data` can be used for sending multiple combination values of binary and
    text.
  prefs: []
  type: TYPE_NORMAL
- en: The key is a unique string used to validate whether the caller has been given
    permission to invoke the URL. This key must be protected such that others who
    should not be able to invoke the endpoints do not get access to it. Later in the
    chapter, you will see ways to safeguard these keys.
  prefs: []
  type: TYPE_NORMAL
- en: Consuming Cognitive Services
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two ways to consume Cognitive Services:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Using an HTTP endpoint directly**: In this case, the endpoint is invoked
    directly by crafting both the header and body with appropriate values. The return
    value is then parsed and data is extracted out of it. All the AI services in Cognitive
    Services are REST APIs. They accept HTTP requests in JSON, as well as other formats,
    and replies in JSON format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Using an SDK**: Azure provides multiple **software development kits** (**SDKs**).
    There are SDKs available for the .NET, Python, Node.js, Java, and Go languages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following section, we will look into the utilization of one of the Cognitive
    Services using both ways. Let's explore this by building some AI services using
    HTTP endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: Building an OCR service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will be using some of the AI services using C# as well as
    PowerShell to show their usage using the HTTP endpoint directly. The next section
    will concentrate on doing the same using a .NET SDK.
  prefs: []
  type: TYPE_NORMAL
- en: Before getting into building a project using Cognitive Services, the first step
    is to provision the API itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Optical character recognition is available as a Vision API and can be provisioned
    using the Azure portal, as shown next. Create a vision API by navigating to **Cognitive
    Services > Compute Vision > Create**, as shown in *Figure 19.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a Vision API](img/Figure_19.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.1: Create a Vision API'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Once the API is provisioned, the overview page provides all the details for
    consuming the API. It provides the base URL and the key information. Make a note
    of the key as it will be used later:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Details of the API in the Overview section](img/Figure_19.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.2: Overview page'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: It also provides an API console to quickly test the API. Clicking on it opens
    a new window that has all the endpoints related to this service available. Clicking
    on `POST` method. The URL points to the endpoint in the East US Azure region.
    It is also related to the Vision group of APIs, version 2, and the OCR endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'The subscription key is passed in the header with the name `ocp-apim-subscription-key`.
    The header also contains the content-type key with `application/json` as a value.
    This is because the body of the request contains a JSON string. The body is in
    the form of JSON with the URL of the image from which text should be extracted:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Details of the HTTP request](img/Figure_19.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.3: Request URL'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The request can be sent to the endpoint by clicking on the **Send** button.
    It will result in an HTTP response 200 OK, as shown next, if everything goes right.
    If there is an error in the request values, the response will be an error HTTP
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![HTTP response 200 OK](img/Figure_19.5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.4: HTTP response 200 OK'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The response consists of details related to billing usage, an internal request
    ID generated by the endpoint, the content length, the response content type (being
    JSON), and the data and time of the response. The content of the response consists
    of a JSON payload with the coordinates of the text and the actual text itself.
  prefs: []
  type: TYPE_NORMAL
- en: Using PowerShell
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The same request can be created using PowerShell. The following PowerShell code
    can be executed using the PowerShell ISE.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code uses the `Invoke-WebRequest` cmdlet to invoke the Cognitive Services
    endpoint by passing the URL to the `Uri` parameter using the `POST` method, and
    adds both the appropriate headers as discussed in the last section, and finally,
    the body consisting of data in JSON format. The data is converted into JSON using
    the `ConvertTo-Json` cmdlet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The response from the cmdlet is saved in a variable that also consists of data
    in JSON format. The data is converted into a PowerShell object using the `Convertfrom-Json`
    cmdlet and looped over to find the words in the text.
  prefs: []
  type: TYPE_NORMAL
- en: Using C#
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will build a service that should accept requests from users,
    extract the URL of the image, construct the HTTP request, and send it to the Cognitive
    Services endpoint. The Cognitive Services endpoint returns a JSON response. The
    appropriate text content is extracted from the response and returned to the user.
  prefs: []
  type: TYPE_NORMAL
- en: '**Architecture and design**'
  prefs: []
  type: TYPE_NORMAL
- en: 'An intelligent application is an ASP.NET Core MVC application. An MVC application
    is built by a developer on a developer machine, goes through the continuous integration
    and delivery pipeline, generates a Docker image, and uploads the Docker image
    to Azure Container Registry. Here, the major components of the application are
    explained, along with their usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ASP.NET Core MVC application architecture](img/19.6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.5: Workflow of an intelligent application'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Docker**'
  prefs: []
  type: TYPE_NORMAL
- en: Docker is one of the major players within container technologies and is available
    cross-platform, including Linux, Windows, and Mac. Developing applications and
    services with containerization in mind provides the flexibility to deploy them
    across clouds and locations, as well as on-premises. It also removes any dependencies
    on the host platform, which again allows less reliance on platform as a service.
    Docker helps with the creation of custom images, and containers can be created
    out of these images. The images contain all the dependencies, binaries, and frameworks
    needed to make the application or service work, and they are completely self-reliant.
    This makes them a great deployment target for services such as microservices.
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Container Registry**'
  prefs: []
  type: TYPE_NORMAL
- en: Azure Container Registry is a registry that's similar to Docker Hub for the
    storage of container images in a repository. It is possible to create multiple
    repositories and upload multiple images in them. An image has a name and a version
    number, together forming a fully qualified name used to refer to them in a Kubernetes
    Pod definition. These images can be accessed and downloaded by any Kubernetes
    ecosystem. A prerequisite of this is that appropriate secrets for pulling the
    image should already be created beforehand. It need not be on the same network
    as Kubernetes nodes and, in fact, there is no need for a network to create and
    use Azure Container Registry.
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Kubernetes Service**'
  prefs: []
  type: TYPE_NORMAL
- en: The intelligent application that accepts the URL of an image to retrieve the
    text in it can be hosted on vanilla virtual machines or even within Azure App
    Service. However, deploying in Azure Kubernetes Service offers lots of advantages,
    which was covered in *Chapter 8, Architecting Azure Kubernetes Solutions*. For
    now, it is important to know that these applications are self-healing in nature
    and a minimum number of instances is automatically maintained by the Kubernetes
    master along with providing the flexibility to update them in a multitude of ways,
    including blue-green deployments and canary updates.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pods, replica sets, and deployments**'
  prefs: []
  type: TYPE_NORMAL
- en: The developer also creates a Kubernetes deployment-related YAML file that references
    the images within the Pod specification and also provides a specification for
    the replica set. It provides its own specification related to the update strategy.
  prefs: []
  type: TYPE_NORMAL
- en: '**Runtime design**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The architecture and design remain the same as in the previous section; however,
    when the application or service is already live and up and running, it has already
    downloaded the images from Azure Container Registry and created Pods running containers
    in them. When a user provides an image URL for decoding the text it contains,
    the application in the Pod invokes the Azure Cognitive Services Computer Vision
    API and passes the URL to it and waits for a response from the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ASP.NET Core MVC application architecture using Azure Cognitive Services](img/19.7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 19.6 Workflow of an intelligent application
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Once it receives the JSON response from the services, it can retrieve the information
    and return it to the user.
  prefs: []
  type: TYPE_NORMAL
- en: The development process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The development environment can be Windows or Linux. It will work with both
    Windows 10 and the Windows 2016/19 server. When using Windows, it is useful to
    deploy Docker for Windows so that it will create both a Linux and a Windows Docker
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: When creating an ASP.NET Core web application project using Visual Studio 2019,
    the `Dockerfile`. The main difference in `Dockerfile` is the base image names.
    It uses different images for Linux compared to Windows.
  prefs: []
  type: TYPE_NORMAL
- en: When installing Docker for Windows, it also installs a Linux virtual machine,
    and so it is important to turn on the Hyper-V hypervisor.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, instead of sending the data as a JSON string, the image is
    downloaded, and binary data is sent to the Cognitive Services endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: It has a function that accepts a string input for URL values. It then invokes
    Cognitive Services with appropriate header values and a body containing the URL.
    The header values should contain the key provided by Cognitive Services while
    provisioning the service. The value in the body can contain vanilla string values
    in the form of JSON or it can contain binary image data itself. The content-type
    header property should be set accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: The code declares the URL and the key related to the Cognitive Services. This
    is shown for demonstration purposes only. The URL and key should be placed in
    configuration files.
  prefs: []
  type: TYPE_NORMAL
- en: Using the `HttpClient` object, the image corresponding to the URL supplied by
    the user is downloaded and stored within the `responseMessage` variable. Another
    `HttpClient` object is instantiated and its headers are filled with `Ocp-Apim-Subscription-Key`
    and `content-type keys`. The value of the content-type header is `application/octet-stream`
    since binary data is being passed to the endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: A post request is made after extracting the content from the `responseMessage`
    variable and passing it as the body of a request to the cognitive service endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for the controller action is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: After the endpoint finishes its processing, it returns the response with a JSON
    payload. The context is extracted and deserialized into .NET objects. Multiple
    loops are coded to extract the text from the response.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we created a simple application that uses Cognitive Services
    to provide word extractions from features using the OCR API and deployed it within
    Kubernetes Pods. This process and architecture can be used within any application
    that wants to consume Cognitive Services APIs. Next, we will take a look at another
    Cognitive Services API, known as visual features.
  prefs: []
  type: TYPE_NORMAL
- en: Building a visual features service using the Cognitive Search .NET SDK
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last section was about creating a service that uses an OCR cognitive endpoint
    to return text within images. In this section, a new service will be created that
    will return visual features within an image, such as descriptions, tags, and objects.
  prefs: []
  type: TYPE_NORMAL
- en: Using PowerShell
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The code in PowerShell is similar to the previous OCR example, so it is not
    repeated here. The URL is different from the previous code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![HTTP request URL when using PowerShell](img/Figure_19.8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.7: Request URL'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The request is made using a `POST` method, and the URL points to the endpoint
    in the East US Azure region. It also uses version 2 and consumes the Vision API.
  prefs: []
  type: TYPE_NORMAL
- en: The Cognitive Services access key is part of the HTTP header named `ocp-apim-subscription-key`.
    The header also contains the header content-type with `application/json` as the
    value. This is because the body of the request contains a JSON value. The body
    has the URL of the image from which text should be extracted.
  prefs: []
  type: TYPE_NORMAL
- en: The response will be in JSON format containing the image content and a description.
  prefs: []
  type: TYPE_NORMAL
- en: Using .NET
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This example is again an ASP.NET Core MVC application and has the `Microsoft.Azure.CognitiveServices.Vision.ComputerVision`
    NuGet package installed in it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ASP.NET Core MVC application with the NuGet package](img/Figure_19.9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.8: ASP.NET Core MVC application with the Microsoft.Azure.CognitiveServices.Vision.ComputerVision
    NuGet package'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The code for the controller action is shown next. In this code, the cognitive
    service and key are declared. It also declares variables for the `ComputerVisionClient`
    and `VisionType` objects. It creates an instance of the `ComputerVisionClient`
    type, providing it the URL and the key.
  prefs: []
  type: TYPE_NORMAL
- en: The `VisionTypes` list consists of multiple types of data sought from the image—tags,
    descriptions, and objects are added. Only these parameters will be extracted from
    the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'An `HttpClient` object is instantiated to download the image using the URL
    provided by the user and sends this binary data to the Cognitive Services endpoint
    using the `AnalyzeImageInStreamAsync` function of type `ComputerVisionClient`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The results are looped through and tags are returned to the user. Similarly,
    descriptions and object properties can also be returned to the user. Now let's
    check out the ways we can safeguard the exposure of service keys.
  prefs: []
  type: TYPE_NORMAL
- en: Safeguarding the Cognitive Services key
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are multiple ways to safeguard the exposure of keys to other actors. This
    can be done using the API Management resource in Azure. It can also be done using
    Azure Functions Proxies.
  prefs: []
  type: TYPE_NORMAL
- en: Using Azure Functions Proxies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure Functions Proxies can refer to any URL, whether internal or external.
    When a request reaches Azure Functions Proxies, it will use the URL of the cognitive
    service along with the key to invoke the cognitive endpoint, and it will also
    override the request parameters and add the incoming image URL and append it to
    the cognitive endpoint URL as POST data. When a response comes back from the service,
    it will override the response, remove the headers, and pass JSON data back to
    the user.
  prefs: []
  type: TYPE_NORMAL
- en: Consuming Cognitive Services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consuming Cognitive Services follows a consistent pattern. Each cognitive service
    is available as a REST API, with each API expecting different sets of parameters
    to work on. Clients invoking these URLs should check out the documentation for
    associate parameters and provide values for them. Consuming URLs is a relatively
    raw method of using Cognitive Services. Azure provides SDKs for each service and
    for multiple languages. Clients can use these SDKs to work with Cognitive Services.
  prefs: []
  type: TYPE_NORMAL
- en: The `https://{luis resource name}-authoring.cognitiveservices.azure.com/` and
    the production API is available at
  prefs: []
  type: TYPE_NORMAL
- en: '`https://{azure region}.api.cognitive.microsoft.com/luis/prediction/v3.0/apps/{application
    id}/slots/production/predict?subscription-key={cognitive key} &verbose=true&show-all-intents=true&log=true&query=YOUR_QUERY_HERE`.'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the Face API is available at `https://{endpoint}/face/v1.0/detect[?returnFaceId][&returnFaceLandmarks][&returnFaceAttributes][&recognitionModel][&returnRecognitionModel][&detectionModel]`.
  prefs: []
  type: TYPE_NORMAL
- en: There are many Cognitive Services APIs, with each having multiple flavors in
    terms of URLs, and the best way to know about these URLs is to use the Azure documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you gained an understanding of the deployment architecture
    and application architecture for creating intelligent applications in Azure. Azure
    provides Cognitive Services with numerous endpoints—each endpoint is responsible
    for executing an AI-related algorithm and providing outputs. Almost all Cognitive
    Services endpoints work in a similar manner with regard to HTTP requests and responses.
    These endpoints can also be invoked using SDKs provided by Azure for different
    languages, and you saw an example of obtaining visual features using them. There
    are more than 50 different endpoints, and you are advised to get an understanding
    of the nature of endpoints using the API console feature provided by Azure.
  prefs: []
  type: TYPE_NORMAL
