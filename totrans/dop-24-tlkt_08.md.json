["```\n`1` `cd` k8s-specs\n`2` \n`3` git pull \n```", "``````````````````````````````````````````````````````````````````````````````````````````` Next, we’ll need a cluster which we can use to experiment with ServiceAccounts. The requirements are the same as those we used in the previous chapter. We’ll need **Kubernetes version 1.9** or higher as well as **nginx Ingress Controller**, **RBAC**, and a **default StorageClass**. If you didn’t destroy it, please continue using the cluster you created in the previous chapter. Otherwise, it should be reasonably fast to create a new one. For your convenience, the Gists and the specs we used before are available here as well.    *   [docker4mac.sh](https://gist.github.com/06e313db2957e92b1df09fe39c249a14): **Docker for Mac** with 2 CPUs, 2GB RAM, and with **nginx Ingress**. *   [minikube.sh](https://gist.github.com/536e6329e750b795a882900c09feb13b): **minikube** with 2 CPUs, 2GB RAM, and with `ingress`, `storage-provisioner`, and `default-storageclass` addons enabled. *   [kops.sh](https://gist.github.com/2a3e4ee9cb86d4a5a65cd3e4397f48fd): **kops in AWS** with 3 t2.small masters and 2 t2.medium nodes spread in three availability zones, and with **nginx Ingress** (assumes that the prerequisites are set through [Appendix B](part0018.html#appendix-b)). *   [minishift.sh](https://gist.github.com/c9968f23ecb1f7b2ec40c6bcc0e03e4f): **minishift** with 2 CPUs, 2GB RAM, and version 1.16+. *   [gke.sh](https://gist.github.com/5c52c165bf9c5002fedb61f8a5d6a6d1): **Google Kubernetes Engine (GKE)** with 3 n1-standard-1 (1 CPU, 3.75GB RAM) nodes (one in each zone), and with **nginx Ingress** controller running on top of the “standard” one that comes with GKE. We’ll use nginx Ingress for compatibility with other platforms. Feel free to modify the YAML files if you prefer NOT to install nginx Ingress. *   [eks.sh](https://gist.github.com/5496f79a3886be794cc317c6f8dd7083): **Elastic Kubernetes Service (EKS)** with 2 t2.medium nodes, with **nginx Ingress** controller, and with a **default StorageClass**.    Now that we have a cluster, we can proceed with a few examples.    ### Configuring Jenkins Kubernetes Plugin    We’ll start by creating the same Jenkins StatefulSet we used in the previous chapter. Once it’s up-and-running, we’ll try to use [Jenkins Kubernetes plugin](https://github.com/jenkinsci/kubernetes-plugin). If we’re successful, we’ll have a tool which could be used to execute continuous delivery or deployment tasks inside a Kubernetes cluster.    ``` `1` cat sa/jenkins-no-sa.yml  ```   `````````````````````````````````````````````````````````````````````````````````````````` We won’t go through the definition since it is the same as the one we used in the previous chapter. There’s no mystery that has to be revealed, so we’ll move on and create the resources defined in that YAML.    ``` `1` kubectl apply `\\` `2 `    -f sa/jenkins-no-sa.yml `\\` `3 `    --record  ```   ````````````````````````````````````````````````````````````````````````````````````````` Next, we’ll wait until `jenkins` StatefulSet is rolled out.    ``` `1` kubectl -n jenkins `\\` `2 `    rollout status sts jenkins  ```   ```````````````````````````````````````````````````````````````````````````````````````` Next, we’ll discover the DNS (or IP) of the load balancer.    ``` `1` `CLUSTER_DNS``=``$(`kubectl -n jenkins `\\` `2 `    get ing jenkins `\\` `3 `    -o `jsonpath``=``\"{.status.loadBalancer.ingress[0].hostname}\"``)` `4`  `5` `echo` `$CLUSTER_DNS`  ```   ``````````````````````````````````````````````````````````````````````````````````````` Now that we know the address of the cluster, we can proceed and open Jenkins UI in a browser.    ``` `1` open `\"http://``$CLUSTER_DNS``/jenkins\"`  ```   `````````````````````````````````````````````````````````````````````````````````````` Now we need to go through the setup wizard. It’s a dull process, and I’m sure you’re not thrilled with the prospect of going through it. However, we’re still missing knowledge and tools that will allow us to automate the process. For now, we’ll have to do the boring part manually.    The first step is to get the initial admin password.    ``` `1` kubectl -n jenkins `\\` `2 `    `exec` jenkins-0 -it -- `\\` `3 `    cat /var/jenkins_home/secrets/initialAdminPassword  ```   ````````````````````````````````````````````````````````````````````````````````````` Please copy the output and paste it into the *Administrator password* field. Click the *Continue* button, followed with a click to *Install suggested plugins* button. Fill in the *Create First Admin User* fields and press the *Save and Finish* button.    Jenkins is ready, and only a click away. Please press the *Start using Jenkins* button.    If we are to use the [Kubernetes plugin](https://github.com/jenkinsci/kubernetes-plugin), we need to install it first. We’ll do that through the *available plugins section* of the *plugin manager screen*.    ``` `1` open `\"http://``$CLUSTER_DNS``/jenkins/pluginManager/available\"`  ```   ```````````````````````````````````````````````````````````````````````````````````` Type *Kubernetes* in the *Filter* field and select the checkbox next to it.    Since we are already in the plugin manager screen, we might just as well install BlueOcean as well. It’ll make Jenkins prettier.    Type *BlueOcean* in the *Filter* field and select the checkbox next to it.    Now that we selected the plugins we want, the next step is to install them. Please click the *Install without restart* button and wait until all the plugins (and their dependencies) are installed.    We are not yet finished. We still need to configure the newly installed Kubernetes plugin.    ``` `1` open `\"http://``$CLUSTER_DNS``/jenkins/configure\"`  ```   ``````````````````````````````````````````````````````````````````````````````````` The plugin adds Kubernetes as yet another *Cloud* provider. Please expand the *Add a new cloud* drop-down list inside the *Cloud* section, and select *Kubernetes*. The section you’re looking for should be somewhere close to the bottom of the screen.    Now that we added Kubernetes as a Cloud provider, we should confirm that it works. Please click the *Test Connection* button.    Unless you forgot to unable RBAC in your cluster, the output should be similar to the one that follows.    ``` `1` Error testing connection : Failure executing: GET at: https://kubernetes.default.svc\\ `2` /api/v1/namespaces/jenkins/pods. Message: Forbidden!Configured service account doesn\\ `3` 't have access. Service account may have been revoked. pods is forbidden: User \"syst\\ `4` em:serviceaccount:jenkins:default\" cannot list pods in the namespace \"jenkins\".  ```   `````````````````````````````````````````````````````````````````````````````````` API server rejected our request to list the Pods in the `jenkins` Namespace. Such a reaction makes perfect sense. If any process in any container could request anything from the API, our security efforts would be useless. What would be the point of trying to restrict users (humans), if all it takes is to create a single Pod that sends a request to the API server? Kube API rightfully denied our request to list the Pods.    Just as a username provides a sort of identity to humans, a ServiceAccount is an identity for all the processes that run in containers. Since we did not specify any ServiceAccount for the Pod where Jenkins is running, Kubernetes assigned one for us. The Pod is authenticated as the `default` account which happens to be bound to roles that give almost no permissions. In other words, if we do not define a ServiceAccount for a Pod, it’ll be associated with the ServiceAccount `default`, and the processes inside that Pod will not be able to requests almost anything from the API server.    The `default` ServiceAccount is created for every Namespace in the cluster. It is, in a way, similar to the default StorageClass. If a Pod does not have a ServiceAccount, it’ll get the `default`. That ServiceAccount has insufficient privileges, and it cannot do almost anything. We can bind more permissive role to the `default` ServiceAccount, but that would be a very uncommon solution to the problem.    We need to associate Jenkins process with an entity that has more permissions. As a minimum, we should be able to list the Pods in the `jenkins` Namespace. To do that, we have to learn about ServiceAccounts first.    We’ll delete `jenkins` Namespace and search for a simple way explore ServiceAccounts.    ``` `1` kubectl delete ns jenkins  ```   ````````````````````````````````````````````````````````````````````````````````` ### Exploring the `default` ServiceAccount    Jenkins might not be the best starting point in our exploration of ServiceAccounts. Too many things are happening that are out of our control. There’s too much “magic” hidden behind Jenkins code. Instead, we’ll start with something simpler. We’ll run `kubectl` as a Pod. If we manage to make that work, we should have no problem applying the newly acquired knowledge to Jenkins and other similar use-cases we might have.    Unfortunately, there is no `kubectl` official image (at least not in Docker Hub), so I built one. The definition is in the [vfarcic/kubectl](https://github.com/vfarcic/kubectl) GitHub repository. Let’s take a quick look.    ``` `1` curl https://raw.githubusercontent.com/vfarcic/kubectl/master/Dockerfile  ```   ```````````````````````````````````````````````````````````````````````````````` The Dockerfile is so uneventful and straightforward that there’s probably no need going through it. It’s a `kubectl` binary in an `alpine` based image. Not more, not less.    Let’s run it.    ``` `1` kubectl run kubectl `\\` `2 `    --image`=`vfarcic/kubectl `\\` `3 `    --restart`=`Never `\\` `4 `    sleep `10000`  ```   ``````````````````````````````````````````````````````````````````````````````` We should wait for a few moments until the image is pulled and the container that forms the Pod is running.    Let’s start by checking out the `serviceAccount` entry in the Pod specification.    ``` `1` kubectl get pod kubectl `\\` `2 `    -o `jsonpath``=``\"{.spec.serviceAccount}\"`  ```   `````````````````````````````````````````````````````````````````````````````` The output is as follows.    ``` `1` default  ```   ````````````````````````````````````````````````````````````````````````````` Since we did not specify any ServiceAccount, Kubernetes automatically assigned the `default`. That account was created with the Namespace.    We might be able to dig a bit more information in the `kubectl` container.    ``` `1` kubectl `exec` -it kubectl -- sh  ```   ```````````````````````````````````````````````````````````````````````````` No matter which ServiceAccount is used, Kubernetes always mounts a secret with the information about that account. The secret is mounted inside the `/var/run/secrets/kubernetes.io/serviceaccount` directory.    ``` `1` `cd` /var/run/secrets/kubernetes.io/serviceaccount `2`  `3` ls -la  ```   ``````````````````````````````````````````````````````````````````````````` We entered into the secret’s directory and listed all the files. The output is as follows.    ``` `1` total 4 `2` ... . `3` ... .. `4` ... ..2018_05_07_00_35_25.899750157 `5` ... ..data -> ..2018_05_07_00_35_25.899750157 `6` ... ca.crt -> ..data/ca.crt `7` ... namespace -> ..data/namespace `8` ... token -> ..data/token  ```   `````````````````````````````````````````````````````````````````````````` We can see that it created three soft-links (`ca.crt`, `namespace`, and `token`) which are pointing to a directory that contains the actual files. You should be able to guess what those files contain. The token and the certificate are used for authentication when communicating with the API server. The third file contains only the Namespace in which the Pod is running.    Let’s try a very simple operation.    ``` `1` kubectl get pods  ```   ````````````````````````````````````````````````````````````````````````` The output is as follows.    ``` `1` Error from server (Forbidden): pods is forbidden: User \"system:serviceaccount:defaul\\ `2` t:default\" cannot list pods in the namespace \"default\"  ```   ```````````````````````````````````````````````````````````````````````` We got a similar error message as when we tried to use Jenkins’ Kubernetes plugin without credentials. Once again we’re faced with limited permissions bound to the `default` account. We’ll change that soon. For now, we’ll exit the container and remove the `kubectl` Pod.    ``` `1` `exit` `2`  `3` kubectl delete pod kubectl  ```   ``````````````````````````````````````````````````````````````````````` We saw the limitations of the `default` account. We’ll try to overcome them by creating our own ServiceAccounts.    ### Creating ServiceAccounts    Let’s take a look at service accounts currently available in the `default` Namespace.    ``` `1` kubectl get sa  ```   `````````````````````````````````````````````````````````````````````` The output is as follows.    ``` `1` NAME    SECRETS AGE `2` default 1       24m  ```   ````````````````````````````````````````````````````````````````````` At the moment, there is only one ServiceAccount called `default`. We already saw the limitations of that account. It is stripped from (almost) all the privileges. If we check the other Namespaces, we’ll notice that all of them have only the `default` ServiceAccount. Whenever we create a new Namespace, Kubernetes creates that account for us.    We already established that we’ll need to create new ServiceAccounts if we are ever to allow processes in containers to communicate with Kube API. As the first exercise, we’ll create an account that will enable us to view (almost) all the resources in the `default` Namespace. The definition is available in the `sa/view.yml` file.    ``` `1` cat sa/view.yml  ```   ```````````````````````````````````````````````````````````````````` The output is as follows.    ```  `1` `apiVersion``:` `v1`  `2` `kind``:` `ServiceAccount`  `3` `metadata``:`  `4`  `name``:` `view`  `5`   `6` `---`  `7`   `8` `apiVersion``:` `rbac.authorization.k8s.io/v1beta1`  `9` `kind``:` `RoleBinding` `10` `metadata``:` `11 `  `name``:` `view` `12` `roleRef``:` `13 `  `apiGroup``:` `rbac.authorization.k8s.io` `14 `  `kind``:` `ClusterRole` `15 `  `name``:` `view` `16` `subjects``:` `17` `-` `kind``:` `ServiceAccount` `18 `  `name``:` `view`  ```   ``````````````````````````````````````````````````````````````````` The YAML defines two resources. The first one is the `ServiceAccount` named `view`. The ServiceAccount kind of resources is on pair with Namespace in its simplicity. Excluding a few flags which we won’t explore just yet, the only thing we can do with it is to declare its existence. The real magic is defined in the RoleBinding.    Just as with RBAC users and groups, RoleBindings are tying Roles to ServiceAccounts. Since our objective to provide read-only permissions that can be fulfilled with the ClusterRole `view`, we did not need to create a new Role. Instead, we’re binding the ClusterRole `view` with the ServiceAccount with the same name.    If you are already experienced with RBAC applied to users and groups, you probably noticed that ServiceAccounts follow the same pattern. The only substantial difference, from YAML perspective, is that the `kind` of the subject is now `ServiceAccount`, instead of being `User` or `Group`.    Let’s create the YAML and observe the results.    ``` `1` kubectl apply -f sa/view.yml --record  ```   `````````````````````````````````````````````````````````````````` The output should show that the ServiceAccount and the RoleBinding were created.    Next, we’ll list the ServiceAccounts in the `default` Namespace and confirm that the new one was created.    ``` `1` kubectl get sa  ```   ````````````````````````````````````````````````````````````````` The output is as follows.    ``` `1` NAME    SECRETS AGE `2` default 1       27m `3` view    1       6s  ```   ```````````````````````````````````````````````````````````````` Let’s take a closer look at the ServiceAccount `view` we just created.    ``` `1` kubectl describe sa view  ```   ``````````````````````````````````````````````````````````````` The output is as follows.    ```  `1` `Name``:`        `view`  `2` `Namespace``:`   `default`  `3` `Labels``:`      `<``none``>`  `4` `Annotations``:` `kubectl``.``kubernetes``.``io``/``last``-``applied``-``configuration``=``{``\"apiVersion\"``:``\"v1\"``,``\"ki\\`  `5` `nd\"``:``\"ServiceAccount\"``,``\"metadata\"``:{``\"annotations\"``:{},``\"name\"``:``\"view\"``,``\"namespace\"``:``\"default\\`  `6` `\"``}}`  `7`             `kubernetes``.``io``/``change``-``cause``=``kubectl` `apply` `--``filename``=``sa``/``view``.``yml` `--``recor``\\`  `8` `d``=``true`  `9` `Image` `pull` `secrets``:` `<``none``>` `10` `Mountable` `secrets``:`  `view``-``token``-``292``vm` `11` `Tokens``:`             `view``-``token``-``292``vm` `12` `Events``:`             `<``none``>`  ```   `````````````````````````````````````````````````````````````` There’s not much to look at since, as we already saw from the definition, ServiceAccounts are only placeholders for bindings.    We should be able to get more information from the binding.    ``` `1` kubectl describe rolebinding view  ```   ````````````````````````````````````````````````````````````` The output is as follows.    ```  `1` `Name``:`        `view`  `2` `Labels``:`      `<``none``>`  `3` `Annotations``:` `kubectl``.``kubernetes``.``io``/``last``-``applied``-``configuration``={``\"apiVersion\"``:``\"rbac.au\\`  `4` `thorization.k8s.io/v1beta1\"``,``\"kind\"``:``\"RoleBinding\"``,``\"metadata\"``:{``\"annotations\"``:{},``\"name\"``\\`  `5` `:``\"view\"``,``\"namespace\"``:``\"default\"``},``\"roleRef\"``:{``\"``ap``...`  `6`             `kubernetes``.``io``/change-cause=kubectl apply --filename=sa/``view``.``yml` `--``recor``\\`  `7` `d``=``true`  `8` `Role``:`  `9`  `Kind``:` `ClusterRole` `10 `  `Name``:` `view` `11` `Subjects``:` `12 `  `Kind`           `Name` `Namespace` `13 `  `----`           `----` `---------` `14 `  `ServiceAccount` `view`  ```   ```````````````````````````````````````````````````````````` We can see that the `ClusterRole` named `view` has a single subject with the ServiceAccount.    Now that we have the ServiceAccount that has enough permissions to view (almost) all the resources, we’ll create a Pod with `kubectl` which we can use to explore permissions.    The definition is in the `sa/kubectl-view.yml` file.    ``` `1` cat sa/kubectl-view.yml  ```   ``````````````````````````````````````````````````````````` The output is as follows.    ```  `1` `apiVersion``:` `v1`  `2` `kind``:` `Pod`  `3` `metadata``:`  `4`  `name``:` `kubectl`  `5` `spec``:`  `6`  `serviceAccountName``:` `view`  `7`  `containers``:`  `8`  `-` `name``:` `kubectl`  `9`    `image``:` `vfarcic/kubectl` `10 `    `command``:` `[``\"sleep\"``]` `11 `    `args``:` `[``\"100000\"``]`  ```   `````````````````````````````````````````````````````````` The only new addition is the `serviceAccountName: view` entry. It associates the Pod with the account.    Let’s create the Pod and describe it.    ``` `1` kubectl apply `\\` `2 `    -f sa/kubectl-view.yml `\\` `3 `    --record `4`  `5` kubectl describe pod kubectl  ```   ````````````````````````````````````````````````````````` The relevant parts of the output of the latter command are as follows.    ```  `1` `Name``:` `kubectl`  `2` `...`  `3` `Containers``:`  `4`  `kubectl``:`  `5`    `...`  `6`    `Mounts``:`  `7`      `/var/run/secrets/kubernetes.io/serviceaccount from view-token-292vm (ro)`  `8` `...`  `9` `Volumes``:` `10 `  `view-token-292vm``:` `11 `    `Type``:`       `Secret (a volume populated by a Secret)` `12 `    `SecretName``:` `view-token-292vm` `13` `...`  ```   ```````````````````````````````````````````````````````` Since we declared that we want to associate the Pod with the account `view`, Kubernetes mounted a token to the container. If we defined more containers in that Pod, all would have the same mount.    Further on, we can see that the mount is using a Secret. It contains the same file structure we observed earlier with the `default` account.    Let’s see whether we can retrieve the Pods from the same Namespace.    ``` `1` kubectl `exec` -it kubectl -- sh `2`  `3` kubectl get pods  ```   ``````````````````````````````````````````````````````` We entered into the Shell of the container and listed the Pods.    The output is as follows.    ``` `1` NAME    READY STATUS  RESTARTS AGE `2` kubectl 1/1   Running 0        55s  ```   `````````````````````````````````````````````````````` Now that the Pod is associated with the ServiceAccount that has `view` permissions, we can indeed list the Pods. At the moment, we can see the `kubectl` Pod since it is the only one running in the `default` Namespace.    Even though you probably know the answer, we’ll confirm that we can indeed only view the resources and that all other operations are forbidden. We’ll try to create a new Pod.    ``` `1` kubectl run new-test `\\` `2 `    --image`=`alpine `\\` `3 `    --restart`=`Never `\\` `4 `    sleep `10000`  ```   ````````````````````````````````````````````````````` The output is a follows.    ``` `1` Error from server (Forbidden): pods is forbidden: User \"system:serviceaccount:defaul\\ `2` t:view\" cannot create pods in the namespace \"default\"  ```   ```````````````````````````````````````````````````` As expected, we cannot create Pods. Since we bound the ClusterRole `view` to the ServiceAccount, and that allows us only read-only access to resources.    We’ll exit the container and delete the resources we created before we continue exploring ServiceAccounts.    ``` `1` `exit` `2`  `3` kubectl delete -f sa/kubectl-view.yml  ```   ``````````````````````````````````````````````````` Jenkins’ Kubernetes plugin needs to have full permissions related to Pods. It should be able to create them, to retrieve logs from them, to execute processes, to delete them, and so on. The resources defined in `sa/pods.yml` should allow us just that.    ``` `1` cat sa/pods.yml  ```   `````````````````````````````````````````````````` The output is as follows.    ```  `1` `apiVersion``:` `v1`  `2` `kind``:` `ServiceAccount`  `3` `metadata``:`  `4`  `name``:` `pods-all`  `5`  `namespace``:` `test1`  `6`   `7` `---`  `8`   `9` `kind``:` `Role` `10` `apiVersion``:` `rbac.authorization.k8s.io/v1beta1` `11` `metadata``:` `12 `  `name``:` `pods-all` `13 `  `namespace``:` `test1` `14` `rules``:` `15` `-` `apiGroups``:` `[``\"\"``]` `16 `  `resources``:` `[``\"pods\"``,` `\"pods/exec\"``,` `\"pods/log\"``]` `17 `  `verbs``:` `[``\"*\"``]` `18`  `19` `---` `20`  `21` `apiVersion``:` `rbac.authorization.k8s.io/v1beta1` `22` `kind``:` `RoleBinding` `23` `metadata``:` `24 `  `name``:` `pods-all` `25 `  `namespace``:` `test1` `26` `roleRef``:` `27 `  `apiGroup``:` `rbac.authorization.k8s.io` `28 `  `kind``:` `Role` `29 `  `name``:` `pods-all` `30` `subjects``:` `31` `-` `kind``:` `ServiceAccount` `32 `  `name``:` `pods-all`  ```   ````````````````````````````````````````````````` Just as before, we are creating a ServiceAccount. This time we’re naming it `pods-all`. Since none of the existing roles provide the types of privileges we need, we’re defining a new one that provides full permissions with Pods. Finally, the last resource is the binding that ties the two together. All three resources are, this time, defined in the Namespace `test1`.    Let’s create the resources.    ``` `1` kubectl apply -f sa/pods.yml `\\` `2 `    --record  ```   ```````````````````````````````````````````````` So far, we did not explore the effect of ServiceAccounts to Namespaces other than those where we created them, so we’ll create another one called `test2`.    ``` `1` kubectl create ns test2  ```   ``````````````````````````````````````````````` Finally, we’ll run `kubectl` as a Pod so that we can test the new account. Let’s take a very quick look at the updated `kubectl` Pod definition.    ``` `1` cat sa/kubectl-test1.yml  ```   `````````````````````````````````````````````` The output is as follows.    ```  `1` `apiVersion``:` `v1`  `2` `kind``:` `Pod`  `3` `metadata``:`  `4`  `name``:` `kubectl`  `5`  `namespace``:` `test1`  `6` `spec``:`  `7`  `serviceAccountName``:` `pods-all`  `8`  `containers``:`  `9`  `-` `name``:` `kubectl` `10 `    `image``:` `vfarcic/kubectl` `11 `    `command``:` `[``\"sleep\"``]` `12 `    `args``:` `[``\"100000\"``]`  ```   ````````````````````````````````````````````` The only differences from the previous `kubectl` definition are in the `namespace` and the `serviceAccountName`. I’ll assume that there’s no need for an explanation. Instead, we’ll proceed and `apply` the definition.    ``` `1` kubectl apply `\\` `2 `    -f sa/kubectl-test1.yml `\\` `3 `    --record  ```   ```````````````````````````````````````````` Now we’re ready to test the new account.    ``` `1` kubectl -n test1 `exec` -it kubectl -- sh `2`  `3` kubectl get pods  ```   ``````````````````````````````````````````` We entered the `kubectl` container and retrieved the Pods.    The output is as follows.    ``` `1` NAME    READY STATUS  RESTARTS AGE `2` kubectl 1/1   Running 0        5m  ```   `````````````````````````````````````````` We already experienced the same result when we used the ServiceAccount with the `view` Role, so let’s try something different and try to create a Pod.    ``` `1` kubectl run new-test `\\` `2 `    --image`=`alpine `\\` `3 `    --restart`=`Never `\\` `4 `    sleep `10000`  ```   ````````````````````````````````````````` Unlike before, this time the `pod \"new-test\"` was `created`. We can confirm that by listing the Pods one more time.    ``` `1` kubectl get pods  ```   ```````````````````````````````````````` The output is as follows.    ``` `1` NAME     READY STATUS  RESTARTS AGE `2` kubectl  1/1   Running 0        6m `3` new-test 1/1   Running 0        17s  ```   ``````````````````````````````````````` How about creating a Deployment?    ``` `1` kubectl run new-test `\\` `2 `    --image`=`alpine sleep `10000`  ```   `````````````````````````````````````` As you hopefully already know, if we execute a `run` command without the `--restart=Never` argument, Kubernetes creates a Deployment, instead of a Pod.    The output is as follows.    ``` `1` Error from server (Forbidden): deployments.extensions is forbidden: User \"system:ser\\ `2` viceaccount:test1:pods-all\" cannot create deployments.extensions in the namespace \"t\\ `3` est1\"  ```   ````````````````````````````````````` It’s obvious that our ServiceAccount does not have any permissions aside from those related to Pods, so we were forbidden from creating a Deployment.    Let’s see what happens if, for example, we try to retrieve the Pods from the Namespace `test2`. As a reminder, we are still inside a container that forms the Pod in the `test1` Namespace.    ``` `1` kubectl -n test2 get pods  ```   ```````````````````````````````````` The ServiceAccount was created in the `test1` Namespace. Therefore only the Pods created in the same Namespace can be attached to the `pods-all` ServiceAccount. In this case, the principal thing to note is that the RoleBinding that gives us the permissions to, for example, retrieve the Pods, exists only in the `test1` Namespace. The moment we tried to retrieve the Pods from a different Namespace, the API server responded with an error notifying us that we do not have permissions to `list pods in the namespace \"test2\"`.    We’ll exit the container and delete the resources we created, before we explore other aspects of ServiceAccounts.    ``` `1` `exit` `2`  `3` kubectl delete -f sa/kubectl-test1.yml  ```   ``````````````````````````````````` We saw that, with the previous definition, we obtained permissions only within the same Namespace as the Pod attached to the ServiceAccount. In some cases that is not enough. Jenkins is a good use-case. We might decide to run Jenkins master in one Namespace but run the builds in another. Or, we might create a pipeline that deploys a beta version of our application and tests it in one Namespace and, later on, deploys it as production release in another. Surely there is a way to accommodate such needs.    Let’s take a look at yet another YAML.    ``` `1` cat sa/pods-all.yml  ```   `````````````````````````````````` The output is as follows.    ```  `1` `apiVersion``:` `v1`  `2` `kind``:` `ServiceAccount`  `3` `metadata``:`  `4`  `name``:` `pods-all`  `5`  `namespace``:` `test1`  `6`   `7` `---`  `8`   `9` `kind``:` `Role` `10` `apiVersion``:` `rbac.authorization.k8s.io/v1beta1` `11` `metadata``:` `12 `  `name``:` `pods-all` `13 `  `namespace``:` `test1` `14` `rules``:` `15` `-` `apiGroups``:` `[``\"\"``]` `16 `  `resources``:` `[``\"pods\"``,` `\"pods/exec\"``,` `\"pods/log\"``]` `17 `  `verbs``:` `[``\"*\"``]` `18`  `19` `---` `20`  `21` `kind``:` `Role` `22` `apiVersion``:` `rbac.authorization.k8s.io/v1beta1` `23` `metadata``:` `24 `  `name``:` `pods-all` `25 `  `namespace``:` `test2` `26` `rules``:` `27` `-` `apiGroups``:` `[``\"\"``]` `28 `  `resources``:` `[``\"pods\"``,` `\"pods/exec\"``,` `\"pods/log\"``]` `29 `  `verbs``:` `[``\"*\"``]` `30`  `31` `---` `32`  `33` `apiVersion``:` `rbac.authorization.k8s.io/v1beta1` `34` `kind``:` `RoleBinding` `35` `metadata``:` `36 `  `name``:` `pods-all` `37 `  `namespace``:` `test1` `38` `roleRef``:` `39 `  `apiGroup``:` `rbac.authorization.k8s.io` `40 `  `kind``:` `Role` `41 `  `name``:` `pods-all` `42` `subjects``:` `43` `-` `kind``:` `ServiceAccount` `44 `  `name``:` `pods-all` `45`  `46` `---` `47`  `48` `apiVersion``:` `rbac.authorization.k8s.io/v1beta1` `49` `kind``:` `RoleBinding` `50` `metadata``:` `51 `  `name``:` `pods-all` `52 `  `namespace``:` `test2` `53` `roleRef``:` `54 `  `apiGroup``:` `rbac.authorization.k8s.io` `55 `  `kind``:` `Role` `56 `  `name``:` `pods-all` `57` `subjects``:` `58` `-` `kind``:` `ServiceAccount` `59 `  `name``:` `pods-all` `60 `  `namespace``:` `test1`  ```   ````````````````````````````````` We start by creating a ServiceAccount and a Role called `pods-all` in the `test1` Namespace. Further on, we’re creating the same role but in the `test2` Namespace. Finally, we’re creating RoleBindings in both Namespaces. The only difference between the two is in a single line. The RoleBinding in the `test2` Namespace has the `subjects` entry `namespace: test1`. With it, we are linking a binding from one Namespace to a ServiceAccount in another. As a result, we should be able to create a Pod in the `test1` Namespace that will have full permissions to operate Pods in both Namespaces.    The two Roles could have been with different permission. They are the same (for now) only for simplicity reasons. We could have simplified the definition by defining a single ClusterRole and save ourselves from having two Roles (one in each Namespace). However, once we get back to Jenkins, we’ll probably want to have different permissions in different Namespaces, so we’re defining two Roles as a practice.    Let’s apply the new definition, create a `kubectl` Pod again, and enter inside its only container.    ``` `1` kubectl apply -f sa/pods-all.yml `\\` `2 `    --record `3`  `4` kubectl apply `\\` `5 `    -f sa/kubectl-test2.yml `\\` `6 `    --record `7`  `8` kubectl -n test1 `exec` -it kubectl -- sh  ```   ```````````````````````````````` There’s probably no need to confirm again that we can retrieve the Pods from the same Namespace so we’ll jump straight to testing whether we can now operate within the `test2` Namespace.    ``` `1` kubectl -n test2 get pods  ```   ``````````````````````````````` The output shows that `no resources` were `found`. If we did not have permissions to view the files, we’d get the already familiar `forbidden` message instead.    To be on the safe side, we’ll try to create a Pod in the `test2` Namespace.    ``` `1` kubectl -n test2 `\\` `2 `    run new-test `\\` `3 `    --image`=`alpine `\\` `4 `    --restart`=`Never `\\` `5 `    sleep `10000` `6`  `7` kubectl -n test2 get pods  ```   `````````````````````````````` The output of the latter command is as follows.    ``` `1` NAME     READY STATUS  RESTARTS AGE `2` new-test 1/1   Running 0        18s  ```   ````````````````````````````` The Pod was created in the `test2` Namespace. Mission was accomplished, and we can get out of the container and delete the Namespaces we created, before we try to apply the knowledge about ServiceAccounts to Jenkins.    ``` `1` `exit` `2`  `3` kubectl delete ns test1 test2  ```   ```````````````````````````` ### Configuring Jenkins Kubernetes Plugin With ServiceAccounts    Now that we got a grip on ServiceAccounts, it should be relatively straightforward to correct the problem we experienced with Jenkins. As a reminder, we could not configure the Kubernetes plugin. We experienced the same `forbidden` message as when we tried to use `kubectl` container with the `default` ServiceAccount. Now that we know that ServiceAccounts provide permissions to processes running inside containers, all we have to do is to define one for Jenkins.    We’ll spice it up a bit with a slightly more complicated use-case. We’ll try to run Jenkins master in one Namespace and perform builds in another. That way we can have a clear separation between Jenkins and “random” stuff our builds might be doing. Through such separation, we can guarantee that Jenkins will (probably) not be affected if we do something wrong in our builds.    Let’s take a look at yet another Jenkins definition.    ``` `1` cat sa/jenkins.yml  ```   ``````````````````````````` The relevant parts of the output are as follows.    ```  `1` `...`  `2` `apiVersion``:` `v1`  `3` `kind``:` `Namespace`  `4` `metadata``:`  `5`  `name``:` `build`  `6`   `7` `---`  `8`   `9` `apiVersion``:` `v1` `10` `kind``:` `ServiceAccount` `11` `metadata``:` `12 `  `name``:` `jenkins` `13 `  `namespace``:` `jenkins` `14`  `15` `---` `16`  `17` `kind``:` `Role` `18` `apiVersion``:` `rbac.authorization.k8s.io/v1beta1` `19` `metadata``:` `20 `  `name``:` `jenkins` `21 `  `namespace``:` `build` `22` `rules``:` `23` `-` `apiGroups``:` `[``\"\"``]` `24 `  `resources``:` `[``\"pods\"``,` `\"pods/exec\"``,` `\"pods/log\"``]` `25 `  `verbs``:` `[``\"*\"``]` `26` `-` `apiGroups``:` `[``\"\"``]` `27 `  `resources``:` `[``\"secrets\"``]` `28 `  `verbs``:` `[``\"get\"``]` `29`  `30` `---` `31`  `32` `apiVersion``:` `rbac.authorization.k8s.io/v1beta1` `33` `kind``:` `RoleBinding` `34` `metadata``:` `35 `  `name``:` `jenkins` `36 `  `namespace``:` `build` `37` `roleRef``:` `38 `  `apiGroup``:` `rbac.authorization.k8s.io` `39 `  `kind``:` `Role` `40 `  `name``:` `jenkins` `41` `subjects``:` `42` `-` `kind``:` `ServiceAccount` `43 `  `name``:` `jenkins` `44 `  `namespace``:` `jenkins` `45` `...` `46` `apiVersion``:` `apps/v1beta2` `47` `kind``:` `StatefulSet` `48` `metadata``:` `49 `  `name``:` `jenkins` `50 `  `namespace``:` `jenkins` `51` `spec``:` `52 `  `...` `53 `  `template``:` `54 `    `...` `55 `    `spec``:` `56 `      `serviceAccountName``:` `jenkins` `57 `      `...`  ```   `````````````````````````` This time we are creating a second Namespace called `build` and a ServiceAccount `jenkins` in the `jenkins` namespace. Further on, we created a Role and a RoleBinding that provides required permissions in the `build` Namespace. As such, we bound the Role with the ServiceAccount in the `jenkins` Namespace. As a result, Jenkins should be able to create Pods in `build`, but it won’t be able to do anything in its own Namespace `jenkins`. That way we can be relatively safe that a problem in our builds will not affect Jenkins. If we specified ResourceQuotas and LimitRanges for both Namespaces, our solution would be even more bulletproof. But, since I assume that you know how to do that, I excluded them in an attempt to simplify the definition.    Let’s apply the config and observe the result.    ``` `1` kubectl apply `\\` `2 `    -f sa/jenkins.yml `\\` `3 `    --record  ```   ````````````````````````` We can see from the output that the resources were created. All that’s left is to wait until Jenkins rolls out.    ``` `1` kubectl -n jenkins `\\` `2 `    rollout status sts jenkins  ```   ```````````````````````` Now that Jenkins is up-and-running, we should open it in a browser and repeat the same setup steps we did before.    ``` `1` open `\"http://``$CLUSTER_DNS``/jenkins\"`  ```   ``````````````````````` The first step is to get the initial admin password.    ``` `1` kubectl -n jenkins `\\` `2 `    `exec` jenkins-0 -it -- `\\` `3 `    cat /var/jenkins_home/secrets/initialAdminPassword  ```   `````````````````````` Please copy the output and paste it into the *Administrator password* field. Click *Continue*, followed by the *Install suggested plugins* button. The rest of the setup requires you to *Create First Admin User*, so please go ahead. You don’t need my help on that one.    Just as before, we’ll need to add *Kubernetes* and *BlueOcean* plugins.    ``` `1` open `\"http://``$CLUSTER_DNS``/jenkins/pluginManager/available\"`  ```   ````````````````````` You already know what to do. Once you’re done installing the two plugins, we’ll go to the configuration screen.    ``` `1` open `\"http://``$CLUSTER_DNS``/jenkins/configure\"`  ```   ```````````````````` Please expand the *Add a new cloud* drop-down list in the *Cloud* section and select *Kubernetes*.    Now that we have the ServiceAccount that grants us the required permissions, we can click the *Test Connection* button and confirm that it works.    The output is as follows.    ``` `1` Error testing connection : Failure executing: GET at: https://kubernetes.default.svc\\ `2` /api/v1/namespaces/jenkins/pods. Message: Forbidden!Configured service account doesn\\ `3` 't have access. Service account may have been revoked. pods is forbidden: User \"syst\\ `4` em:serviceaccount:jenkins:jenkins\" cannot list pods in the namespace \"jenkins\".  ```   ``````````````````` Did we do something wrong? We didn’t. That was the desired behavior. By not specifying a Namespace, Jenkins checked whether it has necessary permission in the Namespace where it runs. If we try to invoke Kube API from a container, it’ll always use the same Namespace as the one where the container is. Jenkins is no exception. On the other hand, our YAML explicitly defined that we should have permissions to create Pods in the `build` Namespace. Let’s fix that.    Please type *build* in the *Kubernetes Namespace* field and click the *Test Connection* button again.    This time the output shows that the `connection test` was `successful`. We managed to configure Jenkins’ Kubernetes plugin to operate inside the `build` Namespace. Still, there is one more thing missing.    When we create a job that uses Kubernetes Pods, an additional container will be added. That container will use JNLP to establish communication with the Jenkins master. We need to specify a valid address JNLP can use to connect to the master. Since the Pods will be in the `build` Namespace and the master is in `jenkins`, we need to use the longer DNS name that specifies both the name of the service (`jenkins`) as well as the Namespace (also `jenkins`). On top of all that, our master is configured to respond to requests with the root path `/jenkins`. All the all, the full address Pods can use to communicate with Jenkins master is should be `http://[SERVICE_NAME].[NAMESPACE]/[PATH]`. Since all three of those elements are `jenkins`, the “real” address is `http://jenkins.jenkins/jenkins`. Please type it inside the *Jenkins URL* field and click the *Save* button.    Now we’re ready to create a job that’ll test that everything works as expected.    Please click the *New Item* link from the left-hand menu to open a screen for creating jobs. Type *my-k8s-job* in the *item name* field, select *Pipeline* as the type, and click the *OK* button. Once inside the job configuration screen, click the *Pipeline* tab and write the script that follows inside the *Pipeline Script* field.    ```  `1` `podTemplate``(`  `2`    `label:` `'kubernetes'``,`  `3`    `containers:` `[`  `4`        `containerTemplate``(``name:` `'maven'``,` `image:` `'maven:alpine'``,` `ttyEnabled:` `true``,` `co``\\`  `5` `mmand:` `'cat'``),`  `6`        `containerTemplate``(``name:` `'golang'``,` `image:` `'golang:alpine'``,` `ttyEnabled:` `true``,` `\\`  `7` `command:` `'cat'``)`  `8`    `]`  `9` `)` `{` `10 `    `node``(``'kubernetes'``)` `{` `11 `        `container``(``'maven'``)` `{` `12 `            `stage``(``'build'``)` `{` `13 `                `sh` `'mvn --version'` `14 `            `}` `15 `            `stage``(``'unit-test'``)` `{` `16 `                `sh` `'java -version'` `17 `            `}` `18 `        `}` `19 `        `container``(``'golang'``)` `{` `20 `            `stage``(``'deploy'``)` `{` `21 `                `sh` `'go version'` `22 `            `}` `23 `        `}` `24 `    `}` `25` `}`  ```   `````````````````` The job is relatively simple. It uses `podTemplate` to define a `node` that will contain two containers. One of those is `golang`, and the other is `maven`. In both cases the `command` is `cat`. Without a long-running command (process `1`), the container would exit immediately, Kubernetes would detect that and start another container based on the same image. It would fail again, and the loop would continue. Without the main process running, we’d enter into a never-ending loop.    Further on, we are defining that we want to use the `podTemplate` as a node and we start executing `sh` commands in different containers. Those commands only output software versions. The goal of this job is not to demonstrate a full CD pipeline (we’ll do that later), but only to prove that integration with Kubernetes works and that we can use different containers that contain the tools we need.    Don’t forget to click the *Save* button.    Now that we have a job, we should run it and validate that the integration with Kubernetes indeed works.    Please click the *Open Blue Ocean* link from the left-hand menu followed by the *Run* button.    We’ll let Jenkins run the build and switch to Shell to observe what’s happening.    ``` `1` kubectl -n build get pods  ```   ````````````````` After a while, the output should be as follows.    ``` `1` NAME              READY STATUS            RESTARTS AGE `2` jenkins-slave-... 0/3   ContainerCreating 0        11s  ```   ```````````````` We can see that Jenkins created a Pod with three containers. At this moment in time, those containers are still not fully functional. Kubernetes is probably pulling them to the assigned node.    You might be wondering why are there three containers even though we specified two. Jenkins added the third to the Pod definition. It contains JNLP that is in charge of communication between Pods acting as nodes and Jenkins masters. From user’s perspective, JNLP is non-existent. It is a transparent process we do not need to worry about.    Let’s take another look at the Pods in the `build` Namespace.    ``` `1` kubectl -n build get pods  ```   ``````````````` The output is as follows.    ``` `1` NAME              READY STATUS  RESTARTS AGE `2` jenkins-slave-... 3/3   Running 0        5s  ```   `````````````` This time, if you are a fast reader, all the containers that form the Pod are running, and Jenkins is using them to execute the instructions we defined in the job.    Let’s take another look at the Pods.    ``` `1` kubectl -n build get pods  ```   ````````````` The output is as follows.    ``` `1` NAME              READY STATUS      RESTARTS AGE `2` jenkins-slave-... 3/3   Terminating 0        32s  ```   ```````````` Once Jenkins finished executing the instructions from the job, it issued a command to Kube API to terminate the Pod.    Jenkins nodes created through `podTemplate` are called on-shot agents. Instead of having long-running nodes, they are created when needed and destroyed when not in use. Since they are Pods, Kubernetes is scheduling them on the nodes that have enough resources. By combining one-shot agents with Kubernetes, we are distributing load and, at the same time, using only the resources we need. After all, there’s no need to waste CPU and memory on non-existing processes.    We’re done with Jenkins, so let’s remove the Namespaces we created before we move into the next use-case.    ``` `1` kubectl delete ns jenkins build  ```   ``````````` ### Using ServiceAccounts From Side-Car Containers    We still have one more pending issue that we can solve with ServiceAccounts. In the previous chapter we tried to use `cvallance/mongo-k8s-sidecar` container in hopes it’ll dynamically create and manage a MongoDB replica set. We failed because, at that time, we did not know how to create sufficient permissions that would allow the side-car to do its job. Now we know better.    Let’s take a look at an updated version of our *go-demo-3* application.    ``` `1` cat sa/go-demo-3.yml  ```   `````````` The relevant parts of the output are as follows    ```  `1` `...`  `2` `apiVersion``:` `v1`  `3` `kind``:` `ServiceAccount`  `4` `metadata``:`  `5`  `name``:` `db`  `6`  `namespace``:` `go-demo-3`  `7`   `8` `---`  `9`  `10` `kind``:` `Role` `11` `apiVersion``:` `rbac.authorization.k8s.io/v1beta1` `12` `metadata``:` `13 `  `name``:` `db` `14 `  `namespace``:` `go-demo-3` `15` `rules``:` `16` `-` `apiGroups``:` `[``\"\"``]` `17 `  `resources``:` `[``\"pods\"``]` `18 `  `verbs``:` `[``\"list\"``]` `19`  `20` `---` `21`  `22` `apiVersion``:` `rbac.authorization.k8s.io/v1beta1` `23` `kind``:` `RoleBinding` `24` `metadata``:` `25 `  `name``:` `db` `26 `  `namespace``:` `go-demo-3` `27` `roleRef``:` `28 `  `apiGroup``:` `rbac.authorization.k8s.io` `29 `  `kind``:` `Role` `30 `  `name``:` `db` `31` `subjects``:` `32` `-` `kind``:` `ServiceAccount` `33 `  `name``:` `db` `34`  `35` `---` `36`  `37` `apiVersion``:` `apps/v1beta1` `38` `kind``:` `StatefulSet` `39` `metadata``:` `40 `  `name``:` `db` `41 `  `namespace``:` `go-demo-3` `42` `spec``:` `43 `  `...` `44 `  `template``:` `45 `    `...` `46 `    `spec``:` `47 `      `serviceAccountName``:` `db` `48 `      `...`  ```   ````````` Just as with Jenkins, we have a ServiceAccount, a Role, and a RoleBinding. Since the side-car needs only to list the Pods, the Role is this time more restrictive than the one we created for Jenkins. Further down, in the StatefulSet, we added `serviceAccountName: db` entry that links the set with the account. By now, you should be familiar with all those resources. We’re applying the same logic to the side-car as to Jenkins.    Since there’s no need for a lengthy discussion, we’ll move on and `apply` the definition.    ``` `1` kubectl apply `\\` `2 `    -f sa/go-demo-3.yml `\\` `3 `    --record  ```   ```````` Next, we’ll take a look at the Pods created in the `go-demo-3` Namespace.    ``` `1` kubectl -n go-demo-3 `\\` `2 `    get pods  ```   ``````` After a while, the output should be as follows.    ``` `1` NAME    READY STATUS  RESTARTS AGE `2` api-... 1/1   Running 1        1m `3` api-... 1/1   Running 1        1m `4` api-... 1/1   Running 1        1m `5` db-0    2/2   Running 0        1m `6` db-1    2/2   Running 0        1m `7` db-2    2/2   Running 0        54s  ```   `````` All the Pods are running so it seems that, this time, the side-car did not have trouble communicating with the API.    To be on the safe side, we’ll output the logs of one of the side-car containers.    ``` `1` kubectl -n go-demo-3 `\\` `2 `    logs db-0 -c db-sidecar  ```   ````` The output, limited to the last entries, is as follows.    ```  `1` `...`  `2`     `{` `_id:` `1,`  `3`       `host:` `'db-1.db.go-demo-3.svc.cluster.local:27017',`  `4`       `arbiterOnly:` `false,`  `5`       `buildIndexes:` `true,`  `6`       `hidden:` `false,`  `7`       `priority:` `1,`  `8`       `tags:` `{``}``,`  `9`       `slaveDelay:` `0``,` `10 `       `votes:` `1` `},` `11 `     `{` `_id:` `2,` `host:` `'db-2.db.go-demo-3.svc.cluster.local:27017'` `}` `],` `12 `  `settings:` `13 `   `{` `chainingAllowed:` `true,` `14 `     `heartbeatIntervalMillis:` `2000,` `15 `     `heartbeatTimeoutSecs:` `10,` `16 `     `electionTimeoutMillis:` `10000,` `17 `     `catchUpTimeoutMillis:` `2000,` `18 `     `getLastErrorModes:` `{``}``,` `19 `     `getLastErrorDefaults:` `{` `w:` `1,` `wtimeout:` `0` `}``,` `20 `     `replicaSetId:` `5``aef``9e4``c``52``b``968``b``72``a``16``ea``5``b` `}` `}`  ```   ```` The details behind the output are not that important. What matters is that there are no errors. The side-car managed to retrieve the information it needs from Kube API, and all that’s left for us is to delete the Namespace and conclude the chapter.    ``` `1` kubectl delete ns go-demo-3  ```   `### What Now?    ServiceAccounts combined with Roles and RoleBindings are an essential component for continuous deployment or any other process that needs to communicate with Kubernetes. The alternative is to run an unsecured cluster which is not an option for any but smallest organizations. RBAC is required when more than one person is operating or using a cluster. If RBAC is enabled, ServiceAccounts are a must. We’ll use them a lot in the chapters that follow.    Please consult the APIs that follow for any additional information about ServiceAccounts and related resources.    *   [ServiceAccount v1 core](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#serviceaccount-v1-core)] *   [Role v1 rbac](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#role-v1-rbac) *   [ClusterRole v1 rbac](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#clusterrole-v1-rbac) *   [RoleBinding v1 rbac](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#rolebinding-v1-rbac) *   [ClusterRoleBinding v1 rbac](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#clusterrolebinding-v1-rbac)    One more thing before you leave. Please consult [jenkins-kubernetes-plugin](https://github.com/jenkinsci/kubernetes-plugin) for more information about the plugin.` ```` ````` `````` ``````` ```````` ````````` `````````` ``````````` ```````````` ````````````` `````````````` ``````````````` ```````````````` ````````````````` `````````````````` ``````````````````` ```````````````````` ````````````````````` `````````````````````` ``````````````````````` ```````````````````````` ````````````````````````` `````````````````````````` ``````````````````````````` ```````````````````````````` ````````````````````````````` `````````````````````````````` ``````````````````````````````` ```````````````````````````````` ````````````````````````````````` `````````````````````````````````` ``````````````````````````````````` ```````````````````````````````````` ````````````````````````````````````` `````````````````````````````````````` ``````````````````````````````````````` ```````````````````````````````````````` ````````````````````````````````````````` `````````````````````````````````````````` ``````````````````````````````````````````` ```````````````````````````````````````````` ````````````````````````````````````````````` `````````````````````````````````````````````` ``````````````````````````````````````````````` ```````````````````````````````````````````````` ````````````````````````````````````````````````` `````````````````````````````````````````````````` ``````````````````````````````````````````````````` ```````````````````````````````````````````````````` ````````````````````````````````````````````````````` `````````````````````````````````````````````````````` ``````````````````````````````````````````````````````` ```````````````````````````````````````````````````````` ````````````````````````````````````````````````````````` `````````````````````````````````````````````````````````` ``````````````````````````````````````````````````````````` ```````````````````````````````````````````````````````````` ````````````````````````````````````````````````````````````` `````````````````````````````````````````````````````````````` ``````````````````````````````````````````````````````````````` ```````````````````````````````````````````````````````````````` ````````````````````````````````````````````````````````````````` `````````````````````````````````````````````````````````````````` ``````````````````````````````````````````````````````````````````` ```````````````````````````````````````````````````````````````````` ````````````````````````````````````````````````````````````````````` `````````````````````````````````````````````````````````````````````` ``````````````````````````````````````````````````````````````````````` ```````````````````````````````````````````````````````````````````````` ````````````````````````````````````````````````````````````````````````` `````````````````````````````````````````````````````````````````````````` ``````````````````````````````````````````````````````````````````````````` ```````````````````````````````````````````````````````````````````````````` ````````````````````````````````````````````````````````````````````````````` `````````````````````````````````````````````````````````````````````````````` ``````````````````````````````````````````````````````````````````````````````` ```````````````````````````````````````````````````````````````````````````````` ````````````````````````````````````````````````````````````````````````````````` `````````````````````````````````````````````````````````````````````````````````` ``````````````````````````````````````````````````````````````````````````````````` ```````````````````````````````````````````````````````````````````````````````````` ````````````````````````````````````````````````````````````````````````````````````` `````````````````````````````````````````````````````````````````````````````````````` ``````````````````````````````````````````````````````````````````````````````````````` ```````````````````````````````````````````````````````````````````````````````````````` ````````````````````````````````````````````````````````````````````````````````````````` `````````````````````````````````````````````````````````````````````````````````````````` ```````````````````````````````````````````````````````````````````````````````````````````"]