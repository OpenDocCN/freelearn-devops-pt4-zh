["```\n`1` `cd` k8s-specs\n`2` \n`3` git pull \n```", "`````````````````````````````````````````````````````` Just as in the previous chapters, we’ll need a cluster if we are to do the hands-on exercises. The rules are still the same. You can continue using the same cluster as before, or you can switch to a different Kubernetes flavor. You can continue using one of the Kubernetes distributions listed below, or be adventurous and try something different. If you go with the latter, please let me know how it went, and I’ll test it myself and incorporate it into the list.    The Gists with the commands I used to create different variations of Kubernetes clusters are as follows.    *   [docker4mac-3cpu.sh](https://gist.github.com/bf08bce43a26c7299b6bd365037eb074): **Docker for Mac** with 3 CPUs, 3 GB RAM, and with **nginx Ingress**. *   [minikube-3cpu.sh](https://gist.github.com/871b5d7742ea6c10469812018c308798): **minikube** with 3 CPUs, 3 GB RAM, and with `ingress`, `storage-provisioner`, and `default-storageclass` addons enabled. *   [kops.sh](https://gist.github.com/2a3e4ee9cb86d4a5a65cd3e4397f48fd): **kops in AWS** with 3 t2.small masters and 2 t2.medium nodes spread in three availability zones, and with **nginx Ingress** (assumes that the prerequisites are set through [Appendix B](part0018.html#appendix-b)). *   [minishift-3cpu.sh](https://gist.github.com/2074633688a85ef3f887769b726066df): **minishift** with 3 CPUs, 3 GB RAM, and version 1.16+. *   [gke-2cpu.sh](https://gist.github.com/e3a2be59b0294438707b6b48adeb1a68): **Google Kubernetes Engine (GKE)** with 3 n1-highcpu-2 (2 CPUs, 1.8 GB RAM) nodes (one in each zone), and with **nginx Ingress** controller running on top of the “standard” one that comes with GKE. We’ll use nginx Ingress for compatibility with other platforms. Feel free to modify the YAML files if you prefer NOT to install nginx Ingress. *   [eks.sh](https://gist.github.com/5496f79a3886be794cc317c6f8dd7083): **Elastic Kubernetes Service (EKS)** with 2 t2.medium nodes, with **nginx Ingress** controller, and with a **default StorageClass**.    Now that we have a cluster, we can move into a more exciting part of this chapter. We’ll start defining and executing stages and steps of a continuous deployment pipeline.    ### Creating Namespaces Dedicated To Continuous Deployment Processes    If we are to accomplish a reasonable level of security of our pipelines, we need to run them in dedicated Namespaces. Our cluster already has RBAC enabled, so we’ll need a ServiceAccount as well. Since security alone is not enough, we also need to make sure that our pipeline does not affect other applications. We’ll accomplish that by creating a LimitRange and a ResourceQuota.    I believe that in most cases we should store everything an application needs in the same repository. That makes maintenance much simpler and enables the team in charge of that application to be in full control, even though that team might not have all the permissions to create the resources in a cluster.    We’ll continue using `go-demo-3` repository but, since we’ll have to change a few things, it is better if you apply the changes to your fork and, maybe, push them back to GitHub.    ``` `1` open `\"https://github.com/vfarcic/go-demo-3\"`  ```   ````````````````````````````````````````````````````` If you’re not familiar with GitHub, all you have to do is to log in and click the *Fork* button located in the top-right corner of the screen.    Next, we’ll remove the `go-demo-3` repository (if you happen to have it) and clone the fork.    Make sure that you replace `[...]` with your GitHub username.    ``` `1` `cd` .. `2`  `3` rm -rf go-demo-3 `4`  `5` `export` `GH_USER``=[`...`]` `6`  `7` git clone https://github.com/`$GH_USER`/go-demo-3.git `8`  `9` `cd` go-demo-3  ```   ```````````````````````````````````````````````````` The only thing left is to edit a few files. Please open *k8s/build.yml* and *k8s/prod.yml* files in your favorite editor and change all occurrences of `vfarcic` with your Docker Hub user.    The namespace dedicated for all building and testing activities of the `go-demo-3` project is defined in the `k8s/build-ns.yml` file stored in the project repository.    ``` `1` git pull `2`  `3` cat k8s/build-ns.yml  ```   ``````````````````````````````````````````````````` The output is as follows.    ```  `1` `apiVersion``:` `v1`  `2` `kind``:` `Namespace`  `3` `metadata``:`  `4`  `name``:` `go-demo-3-build`  `5`   `6` `---`  `7`   `8` `apiVersion``:` `v1`  `9` `kind``:` `ServiceAccount` `10` `metadata``:` `11 `  `name``:` `build` `12 `  `namespace``:` `go-demo-3-build` `13`  `14` `---` `15`  `16` `apiVersion``:` `rbac.authorization.k8s.io/v1beta1` `17` `kind``:` `RoleBinding` `18` `metadata``:` `19 `  `name``:` `build` `20 `  `namespace``:` `go-demo-3-build` `21` `roleRef``:` `22 `  `apiGroup``:` `rbac.authorization.k8s.io` `23 `  `kind``:` `ClusterRole` `24 `  `name``:` `admin` `25` `subjects``:` `26` `-` `kind``:` `ServiceAccount` `27 `  `name``:` `build` `28`  `29` `---` `30`  `31` `apiVersion``:` `v1` `32` `kind``:` `LimitRange` `33` `metadata``:` `34 `  `name``:` `build` `35 `  `namespace``:` `go-demo-3-build` `36` `spec``:` `37 `  `limits``:` `38 `  `-` `default``:` `39 `      `memory``:` `200Mi` `40 `      `cpu``:` `0.2` `41 `    `defaultRequest``:` `42 `      `memory``:` `100Mi` `43 `      `cpu``:` `0.1` `44 `    `max``:` `45 `      `memory``:` `500Mi` `46 `      `cpu``:` `0.5` `47 `    `min``:` `48 `      `memory``:` `10Mi` `49 `      `cpu``:` `0.05` `50 `    `type``:` `Container` `51`  `52` `---` `53`  `54` `apiVersion``:` `v1` `55` `kind``:` `ResourceQuota` `56` `metadata``:` `57 `  `name``:` `build` `58 `  `namespace``:` `go-demo-3-build` `59` `spec``:` `60 `  `hard``:` `61 `    `requests.cpu``:` `2` `62 `    `requests.memory``:` `3Gi` `63 `    `limits.cpu``:` `3` `64 `    `limits.memory``:` `4Gi` `65 `    `pods``:` `15`  ```   `````````````````````````````````````````````````` If you are familiar with Namespaces, ServiceAccounts, LimitRanges, and ResourceQuotas, the definition should be fairly easy to understand.    We defined the `go-demo-3-build` Namespace which we’ll use for all our CDP tasks. It’ll contain the ServiceAccount `build` bound to the ClusterRole `admin`. As a result, containers running inside that Namespace will be able to do anything they want. It’ll be their playground.    We also defined the LimitRange named `build`. It’ll make sure to give sensible defaults to the Pods that running in the Namespace. That way we can create Pods from which we’ll build and test without worrying whether we forgot to specify resources they need. After all, most of us do not know how much memory and CPU a build needs. The same LimitRange also contains some minimum and maximum limits that should prevent users from specifying too small or too big resource reservations and limits.    Finally, since the capacity of our cluster is probably not unlimited, we defined a ResourceQuota that specifies the total amount of memory and CPU for requests and limits in that Namespace. We also defined that the maximum number of Pods running in that Namespace cannot be higher than fifteen.    If we do have more Pods than what we can place in that Namespace, some will be pending until others finish their work and resources are liberated.    It is very likely that the team behind the project will not have sufficient permissions to create new Namespaces. If that’s the case, the team would need to let cluster administrator know about the existence of that YAML. In turn, he (or she) would review the definition and create the resources, once he (or she) deduces that they are safe. For the sake of simplicity, you are that person, so please execute the command that follows.    ``` `1` kubectl apply `\\` `2 `    -f k8s/build-ns.yml `\\` `3 `    --record  ```   ````````````````````````````````````````````````` As you can see from the output, the `go-demo-3-build` Namespace was created together with a few other resources.    Now that we have a Namespace dedicated to the lifecycle of our application, we’ll create another one that to our production release.    ``` `1` cat k8s/prod-ns.yml  ```   ```````````````````````````````````````````````` The `go-demo-3` Namespace is very similar to `go-demo-3-build`. The major difference is in the RoleBinding. Since we can assume that processes running in the `go-demo-3-build` Namespace will, at some moment, want to deploy a release to production, we created the RoleBinding `build` which binds to the ServiceAccount `build` in the Namespace `go-demo-3-build`.    We’ll `apply` this definition while still keeping our cluster administrator’s hat.    ``` `1` kubectl apply `\\` `2 `    -f k8s/prod-ns.yml `\\` `3 `    --record  ```   ``````````````````````````````````````````````` Now we have two Namespaces dedicated to the `go-demo-3` application. We are yet to figure out which tools we’ll need for our continuous deployment pipeline.    ### Defining A Pod With The Tools    Every application is different, and the tools we need for a continuous deployment pipeline vary from one case to another. For now, we’ll focus on those we’ll need for our *go-demo-3* application.    Since the application is written in Go, we’ll need `golang` image to download the dependencies and run the tests. We’ll have to build Docker images, so we should probably add a `docker` container as well. Finally, we’ll have to execute quite a few `kubectl` commands. For those of you using OpenShift, we’ll need `oc` as well. All in all, we need a Pod with `golang`, `docker`, `kubectl`, and (for some of you) `oc`.    The *go-demo-3* repository already contains a definition of a Pod with all those containers, so let’s take a closer look at it.    ``` `1` cat k8s/cd.yml  ```   `````````````````````````````````````````````` The output is as follows.    ```  `1` `apiVersion``:` `v1`  `2` `kind``:` `Pod`  `3` `metadata``:`  `4`  `name``:` `cd`  `5`  `namespace``:` `go-demo-3-build`  `6` `spec``:`  `7`  `containers``:`  `8`  `-` `name``:` `docker`  `9`    `image``:` `docker:18.03-git` `10 `    `command``:` `[``\"sleep\"``]` `11 `    `args``:` `[``\"100000\"``]` `12 `    `volumeMounts``:` `13 `    `-` `name``:` `workspace` `14 `      `mountPath``:` `/workspace` `15 `    `-` `name``:` `docker-socket` `16 `      `mountPath``:` `/var/run/docker.sock` `17 `    `workingDir``:` `/workspace` `18 `  `-` `name``:` `kubectl` `19 `    `image``:` `vfarcic/kubectl` `20 `    `command``:` `[``\"sleep\"``]` `21 `    `args``:` `[``\"100000\"``]` `22 `    `volumeMounts``:` `23 `    `-` `name``:` `workspace` `24 `      `mountPath``:` `/workspace` `25 `    `workingDir``:` `/workspace` `26 `  `-` `name``:` `oc` `27 `    `image``:` `vfarcic/openshift-client` `28 `    `command``:` `[``\"sleep\"``]` `29 `    `args``:` `[``\"100000\"``]` `30 `    `volumeMounts``:` `31 `    `-` `name``:` `workspace` `32 `      `mountPath``:` `/workspace` `33 `    `workingDir``:` `/workspace` `34 `  `-` `name``:` `golang` `35 `    `image``:` `golang:1.9` `36 `    `command``:` `[``\"sleep\"``]` `37 `    `args``:` `[``\"100000\"``]` `38 `    `volumeMounts``:` `39 `    `-` `name``:` `workspace` `40 `      `mountPath``:` `/workspace` `41 `    `workingDir``:` `/workspace` `42 `  `serviceAccount``:` `build` `43 `  `volumes``:` `44 `  `-` `name``:` `docker-socket` `45 `    `hostPath``:` `46 `      `path``:` `/var/run/docker.sock` `47 `      `type``:` `Socket` `48 `  `-` `name``:` `workspace` `49 `    `emptyDir``:` `{}`  ```   ````````````````````````````````````````````` Most of the YAML defines the containers based on images that contain the tools we need. What makes it special is that all the containers have the same mount called `workspace`. It maps to `/workspace` directory inside containers, and it uses `emptyDir` volume type.    We’ll accomplish two things with those volumes. On the one hand, all the containers will have a shared space so the artifacts generated through the actions we will perform in one will be available in the other. On the other hand, since `emptyDir` volume type exists only just as long as the Pod is running, it’ll be deleted when we remove the Pod. As a result, we won’t be leaving unnecessary garbage on our nodes or external drives.    To simplify the things and save us from typing `cd /workspace`, we set `workingDir` to all the containers.    Unlike most of the other Pods we usually run in our clusters, those dedicated to CDP processes are short lived. They are not supposed to exist for a long time nor should they leave any trace of their existence once they finish executing the steps we are about to define.    The ability to run multiple containers on the same node and with a shared file system and networking will be invaluable in our quest to define continuous deployment processes. If you were ever wondering what the purpose of having Pods as entities that envelop multiple containers is, the steps we are about to explore will hopefully provide a perfect use-case.    Let’s create the Pod.    ``` `1` kubectl apply -f k8s/cd.yml --record  ```   ```````````````````````````````````````````` Pleases confirm that all the containers of the Pod are up and running by executing `kubectl -n go-demo-3-build get pods`. You should see that `4/4` are `ready`.    Now we can start working on our continuous deployment pipeline steps.    ### Executing Continuous Integration Inside Containers    The first stage in our continuous deployment pipeline will contain quite a few steps. We’ll need to check out the code, to run unit tests and any other static analysis, to build a Docker image, and to push it to the registry. If we define continuous integration (CI) as a set of automated steps followed with manual operations and validations, we can say that the steps we are about to execute can be qualified as CI.    The only thing we truly need to make all those steps work is Docker client with the access to Docker server. One of the containers of the `cd` Pod already contains it. If you take another look at the definition, you’ll see that we are mounting Docker socket so that the Docker client inside the container can issue commands to Docker server running on the host. Otherwise, we would be running Docker-in-Docker, and that is not a very good idea.    Now we can enter the `docker` container and check whether Docker client can indeed communicate with the server.    ``` `1` kubectl -n go-demo-3-build `\\` `2 `    `exec` -it `cd` -c docker -- sh `3`  `4` docker container ls  ```   ``````````````````````````````````````````` Once inside the `docker` container, we executed `docker container ls` only as a proof that we are using a client inside the container which, in turn, uses Docker server running on the node. The output is the list of the containers running on top of one of our servers.    Let’s get moving and execute the first step.    We cannot do much without the code of our application, so the first step is to clone the repository.    Make sure that you replace `[...]` with your GitHub username in the command that follows.    ``` `1` `export` `GH_USER``=[`...`]` `2`  `3` git clone `\\` `4 `    https://github.com/`$GH_USER`/go-demo-3.git `\\` `5 `    .  ```   `````````````````````````````````````````` We cloned the repository into the `workspace` directory. That is the same folder we mounted as an `emptyDir` volume and is, therefore, available in all the containers of the `cd` Pod. Since that folder is set as `workingDir` of the container, we did not need to `cd` into it.    Please note that we cloned the whole repository and, as a result, we are having a local copy of the HEAD commit of the master branch. If this were a “real” pipeline, such a strategy would be unacceptable. Instead, we should have checked out a specific branch and a commit that initiated the process. However, we’ll ignore those details for now, and assume that we’ll solve them when we move the pipeline steps into Jenkins and other tools.    Next, we’ll build an image and push it to Docker Hub. To do that, we’ll need to login first.    Make sure that you replace `[...]` with your Docker Hub username in the command that follows.    ``` `1` `export` `DH_USER``=[`...`]` `2`  `3` docker login -u `$DH_USER`  ```   ````````````````````````````````````````` Once you enter your password, you should see the `Login Succeeded` message.    We are about to execute the most critical step of this stage. We’ll build an image.    At this moment you might be freaking out. You might be thinking that I went insane. A Pastafarian and a firm believer that nothing should be built without running tests first just told you to build an image as the first step after cloning the code. Sacrilege!    However, this Dockerfile is special, so let’s take a look at it.    ``` `1` cat Dockerfile  ```   ```````````````````````````````````````` The output is as follows.    ```  `1` FROM golang:1.9 AS build  `2` ADD . /src  `3` WORKDIR /src  `4` RUN go get -d -v -t  `5` RUN go test --cover -v ./... --run UnitTest  `6` RUN go build -v -o go-demo  `7`   `8`   `9` FROM alpine:3.4 `10` MAINTAINER \tViktor Farcic <viktor@farcic.com> `11` RUN mkdir /lib64 && ln -s /lib/libc.musl-x86_64.so.1 /lib64/ld-linux-x86-64.so.2 `12` EXPOSE 8080 `13` ENV DB db `14` CMD [\"go-demo\"] `15` COPY --from=build /src/go-demo /usr/local/bin/go-demo `16` RUN chmod +x /usr/local/bin/go-demo  ```   ``````````````````````````````````````` Normally, we’d run a container, in this case, based on the `golang` image, execute a few processes, store the binary into a directory that was mounted as a volume, exit the container, and build a new image using the binary created earlier. While that would work fairly well, multi-stage builds allow us to streamline the processes into a single `docker image build` command.    If you’re not following Docker releases closely, you might be wondering what a multi-stage build is. It is a feature introduced in Docker 17.05 that allows us to specify multiple `FROM` statements in a Dockerfile. Each `FROM` instruction can use a different base, and each starts a new stage of the build process. Only the image created with the last `FROM` segment is kept. As a result, we can specify all the steps we need to execute before building the image without increasing its size.    In our example, we need to execute a few Go commands that will download all the dependencies, run unit tests, and compile a binary. Therefore, we specified `golang` as the base image followed with the `RUN` instruction that does all the heavy lifting. Please note that the first `FROM` statement is named `build`. We’ll see why that matters soon.    Further down, we start over with a new `FROM` section that uses `alpine`. It is a very minimalist linux distribution (a few MB in size) that guarantees that our final image is minimal and is not cluttered with unnecessary tools that are typically used in “traditional” Linux distros like `ubuntu`, `debian`, and `centos`. Further down we are creating everything our application needs, like the `DB` environment variable used by the code to know where the database is, the command that should be executed when a container starts, and so on. The critical part is the `COPY` statement. It copies the binary we created in the `build` stage into the final image.    Let’s build the image.    ``` `1` docker image build `\\` `2 `    -t `$DH_USER`/go-demo-3:1.0-beta `\\` `3 `    .  ```   `````````````````````````````````````` We can see from the output that the steps of our multi-stage build were executed. We downloaded the dependencies, run unit tests, and built the `go-demo` binary. All those things were temporary, and we do not need them in the final image. There’s no need to have a Go compiler, nor to keep the code. Therefore, once the first stage was finished, we can see the message *Removing intermediate container*. Everything was discarded. We started over, and we built the production-ready image with the binary generated in the previous stage.    We have the whole continuous integration process reduced to a single command. Developers can run it on their laptops, and CI/CD tools can use it as part of their extended processes. Isn’t that neat?    Let’s take a quick look at the images on the node.    ``` `1` docker image ls  ```   ````````````````````````````````````` The output, limited to the relevant parts, is as follows.    ``` `1` REPOSITORY        TAG      IMAGE ID CREATED            SIZE `2` vfarcic/go-demo-3 1.0-beta ...      54 seconds ago     25.8MB `3` <none>            <none>   ...      About a minute ago 779MB `4` ...  ```   ```````````````````````````````````` The first two images are the result of our build. The final image (`vfarcic/go-demo-3`) is only 25 MB. It’s that small because Docker discarded all but the last stage. If you’d like to know how big your image would be if everything was built in a single stage, please combine the size of the `vfarcic/go-demo-3` image with the size of the temporary image used in the first stage (it’s just below `vfarcic/go-demo-3 1.0-beta`).    The only thing missing is to push the image to the registry (e.g., Docker Hub).    ``` `1` docker image push `\\` `2 `    `$DH_USER`/go-demo-3:1.0-beta  ```   ``````````````````````````````````` The image is in the registry and ready for further deployments and testing. Mission accomplished. We’re doing continuous integration manually. If we’d place those few commands into a CI/CD tool, we would have the first part of the process up and running.  ![Figure 3-2: The build stage of a continuous deployment pipeline](img/00008.jpeg)  Figure 3-2: The build stage of a continuous deployment pipeline    We are still facing a few problems. Docker running in a Kubernetes cluster might be too old. It might not support all the features we need. As an example, most of the Kubernetes distributions before 1.10 supported Docker versions older than 17.05\\. If that’s not enough, consider the possibility that you might not even use Docker in a Kubernetes cluster. It is very likely that ContainerD will be the preferable container engine in the future, and that is only one of many choices we can select. The point is that container engine in a Kubernetes cluster should be in charge of running container, and not much more. There should be no need for the nodes in a Kubernetes cluster to be able to build images.    Another issue is security. If we allow containers to mount Docker socket, we are effectively allowing them to control all the containers running on that node. That by itself makes security departments freak out, and for a very good reason. Also, don’t forget that we logged into the registry. Anyone on that node could push images to the same registry without the need for credentials. Even if we do log out, there was still a period when everyone could exploit the fact that Docker server is authenticated and authorized to push images.    Truth be told, **we are not preventing anyone from mounting a Docker socket**. At the moment, our policy is based on trust. That should change with PodSecurityPolicy. However, security is not the focus of this book, so I’ll assume that you’ll set up the policies yourself, if you deem them worthy of your time.    If that’s not enough, there’s also the issue of preventing Kubernetes to do its job. The moment we adopt container schedulers, we accept that they are in charge of scheduling all the processes running inside the cluster. If we start doing things behind their backs, we might end up messing with their scheduling capabilities. Everything we do without going through Kube API is unknown to Kubernetes.    We could use Docker inside Docker. That would allow us to build images inside containers without reaching out to Docker socket on the nodes. However, that requires privileged access which poses as much of a security risk as mounting a Docker socket. Actually, it is even riskier. So, we need to discard that option as well.    Another solution might be to use [kaniko](https://github.com/GoogleContainerTools/kaniko). It allows us to build Docker images from inside Pods. The process is done without Docker so there is no dependency on Docker socket nor there is a need to run containers in privileged mode. However, at the time of this writing (May 2018) *kaniko* is still not ready. It is complicated to use, and it does not support everything Docker does (e.g., multi-stage builds), it’s not easy to decipher its logs (especially errors), and so on. The project will likely have a bright future, but it is still not ready for prime time.    Taking all this into consideration, the only viable option we have, for now, is to build our Docker images outside our cluster. The steps we should execute are the same as those we already run. The only thing missing is to figure out how to create a build server and hook it up to our CI/CD tool. We’ll revisit this subject later on.    For now, we’ll exit the container.    ``` `1` `exit`  ```   `````````````````````````````````` Let’s move onto the next stage of our pipeline.    ### Running Functional Tests    Which steps do we need to execute in the functional testing phase? We need to deploy the new release of the application. Without it, there would be nothing to test. All the static tests were already executed when we built the image, so everything we do from now on will need a live application.    Deploying the application is not enough, we’ll have to validate that at least it rolled out successfully. Otherwise, we’ll have to abort the process.    We’ll have to be cautious how we deploy the new release. Since we’ll run it in the same cluster as production, we need to be careful that one does not affect the other. We already have a Namespace that provides some level of isolation. However, we’ll have to be attentive not to use the same path or domain in Ingress as the one used for production. The two need to be accessible separately from each other until we are confident that the new release meets all the quality standards.    Finally, once the new release is running, we’ll execute a set of tests that will validate it. Please note that we will run functional tests only. You should translate that into “in this stage, I run all kinds of tests that require a live application.” You might want to add performance and integration tests as well. From the process point of view, it does not matter which tests you run. What matters is that in this stage you run all those that could not be executed statically when we built the image.    If any step in this stage fails, we need to be prepared to destroy everything we did and leave the cluster in the same state as before we started this stage. We’ll postpone exploration of rollback steps until one of the next chapters. I’m sure you know how to do it anyway. If you don’t, I’ll leave you feeling ashamed until the next chapter.    As you probably guessed, we’ll need to go into the `kubectl` container for at least some of the steps in this stage. It is already running as part of the `cd` Pod.    Remember, we are performing a manual simulation of a CDP pipeline. We must assume that everything will be executed from inside the cluster, not from your laptop.    ``` `1` kubectl -n go-demo-3-build `\\` `2 `    `exec` -it `cd` -c kubectl -- sh  ```   ````````````````````````````````` The project contains separate definitions for deploying test and production releases. For now, we are interested only in prior which is defined in `k8s/build.yml`.    ``` `1` cat k8s/build.yml  ```   ```````````````````````````````` We won’t comment on all the resources defined in that YAML since they are very similar to those we used before. Instead, we’ll take a quick look at the differences between a test and a production release.    ``` `1` diff k8s/build.yml k8s/prod.yml  ```   ``````````````````````````````` The two are almost the same. One is using `go-demo-3-build` Namespace while the other works with `go-demo-3`. The `path` of the Ingress resource also differs. Non-production releases will be accessible through `/beta/demo` and thus provide separation from the production release accessible through `/demo`. Everything else is the same.    It’s a pity that we had to create two separate YAML files only because of a few differences (Namespace and Ingress). We’ll discuss the challenges behind rapid deployments using standard YAML files later. For now, we’ll roll with what we have.    Even though we separated production and non-production releases, we still need to modify the tag of the image on the fly. The alternative would be to change release numbers with each commit, but that would represent a burden to developers and a likely source of errors. So, we’ll go back to exercising “magic” with `sed`.    ``` `1` cat k8s/build.yml `|` sed -e `\\` `2 `    `\"s@:latest@:1.0-beta@g\"` `|` `\\` `3 `    tee /tmp/build.yml  ```   `````````````````````````````` We output the contents of the `/k8s/build.yml` file, we modified it with `sed` so that the `1.0-beta` tag is used instead of the `latest`, and we stored the output in `/tmp/build.yml`.    Now we can deploy the new release.    ``` `1` kubectl apply `\\` `2 `    -f /tmp/build.yml --record `3`  `4` kubectl rollout status deployment api  ```   ````````````````````````````` We applied the new definition and waited until it rolled out.    Even though we know that the rollout was successful by reading the output, we cannot rely on such methods when we switch to full automation of the pipeline. Fortunately, the `rollout status` command will exit with `0` if everything is OK, and with a different code if it’s not.    Let’s check the exit code of the last command.    ``` `1` `echo` `$?`  ```   ```````````````````````````` The output is `0` thus confirming that the rollout was successful. If it was anything else, we’d need to roll back or, even better, quickly fix the problem and roll forward.    The only thing missing in this stage is to run the tests. However, before we do that, we need to find out the address through which the application can be accessed.    ``` `1` `ADDR``=``$(`kubectl -n go-demo-3-build `\\` `2 `    get ing api `\\` `3 `    -o `jsonpath``=``\"{.status.loadBalancer.ingress[0].hostname}\"``)`/beta `4`  `5` `echo` `$ADDR` `|` tee /workspace/addr `6`  `7` `exit`  ```   ``````````````````````````` We retrieved the `hostname` from Ingress with the appended path (`/beta`) dedicated to beta releases. Further on, we stored the result in the `/workspace/addr` file. That way we’ll be able to retrieve it from other containers running in the same Pod. Finally, we exited the container since the next steps will require a different one.    Let’s go inside the `golang` container. We’ll need it to execute functional tests.    ``` `1` kubectl -n go-demo-3-build `\\` `2 `    `exec` -it `cd` -c golang -- sh  ```   `````````````````````````` Before we run the functional tests, we’ll send a request to the application manually. That will give us confidence that everything we did so far works as expected.    ``` `1` curl `\"http://``$(`cat addr`)``/demo/hello\"`  ```   ````````````````````````` We constructed the address using the information we stored in the `addr` file and sent a `curl` request. The output is `hello, world!`, thus confirming that the test release of application seems to be deployed correctly.    The tests require a few dependencies, so we’ll download them using the `go get` command. Don’t worry if you’re new to Go. This exercise is not aimed at teaching you how to work with it, but only to show you the principles that apply to almost any language. In your head, you can replace the command that follows with `maven` this, `gradle` that, `npm` whatever.    ``` `1` go get -d -v -t  ```   ```````````````````````` The tests expect the environment variable `ADDRESS` to tell them where to find the application under test, so our next step is to declare it.    ``` `1` `export` `ADDRESS``=`api:8080  ```   ``````````````````````` In this case, we chose to allow the tests to communicate with the application through the service called `api`.    Now we’re ready to execute the tests.    ``` `1` go `test` ./... -v --run FunctionalTest  ```   `````````````````````` The output is as follows.    ```  `1` === RUN   TestFunctionalTestSuite  `2` === RUN   TestFunctionalTestSuite/Test_Hello_ReturnsStatus200  `3` 2018/05/14 14:41:25 Sending a request to http://api:8080/demo/hello  `4` === RUN   TestFunctionalTestSuite/Test_Person_ReturnsStatus200  `5` 2018/05/14 14:41:25 Sending a request to http://api:8080/demo/person  `6` --- PASS: TestFunctionalTestSuite (0.03s)  `7`    --- PASS: TestFunctionalTestSuite/Test_Hello_ReturnsStatus200 (0.01s)  `8`    --- PASS: TestFunctionalTestSuite/Test_Person_ReturnsStatus200 (0.01s)  `9` PASS `10` ok      _/go/go-demo-3  0.129s  ```   ````````````````````` We can see that the tests passed and we can conclude that the application is a step closer towards production. In a real-world situation, you’d run other types of tests or maybe bundle them all together. The logic is still the same. We deployed the application under test while leaving production intact, and we validated that it behaves as expected. We are ready to move on.    Testing an application through the service associated with it is a good idea,if for some reason we are not allowed to expose it to the outside world through Ingress. If there is no such restriction, executing the tests through a DNS which points to an external load balancer, which forwards to the Ingress service on one of the worker nodes, and from there load balances to one of the replicas, is much closer to how our users access the application. Using the “real” externally accessible address is a better option when that is possible, so we’ll change our `ADDRESS` variable and execute the tests one more time.    ``` `1` `export` `ADDRESS``=``$(`cat addr`)` `2`  `3` go `test` ./... -v --run FunctionalTest  ```   ```````````````````` We’re almost finished with this stage. The only thing left is to exit the `golang` container, go back to `kubectl`, and remove the application under test.    ``` `1` `exit` `2`  `3` kubectl -n go-demo-3-build `\\` `4 `    `exec` -it `cd` -c kubectl -- sh `5`  `6` kubectl delete `\\` `7 `    -f /workspace/k8s/build.yml  ```   ``````````````````` We exited the `golang` container and entered into `kubectl` to delete the test release.  ![Figure 3-3: The functional testing stage of a continuous deployment pipeline](img/00009.jpeg)  Figure 3-3: The functional testing stage of a continuous deployment pipeline    Let’s take a look at what’s left in the Namespace.    ``` `1` kubectl -n go-demo-3-build get all  ```   `````````````````` The output is as follows.    ``` `1` NAME  READY STATUS  RESTARTS AGE `2` po/cd 4/4   Running 0        11m  ```   ````````````````` Our `cd` Pod is still running. We will remove it later when we’re confident that we don’t need any of the tools it contains.    There’s no need for us to stay inside the `kubectl` container anymore, so we’ll exit.    ``` `1` `exit`  ```   ```````````````` ### Creating Production Releases    We are ready to create our first production release. We trust our tests, and they proved that it is relatively safe to deploy to production. Since we cannot deploy to air, we need to create a production release first.    Please make sure to replace `[...]` with your Docker Hub user in one of the commands that follow.    ```  `1` kubectl -n go-demo-3-build `\\`  `2`    `exec` -it `cd` -c docker -- sh  `3`   `4` `export` `DH_USER``=[`...`]`  `5`   `6` docker image tag `\\`  `7`    `$DH_USER`/go-demo-3:1.0-beta `\\`  `8`    `$DH_USER`/go-demo-3:1.0  `9`  `10` docker image push `\\` `11 `    `$DH_USER`/go-demo-3:1.0  ```   ``````````````` We went back to the `docker` container, we tagged the `1.0-beta` release as `1.0`, and we pushed it to the registry (in this case Docker Hub). Both commands should take no time to execute since we already have all the layers cashed in the registry.    We’ll repeat the same process, but this time with the `latest` tag.    ``` `1` docker image tag `\\` `2 `    `$DH_USER`/go-demo-3:1.0-beta `\\` `3 `    `$DH_USER`/go-demo-3:latest `4`  `5` docker image push `\\` `6 `    `$DH_USER`/go-demo-3:latest `7`  `8` `exit`  ```   `````````````` Now we have the same image tagged and pushed to the registry as `1.0-beta`, `1.0`, and `latest`.    You might be wondering why we have three tags. They are all pointing to the same image, but they serve different purposes.    The `1.0-beta` is a clear indication that the image might not have been tested and might not be ready for prime. That’s why we intentionally postponed tagging until this point. It would be simpler if we tagged and pushed everything at once when we built the image. However, that would send a wrong message to those using our images. If one of the steps failed during the pipeline, it would be an indication that the commit is not ready for production. As a result, if we pushed all tags at once, others might have decided to use `1.0` or `latest` without knowing that it is faulty.    We should always be explicit with versions we are deploying to production, so the `1.0` tag is what we’ll use. That will help us control what we have and debug problems if they occur. However, others might not want to use explicit versions. A developer might want to deploy the last stable version of an application created by a different team. In those cases, developers might not care which version is in production. In such a case, deploying `latest` is probably a good idea, assuming that we take good care that it (almost) always works.  ![Figure 3-4: The release stage of a continuous deployment pipeline](img/00010.jpeg)  Figure 3-4: The release stage of a continuous deployment pipeline    We’re making significant progress. Now that we have a new release, we can proceed and execute rolling updates against production.    ### Deploying To Production    We already saw that `prod.yml` is almost the same as `build.yml` we deployed earlier, so there’s probably no need to go through it in details. The only substantial difference is that we’ll create the resources in the `go-demo-3` Namespace, and that we’ll leave Ingress to its original path `/demo`.    ``` `1` kubectl -n go-demo-3-build `\\` `2 `    `exec` -it `cd` -c kubectl -- sh `3`  `4` cat k8s/prod.yml `\\` `5 `    `|` sed -e `\"s@:latest@:1.0@g\"` `\\` `6 `    `|` tee /tmp/prod.yml `7`  `8` kubectl apply -f /tmp/prod.yml --record  ```   ````````````` We used `sed` to convert `latest` to the tag we built a short while ago, and we applied the definition. This was the first release, so all the resources were created. Subsequent releases will follow the rolling update process. Since that is something Kubernetes does out-of-the-box, the command will always be the same.    Next, we’ll wait until the release rolls out before we check the exit code.    ``` `1` kubectl -n go-demo-3 `\\` `2 `    rollout status deployment api `3`  `4` `echo` `$?`  ```   ```````````` The exit code is `0`, so we can assume that the rollout was successful. There’s no need even to look at the Pods. They are almost certainly running.    Now that the production release is up-and-running, we should find the address through which we can access it. Excluding the difference in the Namespace, the command for retrieving the hostname is the same.    ``` `1` `ADDR``=``$(`kubectl -n go-demo-3 `\\` `2 `    get ing api `\\` `3 `    -o `jsonpath``=``\"{.status.loadBalancer.ingress[0].hostname}\"``)` `4`  `5` `echo` `$ADDR` `|` tee /workspace/prod-addr  ```  ``````````` ![Figure 3-5: The deploy stage of a continuous deployment pipeline](img/00011.jpeg)  Figure 3-5: The deploy stage of a continuous deployment pipeline    To be on the safe side, we’ll run another round of validation, which we’ll call *production tests*. We don’t need to be in the `kubectl` container for that, so let’s exit.    ``` `1` `exit`  ```   `````````` ### Running Production Tests    The process for running production tests is the same as functional testing we executed earlier. The difference is in the tests we execute, not how we do it.    The goal of production tests is not to validate all the units of our application. Unit tests did that. It is not going to validate anything on the functional level. Functional tests did that. Instead, they are very light tests with a simple goal of validating whether the newly deployed application is correctly integrated with the rest of the system. Can we connect to the database? Can we access the application from outside the cluster (as our users will)? Those are a few of the questions we’re concerned with when running this last round of tests.    The tests are written in Go, and we still have the `golang` container running. All we have to do it to go through the similar steps as before.    ``` `1` kubectl -n go-demo-3-build `\\` `2 `    `exec` -it `cd` -c golang -- sh `3`  `4` `export` `ADDRESS``=``$(`cat prod-addr`)`  ```   ````````` Now that we have the address required for the tests, we can go ahead and execute them.    ``` `1` go `test` ./... -v --run ProductionTest  ```   ```````` The output of the command is as follows.    ``` `1` === RUN   TestProductionTestSuite `2` === RUN   TestProductionTestSuite/Test_Hello_ReturnsStatus200 `3` --- PASS: TestProductionTestSuite (0.10s) `4 `    --- PASS: TestProductionTestSuite/Test_Hello_ReturnsStatus200 (0.01s) `5` PASS `6` ok      _/go/go-demo-3  0.107s  ```  ``````` ![Figure 3-6: The production testing stage of a continuous deployment pipeline](img/00012.jpeg)  Figure 3-6: The production testing stage of a continuous deployment pipeline    Production tests were successful, and we can conclude that the deployment was successful as well.    All that’s left is to exit the container before we clean up.    ``` `1` `exit`  ```   `````` ### Cleaning Up Pipeline Leftovers    The last step in our manually-executed pipeline is to remove all the resources we created, except the production release. Since they are all Pods in the same Namespace, that should be reasonably easy. We can remove them all from `go-demo-3-build`.    ``` `1` kubectl -n go-demo-3-build `\\` `2 `    delete pods --all  ```   ````` The output is as follows.    ``` `1` pod \"cd\" deleted  ```  ```` ![Figure 3-7: The cleanup stage of a continuous deployment pipeline](img/00013.jpeg)  Figure 3-7: The cleanup stage of a continuous deployment pipeline    That’s it. Our continuous pipeline is finished. Or, to be more precise, we defined all the steps of the pipeline. We are yet to automate everything.    ### Did We Do It?    We only partially succeeded in defining our continuous deployment stages. We did manage to execute all the necessary steps. We cloned the code, we run unit tests, and we built the binary and the Docker image. We deployed the application under test without affecting the production release, and we run functional tests. Once we confirmed that the application works as expected, we updated production with the new release. The new release was deployed through rolling updates but, since it was the first release, we did not see the effect of it. Finally, we run another round of tests to confirm that rolling updates were successful and that the new release is integrated with the rest of the system.    You might be wondering why I said that “we only partially succeeded.” We executed the full pipeline. Didn’t we?    One of the problems we’re facing is that our process can run only a single pipeline for an application. If another commit is pushed while our pipeline is in progress, it would need to wait in a queue. We cannot have a separate Namespace for each build since we’d need to have cluster-wide permissions to create Namespaces and that would defy the purpose of having RBAC. So, the Namespaces need to be created in advance. We might create a few Namespaces for building and testing, but that would still be sub-optimal. We’ll stick with a single Namespace with the pending task to figure out how to deploy multiple revisions of an application in the same Namespace given to us by the cluster administrator.    Another problem is the horrifying usage of `sed` commands to modify the content of a YAML file. There must be a better way to parametrize definition of an application. We’ll try to solve that problem in the next chapter.    Once we start running multiple builds of the same application, we’ll need to figure out how to remove the tools we create as part of our pipeline. Commands like `kubectl delete pods --all` will obviously not work if we plan to run multiple pipelines in parallel. We’ll need to restrict the removal only to the Pods spin up by the build we finished, not all those in a Namespace. CI/CD tools we’ll use later might be able to help with this problem.    We are missing quite a few steps in our pipeline. Those are the issues we will not try to fix in this book. Those that we explored so far are common to almost all pipelines. We always run different types of tests, some of which are static (e.g., unit tests), while others need a live application (e.g., functional tests). We always need to build a binary or package our application. We need to build an image and deploy it to one or more locations. The rest of the steps differs from one case to another. You might want to send test results to SonarQube, or you might choose to make a GitHub release. If your images can be deployed to different operating systems (e.g., Linux, Windows, ARM), you might want to create a manifest file. You’ll probably run some security scanning as well. The list of the things you might do is almost unlimited, so I chose to stick with the steps that are very common and, in many cases, mandatory. Once you grasp the principles behind a well defined, fully automated, and container-based pipeline executed on top of a scheduler, I’m sure you won’t have a problem extending our examples to fit your particular needs.    How about building Docker images? That is also one of the items on our TODO list. We shouldn’t build them inside Kubernetes cluster because mounting Docker socket is a huge security risk and because we should not run anything without going through Kube API. Our best bet, for now, is to build them outside the cluster. We are yet to discover how to do that effectively. I suspect that will be a very easy challenge.    One message I tried to convey is that everything related to an application should be in the same repository. That applies not only to the source code and tests, but also to build scripts, Dockerfile, and Kubernetes definitions. Outside of that application-related repository should be only the code and configurations that transcends a single application (e.g., cluster setup). We’ll continue using the same separation throughout the rest of the book. Everything required by `go-demo-3` will be in the [vfarcic/go-demo-3](https://github.com/vfarcic/go-demo-3) repository. Cluster-wide code and configuration will continue living in [vfarcic/k8s-specs](https://github.com/vfarcic/k8s-specs).    The logic behind everything-an-application-needs-is-in-a-single-repository mantra is vital if we want to empower the teams to be in charge of their applications. It’s up to those teams to choose how to do something, and it’s everyone else’s job to teach them the skills they need. With some other tools, such approach would pose a big security risk and could put other teams in danger. However, Kubernetes provides quite a lot of tools that can help us to avoid those risks without sacrificing autonomy of the teams in charge of application development. We have RBAC and Namespaces. We have ResourceQuotas, LimitRanges, PodSecurityPolicies, NetworkPolicies, and quite a few other tools at our disposal.    ### What Now?    We’re done, for now. Please destroy the cluster if you’re not planning to jump to the next chapter right away and if it is dedicated to the exercises in this book. Otherwise, execute the command that follows to remove everything we did.    ``` `1` kubectl delete ns `\\` `2 `    go-demo-3 go-demo-3-build  ``` ```` ````` `````` ``````` ```````` ````````` `````````` ``````````` ```````````` ````````````` `````````````` ``````````````` ```````````````` ````````````````` `````````````````` ``````````````````` ```````````````````` ````````````````````` `````````````````````` ``````````````````````` ```````````````````````` ````````````````````````` `````````````````````````` ``````````````````````````` ```````````````````````````` ````````````````````````````` `````````````````````````````` ``````````````````````````````` ```````````````````````````````` ````````````````````````````````` `````````````````````````````````` ``````````````````````````````````` ```````````````````````````````````` ````````````````````````````````````` `````````````````````````````````````` ``````````````````````````````````````` ```````````````````````````````````````` ````````````````````````````````````````` `````````````````````````````````````````` ``````````````````````````````````````````` ```````````````````````````````````````````` ````````````````````````````````````````````` `````````````````````````````````````````````` ``````````````````````````````````````````````` ```````````````````````````````````````````````` ````````````````````````````````````````````````` `````````````````````````````````````````````````` ``````````````````````````````````````````````````` ```````````````````````````````````````````````````` ````````````````````````````````````````````````````` ``````````````````````````````````````````````````````"]