<html><head></head><body>
<div class="calibre6">
<h2 id="leanpub-auto-creating-a-continuous-deployment-pipeline-with-jenkins" class="calibre16">Creating A Continuous Deployment Pipeline With Jenkins</h2>

<aside class="tip">
    <p class="calibre3">Having A Continuous Deployment pipeline capable of a fully automated application life-cycle is a real sign of maturity of an organization.</p>

</aside>

<p class="calibre3">This is it. The time has come to put all the knowledge we obtained into good use. We are about to define a “real” continuous deployment pipeline in Jenkins. Our goal is to move every commit through a set of steps until the application is installed (upgraded) and tested in production. We will undoubtedly face some new challenges, but I am confident that we’ll manage to overcome them. We already have all the base ingredients, and the main thing left is to put them all together into a continuous deployment pipeline.</p>

<p class="calibre3">Before we move into a practical section, we might want to spend a few moments discussing our goals.</p>

<h3 id="leanpub-auto-exploring-the-continuous-deployment-process" class="calibre20">Exploring The Continuous Deployment Process</h3>

<p class="calibre3">Explaining continuous deployment (CDP) is easy. Implementing it is very hard, and the challenges are often hidden and unexpected. Depending on the maturity of your processes, architecture, and code, you might find out that the real problems do not lie in the code of a continuous deployment pipeline, but everywhere else. As a matter of fact, developing a pipeline is the easiest part. That being said, you might wonder whether you made a mistake by investing your time in reading this book since we are focused mostly on the pipeline that will be executed inside a Kubernetes cluster.</p>

<p class="calibre3">We did not discuss the changes in your other processes. We did not explore what a good architecture that will support CDP pipelines is. We did not dive into how to code your application to be pipeline-friendly. I assumed that you already know all that. I hope that you do understand the basic concepts behind Agile and DevOps movements and that you already started dismantling the silos in your company. I assume that you do know what it means for your software architecture to be cloud-native and that you do implement some if not all of the <a href="https://12factor.net/">12 factors</a>. I guessed that you are already practicing Test-Driven Development, Behavior-Driven Development, Acceptance-Driven Development, or any other technique that help you design your applications.</p>

<p class="calibre3">I might be wrong. To be more precise, I’m sure that I’m wrong. Most of you are not there yet. If you are one of those, please get informed. Read more books, do some courses, and convince your managers to give you time, space, and resources you’ll need to modernize your applications. It needs to be done. All those things and many others are what differentiates top performers (e.g., Google, Amazon, Netflix) and the rest of us. Still, none of them is the same. Every high-performing company is different, and yet, they all share some things in common. They all need to ship features fast. They all need to have a high level of quality. And they all acknowledge that highly-available, fault-tolerant, and distributed systems require a very different approach than what most of the rest of us are used to.</p>

<p class="calibre3">If you got depressed by thinking that you are not yet ready and that you are on the verge of quitting, my advice is to continue. Even though you might need to make a lot of changes before you are able to practice continuous deployment, knowing what the end result looks like will put you on the right path. We are about to design a fully operational continuous deployment pipeline. Once we’re done, you’ll know which other changes you’ll need to make. You’ll understand where the finish line is, and you will be able to go back to where you are and start moving in the right direction.</p>

<p class="calibre3">We already discussed what a continuous deployment pipeline looks like. In case you’re forgetful (I know I am), here are a few of the rules that represent the short version.</p>

<p class="calibre3"><strong class="calibre18">Rule number one</strong>: Every commit to the master branch is deployed to production if it passes all the steps of a fully automated pipeline. If you need to involve humans after the commit, it’s not continuous deployment, nor it is continuous delivery. At best, you’re doing continuous integration.</p>

<p class="calibre3"><strong class="calibre18">Rule number two</strong>: You commit directly to the master branch, or you’re using short-living feature branches. The master branch is the only one that matters. Production releases are made from it. If you do use branches, they are taken from the master branch, since that’s the only one that truly matters. When you do create a feature branch, you are merging back to master soon afterward. You’re not waiting for weeks to do so. If you are, you are not “continuously” validating whether your code integrates with the code of others. If that’s the case, you’re not even doing continuous integration. Unless, you have an elaborate branching strategy, in which case you are only making everyone’s lives more complicated than they should be.</p>

<p class="calibre3"><strong class="calibre18">Rule number three</strong>: You trust your automation. When a test fails, there is a bug, and you fix it before anything else. I hope that you do not belong to a big group of companies that have flaky tests that sometimes work, and sometimes fail for random reasons. If you do, fix your tests first or remove those that are flaky. It’s pointless to run tests you do not trust. The same can be said for builds, deployments, and just about any other step of the process. If you see yourself in the group of those that do not trust their code, you’ll have to fix it first. Tests are code, just as builds, deployments, and everything else is. When code produces inconsistent results, we fix it, we do not restart it. Unfortunately, I do see a lot of companies that rather re-run a build that failed because of flaky tests than fix the cause of that flakiness. There’s an alarming number of those that solve half of the production problems by restarting applications. Anyways, if you do not trust your automation, you cannot deploy to production automatically. You cannot even say that it is production ready.</p>

<p class="calibre3">Now that we established a set of straightforward ground rules, we can move on and describe the pipeline we should develop. We are going to build something. Since building without running unit and other types of static tests should be declared officially illegal and punishable with public shame, we’ll include those in our <strong class="calibre18">build stage</strong>. Then we’re going execute the steps of the <strong class="calibre18">functional testing stage</strong> that will run all sorts of tests that require a live application. Therefore, we’ll need to deploy a test release during this stage. Once we’re confident that our application behaves as expected, we’re going to make a <strong class="calibre18">production release</strong>, followed with the <strong class="calibre18">deploy stage</strong> that will not only upgrade the production release but also run another round of tests to validate whether everything works as expected.</p>


<figure class="image1">
  <img src="../images/00028.jpeg" alt="Figure 7-1: The stages of a continuous deployment pipeline" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-1: The stages of a continuous deployment pipeline</figcaption>
</figure>


<p class="calibre3">You might not agree with the names of the stages. That’s OK. It does not matter much how you name things, nor how you group steps. What matters is that the pipeline has everything we need to feel confident that a release is safely deployed to production. Steps matter, stages are only labels.</p>

<p class="calibre3">We won’t discuss the exact steps just yet. Instead, we’ll break the stages apart and build one at the time. During the process, we’ll discuss which steps are required.</p>

<p class="calibre3">It is almost certain that you’ll need to add steps that I do not use. That’s OK as well. It’s all about principles and knowledge. Slight modifications should not be a problem.</p>

<p class="calibre3">Let’s create a cluster.</p>

<h3 id="leanpub-auto-creating-a-cluster-4" class="calibre20">Creating A Cluster</h3>

<p class="calibre3">We’ll start the practical section of the chapter by going to the <em class="calibre17">vfarcic/k8s-specs</em> repository and by making sure that we have the latest revision.</p>

<aside class="information">
    <p class="calibre3">All the commands from this chapter are available in the <a href="https://gist.github.com/d0cbca319360eb000098383a09fd65f7">07-jenkins-cdp.sh</a> Gist.</p>

</aside>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code><code class="nb">cd</code> k8s-specs
<code class="lineno">2 </code>
<code class="lineno">3 </code>git pull
</pre></div>

</figure>

<p class="calibre3">Next, we’ll merge your <em class="calibre17">go-demo-3</em> fork with the upstream. If you forgot the commands, they are available in the <a href="https://gist.github.com/171172b69bb75903016f0676a8fe9388">go-demo-3-merge.sh gist</a>.</p>

<aside class="warning">
    <p class="calibre3">It is imperative that you change all the references of <code class="calibre19">vfarcic/go-demo-3</code> to the address of the image in your Docker Hub account. If, for example, your hub user is <code class="calibre19">jdoe</code>, you should change all <code class="calibre19">vfarcic/go-demo-3</code> references to <code class="calibre19">jdoe/go-demo-3</code>. Even though I invite you to apply the modifications to all the files of the repository, the necessary changes are in files <em class="calibre17">helm/go-demo-3/Chart.yaml</em>, <em class="calibre17">helm/go-demo-3/templates/deployment.yaml</em>, and <em class="calibre17">k8s/build-config.yml</em>. Please make sure to <strong class="calibre18">change all the branches</strong>. Do not forget to <strong class="calibre18">push</strong> them to GitHub.</p>

</aside>

<p class="calibre3">Now comes boring, but necessary part. We need to create a cluster unless you kept the one from the previous chapter running.</p>

<p class="calibre3">The additional requirements, when compared with the Gists from the previous chapter, are <strong class="calibre18">ChartMuseum</strong> and the environment variable <code class="calibre19">CM_ADDR</code> that contains the address through which we can access it.</p>

<p class="calibre3">If you’re using a local cluster created through <strong class="calibre18">Docker For Mac or Windows</strong>, <strong class="calibre18">minikube</strong>, or <strong class="calibre18">minishift</strong>, we’ll have to increase its size to <strong class="calibre18">4GB RAM</strong> and <strong class="calibre18">4CPU</strong>.</p>

<p class="calibre3"><strong class="calibre18">Docker For Mac or Windows</strong> users will also need to get the “real” IP of the cluster, instead of <code class="calibre19">localhost</code> we used so far. You should be able to get it by executing <code class="calibre19">ifconfig</code> and picking the address dedicated to Docker.</p>

<p class="calibre3">For your convenience, the Gists and the specs are available below.</p>

<ul class="calibre21">
  <li class="calibre15">
<a href="https://gist.github.com/4b5487e707043c971989269883d20d28">docker4mac-4gb.sh</a>: <strong class="calibre18">Docker for Mac</strong> with 3 CPUs, 4 GB RAM, with <strong class="calibre18">nginx Ingress</strong>, with <strong class="calibre18">tiller</strong>, with <code class="calibre19">LB_IP</code> variable set to the IP of the cluster, and with <strong class="calibre18">ChartMuseum</strong> and its address set as <code class="calibre19">CM_ADDR</code> variable.</li>
  <li class="calibre15">
<a href="https://gist.github.com/0a29803842b62c5c033e4c75cd37f3d4">minikube-4gb.sh</a>: <strong class="calibre18">minikube</strong> with 3 CPUs, 4 GB RAM, with <code class="calibre19">ingress</code>, <code class="calibre19">storage-provisioner</code>, and <code class="calibre19">default-storageclass</code> addons enabled, with <strong class="calibre18">tiller</strong>, with <code class="calibre19">LB_IP</code> variable set to the VM created by minikube, and with <strong class="calibre18">ChartMuseum</strong> and its address set as <code class="calibre19">CM_ADDR</code> variable.</li>
  <li class="calibre15">
<a href="https://gist.github.com/603e2dca21b4475985a078b0f78db88c">kops-cm.sh</a>: <strong class="calibre18">kops in AWS</strong> with 3 t2.small masters and 2 t2.medium nodes spread in three availability zones, with <strong class="calibre18">nginx Ingress</strong>, with <strong class="calibre18">tiller</strong>, and with <code class="calibre19">LB_IP</code> variable set to the IP retrieved by pinging ELB’s hostname, and with <strong class="calibre18">ChartMuseum</strong> and its address set as <code class="calibre19">CM_ADDR</code> variable. The Gist assumes that the prerequisites are set through <a href="part0018.html#appendix-b">Appendix B</a>.</li>
  <li class="calibre15">
<a href="https://gist.github.com/b3d9c8da6e6dfd3b49d3d707595f6f99">minishift-4gb.sh</a>: <strong class="calibre18">minishift</strong> with 4 CPUs, 4 GB RAM, with version 1.16+, with <strong class="calibre18">tiller</strong>, and with <code class="calibre19">LB_IP</code> variable set to the VM created by minishift, and with <strong class="calibre18">ChartMuseum</strong> and its address set as <code class="calibre19">CM_ADDR</code> variable.</li>
  <li class="calibre15">
<a href="https://gist.github.com/52b52500c469548e9d98c3f03529c609">gke-cm.sh</a>: <strong class="calibre18">Google Kubernetes Engine (GKE)</strong> with 3 n1-highcpu-2 (2 CPUs, 1.8 GB RAM) nodes (one in each zone), with <strong class="calibre18">nginx Ingress</strong> controller running on top of the “standard” one that comes with GKE, with <strong class="calibre18">tiller</strong>, with <code class="calibre19">LB_IP</code> variable set to the IP of the external load balancer created when installing nginx Ingress, and with <strong class="calibre18">ChartMuseum</strong> and its address set as <code class="calibre19">CM_ADDR</code> variable. We’ll use nginx Ingress for compatibility with other platforms. Feel free to modify the YAML files and Helm Charts if you prefer NOT to install nginx Ingress.</li>
  <li class="calibre15">
<a href="https://gist.github.com/fd9c0cdb3a104e7c745e1c91f7f75a2e">eks-cm.sh</a>: <strong class="calibre18">Elastic Kubernetes Service (EKS)</strong> with 2 t2.medium nodes, with <strong class="calibre18">nginx Ingress</strong> controller, with a <strong class="calibre18">default StorageClass</strong>, with <strong class="calibre18">tiller</strong>, with <code class="calibre19">LB_IP</code> variable set tot he IP retrieved by pinging ELB’s hostname, and with <strong class="calibre18">ChartMuseum</strong> and its address set as <code class="calibre19">CM_ADDR</code> variable.</li>
</ul>

<p class="calibre3">Now we are ready to install Jenkins.</p>

<h3 id="leanpub-auto-installing-jenkins" class="calibre20">Installing Jenkins</h3>

<p class="calibre3">We already automated Jenkins installation so that it provides all the features we need out-of-the-box. Therefore, the exercises that follow should be very straightforward.</p>

<p class="calibre3">If you are a <strong class="calibre18">Docker For Mac or Windows</strong>, <strong class="calibre18">minikube</strong>, or <strong class="calibre18">minishift</strong> user, we’ll need to bring back up the VM we suspended in the previous chapter. Feel free to skip the commands that follow if you are hosting your cluster in AWS or GCP.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code><code class="nb">cd</code> cd/docker-build
<code class="lineno">2 </code>
<code class="lineno">3 </code>vagrant up
<code class="lineno">4 </code>
<code class="lineno">5 </code><code class="nb">cd</code> ../../
<code class="lineno">6 </code>
<code class="lineno">7 </code><code class="nb">export</code> <code class="nv">DOCKER_VM</code><code class="o">=</code><code class="nb">true</code>
</pre></div>

</figure>

<p class="calibre3">If you prefer running your cluster in <strong class="calibre18">AWS with kops or EKS</strong>, we’ll need to retrieve the AMI ID we stored in <code class="calibre19">docker-ami.log</code> in the previous chapter.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code><code class="nv">AMI_ID</code><code class="o">=</code><code class="k">$(</code>grep <code class="s">'artifact,0,id'</code> <code class="se">\</code>
<code class="lineno">2 </code>    cluster/docker-ami.log <code class="se">\</code>
<code class="lineno">3 </code>    <code class="calibre19">|</code> cut -d: -f2<code class="k">)</code>
<code class="lineno">4 </code>
<code class="lineno">5 </code><code class="nb">echo</code> <code class="nv">$AMI_ID</code>
</pre></div>

</figure>

<p class="calibre3">If <strong class="calibre18">GKE</strong> is your cluster of choice, we’ll need to define variables <code class="calibre19">G_PROJECT</code> and <code class="calibre19">G_AUTH_FILE</code> which we’ll pass to Helm Chart. We’ll retrieve the project using <code class="calibre19">gcloud</code> CLI, and the authentication file is a reference to the one we stored in <code class="calibre19">/cluster/jenkins/secrets</code> directory in the previous chapter.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno"> 1 </code><code class="nb">export</code> <code class="nv">G_PROJECT</code><code class="o">=</code><code class="k">$(</code>gcloud info <code class="se">\</code>
<code class="lineno"> 2 </code>    --format<code class="o">=</code><code class="s">'value(config.project)'</code><code class="k">)</code>
<code class="lineno"> 3 </code>
<code class="lineno"> 4 </code><code class="nb">echo</code> <code class="nv">$G_PROJECT</code>
<code class="lineno"> 5 </code>
<code class="lineno"> 6 </code><code class="nv">G_AUTH_FILE</code><code class="o">=</code><code class="k">$(</code><code class="se">\</code>
<code class="lineno"> 7 </code>    ls cluster/jenkins/secrets/key*json <code class="se">\</code>
<code class="lineno"> 8 </code>    <code class="calibre19">|</code> xargs -n <code class="o">1</code> basename <code class="se">\</code>
<code class="lineno"> 9 </code>    <code class="calibre19">|</code> tail -n <code class="o">1</code><code class="k">)</code>
<code class="lineno">10 </code>
<code class="lineno">11 </code><code class="nb">echo</code> <code class="nv">$G_AUTH_FILE</code>
</pre></div>

</figure>

<p class="calibre3">Next, we’ll need to create the Namespaces we’ll need. Let’s take a look at the definition we’ll use.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>cat ../go-demo-3/k8s/ns.yml
</pre></div>

</figure>

<p class="calibre3">You’ll notice that the definition is a combination of a few we used in the previous chapters. It contains three Namespaces.</p>

<p class="calibre3">The <code class="calibre19">go-demo-3-build</code> Namespace is where we’ll run Pods from which we’ll execute most of the steps of our pipeline. Those Pods will contain the tools like <code class="calibre19">kubectl</code>, <code class="calibre19">helm</code>, and Go compiler. We’ll use the same Namespace to deploy our releases under test. All in all, the <code class="calibre19">go-demo-3-build</code> Namespace is for short-lived Pods. The tools will be removed when a build is finished, just as installations of releases under test will be deleted when tests are finished executing. This Namespace will be like a trash can that needs to be emptied whenever it gets filled or start smelling.</p>

<p class="calibre3">The second Namespace is <code class="calibre19">go-demo-3</code>. That is the Namespace dedicated to the applications developed by the <code class="calibre19">go-demo-3</code> team. We’ll work only on their primary product, named after the team, but we can imagine that they might be in charge of other application. Therefore, do not think of this Namespace as dedicated to a single application, but assigned to a team. They have full permissions to operate inside that Namespace, just as the others defined in <code class="calibre19">ns.yml</code>. They own them, and <code class="calibre19">go-demo-3</code> is dedicated for production releases.</p>

<p class="calibre3">While we already used the two Namespaces, the third one is a bit new. The <code class="calibre19">go-demo-3-jenkins</code> is dedicated to Jenkins, and you might wonder why we do not use the <code class="calibre19">jenkins</code> Namespace as we did so far. The answer lies in my belief that it is a good idea to give each team their own Jenkins. That way, we do not need to create an elaborate system with user permissions, we do not need to think whether a plugin desired by one team will break a job owned by another, and we do not need to worry about performance issues when Jenkins is stressed by hundreds or thousands of parallel builds. So, we’ll apply “<strong class="calibre18">every team gets Jenkins</strong>” type of logic. “<em class="calibre17">It’s your Jenkins, do whatever you want to do with it,</em>” is the message we want to transmit to the teams in our company. Now, if your organization has only twenty developers, there’s probably no need for splitting Jenkins into multiple instances. Fifty should be OK as well. But, when that number rises to hundreds, or even thousands, having various Jenkins masters has clear benefits. Traditionally, that would not be practical due to increased operational costs. But now that we are deep into Kubernetes, and that we already saw that a fully functional and configured Jenkins is only a few commands away, we can agree that monster instances do not make much sense. If you are small and that logic does not apply, the processes we’ll explore are still the same, no matter whether you have one or a hundred Jenkins masters. Only the Namespace will be different (e.g., <code class="calibre19">jenkins</code>).</p>

<p class="calibre3">The rest of the definition is the same as what we used before. We have ServiceAccounts and RoleBindings that allow containers to interact with KubeAPI. We have LimitRanges and ResourceQuotas that protect the cluster from rogue Pods.</p>

<p class="calibre3">The LimitRange defined for the <code class="calibre19">go-demo-3-build</code> Namespace is especially important. We can assume that many of the Pods created through CDP pipeline will not have memory and CPU requests and limits. It’s only human to forget to define those things in pipelines. Still, that can be disastrous since it might produce undesired effects in the cluster. If nothing else, that would limit Kubernetes’ capacity to schedule Pods. So, defining LimitRange <code class="calibre19">default</code> and <code class="calibre19">defaultRequest</code> entries is a crucial step.</p>

<p class="calibre3">Please go through the whole <code class="calibre19">ns.yml</code> definition to refresh your memory of the things we explored in the previous chapters. We’ll <code class="calibre19">apply</code> it once you’re back.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>kubectl apply <code class="se">\</code>
<code class="lineno">2 </code>    -f ../go-demo-3/k8s/ns.yml <code class="se">\</code>
<code class="lineno">3 </code>    --record
</pre></div>

</figure>

<p class="calibre3">Now that we have the Namespaces, the ServiceAccounts, the RoleBindings, the LimitRanges, and the ResourceQuotas, we can proceed and create the secrets and the credentials required by Jenkins.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>kubectl -n go-demo-3-jenkins <code class="se">\</code>
<code class="lineno">2 </code>    create secret generic <code class="se">\</code>
<code class="lineno">3 </code>    jenkins-credentials <code class="se">\</code>
<code class="lineno">4 </code>    --from-file cluster/jenkins/credentials.xml
<code class="lineno">5 </code>
<code class="lineno">6 </code>kubectl -n go-demo-3-jenkins <code class="se">\</code>
<code class="lineno">7 </code>    create secret generic <code class="se">\</code>
<code class="lineno">8 </code>    jenkins-secrets <code class="se">\</code>
<code class="lineno">9 </code>    --from-file cluster/jenkins/secrets
</pre></div>

</figure>

<p class="calibre3">Only one more thing is missing before we install Jenkins. We need to install Tiller in the <code class="calibre19">go-demo-3-build</code> Namespace.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>helm init --service-account build <code class="se">\</code>
<code class="lineno">2 </code>    --tiller-namespace go-demo-3-build
</pre></div>

</figure>

<aside class="warning">
    <h3 id="leanpub-auto-a-note-to-minishift-users-26" class="calibre22">A note to minishift users</h3>

  <p class="calibre3">Helm will try to install Jenkins Chart with the process in a container running as user <code class="calibre19">0</code>. By default, that is not allowed in OpenShift. We’ll skip discussing the best approach to correct the issue, and I’ll assume you already know how to set the permissions on the per-Pod basis. Instead, we’ll do the most straightforward fix by executing the command that follows that will allow the creation of restricted Pods to run as any user.</p>

  <p class="calibre3"><code class="calibre19">oc patch scc restricted -p '{"runAsUser":{"type": "RunAsAny"}}'</code></p>

</aside>

<p class="calibre3">Now we are ready to install Jenkins.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno"> 1 </code><code class="nv">JENKINS_ADDR</code><code class="o">=</code><code class="s">"go-demo-3-jenkins.</code><code class="nv">$LB_IP</code><code class="s">.nip.io"</code>
<code class="lineno"> 2 </code>
<code class="lineno"> 3 </code>helm install helm/jenkins <code class="se">\</code>
<code class="lineno"> 4 </code>    --name go-demo-3-jenkins <code class="se">\</code>
<code class="lineno"> 5 </code>    --namespace go-demo-3-jenkins <code class="se">\</code>
<code class="lineno"> 6 </code>    --set jenkins.Master.HostName<code class="o">=</code><code class="nv">$JENKINS_ADDR</code> <code class="se">\</code>
<code class="lineno"> 7 </code>    --set jenkins.Master.DockerVM<code class="o">=</code><code class="nv">$DOCKER_VM</code> <code class="se">\</code>
<code class="lineno"> 8 </code>    --set jenkins.Master.DockerAMI<code class="o">=</code><code class="nv">$AMI_ID</code> <code class="se">\</code>
<code class="lineno"> 9 </code>    --set jenkins.Master.GProject<code class="o">=</code><code class="nv">$G_PROJECT</code> <code class="se">\</code>
<code class="lineno">10 </code>    --set jenkins.Master.GAuthFile<code class="o">=</code><code class="nv">$G_AUTH_FILE</code>
</pre></div>

</figure>

<p class="calibre3">We generated a <code class="calibre19">nip.io</code> address and installed Jenkins in the <code class="calibre19">go-demo-3-jenkins</code> Namespace. Remember, this Jenkins is dedicated to the <em class="calibre17">go-demo-3</em> team, and we might have many other instances serving the needs of other teams.</p>

<aside class="warning">
    <h3 id="leanpub-auto-a-note-to-minishift-users-27" class="calibre22">A note to minishift users</h3>

  <p class="calibre3">OpenShift requires Routes to make services accessible outside the cluster. To make things more complicated, they are not part of “standard Kubernetes” so we’ll need to create one using <code class="calibre19">oc</code>. Please execute the command that follows.</p>

  <p class="calibre3"><code class="calibre19">oc -n go-demo-3-jenkins create route edge --service go-demo-3-jenkins --insecure-policy Allow --hostname $JENKINS_ADDR</code></p>

  <p class="calibre3">That command created an <code class="calibre19">edge</code> Router tied to the <code class="calibre19">go-demo-3-jenkins</code> Service. Since we do not have SSL certificates for HTTPS communication, we also specified that it is OK to use insecure policy which will allow us to access Jenkins through plain HTTP. The last argument defined the address through which we’d like to access Jenkins UI.</p>

</aside>

<p class="calibre3">So far, everything we did is almost the same as what we’ve done in the previous chapters. The only difference is that we changed the Namespace where we deployed Jenkins. Now, the only thing left before we jump into pipelines is to wait until Jenkins is rolled out and confirm a few things.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>kubectl -n go-demo-3-jenkins <code class="se">\</code>
<code class="lineno">2 </code>    rollout status deployment <code class="se">\</code>
<code class="lineno">3 </code>    go-demo-3-jenkins
</pre></div>

</figure>

<p class="calibre3">The only thing we’ll validate, right now, is whether the node that we’ll use to build and push Docker images is indeed connected to Jenkins.</p>

<aside class="warning">
    <h3 id="leanpub-auto-a-note-to-windows-users-4" class="calibre22">A note to Windows users</h3>

  <p class="calibre3">Don’t forget that <code class="calibre19">open</code> command might not work in Windows and that you might need to replace it with <code class="calibre19">echo</code>, copy the output, and paste it into a tab of your favorite browser.</p>

</aside>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"http://</code><code class="nv">$JENKINS_ADDR</code><code class="s">/computer"</code>
</pre></div>

</figure>

<p class="calibre3">Just as before, we’ll need the auto-generated password.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code><code class="nv">JENKINS_PASS</code><code class="o">=</code><code class="k">$(</code>kubectl -n go-demo-3-jenkins <code class="se">\</code>
<code class="lineno">2 </code>    get secret go-demo-3-jenkins <code class="se">\</code>
<code class="lineno">3 </code>    -o <code class="nv">jsonpath</code><code class="o">=</code><code class="s">"{.data.jenkins-admin-password}"</code> <code class="se">\</code>
<code class="lineno">4 </code>    <code class="calibre19">|</code> base64 --decode<code class="calibre19">;</code> <code class="nb">echo</code><code class="k">)</code>
<code class="lineno">5 </code>
<code class="lineno">6 </code><code class="nb">echo</code> <code class="nv">$JENKINS_PASS</code>
</pre></div>

</figure>

<p class="calibre3">Please copy the output of the <code class="calibre19">echo</code> command, go back to the browser, and use it to log in as the <code class="calibre19">admin</code> user.</p>

<p class="calibre3">Once inside the nodes screen, you’ll see different results depending on how you set up the node for building and pushing Docker images.</p>

<p class="calibre3">If you are a <strong class="calibre18">Docker For Mac or Windows</strong>, a <strong class="calibre18">minikube</strong> user, or a <strong class="calibre18">minishift</strong> user, you’ll see a node called <code class="calibre19">docker-build</code>. That confirms that we successfully connected Jenkins with the VM we created with Vagrant.</p>

<p class="calibre3">If you created a cluster in <strong class="calibre18">AWS</strong> using <strong class="calibre18">kops</strong>, you should see a drop-down list called <strong class="calibre18">docker-agents</strong>.</p>

<p class="calibre3"><strong class="calibre18">GKE</strong> users should see a drop-down list called <strong class="calibre18">docker</strong>.</p>

<aside class="warning">
    <h3 id="leanpub-auto-a-note-to-aws-ec2-users-1" class="calibre22">A note to AWS EC2 users</h3>

  <p class="calibre3">Unlike on-prem and GKE solutions, AWS requires a single manual step to complete the Jenkins setup.</p>

  <p class="calibre3"><code class="calibre19">cat cluster/devops24.pem</code></p>

  <p class="calibre3">Copy the output.</p>

  <p class="calibre3"><code class="calibre19">open "http://$JENKINS_ADDR/configure"</code></p>

  <p class="calibre3">Scroll to the <em class="calibre17">EC2 Key Pair’s Private Key</em> field, and paste the key. Don’t forget to click the <em class="calibre17">Apply</em> button to persist the change.</p>

</aside>

<p class="calibre3">Now that we confirmed that a node (static or dynamic) is available for building and pushing Docker images, we can start designing our first stage of the continuous deployment pipeline.</p>

<h3 id="leanpub-auto-defining-the-build-stage" class="calibre20">Defining The Build Stage</h3>

<p class="calibre3">The primary function of the <strong class="calibre18">build stage</strong> of the continuous deployment pipeline is to build artifacts and a container image and push it to a registry from which it can be deployed and tested. Of course, we cannot build anything without code, so we’ll have to check out the repository as well.</p>

<p class="calibre3">Since building things without running static analysis, unit tests, and other types of validation against static code should be illegal and punishable by public shame, we’ll include those steps as well.</p>

<p class="calibre3">We won’t deal with building artifacts, nor we are going to run static testing and analysis from inside the pipeline. Instead, we’ll continue relying on Docker’s multistage builds for all those things, just as we did in the previous chapters.</p>

<p class="calibre3">Finally, we couldn’t push to a registry without authentication, so we’ll have to log in to Docker Hub just before we push a new image.</p>

<p class="calibre3">There are a few things that we are NOT going to do, even though you probably should when applying the lessons learned your “real” projects. We do NOT have static analysis. We are NOT generating code coverage, we are NOT creating reports, and we are not sending the result to analysis tools like <a href="https://www.sonarqube.org/">SonarQube</a>. More importantly, we are NOT running any security scanning. There are many other things we could do in this chapter, but we are not. The reason is simple. There is an almost infinite number of tools we could uses and steps we could execute. They depend on programming languages, internal processes, and what so not. Our goal is to understand the logic and, later on, to adapt the examples to your own needs. With that in mind, we’ll stick only to the bare minimum, not only in this stage but also in those that follow. It is up to you to extend them to fit your specific needs.</p>


<figure class="image1">
  <img src="../images/00029.jpeg" alt="Figure 7-2: The essential steps of the build stage" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-2: The essential steps of the build stage</figcaption>
</figure>


<p class="calibre3">Let’s define the steps of the build stage as a Jenkins job.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"http://</code><code class="nv">$JENKINS_ADDR</code><code class="s">"</code>
</pre></div>

</figure>

<p class="calibre3">From the Jenkins home screen, please click the <em class="calibre17">New Item</em> link from the left-hand menu. The script for creating new jobs will appear.</p>

<p class="calibre3">Type <em class="calibre17">go-demo-3</em> as the <em class="calibre17">item name</em>, select <em class="calibre17">Pipeline</em> as the job type and click the <em class="calibre17">OK</em> button.</p>

<aside class="information">
    <p class="calibre3">As a rule of thumb, name your pipeline jobs after the repositories from which you’re building the applications.</p>

</aside>

<p class="calibre3">Once inside job’s configuration screen, click the <em class="calibre17">Pipeline</em> tab in the top of the screen and type the script that follows inside the <em class="calibre17">Script</em> field.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno"> 1 </code><code class="k">import</code> <code class="nn">java.text.SimpleDateFormat</code>
<code class="lineno"> 2 </code>
<code class="lineno"> 3 </code><code class="calibre19">currentBuild</code><code class="o">.</code><code class="na">displayName</code> <code class="o">=</code> <code class="k">new</code> <code class="calibre19">SimpleDateFormat</code><code class="o">(</code><code class="s">"yy.MM.dd"</code><code class="o">).</code><code class="na">format</code><code class="o">(</code><code class="k">new</code> <code class="calibre19">Date</code><code class="o">())</code> <code class="o">+</code> <code class="s">"-"</code><code class="err">\</code>
<code class="lineno"> 4 </code> <code class="o">+</code> <code class="calibre19">env</code><code class="o">.</code><code class="na">BUILD_NUMBER</code>
<code class="lineno"> 5 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">REPO</code> <code class="o">=</code> <code class="s">"https://github.com/vfarcic/go-demo-3.git"</code>
<code class="lineno"> 6 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">IMAGE</code> <code class="o">=</code> <code class="s">"vfarcic/go-demo-3"</code>
<code class="lineno"> 7 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">TAG_BETA</code> <code class="o">=</code> <code class="s">"${currentBuild.displayName}-${env.BRANCH_NAME}"</code>
<code class="lineno"> 8 </code>
<code class="lineno"> 9 </code><code class="calibre19">node</code><code class="o">(</code><code class="s">"docker"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">10 </code>  <code class="calibre19">stage</code><code class="o">(</code><code class="s">"build"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">11 </code>    <code class="calibre19">git</code> <code class="s">"${env.REPO}"</code>
<code class="lineno">12 </code>    <code class="calibre19">sh</code> <code class="s">"""sudo docker image build \</code>
<code class="lineno">13 </code><code class="s">      -t ${env.IMAGE}:${env.TAG_BETA} ."""</code>
<code class="lineno">14 </code>    <code class="calibre19">withCredentials</code><code class="o">([</code><code class="calibre19">usernamePassword</code><code class="o">(</code>
<code class="lineno">15 </code>      <code class="nl">credentialsId:</code> <code class="s">"docker"</code><code class="o">,</code>
<code class="lineno">16 </code>      <code class="nl">usernameVariable:</code> <code class="s">"USER"</code><code class="o">,</code>
<code class="lineno">17 </code>      <code class="nl">passwordVariable:</code> <code class="s">"PASS"</code>
<code class="lineno">18 </code>    <code class="o">)])</code> <code class="o">{</code>
<code class="lineno">19 </code>      <code class="calibre19">sh</code> <code class="s">"""sudo docker login \</code>
<code class="lineno">20 </code><code class="s">        -u $USER -p $PASS"""</code>
<code class="lineno">21 </code>    <code class="o">}</code>
<code class="lineno">22 </code>    <code class="calibre19">sh</code> <code class="s">"""sudo docker image push \</code>
<code class="lineno">23 </code><code class="s">      ${env.IMAGE}:${env.TAG_BETA}"""</code>
<code class="lineno">24 </code>  <code class="o">}</code>
<code class="lineno">25 </code><code class="o">}</code>
</pre></div>

</figure>

<aside class="information">
    <p class="calibre3">If you prefer to copy and paste, the job is available in the <a href="https://gist.github.com/f990482b94e1c292d36da4526a4fa536">cdp-jenkins-build.groovy Gist</a>.</p>

</aside>

<p class="calibre3">Since we already went through all those steps manually, the steps inside the Jenkins job should be self-explanatory. Still, we’ll briefly explain what’s going on since this might be your first contact with Jenkins pipeline.</p>

<p class="calibre3">First of all, the job is written using the <strong class="calibre18">scripted pipeline</strong> syntax. The alternative would be to use <strong class="calibre18">declarative pipeline</strong> which forces a specific structure and naming convention. Personally, I prefer the latter. A declarative pipeline is easier to write and read, and it provides the structure that makes implementation of some patterns much easier. However, it also comes with a few limitations. In our case, those limitations are enough to make the declarative pipeline a lousy choice. Namely, it does not allow us to mix different types of agents, and it does not support all the options available in <code class="calibre19">podTemplate</code> (e.g., <code class="calibre19">namespace</code>). Since scripted pipeline does not have such limitations, we opted for that flavor, even though it makes the code often harder to maintain.</p>

<aside class="information">
    <p class="calibre3">Visit <a href="https://jenkins.io/doc/book/pipeline/">Pipeline documentation</a> if you’re somewhat new to it and want to learn more.</p>

</aside>

<p class="calibre3">What did we do so far?</p>

<p class="calibre3">We imported <code class="calibre19">SimpleDateFormat</code> library that allows us to retrieve dates. The reason for the <code class="calibre19">import</code> becomes evident in the next line where we are changing the name of the build. By default, each build is named sequentially. The first build is named <code class="calibre19">1</code>, the second <code class="calibre19">2</code>, and so on. We changed the naming pattern so that it contains the date in <code class="calibre19">yy.MM.dd</code> format, followed with the sequential build number.</p>

<p class="calibre3">Next, we’re defining a few environment variables that contain the information we’ll need in the pipeline steps. <code class="calibre19">REPO</code> holds the GitHub repository we’re using, <code class="calibre19">IMAGE</code> is the name of the Docker image we’ll build, and <code class="calibre19">TAG_BETA</code> has the tag the image we’ll use for testing. The latter is a combination of the build and the branch name.</p>

<p class="calibre3">Before we proceed, please change the <code class="calibre19">REPO</code> and the <code class="calibre19">IMAGE</code> variables to match the address of the repository you forked and the name of the image. In most cases, changing <code class="calibre19">vfarcic</code> to your GitHub and Docker Hub user should be enough.</p>

<p class="calibre3">The <code class="calibre19">node</code> block is where the “real” action is happening.</p>

<p class="calibre3">By setting the <code class="calibre19">node</code> to <code class="calibre19">docker</code>, we’re telling Jenkins to use the agent with the matching name or label for all the steps within that block. The mechanism will differ from one case to another. It could match the VM we created with Vagrant, or it could be a dynamically created node in AWS or GCP.</p>

<p class="calibre3">Inside the <code class="calibre19">node</code> is the <code class="calibre19">stage</code> block. It is used to group steps and has no practical purpose. It is purely cosmetic, and it’s used to visualize the pipeline.</p>

<p class="calibre3">Inside the <code class="calibre19">stage</code> are the steps. The full list of available steps depends on the available plugins. The most commonly used ones are documented in the <a href="https://jenkins.io/doc/pipeline/steps/">Pipeline Steps Reference</a>. As you’ll see, most of the pipeline we’ll define will be based on the <a href="https://jenkins.io/doc/pipeline/steps/workflow-durable-task-step/#sh-shell-script">sh: Shell Script</a> step. Since we already determined almost everything we need through commands executed in a terminal, using <code class="calibre19">sh</code> allows us to copy and paste those same commands. That way, we’ll have little dependency on Jenkins-specific way of working, and we’ll have parity between command line used by developers on their laptops and Jenkins pipelines.</p>

<p class="calibre3">Inside the <code class="calibre19">build</code> stage, we’re using <code class="calibre19">git</code> to retrieve the repository. Further on, we’re using <code class="calibre19">sh</code> to execute Docker commands to <code class="calibre19">build</code> an image, to <code class="calibre19">login</code> to Docker Hub, and to <code class="calibre19">push</code> the image.</p>

<p class="calibre3">The only “special” part of the pipeline is the <code class="calibre19">withCredentials</code> block. Since it would be very insecure to hard-code into our jobs Docker Hub’s username and password, we’re retrieving the information from Jenkins. The credentials with the ID <code class="calibre19">docker</code> will be converted into variables <code class="calibre19">USER</code> and <code class="calibre19">PASS</code> which are used with the <code class="calibre19">docker login</code> command. Besides the apparent do-not-hard-code-secrets reason, the primary motivation for using the <code class="calibre19">withCredentials</code> block lies in Jenkins’ ability to obfuscate confidential information. As you’ll see later on, the credentials will be removed from logs making them hidden to anyone poking around our builds.</p>

<aside class="information">
    <p class="calibre3">I split some of the instructions into multiple-lines to avoid potential problems with the width limitations in books. You won’t have those limitations in your pipelines, and you might want to refactor examples into single-line steps thus making them easier to read and maintain.</p>

</aside>

<p class="calibre3">Now that we had a brief exploration of our first draft of the pipeline, the time has come to try it out.</p>

<p class="calibre3">Please click the <em class="calibre17">Save</em> button to persist the job.</p>

<p class="calibre3">We’ll use the new UI to run the builds and visualize them.</p>

<p class="calibre3">Click the <em class="calibre17">Open Blue Ocean</em> link from the left-hand menu, followed with the <em class="calibre17">Run</em> button.</p>

<p class="calibre3">Once the build starts, a new row will appear. Click it to enter into the details of the build and to observe the progress until it’s finished and everything is green.</p>


<figure class="image">
  <img src="../images/00030.jpeg" alt="Figure 7-3: Jenkins build with a single stage" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-3: Jenkins build with a single stage</figcaption>
</figure>


<p class="calibre3">Let’s check whether Jenkins executed the steps correctly. If it did, we should have a new image pushed to our Docker Hub account.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code><code class="nb">export</code> <code class="nv">DH_USER</code><code class="o">=[</code>...<code class="o">]</code>
<code class="lineno">2 </code>
<code class="lineno">3 </code>open <code class="s">"https://hub.docker.com/r/</code><code class="nv">$DH_USER</code><code class="s">/go-demo-3/tags/"</code>
</pre></div>

</figure>

<p class="calibre3">Please replace <code class="calibre19">[...]</code> with your Docker Hub username.</p>

<p class="calibre3">You should see a new image tagged as a combination of the date, build number (<code class="calibre19">1</code>), and the branch. The only problem so far is that the branch is set to <code class="calibre19">null</code>. That is the expected behavior since we did not tell Jenkins which branch to retrieve. As a result, the environment variable <code class="calibre19">BRANCH_NAME</code> is set to <code class="calibre19">null</code> and, with it, our image tag as well. We’ll fix that problem later on. For now, we’ll have to live with <code class="calibre19">null</code>.</p>

<p class="calibre3">Now that we finished defining and verifying the <code class="calibre19">build</code> stage, we can proceed to the <em class="calibre17">functional testing</em>.</p>

<h3 id="leanpub-auto-defining-the-functional-testing-stage" class="calibre20">Defining The Functional Testing Stage</h3>

<p class="calibre3">For the <em class="calibre17">functional testing</em> stage, the first step is to install the application under test. To avoid the potential problems of installing the same release twice, we’ll use <code class="calibre19">helm upgrade</code> instead of <code class="calibre19">install</code>.</p>

<p class="calibre3">As you already know, Helm only acknowledges that the resources are created, not that all the Pods are running. To mitigate that, we’ll wait for <code class="calibre19">rollout status</code> before proceeding with tests.</p>

<p class="calibre3">Once the application is rolled out, we’ll run the functional tests. Please note that, in this case, we will run only one set of tests. In the “real” world scenario, there would probably be others like, for example, performance tests or front-end tests for different browsers.</p>

<aside class="information">
    <p class="calibre3">When running multiple sets of different tests, consider using <code class="calibre19">parallel</code> construct. More information can be found in the <a href="https://www.cloudbees.com/blog/parallelism-and-distributed-builds-jenkins">Parallelism and Distributed Builds with Jenkins</a> article.</p>

</aside>

<p class="calibre3">Finally, we’ll have to <code class="calibre19">delete</code> the Chart we installed. After all, it’s pointless to waste resources by running an application longer than we need it. In our scenario, as soon as the execution of the tests is finished, we’ll remove the application under test. However, there is a twist. Jenkins, like most other CI/CD tools, will stop the execution of the first error. Since there is no guarantee that none of the steps in this stage will fail, we’ll have to envelop all the inside a big <code class="calibre19">try</code>/<code class="calibre19">catch</code>/<code class="calibre19">finally</code> statement.</p>


<figure class="image">
  <img src="../images/00031.jpeg" alt="Figure 7-4: The essential steps of the functional stage" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-4: The essential steps of the functional stage</figcaption>
</figure>


<p class="calibre3">Before we move on and write a new version of the pipeline, we’ll need an address that we’ll use as Ingress host of our application under tests.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code><code class="nb">export</code> <code class="nv">ADDR</code><code class="o">=</code><code class="nv">$LB_IP</code>.nip.io
<code class="lineno">2 </code>
<code class="lineno">3 </code><code class="nb">echo</code> <code class="nv">$ADDR</code>
</pre></div>

</figure>

<p class="calibre3">Please copy the output of the <code class="calibre19">echo</code>. We’ll need it soon.</p>

<p class="calibre3">Next, we’ll open the job’s configuration screen.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"http://</code><code class="nv">$JENKINS_ADDR</code><code class="s">/job/go-demo-3/configure"</code>
</pre></div>

</figure>

<p class="calibre3">If you are <strong class="calibre18">NOT using minishift</strong>, please replace the existing code with the content of the <a href="https://gist.github.com/4edc53d5dd11814651485c9ff3672fb7">cdp-jenkins-func.groovy Gist</a>.</p>

<p class="calibre3">If you are <strong class="calibre18">using minishift</strong>, replace the existing code with the content of the <a href="https://gist.github.com/1661c2527eda2bfe1e35c77f448f7c34">cdp-jenkins-func-oc.groovy Gist</a>.</p>

<p class="calibre3">We’ll explore only the differences between the two revisions of the pipeline. They are as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno"> 1 </code><code class="o">...</code>
<code class="lineno"> 2 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">ADDRESS</code> <code class="o">=</code> <code class="s">"go-demo-3-${env.BUILD_NUMBER}-${env.BRANCH_NAME}.acme.com"</code>
<code class="lineno"> 3 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">CHART_NAME</code> <code class="o">=</code> <code class="s">"go-demo-3-${env.BUILD_NUMBER}-${env.BRANCH_NAME}"</code>
<code class="lineno"> 4 </code><code class="kt">def</code> <code class="calibre19">label</code> <code class="o">=</code> <code class="s">"jenkins-slave-${UUID.randomUUID().toString()}"</code>
<code class="lineno"> 5 </code>
<code class="lineno"> 6 </code><code class="calibre19">podTemplate</code><code class="o">(</code>
<code class="lineno"> 7 </code>  <code class="nl">label:</code> <code class="calibre19">label</code><code class="o">,</code>
<code class="lineno"> 8 </code>  <code class="nl">namespace:</code> <code class="s">"go-demo-3-build"</code><code class="o">,</code>
<code class="lineno"> 9 </code>  <code class="nl">serviceAccount:</code> <code class="s">"build"</code><code class="o">,</code>
<code class="lineno">10 </code>  <code class="nl">yaml:</code> <code class="s">"""</code>
<code class="lineno">11 </code><code class="s">apiVersion: v1</code>
<code class="lineno">12 </code><code class="s">kind: Pod</code>
<code class="lineno">13 </code><code class="s">spec:</code>
<code class="lineno">14 </code><code class="s">  containers:</code>
<code class="lineno">15 </code><code class="s">  - name: helm</code>
<code class="lineno">16 </code><code class="s">    image: vfarcic/helm:2.9.1</code>
<code class="lineno">17 </code><code class="s">    command: ["cat"]</code>
<code class="lineno">18 </code><code class="s">    tty: true</code>
<code class="lineno">19 </code><code class="s">  - name: kubectl</code>
<code class="lineno">20 </code><code class="s">    image: vfarcic/kubectl</code>
<code class="lineno">21 </code><code class="s">    command: ["cat"]</code>
<code class="lineno">22 </code><code class="s">    tty: true</code>
<code class="lineno">23 </code><code class="s">  - name: golang</code>
<code class="lineno">24 </code><code class="s">    image: golang:1.9</code>
<code class="lineno">25 </code><code class="s">    command: ["cat"]</code>
<code class="lineno">26 </code><code class="s">    tty: true</code>
<code class="lineno">27 </code><code class="s">"""</code>
<code class="lineno">28 </code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">29 </code>  <code class="calibre19">node</code><code class="o">(</code><code class="calibre19">label</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">30 </code>    <code class="calibre19">node</code><code class="o">(</code><code class="s">"docker"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">31 </code>      <code class="calibre19">stage</code><code class="o">(</code><code class="s">"build"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">32 </code>        <code class="o">...</code>
<code class="lineno">33 </code>      <code class="o">}</code>
<code class="lineno">34 </code>    <code class="o">}</code>
<code class="lineno">35 </code>    <code class="calibre19">stage</code><code class="o">(</code><code class="s">"func-test"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">36 </code>      <code class="k">try</code> <code class="o">{</code>
<code class="lineno">37 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">38 </code>          <code class="calibre19">git</code> <code class="s">"${env.REPO}"</code>
<code class="lineno">39 </code>          <code class="calibre19">sh</code> <code class="s">"""helm upgrade \</code>
<code class="lineno">40 </code><code class="s">            ${env.CHART_NAME} \</code>
<code class="lineno">41 </code><code class="s">            helm/go-demo-3 -i \</code>
<code class="lineno">42 </code><code class="s">            --tiller-namespace go-demo-3-build \</code>
<code class="lineno">43 </code><code class="s">            --set image.tag=${env.TAG_BETA} \</code>
<code class="lineno">44 </code><code class="s">            --set ingress.host=${env.ADDRESS} \</code>
<code class="lineno">45 </code><code class="s">            --set replicaCount=2 \</code>
<code class="lineno">46 </code><code class="s">            --set dbReplicaCount=1"""</code>
<code class="lineno">47 </code>        <code class="o">}</code>
<code class="lineno">48 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"kubectl"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">49 </code>          <code class="calibre19">sh</code> <code class="s">"""kubectl -n go-demo-3-build \</code>
<code class="lineno">50 </code><code class="s">            rollout status deployment \</code>
<code class="lineno">51 </code><code class="s">            ${env.CHART_NAME}"""</code>
<code class="lineno">52 </code>        <code class="o">}</code>
<code class="lineno">53 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"golang"</code><code class="o">)</code> <code class="o">{</code> <code class="c">// Uses env ADDRESS</code>
<code class="lineno">54 </code>          <code class="calibre19">sh</code> <code class="s">"go get -d -v -t"</code>
<code class="lineno">55 </code>          <code class="calibre19">sh</code> <code class="s">"""go test ./... -v \</code>
<code class="lineno">56 </code><code class="s">            --run FunctionalTest"""</code>
<code class="lineno">57 </code>        <code class="o">}</code>
<code class="lineno">58 </code>      <code class="o">}</code> <code class="k">catch</code><code class="o">(</code><code class="calibre19">e</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">59 </code>          <code class="calibre19">error</code> <code class="s">"Failed functional tests"</code>
<code class="lineno">60 </code>      <code class="o">}</code> <code class="k">finally</code> <code class="o">{</code>
<code class="lineno">61 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">62 </code>          <code class="calibre19">sh</code> <code class="s">"""helm delete \</code>
<code class="lineno">63 </code><code class="s">            ${env.CHART_NAME} \</code>
<code class="lineno">64 </code><code class="s">            --tiller-namespace go-demo-3-build \</code>
<code class="lineno">65 </code><code class="s">            --purge"""</code>
<code class="lineno">66 </code>        <code class="o">}</code>
<code class="lineno">67 </code>      <code class="o">}</code>
<code class="lineno">68 </code>    <code class="o">}</code>
<code class="lineno">69 </code>  <code class="o">}</code>
<code class="lineno">70 </code><code class="o">}</code>
</pre></div>

</figure>

<p class="calibre3">We added a few new environment variables that will simplify the steps that follow. The <code class="calibre19">ADDRESS</code> will be used to provide a unique host for the Ingress of the application under test. The uniqueness is accomplished by combining the name of the project (<code class="calibre19">go-demo-3</code>), the build number, and the name of the branch. We used a similar pattern to generate the name of the Chart that will be installed. All in all, both the address and the Chart are unique for each release of each application, no matter the branch.</p>

<p class="calibre3">We also defined <code class="calibre19">label</code> variable with a unique value by adding a suffix based on random UUID. Further down, when we define <code class="calibre19">podTemplate</code>, we’ll use the <code class="calibre19">label</code> to ensure that each build uses its own Pod.</p>

<p class="calibre3">The <code class="calibre19">podTemplate</code> itself is very similar to those we used in quite a few occasions. It’ll be created in the <code class="calibre19">go-demo-3-build</code> Namespace dedicated to building and testing applications owned by the <code class="calibre19">go-demo-3</code> team. The <code class="calibre19">yaml</code> contains the definitions of the Pod that includes containers with <code class="calibre19">helm</code>, <code class="calibre19">kubectl</code>, and <code class="calibre19">golang</code>. Those are the tools we’ll need to execute the steps of the <em class="calibre17">functional testing</em> stage.</p>

<aside class="warning">
    <h3 id="leanpub-auto-a-note-to-minishift-users-28" class="calibre22">A note to minishift users</h3>

  <p class="calibre3">Your version of the pipeline contains a few things that other Kubernetes users do not need. You’ll notice that there is an additional container named <code class="calibre19">oc</code> in the <code class="calibre19">podTemplate</code>. Further down, in the <code class="calibre19">func-test</code> stage, we’re using that container to create an Edge Route that provides the same functionality as Ingress controller used by other Kubernetes flavors.</p>

</aside>

<p class="calibre3">The curious part is the way nodes (agents) are organized in this iteration of the pipeline. Everything is inside one big block of <code class="calibre19">node(label)</code>. As a result, all the steps will be executed in one of the containers of the <code class="calibre19">podTemplate</code>. However, since we do not want the build steps to run inside the cluster, inside the node based on the <code class="calibre19">podTemplate</code> is the same <code class="calibre19">node("docker")</code> block we are using for building and pushing Docker images.</p>

<p class="calibre3">The reason for using nested <code class="calibre19">node</code> blocks lies in Jenkins’ ability to delete unused Pods. The moment <code class="calibre19">podTemplate</code> node is closed, Jenkins will remove the associated Pod. To preserve the state we’ll generate inside that Pod, we’re making sure that it is alive through the whole build by enveloping all the steps (even those running somewhere else) inside one colossal <code class="calibre19">node(label)</code> block.</p>

<p class="calibre3">Inside the <code class="calibre19">func-test</code> stage is a <code class="calibre19">try</code> block that contains all the steps (except cleanup). Each of the steps is executed inside a different container. We enter <code class="calibre19">helm</code> to clone the code and execute <code class="calibre19">helm upgrade</code> that installs the release under test. Next, we jump into the <code class="calibre19">kubectl</code> container to wait for the <code class="calibre19">rollout status</code> that confirms that the application is rolled out completely. Finally, we switch into the <code class="calibre19">golang</code> container to run our tests.</p>

<p class="calibre3">Please note that we are installing only two replicas of the application under test and one replica of the DB. That’s more than enough to validate whether it works as expected from the functional point of view. There’s no need to have the same number of replicas as what we’ll run in the production Namespace.</p>

<p class="calibre3">You might be wondering why we checked out the code for the second time. The reason is simple. In the first stage, we cloned the code inside the VM dedicated to (or dynamically created for) building Docker images. The Pod created through <code class="calibre19">podTemplate</code> does not have that code, so we had to clone it again. We did that inside the <code class="calibre19">helm</code> container since that’s the first one we’re using.</p>

<p class="calibre3">Why didn’t we clone the code to all the containers of the Pod? After all, almost everything we do needs the code of the application. While that might not be true for the <code class="calibre19">kubectl</code> container (it only waits for the installation to roll out), it is undoubtedly true for <code class="calibre19">golang</code>. The answer lies in Jenkins <code class="calibre19">podTemplate</code> “hidden” features. Among other things, it creates a volume and mounts it to all the containers of the Pod as the directory <code class="calibre19">/workspace</code>. That directory happens to be the default directory in which it operates when inside those containers. So, the state created inside one of the containers, exists in all the others, as long as we do not switch to a different folder.</p>

<p class="calibre3">The <code class="calibre19">try</code> block is followed with <code class="calibre19">catch</code> that is executed only if one of the steps throws an error. The only purpose for having the <code class="calibre19">catch</code> block is to re-throw the error if there is any.</p>

<p class="calibre3">The sole purpose for using <code class="calibre19">try</code>/<code class="calibre19">catch</code> is in the <code class="calibre19">finally</code> block. In it, we are deleting the application we deployed. Since it executes no matter whether there was an error, we have a reasonable guarantee that we’ll have a clean system no matter the outcome of the pipeline.</p>

<p class="calibre3">To summarize, <code class="calibre19">try</code> block ensures that errors are caught. Without it, the pipeline would stop executing on the first sign of failure, and the release under test would never be removed. The <code class="calibre19">catch</code> block re-throws the error, and the <code class="calibre19">finally</code> block deletes the release no matter what happens.</p>

<p class="calibre3">Before we test the new iteration of the pipeline, please replace the values of the environment variables to fit your situation. As a minimum, you’ll need to change <code class="calibre19">vfarcic</code> to your GitHub and Docker Hub users, and you’ll have to replace <code class="calibre19">acme.com</code> with the value stored in the environment variable <code class="calibre19">ADDR</code> in your terminal session.</p>

<p class="calibre3">Once finished with the changes, please click the <em class="calibre17">Save</em> button. Use the <em class="calibre17">Open Blue Ocean</em> link from the left-hand menu to switch to the new UI and click the <em class="calibre17">Run</em> button followed with a click on the row of the new build.</p>

<aside class="information">
    <p class="calibre3">If you configured Jenkins to spin up new Docker nodes in AWS or GCP, it will take around a minute until the VM is created and operational.</p>

</aside>

<p class="calibre3">Please wait until the build reaches the <code class="calibre19">func-test</code> stage and finishes executing the second step that executes <code class="calibre19">helm upgrade</code>. Once the release under test is installed, switch to the terminal session to confirm that the new release is indeed installed.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>helm ls <code class="se">\</code>
<code class="lineno">2 </code>    --tiller-namespace go-demo-3-build
</pre></div>

</figure>

<p class="calibre3">The output is as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>NAME             REVISION UPDATED        STATUS   CHART           NAMESPACE
<code class="lineno">2 </code>go-demo-3-2-null 1        Tue Jul 17 ... DEPLOYED go-demo-3-0.0.1 go-demo-3-build
</pre></div>

</figure>

<p class="calibre3">As we can see, Jenkins did initiate the process that resulted in the new Helm Chart being installed in the <code class="calibre19">go-demo-3-build</code> Namespace.</p>

<p class="calibre3">To be on the safe side, we’ll confirm that the Pods are running as well.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>kubectl -n go-demo-3-build <code class="se">\</code>
<code class="lineno">2 </code>    get pods
</pre></div>

</figure>

<p class="calibre3">The output is as follows</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>NAME                  READY STATUS  RESTARTS AGE
<code class="lineno">2 </code>go-demo-3-2-null-...  1/1   Running 4        2m
<code class="lineno">3 </code>go-demo-3-2-null-...  1/1   Running 4        2m
<code class="lineno">4 </code>go-demo-3-2-null-db-0 2/2   Running 0        2m
<code class="lineno">5 </code>jenkins-slave-...     4/4   Running 0        6m
<code class="lineno">6 </code>tiller-deploy-...     1/1   Running 0        14m
</pre></div>

</figure>

<p class="calibre3">As expected, the two Pods of the API and one of the DB are running together with <code class="calibre19">jenkins-slave</code> Pod created by Jenkins.</p>

<p class="calibre3">Please return to Jenkins UI and wait until the build is finished.</p>


<figure class="image1">
  <img src="../images/00032.jpeg" alt="Figure 7-5: Jenkins build with the build and the functional testing stage" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-5: Jenkins build with the build and the functional testing stage</figcaption>
</figure>


<p class="calibre3">If everything works as we designed, the release under test was removed once the testing was finished. Let’s confirm that.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>helm ls <code class="se">\</code>
<code class="lineno">2 </code>    --tiller-namespace go-demo-3-build
</pre></div>

</figure>

<p class="calibre3">This time the output is empty, clearly indicating that the Chart was removed.</p>

<p class="calibre3">Let’s check the Pods one more time.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>kubectl -n go-demo-3-build <code class="se">\</code>
<code class="lineno">2 </code>    get pods
</pre></div>

</figure>

<p class="calibre3">The output is as follows</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>NAME              READY STATUS  RESTARTS AGE
<code class="lineno">2 </code>tiller-deploy-... 1/1   Running 0        31m
</pre></div>

</figure>

<p class="calibre3">Both the Pods of the release under tests as well as Jenkins agent are gone, leaving us only with Tiller. We defined the steps that remove the former, and the latter is done by Jenkins automatically.</p>

<p class="calibre3">Let’s move onto the <em class="calibre17">release stage</em>.</p>

<h3 id="leanpub-auto-defining-the-release-stage" class="calibre20">Defining The Release Stage</h3>

<p class="calibre3">In the <em class="calibre17">release stage</em>, we’ll push Docker images to the registry as well as the project’s Helm Chart. The images will be tags of the image under test, but this time they will be named using a convention that clearly indicates that they are production- ready.</p>

<p class="calibre3">In the <em class="calibre17">build stage</em>, we’re tagging images by including the branch name. That way, we made it clear that an image is not yet thoroughly tested. Now that we executed all sorts of tests that validated that the release is indeed working as expected, we can re-tag the images so that they do not include branch names. That way, everyone in our organization can easily distinguish yet-to-be-tested from production-ready releases.</p>

<p class="calibre3">Since we cannot know (easily) whether the Chart included in the project’s repository changed or not, during this stage, we’ll push it to ChartMuseum. If the Chart’s release number is unchanged, the push will merely overwrite the existing Chart. Otherwise, we’ll have a new Chart release as well.</p>

<p class="calibre3">The significant difference between Docker images and Charts is in the way how we’re generating releases. Each commit to the repository probably results in changes to the code, so building new images on each build makes perfect sense. Helm Charts, on the other hand, do not change that often.</p>

<p class="calibre3">One thing worth noting is that we will not use ChartMuseum for deploying applications through Jenkins’ pipelines. We already have the Chart inside the repository that we’re cloning. We’ll store Charts in ChartMuseum only for those that want to deploy them manually without Jenkins. A typical user of those Charts are developers that want to spin up applications inside local clusters that are outside Jenkins’ control.</p>

<p class="calibre3">Just as with the previous stages, we are focused only on the essential steps which you should extend to suit your specific needs. Examples that might serve as inspiration for the missing steps are those that would create a release in GitHub, GitLab, or Bitbucket. Also, it might be useful to build Docker images with manifest files in case you’re planning on deploying them to different operating system families (e.g., ARM, Windows, etc.). Another thing that would be interesting to add is an automated way to create and publish release notes. Don’t get your hopes too high because we’ll skip those and quite a few other use-cases in an attempt to keep the pipeline simple, and yet fully functional.</p>


<figure class="image1">
  <img src="../images/00033.jpeg" alt="Figure 7-6: The essential steps of the release stage" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-6: The essential steps of the release stage</figcaption>
</figure>


<p class="calibre3">Before we move on, we’ll need to create a new set of credentials in Jenkins to store ChartMuseum’s username and password.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"http://</code><code class="nv">$JENKINS_ADDR</code><code class="s">/credentials/store/system/domain/_/newCredentials"</code>
</pre></div>

</figure>

<p class="calibre3">Please type <em class="calibre17">admin</em> as both the <em class="calibre17">Username</em> and the <em class="calibre17">Password</em>. The <em class="calibre17">ID</em> and the <em class="calibre17">Description</em> should be set to <em class="calibre17">chartmuseum</em>. Once finished, please click the <em class="calibre17">OK</em> button to persist the credentials.</p>


<figure class="image">
  <img src="../images/00034.jpeg" alt="Figure 7-7: ChartMuseum Jenkins credentials" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-7: ChartMuseum Jenkins credentials</figcaption>
</figure>


<p class="calibre3">Next, we’ll retrieve the updated <code class="calibre19">credentials.xml</code> file and store it in the <code class="calibre19">cluster/jenkins</code> directory. That way, if we want to create a new Jenkins instance, the new credentials will be available just as those that we created in the previous chapter.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno"> 1 </code><code class="nv">JENKINS_POD</code><code class="o">=</code><code class="k">$(</code>kubectl <code class="se">\</code>
<code class="lineno"> 2 </code>    -n go-demo-3-jenkins <code class="se">\</code>
<code class="lineno"> 3 </code>    get pods <code class="se">\</code>
<code class="lineno"> 4 </code>    -l <code class="nv">component</code><code class="o">=</code>go-demo-3-jenkins-jenkins-master <code class="se">\</code>
<code class="lineno"> 5 </code>    -o <code class="nv">jsonpath</code><code class="o">=</code><code class="s">'{.items[0].metadata.name}'</code><code class="k">)</code>
<code class="lineno"> 6 </code>
<code class="lineno"> 7 </code><code class="nb">echo</code> <code class="nv">$JENKINS_POD</code>
<code class="lineno"> 8 </code>
<code class="lineno"> 9 </code>kubectl -n go-demo-3-jenkins cp <code class="se">\</code>
<code class="lineno">10 </code>    <code class="nv">$JENKINS_POD</code>:var/jenkins_home/credentials.xml <code class="se">\</code>
<code class="lineno">11 </code>    cluster/jenkins
</pre></div>

</figure>

<p class="calibre3">We retrieved the name of the Pod hosting Jenkins, and we used it to copy the <code class="calibre19">credentials.xml</code> file.</p>

<p class="calibre3">Now we can update the job.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"http://</code><code class="nv">$JENKINS_ADDR</code><code class="s">/job/go-demo-3/configure"</code>
</pre></div>

</figure>

<p class="calibre3">If you are <strong class="calibre18">NOT using minishift</strong>, please replace the existing code with the content of the <a href="https://gist.github.com/2e89eec6ca991ab676d740733c409d35">cdp-jenkins-release.groovy Gist</a>.</p>

<p class="calibre3">If you are a <strong class="calibre18">minishift user</strong>, replace the existing code with the content of the <a href="https://gist.github.com/33650e28417ceb1f2f349ec71b8a934d">cdp-jenkins-release-oc.groovy Gist</a>.</p>

<p class="calibre3">Just as before, we’ll explore only the differences between the two pipeline iterations.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno"> 1 </code><code class="o">...</code>
<code class="lineno"> 2 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">CM_ADDR</code> <code class="o">=</code> <code class="s">"cm.acme.com"</code>
<code class="lineno"> 3 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">TAG</code> <code class="o">=</code> <code class="s">"${currentBuild.displayName}"</code>
<code class="lineno"> 4 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">TAG_BETA</code> <code class="o">=</code> <code class="s">"${env.TAG}-${env.BRANCH_NAME}"</code>
<code class="lineno"> 5 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">CHART_VER</code> <code class="o">=</code> <code class="s">"0.0.1"</code>
<code class="lineno"> 6 </code><code class="o">...</code>
<code class="lineno"> 7 </code>    <code class="calibre19">stage</code><code class="o">(</code><code class="s">"release"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno"> 8 </code>      <code class="calibre19">node</code><code class="o">(</code><code class="s">"docker"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno"> 9 </code>        <code class="calibre19">sh</code> <code class="s">"""sudo docker pull \</code>
<code class="lineno">10 </code><code class="s">          ${env.IMAGE}:${env.TAG_BETA}"""</code>
<code class="lineno">11 </code>        <code class="calibre19">sh</code> <code class="s">"""sudo docker image tag \</code>
<code class="lineno">12 </code><code class="s">          ${env.IMAGE}:${env.TAG_BETA} \</code>
<code class="lineno">13 </code><code class="s">          ${env.IMAGE}:${env.TAG}"""</code>
<code class="lineno">14 </code>        <code class="calibre19">sh</code> <code class="s">"""sudo docker image tag \</code>
<code class="lineno">15 </code><code class="s">          ${env.IMAGE}:${env.TAG_BETA} \</code>
<code class="lineno">16 </code><code class="s">          ${env.IMAGE}:latest"""</code>
<code class="lineno">17 </code>        <code class="calibre19">withCredentials</code><code class="o">([</code><code class="calibre19">usernamePassword</code><code class="o">(</code>
<code class="lineno">18 </code>          <code class="nl">credentialsId:</code> <code class="s">"docker"</code><code class="o">,</code>
<code class="lineno">19 </code>          <code class="nl">usernameVariable:</code> <code class="s">"USER"</code><code class="o">,</code>
<code class="lineno">20 </code>          <code class="nl">passwordVariable:</code> <code class="s">"PASS"</code>
<code class="lineno">21 </code>        <code class="o">)])</code> <code class="o">{</code>
<code class="lineno">22 </code>          <code class="calibre19">sh</code> <code class="s">"""sudo docker login \</code>
<code class="lineno">23 </code><code class="s">            -u $USER -p $PASS"""</code>
<code class="lineno">24 </code>        <code class="o">}</code>
<code class="lineno">25 </code>        <code class="calibre19">sh</code> <code class="s">"""sudo docker image push \</code>
<code class="lineno">26 </code><code class="s">          ${env.IMAGE}:${env.TAG}"""</code>
<code class="lineno">27 </code>        <code class="calibre19">sh</code> <code class="s">"""sudo docker image push \</code>
<code class="lineno">28 </code><code class="s">          ${env.IMAGE}:latest"""</code>
<code class="lineno">29 </code>      <code class="o">}</code>
<code class="lineno">30 </code>      <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">31 </code>        <code class="calibre19">sh</code> <code class="s">"helm package helm/go-demo-3"</code>
<code class="lineno">32 </code>        <code class="calibre19">withCredentials</code><code class="o">([</code><code class="calibre19">usernamePassword</code><code class="o">(</code>
<code class="lineno">33 </code>          <code class="nl">credentialsId:</code> <code class="s">"chartmuseum"</code><code class="o">,</code>
<code class="lineno">34 </code>          <code class="nl">usernameVariable:</code> <code class="s">"USER"</code><code class="o">,</code>
<code class="lineno">35 </code>          <code class="nl">passwordVariable:</code> <code class="s">"PASS"</code>
<code class="lineno">36 </code>        <code class="o">)])</code> <code class="o">{</code>
<code class="lineno">37 </code>          <code class="calibre19">sh</code> <code class="s">"""curl -u $USER:$PASS \</code>
<code class="lineno">38 </code><code class="s">            --data-binary "@go-demo-3-${CHART_VER}.tgz" \</code>
<code class="lineno">39 </code><code class="s">            http://${env.CM_ADDR}/api/charts"""</code>
<code class="lineno">40 </code>        <code class="o">}</code>
<code class="lineno">41 </code>      <code class="o">}</code>
<code class="lineno">42 </code>    <code class="o">}</code>
<code class="lineno">43 </code>  <code class="o">}</code>
<code class="lineno">44 </code><code class="o">}</code>
</pre></div>

</figure>

<p class="calibre3">Jut as before, we declared a few new environment variables. They should be self-explanatory.</p>

<p class="calibre3">We start the steps of the <em class="calibre17">release stage</em> inside the <code class="calibre19">docker</code> node. Since the nodes in AWS and GCP are dynamic, there is no guarantee that it’ll be the same agent as the one used in the <em class="calibre17">build stage</em> since we set retention to ten minutes. Typically, that is more than enough time between the two requests for the node. However, some other build might have requested the node in between and, in that case, a new one would be created. Therefore, we cannot be sure that it’s the same physical VM. To mitigate that, the first step is pulling the image we build previously. That way, we’re ensuring that the cache is used in subsequent steps.</p>

<p class="calibre3">Next, we’re creating two tags. One is based on the release (build display name), and the other on the <code class="calibre19">latest</code>. We’ll use the more specific tag, while leaving the option to others to use the <code class="calibre19">latest</code> that that points to the last production-ready release.</p>

<p class="calibre3">Further on, we’re logging to Docker Hub and pushing the new tags.</p>

<p class="calibre3">Finally, we are switching to the <code class="calibre19">helm</code> container of the <code class="calibre19">podTemplate</code>. Once inside, we are packaging the Chart and pushing it to ChartMuseum with <code class="calibre19">curl</code>. The essential element is the environment variable <code class="calibre19">CHART_VER</code>. It contains the version of the Chart that <strong class="calibre18">must</strong> correspond to the version in <code class="calibre19">Chart.yaml</code> file. We’re using it to know which file to push. Truth be told, we could have parsed the output of the <code class="calibre19">helm package</code> command. However, since Charts do not change that often, it might be less work to update the version in two places than to add parsing to the code. It is true that having the same thing in two places increases the chances of an error by omission. I invite you to a challenge the current design by making a PR that will improve it.</p>

<p class="calibre3">Before we move on, you’ll need to make the necessary changes to the values of the environment variables. Most likely, all you need to do is change <code class="calibre19">vfarcic</code> to your Docker Hub and GitHub users as well as <code class="calibre19">acme.com</code> to the value of the environment variable <code class="calibre19">ADDR</code> available in your terminal session.</p>

<p class="calibre3">Don’t forget to click the <em class="calibre17">Save</em> button to persist the change. After that, follow the same process as before to run a new build by clicking the <em class="calibre17">Open Blue Ocean</em> link from the left-hand menu, followed with the <em class="calibre17">Run</em> button. Click on the row of the new build and wait until it’s finished.</p>


<figure class="image">
  <img src="../images/00035.jpeg" alt="Figure 7-8: Jenkins build with the build, the functional testing, and the release stages" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-8: Jenkins build with the build, the functional testing, and the release stages</figcaption>
</figure>


<p class="calibre3">If everything went as expected, we should have a couple of new images pushed to Docker Hub. Let’s confirm that.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"https://hub.docker.com/r/</code><code class="nv">$DH_USER</code><code class="s">/go-demo-3/tags/"</code>
</pre></div>

</figure>

<p class="calibre3">This time, besides the tags based on branches (for now with <code class="calibre19">null</code>), we got two new ones that represent the production-ready release.</p>


<figure class="image1">
  <img src="../images/00036.jpeg" alt="Figure 7-9: Images pushed to Docker Hub" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-9: Images pushed to Docker Hub</figcaption>
</figure>


<p class="calibre3">Similarly, we should also have the Chart stored in ChartMuseum.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>curl -u admin:admin <code class="se">\</code>
<code class="lineno">2 </code>    <code class="s">"http://</code><code class="nv">$CM_ADDR</code><code class="s">/index.yaml"</code>
</pre></div>

</figure>

<p class="calibre3">The output is as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno"> 1 </code><code class="calibre19">apiVersion</code><code class="calibre19">:</code> <code class="calibre19">v1</code>
<code class="lineno"> 2 </code><code class="calibre19">entries</code><code class="calibre19">:</code>
<code class="lineno"> 3 </code>  <code class="calibre19">go-demo-3</code><code class="calibre19">:</code>
<code class="lineno"> 4 </code>  <code class="calibre19">-</code> <code class="calibre19">apiVersion</code><code class="calibre19">:</code> <code class="calibre19">v1</code>
<code class="lineno"> 5 </code>    <code class="calibre19">created</code><code class="calibre19">:</code> <code class="s">"2018-07-17T21:53:30.760065856Z"</code>
<code class="lineno"> 6 </code>    <code class="calibre19">description</code><code class="calibre19">:</code> <code class="calibre19">A silly demo based on API written in Go and MongoDB</code>
<code class="lineno"> 7 </code>    <code class="calibre19">digest</code><code class="calibre19">:</code> <code class="calibre19">d73134fc9ff594e9923265476bac801b1bd38d40548799afd66328158f0617d8</code>
<code class="lineno"> 8 </code>    <code class="calibre19">home</code><code class="calibre19">:</code> <code class="calibre19">http://www.devopstoolkitseries.com/</code>
<code class="lineno"> 9 </code>    <code class="calibre19">keywords</code><code class="calibre19">:</code>
<code class="lineno">10 </code>    <code class="calibre19">-</code> <code class="calibre19">api</code>
<code class="lineno">11 </code>    <code class="calibre19">-</code> <code class="calibre19">backend</code>
<code class="lineno">12 </code>    <code class="calibre19">-</code> <code class="calibre19">go</code>
<code class="lineno">13 </code>    <code class="calibre19">-</code> <code class="calibre19">database</code>
<code class="lineno">14 </code>    <code class="calibre19">-</code> <code class="calibre19">mongodb</code>
<code class="lineno">15 </code>    <code class="calibre19">maintainers</code><code class="calibre19">:</code>
<code class="lineno">16 </code>    <code class="calibre19">-</code> <code class="calibre19">email</code><code class="calibre19">:</code> <code class="calibre19">viktor@farcic.com</code>
<code class="lineno">17 </code>      <code class="calibre19">name</code><code class="calibre19">:</code> <code class="calibre19">Viktor Farcic</code>
<code class="lineno">18 </code>    <code class="calibre19">name</code><code class="calibre19">:</code> <code class="calibre19">go-demo-3</code>
<code class="lineno">19 </code>    <code class="calibre19">sources</code><code class="calibre19">:</code>
<code class="lineno">20 </code>    <code class="calibre19">-</code> <code class="calibre19">https://github.com/vfarcic/go-demo-3</code>
<code class="lineno">21 </code>    <code class="calibre19">urls</code><code class="calibre19">:</code>
<code class="lineno">22 </code>    <code class="calibre19">-</code> <code class="calibre19">charts/go-demo-3-0.0.1.tgz</code>
<code class="lineno">23 </code>    <code class="calibre19">version</code><code class="calibre19">:</code> <code class="calibre19">0.0.1</code>
<code class="lineno">24 </code><code class="calibre19">generated</code><code class="calibre19">:</code> <code class="s">"2018-07-17T21:56:28Z"</code>
</pre></div>

</figure>

<p class="calibre3">Now that we confirmed that both the images and the Chart are being pushed to their registries, we can move onto the last stage of the pipeline.</p>

<h3 id="leanpub-auto-defining-the-deploy-stage" class="calibre20">Defining The Deploy Stage</h3>

<p class="calibre3">We’re almost finished with the pipeline, at least in its current form.</p>

<p class="calibre3">The purpose of the <em class="calibre17">deploy stage</em> is to install the new release to production and to do the last round of tests that only verify whether the new release integrates with the rest of the system. Those tests are often elementary since they do not validate the release on the functional level. We already know that the features work as expected and immutability of the containers guarantee that what was deployed as a test release is the same as what will be upgraded to production. What we’re not yet sure is whether there is a problem related to the configuration of the production environment or, in our case, production Namespace.</p>

<p class="calibre3">If something goes wrong, we need to be able to act swiftly and roll back the release. I’ll skip the discussion about the inability to roll back when changing database schemas and a few other cases. Instead, for the sake of simplicity, I’ll assume that we’ll roll back always if any of the steps in this stage fail.</p>


<figure class="image1">
  <img src="../images/00037.jpeg" alt="Figure 7-10: The essential steps of the deploy stage" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-10: The essential steps of the deploy stage</figcaption>
</figure>


<p class="calibre3">Let’s go back to <em class="calibre17">go-demo-3</em> configuration screen and update the pipeline.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"http://</code><code class="nv">$JENKINS_ADDR</code><code class="s">/job/go-demo-3/configure"</code>
</pre></div>

</figure>

<p class="calibre3">If you are <strong class="calibre18">NOT using minishift</strong>, please replace the existing code with the content of the <a href="https://gist.github.com/3657e7262b65749f29ddd618cf511d72">cdp-jenkins-deploy.groovy Gist</a>.</p>

<p class="calibre3">If you are <strong class="calibre18">using minishift</strong>, please replace the existing code with the content of the <a href="https://gist.github.com/1a490bff0c90b021e3390a66dd75284e">cdp-jenkins-deploy-oc.groovy Gist</a>.</p>

<p class="calibre3">The additions to the pipeline are as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno"> 1 </code><code class="o">...</code>
<code class="lineno"> 2 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">PROD_ADDRESS</code> <code class="o">=</code> <code class="s">"go-demo-3.acme.com"</code>
<code class="lineno"> 3 </code><code class="o">...</code>
<code class="lineno"> 4 </code>    <code class="calibre19">stage</code><code class="o">(</code><code class="s">"deploy"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno"> 5 </code>      <code class="k">try</code> <code class="o">{</code>
<code class="lineno"> 6 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno"> 7 </code>          <code class="calibre19">sh</code> <code class="s">"""helm upgrade \</code>
<code class="lineno"> 8 </code><code class="s">            go-demo-3 \</code>
<code class="lineno"> 9 </code><code class="s">            helm/go-demo-3 -i \</code>
<code class="lineno">10 </code><code class="s">            --tiller-namespace go-demo-3-build \</code>
<code class="lineno">11 </code><code class="s">            --namespace go-demo-3 \</code>
<code class="lineno">12 </code><code class="s">            --set image.tag=${env.TAG} \</code>
<code class="lineno">13 </code><code class="s">            --set ingress.host=${env.PROD_ADDRESS}</code>
<code class="lineno">14 </code><code class="s">            --reuse-values"""</code>
<code class="lineno">15 </code>        <code class="o">}</code>
<code class="lineno">16 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"kubectl"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">17 </code>          <code class="calibre19">sh</code> <code class="s">"""kubectl -n go-demo-3 \</code>
<code class="lineno">18 </code><code class="s">            rollout status deployment \</code>
<code class="lineno">19 </code><code class="s">            go-demo-3"""</code>
<code class="lineno">20 </code>        <code class="o">}</code>
<code class="lineno">21 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"golang"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">22 </code>          <code class="calibre19">sh</code> <code class="s">"go get -d -v -t"</code>
<code class="lineno">23 </code>          <code class="calibre19">sh</code> <code class="s">"""DURATION=1 ADDRESS=${env.PROD_ADDRESS} \</code>
<code class="lineno">24 </code><code class="s">            go test ./... -v \</code>
<code class="lineno">25 </code><code class="s">            --run ProductionTest"""</code>
<code class="lineno">26 </code>        <code class="o">}</code>
<code class="lineno">27 </code>      <code class="o">}</code> <code class="k">catch</code><code class="o">(</code><code class="calibre19">e</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">28 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">29 </code>          <code class="calibre19">sh</code> <code class="s">"""helm rollback \</code>
<code class="lineno">30 </code><code class="s">            go-demo-3 0 \</code>
<code class="lineno">31 </code><code class="s">            --tiller-namespace go-demo-3-build"""</code>
<code class="lineno">32 </code>          <code class="calibre19">error</code> <code class="s">"Failed production tests"</code>
<code class="lineno">33 </code>        <code class="o">}</code>
<code class="lineno">34 </code>      <code class="o">}</code>
<code class="lineno">35 </code>    <code class="o">}</code>
<code class="lineno">36 </code>  <code class="o">}</code>
<code class="lineno">37 </code><code class="o">}</code>
</pre></div>

</figure>

<p class="calibre3">We added yet another environment variable (<code class="calibre19">PROD_ADDRESS</code>) that holds the address through which our production releases are accessible. We’ll use it both for defining Ingress host as well as for the final round of testing.</p>

<p class="calibre3">Inside the stage, we’re upgrading the production release with the <code class="calibre19">helm upgrade</code> command. The critical value is <code class="calibre19">image.tag</code> that specifies the image tag that should be used.</p>

<aside class="warning">
    <h3 id="leanpub-auto-a-note-to-minishift-users-29" class="calibre22">A note to minishift users</h3>

  <p class="calibre3">Just as in the <code class="calibre19">func-test</code> stage, we had to add yet another Edge Route to the <code class="calibre19">deploy</code> stage so that we can gain the same functionality as what Ingress controller provides to other Kubernetes flavors.</p>

</aside>

<p class="calibre3">Before we proceed with testing, we’re waiting until the update rolls out. If there is something obviously wrong with the upgrade (e.g., the tag does not exist, or there are no available resources), the <code class="calibre19">rollout status</code> command will fail.</p>

<p class="calibre3">Finally, we’re executing the last round of tests. In our case, the tests will run in a loop for one minute.</p>

<p class="calibre3">All the steps in this stage are inside a big <code class="calibre19">try</code> block, so a failure of any of the steps will be handled with the <code class="calibre19">catch</code> block. Inside it is a simple <code class="calibre19">helm rollback</code> command set to revision <code class="calibre19">0</code> which will result in a rollback to the previous release.</p>

<p class="calibre3">Just as in the other stages, we’re jumping from one container to another depending on the tool we need at any given moment.</p>

<p class="calibre3">Before we move on, please make the necessary changes to the values of the environment variables. Just as before, you likely need to change <code class="calibre19">vfarcic</code> to your Docker Hub and GitHub users as well as <code class="calibre19">acme.com</code> to the value of the environment variable <code class="calibre19">ADDR</code> available in your terminal session.</p>

<p class="calibre3">Please click the <em class="calibre17">Save</em> button once you’re finished with the changes that aim at making the pipeline work in your environment. The rest of the steps are the same as those we performed countless times before. Click the <em class="calibre17">Open Blue Ocean</em> link from the left-hand menu, press the <em class="calibre17">Run</em> button, and click on the row of the new build. Wait until the build is finished.</p>


<figure class="image">
  <img src="../images/00038.jpeg" alt="Figure 7-11: Jenkins build with all the continuous deployment stages" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-11: Jenkins build with all the continuous deployment stages</figcaption>
</figure>


<p class="calibre3">Since this is the first time we’re running the <em class="calibre17">deploy stage</em>, we’ll double-check that the production release was indeed deployed correctly.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>helm ls <code class="se">\</code>
<code class="lineno">2 </code>    --tiller-namespace go-demo-3-build
</pre></div>

</figure>

<p class="calibre3">The output is as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>NAME      REVISION UPDATED        STATUS   CHART           NAMESPACE
<code class="lineno">2 </code>go-demo-3 1        Wed Jul 18 ... DEPLOYED go-demo-3-0.0.1 go-demo-3
</pre></div>

</figure>

<p class="calibre3">This is the first time we upgraded <code class="calibre19">go-demo-3</code> production release, so the revision is <code class="calibre19">1</code>.</p>

<p class="calibre3">How about Pods? Are they running as expected inside the <code class="calibre19">go-demo-3</code> Namespace dedicated to production releases of that team?</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>kubectl -n go-demo-3 get pods
</pre></div>

</figure>

<p class="calibre3">The output is as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>NAME           READY STATUS  RESTARTS AGE
<code class="lineno">2 </code>go-demo-3-...  1/1   Running 2        6m
<code class="lineno">3 </code>go-demo-3-...  1/1   Running 2        6m
<code class="lineno">4 </code>go-demo-3-...  1/1   Running 2        6m
<code class="lineno">5 </code>go-demo-3-db-0 2/2   Running 0        6m
<code class="lineno">6 </code>go-demo-3-db-1 2/2   Running 0        6m
<code class="lineno">7 </code>go-demo-3-db-2 2/2   Running 0        5m
</pre></div>

</figure>

<p class="calibre3">All the Pods are indeed running. We have three replicas of the API and three replicas of the database.</p>

<p class="calibre3">Finally, we’ll send a request to the newly deployed release and confirm that we are getting the correct response.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>curl <code class="s">"http://go-demo-3.</code><code class="nv">$ADDR</code><code class="s">/demo/hello"</code>
</pre></div>

</figure>

<p class="calibre3">The output should be the familiar <code class="calibre19">hello, world!</code> message.</p>

<h3 id="leanpub-auto-what-are-we-missing-in-our-pipeline" class="calibre20">What Are We Missing In Our Pipeline?</h3>

<p class="calibre3">We already discussed some the steps that we might be missing. We might want to store test results in SonarQube. We might want to generate release notes and store them in GitHub. We might need to run performance tests. There are many things we could have done, but we didn’t. Those additional steps will differ significantly from one organization to another. Even within a company, one team might have different steps than the other. Guessing which ones you might need would be an exercise in futility. I would have almost certainly guessed wrong.</p>

<p class="calibre3">One step that almost everyone needs is notification of failure. We need to be notified when something goes wrong and fix the issue. However, there are too many destinations where those notifications might need to be sent. Some prefer email, while others opt for chats. In the latter case, it could be Slack, HipChat, Skype, and many others. We might even choose to create a JIRA issue when one of the steps in the pipeline fails. Since even a simple notification can be performed in so many different ways, I’ll skip adding them to the pipeline. I’m sure that you won’t have a problem looking for a plugin you need (e.g., <a href="https://plugins.jenkins.io/slack">Slack Notification</a>) and injecting notifications into the stages. We already have a few <code class="calibre19">try</code> statements, and notifications can be inserted into <code class="calibre19">catch</code> blocks. You might need to add a few additional <code class="calibre19">try</code>/<code class="calibre19">catch</code> blocks or a big one that envelops the whole pipeline. I believe in you by being confident that you’ll know how to do that. So, we’ll move to the next subject.</p>

<h3 id="leanpub-auto-reusing-pipeline-snippets-through-global-pipeline-libraries" class="calibre20">Reusing Pipeline Snippets Through Global Pipeline Libraries</h3>

<p class="calibre3">The pipeline we designed works as we expect. However, we’ll have a problem on our hands if other teams start copying and pasting the same script for their pipelines. We’d end up with a lot of duplicated code that will be hard to maintain.</p>

<p class="calibre3">Most likely it will get worse than the simple practice of duplicating code since not all pipelines will be the same. There’s a big chance each is going to be different, so copy and paste practice will only be the first action. People will find the pipeline that is closest to what they’re trying to accomplish, replicate it, and then change it to suit their needs. Some steps are likely going to be the same for many (if not all) projects, while others will be specific to only one, or just a few pipelines.</p>

<p class="calibre3">The more pipelines we design, the more patterns will emerge. Everyone might want to build Docker images with the same command, but with different arguments. Others might use Helm to install their applications, but will not (yet) have any tests to run (be nice, do not judge them). Someone might choose to use <a href="https://www.rust-lang.org/">Rust</a> for the new project, and the commands will be unique only to a single pipeline.</p>

<p class="calibre3">What we need to do is look for patterns. When we notice that a step, or a set of steps, are the same across multiple pipelines, we should be able to convert that snippet into a library, just as what we’re likely doing when repetition happens in code of our applications. Those libraries need to be accessible to all those who need it, and they need to be flexible so that their behavior can be adjusted to slightly different needs. We should be able to provide arguments to those libraries.</p>

<p class="calibre3">What we truly need is the ability to create new pipeline steps that are tailored to our needs. Just as there is a general step <code class="calibre19">git</code>, we might want something like <code class="calibre19">k8sUpgrade</code> that will perform Helm’s <code class="calibre19">upgrade</code> command. We can accomplish that, and quite a few other things through Jenkins` <em class="calibre17">Global Pipeline Libraries</em>.</p>

<p class="calibre3">We’ll explore libraries through practical examples, so the firsts step is to configure them.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"http://</code><code class="nv">$JENKINS_ADDR</code><code class="s">/configure"</code>
</pre></div>

</figure>

<p class="calibre3">Please search for <em class="calibre17">Global Pipeline Libraries</em> section of the configuration, and click the <em class="calibre17">Add</em> button.</p>

<p class="calibre3">Type <em class="calibre17">my-library</em> as the <em class="calibre17">Name</em> (it can be anything else) and <em class="calibre17">master</em> as the <em class="calibre17">Default version</em>. In our context, the latter defines the branch from which we’ll load the libraries.</p>

<p class="calibre3">Next, we’ll click the <em class="calibre17">Load implicitly</em> checkbox. As a result, the libraries will be available automatically to all the pipeline jobs. Otherwise, our jobs would need to have <code class="calibre19">@Library('my-library')</code> instruction.</p>

<p class="calibre3">Select <em class="calibre17">Modern SCM</em> from the <em class="calibre17">Retrieval method</em> section and select <em class="calibre17">Git</em> from <em class="calibre17">Source Code Management</em>.</p>

<p class="calibre3">We’re almost done. The only thing left is to specify the repository from which Jenkins will load the libraries. I already created a repo with all the libraries we’ll use (and a few others we won’t need). However, GitHub API has a limit to the number of requests that can be made per hour so if you (and everyone else) uses my repo, you might see some undesirable effects. My recommendation is to go to <a href="https://github.com/vfarcic/jenkins-shared-libraries.git">vfarcic/jenkins-shared-libraries.git</a> and fork it. Once the fork is created, copy the address from the <em class="calibre17">Clone and download</em> drop-down list, return to Jenkins UI, and paste it into the <em class="calibre17">Project Repository</em> field.</p>

<p class="calibre3">We’re finished with the configuration. Don’t forget to click the <em class="calibre17">Save</em> button to persist the changes.</p>


<figure class="image1">
  <img src="../images/00039.jpeg" alt="Figure 7-12: Jenkins Global Pipeline Libraries configuration screen" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-12: Jenkins Global Pipeline Libraries configuration screen</figcaption>
</figure>


<p class="calibre3">Let’s take a closer look at the repository we’ll use as the <em class="calibre17">global pipeline library</em>.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code><code class="nb">export</code> <code class="nv">GH_USER</code><code class="o">=[</code>...<code class="o">]</code>
<code class="lineno">2 </code>
<code class="lineno">3 </code>open <code class="s">"https://github.com/</code><code class="nv">$GH_USER</code><code class="s">/jenkins-shared-libraries.git"</code>
</pre></div>

</figure>

<p class="calibre3">Please replace <code class="calibre19">[...]</code> with your GitHub user before opening the forked repository in a browser.</p>

<p class="calibre3">You’ll see that the repository has only <code class="calibre19">.gitignore</code> file and the <code class="calibre19">vars</code> dir in the root. Jenkins’ <em class="calibre17">Global Pipeline Libraries</em> use a naming convention to discover the functions we’d like to use. They can be either in <code class="calibre19">src</code> or <code class="calibre19">vars</code> folder. The former is rarely used these days, so we’re having only the latter.</p>

<p class="calibre3">If you enter into the <code class="calibre19">vars</code> directory, you’ll see that there are quite a few <code class="calibre19">*.groovy</code> files mixed with a few <code class="calibre19">*.txt</code> files. We’ll postpone exploration of the latter group of files and concentrate on the Groovy files instead. We’ll use those with names that start with <code class="calibre19">k8s</code> and <code class="calibre19">oc</code> (in case you’re using OpenShift).</p>

<p class="calibre3">Please find the <em class="calibre17">k8sBuildImageBeta.groovy</em> file and open it. You’ll notice that the code inside it is almost the same as the one we used in the <em class="calibre17">build stage</em>. There are a few differences though, so let’s go through the structure of the shared functions. It’ll be a concise explanation.</p>

<p class="calibre3">The name of the file (e.g., <em class="calibre17">k8sBuildImageBeta.groovy</em>) becomes a pipeline step (e.g., <code class="calibre19">k8sBuildImageBeta</code>). If we use a step converted from a file, Jenkins will invoke the function <code class="calibre19">call</code>. So, every Groovy file needs to have such a function, even though additional internal functions can be defined as well. The <code class="calibre19">call</code> function can have any number of arguments. If we continue using the same example, you’ll see that <code class="calibre19">call</code> inside <em class="calibre17">k8sBuildImageBeta.groovy</em> has a single argument <code class="calibre19">image</code>. It could have been defined with the explicit type like <code class="calibre19">String image</code>, but in most cases, there’s no need for it. Groovy will figure out the type.</p>

<p class="calibre3">Inside the <code class="calibre19">call</code> function are almost the same steps as those we used inside the <em class="calibre17">build stage</em>. I copied and pasted them. The only modification to the steps was to replace Docker image references with the <code class="calibre19">image</code> argument. Since we already know that Groovy extrapolates arguments in a string when they are prefixed with the dollar sign (<code class="calibre19">$</code>) and optional curly braces (<code class="calibre19">{</code> and <code class="calibre19">}</code>), our <code class="calibre19">image</code> argument became <code class="calibre19">${image}</code>.</p>

<p class="calibre3">Using arguments in the functions is essential. They make them reusable across different pipelines. If <em class="calibre17">k8sBuildImageBeta.groovy</em> would have <code class="calibre19">go-demo-3</code> image hard-coded, that would not be useful to anyone except those trying to build the <em class="calibre17">go-demo</em> application. The alternative would be to use environment variables and ditch arguments altogether. I’ve seen that pattern in many organizations, and I think it’s horrible. It does not make it clear what is needed to use the function. There are a few exceptions though. My usage of environment variables is limited to those available to all builds. For example, <code class="calibre19">${env.BRANCH_NAME}</code> is always available. One does not need to create it when writing a pipeline script. For everything else, please use arguments. That will be a clear indication to the users of those functions what is required.</p>

<p class="calibre3">I won’t go through all the Groovy files that start with <code class="calibre19">k8s</code> (and <code class="calibre19">oc</code>) since they follow the same logic as <em class="calibre17">k8sBuildImageBeta.groovy</em>. They are copies of what we used in our pipeline, with the addition of a few arguments. So, instead of me going over all the functions, please take some time to explore them yourself. Return here once you’re done, and we’ll put those functions to good use and clarify a few other important aspects of Jenkins’ shared libraries.</p>

<p class="calibre3">Before we continue, you might want to persist the changes we did to Jenkins configuration. All the information about the shared libraries is available in <em class="calibre17">org.jenkinsci.plugins.workflow.libs.GlobalLibraries.xml</em> file. We just need to copy it.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>kubectl -n go-demo-3-jenkins cp <code class="se">\</code>
<code class="lineno">2 </code>    <code class="nv">$JENKINS_POD</code>:var/jenkins_home/org.jenkinsci.plugins.workflow.libs.GlobalLibrarie<code class="se">\</code>
<code class="lineno">3 </code>s.xml <code class="se">\</code>
<code class="lineno">4 </code>    cluster/jenkins/secrets
</pre></div>

</figure>

<p class="calibre3">I already modified the template of the Jenkins Helm Chart to include the file we just copied. All you have to do the next time you install Jenkins with Helm is to add <code class="calibre19">jenkins.Master.GlobalLibraries</code> value. The full argument should be as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>--set jenkins.Master.GlobalLibraries=true
</pre></div>

</figure>

<p class="calibre3">Now we can refactor our pipeline to use shared libraries and see whether that simplifies things.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"http://</code><code class="nv">$JENKINS_ADDR</code><code class="s">/job/go-demo-3/configure"</code>
</pre></div>

</figure>

<p class="calibre3">If you are <strong class="calibre18">NOT using minishift</strong>, please replace the existing code with the content of the <a href="https://gist.github.com/e9821d0430ca909d68eecc7ccbb1825d">cdp-jenkins-lib.groovy Gist</a>.</p>

<p class="calibre3">If you are <strong class="calibre18">using minishift</strong>, please replace the existing code with the content of the <a href="https://gist.github.com/ff6e0b04f165d2b26d326c116a7cc14f">cdp-jenkins-lib-oc.groovy Gist</a>.</p>

<p class="calibre3">We’ll explore only the differences from the previous iteration of the pipeline. They are as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno"> 1 </code><code class="o">...</code>
<code class="lineno"> 2 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">PROJECT</code> <code class="o">=</code> <code class="s">"go-demo-3"</code>
<code class="lineno"> 3 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">REPO</code> <code class="o">=</code> <code class="s">"https://github.com/vfarcic/go-demo-3.git"</code>
<code class="lineno"> 4 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">IMAGE</code> <code class="o">=</code> <code class="s">"vfarcic/go-demo-3"</code>
<code class="lineno"> 5 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">DOMAIN</code> <code class="o">=</code> <code class="s">"acme.com"</code>
<code class="lineno"> 6 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">ADDRESS</code> <code class="o">=</code> <code class="s">"go-demo-3.acme.com"</code>
<code class="lineno"> 7 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">CM_ADDR</code> <code class="o">=</code> <code class="s">"cm.acme.com"</code>
<code class="lineno"> 8 </code><code class="calibre19">env</code><code class="o">.</code><code class="na">CHART_VER</code> <code class="o">=</code> <code class="s">"0.0.1"</code>
<code class="lineno"> 9 </code><code class="o">...</code>
<code class="lineno">10 </code>  <code class="calibre19">node</code><code class="o">(</code><code class="s">"kubernetes"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">11 </code>    <code class="calibre19">node</code><code class="o">(</code><code class="s">"docker"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">12 </code>      <code class="calibre19">stage</code><code class="o">(</code><code class="s">"build"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">13 </code>        <code class="calibre19">git</code> <code class="s">"${env.REPO}"</code>
<code class="lineno">14 </code>        <code class="calibre19">k8sBuildImageBeta</code><code class="o">(</code><code class="calibre19">env</code><code class="o">.</code><code class="na">IMAGE</code><code class="o">)</code>
<code class="lineno">15 </code>      <code class="o">}</code>
<code class="lineno">16 </code>    <code class="o">}</code>
<code class="lineno">17 </code>    <code class="calibre19">stage</code><code class="o">(</code><code class="s">"func-test"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">18 </code>      <code class="k">try</code> <code class="o">{</code>
<code class="lineno">19 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">20 </code>          <code class="calibre19">git</code> <code class="s">"${env.REPO}"</code>
<code class="lineno">21 </code>          <code class="calibre19">k8sUpgradeBeta</code><code class="o">(</code><code class="calibre19">env</code><code class="o">.</code><code class="na">PROJECT</code><code class="o">,</code> <code class="calibre19">env</code><code class="o">.</code><code class="na">DOMAIN</code><code class="o">,</code> <code class="s">"--set replicaCount=2 --set dbRepl\</code>
<code class="lineno">22 </code><code class="s">icaCount=1"</code><code class="o">)</code>
<code class="lineno">23 </code>        <code class="o">}</code>
<code class="lineno">24 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"kubectl"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">25 </code>          <code class="calibre19">k8sRolloutBeta</code><code class="o">(</code><code class="calibre19">env</code><code class="o">.</code><code class="na">PROJECT</code><code class="o">)</code>
<code class="lineno">26 </code>        <code class="o">}</code>
<code class="lineno">27 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"golang"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">28 </code>          <code class="calibre19">k8sFuncTestGolang</code><code class="o">(</code><code class="calibre19">env</code><code class="o">.</code><code class="na">PROJECT</code><code class="o">,</code> <code class="calibre19">env</code><code class="o">.</code><code class="na">DOMAIN</code><code class="o">)</code>
<code class="lineno">29 </code>        <code class="o">}</code>
<code class="lineno">30 </code>      <code class="o">}</code> <code class="k">catch</code><code class="o">(</code><code class="calibre19">e</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">31 </code>          <code class="calibre19">error</code> <code class="s">"Failed functional tests"</code>
<code class="lineno">32 </code>      <code class="o">}</code> <code class="k">finally</code> <code class="o">{</code>
<code class="lineno">33 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">34 </code>          <code class="calibre19">k8sDeleteBeta</code><code class="o">(</code><code class="calibre19">env</code><code class="o">.</code><code class="na">PROJECT</code><code class="o">)</code>
<code class="lineno">35 </code>        <code class="o">}</code>
<code class="lineno">36 </code>      <code class="o">}</code>
<code class="lineno">37 </code>    <code class="o">}</code>
<code class="lineno">38 </code>    <code class="calibre19">stage</code><code class="o">(</code><code class="s">"release"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">39 </code>      <code class="calibre19">node</code><code class="o">(</code><code class="s">"docker"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">40 </code>        <code class="calibre19">k8sPushImage</code><code class="o">(</code><code class="calibre19">env</code><code class="o">.</code><code class="na">IMAGE</code><code class="o">)</code>
<code class="lineno">41 </code>      <code class="o">}</code>
<code class="lineno">42 </code>      <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">43 </code>        <code class="calibre19">k8sPushHelm</code><code class="o">(</code><code class="calibre19">env</code><code class="o">.</code><code class="na">PROJECT</code><code class="o">,</code> <code class="calibre19">env</code><code class="o">.</code><code class="na">CHART_VER</code><code class="o">,</code> <code class="calibre19">env</code><code class="o">.</code><code class="na">CM_ADDR</code><code class="o">)</code>
<code class="lineno">44 </code>      <code class="o">}</code>
<code class="lineno">45 </code>    <code class="o">}</code>
<code class="lineno">46 </code>    <code class="calibre19">stage</code><code class="o">(</code><code class="s">"deploy"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">47 </code>      <code class="k">try</code> <code class="o">{</code>
<code class="lineno">48 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">49 </code>          <code class="calibre19">k8sUpgrade</code><code class="o">(</code><code class="calibre19">env</code><code class="o">.</code><code class="na">PROJECT</code><code class="o">,</code> <code class="calibre19">env</code><code class="o">.</code><code class="na">ADDRESS</code><code class="o">)</code>
<code class="lineno">50 </code>        <code class="o">}</code>
<code class="lineno">51 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"kubectl"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">52 </code>          <code class="calibre19">k8sRollout</code><code class="o">(</code><code class="calibre19">env</code><code class="o">.</code><code class="na">PROJECT</code><code class="o">)</code>
<code class="lineno">53 </code>        <code class="o">}</code>
<code class="lineno">54 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"golang"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">55 </code>          <code class="calibre19">k8sProdTestGolang</code><code class="o">(</code><code class="calibre19">env</code><code class="o">.</code><code class="na">ADDRESS</code><code class="o">)</code>
<code class="lineno">56 </code>        <code class="o">}</code>
<code class="lineno">57 </code>      <code class="o">}</code> <code class="k">catch</code><code class="o">(</code><code class="calibre19">e</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">58 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">59 </code>          <code class="calibre19">k8sRollback</code><code class="o">(</code><code class="calibre19">env</code><code class="o">.</code><code class="na">PROJECT</code><code class="o">)</code>
<code class="lineno">60 </code>        <code class="o">}</code>
<code class="lineno">61 </code>      <code class="o">}</code>
<code class="lineno">62 </code>    <code class="o">}</code>
<code class="lineno">63 </code>  <code class="o">}</code>
<code class="lineno">64 </code><code class="o">}</code>
</pre></div>

</figure>

<p class="calibre3">We have fewer environment variables since part of the logic for constructing the values is moved into the functions. The <code class="calibre19">podTemplate</code> is still the same, and the real differences are noticeable inside stages.</p>

<p class="calibre3">All the stages now contain fewer steps. Everything is much simpler since the logic, steps, and the commands are moved to functions. All we’re doing is treat those functions as simplified steps.</p>

<p class="calibre3">You might say that even though the pipeline is now much more straightforward, it is still not trivial. You’d be right. We could have replaced them with bigger and fewer functions. We could have had only four like <code class="calibre19">build</code>, <code class="calibre19">test</code>, <code class="calibre19">release</code>, and <code class="calibre19">deploy</code>. However, that would reduce flexibility. Every team in our organization would need to build, test, release, and deploy in the same way, or skip using the library and do the coding inside the pipeline. If the functions are too big, people must choose to adopt the whole process or not use them at all. By having a very focused function that does only one, or just a few things, we gain more flexibility when combining them.</p>

<p class="calibre3">Good examples are the functions used in the <code class="calibre19">deploy</code> stage. If there were only one (e.g., <code class="calibre19">k8sDeploy</code>), everyone would need to use Go to test. As it is now, a different team could choose to use <code class="calibre19">k8sUpgrade</code> and <code class="calibre19">k8sRollout</code> functions, but skip <code class="calibre19">k8sProdTestGolang</code>. Maybe their application is coded in <a href="https://www.rust-lang.org/">Rust</a>, and they will need a separate function. Or, there might be only one project that uses Rust, and there’s no need for a function since there is no repetition. The point is that teams should be able to choose to re-use libraries that fit their process, and write themselves whatever they’re missing.</p>

<aside class="information">
    <p class="calibre3">From my experience, functions from Jenkins’ global pipeline libraries should be small and with a single purpose. That way, we can combine them as if they are pieces of a puzzle, instead of continually adding complexity by trying to fit all the scenarios into one or a few libraries.</p>

</aside>

<p class="calibre3">Another thing worth mentioning is that <code class="calibre19">node</code> and <code class="calibre19">container</code> blocks are not inside libraries. There are two reasons for that. First, I think it is easier to understand the flow of the pipeline (without going into libraries) when those blocks are there. The second and the much more important reason is that they are not allowed in a declarative pipeline. We are using scripted flavor only because a few things are missing in declarative. However, the declarative pipeline is the future, and you should be prepared to switch once those issues are resolved. I will refactor the code into declarative once that becomes an option.</p>

<p class="calibre3">Before we move forward, please replace the values of the environment variables to fit your situation. As a reminder, you most likely need to change <code class="calibre19">vfarcic</code> with your GitHub and Docker Hub users, and <code class="calibre19">acme.com</code> with the value of the environment variable <code class="calibre19">ADDR</code> available in your terminal session.</p>

<p class="calibre3">Once you’re finished adjusting the values, please click the <em class="calibre17">Save</em> button to persist the changes. Click the <em class="calibre17">Open Blue Ocean</em> link from the left-hand menu, followed with the <em class="calibre17">Run</em> button. Go to the new build and wait until it is finished.</p>

<p class="calibre3">We refactored the pipeline by making it more readable and easier to maintain. We did not introduce new functionalities, so the result of this build should be functionally the same as the previous that was done with the prior iteration of the code. Let’s confirm that.</p>

<p class="calibre3">Did we push a new image to Docker Hub?</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"https://hub.docker.com/r/</code><code class="nv">$DH_USER</code><code class="s">/go-demo-3/tags/"</code>
</pre></div>

</figure>

<p class="calibre3">The new image (with a few tags) was pushed.</p>

<p class="calibre3">How about Helm upgrades?</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>helm ls <code class="se">\</code>
<code class="lineno">2 </code>    --tiller-namespace go-demo-3-build
</pre></div>

</figure>

<p class="calibre3">The output is as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>NAME      REVISION UPDATED        STATUS   CHART           NAMESPACE
<code class="lineno">2 </code>go-demo-3 2        Wed Jul 18 ... DEPLOYED go-demo-3-0.0.1 go-demo-3
</pre></div>

</figure>

<p class="calibre3">We are now on the second revision, so that part seems to be working as expected. To be on the safe side, we’ll check the history.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>helm <code class="nb">history</code> go-demo-3 <code class="se">\</code>
<code class="lineno">2 </code>    --tiller-namespace go-demo-3-build
</pre></div>

</figure>

<p class="calibre3">The output is as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>REVISION UPDATED        STATUS     CHART           DESCRIPTION
<code class="lineno">2 </code>1        Wed Jul 18 ... SUPERSEDED go-demo-3-0.0.1 Install complete
<code class="lineno">3 </code>2        Wed Jul 18 ... DEPLOYED   go-demo-3-0.0.1 Upgrade complete
</pre></div>

</figure>

<p class="calibre3">The first revision was superseded by the second.</p>

<p class="calibre3">Our mission has been accomplished, but our pipeline is still not as it’s supposed to be.</p>

<h3 id="leanpub-auto-consulting-global-pipeline-libraries-documentation" class="calibre20">Consulting Global Pipeline Libraries Documentation</h3>

<p class="calibre3">We already saw that we can open a repository with global pipeline libraries and consult the functions to find out what they do. While the developer in me prefers that option, many might find it too complicated and might prefer something more “non-developer friendly”. Fortunately, there is an alternative way to document and consult libraries.</p>

<p class="calibre3">Let’s go back to the forked repository with the libraries.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"https://github.com/</code><code class="nv">$GH_USER</code><code class="s">/jenkins-shared-libraries/tree/master/vars"</code>
</pre></div>

</figure>

<p class="calibre3">If you pay closer attention, you’ll notice that all Groovy files with names that start with <code class="calibre19">k8s</code> have an accompanying <code class="calibre19">txt</code> file. Let’s take a closer look at one of them.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>curl <code class="s">"https://raw.githubusercontent.com/</code><code class="nv">$GH_USER</code><code class="s">/jenkins-shared-libraries/master/var\</code>
<code class="lineno">2 </code><code class="s">s/k8sBuildImageBeta.txt"</code>
</pre></div>

</figure>

<p class="calibre3">The output is as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno"> 1 </code>## Builds a Docker image with a beta release
<code class="lineno"> 2 </code>
<code class="lineno"> 3 </code>The image is tagged with the **build display name** suffixed with the **branch name**
<code class="lineno"> 4 </code>
<code class="lineno"> 5 </code>**Arguments:**
<code class="lineno"> 6 </code>
<code class="lineno"> 7 </code>* **image**: the name of the Docker image (e.g. `vfarcic/go-demo-3`).
<code class="lineno"> 8 </code>
<code class="lineno"> 9 </code>**Requirements:**
<code class="lineno">10 </code>
<code class="lineno">11 </code>* A node with Docker
<code class="lineno">12 </code>* Docker Hub credentials with the ID **docker**
</pre></div>

</figure>

<p class="calibre3">Do not get confused with <code class="calibre19">txt</code> extension. Documentation can be written not only in plain text but also as HTML or Markdown. As you can see, I chose the latter. It is entirely up to you how you’ll write corresponding documentation of a function. There is no prescribed formula. The only thing that matters is that the name of the <code class="calibre19">txt</code> file is the same as the name of the <code class="calibre19">groovy</code> function. The only difference is in the extension.</p>

<p class="calibre3">But, how do we visualize those helper files, besides visiting the repository where they reside? Before I answer that question, we’ll make a slight change to Jenkins’ security configuration.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"http://</code><code class="nv">$JENKINS_ADDR</code><code class="s">/configureSecurity/"</code>
</pre></div>

</figure>

<p class="calibre3">Please scroll down to the <em class="calibre17">Markup Formatter</em> section and change the value to <em class="calibre17">PegDown</em>. Click the <em class="calibre17">Apply</em> button to persist the change. From now on, Jenkins will format everything using the Markdown parser. Since our helper files are also written in Markdown, we should be able to visualize them correctly.</p>

<p class="calibre3">Let’s find the documentation of the libraries.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"http://</code><code class="nv">$JENKINS_ADDR</code><code class="s">/job/go-demo-3/"</code>
</pre></div>

</figure>

<p class="calibre3">We are in the old view of the job we created short while ago. If you look at the left-hand menu, you’ll see the link <em class="calibre17">Pipeline Syntax</em>. Click it.</p>

<p class="calibre3">The screen we’re looking at contains quite a few useful links. There’s <em class="calibre17">Snippet Generator</em> that we can use to generate code for each of the available steps. <em class="calibre17">Declarative Directive Generator</em> generates the code specific to Declarative Pipeline syntax that we’re not (yet) using. I’ll let you explore those and the other links at your own leisure. The one we’re interested right now is the <em class="calibre17">Global Variables Reference</em> link. Please click it.</p>

<p class="calibre3">Inside the <em class="calibre17">Global Variable Reference</em> screen are all the variables and functions we can use. We’re interested in those with names starting with <em class="calibre17">k8s</em>. Please scroll down until you find them. You’ll see that <em class="calibre17">.txt</em> files are nicely formatted and available to anyone interested how to use our functions.</p>


<figure class="image1">
  <img src="../images/00040.jpeg" alt="Figure 7-13: Global Pipeline Libraries documentation" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-13: Global Pipeline Libraries documentation</figcaption>
</figure>


<h3 id="leanpub-auto-using-jenkinsfile--multistage-builds" class="calibre20">Using Jenkinsfile &amp; Multistage Builds</h3>

<p class="calibre3">The pipeline we designed has at least two significant shortcomings. It is not aware of branches, and it is not in source control.</p>

<p class="calibre3">Every time we instructed Jenkins to use the <code class="calibre19">git</code> step, it pulled the latest commit from the <code class="calibre19">master</code> branch. While that might be OK for demos, it is unacceptable in real-world situations. Our pipeline must pull the commit that initiated a build from the correct branch. In other words, no matter where we push a commit, that same commit must be used by the pipeline.</p>

<p class="calibre3">If we start processing all commits, no matter from which branch they’re coming, we will soon realize that it does not make sense always to execute the same stages. As an example, the <em class="calibre17">release</em> and <em class="calibre17">deploy</em> stages should be executed only if a commit is made to the master branch. Otherwise, we’d create a new production release always, even if the branch is called <em class="calibre17">i-am-bored-so-i-decided-to-experiment</em>. As you can imagine, that is not what we’d like to happen.</p>

<p class="calibre3">Moving onto the second issue with the current pipeline…</p>

<p class="calibre3">I have a mantra that I already repeated quite a few times in this book. Everything we do, no matter whether its code, a configuration, or a properties file, <strong class="calibre18">must</strong> be in version control. I even go as far as to say that if someone finds something on some server that is not stored in version control, that person has full rights to remove that something. <strong class="calibre18">If it’s not in Git, it does not exist.</strong> It’s as simple as that. Everything else can be considered “hocus-pocus, ad-hoc, nobody knows what was done” type of things. CD pipeline is code and, as such, it must be stored in version control. There can be no exceptions.</p>

<p class="calibre3">Fortunately, we can solve those problems through a combination of Jenkinsfiles, Multistage Builds, and a bit of refactoring.</p>

<p class="calibre3">Let’s take a look at <em class="calibre17">Jenkinsfile</em> located in the root of <em class="calibre17">go-demo-3</em> repository.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>cat ../go-demo-3/Jenkinsfile
</pre></div>

</figure>

<p class="calibre3">The output is as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno"> 1 </code><code class="k">import</code> <code class="nn">java.text.SimpleDateFormat</code>
<code class="lineno"> 2 </code>
<code class="lineno"> 3 </code><code class="kt">def</code> <code class="calibre19">props</code>
<code class="lineno"> 4 </code><code class="kt">def</code> <code class="calibre19">label</code> <code class="o">=</code> <code class="s">"jenkins-slave-${UUID.randomUUID().toString()}"</code>
<code class="lineno"> 5 </code><code class="calibre19">currentBuild</code><code class="o">.</code><code class="na">displayName</code> <code class="o">=</code> <code class="k">new</code> <code class="calibre19">SimpleDateFormat</code><code class="o">(</code><code class="s">"yy.MM.dd"</code><code class="o">).</code><code class="na">format</code><code class="o">(</code><code class="k">new</code> <code class="calibre19">Date</code><code class="o">())</code> <code class="o">+</code> <code class="s">"-"</code><code class="err">\</code>
<code class="lineno"> 6 </code> <code class="o">+</code> <code class="calibre19">env</code><code class="o">.</code><code class="na">BUILD_NUMBER</code>
<code class="lineno"> 7 </code>
<code class="lineno"> 8 </code><code class="calibre19">podTemplate</code><code class="o">(</code>
<code class="lineno"> 9 </code>  <code class="nl">label:</code> <code class="calibre19">label</code><code class="o">,</code>
<code class="lineno">10 </code>  <code class="nl">namespace:</code> <code class="s">"go-demo-3-build"</code><code class="o">,</code>
<code class="lineno">11 </code>  <code class="nl">serviceAccount:</code> <code class="s">"build"</code><code class="o">,</code>
<code class="lineno">12 </code>  <code class="nl">yaml:</code> <code class="s">"""</code>
<code class="lineno">13 </code><code class="s">apiVersion: v1</code>
<code class="lineno">14 </code><code class="s">kind: Pod</code>
<code class="lineno">15 </code><code class="s">spec:</code>
<code class="lineno">16 </code><code class="s">  containers:</code>
<code class="lineno">17 </code><code class="s">  - name: helm</code>
<code class="lineno">18 </code><code class="s">    image: vfarcic/helm:2.9.1</code>
<code class="lineno">19 </code><code class="s">    command: ["cat"]</code>
<code class="lineno">20 </code><code class="s">    tty: true</code>
<code class="lineno">21 </code><code class="s">    volumeMounts:</code>
<code class="lineno">22 </code><code class="s">    - name: build-config</code>
<code class="lineno">23 </code><code class="s">      mountPath: /etc/config</code>
<code class="lineno">24 </code><code class="s">  - name: kubectl</code>
<code class="lineno">25 </code><code class="s">    image: vfarcic/kubectl</code>
<code class="lineno">26 </code><code class="s">    command: ["cat"]</code>
<code class="lineno">27 </code><code class="s">    tty: true</code>
<code class="lineno">28 </code><code class="s">  - name: golang</code>
<code class="lineno">29 </code><code class="s">    image: golang:1.9</code>
<code class="lineno">30 </code><code class="s">    command: ["cat"]</code>
<code class="lineno">31 </code><code class="s">    tty: true</code>
<code class="lineno">32 </code><code class="s">  volumes:</code>
<code class="lineno">33 </code><code class="s">  - name: build-config</code>
<code class="lineno">34 </code><code class="s">    configMap:</code>
<code class="lineno">35 </code><code class="s">      name: build-config</code>
<code class="lineno">36 </code><code class="s">"""</code>
<code class="lineno">37 </code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">38 </code>  <code class="calibre19">node</code><code class="o">(</code><code class="calibre19">label</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">39 </code>    <code class="calibre19">stage</code><code class="o">(</code><code class="s">"build"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">40 </code>      <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">41 </code>        <code class="calibre19">sh</code> <code class="s">"cp /etc/config/build-config.properties ."</code>
<code class="lineno">42 </code>        <code class="calibre19">props</code> <code class="o">=</code> <code class="calibre19">readProperties</code> <code class="nl">interpolate:</code> <code class="k">true</code><code class="o">,</code> <code class="nl">file:</code> <code class="s">"build-config.properties"</code>
<code class="lineno">43 </code>      <code class="o">}</code>
<code class="lineno">44 </code>      <code class="calibre19">node</code><code class="o">(</code><code class="s">"docker"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">45 </code>        <code class="calibre19">checkout</code> <code class="calibre19">scm</code>
<code class="lineno">46 </code>        <code class="nf">k8sBuildImageBeta</code><code class="o">(</code><code class="calibre19">props</code><code class="o">.</code><code class="na">image</code><code class="o">)</code>
<code class="lineno">47 </code>      <code class="o">}</code>
<code class="lineno">48 </code>    <code class="o">}</code>
<code class="lineno">49 </code>    <code class="calibre19">stage</code><code class="o">(</code><code class="s">"func-test"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">50 </code>      <code class="k">try</code> <code class="o">{</code>
<code class="lineno">51 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">52 </code>          <code class="calibre19">checkout</code> <code class="calibre19">scm</code>
<code class="lineno">53 </code>          <code class="nf">k8sUpgradeBeta</code><code class="o">(</code><code class="calibre19">props</code><code class="o">.</code><code class="na">project</code><code class="o">,</code> <code class="calibre19">props</code><code class="o">.</code><code class="na">domain</code><code class="o">,</code> <code class="s">"--set replicaCount=2 --set db\</code>
<code class="lineno">54 </code><code class="s">ReplicaCount=1"</code><code class="o">)</code>
<code class="lineno">55 </code>        <code class="o">}</code>
<code class="lineno">56 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"kubectl"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">57 </code>          <code class="calibre19">k8sRolloutBeta</code><code class="o">(</code><code class="calibre19">props</code><code class="o">.</code><code class="na">project</code><code class="o">)</code>
<code class="lineno">58 </code>        <code class="o">}</code>
<code class="lineno">59 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"golang"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">60 </code>          <code class="calibre19">k8sFuncTestGolang</code><code class="o">(</code><code class="calibre19">props</code><code class="o">.</code><code class="na">project</code><code class="o">,</code> <code class="calibre19">props</code><code class="o">.</code><code class="na">domain</code><code class="o">)</code>
<code class="lineno">61 </code>        <code class="o">}</code>
<code class="lineno">62 </code>      <code class="o">}</code> <code class="k">catch</code><code class="o">(</code><code class="calibre19">e</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">63 </code>          <code class="calibre19">error</code> <code class="s">"Failed functional tests"</code>
<code class="lineno">64 </code>      <code class="o">}</code> <code class="k">finally</code> <code class="o">{</code>
<code class="lineno">65 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">66 </code>          <code class="calibre19">k8sDeleteBeta</code><code class="o">(</code><code class="calibre19">props</code><code class="o">.</code><code class="na">project</code><code class="o">)</code>
<code class="lineno">67 </code>        <code class="o">}</code>
<code class="lineno">68 </code>      <code class="o">}</code>
<code class="lineno">69 </code>    <code class="o">}</code>
<code class="lineno">70 </code>    <code class="k">if</code> <code class="o">(</code><code class="s">"${BRANCH_NAME}"</code> <code class="o">==</code> <code class="s">"master"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">71 </code>      <code class="calibre19">stage</code><code class="o">(</code><code class="s">"release"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">72 </code>        <code class="calibre19">node</code><code class="o">(</code><code class="s">"docker"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">73 </code>          <code class="calibre19">k8sPushImage</code><code class="o">(</code><code class="calibre19">props</code><code class="o">.</code><code class="na">image</code><code class="o">)</code>
<code class="lineno">74 </code>        <code class="o">}</code>
<code class="lineno">75 </code>        <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">76 </code>          <code class="calibre19">k8sPushHelm</code><code class="o">(</code><code class="calibre19">props</code><code class="o">.</code><code class="na">project</code><code class="o">,</code> <code class="calibre19">props</code><code class="o">.</code><code class="na">chartVer</code><code class="o">,</code> <code class="calibre19">props</code><code class="o">.</code><code class="na">cmAddr</code><code class="o">)</code>
<code class="lineno">77 </code>        <code class="o">}</code>
<code class="lineno">78 </code>      <code class="o">}</code>
<code class="lineno">79 </code>      <code class="calibre19">stage</code><code class="o">(</code><code class="s">"deploy"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">80 </code>        <code class="k">try</code> <code class="o">{</code>
<code class="lineno">81 </code>          <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">82 </code>            <code class="calibre19">k8sUpgrade</code><code class="o">(</code><code class="calibre19">props</code><code class="o">.</code><code class="na">project</code><code class="o">,</code> <code class="calibre19">props</code><code class="o">.</code><code class="na">addr</code><code class="o">)</code>
<code class="lineno">83 </code>          <code class="o">}</code>
<code class="lineno">84 </code>          <code class="calibre19">container</code><code class="o">(</code><code class="s">"kubectl"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">85 </code>            <code class="calibre19">k8sRollout</code><code class="o">(</code><code class="calibre19">props</code><code class="o">.</code><code class="na">project</code><code class="o">)</code>
<code class="lineno">86 </code>          <code class="o">}</code>
<code class="lineno">87 </code>          <code class="calibre19">container</code><code class="o">(</code><code class="s">"golang"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">88 </code>            <code class="calibre19">k8sProdTestGolang</code><code class="o">(</code><code class="calibre19">props</code><code class="o">.</code><code class="na">addr</code><code class="o">)</code>
<code class="lineno">89 </code>          <code class="o">}</code>
<code class="lineno">90 </code>        <code class="o">}</code> <code class="k">catch</code><code class="o">(</code><code class="calibre19">e</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">91 </code>          <code class="calibre19">container</code><code class="o">(</code><code class="s">"helm"</code><code class="o">)</code> <code class="o">{</code>
<code class="lineno">92 </code>            <code class="calibre19">k8sRollback</code><code class="o">(</code><code class="calibre19">props</code><code class="o">.</code><code class="na">project</code><code class="o">)</code>
<code class="lineno">93 </code>          <code class="o">}</code>
<code class="lineno">94 </code>        <code class="o">}</code>
<code class="lineno">95 </code>      <code class="o">}</code>
<code class="lineno">96 </code>    <code class="o">}</code>
<code class="lineno">97 </code>  <code class="o">}</code>
<code class="lineno">98 </code><code class="o">}</code>
</pre></div>

</figure>

<aside class="warning">
    <h3 id="leanpub-auto-a-note-to-minishift-users-30" class="calibre22">A note to minishift users</h3>

  <p class="calibre3">Due to differences between OpenShift and other Kubernetes flavors, you’ll have to explore the file called Jenkinsfile.oc. It contains a few OpenShift-specific differences we commented earlier.</p>

</aside>

<p class="calibre3">As you can see, the content of Jenkinsfile is a pipeline similar to the one we previously created in Jenkins. Soon we’ll discover how to tell Jenkins to use that file instead. For now, we’ll explore the differences between the pipeline we defined in Jenkins and the one available in Jenkinsfile.</p>

<p class="calibre3">On the first inspection, you might say that both pipelines are the same. Take a closer look, and you’ll notice that there are quite a few differences. They might be subtle, but they are important nevertheless.</p>

<p class="calibre3">The first difference is that there are no environment variables. Instead, there is a single variable <code class="calibre19">props</code>. We’ll have to fast forward to the <code class="calibre19">build</code> stage to see its usage.</p>

<p class="calibre3">We added a set of new steps to the <code class="calibre19">build</code> stage. We are using <code class="calibre19">readProperties</code> to read the <code class="calibre19">build-config.properties</code> file and store interpolated values to the <code class="calibre19">props</code> variable. There is a bug in Jenkins that prevents us from using absolute paths so before we <code class="calibre19">readProperies</code>, we copy the file from <code class="calibre19">/etc/config/</code> to the current directory.</p>

<p class="calibre3">If you go back to the <code class="calibre19">podTemplate</code> definition, you’ll notice that the <code class="calibre19">helm</code> container has a mount to the directory <code class="calibre19">/etc/config</code>. Further down, the same volume is defined as <code class="calibre19">configMap</code>. In other words, we’re injecting the <code class="calibre19">build-config.properties</code> file as Kubernetes ConfigMap and using its content to interpolate all the variables we need.</p>

<p class="calibre3">You don’t have to use ConfigMap. It could be a Secret, or it could be a file located in the code repository. It does not matter how the file gets there, but that it contains the values we’ll need for our pipeline. Those are the same ones we defined previously as environment variables. In my opinion, that’s a much more elegant and easier way to define them. If you do not like the idea of a properties file, feel free to continue using environment variables as we did in previous iterations of the pipeline.</p>

<p class="calibre3">The next significant difference is that we changed <code class="calibre19">git</code> steps with <code class="calibre19">checkout scm</code>. Later on, we’ll establish a connection between pipeline jobs and repositories and branches, and Jenkins will know which repository, which branch, and which commit to pull. Until now, we were always pulling HEAD of the master branch, and that is, obviously, apparently. We’ll see how <code class="calibre19">checkout scm</code> works later on. For now, just remember that Jenkins will know what to pull with that instruction.</p>

<p class="calibre3">The step directly below <code class="calibre19">checkout scm</code> features the usage of <code class="calibre19">readProperties</code> step we declared earlier. Since we specified <code class="calibre19">interpolate: true</code>, Jenkins converted each property into a different variable or, to be more precise, a separate map entry. We’re leveraging that with steps like <code class="calibre19">k8sBuildImageBeta(props.image)</code> where <code class="calibre19">props.image</code> is one of the interpolated property keys.</p>

<p class="calibre3">The rest of the pipeline is the same as what we had before, except that environment variables are replaced with <code class="calibre19">props.SOMETHING</code> variables.</p>

<p class="calibre3">There is one more important difference though. Two of the stages (<code class="calibre19">release</code> and <code class="calibre19">deploy</code>) are now enveloped in an <code class="calibre19">if ("${BRANCH_NAME}" == "master")</code> block. That allows us to control which parts of the pipeline are always executed, and which will run only if the branch is <em class="calibre17">master</em>. You might choose different conditions. For our use case, the logic is straightforward. If a commit (or a merge) is done to master, we want to execute the whole pipeline that, ultimately, upgrades the production release. All the other branches (typically feature branches), should only validate whether the commit works as expected. They should not make a (production) release, nor they should deploy to production.</p>

<aside class="warning">
    <h3 id="leanpub-auto-a-note-to-minishift-users-31" class="calibre22">A note to minishift users</h3>

  <p class="calibre3">Please replace <em class="calibre17">Jenkinsfile</em> with <em class="calibre17">Jenkinsfile.oc</em>, commit the change, and push it to the forked repository. You’ll have to repeat the same step for all the branches.</p>

</aside>

<p class="calibre3">Now that we know that our pipeline needs a ConfigMap named <code class="calibre19">go-demo-3-build</code>, our next step will be to create it. We already have a YAML file in the application’s repository.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>cat ../go-demo-3/k8s/build-config.yml
</pre></div>

</figure>

<p class="calibre3">The output is as follows.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno"> 1 </code><code class="calibre19">kind</code><code class="calibre19">:</code> <code class="calibre19">ConfigMap</code>
<code class="lineno"> 2 </code><code class="calibre19">apiVersion</code><code class="calibre19">:</code> <code class="calibre19">v1</code>
<code class="lineno"> 3 </code><code class="calibre19">metadata</code><code class="calibre19">:</code>
<code class="lineno"> 4 </code>  <code class="calibre19">creationTimestamp</code><code class="calibre19">:</code> <code class="calibre19">2016-02-18...</code>
<code class="lineno"> 5 </code>  <code class="calibre19">name</code><code class="calibre19">:</code> <code class="calibre19">build-config</code>
<code class="lineno"> 6 </code>  <code class="calibre19">namespace</code><code class="calibre19">:</code> <code class="calibre19">go-demo-3-build</code>
<code class="lineno"> 7 </code><code class="calibre19">data</code><code class="calibre19">:</code>
<code class="lineno"> 8 </code>  <code class="calibre19">build-config.properties</code><code class="calibre19">:</code> <code class="calibre19">|</code>
<code class="lineno"> 9 </code>    <code class="no">project=go-demo-3</code>
<code class="lineno">10 </code>    <code class="no">image=vfarcic/go-demo-3</code>
<code class="lineno">11 </code>    <code class="no">domain=acme.com</code>
<code class="lineno">12 </code>    <code class="no">addr=go-demo-3.acme.com</code>
<code class="lineno">13 </code>    <code class="no">cmAddr=cm.acme.com</code>
<code class="lineno">14 </code>    <code class="no">chartVer=0.0.1</code>
</pre></div>

</figure>

<p class="calibre3">If you focus on the <code class="calibre19">build-config.properties</code> data entry, you’ll notice that it contains similar values as those we used before as environment variables. Obviously, we won’t be able to create the ConfigMap as-is since we need to replace <code class="calibre19">acme.com</code> with the address and <code class="calibre19">vfarcic</code> with your Docker Hub user. We’ll use a bit of <code class="calibre19">sed</code> magic to modify the YAML before passing it to <code class="calibre19">kubectl</code>.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>cat ../go-demo-3/k8s/build-config.yml <code class="se">\</code>
<code class="lineno">2 </code>    <code class="calibre19">|</code> sed -e <code class="s">"s@acme.com@</code><code class="nv">$ADDR</code><code class="s">@g"</code> <code class="se">\</code>
<code class="lineno">3 </code>    <code class="calibre19">|</code> sed -e <code class="s">"s@vfarcic@</code><code class="nv">$DH_USER</code><code class="s">@g"</code> <code class="se">\</code>
<code class="lineno">4 </code>    <code class="calibre19">|</code> kubectl apply -f - --record
</pre></div>

</figure>

<p class="calibre3">We’ll replace the Jenkins job we used so far with a different kind, so our next step is to delete it.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"http://</code><code class="nv">$JENKINS_ADDR</code><code class="s">/job/go-demo-3/"</code>
</pre></div>

</figure>

<p class="calibre3">Please click the <em class="calibre17">Delete Pipeline</em> link and confirm the action.</p>

<p class="calibre3">Now we are ready to create a job in the way we should have done it all along if we didn’t need a playground that allows us to modify a pipeline easily.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code>open <code class="s">"http://</code><code class="nv">$JENKINS_ADDR</code><code class="s">/blue/create-pipeline"</code>
</pre></div>

</figure>

<p class="calibre3">Please select <em class="calibre17">GitHub</em>, and you’ll be asked for <em class="calibre17">Your GitHub access token</em>. If you do NOT have a token at hand, please click the <em class="calibre17">Create an access token here</em> link, and you will be redirected to the page in GitHub that is already pre-configured with all the permissions the token needs. All you have to do is type <em class="calibre17">Token description</em>. Anything should do. Feel free to type <em class="calibre17">jenkins</em> if today is not your creative day. Click the <em class="calibre17">Generate token</em> button at the bottom.</p>

<p class="calibre3">You’ll see the newly generated token. Make sure to copy it and, optionally, save it somewhere. This is the first, and the last time you will see the value of the token.</p>

<p class="calibre3">Go back to Jenkins UI, paste the token into the <em class="calibre17">Your GitHub access token</em> field, and click the <em class="calibre17">Connect</em> button.</p>

<p class="calibre3">Next, we need to select the organization. You might have multiple entries if you are an active GitHub user. Choose the one where you forked <em class="calibre17">go-demo-3</em> repository.</p>

<p class="calibre3">Once you selected the organization, you’ll see the list of all the repositories you own. Select <em class="calibre17">go-demo-3</em>. If there are too many, you can use the <em class="calibre17">Search…</em> field to filter the results.</p>

<p class="calibre3">The only thing left is to click the <em class="calibre17">Create Pipeline</em> button, and Jenkins will start creating new jobs. There will be one for each branch. You should, as a minimum, see three; <em class="calibre17">master</em>, <em class="calibre17">feature-3</em>, and <em class="calibre17">feature-4</em>. If we add a WebHook to our GitHub repository, Jenkins would be notified every time we create a new branch, and it would create a corresponding job. Similarly, when we delete a branch, the job would be removed as well.</p>

<p class="calibre3">Unfortunately, we might not be able to create a WebHook for our examples. At least, not for all of you. Those that are running a local cluster using Docker For Mac or Windows, minikube, or minishift, do not have an IP that is reachable from GitHub. Since I don’t want to discriminate against those that run a cluster locally from those running it in one of the Cloud providers, I’ll skip providing detailed instructions. Instead, when you translate lessons learned from this book into your production cluster, please follow the instructions from <a href="https://support.cloudbees.com/hc/en-us/articles/115003019232-GitHub-Webhook-Pipeline-Multibranch">GitHub Webhook: Pipeline Multibranch</a> (jump to the <em class="calibre17">Validate GitHub WebHook section</em>). Google is your friend if you prefer using GitLab, BitBucket, or some other Git solution.</p>

<p class="calibre3">Going back to Jenkins…</p>

<p class="calibre3">The first build of each job that corresponds to a different branch or a pull request is running. You can click on the <em class="calibre17">Branches</em> tab if you are interested only in jobs based on branches. Similarly, you can click on the <em class="calibre17">Pull Requests</em> tab to see the PRs. I did create a few pull requests in the <em class="calibre17">vfarcic/go-demo-3</em> repository, but they were not transferred to your fork. For now, you’ll need to trust me when I say that new jobs will be created for each PR, as long as there is a GitHub WebHook that will notify Jenkins when you create them.</p>

<p class="calibre3">The communication between GitHub and Jenkins goes both ways. On the one hand, GitHub is notifying Jenkins whenever we created a new branch, commit something, or if we perform any other action configured through WebHooks. On the other hand, Jenkins will notify GitHub with a status of a build. A good example is a pull request. If we’d have one, would see that the state of the corresponding build would be available in PRs screen. We’d see both the activity while the build is running, as well as the outcome once it’s finished.</p>


<figure class="image1">
  <img src="../images/00041.jpeg" alt="Figure 7-14: Jenkins integration with GitHub pull requests" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-14: Jenkins integration with GitHub pull requests</figcaption>
</figure>


<p class="calibre3">Please note that each of the jobs based on different branches are now using <code class="calibre19">checkout scm</code> in their pipelines. Since now Jenkins keeps tracks of repositories, branches, and commits, there is no need for us to be explicit through steps like <code class="calibre19">git</code>. When a job is triggered by a commit, and Jenkins is notified via a webhook, it’ll make sure it is that specific commit that is checked out. This by itself is a significant advantage of using Jenkins’ multistage builds. Please note that when triggered manually, checkout scm will checkout the latest commit of the branch and the repository the job is pointing at.</p>

<p class="calibre3">The <em class="calibre17">Activity</em> tab shows all the builds, independently whether they come from a branch or a pull request.</p>

<p class="calibre3">We have a problem though. The <code class="calibre19">go-demo-3-build</code> Namespace does not have enough capacity to run more than one build at a time. I did my best to keep ResourceQuotas and overall cluster capacity to a minimum so that the cost for those running in Cloud is as small as possible. For those running a local cluster, we have limits of your laptops which we are probably already stretching to the limit.</p>

<p class="calibre3">Small capacity of our cluster and quotas is not really a big deal if we have enough patience. One of the builds is running while others are waiting in a queue. Once the first build is finished, the second one will start, and then the third, all the way until all the builds are completed. So, we’ll have to be patient.</p>

<p class="calibre3">Please wait until a build of a feature branch is finished (e.g., <em class="calibre17">feature-3</em>  or <em class="calibre17">feature-4</em>). Click on the row that represents that build and observe the stages. You’ll notice that there are only two (<code class="calibre19">build</code> and <code class="calibre19">func-test</code>). The second half of the pipeline (<code class="calibre19">release</code> and <code class="calibre19">deploy</code>) was not executed since the <code class="calibre19">if</code> condition did not evaluate to <code class="calibre19">true</code>.</p>

<p class="calibre3">Similarly, once the build of the <em class="calibre17">master</em> branch is finished, enter inside it and observe that all the stages were executed thus upgrading our production release. Feel free to go to your cluster and confirm that a new Helm revision was created and that new Pods are running. Similarly, a new image should be available in Docker Hub.</p>


<figure class="image1">
  <img src="../images/00042.jpeg" alt="Figure 7-15: The jobs from the go-demo-3 Multi-Branch Pipeline" class="calibre25"/>
  <figcaption class="calibre26">Figure 7-15: The jobs from the go-demo-3 Multi-Branch Pipeline</figcaption>
</figure>


<h3 id="leanpub-auto-what-now-6" class="calibre20">What Now?</h3>

<p class="calibre3">We are, finally, finished designing the first iteration of a fully functioning continuous deployment pipeline. All the subjects we explored in previous chapters and all the problems we solved led us to this point. Everything we learned before were prerequisites for the pipeline we just created.</p>

<p class="calibre3">We succeeded! We are victorious! And we deserve a break.</p>

<p class="calibre3">Before you run away, there are two things I’d like to comment.</p>

<p class="calibre3">Our builds were very slow. Realistically, they should be at least twice as fast. However, we are operating in a tiny cluster and, more importantly, <code class="calibre19">go-demo-3-build</code> Namespace has limited resources and very low defaults. Kubernetes throttled CPU usage of the containers involved in builds to maintain the default values we set on that Namespace. That was intentional. I wanted to keep the cluster and the Namespaces small so that the costs are at a minimum. If you’re running a cluster in AWS or GCE, the total price should be very low. It should probably be less than a cup of coffee you had while reading the chapter. On the other hand, if you are running it locally, the chances are that you don’t have a laptop in which you can spare much more CPU for the cluster (memory should be less of an issue). In either case, the critical thing to note is that you should be more generous when creating “real” production pipelines.</p>

<p class="calibre3">The second and the last note concerns the VM we’re using to build and push Docker images. If you’re using AWS or GCE, it was created dynamically with each build. If you recall the settings, the VMs are removed only after ten minutes of inactivity. Please make sure that period passed before you destroy your cluster. That way, we’ll let Jenkins destroy the VM for us. If, on the other hand, you created a local VM with Vagrant, please execute the commands that follow to suspend it.</p>

<figure class="code">
<div class="highlight"><pre class="calibre24"><code class="calibre19"/><code class="lineno">1 </code><code class="nb">cd</code> cd/docker-build
<code class="lineno">2 </code>
<code class="lineno">3 </code>vagrant <code class="nb">suspend</code>
<code class="lineno">4 </code>
<code class="lineno">5 </code><code class="nb">cd</code> ../../
</pre></div>

</figure>

<p class="calibre3">That’s it. We reached the end of the chapter. Feel free to destroy the cluster if you’re not planning to continue straight away.</p>



</div>
</body></html>