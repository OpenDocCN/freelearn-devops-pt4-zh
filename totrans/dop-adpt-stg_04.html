<html><head></head><body>
		<div id="_idContainer020">
			<h1 id="_idParaDest-72"><em class="italic"><a id="_idTextAnchor071"/>Chapter 3</em>: Measuring the Success of DevOps</h1>
			<p>You have to be able to point to metrics and measurements that show the success of DevOps within your organization. Selecting the right metrics is critical to showcasing your progress, ensuring teams stay aligned with the vision and empowerment of people. This chapter looks at the various metrics used in DevOps and how to measure success.</p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Common metrics used to measure success</li>
				<li>Designing metrics for your team</li>
				<li>Creating rollups at an organizational level</li>
			</ul>
			<h1 id="_idParaDest-73"><a id="_idTextAnchor072"/>Common metrics used to measure success</h1>
			<p>Firstly, it's important to <a id="_idIndexMarker133"/>know why to measure your performance. I speak to many leaders of various businesses, and a frightening trend is that they all think measuring success is a tool that can be used to help with performance management.</p>
			<p>The reality is that tracking of <a id="_idIndexMarker134"/>performance is a tool for improvement. <strong class="bold">Continuous improvement</strong> (<strong class="bold">CI</strong>) is a key pillar of DevOps, so if you have no idea how you are performing, how can you improve? Improvement should be the main goal of the metrics used in DevOps, ones that can drive tangible results and highlight growth areas.</p>
			<p>Before we look at the metrics you can use, I like to put them into three buckets. Then, as you will see later in the chapter, depending on the type of team you are running, you can pick appropriate metrics from each bucket to look at your performance and generate useful methods of feedback. The number of metrics you pick from each bucket depends on your goals and your style of team. Have a look at the following diagram:</p>
			<div>
				<div id="_idContainer019" class="IMG---Figure">
					<img src="image/B17192_03_01.jpg" alt="Figure 3.1 – Venn diagram showing the relationship of velocity, quality, and stability&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.1 – Venn diagram showing the relationship of velocity, quality, and stability</p>
			<p>The idea behind the <a id="_idIndexMarker135"/>preceding diagram is to illustrate that in an ideal world, you have a balance of metrics from each of the three categories, but you can have scenarios where you have more from one category. In all scenarios, you will notice that stability is present throughout. </p>
			<p>The following possibilities exist in this model:</p>
			<ul>
				<li><strong class="bold">Velocity</strong> + <strong class="bold">Stability</strong></li>
				<li><strong class="bold">Quality</strong> + <strong class="bold">Stability</strong></li>
				<li><strong class="bold">Velocity</strong> + <strong class="bold">Quality</strong> + <strong class="bold">Stability</strong></li>
			</ul>
			<p>Stability is core because whatever we are doing within our organization, no matter what changes we are going through, stability should be central to what we do, and in no circumstances should we impact this.</p>
			<p>First, let's look at the metrics you would associate with velocity. In DevOps, when we talk about velocity, we mean working with both speed and direction.</p>
			<h2 id="_idParaDest-74"><a id="_idTextAnchor073"/>Common velocity metrics</h2>
			<p>Velocity is vitally important in DevOps, as we <a id="_idIndexMarker136"/>are going on a journey that tries to break down silos in your organization and improve <a id="_idIndexMarker137"/>collaboration and communication. Having metrics that look at velocity can be very useful when it comes to highlighting areas for improvement. With that in mind, let's look at some of the common velocity metrics, as follows:</p>
			<ul>
				<li>Deployment duration</li>
				<li>Deployment frequency</li>
				<li>Change volume</li>
				<li>Test automation coverage</li>
				<li>Lead time</li>
				<li>Cycle time</li>
				<li>Deployment failure rate</li>
				<li>Environment provisioning time</li>
			</ul>
			<p>From looking at these metrics at a high level, let's now look at them in more detail to understand what each one means.</p>
			<h3>Deployment duration</h3>
			<p>Deployment duration is <a id="_idIndexMarker138"/>the amount of time it takes to <a id="_idIndexMarker139"/>execute your <strong class="bold">continuous deployment</strong> (<strong class="bold">CD</strong>) pipeline. If you are producing a build and running a deployment at the same time rather than just picking up the latest build artifact, then record both the CI and CD pipelines, but make sure you have a way of knowing how long each pipeline is taking to execute. Most tooling provides you with the ability to look at the start and end time of each pipeline and the steps executed within.</p>
			<h3>Deployment frequency</h3>
			<p>Measuring deployment frequency <a id="_idIndexMarker140"/>enables you to look at how many times you deploy. In mature organizations, the target is to deploy numerous times a day. Whether you do or not is dependent on several factors.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Charting progress over time with an increasing number of deployments can show real progress in your DevOps transformation.</p>
			<h3>Change volume</h3>
			<p>In DevOps, there is often a <a id="_idIndexMarker141"/>common misconception that you don't follow the normal change management procedures. In reality, it's quite the opposite—transparency is important, and there is no better tool for transparency in service management than change management. You can measure the number of changes sprint to sprint, or even just monthly, to get an idea of the number of releases you are shipping.</p>
			<h3>Test automation coverage</h3>
			<p>Test automation is also a key part of <a id="_idIndexMarker142"/>automation in DevOps. When talking about measuring coverage in test automation, we mean the amount of the application or code base that is covered by automated tests.</p>
			<h3>Lead time</h3>
			<p>In DevOps, if you are <a id="_idIndexMarker143"/>looking to ship features quickly, then lead time is an important metric for you to measure. Lead time is the amount of elapsed time between adding an item to the backlog and that item shipping to release. This lets you measure how long it takes on average to take an item from backlog to production.</p>
			<h3>Cycle time</h3>
			<p>Very similar to <a id="_idIndexMarker144"/>lead time is cycle time. The slight difference in this metric is that rather than measuring from when an item is added to the backlog to when <a id="_idIndexMarker145"/>that item is shipped, cycle time looks at the time from when work on that item is started to when it is completed, or shipped.</p>
			<h3>Deployment failure rate</h3>
			<p>Identifying the rate of failure in <a id="_idIndexMarker146"/>deployment helps teams determine the quality of code and testing, moving from other stages to production. It is a leading indicator for code and pipeline maturity. Failure of deployments is obviously something you need to know about and monitoring can help with this, but recording your deployment failure rate as a percentage is also important. This lets you understand how often your deployments fail. Mature organizations look for a value below 5% for large volumes of deployments.</p>
			<h3>Environment provisioning time</h3>
			<p>When using <strong class="bold">infrastructure as code</strong> (<strong class="bold">IaC</strong>) to <a id="_idIndexMarker147"/>deploy your environments, much <a id="_idIndexMarker148"/>like when measuring deployment duration, environment provisioning time allows you to understand how long it takes to <a id="_idIndexMarker149"/>deploy your environment. In environments with a high number of microservices this is a great metric, as you will be able to see as you deploy more microservices how your provisioning time hopefully decreases.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">As your organization progresses through maturity, it's useful to see where you have come from on your journey. Track this metric from the beginning so that you can see the progress you are making.</p>
			<p>Now, let's look at some of the metrics associated with quality.</p>
			<h2 id="_idParaDest-75"><a id="_idTextAnchor074"/>Common quality metrics</h2>
			<p>As we discussed earlier, measuring <a id="_idIndexMarker150"/>stability is <a id="_idIndexMarker151"/>important; second on that list is quality. You can have a high velocity, meaning you are working at a fast rate, but the quality may suffer because of that. This isn't a scenario you want, as low quality starts to erode trust in what you are doing and how you are doing it. Here are some common quality metrics you can use in your organization:</p>
			<ul>
				<li>Defect density</li>
				<li>Defect aging</li>
				<li>Code quality</li>
				<li>Unit test coverage</li>
				<li>Code vulnerabilities</li>
				<li>Standards violations</li>
				<li>Defect reintroduction rate</li>
			</ul>
			<p>Now that we understand the <a id="_idIndexMarker152"/>quality metrics <a id="_idIndexMarker153"/>we can use, let's look at them again in more detail to understand what they mean.</p>
			<h3>Defect density</h3>
			<p>You can measure <a id="_idIndexMarker154"/>defect density in several different ways. The most common way is to calculate the number of defects per 1,000 lines of code. Using this metric is useful to help with sprint planning. You can, over time, use this metric to estimate the number of defects you may be presented with from sprint to sprint.</p>
			<p>With the <a id="_idIndexMarker155"/>adoption of <strong class="bold">integrated development environments</strong> (<strong class="bold">IDEs</strong>) and automation tools it can be hard to identify lines of code, but it is still an important metric, and most development tools will be able to get past this limitation.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">The calculation for defect <a id="_idIndexMarker156"/>density is defect count/<strong class="bold">lines of code</strong> (<strong class="bold">LOC</strong>) of the release. Note that this is on the specific release, not the overall code base.</p>
			<h3>Defect aging</h3>
			<p>This is a valuable metric to measure, and is simply <a id="_idIndexMarker157"/>the measure of time between a defect getting reported to the backlog and the current date, provided that defect is still open. Tracking this metric is important when it comes to technical debt. It allows you to understand how long on average you keep defects open for before they are resolved.</p>
			<h3>Code quality</h3>
			<p>When we talk about <a id="_idIndexMarker158"/>code quality, it's easy to think we are talking about the number of standards violations. We're going to talk about that metric as another quality metric you can use. In this context, when we talk about code quality, we mean in the overall context of an application. This can be represented as a percentage of the overall application. The degrading part of this metric is the number of violations against code quality, defined by many of the rulesets available for whichever language you are programming in.</p>
			<h3>Unit test coverage</h3>
			<p>Coverage of unit testing is <a id="_idIndexMarker159"/>measured as a percentage. It covers the percentage of the application that is covered by unit tests written by developers. In <strong class="bold">test-driven deployment</strong> (<strong class="bold">TDD</strong>) environments where <a id="_idIndexMarker160"/>the tests are written before the functional code, organizations look for 80% coverage as an absolute minimum.</p>
			<h3>Code vulnerabilities</h3>
			<p>Scanning your code for <a id="_idIndexMarker161"/>known vulnerabilities is a fundamental aspect of good security practice. For this reason, understanding the number of vulnerabilities by release is a key metric. You can introduce vulnerabilities in other areas of your application when you write new features or fix others. Tracking this metric then becomes important for ensuring you are following good security practices.</p>
			<h3>Standards violations</h3>
			<p>Static analysis tools can <a id="_idIndexMarker162"/>look at your source code in detail and highlight areas of code that do not conform to standards. These are generally community-driven or professionally set standards. However, some tools allow organizations to set their own rules for standards. This <a id="_idIndexMarker163"/>metric provides you with information and insights on how your developers are developing to standards baselines.</p>
			<h3>Defect reintroduction rate</h3>
			<p>Despite what you <a id="_idIndexMarker164"/>might think, this metric tracks the effectiveness of your developers' local testing. We are measuring with this metric the number of defects that are reported as breaking other functionality and causing other defects to be raised. You will sometimes see this <a id="_idIndexMarker165"/>metric being called <em class="italic">defect leakage</em>.</p>
			<p>Finally, let's look at the common metrics for stability. You will recognize some of these if you have a service management background.</p>
			<h2 id="_idParaDest-76"><a id="_idTextAnchor075"/>Common stability metrics</h2>
			<p>Stability is critical—just as <a id="_idIndexMarker166"/>poor quality can erode trust internally and within your customer base, so can poor stability. Nobody wants to <a id="_idIndexMarker167"/>use a product or platform that is not stable. Instrumentation is designed to help you understand what is happening and how it affects stability. The following metrics exist to help you measure stability:</p>
			<ul>
				<li><strong class="bold">Mean Time to Recovery</strong> (<strong class="bold">MTTR</strong>)</li>
				<li>Deployment downtime</li>
				<li>Change failure rate</li>
				<li>Incidents per deployment</li>
				<li>Unapproved changes</li>
				<li>Number of hotfixes</li>
				<li>Platform availability</li>
			</ul>
			<p>Let's now look at these common stability metrics in more detail.</p>
			<h3>MTTR</h3>
			<p>I find this metric powerful and more <a id="_idIndexMarker168"/>useful than measuring availability, especially in the cloud world, where availability of the platform is less within your control than within a traditional <a id="_idIndexMarker169"/>data center environment. Measuring MTTR looks at the time from when the system or product fails to when it is available again. Over time, this calculates an average that you want to see decreasing over time.</p>
			<h3>Deployment downtime</h3>
			<p>This interesting metric <a id="_idIndexMarker170"/>looks over time at the average time your application or product is unavailable during a deployment. You can measure this as a percentage of overall availability over the month or sprint, or measure the specific blocks of time.</p>
			<h3>Change failure rate</h3>
			<p>As we discussed earlier, it's important to <a id="_idIndexMarker171"/>make use of change management, own your failures, and measure the change failure rate as a percentage of changes implemented. This may be something the change management team already measures, but it is recommended to make specific measurement for your DevOps teams.</p>
			<h3>Incidents per deployment</h3>
			<p>There is no better metric to <a id="_idIndexMarker172"/>understand the impact releases make on your user community than by tracking the number of incidents raised per deployment. Systems such as ServiceNow have the ability to link in releases with incidents, so it's easy to see which release the incident is attributed to. This can go back in the backlog as a bug.</p>
			<h3>Unapproved changes</h3>
			<p>Any good change <a id="_idIndexMarker173"/>management function will track the number of unauthorized or unapproved changes on a platform. Some of them may be emergency releases and waiting for paperwork to catch up, but some of these may be genuine and represent learning opportunities.</p>
			<h3>Number of hotfixes</h3>
			<p>It is all well and good <a id="_idIndexMarker174"/>measuring the number of deployments you make and how quickly they happen, but what about the number of bug fixes or hotfixes you release? Looking to put measures in place to reduce this number is also a key differentiator between immature and mature DevOps organizations.</p>
			<h3>Platform availability</h3>
			<p>This is a typical metric that <a id="_idIndexMarker175"/>looks at measuring the time of availability of a platform, but representing this as a percentage. In its most basic form, the higher the percentage, the more available the platform was. Some organizations have credit schemes to compensate clients who do not get over a contractually agreed availability threshold.</p>
			<p>That wraps up our look at the common metrics you can use to measure success in DevOps. But how do we apply these in meaningful scenarios, and what sort of baseline targets should you be looking at?</p>
			<h1 id="_idParaDest-77"><a id="_idTextAnchor076"/>Designing metrics for your team</h1>
			<p>Now that we <a id="_idIndexMarker176"/>understand the key metrics that are involved in DevOps, it is next important to understand where those metrics can be used and in which scenarios. You can have too many metrics that you track in an organization, and these can then be counterproductive.</p>
			<p>Knowing which metrics to use depends on many different parameters. However, we will now look at some example scenarios, describe what the goal of their DevOps transformation is, and look at the metrics that will help them identify their success.</p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor077"/>Scenario 1: Small organization with a dedicated DevOps team</h2>
			<p>For small organizations, one thing <a id="_idIndexMarker177"/>that is common between them is their ability to become more agile and break down silos that exist between teams. Smaller teams allow for faster feedback loops and cycle time. In fact, most small organizations have fewer silos overall, and some may have no silos.</p>
			<p>In this scenario, let's imagine we have a dedicated DevOps team at our organization, comprising six people. This organization runs one single product, which is sold to customers <a id="_idIndexMarker178"/>on a <strong class="bold">software-as-a-service</strong> (<strong class="bold">SaaS</strong>) basis.</p>
			<p>In this example, the interaction is very simple. The team works well together due to the size of the organization, and roles and responsibilities are well defined. As with most organizations of this size, with the growth they have seen comes teething issues, such as a drop in quality due to pressure to execute.</p>
			<p>For them, it's important to focus on stability as well as quality, to ensure that high quality leads to better stability. Let's now have a look at four metrics they could use and why, as follows:</p>
			<ul>
				<li><strong class="bold">MTTR</strong>—Understanding how long it takes to recover the application platform is critical. The organization needs to look at how the platform needs to evolve in the future. This is important as the platform grows and scales, and information discovered here can lead to architectural improvements that reduce the average recovery time.</li>
				<li><strong class="bold">Platform availability</strong> (&gt; 99%)—Providing a contractual incentive to keep the platform available may help improve stability, but be warned: it could also cause unwanted pressure on the team and make the problem worse. Simple measurement and a discussion on what causes the downtime and how to fix it longer-term is much more productive.</li>
				<li><strong class="bold">Unit test coverage</strong> (&gt; 80%)—Ensuring good coverage of testing is very important. As this organization suffers from high levels of defects, ensuring good unit test coverage will ensure better testing is performed and that code is performing as expected.</li>
				<li><strong class="bold">Defect density</strong> (&lt; 1/1,000 lines)—Releases at this organization have presented problems before. Understanding the density of defects will help them plan better, as well as <a id="_idIndexMarker179"/>understand where the problems are when they are developing and which ones transpire into defects.</li>
			</ul>
			<p>Let's now look at a different scenario for a medium-sized organization with an advocacy team.</p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor078"/>Scenario 2: Medium organization with advocacy team</h2>
			<p>For this scenario, our organization has <a id="_idIndexMarker180"/>separate operations and development teams, and they're trying to work better together with the help of an advocacy team. Their aim is to facilitate the right level of collaboration and communication between them using different techniques, while still continuing with their day-to-day work.</p>
			<p>As discussed in the previous chapter, advocacy teams are not given specific deliverable tasks in the sprint team, but are there to drive forward the best practices of DevOps and help the team achieve the goals set out for them.</p>
			<p>For a team which is of a medium size, stability as well as quality is important to them on their journey, but understanding velocity is also important. The team needs a broad view of their performance over time so that adjustments can be made as they become more mature. Let's look at the metrics this team can use to track their performance, as follows:</p>
			<ul>
				<li><strong class="bold">Lead time</strong>—Tracking lead time allows them to understand where time is used, from the allocation of a backlog item to when it is delivered. This helps the team plan better in the future, give appropriate estimates, and help identify areas where processes can be streamlined.</li>
				<li><strong class="bold">Cycle time</strong>—Similarly, understanding the average time taken from work starting to shipping also gives the team metrics that help them improve their estimation and planning meetings, delivering over time to improve customer satisfaction.</li>
				<li><strong class="bold">Unit test coverage</strong>—As a new team in DevOps, having high-quality code is important, but understanding where you are now is even more important. This helps highlight the amount of technical debt inherited by the lack of quality unit test coverage.</li>
				<li><strong class="bold">Code quality</strong>—In a similar way to unit test coverage, this metric will help the team understand where skills gaps with their developers may exist and can be improved by targeting trouble areas.</li>
				<li><strong class="bold">MTTR</strong>—Remember: stability is important, as is <a id="_idIndexMarker181"/>understanding how long it takes to recover service. This information for the team feeds back into their improvement cycles to again help them improve.</li>
				<li><strong class="bold">Deployment downtime</strong>—Finally, any new team at DevOps needs to understand the impact of their work during releases. Measuring the downtime of your releases helps you improve the automation process in the future, or even move away from manual deployments to automated ones.</li>
			</ul>
			<p>Let's now look at a large organization scenario where they have numerous DevOps teams.</p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor079"/>Scenario 3: Large organization with numerous DevOps teams</h2>
			<p>When you have a large organization with numerous DevOps teams of various sizes, it's important to make sure each team focuses on their own priorities in terms of what their goals are. The overall goal of the business must remain in sight, though, and metrics can help ensure that the goal is tracked.</p>
			<p>For this scenario, our <a id="_idIndexMarker182"/>large organization is looking to increase the pace of development and release across the board. Of course, as we discussed earlier in the chapter, this cannot be at the expense of stability.</p>
			<p>Their challenge from a DevOps perspective is changing ways of working that have been carried out in a legacy fashion for a number of years, and some red tape exists that makes the process changes difficult and slow.</p>
			<p>Let's now look at the metrics they can use to ensure the wider outcome of increased pace is achieved, while keeping an eye on stability, as follows:</p>
			<ul>
				<li><strong class="bold">Lead time</strong>—Understanding how quickly things are dealt with from the backlog is important, especially in environments where teams are looking to pivot quickly and improve results. This can help you understand what you need to do in terms of making sure your processes are lean.</li>
				<li><strong class="bold">Deployment frequency</strong>—Where the goal is to improve the release cadence, this metric is a must. You can understand how often you deploy, and do this in conjunction with other metrics here. Make sure that is not just a number but a number of quality releases.</li>
				<li><strong class="bold">Change failure rate</strong>—Mistakes happen, especially in fast-moving environments. We can use this metric to help all teams understand if the releases they are <a id="_idIndexMarker183"/>doing are of high quality, not in terms of functionality but through adherence to the existing change management policies in place as they change the way they deploy. </li>
				<li><strong class="bold">Number of hotfixes</strong>—It's OK to release hotfixes; they're a staple of the development life cycle. Tracking the number of hotfixes can help teams understand stability, but can also evaluate quality in parallel. It's a really useful metric to use in fast environments looking for quick change, but as discussed previously, mistakes can happen.<p class="callout-heading">Important note</p><p class="callout">In these types of organizations, it can easily be the case that teams go their own way. Keeping them stitched together in terms of the overall goal is tricky, but finding common metrics can help explain that. Teams may have the same metrics, but leading and lagging indicators may be different based on products or acumen.</p></li>
			</ul>
			<p>Let's now look at another small organization scenario, this time with an outsourced DevOps team.</p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor080"/>Scenario 4: Small organization with outsourced DevOps team</h2>
			<p>For some smaller organizations who are looking to reap the benefits that the adoption of DevOps can bring them, outsourcing can be used to enable a specialist third-party team to work with the organization to achieve a number of goals.</p>
			<p>This could be assistance with delivery, execution of agile methodologies, or support of environments and providing automation as part of the whole solution. Third parties can be used in numerous ways, and depending on the size of the organization and their requirements, this will change the scope of the third-party involvement.</p>
			<p>For our small organization, a big focus for them is around the need to provide higher levels of automation, especially <a id="_idIndexMarker184"/>around testing. This will really help them drive forward where they are with DevOps.</p>
			<p>Let's now look at the metrics we can use for this team, as follows:</p>
			<ul>
				<li><strong class="bold">Test automation coverage</strong>—Due to the size of the team, they have outsourced test automation. Use this metric to look at the coverage of automation provided, and build up this number over time.</li>
				<li><strong class="bold">Deployment failure rate</strong>—Deployment failure rates have many focuses, but this team has decided to look at failed testing gates. Using this metric will help the team understand what is failing, how often, and—through discovery—why it is happening.</li>
				<li><strong class="bold">Deployment downtime</strong>—In a similar way to the preceding metric, tracking the amount of downtime in deployments can help with your third-party interactions. This can help you both work on and improve the CI and CD pipelines within your organization as you do more.</li>
				<li><strong class="bold">Platform availability</strong>—Understanding how the third party is working within your environment is critical. Understanding platform availability is essential, and holding them to account when they make mistakes that cause outages is something you would need to consider. This needs to be handled properly, with no aggressive tones and an attitude of working together to improve things rather than penalizing.</li>
			</ul>
			<p>In all four scenarios, you could use various different metrics to measure yourself; however, that doesn't mean that some metrics are worse than others. It comes down to what you are trying to measure, and you measure what you are trying to improve overall.</p>
			<p>Now that we have looked at the <a id="_idIndexMarker185"/>various metrics you can use in different scenarios, what happens when you have multiple teams practicing, as in <em class="italic">Scenario 3</em>? How do you ensure that you report at an appropriate level? Let's look at the answers in the following section.</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor081"/>Creating rollups at an organizational level</h1>
			<p>Regardless of if you are <a id="_idIndexMarker186"/>practicing DevOps in your organization or not, clear communication is one of the keys to success. This is also true when it comes to communication <a id="_idIndexMarker187"/>of your <strong class="bold">key performance indicators</strong> (<strong class="bold">KPIs</strong>).</p>
			<p>You must ensure that the data you present back to leaders within your organization is clear, concise, and tells the appropriate picture about the performance within your organization.</p>
			<p>In DevOps, especially when you are communicating organization-wide progress, you will first have to go on a journey of explaining what the metrics mean to the wider business. It's not immediately obvious what the metrics mean and show.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Try to display clear wording to executive leaders, even if this means changing the explanation of the metric. It's easier to relate it to something they understand than having to face questions on how it's measured, why you measure it, and more in executive meetings.</p>
			<p>Another critical factor in DevOps, especially when measuring velocity, is to understand that not all teams are equal. Even from the inside, when it appears teams are delivering very similar things, the way they work and the way they operate as a team means the velocity of both teams is unlikely to be a comparable metric.</p>
			<p>For this reason, I would <em class="italic">never</em> recommend comparing teams by using plain metrics such as velocity measured in <strong class="bold">story points</strong>. Teams can use this metric internally to see how effective they are at planning the work assigned to them and, throughout sprints, use the output from the previous sprint to see how they perform and where they can be better at planning.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">If you are using story points to measure velocity of completed user stories, never make this metric public on executive dashboards.</p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor082"/>Reporting when multiple teams work on one product</h2>
			<p>If your organization has multiple teams working on one product and each team is responsible for a different part of the product, then creating a rollup is quite simple. As with any project, you would report the overall progress against any plans. The same can be said in this scenario.</p>
			<p>Each individual team may be <a id="_idIndexMarker188"/>working on individual features and requirements from different business analysts, but they will be working for—and aligned to—one common goal. For that reason, you need to understand what the end goal looks like, and from there you can create metrics that measure that goal.</p>
			<p>This style is what might be known as an executive scorecard, or sometimes a business scorecard. It lists out the KPIs that show if you are on a path to success, or if blockers are in your way.</p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor083"/>Reporting when multiple teams work on multiple products</h2>
			<p>When you have multiple teams working on multiple products, you can employ similar tactics to those outlined previously. Think of each product team as one, and create reports that reflect the work done by that team on that product.</p>
			<p>Remember the previous discussion: no two teams are equal, and the same is said regardless of whether they are in the same product group or different product groups. Be careful not to compare teams across different products, even if they are working on the same deliverable, just in different products.</p>
			<p>Depending on your organization, your multiple products may be completely unrelated, in which case it does not make any sense to create reporting that rolls up performance to a higher level.</p>
			<p>If, for example, you are an organization that has products related to one another by a higher piece of marketing (maybe your organization has an overarching product that is actually made up of numerous products), then try where you can to align your reporting to that top level.</p>
			<p>It is the top level that is understood across the business, so when it comes to reporting the velocity, quality, or stability metrics we discussed earlier in the chapter, make sure they relate to the highest level you can go that makes practical sense.</p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor084"/>Creating goals that are S.M.A.R.T</h2>
			<p>Creating goals for your product or taking goals from an executive level and then disseminating them down to your team to be more actionable chunks of work can be a difficult task.</p>
			<p>Within your department, you <a id="_idIndexMarker189"/>may need to break up a higher-level goal into more manageable goals between different teams. This is when the collaboration and communication with DevOps comes into its own. When one larger goal is split into numerous goals for smaller teams, working together and speaking to each other is critical in ensuring you achieve the fundamental task.</p>
			<p>A common tool in the business world for <a id="_idIndexMarker190"/>setting measurable and achievable goals is using the <strong class="bold">S.M.A.R.T</strong> method. If this isn't something you have heard of before, this is what it stands for:</p>
			<ul>
				<li><strong class="bold">Specific</strong></li>
				<li><strong class="bold">Measurable</strong></li>
				<li><strong class="bold">Achievable</strong></li>
				<li><strong class="bold">Realistic</strong></li>
				<li><strong class="bold">Timely</strong></li>
			</ul>
			<p>There are different versions of S.M.A.R.T. goals, but these are the definitions I prefer. It really means that to set a proper goal, it has to be something that answers the following five questions:</p>
			<ul>
				<li>What exactly do you want to do?</li>
				<li>How do you know when you have reached it?</li>
				<li>Is the goal within your power to achieve?</li>
				<li>Is it realistic that you can achieve this goal?</li>
				<li>When do you want to accomplish the goal?</li>
			</ul>
			<p>I have used this method many different times before, you can find a lot more details about this <a id="_idIndexMarker191"/>method from <em class="italic">Mind Tools</em> (<a href="https://www.mindtools.com/pages/article/smart-goals.htm">https://www.mindtools.com/pages/article/smart-goals.htm</a>).</p>
			<p>One easy example to follow is that you want to become trained in a specific tool—for example: <em class="italic">I want to understand how to create pipelines in Azure DevOps</em>. How would we now go about making this goal S.M.A.R.T.? Here's how:</p>
			<ul>
				<li><strong class="bold">Specific</strong>—I want to learn how to create <a id="_idIndexMarker192"/>pipelines using <strong class="bold">YAML Ain't Markup Language</strong> (<strong class="bold">YAML</strong>) in Azure DevOps.</li>
				<li><strong class="bold">Measurable</strong>—Ability to create working pipelines to deploy <em class="italic">Application X</em> without assistance <a id="_idIndexMarker193"/>from our <strong class="bold">subject-matter experts</strong> (<strong class="bold">SMEs</strong>).</li>
				<li><strong class="bold">Achievable</strong>—I need to learn how to build basic pipelines, then understand our own process so that I can learn appropriate items to add into the pipeline to complete the build.</li>
				<li><strong class="bold">Realistic</strong>—By using online videos, working with our experts, and taking online courses I am able to achieve this goal.</li>
				<li><strong class="bold">Timely</strong>—I will have achieved this in 6 months.</li>
			</ul>
			<p>When you use the <a id="_idIndexMarker194"/>model shown here, you provide clarity toward the goals you are trying to achieve, how you plan to achieve them, what you need to achieve them, and—finally—when you will achieve them.</p>
			<p>You may have multiple lines in a sheet describing your various goals, and you may use steps to describe the ways in which you will get there. The key is getting it down on paper.</p>
			<h1 id="_idParaDest-86"><a id="_idTextAnchor085"/>Summary</h1>
			<p>In this chapter, we have looked at some of the most common metrics you can use to measure success in DevOps and looked at ensuring the importance of defining what success looks like. We have looked through some scenarios of different teams, highlighting the metrics that can be used to track their success. Finally, we looked at how to ensure you track at an organizational level rather than focusing too much on individual teams.</p>
			<p>One of the biggest challenges in DevOps is measuring success. Using the skills you have learned in this chapter, you can implement meaningful goals and metrics to measure success in your organization.</p>
			<p>In the next chapter, we explore how you build a culture within DevOps and how to break down silos in your organization for maximum efficiency.</p>
		</div>
	</body></html>