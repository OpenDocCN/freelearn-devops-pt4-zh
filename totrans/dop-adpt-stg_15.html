<html><head></head><body>
		<div id="_idContainer045">
			<h1 id="_idParaDest-231"><em class="italic"><a id="_idTextAnchor230"/>Chapter 11</em>: Keeping Up with Key DevOps Trends</h1>
			<p>A number of different disciplines now exist that look to build upon the core principles and practices of DevOps and target different areas of the business, and even specific departments. Terms such as DataOps, GitOps, and DevSecOps are now common terminology in the industry and tooling exists for each of these, too. In this chapter, we look at some of these trends in more detail to understand what they are, what their goal is, and what tooling can be used.</p>
			<p>By the end of this chapter, you will understand some of the key trends associated with DevOps specialties, understand what they are, how they apply to organizations, and how tooling can be used within them.</p>
			<p>In this chapter, we're going to cover the following topics:</p>
			<ul>
				<li>What is XOps?</li>
				<li>Understanding the DataOps ecosystem</li>
				<li>Understanding the DevSecOps ecosystem</li>
				<li>Understanding the GitOps ecosystem</li>
			</ul>
			<h1 id="_idParaDest-232"><a id="_idTextAnchor231"/>What is XOps?</h1>
			<p><strong class="bold">XOps</strong> is a general catch-all term <a id="_idIndexMarker543"/>that describes the adoption of other forms of operations both inside and outside of technology. In this context, DevOps is really just the tip of the iceberg.</p>
			<p>DevOps is just the beginning. You can also include BizOps, FinOps, AIOps, and MarketingOps as a start, but the term <em class="italic">XOps</em> covers more than just the ones listed here. These are all cross-functional efforts, like DevOps is, but do organizations really need all of them, even some of them, or is the movement just hype?</p>
			<p>One thing we can all agree on is that all organizations are at their own stages of maturity. The factors for this include their size, age, industry, technical adoption, budgets, and, of course, culture.</p>
			<p>Organizations are increasingly requiring the benefits of what these different kinds of operation models provide. Some organizations will implement as many of them as possible, while some will implement what they need and even manipulate the processes and level of adoption to best fit with their organization.</p>
			<p>This does not mean that the <a id="_idIndexMarker544"/>results will be any different depending on the factors previously mentioned. As with DevOps, the key element that all of these models have in common is the focus on value, which is something unique to each organization.</p>
			<h2 id="_idParaDest-233"><a id="_idTextAnchor232"/>Where did XOps begin?</h2>
			<p>Some people <a id="_idIndexMarker545"/>believe that XOps is just hype, hype that will disappear, and that much of what is proposed is a relabeling of what already exists. You can say the same about DevOps as well, but it is the way that practices within DevOps are brought together and not left fragmented that delivers real value to organizations.</p>
			<p>Like DevOps, most of the types of operation models will look at the acceleration of the process and improvements in quality when it comes to what they deliver. For example, in DataOps, this would be data, and analytical insights into operations performance for AIOps.</p>
			<p>Those who believe that XOps is overhyped believe that the risk is that fragmentation is created by the different groups that are involved. This fragmentation further dilutes the faster value that is created and creates a level of additional bureaucracy.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Agility has been at the heart of XOps since the turn of the millennium. Business leaders have since been aware that their organizations need to be more Agile in order to stay competitive in their industry.</p>
			<p>Agile practices that form part of XOps have been around for some time and have been rising further up the business stack for some time. Sadly, some leaders take the view that agility will equal the ability to do more with less.</p>
			<p>The truth is that fundamentally, agility backed up with solid processes provides your organization with the ability to scale when needed, deliver more value to your end users, improve your processes, and your efficiency.</p>
			<p>The link between XOps and DevOps is not just in the similarities in names, approaches to achieving the gold standard, or the processes involved. Culture is an important part of DevOps, specifically regarding the ability to improve your communication and collaboration in your organization.</p>
			<p>Other important aspects <a id="_idIndexMarker546"/>that XOps takes from DevOps is the focus on continuous improvement, as well as the focus on the automation of tasks. Technical staff often forget that process automation does not just have to be on technical elements of the process. After all, business process automation was around long before DevOps was conceived.</p>
			<h2 id="_idParaDest-234"><a id="_idTextAnchor233"/>Understanding the XOps landscape</h2>
			<p>To understand <a id="_idIndexMarker547"/>the XOps landscape further, let's look at two of the common initiatives in XOps, which are FinOps and CloudOps. We will learn about DataOps, DevSecOps, and GitOps in more detail later in this chapter.</p>
			<h3>FinOps</h3>
			<p>FinOps is also known as <a id="_idIndexMarker548"/>Cloud Financial Management, and it is the amalgamation of finance and operations teams within an organization. Specifically, FinOps <a id="_idIndexMarker549"/>focuses on the processes involved in managing financial operations while linking together the people involved, the processes, and, of course, the technology.</p>
			<p>The need for FinOps arises from the traditional financial model in IT, which worked separately from other teams and lacked a level of data-driven decision making and technical modernization for managing scalable, cloud-enabled applications.</p>
			<p>Limitations regarding the lack of flexibility concerning business requirements only inflated the costs, which make the system slow moving and more expensive. As a result of this, organizations needed to come up with a method for providing cost control for their highly scalable cloud environments, understand what those costs are, how they are occurring, and keep track of their cloud spend.</p>
			<p>As the cloud has evolved, so has the need for the ability to provide chargeback of services hosted in cloud environments for other parts of the organization. The granular costs involved with cloud computing have made the idea of chargeback simpler in many ways, but it is actually hard to implement.</p>
			<p>Complexities around how to bill for shared services such as network and storage make it difficult to realize how these costs can be charged back to various departments. These fabric-level services, or core services, are often consumed by the technology department, while application services are charged back to cost centers.</p>
			<p>To have robust practices <a id="_idIndexMarker550"/>regarding FinOps, it is important to follow three phases of adoption. These phases are inform, optimize, and operate. The first phase, <em class="italic">inform</em>, looks at a <a id="_idIndexMarker551"/>detailed assessment of assets, budget allocation, and providing an understanding of industry standards to detect areas of improvement.</p>
			<p>The second phase, <em class="italic">optimize</em>, helps to set alerts and metrics that identify any areas that need to both spend and redistribute resources. These generate decision-making capabilities and provide recommendations on architecture changes where required.</p>
			<p>The final phase, <em class="italic">operate</em>, assists in tracking costs and cost control mechanisms at a resource level. FinOps provides a level of flexibility in operations, but maintains financial accountability to the variable costs that are associated with cloud platforms.</p>
			<h3>CloudOps</h3>
			<p>CloudOps is the <a id="_idIndexMarker552"/>process of <a id="_idIndexMarker553"/>defining and identifying operational procedures, which are appropriate to optimizing services within cloud environments. CloudOps is a bringing together of DevOps and traditional operations allowing cloud platforms, applications, and data to provide further technical strengthening while maintaining services.</p>
			<p>For organizations to accelerate agility any further, they must keep a check on any budget constraints, such as waste and overrun. This is one of the reasons why organizations decide to move to cloud platforms for their workloads.</p>
			<p>CloudOps provides predictability and proactiveness and helps enhance visibility and governance. In maintaining on-premises locations, the associated power, network, storage, and high availability are always a challenge. This is easier in the cloud even though challenges remain, but those challenges differ from on-premises.</p>
			<p>Since CloudOps is an extension of DevOps, it aims to build cloud operations teams that are responsible for post-migration applications on cloud platforms. Governance tools that optimize costs, enhance security posture, and provide capacity planning are essential in CloudOps. It also promotes the notion of continuous monitoring as well as the management of cloud applications with smaller numbers of resources.</p>
			<p>Automation provides techniques to increase the agility, speed, and performance of cloud applications. Automation in CloudOps also facilitates the handling of services, incidents, and problems in a <a id="_idIndexMarker554"/>smooth manner. Combining elements of <a id="_idIndexMarker555"/>DevOps such as continuous integration and continuous deployment with infrastructure services and introducing infrastructure as code provides high levels of automation, increases the value of CloudOps, and provides level scalability not previously seen by operations teams.</p>
			<h2 id="_idParaDest-235"><a id="_idTextAnchor234"/>Approach to XOps</h2>
			<p>Let's look at an <a id="_idIndexMarker556"/>example approach to XOps. The objective is to transform what is currently a monolithic application into a microservice architecture. Additionally, the migration process should be automated, along with separate environments for production, UAT, and test.</p>
			<p>The primary identity should be managed by the DevOps team. This allows you to manage users and groups as well as third-party services and applications. This approach advocates collaborative culture.</p>
			<p>Furthermore, to make resources modular, the team generates container-based modules for multiple resources, and stacks are then broken down, making them scalable and ensuring that deployment is easier.</p>
			<p>Maintenance and debugging with this approach become simpler for development teams as well, and automated processes help enhance code quality. Role-based access control ensures secure authentication and authorization.</p>
			<p>The deployment of centralized systems for logging and monitoring allows views of performance, availability, and security on centralized dashboards. This helps to provide cost-effectiveness and improve the performance of the application.</p>
			<p>Here, we have discussed a number of disciplines, such as DevOps, CloudOps, and FinOps, to make this happen.</p>
			<p>We now have an understanding of the term <em class="italic">XOps</em>. We understand where XOps came from and the landscape of XOps. Let's now look at the DataOps ecosystem in more detail.</p>
			<h1 id="_idParaDest-236"><a id="_idTextAnchor235"/>Understanding the DataOps ecosystem</h1>
			<p>One of the <a id="_idIndexMarker557"/>most common misconceptions around DataOps is that under the covers, it is just DevOps applied to data analytics. While the name shares similarities with both DevOps and DataOps, they're not the same.</p>
			<p>Look at the following diagram, which depicts the DevOps loop:</p>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="image/B17192_11_01.jpg" alt="Figure 11.1 – Graphic showing the phases of DevOps in an infinite loop&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.1 – Graphic showing the phases of DevOps in an infinite loop</p>
			<p>DevOps is often depicted as an infinite loop. As you can see in the previous diagram, DataOps is different. When illustrating DataOps, it is shown as an intersection of value and innovation pipelines, as you can see in the following diagram:</p>
			<div>
				<div id="_idContainer043" class="IMG---Figure">
					<img src="image/B17192_11_02.jpg" alt="Figure 11.2 – DataOps depiction showing a value pipeline along the top and innovation from bottom to top&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.2 – DataOps depiction showing a value pipeline along the top and innovation from bottom to top</p>
			<p>DataOps communicates that <a id="_idIndexMarker558"/>data analytics can achieve what DevOps accomplished for software development. That is, when data teams use new tools and methodologies, DataOps can result in an order of magnitude improvement in quality and cycle time. The specific methods by which DataOps achieves these gains reflect the distinct people, processes, and tools that characterize data teams.</p>
			<p>The Agile methodology is particularly useful in environments where requirements evolve quickly and often change. This is a situation that data professionals will understand all too well. Like in DevOps, Agile in DataOps allows organizations to respond very quickly to requirements and accelerate the time to value.</p>
			<p>DataOps is also as much about managing people as it is about the tools. The needs and preferences of stakeholders are one subtle difference between DataOps and DevOps.</p>
			<p>In DevOps, our users are software engineers and operations engineers who are comfortable with coding, the complexity involved with multiple languages in one environment, as well as hardware and software. However, in DataOps, our users are data scientists, engineers, and analysts who analyze data and build complex data models.</p>
			<p>DevOps was developed to meet the needs of software developers. Dev engineers enjoy coding and are technologically savvy. Learning a new language or deploying a new tool is an opportunity, not a burden. They take a keen interest in all aspects of code creation, integration, and deployment. DevOps welcomes complexity.</p>
			<p>DataOps users are <a id="_idIndexMarker559"/>frequently the polar opposite of that. They are data scientists or analysts who specialize in the development and deployment of models and visualizations. Engineers are typically more technically savvy than scientists and analysts. They concentrate on domain expertise. They are interested in making models more predictive or determining the best way to visually render data.</p>
			<p>The technology used to create these models and visualizations is merely a tool. Data professionals are happiest when they only use one or two tools. Anything more adds unwelcome complexity. In the most extreme cases, the complexity exceeds their ability to manage it.</p>
			<p>DataOps recognizes that data professionals live in a multi-tool, heterogeneous world, and strives to make it more manageable for them.</p>
			<h2 id="_idParaDest-237"><a id="_idTextAnchor236"/>Understanding processes involved in DataOps</h2>
			<p>By examining <a id="_idIndexMarker560"/>data analytics development and life cycle processes, we can begin to understand the unique complexity that data professionals face. We discovered that data analytics professionals face challenges that are both similar to and distinct from those faced by software developers.</p>
			<p>In DevOps, the life cycle starts with the planning phase, and this feeds back to the beginning, which is the code phase. Hence, the process iterates indefinitely.</p>
			<p>The DataOps life cycle shares these iterative characteristics, but there is a significant difference: DataOps consists of two active and intersecting pipelines. The previously mentioned data factory is a single pipeline. The other pipeline governs how the data factory is updated, which includes the creation and deployment of new analytics into the data pipeline.</p>
			<p>The process by which new analytic ideas are introduced into the value pipeline is referred to as the innovation pipeline. Although the innovation pipeline conceptually resembles the <a id="_idIndexMarker561"/>DevOps development process, several factors make the DataOps development process more difficult than DevOps.</p>
			<h2 id="_idParaDest-238"><a id="_idTextAnchor237"/>Understanding tools involved in DataOps</h2>
			<p>To deliver a <a id="_idIndexMarker562"/>reliable data pipeline, the tooling to directly and indirectly support DataOps needs can be broken down into five steps, leveraging existing analytics tools along with toolchain components meant to address source control management, process management, and efficient communication among groups:</p>
			<ul>
				<li>Source control management</li>
				<li>Automation of processes and workflow</li>
				<li>Adding data and logic tests</li>
				<li>Working without fear with consistent deployment</li>
				<li>Implementing communication and process management</li>
			</ul>
			<p>Now, let's provide a little more detail regarding these five steps.</p>
			<h3>Source control management</h3>
			<p>A data pipeline is <a id="_idIndexMarker563"/>nothing more than source code that is responsible for converting raw data into usable information. We can automate the data pipeline from start to finish, resulting in reproducible source code. A revision control tool (such as GitHub) aids in the storage and management of all changes to code and configuration in order to reduce inconsistent deployment.</p>
			<h3>Automation of processes and workflow</h3>
			<p>Automation is essential for the <a id="_idIndexMarker564"/>success of the DataOps methodology, which necessitates the design of a data pipeline with runtime flexibility. Automated data curation services, metadata management, data governance, master data management, and self-service interaction are critical requirements for achieving this.</p>
			<h3>Adding data and logic tests</h3>
			<p>To ensure that the <a id="_idIndexMarker565"/>data pipeline is working properly, inputs, outputs, and business <a id="_idIndexMarker566"/>logic must be tested. To ensure consistent data quality, the data pipeline is tested at each stage for accuracy or potential deviation, as well as errors or warnings.</p>
			<h3>Working without fear with consistent deployment</h3>
			<p>Data analytics <a id="_idIndexMarker567"/>professionals are terrified of introducing changes that will disrupt the current data pipeline. This can be addressed with two key workflows that will be integrated later in production. For starters, the value pipeline generates ongoing value for organizations. Second, the innovation pipeline consists of new analytics in the development stage that are later added to the production pipeline.</p>
			<h3>Implementing communication and process management</h3>
			<p>Within a <a id="_idIndexMarker568"/>DataOps practice, efficient and automated notifications are critical. When changes are made to any source code, or a data pipeline is triggered, failed, completed, or deployed, the appropriate stakeholders can be immediately notified. The toolchain also includes tools for facilitating cross-stakeholder communication (think Slack or Trello).</p>
			<p>We now have an understanding of what DataOps is, what it tries to achieve when implemented correctly, as well as an understanding of the processes and tooling involved in the DataOps life cycle. Now, let's look at the DevSecOps ecosystem.</p>
			<h1 id="_idParaDest-239"><a id="_idTextAnchor238"/>Understanding the DevSecOps ecosystem</h1>
			<p><strong class="bold">DevSecOps</strong> is a <a id="_idIndexMarker569"/>software industry culture shift that aims to incorporate security into the rapid-release cycles typical of modern application development and deployment, also known as the DevOps movement. Embracing this shift-left mindset necessitates organizations bridging the gap that typically exists between development and security teams, to the point where many of the security processes are automated and handled by engineering teams.</p>
			<p>The following diagram helps depict how security fits into the existing DevOps loop:</p>
			<div>
				<div id="_idContainer044" class="IMG---Figure">
					<img src="image/B17192_11_03.jpg" alt="Figure 11.3 – Diagram showing the interaction between DevOps and DevSecOps&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.3 – Diagram showing the interaction between DevOps and DevSecOps</p>
			<p>Historically, major <a id="_idIndexMarker570"/>software developers would release new versions of their applications every few months, if not years. This gave the code enough time to go through quality assurance and security testing, which was handled by separate specialized teams, either internal or externally contracted.</p>
			<p>However, the last 10 years have seen a rise in public clouds, containers, and the microservice model, which divides monolithic applications into smaller parts that run independently. This breakdown has also had a direct impact on the way software is developed, resulting in rolling releases and Agile development practices in which new features and code are constantly pushed into production at a rapid pace.</p>
			<p>DevSecOps combines DevOps and SecOps to form a cyclical practice for software development, technology operations, and cybersecurity.</p>
			<p>DevSecOps aims to promote the rapid development of a secure code base. Rather than emphasizing development speed or security, the DevSecOps methodology assists developers and security professionals in striking a healthy balance. The use of an Agile framework allows development and security teams to collaborate continuously.</p>
			<p>DevOps and DevSecOps methodologies are similar in many ways, including the use of automation and continuous processes to establish collaborative development cycles. While DevOps promotes delivery speed, DevSecOps promotes security.</p>
			<p>DevSecOps practices may <a id="_idIndexMarker571"/>initially increase development time, but they will ensure that the code base is secure from the start. After some practice, and once security has been fully integrated into the development process, teams will benefit from increased writing and delivery speed for secure code bases.</p>
			<h2 id="_idParaDest-240"><a id="_idTextAnchor239"/>Understanding processes involved in DevSecOps</h2>
			<p>Many of the <a id="_idIndexMarker572"/>processes involved in DevSecOps are not new. Your organization will hopefully be practicing them already. The main difference will be that current processes may not be optimal for use in a DevSecOps environment.</p>
			<p>A good starting point to <a id="_idIndexMarker573"/>look at what needs to be changed in your processes is to look at the <em class="italic">DevSecOps manifesto</em> (<a href="https://www.devsecops.org">https://www.devsecops.org</a>). In a similar way to the Agile manifesto, the DevSecOps manifesto lays out nine points to mature your information security practice. These are as follows:</p>
			<ul>
				<li>Leaning in over and always saying no</li>
				<li>Data and security science over fear, uncertainty, and doubt</li>
				<li>Open contribution and collaboration over security-only requirements</li>
				<li>Consumable security services with APIs over mandated security controls</li>
				<li>Business-driven security scores over rubber stamp security</li>
				<li>Red and blue team exploit testing over relying on scans and theoretical vulnerabilities</li>
				<li>24x7 proactive monitoring over reacting</li>
				<li>Shared threat intelligence over keeping information to ourselves</li>
				<li>Compliance operations over clipboards and checklists</li>
			</ul>
			<p>You can see that most of what the manifesto lays out involves the maturity of your existing investments in information security and goes a long way to retracting some of the negative connotations that have become attached to information security over the years.</p>
			<p>DevSecOps is hard, but <a id="_idIndexMarker574"/>when done well, you can significantly improve your security posture, as well as your understanding of security within your organization. To shift to the DevSecOps way of thinking, these five steps should be followed:</p>
			<ol>
				<li>DevSecOps is a cultural change.</li>
				<li>Align practices with the development workflow.</li>
				<li>Demonstrable evidence that security keeps pace with velocity.</li>
				<li>Change from prevention to detection.</li>
				<li>Use the security budget to support the development workflow.</li>
			</ol>
			<p>Let's have a look at the further five steps to understand the implementation.</p>
			<h3>DevSecOps is a cultural change</h3>
			<p>Adopting a DevSecOps approach will be a massive undertaking for most businesses, so be mindful of how significant a cultural shift it is. Start a conversation, be brave, and be the one to take the first step toward change. It will be easier to find common ground and reach an agreement if you engage in a clear and simple manner that highlights the business, efficiency, and security benefits for each organization.</p>
			<h3>Align practices with the development workflow</h3>
			<p>It is critical that when you engage in discussions with development teams, you do not bring your current security practices to the table and expect them to change the way they develop code.</p>
			<p>Obviously, you should not disregard your security needs in terms of monitoring, risk assessment, and so on, but you must be willing to change your security practices to align with the development workflow. If you tried to base your DevSecOps approach on how you traditionally approach security, the entire speed and cadence of your production releases would stall.</p>
			<h3>Demonstrable evidence that security keeps pace with velocity</h3>
			<p>Your development, operations, or DevOps teams will most likely be hesitant to welcome your security teams or professionals into their <em class="italic">way of doing things</em>. You can overcome this hesitance by offering visibility and monitoring services, as well as collaborating to map your processes and identify opportunities to support agility.</p>
			<p>Early on, you should be less <a id="_idIndexMarker575"/>concerned with enforcement, blocking activities, and slowing down the pipeline, and more concerned with demonstrating that security can keep up with the velocity with which your development teams are building so much product to ensure that the pipeline runs smoothly.</p>
			<h3>Change from prevention to detection</h3>
			<p>Once security has established itself in the development workflow, you can consider shifting from a monitoring and visibility role to proactively identifying vulnerabilities in code. The security team can become the development team's best friend in this situation.</p>
			<h3>Using your security budget to support the development workflow</h3>
			<p>Finally, consider your own security budget. Are there any areas where you can redirect some security budget to that workflow pipeline as you change your practices to align with the development workflow? This demonstrates your commitment to the sustainability of security in every release by devoting additional resources to the continuous integration and continuous deployment pipeline.</p>
			<h2 id="_idParaDest-241"><a id="_idTextAnchor240"/>Understanding tools involved in DevSecOps</h2>
			<p>As DevSecOps is <a id="_idIndexMarker576"/>closely aligned from a process perspective with the DevOps life cycle, the tooling involved in DevSecOps closely aligns with the flow of the DevOps life cycle. The tooling in DevSecOps therefore lines up with the eight different phases of DevOps. These are the phases, along with common security tooling and processes, that you might find at each point:</p>
			<ul>
				<li><strong class="bold">Plan</strong>: Threat modeling</li>
				<li><strong class="bold">Code</strong>: Static analysis and code review</li>
				<li><strong class="bold">Build</strong>: Penetration testing</li>
				<li><strong class="bold">Test</strong>: Compliance validation</li>
				<li><strong class="bold">Release</strong>: Logging</li>
				<li><strong class="bold">Deploy</strong>: Auditing</li>
				<li><strong class="bold">Operate</strong>: Threat intelligence</li>
				<li><strong class="bold">Monitor</strong>: Detect, respond, recover</li>
			</ul>
			<p>Next, let's have a look at <a id="_idIndexMarker577"/>some of these in more detail to understand some specifics regarding the tooling used.</p>
			<h3>Threat modeling</h3>
			<p>Unfortunately, threat modeling has <a id="_idIndexMarker578"/>long been regarded as a time-consuming and labor-intensive activity. As a result, as organizations adopt a DevSecOps approach, threat modeling is frequently left out of the security practices employed. However, the importance of thread modeling in development should not be underestimated.</p>
			<p>According to the <em class="italic">2020 DevSecOps Insights Report</em> (<a href="https://snyk.io/wp-content/uploads/dso_2020.pdf">https://snyk.io/wp-content/uploads/dso_2020.pdf</a>), threat modeling has a significant positive impact on a team's overall confidence in their code's security.</p>
			<p>At its core, threat modeling is intended to examine planned software to identify what might go wrong if an attacker targets that software. The purpose of this analysis is to inform the development team about which security controls should be considered as part of their implementation. Traditionally, threat modeling has been done with a broad scope across the entire application context. As part of this process, data flow diagrams, detailed threat analysis frameworks, and prescriptive threat prioritization methodologies are frequently used.</p>
			<h3>Static analysis</h3>
			<p>Static analysis tools, or <strong class="bold">Static Application Security Testing</strong> (<strong class="bold">SAST</strong>), work <a id="_idIndexMarker579"/>well with almost any software <a id="_idIndexMarker580"/>automation toolchain, as well as any development methodology and process. This is primarily because they can be used locally by developers at their desktop for instantaneous feedback and to analyze a complete build, whether it is done hourly or at whatever other cadence.</p>
			<p>Furthermore, because they do not require interaction with testers or developers, SAST tools are completely autonomous. They are useful whenever it is necessary to check the code for bugs and security vulnerabilities.</p>
			<p>Although not a panacea <a id="_idIndexMarker581"/>when used alone, these tools should be used in tandem with other automation tools. As software teams begin to integrate security into their DevOps processes, tools <a id="_idIndexMarker582"/>such as <em class="italic">SonarQube</em> (<a href="https://www.sonarqube.org">https://www.sonarqube.org</a>) are simple to implement and integrate into the automation pipeline. By detecting vulnerabilities early and preventing them from entering later in the development cycle, the pipeline pays off in reducing security fixes later.</p>
			<h3>Penetration testing</h3>
			<p>While automated tools in <a id="_idIndexMarker583"/>your pipeline can go a long way to detecting many different vulnerabilities, you will likely still have a need for penetration testing tools. Traditionally speaking, penetration testing is an art and a science in many ways. You would be forgiven for thinking that penetration testing and the focus on speed, frequency, and repeatability with DevOps would mean DevOps and penetration testing are juxtaposed.</p>
			<p><em class="italic">BreachLock</em> (<a href="https://www.breachlock.com">https://www.breachlock.com</a>), for example, can be <a id="_idIndexMarker584"/>fully integrated into a DevOps environment by performing end-to-end security testing for your product, ensuring the speed, reliability, and consistency of your development process.</p>
			<h3>Threat intelligence</h3>
			<p>Visibility for threat intelligence grows as <a id="_idIndexMarker585"/>more components of the environment are defined and documented in code. Many organizations struggle to identify their IT assets in such a way that threat intelligence can be effectively linked to the assets in their environment. By ensuring that processes are in place to feed metadata from the DevSecOps pipeline to threat intelligence capabilities, the organization can ensure that the right intelligence is gathered and applied, and responded to in a risk-prioritized manner.</p>
			<p>We now have an understanding of what DevSecOps is, what it tries to achieve when implemented correctly, as well as an understanding of the processes and tooling involved in the <a id="_idIndexMarker586"/>DevSecOps life cycle. Now, let's look at the GitOps ecosystem.</p>
			<h1 id="_idParaDest-242"><a id="_idTextAnchor241"/>Understanding the GitOps ecosystem</h1>
			<p>GitOps is a technique for <a id="_idIndexMarker587"/>implementing continuous deployment in cloud-native applications. It focuses on providing a developer-centric experience when operating infrastructure by utilizing tools that developers are already familiar with, such as Git and continuous deployment tools.</p>
			<p>The core concept of GitOps is to have a Git repository that always contains declarative descriptions of the infrastructure that is currently desired in the production environment, as well as an automated process to match the described state in the repository. If you want to deploy a new application or update an existing one, all you have to do is update the repository; the automated process will handle the rest. It's like having cruise control for managing your production applications.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">While we are specifically talking about Git, you can use any source control repository to achieve the same results.</p>
			<p>GitOps provides a complete history of how your environment has changed over time. This makes error recovery as simple as running <strong class="source-inline">git revert</strong> and watching your environment restore itself.</p>
			<p>GitOps enables you to manage deployments entirely from within your environment. Your environment only requires access to your repository and image registry for this purpose. That is all there is to it. You are not required to grant your developers direct access to the environment.</p>
			<p>When you use Git to store complete descriptions of your deployed infrastructure, everyone on your team can see how it evolves over time. With excellent commit messages, anyone can easily reproduce the thought process of changing infrastructure and find examples of how to set up new systems.</p>
			<p>The deployment process in GitOps is organized around code repositories as the central element. There are at least two repositories, one for the application and one for the environment configuration. The application repository contains the application's source code as well as the deployment manifests used to deploy the application.</p>
			<p>The environment configuration <a id="_idIndexMarker588"/>repository contains all deployment manifests for a deployment environment's currently desired infrastructure. It specifies which applications and infrastructure services should be run in the deployment environment and with what configuration and version.</p>
			<p>GitOps is a highly effective workflow pattern for managing modern cloud infrastructure. Despite its primary focus on Kubernetes cluster management, the DevOps community is applying and publishing GitOps solutions to non-Kubernetes systems. GitOps can benefit an engineering team in a variety of ways, including improved communication, visibility, stability, and system reliability.</p>
			<h2 id="_idParaDest-243"><a id="_idTextAnchor242"/>Understanding processes involved in GitOps</h2>
			<p>The great thing about <a id="_idIndexMarker589"/>GitOps is that you don't need to be doing anything differently. If you are already writing infrastructure as code and you store your code in a repository, then you are almost there already.</p>
			<p>The hardest thing is moving from an imperative method of deployment to a declarative method of deployment. Infrastructure as code promotes a declarative approach to system administration, which has led to the development of tools such as Ansible, Terraform, and Kubernetes, which all use static files to declare configuration.</p>
			<p>Consider the following imperative statements, which are steps for deploying an application:</p>
			<ol>
				<li value="1">Install the operating system.</li>
				<li>Install these dependencies.</li>
				<li>Download the application from this URL.</li>
				<li>Move the application to this directory.</li>
				<li>Repeat this thrice on three other servers.</li>
			</ol>
			<p>The declarative version of this would simply be something like <em class="italic">Four machines have an application from this URL, installed at this directory</em>. Instead of a sequence of commands, declarative software follows a declaration of an expected state.</p>
			<p>A pipeline platform is required to complete a full GitOps installation. Some popular pipeline tools that complement GitOps include Jenkins, Azure DevOps pipelines, and CircleCI. Pipelines automate and connect Git pull requests to the orchestration system. Commands are sent to the orchestration piece after pipeline hooks are established and triggered by pull requests.</p>
			<p>The processes involved in <a id="_idIndexMarker590"/>GitOps are therefore not really that much different from the same phases involved in the software development life cycle. Those processes define how code should be stored, what language should be used, who should review, how pipelines should be built, and where those pipelines are executed.</p>
			<p>To achieve GitOps, you can extend what you already do in DevOps for software engineering and apply it to the infrastructure world.</p>
			<h2 id="_idParaDest-244"><a id="_idTextAnchor243"/>Understanding tools involved in GitOps</h2>
			<p>As we touched on in the <a id="_idIndexMarker591"/>previous section, two tools are required to get started with GitOps. These tools are version control in the form of Git, as well as a tool to build and execute pipelines.</p>
			<p>Git is the design center in the GitOps pipeline model. It serves as the source of authority for everything in the system, from code to configuration, and the entire stack. Building deployable artifacts necessitates the use of continuous integration, build, and test services. However, in the GitOps pipeline, the overall delivery orchestration is coordinated by the deployment and release automation system, which is triggered by repository updates. To summarize, continuous deployment, not continuous integration, owns delivery orchestration. It is a very subtle shift in how pipelines work from the software development life cycle. Any continuous integration provider should be able to adopt this model.</p>
			<h1 id="_idParaDest-245"><a id="_idTextAnchor244"/>Summary</h1>
			<p>In this chapter, we have looked at XOps in detail as well as at the various operating models that are available. We have looked at DevSecOps, DataOps, and GitOps in further detail to understand their origins, benefits, processes, and tooling, looking at how this differs from DevOps.</p>
			<p>In the next chapter, we look to bring together everything we have learned so far, review some key learnings, and walk through an example implementation of DevOps using an example organization, listing their challenges, what can be done to resolve these challenges, and finally how to implement those changes.</p>
			<h1 id="_idParaDest-246"><a id="_idTextAnchor245"/>Questions</h1>
			<p>Let's now recap some of what we have learned throughout this chapter:</p>
			<ol>
				<li value="1">What does FinOps set out to achieve?<p>a) Manage financial operations in cloud platforms.</p><p>b) Set appropriate budgets.</p><p>c) Ensure accountability for consumption.</p><p>d) Increase agility.</p></li>
				<li>What differentiates DevOps and DataOps?<p>a) DataOps focuses on data and not software.</p><p>b) DataOps focuses on database management.</p><p>c) DataOps is not an iterative process like DevOps.</p><p>d) No difference; both are the same.</p></li>
			</ol>
		</div>
	</body></html>