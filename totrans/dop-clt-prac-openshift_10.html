<html><head></head><body>
		<div>&#13;
			<div id="_idContainer162" class="Content">&#13;
			</div>&#13;
		</div>&#13;
		<div id="_idContainer163" class="Content">&#13;
			<h1 id="_idParaDest-131">7. <a id="_idTextAnchor156"/>Open Technical Practices — The Midpoint</h1>&#13;
		</div>&#13;
		<div id="_idContainer205" class="Content">&#13;
			<p>In this chapter, we are going to build on the foundational technical practices that we started in the previous chapter. We will acquire a shared understanding of our software delivery pipeline using the Big Picture practice. Even the less technical team members will be able to follow what happens to our software as it is being written and delivered.</p>&#13;
			<p>We will then explain a technique that allows DevOps teams to deliver software changes using Git as the driving tool. The practice of GitOps leads to greater visibility of changes within our system, allowing the team to debug and resolve issues faster. We will explore how to improve our code quality through test automation and conclude this chapter by asking the question <em class="italics">How do we know if our architecture is good?</em></p>&#13;
			<p>This chapter will cover the following topics:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>The Big Picture</li>&#13;
				<li>GitOps</li>&#13;
				<li>Testing</li>&#13;
				<li>Emerging architecture</li>&#13;
			</ul>&#13;
			<h2 id="_idParaDest-132"><a id="_idTextAnchor157"/>The Big Picture</h2>&#13;
			<p>An Open Technical practice<a id="_idIndexMarker846"/><a id="_idIndexMarker847"/> that costs little to produce but is great in creating a shared understanding of part of a system is the Big Picture workshop. It is a simple practice used to visualize all the steps that a software pipeline goes through in moving code from source (for example, Git), through compile and test, and then into the hands of our happy users. Building it collaboratively is a great activity for a team to do as it helps to bridge the gap between techies and business folks. It's great for articulating the importance and sometimes the complexity of continuous delivery.</p>&#13;
			<div>&#13;
				<div id="_idContainer164" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_01.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.1: The Big Picture</p>&#13;
			<p>A Big Picture can easily be created with just some stickies and a clear board or space. Of course, if you're feeling more<a id="_idIndexMarker848"/><a id="_idIndexMarker849"/> artistic, it can also be doodled!</p>&#13;
			<div>&#13;
				<div id="_idContainer165" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_02.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.2: An example Big Picture</p>&#13;
			<p>You may be reading this and thinking <em class="italics">Sounds fluffy to me – why should I bother to make one?</em> Here's why:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li><strong class="bold">Shared understanding</strong>: When the <a id="_idIndexMarker850"/><a id="_idIndexMarker851"/>whole team collaborates around making the Big Picture, they get a shared sense of how their pipelines connect code to users.</li>&#13;
				<li><strong class="bold">Prototype quickly</strong>: It's cheaper to write and draw before implementing a single line of code! Rapidly prototype with some markers and Post-Its, moving stages of your pen and paper pipeline.</li>&#13;
				<li><strong class="bold">Complexity simplified</strong>: The Big Picture helps bring non-techies into the mix by showing them the components required to manage the software life cycle. Build it up one step at a time to demonstrate the complexity in a simple visual flow.</li>&#13;
				<li><strong class="bold">Information radiator</strong>: Like all these practices, the Big Picture is an evolving artifact. As the complexity of a software delivery pipeline grows, the Big Picture should be updated to reflect this. It is a graphic that can be displayed to all and should not be hidden.</li>&#13;
			</ul>&#13;
			<div>&#13;
				<div id="_idContainer166" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_03.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.3: Collaborating to get a shared understanding of the Big Picture</p>&#13;
			<p>Big Pictures can also be drawn using online <a id="_idIndexMarker852"/><a id="_idIndexMarker853"/>collaboration tools. We used Miro to draw the following digital Big Picture online.</p>&#13;
			<div>&#13;
				<div id="_idContainer167" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_04.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.4: A digital Big Picture</p>&#13;
			<p>The material<a id="_idIndexMarker854"/><a id="_idIndexMarker855"/> required for this practice is fairly simple: some stickies, marker pens, painters' tape, and a big blank wall or canvas are all that's required, and these are fairly common things to have in our kit bags! There are a number of simple steps to follow in creating your Big Picture, but let's use our PetBattle example to show how a team might use this in practice.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-133" class="Author-Heading"><a id="_idTextAnchor158"/>PetBattle – Building a Big Picture</h2>&#13;
			<p>The PetBattle Techies decided to build a Big Picture to demonstrate their proposal for how the software should be built, tested, and deployed via some automation. </p>&#13;
			<p>First, they invite all the others in the team to help explain some of the technology and complexity of the automation.</p>&#13;
			<p>They use painters' tape to form a large box that represents the cloud and another box inside it to represent the OpenShift cluster they're going to use (deployed in the cloud). In this case, the metaphor is: OpenShift is just a big box where we can put some things running in the cloud. The box is so large that we can fill it with all the things we could possibly want, from sandboxes, to tooling, to production apps.</p>&#13;
			<div>&#13;
				<div id="_idContainer168" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_05.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Figure 7.5: Starting the PetBattle Big Picture</p>&#13;
			<p>They draw a box to the left side to represent their local development environment. This is their laptop for now, but it could also be a cloud-hosted IDE that the development team could write their code in that is deployed inside the cluster. One such product, CodeReadyWorkspaces, is a cloud-hosted IDE that runs in the OpenShift cluster that could be of great use to the team. Using an IDE like this allows us to further our everything-as-code practice by providing developers with their coding environment as a code artifact.</p>&#13;
			<p>Next, they slice up the OpenShift cluster into smaller boxes. Each of these represents the OpenShift projects (or Kubernetes namespaces). We can think of these projects as rooms that separate one collection of applications from another. To keep things simple, the team decides <a id="_idIndexMarker856"/><a id="_idIndexMarker857"/>on four namespaces initially:</p>&#13;
			<div>&#13;
				<div id="_idContainer169" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_06.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Figure 7.6: PetBattle Big Picture projects</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li><strong class="bold">Dev</strong>: A sandbox project for the dev team to validate their app or get fast feedback from.</li>&#13;
				<li><strong class="bold">Test</strong>: A project to deploy all our <a id="_idIndexMarker858"/><a id="_idIndexMarker859"/>applications to and run our system tests against.</li>&#13;
				<li><strong class="bold">Production</strong>: The project that PetBattle's customers will use to access the applications once they've cleared our tests.</li>&#13;
				<li><strong class="bold">CI-CD</strong>: The project that houses all the tooling that supports <strong class="bold">Continuous Integration</strong> (<strong class="bold">CI</strong>) and <strong class="bold">Continuous Delivery</strong> (<strong class="bold">CD</strong>).</li>&#13;
				</ul>&#13;
				<p>With the OpenShift cluster logically sliced up into the projects the teams will use, the team draws the tools they will use in each project.</p>&#13;
				<div id="_idContainer170" class="IMG---Figure">&#13;
				<img src="../Images/B16297_07_07.jpg" alt=""/></div>&#13;
				<p>Figure 7.7: PetBattle Big Picture initial frameworks</p>&#13;
				<p>Starting with their <em class="italics">local</em> development environment – in other words, their laptops or <a id="_idIndexMarker860"/><a id="_idIndexMarker861"/>cloud-hosted workspace – the existing PetBattle is built using Angular (a JavaScript framework<a id="_idIndexMarker862"/><a id="_idIndexMarker863"/> for building web apps) for the frontend. Quarkus (supersonic Java) is used for the API layer, and MongoDB for the persistence layer, so they add each of these tools to their workspace and write a one-line definition for how the tool or framework is being used by this team.</p>&#13;
				<p>For PetBattle, we are going to use Helm to package up all the Kubernetes resources (Deployments, ConfigMaps, and so on) used to manage the application topology. We'll also use ArgoCD, a GitOps tool to manage our config-as-code.</p>&#13;
				<div id="_idContainer171" class="IMG---Figure">&#13;
				<img src="../Images/B16297_07_08.jpg" alt=""/></div>&#13;
				<p>Figure 7.8: PetBattle Big Picture source code and registry</p>&#13;
				<p>PetBattle will use GitHub to store its source code. When building images, it is likely the team will need to store the built image internally on the OpenShift cluster using the internal registry. The team also wants to make their images available externally and so have decided to also make use of <a href="http://Quay.io">Quay.io</a>, an external registry hosted in the public cloud.</p>&#13;
				<div id="_idContainer172" class="IMG---Figure">&#13;
				<img src="../Images/B16297_07_09.jpg" alt=""/></div>&#13;
				<p>Figure 7.9: PetBattle Big Picture pipeline tools</p>&#13;
				<p>The team then starts to add the tooling they will use to create their pipelines in their CI/CD namespace. They use more stickies to draw the tools and add a one-liner definition of what each tool is or how they will use it.</p>&#13;
				<p>For example, the team is going to use Jenkins for their build and test automation. To store and cache application build dependencies and artifacts, the team opted to use the open-source artifact repository called Nexus. For Nexus, they add a simple one-liner to highlight the fact that it is used to house their software artifacts as well as their Helm repository. Shared understanding is key here, so it's important for the team to make sure everyone is aware what the purpose of each item is – this includes the product owner, designers, and all other interested parties. They don't need to be experts, but having an understanding of what the tools are used for can help them establish <a id="_idIndexMarker864"/><a id="_idIndexMarker865"/>better empathy with the development team and see for themselves all the things needed to be able to ship code so quickly to users.</p>&#13;
				<p>With some of the tools in place on the Big Picture, the PetBattle team can now start to implement the design they've put in place.</p>&#13;
			&#13;
			</div>&#13;
			<p>The Big Picture can be<a id="_idIndexMarker866"/><a id="_idIndexMarker867"/> created in a physical room with lots of colorful sticky notes or with everyone distributed using a tool such as Mural, Miro, PowerPoint or Google Slides. We have provided a useful template with all the icons we use which should help you get started. You can download this from the book's GitHub repository.</p>&#13;
			<div>&#13;
				<div id="_idContainer173" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_10.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.10: The Big Picture template</p>&#13;
			<p>You can download this from the book's GitHub repository.</p>&#13;
			<p>The Big Picture allows us to get a shared understanding and team alignment around the use of technical tools at a high level. Like all the practices we put in place in this book, the Big Picture is not a one-time thing. The Big Picture is a tool we will revisit and enhance as we add more complexity to our architecture and begin implementing our pipelines. We will continue to explore the Big Picture in <em class="italics">Section 6, Build It, Run It, Own It</em>.</p>&#13;
			<p>You can learn more <a id="_idIndexMarker868"/><a id="_idIndexMarker869"/>about, and collaborate on, Big Picture practices by going to the Open Practice Library page at <a href="https://openpracticelibrary.com/practice/the-big-picture/">https://openpracticelibrary.com/practice/the-big-picture/</a>.</p>&#13;
			<h2 id="_idParaDest-134"><a id="_idTextAnchor159"/>GitOps</h2>&#13;
			<p>Up to this point, we've talked <a id="_idIndexMarker870"/><a id="_idIndexMarker871"/><a id="_idIndexMarker872"/><a id="_idIndexMarker873"/>about Git and the developer workflows available to our teams. We've spoken about everything-as-code, from infrastructure to tooling to applications all along the stack. Now, let's tie this all together with GitOps.</p>&#13;
			<p>GitOps sounds a bit like a buzzword, as DevOps was when it was first coined. In fact, we heard someone describe it to us as DevOps for the year 2020. GitOps is a simple process of managing all of your systems, environments, and applications via Git. Git represents the single source of truth for all your applications, your tooling, and even your clusters. Changes to any of these things can be pull requested and discussed before an automated process applies them.</p>&#13;
			<p>The difference between <strong class="bold">infrastructure-as-code</strong> (<strong class="bold">IaC</strong>) and <a id="_idIndexMarker874"/><a id="_idIndexMarker875"/>GitOps is the approach to managing the configuration. IaC is agnostic to where you store the configuration; it could be on a flash drive in your drawer or it could be a shared drive in the cloud. GitOps, as the name suggests, means storing the full system specifications in Git.</p>&#13;
			<p>The same principles hold true for IaC and GitOps – ideally, every action should be idempotent. Every action or operation can be applied multiple times, producing the exact same result. This is a very useful property in many situations, as it means that an operation can be repeated or retried as often as necessary without causing unintended effects. Configuration should be created declaratively. That is to say, you write the configuration to describe the desired state of an application or set of apps.</p>&#13;
			<p>GitOps can be seen as a developer-centric approach to Ops. It teaches developers good practices around taking ownership of code once it leaves their machines and the approach to deploying and monitoring this code once it's running.</p>&#13;
			<p>As developers, we hate repeating ourselves, so much so that we even have an acronym for it – DRY = don't repeat yourself! When encountering something that needs to be done more than once, our first instinct should be to try to automate it. Once something is automated or repeatable, the next step is simple. Check it into Git so that it can be audited, shared, and managed.</p>&#13;
			<p>For example, whenever we want to deploy a new application to OpenShift, we could run some manual commands to spin up the application, create services and routes, and even bind a ConfigMap. But taking the time to create a Helm chart for this is reusable and repeatable. We can design the final state of the application in code and then check this into Git instead. This is a <a id="_idIndexMarker876"/><a id="_idIndexMarker877"/>more cloud-native way of writing and managing our application code.</p>&#13;
			<p>To implement a <a id="_idIndexMarker878"/><a id="_idIndexMarker879"/>GitOps approach to our Helm chart example, all we need to do is connect a tool to the Git repository, which can be alerted or watch for changes coming through. When those changes arrive, this tool can assess the difference between what the current state is and what state is desired and apply the changes automatically for us. Enter ArgoCD.</p>&#13;
			<h3 id="_idParaDest-135"><a id="_idTextAnchor160"/>ArgoCD</h3>&#13;
			<p>From ArgoCD's website, this is<a id="_idIndexMarker880"/><a id="_idIndexMarker881"/> described as a tool that:</p>&#13;
			<p><em class="italics">automates the deployment of the desired application states in the specified target environments. Application deployments can track updates to branches, tags, or be pinned to a specific version of manifests at a Git commit</em>.<span id="footnote-029-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-029">1</a></span></p>&#13;
			&#13;
			<p>When something is seen as not matching the required state in Git, an application becomes out of sync. Depending on how you have implemented your GitOps, ArgoCD can then resync the changes to apply whatever is in Git immediately or fire a warning to initiate some other workflow. In the world of Continuous Delivery as implemented by ArgoCD, Git is the single source of truth, so we should always apply the changes as seen there.</p>&#13;
			<p>What types of things can ArgoCD apply? ArgoCD recognizes traditional Kubernetes YAML, Kustomize,<span id="footnote-028-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-028">2</a></span> Helm, and all sorts of other things. Unlike Helm, which uses templating heavily, Kustomize allows you to take YAML files and emits text in a template-free declarative way. You can patch Kubernetes resources and use folder-based structures to apply what is termed an overlay or YAML override, which emits text, leaving the original YAML untouched. For our purposes, we will stick to Helm and a little bit of Kustomize where appropriate.</p>&#13;
			&#13;
			<p>ArgoCD is another tool (and there are others like it, such as Flux) in the<a id="_idIndexMarker882"/><a id="_idIndexMarker883"/> long list of tools that we need to be able to implement CI and CD. Unlike Jenkins, which we could also use to manage our application deployments, ArgoCD is specialized and very good at managing and maintaining just our deployments.</p>&#13;
			<div id="footnote-029" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-029-backlink">1</a>	<a href="https://argo-cd.readthedocs.io/en/stable/">https://argo-cd.readthedocs.io/en/stable/</a></p>&#13;
			</div>&#13;
			<div id="footnote-028" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-028-backlink">2</a>	<a href="https://github.com/kubernetes-sigs/kustomize">https://github.com/kubernetes-sigs/kustomize</a></p>&#13;
			</div>&#13;
			<p>Jenkins could apply our Helm charts in a done once and finish sort of way. It doesn't have the capability to keep watching our Kubernetes resources to ensure the desired state in Git stays that way in our clusters. If someone decides to change something in the cluster, for example, add a new environment variable to a running application, ArgoCD will detect that change and overwrite it. This means no more one-of-a-kind deployments or manual tweaks once they're deployed.</p>&#13;
			<p>ArgoCD enables <a id="_idIndexMarker884"/><a id="_idIndexMarker885"/>teams to enforce this golden rule – if it's not in Git, it's not real. This is perfect for audit tasks – all you have to do is check the Git log to see who committed and pushed the code.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-136" class="Author-Heading"><a id="_idTextAnchor161"/>If It's Not in Git, It's Not Real!</h2>&#13;
			<div>&#13;
				<div id="_idContainer175" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/Author_21.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			<div>&#13;
				<div id="_idContainer174" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/Author_41.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			&#13;
			<p>We worked on a virtual residency with the<a id="_idIndexMarker886"/><a id="_idIndexMarker887"/> World Health Organization helping to manage the <a id="_idIndexMarker888"/><a id="_idIndexMarker889"/>COVID-19 crisis. We were building a new platform to help educate people in the field and disseminate information faster. We decided to use GitOps to do Continuous Delivery and, in particular, used ArgoCD to manage our Helm charts.</p>&#13;
			<p>To do cloud-native properly, namespaces <a id="_idIndexMarker890"/><a id="_idIndexMarker891"/>and environments should be ephemeral. We should be <a id="_idIndexMarker892"/><a id="_idIndexMarker893"/>able to recreate everything of use to us from their description in code. This includes namespaces, quotas, and role bindings, as well as applications and databases. To prove this in one sprint, we created a cleanup job that would delete the dev and test projects in OpenShift. Our configuration repository was linked to ArgoCD, which watched the cluster and, if anything changed, it was set to reapply the resources as described in Git. The time for this job to execute was on a Wednesday afternoon around lunchtime, about an hour before our sprint review. What could possibly go wrong?</p>&#13;
			<p>The team got ready to do their demo as normal, but about 20 mins before showtime, one team member called out<a id="_idIndexMarker894"/><a id="_idIndexMarker895"/> that the build was failing and his demo was broken and he could not figure out why. The team scrambled to sort the issue, with everyone jumping on a call and mobbing around the problem. Rewinding what could have changed in the past hour, the only thing that had executed was the cleanup job we had written. We immediately thought we'd written something incorrectly with our job and so went to debug it, but it was fine. The next step was to look more closely at the build and the<a id="_idIndexMarker896"/><a id="_idIndexMarker897"/> failure message.</p>&#13;
			<p>At this point, we discovered someone on the team had manually deployed a database to the dev environment. They were connecting to it for their demo AND using it as the test database in our Jenkins Pipelines. Essentially, someone on the team had created a Pet – a hand-reared server that was cared for and nurtured by one person and not known about by the rest of the team. In the world of ephemeral environments, what we really want is Cattle. Cattle are mass-produced, created using automation, and killed off when no longer required. Hence, when our job ran to clear out the project, all resources were destroyed.</p>&#13;
			<p>The team learned a valuable lesson in this experience which they made very visible:</p>&#13;
			<div>&#13;
				<div id="_idContainer176" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_11.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Figure 7.11: If it's not in Git, it's not real</p>&#13;
			</div>&#13;
			<p>It gave rise to a <a id="_idIndexMarker898"/><a id="_idIndexMarker899"/>mantra we added to our social contract from <em class="italics">Chapter 4, Open Culture.</em></p>&#13;
			<h3 id="_idParaDest-137"><a id="_idTextAnchor162"/>Implementing GitOps</h3>&#13;
			<div style="display:block; overflow-x:auto; padding:.5em; margin: 5px;">&#13;
			<div>&#13;
				<div id="_idContainer177" class="IMG---Figure" style="float: left; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/Techie1.jpg" alt="" width="220" height="220"/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Let's build the big picture with some real working code! In this section, we are going to take a technical detour! Prepare for <a id="_idIndexMarker900"/><a id="_idIndexMarker901"/>some code snippets. If this is not your thing, feel free to skip over it to the next section all about testing! We'll mark any section that's going to have code snippets with this handy sign.</p>&#13;
			<p>Let's explore ArgoCD and create the components of our Big Picture from code. To do this, we will first explore a sample project that can be used as a starting point for development.</p>&#13;
			<p>At Red Hat Open Innovation Labs, we have automated the bootstrap of Labs Residency CI-CD tooling to accelerate setup and onboarding. The code repository is called Ubiquitous Journey, so it makes sense for us to start here. We will explore this repository and set up our technical foundation using it. In later sections of the book, we will extend it with new technology and tools. This repo is available on the PetBattle GitHub organization – <a href="https://github.com/petbattle/ubiquitous-journey">https://github.com/petbattle/ubiquitous-journey</a>.</p>&#13;
			</div>&#13;
			<p>The first task we would normally perform on our OpenShift cluster when deploying Jenkins is to create a new project using the command line. We could follow this manual approach again, adding in role bindings and quotas for our project, and repeat these steps for each bit of our Big Picture. But let's do it in a way that honors our everything-as-code practice.</p>&#13;
			<p>From your laptop, fork the sample project and open it up in your favorite code editor.</p>&#13;
			<p>We are going to make changes to our project so maintaining your own copy of it is necessary for GitOps. From here on out, when we encounter a new repo, you'll probably find it easier to fork it so you can make changes to it. For the purposes of the book going forward, we will continue using PetBattle organization so feel free to equate this to your own organization or user.</p>&#13;
			<p class="snippet">git clone <a href="https://github.com/petbattle/ubiquitous-journey.git">https://github.com/petbattle/ubiquitous-journey.git</a></p>&#13;
			<p>The Ubiquitous Journey project is broken down into two main components (some of the files are removed from the breakdown below for simplicity), Bootstrap and Ubiquitous Journey. If you're wondering why we named the project Ubiquitous Journey… well, we didn't! We hit the <strong class="bold">generate random name</strong> button on GitHub and this is what it chose for us. As is the case with most things in software, naming things is hard! We did plan on renaming the repo at some stage, but now the name has kind of stuck and we like it!</p>&#13;
			<p class="snippet">$ tree ubiquitous-journey</p>&#13;
			<p class="snippet">ubiquitous-journey</p>&#13;
			<p class="snippet">├── argo-app-of-apps.yaml</p>&#13;
			<p class="snippet">├── bootstrap</p>&#13;
			<p class="snippet">│   ├── charts</p>&#13;
			<p class="snippet">│   ├── Chart.yaml</p>&#13;
			<p class="snippet">│   └── values-bootstrap.yaml</p>&#13;
			<p class="snippet">├── docs</p>&#13;
			<p class="snippet">├── ...</p>&#13;
			<p class="snippet">├── README.md</p>&#13;
			<p class="snippet">└── ubiquitous-journey</p>&#13;
			<p class="snippet">    ├── Chart.yaml</p>&#13;
			<p class="snippet">    ├── templates</p>&#13;
			<p class="snippet">    │   ├── argoapplicationdeploy.yaml</p>&#13;
			<p class="snippet">    │   └── _helpers.tpl</p>&#13;
			<p class="snippet">    ├── values-day2ops.yaml</p>&#13;
			<p class="snippet">    ├── values-extratooling.yaml</p>&#13;
			<p class="snippet">    └── values-tooling.yaml</p>&#13;
			<p>The bootstrap folder <a id="_idIndexMarker902"/><a id="_idIndexMarker903"/>contains a Helm chart definition with a values-bootstrap.yaml file and Chart.yaml manifest. There are no templates for this chart because it's actually just a wrapper for other Helm charts. If we look at the Chart.yaml manifest, we can see that it has a dependency of the ArgoCD chart, another called bootstrap, and a helper chart called sealed-secrets. The bootstrap folder Helm chart is acting as a wrapper chart, allowing us to control the variables we pass to these dependencies. In this case, our variables are stored in the <strong class="inline">values-bootstrap.yaml</strong> file:</p>&#13;
			<p class="snippet">bootstrap-project:</p>&#13;
			<p class="snippet">  enabled: true</p>&#13;
			<p class="snippet">  ci_cd_namespace: &amp;ci_cd "labs-ci-cd"</p>&#13;
			<p class="snippet">  pm_namespace: &amp;pm "labs-pm"</p>&#13;
			<p class="snippet">  ops_namespace: &amp;ops "labs-cluster-ops"</p>&#13;
			<p class="snippet">  dev_namespace: &amp;dev "labs-dev"</p>&#13;
			<p class="snippet">  test_namespace: &amp;test "labs-test"</p>&#13;
			<p class="snippet">  staging_namespace: &amp;stage "labs-staging"</p>&#13;
			<p class="snippet">  bindings: &amp;binds </p>&#13;
			<p class="snippet">  # this labs-devs is the GROUP NAME in IDM</p>&#13;
			<p class="snippet">    – name: labs-devs</p>&#13;
			<p class="snippet">      kind: Group</p>&#13;
			<p class="snippet">      role: edit</p>&#13;
			<p class="snippet">  # this labs-admins is the GROUP NAME in IDM</p>&#13;
			<p class="snippet">    – name: labs-admins</p>&#13;
			<p class="snippet">      kind: Group</p>&#13;
			<p class="snippet">      role: admin</p>&#13;
			<p class="snippet">    – name: jenkins</p>&#13;
			<p class="snippet">      kind: ServiceAccount</p>&#13;
			<p class="snippet">      role: admin</p>&#13;
			<p class="snippet">      namespace: *ci_cd</p>&#13;
			<p class="snippet">  namespaces:</p>&#13;
			<p class="snippet">    – name: *ci_cd</p>&#13;
			<p class="snippet">      bindings: *binds</p>&#13;
			<p class="snippet">    - name: *pm</p>&#13;
			<p class="snippet">      bindings: *binds</p>&#13;
			<p class="snippet">    - name: *ops</p>&#13;
			<p class="snippet">      bindings: *binds</p>&#13;
			<p class="snippet">    - name: *dev</p>&#13;
			<p class="snippet">      bindings: *binds</p>&#13;
			<p class="snippet">    - name: *test</p>&#13;
			<p class="snippet">      bindings: *binds</p>&#13;
			<p class="snippet">    - name: *stage</p>&#13;
			<p class="snippet">      bindings: *binds</p>&#13;
			<p>The bootstrap chart is <a id="_idIndexMarker904"/><a id="_idIndexMarker905"/>responsible for creating the listed projects in our OpenShift cluster. In the example, these are labs-ci-cd, labs-dev, labs-test, labs-staging, labs-pm, and labs-cluster-ops. Dev, Test, Staging, and CI/CD will hopefully be self-explanatory; if not, take a look at the previous chapter, where we discussed CI/CD in depth. The labs-pm namespace is for deploying other project management tools (for example, collaboration tools such as etherpad). The labs-cluster-ops namespace is used for operational jobs and tasks.</p>&#13;
			<p>Resources in OpenShift have <strong class="bold">role-based access control</strong> (<strong class="bold">RBAC</strong>) applied.<span id="footnote-027-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-027">3</a></span> RBAC determines whether a user is <a id="_idIndexMarker906"/><a id="_idIndexMarker907"/>allowed to perform a given action within a project. We bind the listed user groups to the service accounts within these projects. Don't worry if your cluster does not have the labs-dev and labs-admin groups set up right now. It is enough if you are logged in to your cluster with a user who has cluster admin privilege.</p>&#13;
			&#13;
			<p class="snippet">argocd-operator:</p>&#13;
			<p class="snippet">  enabled: true</p>&#13;
			<p class="snippet">  name: argocd</p>&#13;
			<p class="snippet">  namespace: *ci_cd</p>&#13;
			<p class="snippet"> argocd_cr:</p>&#13;
			<p class="snippet">    applicationInstanceLabelKey: petbattle.app/uj</p>&#13;
			<p class="snippet">  # operator manages upgrades etc</p>&#13;
			<p class="snippet">  version: v1.8.6</p>&#13;
			<p class="snippet">  operator:</p>&#13;
			<p class="snippet">    version: argocd-operator.v0.0.14</p>&#13;
			<p class="snippet">    channel: alpha</p>&#13;
			<p class="snippet">    name: argocd-operator</p>&#13;
			<div id="footnote-027" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-027-backlink">3</a>	<a href="https://docs.openshift.com/container-platform/4.6/authentication/using-rbac.html">https://docs.openshift.com/container-platform/4.6/authentication/using-rbac.html</a></p>&#13;
			</div>&#13;
			<p>The second part of this file overwrites some variables in the ArgoCD chart. This Helm chart installs the ArgoCD operator and configures it with sensible defaults. For a list of all the possible variables that could be passed to this chart, you can check out the Operator Docs for ArgoCD – <a href="https://argocd-operator.readthedocs.io/en/latest/">https://argocd-operator.readthedocs.io/en/latest/</a>. There is no point in<a id="_idIndexMarker908"/><a id="_idIndexMarker909"/> recreating those docs in this book, but it's useful to have them saved if you want to do some exploring.</p>&#13;
			<p>It is worth calling out the <strong class="inline">applicationInstanceLabelKey</strong> variable. This needs to be unique for your cluster. If you deploy more than one instance of ArgoCD to a cluster with the same instance label, the two ArgoCD instances will try to manage the same resources and then they'll fight over who actually owns them and get you into a world of pain, so make sure the <strong class="inline">applicationInstanceLabelKey</strong> is unique!</p>&#13;
			<p>Let's deploy this setup <a id="_idIndexMarker910"/>and see what it gives us. If you wish to change the names of the projects that are created, you can edit the values file, but for now we'll use the defaults. In a terminal on your laptop, try the following command:</p>&#13;
			<p class="snippet">$ helm template bootstrap --dependency-update -f \</p>&#13;
			<p class="snippet">bootstrap/values-bootstrap.yaml bootstrap</p>&#13;
			<p>Running a Helm template like this should bring down our chart dependencies and process our templates. This can be a handy way to validate that the YAML file looks as we expect. Let's install the bootstrap Helm chart into its own namespace.</p>&#13;
			<p class="snippet">$ helm upgrade --install bootstrap-journey \</p>&#13;
			<p class="snippet">  -f bootstrap/values-bootstrap.yaml \</p>&#13;
			<p class="snippet">  bootstrap --create-namespace --namespace labs-bootstrap</p>&#13;
			<p>The output of this command should be a successful installation of the bootstrap Helm chart:</p>&#13;
			<div>&#13;
				<div id="_idContainer178" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_12.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.12: Bootstrap ArgoCD using Helm</p>&#13;
			<p>You can check the pods coming up with:</p>&#13;
			<p class="snippet">oc get pods -n labs-ci-cd  </p>&#13;
			<p>You should start to see the <a id="_idIndexMarker911"/><a id="_idIndexMarker912"/>ArgoCD server start to come alive after a minute or two:</p>&#13;
			<div>&#13;
				<div id="_idContainer179" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_13.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.13: Labs-ci-cd namespace pods starting up</p>&#13;
			<p>Or, if you have a look in the UI, you should see the topology with all the components of ArgoCD:</p>&#13;
			<div>&#13;
				<div id="_idContainer180" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_14.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.14: OpenShift developer topology view of the labs-ci-cd project</p>&#13;
			<p>Let's take a look at ArgoCD by clicking the link in the UI, or you can get the URL from the command line using the following command:</p>&#13;
			<p class="snippet">oc get routes argocd-server -n labs-ci-cd</p>&#13;
			<p>Log in with your OpenShift credentials. We should see an empty ArgoCD instance:</p>&#13;
			<p> </p>&#13;
			<div>&#13;
				<div id="_idContainer181" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_15.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.15: Empty ArgoCD instance from the web interface</p>&#13;
			<p>At this point, we <a id="_idIndexMarker913"/>should ask ourselves the question <em class="italics">What happens when someone changes the bootstrap configuration values for our cluster?</em> for example, to add more projects or change the roles or groups? Can we do this in an automated and tracked way, in other words, using GitOps? Fear not, ArgoCD to the rescue! We can now point ArgoCD to the Git repository we've been working on.</p>&#13;
			<p>We can create an ArgoCD application from the ArgoCD web interface by selecting <span class="P---Screen-Text">+New App</span> -&gt; <span class="P---Screen-Text">Edit as YAML</span> and copying and pasting the following definition:</p>&#13;
			<p class="snippet">apiVersion: argoproj.io/v1alpha1</p>&#13;
			<p class="snippet">kind: Application</p>&#13;
			<p class="snippet">metadata:</p>&#13;
			<p class="snippet">  name: bootstrap-journey</p>&#13;
			<p class="snippet">  namespace: labs-ci-cd</p>&#13;
			<p class="snippet">spec:</p>&#13;
			<p class="snippet">  destination:</p>&#13;
			<p class="snippet">    namespace: labs-bootstrap</p>&#13;
			<p class="snippet">    server: <a href="https://kubernetes.default.svc">https://kubernetes.default.svc</a></p>&#13;
			<p class="snippet">  project: default</p>&#13;
			<p class="snippet">  source:</p>&#13;
			<p class="snippet">    helm:</p>&#13;
			<p class="snippet">      parameters:</p>&#13;
			<p class="snippet">      - name: argocd-operator.ignoreHelmHooks</p>&#13;
			<p class="snippet">        value: "true"</p>&#13;
			<p class="snippet">      valueFiles:</p>&#13;
			<p class="snippet">      - values-bootstrap.yaml</p>&#13;
			<p class="snippet">    path: bootstrap</p>&#13;
			<p class="snippet">    repoURL: <a href="https://github.com/petbattle/ubiquitous-journey.git">https://github.com/[YOUR FORK]/ubiquitous-journey.git</a></p>&#13;
			<p class="snippet">    targetRevision: main</p>&#13;
			<p class="snippet">  syncPolicy:</p>&#13;
			<p class="snippet">    automated: {}</p>&#13;
			<p>Hit <span class="P---Screen-Text">Save</span>, followed by <span class="P---Screen-Text">Create</span>. You should see the <strong class="inline">bootstrap-journey</strong> application synced:</p>&#13;
			<div>&#13;
				<div id="_idContainer182" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_16.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.16: Bootstrap ArgoCD application from the web interface</p>&#13;
			<p>We can also create the same <a id="_idIndexMarker914"/><a id="_idIndexMarker915"/>application on the terminal. You can log in using single sign-on to OpenShift from the terminal using this one liner. It requires a terminal that is not headless, in other words, it can connect to your screen and browser:</p>&#13;
			<p class="snippet">$ argocd login $(oc get route argocd-server --template='{{ .spec.host }}' \</p>&#13;
			<p class="snippet">-n labs-ci-cd):443 \</p>&#13;
			<p class="snippet">--sso --insecure</p>&#13;
			<p>Create the new app and sync the changes. With this in place, argocd will now actively track changes to our Git repository and roll them out for us! Simple!</p>&#13;
			<p class="snippet">argocd app create bootstrap-journey \</p>&#13;
			<p class="snippet">  --dest-namespace labs-bootstrap \</p>&#13;
			<p class="snippet">  --dest-server <a href="https://kubernetes.default.svc">https://kubernetes.default.svc</a> \</p>&#13;
			<p class="snippet">  --repo <a href="https://github.com/petbattle/ubiquitous-journey.git">https://github.com/[YOUR FORK]/ubiquitous-journey.git</a> \</p>&#13;
			<p class="snippet">  --revision main \</p>&#13;
			<p class="snippet">  --sync-policy automated \</p>&#13;
			<p class="snippet">  --path "bootstrap" \</p>&#13;
			<p class="snippet">  --helm-set argocd-operator.ignoreHelmHooks=true \</p>&#13;
			<p class="snippet">  --values "values-bootstrap.yaml" </p>&#13;
			<p>You can select the<a id="_idIndexMarker916"/><a id="_idIndexMarker917"/> application in the web interface to drill down into it:</p>&#13;
			<div>&#13;
				<div id="_idContainer183" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_17.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.17: Bootstrap application details from the web interface</p>&#13;
			<p>Excellent – we are on our way to completing our Big Picture as code and laying down our technical foundation! We've created the projects and added the first tool, ArgoCD, to our kit bag. Now, let's take it a step further and fill our cluster with some of the applications we think would be initially useful for <a id="_idIndexMarker918"/><a id="_idIndexMarker919"/>building out CI/CD pipelines. At the beginning of any project, this will usually be a best guess. As we start to build out the product, we must continuously evolve the toolset we use. This is not a one-time process; it's a set of tools that need to be extended when required or trashed if no longer useful. The important thing here is to ensure that things are deployed in a repeatable way.</p>&#13;
			<p>Let's add some tooling. Open your editor on the ubiquitous-journey project. Inside ubiquitous-journey/values-tooling.yaml, we have some useful variables referencing Helm charts ready for us to pick from, including Jenkins, which we manually deployed previously!</p>&#13;
			<p class="snippet">##############</p>&#13;
			<p class="snippet"># 🛎 Argo App of Apps declaration</p>&#13;
			<p class="snippet">#############</p>&#13;
			<p class="snippet"># enabled true on an app is to tell helm to create an argo app cr for this item</p>&#13;
			<p class="snippet"># Custom values override the default values in Helm Charts</p>&#13;
			<p class="snippet">applications:</p>&#13;
			<p class="snippet">  # Nexus</p>&#13;
			<p class="snippet">  – name: nexus</p>&#13;
			<p class="snippet">    enabled: true</p>&#13;
			<p class="snippet">    source: <a href="https://redhat-cop.github.io/helm-charts">https://redhat-cop.github.io/helm-charts</a></p>&#13;
			<p class="snippet">    chart_name: sonatype-nexus</p>&#13;
			<p class="snippet">    source_path: ""</p>&#13;
			<p class="snippet">    source_ref: "0.0.11"</p>&#13;
			<p class="snippet">    sync_policy: *sync_policy_true</p>&#13;
			<p class="snippet">    destination: *ci_cd_ns</p>&#13;
			<p class="snippet">    ignore_differences:</p>&#13;
			<p class="snippet">      – group: route.openshift.io</p>&#13;
			<p class="snippet">        kind: Route</p>&#13;
			<p class="snippet">        jsonPointers:</p>&#13;
			<p class="snippet">          – /status/ingress</p>&#13;
			<p class="snippet">  # Jenkins</p>&#13;
			<p class="snippet">  – name: jenkins</p>&#13;
			<p class="snippet">...</p>&#13;
			<p class="snippet">  # Sonarqube</p>&#13;
			<p class="snippet">  – name: sonarqube</p>&#13;
			<p class="snippet">...</p>&#13;
			<p>The layout of this file is simple. For each<a id="_idIndexMarker920"/><a id="_idIndexMarker921"/> item in the applications array, it expects to find a Helm chart or a reference to a Git repository with some Kubernetes yaml (or Kustomize) at a particular version.</p>&#13;
			<p>When using Helm, any overrides to the defaults supplied by the chart can be added here, but for the Nexus chart shown, we are using the default values, so there is no need for value overrides for Nexus. There are other fields for each application, and these are mostly related to the operation of ArgoCD. For example, you can configure the application synchronization policy – sync-policy – which tells ArgoCD to always keep your application synced when set to automatic. The destination namespace may be specified. With some Kubernetes and OpenShift API objects, ArgoCD needs to be asked to ignore differences it finds; this is particularly true when controllers and operators write back the status and other fields into the objects themselves. We have found over time that each release of ArgoCD lessens the need to specify these <em class="italics">ignores</em> as the generated differences are taken care of automatically.</p>&#13;
			<p>The other important field for each application entry is the <strong class="inline">enabled: true | false</strong> – it's easy to run down the list and enable the tools we know we need straight away. For now, we are going to start with just four tools: Jenkins, Nexus, Tekton, and Code Ready Workspaces. These<a id="_idIndexMarker922"/><a id="_idIndexMarker923"/> are the bare bones for scaffolding our application and pipelines. At this point, it is worth mentioning the other two <strong class="inline">values</strong> files, <strong class="inline">extratooling</strong> and <strong class="inline">day2ops</strong>:</p>&#13;
			<p class="snippet">└── ubiquitous-journey</p>&#13;
			<p class="snippet">    ├── Chart.yaml</p>&#13;
			<p class="snippet">    ├── ...</p>&#13;
			<p class="snippet">    ├── values-day2ops.yaml</p>&#13;
			<p class="snippet">    ├── values-extratooling.yaml</p>&#13;
			<p class="snippet">    └── values-tooling.yaml</p>&#13;
			<p>Like our CI/CD application list in <strong class="inline">values-tooling.yaml</strong>, they contain references to useful Helm charts and YAML files for deploying in our cluster. The extra tooling contains project management and collaboration tools, while the <strong class="inline">day2ops</strong> contains useful prune jobs to keep our cluster tidy. For now, we will disable all of the extra tooling and day2ops apps. This gives us a minimal setup to get started with.</p>&#13;
			<p>If you are running CRC, please check the Appendix for any details prior to deploying the tooling. Let's deploy these tools from the command line using Helm and <strong class="inline">oc</strong>:</p>&#13;
			<p class="snippet">$ helm template -f argo-app-of-apps.yaml ubiquitous-journey/ \</p>&#13;
			<p class="snippet">| oc -n labs-ci-cd apply -f-</p>&#13;
			<p>If you check the ArgoCD web page, you should now see these applications begin to deploy and synchronize into your cluster. It will take some time for them all to synchronize completely. Jenkins, for example, builds all of the default agent images that we may need for running pipeline jobs.</p>&#13;
			<div>&#13;
				<div id="_idContainer184" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_18.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.18: The complete picture with all our tools installed</p>&#13;
			<p>We have now successfully <a id="_idIndexMarker924"/><a id="_idIndexMarker925"/>bootstrapped our CI/CD tooling! We will revisit these configurations as we find we need to add and update the tools we need to develop, test, and deliver PetBattle. By practicing <em class="italics">everything-as-code</em>, we can easily redeploy these tools into any Kubernetes cluster, track changes we may make, and manage the life cycle of the tools (upgrade them as their versions and features change).</p>&#13;
			<h2 id="_idParaDest-138"><a id="_idTextAnchor163"/>Testing Testing Testing!</h2>&#13;
			<p>Up to this point, we've spoken about some of the tools we can use to move application code from ideas through compilation and into deployment. But how do we know the stuff we've built is actually working as we expect it to? If we create a pipeline that just compiles code and moves it to production – is it done? No, there are testing quality steps and gates that we need to introduce into our software pipelines!</p>&#13;
			<h3 id="_idParaDest-139"><a id="_idTextAnchor164"/>The Test Automation Pyramid</h3>&#13;
			<p>How do we know our feature works as we expect it to? We should test it and see! It is not always clear how we should test our feature, nor is it clear when we have done too much or not enough testing. Should we create test instructions and manually test the feature? Should we test the feature in isolation? Should we test all its constituent parts or just the whole thing? What is a definition of a unit test exactly?</p>&#13;
			<p>Let's face it, testing is complicated. We are<a id="_idIndexMarker926"/><a id="_idIndexMarker927"/> going to advocate for creating not just any tests, but automated tests! <em class="italics">The Test Automation Pyramid</em>, authored <a id="_idIndexMarker928"/><a id="_idIndexMarker929"/>by <em class="italics">Michael Cohn</em>, is a good starting point for us <a id="_idIndexMarker930"/><a id="_idIndexMarker931"/>moving through the world of automated testing. Let's take a simplified look at the <em class="italics">traditional</em> test automation pyramid by the original author:</p>&#13;
			<div>&#13;
				<div id="_idContainer185" class="IMG---Figure">&#13;
					<img src="../Images/image043.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.19: The testing triangle</p>&#13;
			<p>In the standard three-tiered testing triangle, the things <a id="_idIndexMarker932"/><a id="_idIndexMarker933"/>at the bottom (listed above as <strong class="bold">UNIT TESTS</strong>) are the things we should do more of. Unit tests are the smallest amount of code we can test within an application. These units should have little to no dependency on other items and so when we run them, they give us immediate and precise feedback. Unit tests should point us exactly to where the problem is in our code. Moreover, the thinking here is that unit tests are cheap to write, easy to maintain, and fast to execute. Therefore, we want more of them. This is why they sit at the base of the testing triangle.</p>&#13;
			<p>Service tests are sometimes seen as integration tests and are the next level up the testing triangle. These <a id="_idIndexMarker934"/><a id="_idIndexMarker935"/>are API tests that are validating the services within your application behave as expected. This may include single service calls, as well as chains of service calls, when one service calls another service. The width of the testing tier in the triangle relates to how many types of a particular test there should be in your code base. According to the <a id="_idIndexMarker936"/><a id="_idIndexMarker937"/>pyramid, we should have fewer of these service tests than unit tests as they can be costly to execute.</p>&#13;
			<p>The top tier of the testing<a id="_idIndexMarker938"/><a id="_idIndexMarker939"/> triangle is reserved for <strong class="bold">User Interface</strong> (<strong class="bold">UI</strong>) tests, or end-to-end system tests. These are responsible for validating that the system, as the sum of its components and parts, is behaving as expected. Often, UI tests can be brittle in the face of change, break more often, and require maintenance to keep them relevant, so the rationale from the testing pyramid is that we should do fewer of these as they are difficult to perform and provide less feedback for us.</p>&#13;
			<h3 id="_idParaDest-140"><a id="_idTextAnchor165"/>Testing in Practice</h3>&#13;
			<p>The Test Automation Pyramid is a great place<a id="_idIndexMarker940"/><a id="_idIndexMarker941"/> to start when thinking about your own testing. As with all models and patterns, people have over-simplified some of its original meaning. In fact, if you do an image search for the testing pyramid, you'll see that most of the results are missing the most important keyword – automation! Often, organizations lose sight of this, and they think doing manual testing for these tiers is good enough.</p>&#13;
			<p>Testing is important; in fact, it's critical to being able to deliver at speed! If you imagine not investing the time into writing automated tests, it may be possible to complete a sprint without breaking things. It's probable that we'd be able to do two sprints and not break things. However, once we hit that third or fourth sprint, that's when your software system starts to misbehave. Applications that were written in sprint one now have bugs appearing in them because their functional behavior does not work as intended. Functions and APIs that were<a id="_idIndexMarker942"/><a id="_idIndexMarker943"/> thought to be working were, in fact, completely broken! Being able to release software at speed is one thing, but being able to release quality software at speed is the differentiator.</p>&#13;
			<p>What is important when thinking about testing is to apply context. You don't have to blindly follow a model such as the testing pyramid. In fact, it's a good place to start from, but it's not a golden<a id="_idIndexMarker944"/><a id="_idIndexMarker945"/> hammer to apply in all environments. For example, you might be building a web app with static content or third-party services, so UI testing is probably the most important thing.</p>&#13;
			<p>What is important is to be sensible about the types of testing you're aiming to perform and the value they provide. You may find that it's more important to your product that covering the services layer is a better option. If you don't have access to the code, then writing black-box tests that assess the services with well-defined inputs and outputs is more appropriate to your quality control. Likewise, measuring the number of tests, as suggested by the pyramid, tells us nothing about the quality of the tests. Good quality tests catch errors before your<a id="_idIndexMarker946"/><a id="_idIndexMarker947"/> user does. When there is a failure in production, or a bug raised by a user, it is very likely that you need to write some more automated tests.</p>&#13;
			<div>&#13;
				<div id="_idContainer186" class="IMG---Figure">&#13;
					<img src="../Images/image045.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.20: Measuring tests</p>&#13;
			<p>The other way to look at this <a id="_idIndexMarker948"/><a id="_idIndexMarker949"/>would be to calculate the risk of not testing a piece of functionality. Perhaps the application you're writing is a one-time throwaway or just a simple technical spike that does not require rigorous testing. However, if a piece of functionality within your product is used all the time and it has no automated tests written for it at all, this could be a good place to focus your automated testing efforts.</p>&#13;
			<p>Create a culture within your product development team where testing is a continual practice. Testing should not be an afterthought of the development process. All too often, we see testing beginning once the development team throws a package over a wall to the test team for some testing to begin. For us, every item in a sprint will always have some level of testing. This isn't done by some third-party team, but by the engineers themselves. Developers will often favor unit and integration testing, but <strong class="bold">quality assurance</strong> (<strong class="bold">QA</strong>) teams will often favor automated UI testing to validate the application from a user's point of view. Sometimes, if the culture is not right and a team is being squeezed to turn out new features, testing quality can drop, leading to an almost inverted testing pyramid: a few unit tests on the bottom, followed by a few more service tests, and then a load of brittle UI tests sitting on top! This has an effect on the quality of the software delivery pipelines. The feedback loop from Dev to QA can be very long, with little to no value from unit tests and expensive UI tests that are not providing feedback quickly enough.</p>&#13;
			<p>Decreasing the quality by inverting the testing pyramid during delivery can be very damaging to a team. If the volume of defects increases markedly, trust in the team will falter. If there is no trust in the team, then autonomy could be the next thing to break, leading to a heavy command-and-control-driven culture. Teams operating in this way will very quickly fail and top talent will leave.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-141" class="Author-Heading"><a id="_idTextAnchor166"/>Testing and the Definition of Done</h2>&#13;
						<div>&#13;
				<div id="_idContainer188" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/Author_42.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			<div>&#13;
				<div id="_idContainer187" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/Noel2.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			<p>While working on a residency recently with the World Health Organization, we started out with great ambition to write tests for each sprint item. We got off to a good start by including testing in our Definition of Done for each sprint item. We agreed that there must be some automated testing for each item being taken into a sprint.</p>&#13;
			<p>The first sprint went by in a flash as we were working in one-week iterations. As we were a new team, everyone was motivated and keen to try new things. By sprint three, we were taking on more stories than we could get through with our team's capacity.</p>&#13;
			<p>The work we were doing was becoming more complex and we missed out some of the automated tests. We claimed a feature or two were done. In the demo for that week, we admitted to the product owner that the piece of work was functionally done, but not done according to our own criteria.</p>&#13;
			<p>We tried to be honest with ourselves, but found we'd slipped up again the following week. At this point, it became clear to us that when we did sprint planning, we were not thinking correctly about the capacity required for writing tests. The Definition of Done was in place, but we were still not being honest. We were a team that was keen to keep moving forward and picking up new items before previous ones were done.</p>&#13;
			<p>In a retrospective session, we decided a good way forward would be for us to capture testing effort when writing our tasks. When taking an item from the backlog, we would add subtasks for all of the automated testing. This way, all of the work associated with test automation became visible to the team because these subtasks were on the sprint board. Having a task to write tests for your feature makes it pretty hard to move on to the next item when it's still in progress!</p>&#13;
			</div>&#13;
			<p>You can learn more and collaborate on CI practices by going to the Open Practice Library page at <a href="https://openpracticelibrary.com/practice/test-automation/">https://openpracticelibrary.com/practice/test-automation/</a>.</p>&#13;
			<h3 id="_idParaDest-142"><a id="_idTextAnchor167"/>TDD or BDD or DDT</h3>&#13;
			<p>There are a number of books written on testing and how to write great tests that are meaningful and provide value. Our ambition is not to rewrite these books, but to give you pointers to things you <a id="_idIndexMarker950"/><a id="_idIndexMarker951"/>could research further if<a id="_idIndexMarker952"/><a id="_idIndexMarker953"/> this topic really interests you. Some approaches <a id="_idIndexMarker954"/><a id="_idIndexMarker955"/>to testing that teams find useful at the various<a id="_idIndexMarker956"/><a id="_idIndexMarker957"/> levels of the triangle are things such as <strong class="bold">Behavior-Driven Development</strong> (<strong class="bold">BDD</strong>), <strong class="bold">Test-Driven Development</strong> (<strong class="bold">TDD</strong>), and <strong class="bold">Developer-Driven Testing</strong> (<strong class="bold">DDT</strong>).</p>&#13;
			<div>&#13;
				<div id="_idContainer189" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_21.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.21: Test-Driven Development</p>&#13;
			<p>TDD is a simple process, yet somewhat misunderstood by some teams. The process is fairly simple. Start off by writing some tests for the functionality you're building. At this point, they should fail (<strong class="bold">RED</strong>). If they don't fail, then your tests are not very well written OR the functionality already exists! A developer will then write the code to make the test pass (<strong class="bold">GREEN</strong>). With the tests now green, refactoring can take place or, as Kent Beck, an American software engineer and the creator of extreme programming, puts it, <em class="italics">refactor to remove duplication</em>. Remove duplicate code or make the code leaner and tidy it up while maintaining the green state of the tests. The process is simple: <strong class="bold">Red &gt; Green &gt; Refactor</strong>. Writing tests first is a hard practice to do and takes time and perseverance to get the skills right, but it can lead to less spaghetti code. Because the tests are written first, they lead the design and implementation of the code.</p>&#13;
			<div>&#13;
				<div id="_idContainer190" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_22.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.22: Executing Test-Driven Development</p>&#13;
			<p>A great exercise to do with teams wanting to try TDD without code is to do the Lego TDD simulation on Gargoyle Software's website: <a href="http://gargoylesoftware.com/articles/lego_tdd">http://gargoylesoftware.com/articles/lego_tdd</a>.</p>&#13;
			<p>You can learn more and <a id="_idIndexMarker958"/><a id="_idIndexMarker959"/>collaborate on TDD by going to the Open Practice Library page at <a href="http://openpracticelibrary.com/practice/test-driven-development">openpracticelibrary.com/practice/test-driven-development</a>.</p>&#13;
			<p>DDT is easy and probably the<a id="_idIndexMarker960"/><a id="_idIndexMarker961"/> place to start if you're not writing any tests. The important point here is that some tests are being written! DDT focuses on the developers writing code as well as writing the tests. Simply put, the developer codes for a bit, writes some automated tests, and then goes back to coding and testing. This might sound a bit like TDD, but the key difference is the order. Code first and then test, resulting in the code influencing the tests as opposed to the tests leading the software design. The objective of DDT is that developers need to own their code and that everyone should be responsible for testing.</p>&#13;
			<div>&#13;
				<div id="_idContainer191" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_23.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.23: Developer-Driven Testing </p>&#13;
			<p>BDD is a great tool to <a id="_idIndexMarker962"/><a id="_idIndexMarker963"/>have in your toolbox as it brings people together in a shared understanding of the scope of a story or feature under development. It's less of an engineering tool and more of a method that focuses on the conversation to be had between business and developers when writing features. BDD is about using a shared language to write concrete examples of how an application should behave.</p>&#13;
			<p>How the tests are implemented is then decided by the developers. But, more importantly, a common language can be used between developers and product owners to scope out a story without leading the design of the software. BDD can be a useful way to write acceptance criteria for a story together. There is a common syntax or approach to writing BDD tests based on work by <em class="italics">Dan North</em>, an <a id="_idIndexMarker964"/><a id="_idIndexMarker965"/>agile coach and originator of BDD<span id="footnote-026-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-026">4</a></span>:</p>&#13;
			&#13;
			<p class="snippet">Scenario  1: Title</p>&#13;
			<p class="snippet">Given [context]</p>&#13;
			<p class="snippet">And [some more context]...</p>&#13;
			<p class="snippet">When  [event]</p>&#13;
			<p class="snippet">Then  [outcome]</p>&#13;
			<p class="snippet">And [another outcome]...</p>&#13;
			<div id="footnote-026" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-026-backlink">4</a>	<a href="https://dannorth.net/introducing-bdd/">https://dannorth.net/introducing-bdd/</a></p>&#13;
			</div>&#13;
			<p>For example:</p>&#13;
			<p class="snippet">Scenario  1: Buying an Ice Cream to cool off on a hot day</p>&#13;
			<p class="snippet">Given I have ten pounds in my pocket</p>&#13;
			<p class="snippet">When  I purchase a Choc Ice for two pounds</p>&#13;
			<p class="snippet">Then  I have only eight pounds left</p>&#13;
			<p class="snippet">And have a Choc Ice</p>&#13;
			<p>For any feature being<a id="_idIndexMarker966"/><a id="_idIndexMarker967"/> developed, there are probably a number of scenarios that could be tested. These scenarios are defined using the common syntax of Given, When, Then. Codifying the acceptance criteria using a common syntax can simplify the writing of tests and gaining a shared understanding of the scope of an activity. Dan North suggested this story-driven approach to BDD some years back and, since then, the syntax has been adopted by lots of the testing frameworks, such <a id="_idIndexMarker968"/><a id="_idIndexMarker969"/>as Cucumber.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-143" class="Author-Heading"><a id="_idTextAnchor168"/>BDD for Our Ops Tooling Python Library</h2>&#13;
			<div>&#13;
				<div id="_idContainer193" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/Author_22.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			<div>&#13;
				<div id="_idContainer192" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/Author_31.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
						<p>I worked on a public sector engagement a few years back. I was part of a team helping them automate some of their Ops capabilities. They had teams of people configuring VMs manually in a non-repeatable way. Part of that work involved me building a command-line interface for the team to help automate the creation and onboarding of team members (users) and their roles into a Free IPA server (Red Hat Identity Management). The following screenshot shows one of the BDD scenario templates for adding an existing user and deleting a user:</p>&#13;
			<div>&#13;
				<div id="_idContainer194" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_231.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Figure 7.24: A BDD scenario</p>&#13;
			<p>The architect on the team was a strong believer in the BDD approach to writing stories. All of our acceptance criteria were written in this way, and it was a great way for us to understand the scope of what we were doing. When I was pairing with another engineer, we would use the acceptance criteria written in the BDD syntax as our starting point. We imported the syntax straight from Jira to scaffold out the test cases using Python Behave. For us as engineers, this made coding the features a breeze. We had been given the specifications, so we could easily implement our code to pass the tests.</p>&#13;
			</div>&#13;
			<p>BDD can help engineers <a id="_idIndexMarker970"/><a id="_idIndexMarker971"/>understand the context of features better. It also helps bridge the gap of alignment with business experts and product owners:</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-144" class="Author-Heading"><a id="_idTextAnchor169"/>Product Owners Seeing Their Thoughts in Code!</h2>&#13;
			<p>When we coach teams, we encourage them to use the sprint review or showcase events as an opportunity to show the world EVERYTHING they've worked on. That includes setting up and improving test automation.</p>&#13;
			<p>One particular recurrence I've noticed from several teams I've worked with is when the product owner or business SMEs first see automation of BDD running. They think back to the sprint planning event a week or two earlier, when the teams were confirming acceptance criteria for stories they were going to accept into the sprint. Often, these criteria would be written using BDD syntax and it would be the PO or business experts providing the input.</p>&#13;
			<p>When they see a test automation suite running in the sprint review or showcase, they will see the console showing the tests automated, the same thoughts, the same instructions, and the same business logic all codified.</p>&#13;
			</div>&#13;
			<p>BDD brings down the wall between technology and business people.</p>&#13;
			<h3 id="_idParaDest-145"><a id="_idTextAnchor170"/>Example Mapping</h3>&#13;
			<p>Example Mapping, by Matt Wynne, CEO of Cucumber,<span id="footnote-025-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-025">5</a></span> is another great tool to have in the toolbox. Once again, with a lot of these practices, it's just another really useful way to articulate and drive a conversation. In this case, Example Mapping is primarily used to drive shared understanding when writing stories and creating acceptance criteria. We believe it's great for helping <a id="_idIndexMarker972"/><a id="_idIndexMarker973"/>teams write behavioral-driven tests. The process is simple and only involves<a id="_idIndexMarker974"/><a id="_idIndexMarker975"/> four colored Post-Its:</p>&#13;
						<ul style="list-style-type:disc;">&#13;
				<li><strong class="bold">Yellow</strong>: For the story itself (as a header for the example map)</li>&#13;
				<li><strong class="bold">Blue</strong>: For specific rules associated with the story</li>&#13;
				<li><strong class="bold">Green</strong>: For examples of rules</li>&#13;
				<li><strong class="bold">Red</strong>: For questions or unknowns that arise during the discussion</li>&#13;
			</ul>&#13;
			<div id="footnote-025" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-025-backlink">5</a>	<a href="https://cucumber.io/blog/bdd/example-mapping-introduction/">https://cucumber.io/blog/bdd/example-mapping-introduction/</a></p>&#13;
			</div>&#13;
			<div>&#13;
				<div id="_idContainer195" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_24.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.25: Example Mapping</p>&#13;
			<p>Begin by selecting a story <a id="_idIndexMarker976"/><a id="_idIndexMarker977"/>and write it on a yellow sticky note. Place it at the top of your example map as a header. In a horizontal row underneath that, begin writing business rules on blue sticky notes. Beneath the blue business rules, create columns of green sticky notes with individual examples of those business rules. These could be relatively unstructured Friends-notation <em class="italics">The one where...</em> examples, or full-blown Given, When, Then criteria.</p>&#13;
			<p>As misunderstandings arise surrounding individual examples or entire business rules, add red stickies with questions written on them.</p>&#13;
			<p>When there are enough examples that everyone is comfortable with, they can be rewritten as both automated tests and acceptance criteria.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-146" class="Author-Heading"><a id="_idTextAnchor171"/>Example Mapping in the Field</h2>&#13;
			<div>&#13;
				<div id="_idContainer196" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/Noel3.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			<p>On the World Health Organization residency, I found this practice so simple to use but such a great tool to articulate the scope of a story and get alignment on the acceptance tests we'd write.</p>&#13;
			<p>We were using Event Storming (more on this later) to model the onboarding process for a new user to their application. We had a command that read <em class="italics">Submit relevant topics of interest</em>, which was added to our backlog. We chose this command so we could learn more about things our users would be interested in, in <a id="_idIndexMarker978"/><a id="_idIndexMarker979"/>order to better serve them recommendations.</p>&#13;
			<p>We used Example Mapping to break this story down by first writing some rules. We were not super strict on following a ubiquitous language at this point as we knew the team would convert them into BDD-style syntax afterward.</p>&#13;
			<div>&#13;
				<div id="_idContainer197" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_25.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Figure 7.26: Example Mapping example</p>&#13;
			<p>The conversion within the team brought out some misunderstandings regarding the scope of the activity. The developers wondered more about edge cases, such as, <em class="italics">what happens if the page is refreshed or returned to?</em> We were able to capture these questions as part of the Example Mapping and add a new rule and some examples. Subsequently, the team could convert the examples into the BDD syntax.</p>&#13;
			<p>As with all these practices, the act of having this conversation with the correct people and capturing the examples meant we gained great team alignment and were able to convert them to acceptance tests and implement them as part of our development workflow.</p>&#13;
			</div>&#13;
			<p>You can learn more about, and <a id="_idIndexMarker980"/>collaborate on, the Example Mapping practice by going to the Open Practice Library page at <a href="http://openpracticelibrary.com/practice/example-mapping">openpracticelibrary.com/practice/example-mapping</a>.</p>&#13;
			<h3 id="_idParaDest-147"><a id="_idTextAnchor172"/>Non-functional Testing</h3>&#13;
			<p>While the importance <a id="_idIndexMarker981"/><a id="_idIndexMarker982"/>of testing cannot be overstated, it's critical to keep an eye on other metrics that may give further insight into the quality of our code. For example, how do you know your tests have enough breadth to check all the code? What if my tests are passing, but the application response time is awful? Traditional unit and integration testing might not catch these things. There are tools we can use to identify causes and issues with our code base and, more importantly, fix them sooner rather than later.</p>&#13;
			<p>Code coverage reporters <a id="_idIndexMarker983"/><a id="_idIndexMarker984"/>are simple to implement and usually come bundled up with a lot of modern test frameworks. The idea is simple. While running our test cases, the code base is being watched. Once test execution is completed, a report is generated showing what lines of code have been hit and where there are gaps. These are useful reports to help the team identify where there is room for improvement but they should not be treated as the absolute truth. As with all these things, there are ways to trick the coverage reports, but good developers and peer review processes should catch these things. Often, teams will strive to increase the testing coverage if they have not started from a very good state. Bringing these reports to a retrospective can be good for teams to analyze and set higher targets. More aggressive teams may even fail their pipeline as unstable if the coverage is below a certain threshold!</p>&#13;
			<p>Static<a id="_idIndexMarker985"/><a id="_idIndexMarker986"/> code analysis is another tool that can provide insight into a code base not detected by unit testing, creating rules for how the code should look and execute. Consistency in an approach to how you write code is particularly important for non-compiled languages such <a id="_idIndexMarker987"/><a id="_idIndexMarker988"/>as JavaScript. JavaScript also behaves differently in different browsers, so writing a set of rules such as using single quotes instead of double quotes for all strings can help ward off any unexpected behavior. If we have the rules codified, we may as well ensure that everyone adheres to them, so add them to our pipeline! Coding standards are very important in multi-team setups too. If the code base conforms to a standard structure and design, it can also make maintenance and updates to it very simple.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-148" class="Author-Heading"><a id="_idTextAnchor173"/>Performance Testing Sam's Code</h2>&#13;
			<div>&#13;
				<div id="_idContainer199" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/Author_23.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			<div>&#13;
				<div id="_idContainer198" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/Author_32.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			&#13;
			<p>Around 2014, we <a id="_idIndexMarker989"/><a id="_idIndexMarker990"/>worked for a retail organization building mobile backend services and some automation around it. This layer of services was responsible for aggregating data from different backend systems such as product listers and categories, and reviews. The services also performed some very basic data manipulation to make the payloads more mobile consumable. It was critical that the adapters responded in a very timely manner, as mobile latency was high compared to modern mobile networks and a fast API response time made all the difference.</p>&#13;
			<p>Our team was always cognizant that we should keep track of the time taken for the adapters to respond. We knew the organization would perform a traditional load-testing initiative at the end of the program; however, we didn't want to wait until then to reveal any surprises. We figured there had to be a way to continuously validate changes we made to the adapter tier in order to highlight any performance degradation.</p>&#13;
			<p>We created a nightly job in Jenkins (our automation tool) to check the performance of the adapters each evening. This was a fairly simple job that simulated 1,000s of parallel requests to the APIs. From this, we plotted the response time of the service each day and reported it through Jenkins. This allowed us to create a baseline for where a normal response should be and allow us to fail the job's execution if the value fell above or below an expected range!</p>&#13;
			<div>&#13;
				<div id="_idContainer200" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_26.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Figure 7.27: Automated discovery of performance bottlenecks</p>&#13;
			<p>One day, we came into the office and our nightly job had turned red! Perfect, we thought, let's Stop the World and stop all the things we're doing while we inspect what's changed in the system since last night. A quick check of the changes that were made in the system revealed that Sam, one of the team members, had tried to check in some new logic for one of the data translation functions. Sam had introduced a big loop inside a loop inside another loop, which had caused the code execution time to spike. It was something that was not caught by our traditional unit testing, as the logic was working fine. It was just taking longer to compute.</p>&#13;
			<p>We quickly responded and fixed the problem immediately. If we hadn't caught this performance bottleneck, it could have been weeks or more before we realized what was happening. We could have been building more functionality on top of this dodgy piece of code, making it much harder to unpick at a later date.</p>&#13;
			<p>Being able to respond to feedback like this was critical. We're not saying that big load testing on the product was not necessary, but this one simple automated job provided us with a ton of value just by catching this one issue. It was cheap to write and maintain and caught this error potentially sooner than we would otherwise have noticed. Sam tried to write some more code a few weeks later and we got a similar failure.</p>&#13;
			<div>&#13;
				<div id="_idContainer201" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_27.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Figure 7.28: More light automated performance tests</p>&#13;
			<p>Have no fear though – Sam, who's a good friend of ours, no longer writes code for a living as he's moved into a technical sales role. We don't have a blame culture within our workspaces and I'm sure if Sam was telling you this story, he'd say it was one of us that checked in that silly piece of code. I'll let you decide who it was.</p>&#13;
			</div>&#13;
			<p>There are lots <a id="_idIndexMarker991"/><a id="_idIndexMarker992"/>of other types of testing and I won't list them all; we'd have to write another book to fit them all in. We go into more detail about the non-functional nature of our software in the next section, <em class="italics">Discover It</em>.</p>&#13;
			<h3 id="_idParaDest-149"><a id="_idTextAnchor174"/>A Few Final Thoughts on Testing</h3>&#13;
			<p>We cannot understate the importance of testing in delivering features at speed, especially automated testing. Whether <a id="_idIndexMarker993"/><a id="_idIndexMarker994"/>you follow the test pyramid or some other paradigm is up to you – just remember it's all about the conversation. If TDD is not the right thing for you, make sure you still have the conversation between business and technical teams to identify sensible tests using examples. The go-to for us is to use BDD as it allows us to bring together the world of business and technology.</p>&#13;
			<p>Lastly, we're not saying there is no place in the world for separate QA teams. Not at all, it's about automating all the things and getting feedback early. If the QA is a separate function within your organization and is only engaged some weeks before going live, then this is a problem. Bring the skills of QA into the team and left-shift that capability into the team so that they can get early feedback more often.</p>&#13;
			<h2 id="_idParaDest-150"><a id="_idTextAnchor175"/>Emerging Architecture</h2>&#13;
			<p><em class="italics">Hope is not a design method</em>.<span id="footnote-024-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-024">6</a></span></p>&#13;
			&#13;
			<p>How do we know our <a id="_idIndexMarker995"/><a id="_idIndexMarker996"/>architecture is good? What does good mean? Is good architecture measurable? Have you ever<a id="_idIndexMarker997"/><a id="_idIndexMarker998"/> had to operate, support, or fix a system that is poorly architected?</p>&#13;
			<p>It may be easier to identify some characteristics of what <em class="italics">a </em><em class="italics"><a id="_idIndexMarker999"/><a id="_idIndexMarker1000"/></em><em class="italics">poor architecture</em> looks like:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>An unstable and unreliable system that fails regularly in unknown and unexpected ways.</li>&#13;
				<li>The system is slow from a user's point of view.</li>&#13;
				<li>It does not scale well with increased users or loads.</li>&#13;
				<li>It is hard to upgrade because one small change requires everything to be re-deployed, which is slow and costly.</li>&#13;
				<li>It is dependent on clients or other systems and cannot be easily modified or changed without changing the other systems as well.</li>&#13;
				<li>It has a lot of complex business functions that are buried in the database, that may involve triggers, and <a id="_idIndexMarker1001"/><a id="_idIndexMarker1002"/>cannot be easily changed due to a complex database schema with unknown side effects when modified.</li>&#13;
				<li>The system is hard to manage and operate.</li>&#13;
			</ul>&#13;
			<div id="footnote-024" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-024-backlink">6</a>	<a href="https://pragprog.com/titles/mnee2/release-it-second-edition/">Michael T. Nygard, Release It!: Design and Deploy Production-Ready Software</a></p>&#13;
			</div>&#13;
			<p>The list goes on and on.</p>&#13;
			<p>In frontline software support and operations, there is nothing worse than getting called consistently at 3 in the morning to firefight a recurrent complex system crash, and after restoring the service, the root cause analysis points back to a complex failing architecture – where there is no easy fix other than re-designing or rewriting the software.</p>&#13;
			<p>A lot of deep-seated issues with software arise from poorly judged architecture decisions. Many times, most of these decisions are made at the initial stages of product development when the big architecture is designed upfront and set in stone, concrete, or mud. Often, the system architects present their architectural masterpiece to the development teams and henceforth work to ensure the problem fits the architecture rather than the architecture fitting the problem.</p>&#13;
			<p>The development process continues using this eighth architectural wonder of the world and all goes well initially; it even may run in production. But then, one day, the business asks for some feature that doesn't fit well into the architectural approach and then there's hell to pay to get the change done.</p>&#13;
			<p>Technical decisions during development often have to be made based on the best intentions, but with incomplete or sparse information. The wisdom gained from the more experienced members of the team can often be invaluable during design discussions. Those with scars from previous projects with bad architecture are definitely worth listening to and learning from. There can, however, be a downside to this, as we'll see in The Hammer section.</p>&#13;
			<p>As a product team, we must be willing and able <a id="_idIndexMarker1003"/><a id="_idIndexMarker1004"/>to adapt and change the architecture when requirements substantially change or a system failure tells us that we're hitting the limits of our existing architecture.</p>&#13;
			<h4>Note</h4>&#13;
			<p class="callout">Generally speaking, it is better to make architectural and technical decisions as late as reasonably responsible to do so, so that the most information is available to those making the decisions.</p>&#13;
			<p class="callout">Emergent architecture is the practice of having <em class="italics">just enough of an architecture</em> so that the product developments keep moving forward, but is flexible enough that architecture changes can be made as more information becomes available.</p>&#13;
			<p>There have been literally dozens of excellent books and articles written on what is considered <em class="italics">good architecture and patterns</em> over the years. Our personal choice is anything written by <em class="italics">Martin Fowler</em> (<a href="https://martinfowler.com/books/">https://martinfowler.com/books/</a>), <em class="italics">Chris Richardson</em> (<a href="https://microservices.io/">https://microservices.io/</a>), and <em class="italics">Sam Newman</em> (<a href="https://samnewman.io/books/">https://samnewman.io/books/</a>), but there are many others.</p>&#13;
			<h2 id="_idParaDest-151"><a id="_idTextAnchor176"/>Observations from the Field</h2>&#13;
			<p>In this <a id="_idIndexMarker1005"/><a id="_idIndexMarker1006"/>section, our intention is to outline some of the recurring patterns/approaches, both good and bad, that <a id="_idIndexMarker1007"/><a id="_idIndexMarker1008"/>we've come across. None of these are new, but we thought it useful to call them out here.</p>&#13;
			<h3 id="_idParaDest-152"><a id="_idTextAnchor177"/>Patterns per Square Meter</h3>&#13;
			<p>The <em class="italics">count of software patterns applied</em> in a product is never a good quality metric. Software patterns are well-known, reusable templates for solving particular problems. Don't make the mistake of assuming that a system that includes a bunch of software patterns is superior to one with fewer of them.</p>&#13;
			<h3 id="_idParaDest-153"><a id="_idTextAnchor178"/>Expect Failures and Deal with It</h3>&#13;
			<p>Catastrophic system<a id="_idIndexMarker1009"/><a id="_idIndexMarker1010"/> failure is clearly undesirable. A system that never completely stops working in the face of subsystem failures is usually preferable. It can recover gracefully when subsystems fail and may support a subset of functions even if components are unavailable. We can apply architectural patterns wisely, for example, bulkheads to reduce the damage done by any individual failure. Absolute failures are often easier to deal with than capacity, latency, or seems kind of slow issues.</p>&#13;
			<p>When reviewing an architecture and, in particular, a distributed one, one piece of invaluable advice that I received from a very experienced architect some time ago is this – always be asking this question: <em class="italics">What happens if this component fails or slows down?</em> If there is no good answer to the question, then there is likely more that needs designing to prevent failure scenarios.</p>&#13;
			<h3 id="_idParaDest-154"><a id="_idTextAnchor179"/>The Hammer</h3>&#13;
			<p>One pattern <a id="_idIndexMarker1011"/><a id="_idIndexMarker1012"/>or behavior that we've seen a lot through the years is the Golden Hammer pattern, in other words, if all you<a id="_idIndexMarker1013"/><a id="_idIndexMarker1014"/> have is a hammer, everything looks like a nail. This is more formally known as the Law of the Instrument.</p>&#13;
			<p>All developers have their favorite tools and architectural approaches. For example, the authors are fans of reactive, streaming architectures (Mike), asynchronous event-driven messaging (Noel), and anything with Node.js or Emojis (Donal). The risk here is that your own bias may lead you down an architectural path that is ultimately the wrong approach. </p>&#13;
			<p>If you find yourself listening to the first 10-20 seconds of a discussion around a business problem and feel compelled to jump in saying Oh well, product, architecture, or tool X can help with this, let's face it, you may be reaching for your golden hammer.</p>&#13;
			<h3 id="_idParaDest-155"><a id="_idTextAnchor180"/>Resumé-Driven Development</h3>&#13;
			<p>Many times, we've been involved in discussions around a technology being used in a customer solution that is either out of place or just doesn't quite fit the problem they're trying to address. We often discover that someone had introduced this technology as they were keen to learn it and somehow it went from a technical experiment or spike to a core component technology. There's absolutely nothing wrong with technology experimentation; it should be encouraged, but care should be applied to ensure that a chosen technology doesn't lead to a dead end or become a technology solution looking for a problem. Examples of technologies where we've seen this include Service Mesh and others as depicted in <em class="italics">Figure 7.29</em>:</p>&#13;
			<div>&#13;
				<div id="_idContainer202" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_28.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.29: Adopting the coolest tech on the block</p>&#13;
			<h3 id="_idParaDest-156"><a id="_idTextAnchor181"/>Wear Different Hats</h3>&#13;
			<p>Software architecture has to work well from multiple perspectives, not just from the design and build viewpoint. Different teams/personas will have different perspectives, for example, deployment, testing, and operational management. A <em class="italics">good</em> software architecture will try to address as many of these concerns as possible.</p>&#13;
			<h3 id="_idParaDest-157"><a id="_idTextAnchor182"/>Social Media-Driven Development — Keeping Up with the Cool Kids</h3>&#13;
			<p>Companies such as Google, Amazon, and Microsoft produce and utilize some amazing technology and techniques. These are<a id="_idIndexMarker1015"/><a id="_idIndexMarker1016"/> often focused on the size of the problems that these hyper-scalers face. Most of us never work with that scale of complexity or user demand, so care should be taken that you judge technology on your particular business needs rather than what is the tech <em class="italics">du jour</em> that the <em class="italics">cool</em> kids are using. One area where we observe this a lot is in the <em class="italics">monolith versus microservices</em> discussion. Both are very relevant and very valid approaches to software architecture. Both have their pros and cons, but the correct approach to take is to ask yourself what is best for the business and customers that adds value.</p>&#13;
			<h3 id="_idParaDest-158"><a id="_idTextAnchor183"/>Good Service Design</h3>&#13;
			<p>Good <a id="_idIndexMarker1017"/><a id="_idIndexMarker1018"/>service design can be<a id="_idIndexMarker1019"/><a id="_idIndexMarker1020"/> hard to achieve. Ultimately, we should always lower the operational burden of our applications. We can do this by designing them so that we minimize the cost of change of any given application. Modern applications are normally broken down into different components or services that expose methods or functions. At the heart of good system architecture is service design. This is often based on practices such as <strong class="bold">Domain-Driven Design</strong> (<strong class="bold">DDD</strong>), which<a id="_idIndexMarker1021"/><a id="_idIndexMarker1022"/> is fundamentally about understanding a business problem and communicating that understanding among the team in an unambiguous way. Services that are part of the same business domain are grouped together, like our Tournament Service in PetBattle V2, or our Cat Service in our hobbyist application. We can achieve<a id="_idIndexMarker1023"/><a id="_idIndexMarker1024"/> good service design by following these two principles:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li><strong class="bold">Loose coupling</strong>: When a change to one service does not require a change to another service. By designing loosely coupled service APIs, we can deploy service changes easily. The interior design of the service may be changed completely without API consumers being affected.</li>&#13;
				<li><strong class="bold">High cohesion</strong>: We want related system behavior to sit together and unrelated behavior to sit elsewhere. Our order management system is independent of our shipping and delivery system. This lowers the cognitive load for developers because related system functionality sits together. Often there is design tension here between defining related business system domains (using DDD, for example) and reusable technical functionality, such as libraries or APIs, that may span multiple systems.</li>&#13;
			</ul>&#13;
			<h3 id="_idParaDest-159"><a id="_idTextAnchor184"/>Technical Design Group-Think</h3>&#13;
			<p>We have talked about some <a id="_idIndexMarker1025"/><a id="_idIndexMarker1026"/>anti-patterns when designing systems in general. Another bit of advice is for technical leaders to set directions and not just descriptions of what to do or of what has been. One way to help achieve this is an exercise in parallel thinking, whereby everyone contributes their ideas collaboratively and at the same time, rather than just following the one way of thinking from the most senior in the team. The emphasis is on <em class="italics">what can be</em>, not <em class="italics">what is</em>, to help design a way forward. It is not about who is right and who is wrong.</p>&#13;
			<h3 id="_idParaDest-160"><a id="_idTextAnchor185"/>Human Resources and Time Are Your Most Valuable Assets</h3>&#13;
			<p>In knowledge-based work, humans are usually the most expensive resource. So, it makes sense to strive to reduce toil or undifferentiated manual work. This is a never-ending trend to automate all the things, which allows much better quality and feedback for our products.</p>&#13;
			<h3 id="_idParaDest-161"><a id="_idTextAnchor186"/>Information Leakage – Data Centricity Matters</h3>&#13;
			<p>In tech, we are <a id="_idIndexMarker1027"/><a id="_idIndexMarker1028"/>flooded with data. But do we make the best use of all the data available in our applications and systems? When architecting, we have to consider carefully the quantity and quality of data available within our applications and infrastructure. Often, engineering decisions and trade-offs must be made that move data processing nearer edge devices just because sending all that data back to a central processing core is not physically possible because of bandwidth or latency restrictions, or it is just too costly to move all that data around (think cloud!). So, when designing systems, consider when:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>Data integrity is lost during data capture</li>&#13;
				<li>Data is not streamed or stored at all</li>&#13;
				<li>Data is not accessible for other uses</li>&#13;
				<li>Data is not analyzed at all</li>&#13;
				<li>Data is not communicated and remains hidden</li>&#13;
				<li>Data is not used in decision-making</li>&#13;
			</ul>&#13;
			<p>We often forget to think about how much data is lost – the lost data can be a massive source of lost opportunity for our business. This happens in cloud, IoT, industrial, and even mobile web use cases with processing data on our mobile phones.</p>&#13;
			<h3 id="_idParaDest-162"><a id="_idTextAnchor187"/>Some Final Musings on Architecture</h3>&#13;
			<p>Architecture is a critical concern when building software systems. Getting it right is a continuous balancing act of reviewing current and potential future requirements and assessing how the architecture fits those requirements.</p>&#13;
			<p>A certain degree of upfront architecture and design work is always needed, and it should be accompanied by flexibility and honesty to ensure that the initial architecture can change as answers to uncertain questions are discovered and more information is added to the collective understanding of the problems at hand. The ability to constantly improve the architecture throughout the product life cycle is another important goal.</p>&#13;
			<p>One quote that comes to<a id="_idIndexMarker1029"/><a id="_idIndexMarker1030"/> mind when we talk about big upfront decisions is the following famous quote from a Prussian field marshal: <em class="italics">No plan survives contact with the enemy. – Helmuth von Moltke</em>. Or, in more modern terms: <em class="italics">Everyone has a plan till they get punched in the mouth. – Mike Tyson</em>.</p>&#13;
			<p>Flexibility, adaptability, and the willingness to change are key characteristics required for success in dynamic environments. In <a id="_idIndexMarker1031"/><a id="_idIndexMarker1032"/>summary, there are many architectural considerations that the team needs to consider as their applications scale and adapt to change. By experimenting and adapting the architecture as the business needs change, they will be better able to deliver the <a id="_idIndexMarker1033"/><a id="_idIndexMarker1034"/>service SLAs that were promised and ultimately evolve the user experience to be optimal.</p>&#13;
			<h2 id="_idParaDest-163"><a id="_idTextAnchor188"/>Conclusion</h2>&#13;
			<p>In this chapter, we continued our exploration of technical practices to create a solid foundation for us to be able to deliver at speed as one single cohesive unit. By using techniques such as the Big Picture to gain a shared understanding of our delivery pipelines, we further identified methods for testing and how we can connect the business to the acceptance tests in a way that's more developer- and business-friendly.</p>&#13;
			<div>&#13;
				<div id="_idContainer203" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_29.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.30: Adding more technical practices to the foundation</p>&#13;
			<p>As we explored lessons that led us to an <a id="_idIndexMarker1035"/><a id="_idIndexMarker1036"/>emerging architecture approach, we also learned that a lot of the magic is in having the conversation to begin with. Treating the whole of your IT organization as a satellite will not be effective; we must create an environment where we can succeed as a whole. Key to this is bringing together the people with the knowledge, and the people with authority and power.</p>&#13;
			<p>In later chapters, we will go more in-depth into the technical implementation of PetBattle.</p>&#13;
			<p>To close off this section, we have now built a solid foundation of culture, leadership, and technical excellence. We have put in place principles and practices, including:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>Autonomy, mastery, and purpose</li>&#13;
				<li>Psychological safety</li>&#13;
				<li>Social contracts, stop-the-world events, real-time retrospectives, team identity, and information radiation</li>&#13;
				<li>Leadership intent and team empowerment</li>&#13;
				<li>Priority sliders</li>&#13;
				<li>Team spaces</li>&#13;
				<li>Everything as code</li>&#13;
				<li>Containers</li>&#13;
				<li>Continuous integration, continuous delivery, and continuous deployment</li>&#13;
				<li>Test automation</li>&#13;
				<li>Emerging architecture</li>&#13;
			</ul>&#13;
			<div>&#13;
				<div id="_idContainer204" class="IMG---Figure">&#13;
					<img src="../Images/B16297_07_30.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 7.31: The foundation of culture and technical practices</p>&#13;
			<p>Our foundation is strong. It will need continuous nurturing and bolstering as we build products on top of it. However, we're good to go with our first product teams. In the next chapter, we'll explore some practices we can use for continuous product discovery.</p>&#13;
		</div>&#13;
</body></html>