- en: 7\. Open Technical Practices — The Midpoint
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we are going to build on the foundational technical practices
    that we started in the previous chapter. We will acquire a shared understanding
    of our software delivery pipeline using the Big Picture practice. Even the less
    technical team members will be able to follow what happens to our software as
    it is being written and delivered.
  prefs: []
  type: TYPE_NORMAL
- en: We will then explain a technique that allows DevOps teams to deliver software
    changes using Git as the driving tool. The practice of GitOps leads to greater
    visibility of changes within our system, allowing the team to debug and resolve
    issues faster. We will explore how to improve our code quality through test automation
    and conclude this chapter by asking the question *How do we know if our architecture
    is good?*
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The Big Picture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GitOps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Emerging architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Big Picture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An Open Technical practice that costs little to produce but is great in creating
    a shared understanding of part of a system is the Big Picture workshop. It is
    a simple practice used to visualize all the steps that a software pipeline goes
    through in moving code from source (for example, Git), through compile and test,
    and then into the hands of our happy users. Building it collaboratively is a great
    activity for a team to do as it helps to bridge the gap between techies and business
    folks. It's great for articulating the importance and sometimes the complexity
    of continuous delivery.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.1: The Big Picture'
  prefs: []
  type: TYPE_NORMAL
- en: A Big Picture can easily be created with just some stickies and a clear board
    or space. Of course, if you're feeling more artistic, it can also be doodled!
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.2: An example Big Picture'
  prefs: []
  type: TYPE_NORMAL
- en: 'You may be reading this and thinking *Sounds fluffy to me – why should I bother
    to make one?* Here''s why:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Shared understanding**: When the whole team collaborates around making the
    Big Picture, they get a shared sense of how their pipelines connect code to users.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prototype quickly**: It''s cheaper to write and draw before implementing
    a single line of code! Rapidly prototype with some markers and Post-Its, moving
    stages of your pen and paper pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Complexity simplified**: The Big Picture helps bring non-techies into the
    mix by showing them the components required to manage the software life cycle.
    Build it up one step at a time to demonstrate the complexity in a simple visual
    flow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Information radiator**: Like all these practices, the Big Picture is an evolving
    artifact. As the complexity of a software delivery pipeline grows, the Big Picture
    should be updated to reflect this. It is a graphic that can be displayed to all
    and should not be hidden.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B16297_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.3: Collaborating to get a shared understanding of the Big Picture'
  prefs: []
  type: TYPE_NORMAL
- en: Big Pictures can also be drawn using online collaboration tools. We used Miro
    to draw the following digital Big Picture online.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.4: A digital Big Picture'
  prefs: []
  type: TYPE_NORMAL
- en: 'The material required for this practice is fairly simple: some stickies, marker
    pens, painters'' tape, and a big blank wall or canvas are all that''s required,
    and these are fairly common things to have in our kit bags! There are a number
    of simple steps to follow in creating your Big Picture, but let''s use our PetBattle
    example to show how a team might use this in practice.'
  prefs: []
  type: TYPE_NORMAL
- en: PetBattle – Building a Big Picture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The PetBattle Techies decided to build a Big Picture to demonstrate their proposal
    for how the software should be built, tested, and deployed via some automation.
  prefs: []
  type: TYPE_NORMAL
- en: First, they invite all the others in the team to help explain some of the technology
    and complexity of the automation.
  prefs: []
  type: TYPE_NORMAL
- en: 'They use painters'' tape to form a large box that represents the cloud and
    another box inside it to represent the OpenShift cluster they''re going to use
    (deployed in the cloud). In this case, the metaphor is: OpenShift is just a big
    box where we can put some things running in the cloud. The box is so large that
    we can fill it with all the things we could possibly want, from sandboxes, to
    tooling, to production apps.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.5: Starting the PetBattle Big Picture'
  prefs: []
  type: TYPE_NORMAL
- en: They draw a box to the left side to represent their local development environment.
    This is their laptop for now, but it could also be a cloud-hosted IDE that the
    development team could write their code in that is deployed inside the cluster.
    One such product, CodeReadyWorkspaces, is a cloud-hosted IDE that runs in the
    OpenShift cluster that could be of great use to the team. Using an IDE like this
    allows us to further our everything-as-code practice by providing developers with
    their coding environment as a code artifact.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, they slice up the OpenShift cluster into smaller boxes. Each of these
    represents the OpenShift projects (or Kubernetes namespaces). We can think of
    these projects as rooms that separate one collection of applications from another.
    To keep things simple, the team decides on four namespaces initially:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.6: PetBattle Big Picture projects'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dev**: A sandbox project for the dev team to validate their app or get fast
    feedback from.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test**: A project to deploy all our applications to and run our system tests
    against.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Production**: The project that PetBattle''s customers will use to access
    the applications once they''ve cleared our tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CI-CD**: The project that houses all the tooling that supports **Continuous
    Integration** (**CI**) and **Continuous Delivery** (**CD**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the OpenShift cluster logically sliced up into the projects the teams will
    use, the team draws the tools they will use in each project.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.7: PetBattle Big Picture initial frameworks'
  prefs: []
  type: TYPE_NORMAL
- en: Starting with their *local* development environment – in other words, their
    laptops or cloud-hosted workspace – the existing PetBattle is built using Angular
    (a JavaScript framework for building web apps) for the frontend. Quarkus (supersonic
    Java) is used for the API layer, and MongoDB for the persistence layer, so they
    add each of these tools to their workspace and write a one-line definition for
    how the tool or framework is being used by this team.
  prefs: []
  type: TYPE_NORMAL
- en: For PetBattle, we are going to use Helm to package up all the Kubernetes resources
    (Deployments, ConfigMaps, and so on) used to manage the application topology.
    We'll also use ArgoCD, a GitOps tool to manage our config-as-code.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.8: PetBattle Big Picture source code and registry'
  prefs: []
  type: TYPE_NORMAL
- en: PetBattle will use GitHub to store its source code. When building images, it
    is likely the team will need to store the built image internally on the OpenShift
    cluster using the internal registry. The team also wants to make their images
    available externally and so have decided to also make use of [Quay.io](http://Quay.io),
    an external registry hosted in the public cloud.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.9: PetBattle Big Picture pipeline tools'
  prefs: []
  type: TYPE_NORMAL
- en: The team then starts to add the tooling they will use to create their pipelines
    in their CI/CD namespace. They use more stickies to draw the tools and add a one-liner
    definition of what each tool is or how they will use it.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the team is going to use Jenkins for their build and test automation.
    To store and cache application build dependencies and artifacts, the team opted
    to use the open-source artifact repository called Nexus. For Nexus, they add a
    simple one-liner to highlight the fact that it is used to house their software
    artifacts as well as their Helm repository. Shared understanding is key here,
    so it's important for the team to make sure everyone is aware what the purpose
    of each item is – this includes the product owner, designers, and all other interested
    parties. They don't need to be experts, but having an understanding of what the
    tools are used for can help them establish better empathy with the development
    team and see for themselves all the things needed to be able to ship code so quickly
    to users.
  prefs: []
  type: TYPE_NORMAL
- en: With some of the tools in place on the Big Picture, the PetBattle team can now
    start to implement the design they've put in place.
  prefs: []
  type: TYPE_NORMAL
- en: The Big Picture can be created in a physical room with lots of colorful sticky
    notes or with everyone distributed using a tool such as Mural, Miro, PowerPoint
    or Google Slides. We have provided a useful template with all the icons we use
    which should help you get started. You can download this from the book's GitHub
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.10: The Big Picture template'
  prefs: []
  type: TYPE_NORMAL
- en: You can download this from the book's GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: The Big Picture allows us to get a shared understanding and team alignment around
    the use of technical tools at a high level. Like all the practices we put in place
    in this book, the Big Picture is not a one-time thing. The Big Picture is a tool
    we will revisit and enhance as we add more complexity to our architecture and
    begin implementing our pipelines. We will continue to explore the Big Picture
    in *Section 6, Build It, Run It, Own It*.
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more about, and collaborate on, Big Picture practices by going
    to the Open Practice Library page at [https://openpracticelibrary.com/practice/the-big-picture/](https://openpracticelibrary.com/practice/the-big-picture/).
  prefs: []
  type: TYPE_NORMAL
- en: GitOps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Up to this point, we've talked about Git and the developer workflows available
    to our teams. We've spoken about everything-as-code, from infrastructure to tooling
    to applications all along the stack. Now, let's tie this all together with GitOps.
  prefs: []
  type: TYPE_NORMAL
- en: GitOps sounds a bit like a buzzword, as DevOps was when it was first coined.
    In fact, we heard someone describe it to us as DevOps for the year 2020\. GitOps
    is a simple process of managing all of your systems, environments, and applications
    via Git. Git represents the single source of truth for all your applications,
    your tooling, and even your clusters. Changes to any of these things can be pull
    requested and discussed before an automated process applies them.
  prefs: []
  type: TYPE_NORMAL
- en: The difference between **infrastructure-as-code** (**IaC**) and GitOps is the
    approach to managing the configuration. IaC is agnostic to where you store the
    configuration; it could be on a flash drive in your drawer or it could be a shared
    drive in the cloud. GitOps, as the name suggests, means storing the full system
    specifications in Git.
  prefs: []
  type: TYPE_NORMAL
- en: The same principles hold true for IaC and GitOps – ideally, every action should
    be idempotent. Every action or operation can be applied multiple times, producing
    the exact same result. This is a very useful property in many situations, as it
    means that an operation can be repeated or retried as often as necessary without
    causing unintended effects. Configuration should be created declaratively. That
    is to say, you write the configuration to describe the desired state of an application
    or set of apps.
  prefs: []
  type: TYPE_NORMAL
- en: GitOps can be seen as a developer-centric approach to Ops. It teaches developers
    good practices around taking ownership of code once it leaves their machines and
    the approach to deploying and monitoring this code once it's running.
  prefs: []
  type: TYPE_NORMAL
- en: As developers, we hate repeating ourselves, so much so that we even have an
    acronym for it – DRY = don't repeat yourself! When encountering something that
    needs to be done more than once, our first instinct should be to try to automate
    it. Once something is automated or repeatable, the next step is simple. Check
    it into Git so that it can be audited, shared, and managed.
  prefs: []
  type: TYPE_NORMAL
- en: For example, whenever we want to deploy a new application to OpenShift, we could
    run some manual commands to spin up the application, create services and routes,
    and even bind a ConfigMap. But taking the time to create a Helm chart for this
    is reusable and repeatable. We can design the final state of the application in
    code and then check this into Git instead. This is a more cloud-native way of
    writing and managing our application code.
  prefs: []
  type: TYPE_NORMAL
- en: To implement a GitOps approach to our Helm chart example, all we need to do
    is connect a tool to the Git repository, which can be alerted or watch for changes
    coming through. When those changes arrive, this tool can assess the difference
    between what the current state is and what state is desired and apply the changes
    automatically for us. Enter ArgoCD.
  prefs: []
  type: TYPE_NORMAL
- en: ArgoCD
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'From ArgoCD''s website, this is described as a tool that:'
  prefs: []
  type: TYPE_NORMAL
- en: '*automates the deployment of the desired application states in the specified
    target environments. Application deployments can track updates to branches, tags,
    or be pinned to a specific version of manifests at a Git commit*.[1](#footnote-029)'
  prefs: []
  type: TYPE_NORMAL
- en: When something is seen as not matching the required state in Git, an application
    becomes out of sync. Depending on how you have implemented your GitOps, ArgoCD
    can then resync the changes to apply whatever is in Git immediately or fire a
    warning to initiate some other workflow. In the world of Continuous Delivery as
    implemented by ArgoCD, Git is the single source of truth, so we should always
    apply the changes as seen there.
  prefs: []
  type: TYPE_NORMAL
- en: What types of things can ArgoCD apply? ArgoCD recognizes traditional Kubernetes
    YAML, Kustomize,[2](#footnote-028) Helm, and all sorts of other things. Unlike
    Helm, which uses templating heavily, Kustomize allows you to take YAML files and
    emits text in a template-free declarative way. You can patch Kubernetes resources
    and use folder-based structures to apply what is termed an overlay or YAML override,
    which emits text, leaving the original YAML untouched. For our purposes, we will
    stick to Helm and a little bit of Kustomize where appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: ArgoCD is another tool (and there are others like it, such as Flux) in the long
    list of tools that we need to be able to implement CI and CD. Unlike Jenkins,
    which we could also use to manage our application deployments, ArgoCD is specialized
    and very good at managing and maintaining just our deployments.
  prefs: []
  type: TYPE_NORMAL
- en: '[1](#footnote-029-backlink) [https://argo-cd.readthedocs.io/en/stable/](https://argo-cd.readthedocs.io/en/stable/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2](#footnote-028-backlink) [https://github.com/kubernetes-sigs/kustomize](https://github.com/kubernetes-sigs/kustomize)'
  prefs: []
  type: TYPE_NORMAL
- en: Jenkins could apply our Helm charts in a done once and finish sort of way. It
    doesn't have the capability to keep watching our Kubernetes resources to ensure
    the desired state in Git stays that way in our clusters. If someone decides to
    change something in the cluster, for example, add a new environment variable to
    a running application, ArgoCD will detect that change and overwrite it. This means
    no more one-of-a-kind deployments or manual tweaks once they're deployed.
  prefs: []
  type: TYPE_NORMAL
- en: ArgoCD enables teams to enforce this golden rule – if it's not in Git, it's
    not real. This is perfect for audit tasks – all you have to do is check the Git
    log to see who committed and pushed the code.
  prefs: []
  type: TYPE_NORMAL
- en: If It's Not in Git, It's Not Real!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](img/Author_21.jpg)![](img/Author_41.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We worked on a virtual residency with the World Health Organization helping
    to manage the COVID-19 crisis. We were building a new platform to help educate
    people in the field and disseminate information faster. We decided to use GitOps
    to do Continuous Delivery and, in particular, used ArgoCD to manage our Helm charts.
  prefs: []
  type: TYPE_NORMAL
- en: To do cloud-native properly, namespaces and environments should be ephemeral.
    We should be able to recreate everything of use to us from their description in
    code. This includes namespaces, quotas, and role bindings, as well as applications
    and databases. To prove this in one sprint, we created a cleanup job that would
    delete the dev and test projects in OpenShift. Our configuration repository was
    linked to ArgoCD, which watched the cluster and, if anything changed, it was set
    to reapply the resources as described in Git. The time for this job to execute
    was on a Wednesday afternoon around lunchtime, about an hour before our sprint
    review. What could possibly go wrong?
  prefs: []
  type: TYPE_NORMAL
- en: The team got ready to do their demo as normal, but about 20 mins before showtime,
    one team member called out that the build was failing and his demo was broken
    and he could not figure out why. The team scrambled to sort the issue, with everyone
    jumping on a call and mobbing around the problem. Rewinding what could have changed
    in the past hour, the only thing that had executed was the cleanup job we had
    written. We immediately thought we'd written something incorrectly with our job
    and so went to debug it, but it was fine. The next step was to look more closely
    at the build and the failure message.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we discovered someone on the team had manually deployed a database
    to the dev environment. They were connecting to it for their demo AND using it
    as the test database in our Jenkins Pipelines. Essentially, someone on the team
    had created a Pet – a hand-reared server that was cared for and nurtured by one
    person and not known about by the rest of the team. In the world of ephemeral
    environments, what we really want is Cattle. Cattle are mass-produced, created
    using automation, and killed off when no longer required. Hence, when our job
    ran to clear out the project, all resources were destroyed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The team learned a valuable lesson in this experience which they made very
    visible:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.11: If it''s not in Git, it''s not real'
  prefs: []
  type: TYPE_NORMAL
- en: It gave rise to a mantra we added to our social contract from *Chapter 4, Open
    Culture.*
  prefs: []
  type: TYPE_NORMAL
- en: Implementing GitOps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![](img/Techie1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let's build the big picture with some real working code! In this section, we
    are going to take a technical detour! Prepare for some code snippets. If this
    is not your thing, feel free to skip over it to the next section all about testing!
    We'll mark any section that's going to have code snippets with this handy sign.
  prefs: []
  type: TYPE_NORMAL
- en: Let's explore ArgoCD and create the components of our Big Picture from code.
    To do this, we will first explore a sample project that can be used as a starting
    point for development.
  prefs: []
  type: TYPE_NORMAL
- en: At Red Hat Open Innovation Labs, we have automated the bootstrap of Labs Residency
    CI-CD tooling to accelerate setup and onboarding. The code repository is called
    Ubiquitous Journey, so it makes sense for us to start here. We will explore this
    repository and set up our technical foundation using it. In later sections of
    the book, we will extend it with new technology and tools. This repo is available
    on the PetBattle GitHub organization – [https://github.com/petbattle/ubiquitous-journey](https://github.com/petbattle/ubiquitous-journey).
  prefs: []
  type: TYPE_NORMAL
- en: The first task we would normally perform on our OpenShift cluster when deploying
    Jenkins is to create a new project using the command line. We could follow this
    manual approach again, adding in role bindings and quotas for our project, and
    repeat these steps for each bit of our Big Picture. But let's do it in a way that
    honors our everything-as-code practice.
  prefs: []
  type: TYPE_NORMAL
- en: From your laptop, fork the sample project and open it up in your favorite code
    editor.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to make changes to our project so maintaining your own copy of
    it is necessary for GitOps. From here on out, when we encounter a new repo, you'll
    probably find it easier to fork it so you can make changes to it. For the purposes
    of the book going forward, we will continue using PetBattle organization so feel
    free to equate this to your own organization or user.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The Ubiquitous Journey project is broken down into two main components (some
    of the files are removed from the breakdown below for simplicity), Bootstrap and
    Ubiquitous Journey. If you're wondering why we named the project Ubiquitous Journey…
    well, we didn't! We hit the **generate random name** button on GitHub and this
    is what it chose for us. As is the case with most things in software, naming things
    is hard! We did plan on renaming the repo at some stage, but now the name has
    kind of stuck and we like it!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The bootstrap folder contains a Helm chart definition with a values-bootstrap.yaml
    file and Chart.yaml manifest. There are no templates for this chart because it''s
    actually just a wrapper for other Helm charts. If we look at the Chart.yaml manifest,
    we can see that it has a dependency of the ArgoCD chart, another called bootstrap,
    and a helper chart called sealed-secrets. The bootstrap folder Helm chart is acting
    as a wrapper chart, allowing us to control the variables we pass to these dependencies.
    In this case, our variables are stored in the `values-bootstrap.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The bootstrap chart is responsible for creating the listed projects in our OpenShift
    cluster. In the example, these are labs-ci-cd, labs-dev, labs-test, labs-staging,
    labs-pm, and labs-cluster-ops. Dev, Test, Staging, and CI/CD will hopefully be
    self-explanatory; if not, take a look at the previous chapter, where we discussed
    CI/CD in depth. The labs-pm namespace is for deploying other project management
    tools (for example, collaboration tools such as etherpad). The labs-cluster-ops
    namespace is used for operational jobs and tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Resources in OpenShift have **role-based access control** (**RBAC**) applied.[3](#footnote-027)
    RBAC determines whether a user is allowed to perform a given action within a project.
    We bind the listed user groups to the service accounts within these projects.
    Don't worry if your cluster does not have the labs-dev and labs-admin groups set
    up right now. It is enough if you are logged in to your cluster with a user who
    has cluster admin privilege.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '[3](#footnote-027-backlink) [https://docs.openshift.com/container-platform/4.6/authentication/using-rbac.html](https://docs.openshift.com/container-platform/4.6/authentication/using-rbac.html)'
  prefs: []
  type: TYPE_NORMAL
- en: The second part of this file overwrites some variables in the ArgoCD chart.
    This Helm chart installs the ArgoCD operator and configures it with sensible defaults.
    For a list of all the possible variables that could be passed to this chart, you
    can check out the Operator Docs for ArgoCD – [https://argocd-operator.readthedocs.io/en/latest/](https://argocd-operator.readthedocs.io/en/latest/).
    There is no point in recreating those docs in this book, but it's useful to have
    them saved if you want to do some exploring.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth calling out the `applicationInstanceLabelKey` variable. This needs
    to be unique for your cluster. If you deploy more than one instance of ArgoCD
    to a cluster with the same instance label, the two ArgoCD instances will try to
    manage the same resources and then they'll fight over who actually owns them and
    get you into a world of pain, so make sure the `applicationInstanceLabelKey` is
    unique!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s deploy this setup and see what it gives us. If you wish to change the
    names of the projects that are created, you can edit the values file, but for
    now we''ll use the defaults. In a terminal on your laptop, try the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Running a Helm template like this should bring down our chart dependencies and
    process our templates. This can be a handy way to validate that the YAML file
    looks as we expect. Let's install the bootstrap Helm chart into its own namespace.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this command should be a successful installation of the bootstrap
    Helm chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.12: Bootstrap ArgoCD using Helm'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check the pods coming up with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'You should start to see the ArgoCD server start to come alive after a minute
    or two:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.13: Labs-ci-cd namespace pods starting up'
  prefs: []
  type: TYPE_NORMAL
- en: 'Or, if you have a look in the UI, you should see the topology with all the
    components of ArgoCD:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.14: OpenShift developer topology view of the labs-ci-cd project'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at ArgoCD by clicking the link in the UI, or you can get
    the URL from the command line using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Log in with your OpenShift credentials. We should see an empty ArgoCD instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.15: Empty ArgoCD instance from the web interface'
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we should ask ourselves the question *What happens when someone
    changes the bootstrap configuration values for our cluster?* for example, to add
    more projects or change the roles or groups? Can we do this in an automated and
    tracked way, in other words, using GitOps? Fear not, ArgoCD to the rescue! We
    can now point ArgoCD to the Git repository we've been working on.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create an ArgoCD application from the ArgoCD web interface by selecting
    +New App -> Edit as YAML and copying and pasting the following definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Hit Save, followed by Create. You should see the `bootstrap-journey` application
    synced:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.16: Bootstrap ArgoCD application from the web interface'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also create the same application on the terminal. You can log in using
    single sign-on to OpenShift from the terminal using this one liner. It requires
    a terminal that is not headless, in other words, it can connect to your screen
    and browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: Create the new app and sync the changes. With this in place, argocd will now
    actively track changes to our Git repository and roll them out for us! Simple!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'You can select the application in the web interface to drill down into it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.17: Bootstrap application details from the web interface'
  prefs: []
  type: TYPE_NORMAL
- en: Excellent – we are on our way to completing our Big Picture as code and laying
    down our technical foundation! We've created the projects and added the first
    tool, ArgoCD, to our kit bag. Now, let's take it a step further and fill our cluster
    with some of the applications we think would be initially useful for building
    out CI/CD pipelines. At the beginning of any project, this will usually be a best
    guess. As we start to build out the product, we must continuously evolve the toolset
    we use. This is not a one-time process; it's a set of tools that need to be extended
    when required or trashed if no longer useful. The important thing here is to ensure
    that things are deployed in a repeatable way.
  prefs: []
  type: TYPE_NORMAL
- en: Let's add some tooling. Open your editor on the ubiquitous-journey project.
    Inside ubiquitous-journey/values-tooling.yaml, we have some useful variables referencing
    Helm charts ready for us to pick from, including Jenkins, which we manually deployed
    previously!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: The layout of this file is simple. For each item in the applications array,
    it expects to find a Helm chart or a reference to a Git repository with some Kubernetes
    yaml (or Kustomize) at a particular version.
  prefs: []
  type: TYPE_NORMAL
- en: When using Helm, any overrides to the defaults supplied by the chart can be
    added here, but for the Nexus chart shown, we are using the default values, so
    there is no need for value overrides for Nexus. There are other fields for each
    application, and these are mostly related to the operation of ArgoCD. For example,
    you can configure the application synchronization policy – sync-policy – which
    tells ArgoCD to always keep your application synced when set to automatic. The
    destination namespace may be specified. With some Kubernetes and OpenShift API
    objects, ArgoCD needs to be asked to ignore differences it finds; this is particularly
    true when controllers and operators write back the status and other fields into
    the objects themselves. We have found over time that each release of ArgoCD lessens
    the need to specify these *ignores* as the generated differences are taken care
    of automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other important field for each application entry is the `enabled: true
    | false` – it''s easy to run down the list and enable the tools we know we need
    straight away. For now, we are going to start with just four tools: Jenkins, Nexus,
    Tekton, and Code Ready Workspaces. These are the bare bones for scaffolding our
    application and pipelines. At this point, it is worth mentioning the other two
    `values` files, `extratooling` and `day2ops`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: Like our CI/CD application list in `values-tooling.yaml`, they contain references
    to useful Helm charts and YAML files for deploying in our cluster. The extra tooling
    contains project management and collaboration tools, while the `day2ops` contains
    useful prune jobs to keep our cluster tidy. For now, we will disable all of the
    extra tooling and day2ops apps. This gives us a minimal setup to get started with.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are running CRC, please check the Appendix for any details prior to
    deploying the tooling. Let''s deploy these tools from the command line using Helm
    and `oc`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: If you check the ArgoCD web page, you should now see these applications begin
    to deploy and synchronize into your cluster. It will take some time for them all
    to synchronize completely. Jenkins, for example, builds all of the default agent
    images that we may need for running pipeline jobs.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.18: The complete picture with all our tools installed'
  prefs: []
  type: TYPE_NORMAL
- en: We have now successfully bootstrapped our CI/CD tooling! We will revisit these
    configurations as we find we need to add and update the tools we need to develop,
    test, and deliver PetBattle. By practicing *everything-as-code*, we can easily
    redeploy these tools into any Kubernetes cluster, track changes we may make, and
    manage the life cycle of the tools (upgrade them as their versions and features
    change).
  prefs: []
  type: TYPE_NORMAL
- en: Testing Testing Testing!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Up to this point, we've spoken about some of the tools we can use to move application
    code from ideas through compilation and into deployment. But how do we know the
    stuff we've built is actually working as we expect it to? If we create a pipeline
    that just compiles code and moves it to production – is it done? No, there are
    testing quality steps and gates that we need to introduce into our software pipelines!
  prefs: []
  type: TYPE_NORMAL
- en: The Test Automation Pyramid
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: How do we know our feature works as we expect it to? We should test it and see!
    It is not always clear how we should test our feature, nor is it clear when we
    have done too much or not enough testing. Should we create test instructions and
    manually test the feature? Should we test the feature in isolation? Should we
    test all its constituent parts or just the whole thing? What is a definition of
    a unit test exactly?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s face it, testing is complicated. We are going to advocate for creating
    not just any tests, but automated tests! *The Test Automation Pyramid*, authored
    by *Michael Cohn*, is a good starting point for us moving through the world of
    automated testing. Let''s take a simplified look at the *traditional* test automation
    pyramid by the original author:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image043.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.19: The testing triangle'
  prefs: []
  type: TYPE_NORMAL
- en: In the standard three-tiered testing triangle, the things at the bottom (listed
    above as **UNIT TESTS**) are the things we should do more of. Unit tests are the
    smallest amount of code we can test within an application. These units should
    have little to no dependency on other items and so when we run them, they give
    us immediate and precise feedback. Unit tests should point us exactly to where
    the problem is in our code. Moreover, the thinking here is that unit tests are
    cheap to write, easy to maintain, and fast to execute. Therefore, we want more
    of them. This is why they sit at the base of the testing triangle.
  prefs: []
  type: TYPE_NORMAL
- en: Service tests are sometimes seen as integration tests and are the next level
    up the testing triangle. These are API tests that are validating the services
    within your application behave as expected. This may include single service calls,
    as well as chains of service calls, when one service calls another service. The
    width of the testing tier in the triangle relates to how many types of a particular
    test there should be in your code base. According to the pyramid, we should have
    fewer of these service tests than unit tests as they can be costly to execute.
  prefs: []
  type: TYPE_NORMAL
- en: The top tier of the testing triangle is reserved for **User Interface** (**UI**)
    tests, or end-to-end system tests. These are responsible for validating that the
    system, as the sum of its components and parts, is behaving as expected. Often,
    UI tests can be brittle in the face of change, break more often, and require maintenance
    to keep them relevant, so the rationale from the testing pyramid is that we should
    do fewer of these as they are difficult to perform and provide less feedback for
    us.
  prefs: []
  type: TYPE_NORMAL
- en: Testing in Practice
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Test Automation Pyramid is a great place to start when thinking about your
    own testing. As with all models and patterns, people have over-simplified some
    of its original meaning. In fact, if you do an image search for the testing pyramid,
    you'll see that most of the results are missing the most important keyword – automation!
    Often, organizations lose sight of this, and they think doing manual testing for
    these tiers is good enough.
  prefs: []
  type: TYPE_NORMAL
- en: Testing is important; in fact, it's critical to being able to deliver at speed!
    If you imagine not investing the time into writing automated tests, it may be
    possible to complete a sprint without breaking things. It's probable that we'd
    be able to do two sprints and not break things. However, once we hit that third
    or fourth sprint, that's when your software system starts to misbehave. Applications
    that were written in sprint one now have bugs appearing in them because their
    functional behavior does not work as intended. Functions and APIs that were thought
    to be working were, in fact, completely broken! Being able to release software
    at speed is one thing, but being able to release quality software at speed is
    the differentiator.
  prefs: []
  type: TYPE_NORMAL
- en: What is important when thinking about testing is to apply context. You don't
    have to blindly follow a model such as the testing pyramid. In fact, it's a good
    place to start from, but it's not a golden hammer to apply in all environments.
    For example, you might be building a web app with static content or third-party
    services, so UI testing is probably the most important thing.
  prefs: []
  type: TYPE_NORMAL
- en: What is important is to be sensible about the types of testing you're aiming
    to perform and the value they provide. You may find that it's more important to
    your product that covering the services layer is a better option. If you don't
    have access to the code, then writing black-box tests that assess the services
    with well-defined inputs and outputs is more appropriate to your quality control.
    Likewise, measuring the number of tests, as suggested by the pyramid, tells us
    nothing about the quality of the tests. Good quality tests catch errors before
    your user does. When there is a failure in production, or a bug raised by a user,
    it is very likely that you need to write some more automated tests.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image045.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.20: Measuring tests'
  prefs: []
  type: TYPE_NORMAL
- en: The other way to look at this would be to calculate the risk of not testing
    a piece of functionality. Perhaps the application you're writing is a one-time
    throwaway or just a simple technical spike that does not require rigorous testing.
    However, if a piece of functionality within your product is used all the time
    and it has no automated tests written for it at all, this could be a good place
    to focus your automated testing efforts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a culture within your product development team where testing is a continual
    practice. Testing should not be an afterthought of the development process. All
    too often, we see testing beginning once the development team throws a package
    over a wall to the test team for some testing to begin. For us, every item in
    a sprint will always have some level of testing. This isn''t done by some third-party
    team, but by the engineers themselves. Developers will often favor unit and integration
    testing, but **quality assurance** (**QA**) teams will often favor automated UI
    testing to validate the application from a user''s point of view. Sometimes, if
    the culture is not right and a team is being squeezed to turn out new features,
    testing quality can drop, leading to an almost inverted testing pyramid: a few
    unit tests on the bottom, followed by a few more service tests, and then a load
    of brittle UI tests sitting on top! This has an effect on the quality of the software
    delivery pipelines. The feedback loop from Dev to QA can be very long, with little
    to no value from unit tests and expensive UI tests that are not providing feedback
    quickly enough.'
  prefs: []
  type: TYPE_NORMAL
- en: Decreasing the quality by inverting the testing pyramid during delivery can
    be very damaging to a team. If the volume of defects increases markedly, trust
    in the team will falter. If there is no trust in the team, then autonomy could
    be the next thing to break, leading to a heavy command-and-control-driven culture.
    Teams operating in this way will very quickly fail and top talent will leave.
  prefs: []
  type: TYPE_NORMAL
- en: Testing and the Definition of Done
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](img/Author_42.jpg)![](img/Noel2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: While working on a residency recently with the World Health Organization, we
    started out with great ambition to write tests for each sprint item. We got off
    to a good start by including testing in our Definition of Done for each sprint
    item. We agreed that there must be some automated testing for each item being
    taken into a sprint.
  prefs: []
  type: TYPE_NORMAL
- en: The first sprint went by in a flash as we were working in one-week iterations.
    As we were a new team, everyone was motivated and keen to try new things. By sprint
    three, we were taking on more stories than we could get through with our team's
    capacity.
  prefs: []
  type: TYPE_NORMAL
- en: The work we were doing was becoming more complex and we missed out some of the
    automated tests. We claimed a feature or two were done. In the demo for that week,
    we admitted to the product owner that the piece of work was functionally done,
    but not done according to our own criteria.
  prefs: []
  type: TYPE_NORMAL
- en: We tried to be honest with ourselves, but found we'd slipped up again the following
    week. At this point, it became clear to us that when we did sprint planning, we
    were not thinking correctly about the capacity required for writing tests. The
    Definition of Done was in place, but we were still not being honest. We were a
    team that was keen to keep moving forward and picking up new items before previous
    ones were done.
  prefs: []
  type: TYPE_NORMAL
- en: In a retrospective session, we decided a good way forward would be for us to
    capture testing effort when writing our tasks. When taking an item from the backlog,
    we would add subtasks for all of the automated testing. This way, all of the work
    associated with test automation became visible to the team because these subtasks
    were on the sprint board. Having a task to write tests for your feature makes
    it pretty hard to move on to the next item when it's still in progress!
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more and collaborate on CI practices by going to the Open Practice
    Library page at [https://openpracticelibrary.com/practice/test-automation/](https://openpracticelibrary.com/practice/test-automation/).
  prefs: []
  type: TYPE_NORMAL
- en: TDD or BDD or DDT
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are a number of books written on testing and how to write great tests
    that are meaningful and provide value. Our ambition is not to rewrite these books,
    but to give you pointers to things you could research further if this topic really
    interests you. Some approaches to testing that teams find useful at the various
    levels of the triangle are things such as **Behavior-Driven Development** (**BDD**),
    **Test-Driven Development** (**TDD**), and **Developer-Driven Testing** (**DDT**).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.21: Test-Driven Development'
  prefs: []
  type: TYPE_NORMAL
- en: 'TDD is a simple process, yet somewhat misunderstood by some teams. The process
    is fairly simple. Start off by writing some tests for the functionality you''re
    building. At this point, they should fail (**RED**). If they don''t fail, then
    your tests are not very well written OR the functionality already exists! A developer
    will then write the code to make the test pass (**GREEN**). With the tests now
    green, refactoring can take place or, as Kent Beck, an American software engineer
    and the creator of extreme programming, puts it, *refactor to remove duplication*.
    Remove duplicate code or make the code leaner and tidy it up while maintaining
    the green state of the tests. The process is simple: **Red > Green > Refactor**.
    Writing tests first is a hard practice to do and takes time and perseverance to
    get the skills right, but it can lead to less spaghetti code. Because the tests
    are written first, they lead the design and implementation of the code.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.22: Executing Test-Driven Development'
  prefs: []
  type: TYPE_NORMAL
- en: 'A great exercise to do with teams wanting to try TDD without code is to do
    the Lego TDD simulation on Gargoyle Software''s website: [http://gargoylesoftware.com/articles/lego_tdd](http://gargoylesoftware.com/articles/lego_tdd).'
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more and collaborate on TDD by going to the Open Practice Library
    page at [openpracticelibrary.com/practice/test-driven-development](http://openpracticelibrary.com/practice/test-driven-development).
  prefs: []
  type: TYPE_NORMAL
- en: DDT is easy and probably the place to start if you're not writing any tests.
    The important point here is that some tests are being written! DDT focuses on
    the developers writing code as well as writing the tests. Simply put, the developer
    codes for a bit, writes some automated tests, and then goes back to coding and
    testing. This might sound a bit like TDD, but the key difference is the order.
    Code first and then test, resulting in the code influencing the tests as opposed
    to the tests leading the software design. The objective of DDT is that developers
    need to own their code and that everyone should be responsible for testing.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.23: Developer-Driven Testing'
  prefs: []
  type: TYPE_NORMAL
- en: BDD is a great tool to have in your toolbox as it brings people together in
    a shared understanding of the scope of a story or feature under development. It's
    less of an engineering tool and more of a method that focuses on the conversation
    to be had between business and developers when writing features. BDD is about
    using a shared language to write concrete examples of how an application should
    behave.
  prefs: []
  type: TYPE_NORMAL
- en: 'How the tests are implemented is then decided by the developers. But, more
    importantly, a common language can be used between developers and product owners
    to scope out a story without leading the design of the software. BDD can be a
    useful way to write acceptance criteria for a story together. There is a common
    syntax or approach to writing BDD tests based on work by *Dan North*, an agile
    coach and originator of BDD[4](#footnote-026):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: '[4](#footnote-026-backlink) [https://dannorth.net/introducing-bdd/](https://dannorth.net/introducing-bdd/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: For any feature being developed, there are probably a number of scenarios that
    could be tested. These scenarios are defined using the common syntax of Given,
    When, Then. Codifying the acceptance criteria using a common syntax can simplify
    the writing of tests and gaining a shared understanding of the scope of an activity.
    Dan North suggested this story-driven approach to BDD some years back and, since
    then, the syntax has been adopted by lots of the testing frameworks, such as Cucumber.
  prefs: []
  type: TYPE_NORMAL
- en: BDD for Our Ops Tooling Python Library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](img/Author_22.jpg)![](img/Author_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'I worked on a public sector engagement a few years back. I was part of a team
    helping them automate some of their Ops capabilities. They had teams of people
    configuring VMs manually in a non-repeatable way. Part of that work involved me
    building a command-line interface for the team to help automate the creation and
    onboarding of team members (users) and their roles into a Free IPA server (Red
    Hat Identity Management). The following screenshot shows one of the BDD scenario
    templates for adding an existing user and deleting a user:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_231.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.24: A BDD scenario'
  prefs: []
  type: TYPE_NORMAL
- en: The architect on the team was a strong believer in the BDD approach to writing
    stories. All of our acceptance criteria were written in this way, and it was a
    great way for us to understand the scope of what we were doing. When I was pairing
    with another engineer, we would use the acceptance criteria written in the BDD
    syntax as our starting point. We imported the syntax straight from Jira to scaffold
    out the test cases using Python Behave. For us as engineers, this made coding
    the features a breeze. We had been given the specifications, so we could easily
    implement our code to pass the tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'BDD can help engineers understand the context of features better. It also helps
    bridge the gap of alignment with business experts and product owners:'
  prefs: []
  type: TYPE_NORMAL
- en: Product Owners Seeing Their Thoughts in Code!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we coach teams, we encourage them to use the sprint review or showcase
    events as an opportunity to show the world EVERYTHING they've worked on. That
    includes setting up and improving test automation.
  prefs: []
  type: TYPE_NORMAL
- en: One particular recurrence I've noticed from several teams I've worked with is
    when the product owner or business SMEs first see automation of BDD running. They
    think back to the sprint planning event a week or two earlier, when the teams
    were confirming acceptance criteria for stories they were going to accept into
    the sprint. Often, these criteria would be written using BDD syntax and it would
    be the PO or business experts providing the input.
  prefs: []
  type: TYPE_NORMAL
- en: When they see a test automation suite running in the sprint review or showcase,
    they will see the console showing the tests automated, the same thoughts, the
    same instructions, and the same business logic all codified.
  prefs: []
  type: TYPE_NORMAL
- en: BDD brings down the wall between technology and business people.
  prefs: []
  type: TYPE_NORMAL
- en: Example Mapping
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Example Mapping, by Matt Wynne, CEO of Cucumber,[5](#footnote-025) is another
    great tool to have in the toolbox. Once again, with a lot of these practices,
    it''s just another really useful way to articulate and drive a conversation. In
    this case, Example Mapping is primarily used to drive shared understanding when
    writing stories and creating acceptance criteria. We believe it''s great for helping
    teams write behavioral-driven tests. The process is simple and only involves four
    colored Post-Its:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Yellow**: For the story itself (as a header for the example map)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Blue**: For specific rules associated with the story'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Green**: For examples of rules'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Red**: For questions or unknowns that arise during the discussion'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5](#footnote-025-backlink) [https://cucumber.io/blog/bdd/example-mapping-introduction/](https://cucumber.io/blog/bdd/example-mapping-introduction/)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.25: Example Mapping'
  prefs: []
  type: TYPE_NORMAL
- en: Begin by selecting a story and write it on a yellow sticky note. Place it at
    the top of your example map as a header. In a horizontal row underneath that,
    begin writing business rules on blue sticky notes. Beneath the blue business rules,
    create columns of green sticky notes with individual examples of those business
    rules. These could be relatively unstructured Friends-notation *The one where...*
    examples, or full-blown Given, When, Then criteria.
  prefs: []
  type: TYPE_NORMAL
- en: As misunderstandings arise surrounding individual examples or entire business
    rules, add red stickies with questions written on them.
  prefs: []
  type: TYPE_NORMAL
- en: When there are enough examples that everyone is comfortable with, they can be
    rewritten as both automated tests and acceptance criteria.
  prefs: []
  type: TYPE_NORMAL
- en: Example Mapping in the Field
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](img/Noel3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: On the World Health Organization residency, I found this practice so simple
    to use but such a great tool to articulate the scope of a story and get alignment
    on the acceptance tests we'd write.
  prefs: []
  type: TYPE_NORMAL
- en: We were using Event Storming (more on this later) to model the onboarding process
    for a new user to their application. We had a command that read *Submit relevant
    topics of interest*, which was added to our backlog. We chose this command so
    we could learn more about things our users would be interested in, in order to
    better serve them recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: We used Example Mapping to break this story down by first writing some rules.
    We were not super strict on following a ubiquitous language at this point as we
    knew the team would convert them into BDD-style syntax afterward.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.26: Example Mapping example'
  prefs: []
  type: TYPE_NORMAL
- en: The conversion within the team brought out some misunderstandings regarding
    the scope of the activity. The developers wondered more about edge cases, such
    as, *what happens if the page is refreshed or returned to?* We were able to capture
    these questions as part of the Example Mapping and add a new rule and some examples.
    Subsequently, the team could convert the examples into the BDD syntax.
  prefs: []
  type: TYPE_NORMAL
- en: As with all these practices, the act of having this conversation with the correct
    people and capturing the examples meant we gained great team alignment and were
    able to convert them to acceptance tests and implement them as part of our development
    workflow.
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more about, and collaborate on, the Example Mapping practice by
    going to the Open Practice Library page at [openpracticelibrary.com/practice/example-mapping](http://openpracticelibrary.com/practice/example-mapping).
  prefs: []
  type: TYPE_NORMAL
- en: Non-functional Testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While the importance of testing cannot be overstated, it's critical to keep
    an eye on other metrics that may give further insight into the quality of our
    code. For example, how do you know your tests have enough breadth to check all
    the code? What if my tests are passing, but the application response time is awful?
    Traditional unit and integration testing might not catch these things. There are
    tools we can use to identify causes and issues with our code base and, more importantly,
    fix them sooner rather than later.
  prefs: []
  type: TYPE_NORMAL
- en: Code coverage reporters are simple to implement and usually come bundled up
    with a lot of modern test frameworks. The idea is simple. While running our test
    cases, the code base is being watched. Once test execution is completed, a report
    is generated showing what lines of code have been hit and where there are gaps.
    These are useful reports to help the team identify where there is room for improvement
    but they should not be treated as the absolute truth. As with all these things,
    there are ways to trick the coverage reports, but good developers and peer review
    processes should catch these things. Often, teams will strive to increase the
    testing coverage if they have not started from a very good state. Bringing these
    reports to a retrospective can be good for teams to analyze and set higher targets.
    More aggressive teams may even fail their pipeline as unstable if the coverage
    is below a certain threshold!
  prefs: []
  type: TYPE_NORMAL
- en: Static code analysis is another tool that can provide insight into a code base
    not detected by unit testing, creating rules for how the code should look and
    execute. Consistency in an approach to how you write code is particularly important
    for non-compiled languages such as JavaScript. JavaScript also behaves differently
    in different browsers, so writing a set of rules such as using single quotes instead
    of double quotes for all strings can help ward off any unexpected behavior. If
    we have the rules codified, we may as well ensure that everyone adheres to them,
    so add them to our pipeline! Coding standards are very important in multi-team
    setups too. If the code base conforms to a standard structure and design, it can
    also make maintenance and updates to it very simple.
  prefs: []
  type: TYPE_NORMAL
- en: Performance Testing Sam's Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](img/Author_23.jpg)![](img/Author_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Around 2014, we worked for a retail organization building mobile backend services
    and some automation around it. This layer of services was responsible for aggregating
    data from different backend systems such as product listers and categories, and
    reviews. The services also performed some very basic data manipulation to make
    the payloads more mobile consumable. It was critical that the adapters responded
    in a very timely manner, as mobile latency was high compared to modern mobile
    networks and a fast API response time made all the difference.
  prefs: []
  type: TYPE_NORMAL
- en: Our team was always cognizant that we should keep track of the time taken for
    the adapters to respond. We knew the organization would perform a traditional
    load-testing initiative at the end of the program; however, we didn't want to
    wait until then to reveal any surprises. We figured there had to be a way to continuously
    validate changes we made to the adapter tier in order to highlight any performance
    degradation.
  prefs: []
  type: TYPE_NORMAL
- en: We created a nightly job in Jenkins (our automation tool) to check the performance
    of the adapters each evening. This was a fairly simple job that simulated 1,000s
    of parallel requests to the APIs. From this, we plotted the response time of the
    service each day and reported it through Jenkins. This allowed us to create a
    baseline for where a normal response should be and allow us to fail the job's
    execution if the value fell above or below an expected range!
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.27: Automated discovery of performance bottlenecks'
  prefs: []
  type: TYPE_NORMAL
- en: One day, we came into the office and our nightly job had turned red! Perfect,
    we thought, let's Stop the World and stop all the things we're doing while we
    inspect what's changed in the system since last night. A quick check of the changes
    that were made in the system revealed that Sam, one of the team members, had tried
    to check in some new logic for one of the data translation functions. Sam had
    introduced a big loop inside a loop inside another loop, which had caused the
    code execution time to spike. It was something that was not caught by our traditional
    unit testing, as the logic was working fine. It was just taking longer to compute.
  prefs: []
  type: TYPE_NORMAL
- en: We quickly responded and fixed the problem immediately. If we hadn't caught
    this performance bottleneck, it could have been weeks or more before we realized
    what was happening. We could have been building more functionality on top of this
    dodgy piece of code, making it much harder to unpick at a later date.
  prefs: []
  type: TYPE_NORMAL
- en: Being able to respond to feedback like this was critical. We're not saying that
    big load testing on the product was not necessary, but this one simple automated
    job provided us with a ton of value just by catching this one issue. It was cheap
    to write and maintain and caught this error potentially sooner than we would otherwise
    have noticed. Sam tried to write some more code a few weeks later and we got a
    similar failure.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.28: More light automated performance tests'
  prefs: []
  type: TYPE_NORMAL
- en: Have no fear though – Sam, who's a good friend of ours, no longer writes code
    for a living as he's moved into a technical sales role. We don't have a blame
    culture within our workspaces and I'm sure if Sam was telling you this story,
    he'd say it was one of us that checked in that silly piece of code. I'll let you
    decide who it was.
  prefs: []
  type: TYPE_NORMAL
- en: There are lots of other types of testing and I won't list them all; we'd have
    to write another book to fit them all in. We go into more detail about the non-functional
    nature of our software in the next section, *Discover It*.
  prefs: []
  type: TYPE_NORMAL
- en: A Few Final Thoughts on Testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We cannot understate the importance of testing in delivering features at speed,
    especially automated testing. Whether you follow the test pyramid or some other
    paradigm is up to you – just remember it's all about the conversation. If TDD
    is not the right thing for you, make sure you still have the conversation between
    business and technical teams to identify sensible tests using examples. The go-to
    for us is to use BDD as it allows us to bring together the world of business and
    technology.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we're not saying there is no place in the world for separate QA teams.
    Not at all, it's about automating all the things and getting feedback early. If
    the QA is a separate function within your organization and is only engaged some
    weeks before going live, then this is a problem. Bring the skills of QA into the
    team and left-shift that capability into the team so that they can get early feedback
    more often.
  prefs: []
  type: TYPE_NORMAL
- en: Emerging Architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Hope is not a design method*.[6](#footnote-024)'
  prefs: []
  type: TYPE_NORMAL
- en: How do we know our architecture is good? What does good mean? Is good architecture
    measurable? Have you ever had to operate, support, or fix a system that is poorly
    architected?
  prefs: []
  type: TYPE_NORMAL
- en: 'It may be easier to identify some characteristics of what *a* *poor architecture*
    looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: An unstable and unreliable system that fails regularly in unknown and unexpected
    ways.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The system is slow from a user's point of view.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It does not scale well with increased users or loads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is hard to upgrade because one small change requires everything to be re-deployed,
    which is slow and costly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is dependent on clients or other systems and cannot be easily modified or
    changed without changing the other systems as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has a lot of complex business functions that are buried in the database,
    that may involve triggers, and cannot be easily changed due to a complex database
    schema with unknown side effects when modified.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The system is hard to manage and operate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6](#footnote-024-backlink) [Michael T. Nygard, Release It!: Design and Deploy
    Production-Ready Software](https://pragprog.com/titles/mnee2/release-it-second-edition/)'
  prefs: []
  type: TYPE_NORMAL
- en: The list goes on and on.
  prefs: []
  type: TYPE_NORMAL
- en: In frontline software support and operations, there is nothing worse than getting
    called consistently at 3 in the morning to firefight a recurrent complex system
    crash, and after restoring the service, the root cause analysis points back to
    a complex failing architecture – where there is no easy fix other than re-designing
    or rewriting the software.
  prefs: []
  type: TYPE_NORMAL
- en: A lot of deep-seated issues with software arise from poorly judged architecture
    decisions. Many times, most of these decisions are made at the initial stages
    of product development when the big architecture is designed upfront and set in
    stone, concrete, or mud. Often, the system architects present their architectural
    masterpiece to the development teams and henceforth work to ensure the problem
    fits the architecture rather than the architecture fitting the problem.
  prefs: []
  type: TYPE_NORMAL
- en: The development process continues using this eighth architectural wonder of
    the world and all goes well initially; it even may run in production. But then,
    one day, the business asks for some feature that doesn't fit well into the architectural
    approach and then there's hell to pay to get the change done.
  prefs: []
  type: TYPE_NORMAL
- en: Technical decisions during development often have to be made based on the best
    intentions, but with incomplete or sparse information. The wisdom gained from
    the more experienced members of the team can often be invaluable during design
    discussions. Those with scars from previous projects with bad architecture are
    definitely worth listening to and learning from. There can, however, be a downside
    to this, as we'll see in The Hammer section.
  prefs: []
  type: TYPE_NORMAL
- en: As a product team, we must be willing and able to adapt and change the architecture
    when requirements substantially change or a system failure tells us that we're
    hitting the limits of our existing architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Generally speaking, it is better to make architectural and technical decisions
    as late as reasonably responsible to do so, so that the most information is available
    to those making the decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Emergent architecture is the practice of having *just enough of an architecture*
    so that the product developments keep moving forward, but is flexible enough that
    architecture changes can be made as more information becomes available.
  prefs: []
  type: TYPE_NORMAL
- en: There have been literally dozens of excellent books and articles written on
    what is considered *good architecture and patterns* over the years. Our personal
    choice is anything written by *Martin Fowler* ([https://martinfowler.com/books/](https://martinfowler.com/books/)),
    *Chris Richardson* ([https://microservices.io/](https://microservices.io/)), and
    *Sam Newman* ([https://samnewman.io/books/](https://samnewman.io/books/)), but
    there are many others.
  prefs: []
  type: TYPE_NORMAL
- en: Observations from the Field
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, our intention is to outline some of the recurring patterns/approaches,
    both good and bad, that we've come across. None of these are new, but we thought
    it useful to call them out here.
  prefs: []
  type: TYPE_NORMAL
- en: Patterns per Square Meter
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *count of software patterns applied* in a product is never a good quality
    metric. Software patterns are well-known, reusable templates for solving particular
    problems. Don't make the mistake of assuming that a system that includes a bunch
    of software patterns is superior to one with fewer of them.
  prefs: []
  type: TYPE_NORMAL
- en: Expect Failures and Deal with It
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Catastrophic system failure is clearly undesirable. A system that never completely
    stops working in the face of subsystem failures is usually preferable. It can
    recover gracefully when subsystems fail and may support a subset of functions
    even if components are unavailable. We can apply architectural patterns wisely,
    for example, bulkheads to reduce the damage done by any individual failure. Absolute
    failures are often easier to deal with than capacity, latency, or seems kind of
    slow issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'When reviewing an architecture and, in particular, a distributed one, one piece
    of invaluable advice that I received from a very experienced architect some time
    ago is this – always be asking this question: *What happens if this component
    fails or slows down?* If there is no good answer to the question, then there is
    likely more that needs designing to prevent failure scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: The Hammer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One pattern or behavior that we've seen a lot through the years is the Golden
    Hammer pattern, in other words, if all you have is a hammer, everything looks
    like a nail. This is more formally known as the Law of the Instrument.
  prefs: []
  type: TYPE_NORMAL
- en: All developers have their favorite tools and architectural approaches. For example,
    the authors are fans of reactive, streaming architectures (Mike), asynchronous
    event-driven messaging (Noel), and anything with Node.js or Emojis (Donal). The
    risk here is that your own bias may lead you down an architectural path that is
    ultimately the wrong approach.
  prefs: []
  type: TYPE_NORMAL
- en: If you find yourself listening to the first 10-20 seconds of a discussion around
    a business problem and feel compelled to jump in saying Oh well, product, architecture,
    or tool X can help with this, let's face it, you may be reaching for your golden
    hammer.
  prefs: []
  type: TYPE_NORMAL
- en: Resumé-Driven Development
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Many times, we''ve been involved in discussions around a technology being used
    in a customer solution that is either out of place or just doesn''t quite fit
    the problem they''re trying to address. We often discover that someone had introduced
    this technology as they were keen to learn it and somehow it went from a technical
    experiment or spike to a core component technology. There''s absolutely nothing
    wrong with technology experimentation; it should be encouraged, but care should
    be applied to ensure that a chosen technology doesn''t lead to a dead end or become
    a technology solution looking for a problem. Examples of technologies where we''ve
    seen this include Service Mesh and others as depicted in *Figure 7.29*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.29: Adopting the coolest tech on the block'
  prefs: []
  type: TYPE_NORMAL
- en: Wear Different Hats
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Software architecture has to work well from multiple perspectives, not just
    from the design and build viewpoint. Different teams/personas will have different
    perspectives, for example, deployment, testing, and operational management. A
    *good* software architecture will try to address as many of these concerns as
    possible.
  prefs: []
  type: TYPE_NORMAL
- en: Social Media-Driven Development — Keeping Up with the Cool Kids
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Companies such as Google, Amazon, and Microsoft produce and utilize some amazing
    technology and techniques. These are often focused on the size of the problems
    that these hyper-scalers face. Most of us never work with that scale of complexity
    or user demand, so care should be taken that you judge technology on your particular
    business needs rather than what is the tech *du jour* that the *cool* kids are
    using. One area where we observe this a lot is in the *monolith versus microservices*
    discussion. Both are very relevant and very valid approaches to software architecture.
    Both have their pros and cons, but the correct approach to take is to ask yourself
    what is best for the business and customers that adds value.
  prefs: []
  type: TYPE_NORMAL
- en: Good Service Design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Good service design can be hard to achieve. Ultimately, we should always lower
    the operational burden of our applications. We can do this by designing them so
    that we minimize the cost of change of any given application. Modern applications
    are normally broken down into different components or services that expose methods
    or functions. At the heart of good system architecture is service design. This
    is often based on practices such as **Domain-Driven Design** (**DDD**), which
    is fundamentally about understanding a business problem and communicating that
    understanding among the team in an unambiguous way. Services that are part of
    the same business domain are grouped together, like our Tournament Service in
    PetBattle V2, or our Cat Service in our hobbyist application. We can achieve good
    service design by following these two principles:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Loose coupling**: When a change to one service does not require a change
    to another service. By designing loosely coupled service APIs, we can deploy service
    changes easily. The interior design of the service may be changed completely without
    API consumers being affected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High cohesion**: We want related system behavior to sit together and unrelated
    behavior to sit elsewhere. Our order management system is independent of our shipping
    and delivery system. This lowers the cognitive load for developers because related
    system functionality sits together. Often there is design tension here between
    defining related business system domains (using DDD, for example) and reusable
    technical functionality, such as libraries or APIs, that may span multiple systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical Design Group-Think
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have talked about some anti-patterns when designing systems in general. Another
    bit of advice is for technical leaders to set directions and not just descriptions
    of what to do or of what has been. One way to help achieve this is an exercise
    in parallel thinking, whereby everyone contributes their ideas collaboratively
    and at the same time, rather than just following the one way of thinking from
    the most senior in the team. The emphasis is on *what can be*, not *what is*,
    to help design a way forward. It is not about who is right and who is wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Human Resources and Time Are Your Most Valuable Assets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In knowledge-based work, humans are usually the most expensive resource. So,
    it makes sense to strive to reduce toil or undifferentiated manual work. This
    is a never-ending trend to automate all the things, which allows much better quality
    and feedback for our products.
  prefs: []
  type: TYPE_NORMAL
- en: Information Leakage – Data Centricity Matters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In tech, we are flooded with data. But do we make the best use of all the data
    available in our applications and systems? When architecting, we have to consider
    carefully the quantity and quality of data available within our applications and
    infrastructure. Often, engineering decisions and trade-offs must be made that
    move data processing nearer edge devices just because sending all that data back
    to a central processing core is not physically possible because of bandwidth or
    latency restrictions, or it is just too costly to move all that data around (think
    cloud!). So, when designing systems, consider when:'
  prefs: []
  type: TYPE_NORMAL
- en: Data integrity is lost during data capture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data is not streamed or stored at all
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data is not accessible for other uses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data is not analyzed at all
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data is not communicated and remains hidden
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data is not used in decision-making
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We often forget to think about how much data is lost – the lost data can be
    a massive source of lost opportunity for our business. This happens in cloud,
    IoT, industrial, and even mobile web use cases with processing data on our mobile
    phones.
  prefs: []
  type: TYPE_NORMAL
- en: Some Final Musings on Architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Architecture is a critical concern when building software systems. Getting it
    right is a continuous balancing act of reviewing current and potential future
    requirements and assessing how the architecture fits those requirements.
  prefs: []
  type: TYPE_NORMAL
- en: A certain degree of upfront architecture and design work is always needed, and
    it should be accompanied by flexibility and honesty to ensure that the initial
    architecture can change as answers to uncertain questions are discovered and more
    information is added to the collective understanding of the problems at hand.
    The ability to constantly improve the architecture throughout the product life
    cycle is another important goal.
  prefs: []
  type: TYPE_NORMAL
- en: 'One quote that comes to mind when we talk about big upfront decisions is the
    following famous quote from a Prussian field marshal: *No plan survives contact
    with the enemy. – Helmuth von Moltke*. Or, in more modern terms: *Everyone has
    a plan till they get punched in the mouth. – Mike Tyson*.'
  prefs: []
  type: TYPE_NORMAL
- en: Flexibility, adaptability, and the willingness to change are key characteristics
    required for success in dynamic environments. In summary, there are many architectural
    considerations that the team needs to consider as their applications scale and
    adapt to change. By experimenting and adapting the architecture as the business
    needs change, they will be better able to deliver the service SLAs that were promised
    and ultimately evolve the user experience to be optimal.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we continued our exploration of technical practices to create
    a solid foundation for us to be able to deliver at speed as one single cohesive
    unit. By using techniques such as the Big Picture to gain a shared understanding
    of our delivery pipelines, we further identified methods for testing and how we
    can connect the business to the acceptance tests in a way that's more developer-
    and business-friendly.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_07_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.30: Adding more technical practices to the foundation'
  prefs: []
  type: TYPE_NORMAL
- en: As we explored lessons that led us to an emerging architecture approach, we
    also learned that a lot of the magic is in having the conversation to begin with.
    Treating the whole of your IT organization as a satellite will not be effective;
    we must create an environment where we can succeed as a whole. Key to this is
    bringing together the people with the knowledge, and the people with authority
    and power.
  prefs: []
  type: TYPE_NORMAL
- en: In later chapters, we will go more in-depth into the technical implementation
    of PetBattle.
  prefs: []
  type: TYPE_NORMAL
- en: 'To close off this section, we have now built a solid foundation of culture,
    leadership, and technical excellence. We have put in place principles and practices,
    including:'
  prefs: []
  type: TYPE_NORMAL
- en: Autonomy, mastery, and purpose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Psychological safety
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Social contracts, stop-the-world events, real-time retrospectives, team identity,
    and information radiation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leadership intent and team empowerment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Priority sliders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Team spaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Everything as code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous integration, continuous delivery, and continuous deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test automation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Emerging architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B16297_07_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.31: The foundation of culture and technical practices'
  prefs: []
  type: TYPE_NORMAL
- en: Our foundation is strong. It will need continuous nurturing and bolstering as
    we build products on top of it. However, we're good to go with our first product
    teams. In the next chapter, we'll explore some practices we can use for continuous
    product discovery.
  prefs: []
  type: TYPE_NORMAL
