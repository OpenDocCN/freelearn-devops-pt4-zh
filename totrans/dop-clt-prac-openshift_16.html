<html><head></head><body>
		<div>&#13;
			<div id="_idContainer325" class="Content">&#13;
			</div>&#13;
		</div>&#13;
		<div id="_idContainer326" class="Content">&#13;
			<h1 id="_idParaDest-225">11. <a id="_idTextAnchor258"/>The Options Pivot</h1>&#13;
		</div>&#13;
		<div id="_idContainer371" class="Content">&#13;
			<p><a id="_idTextAnchor259"/>During the Discovery Loop, we started to come up with lots of ideas for implementation. The Impact Map gave us deliverables that formed hypothesis statements. The human-centered design and Empathy Mapping practices gave us ideas directly from the user. The Event Storm gave us standalone features (triggered by commands) that can be implemented using standalone microservices (codifying the aggregate). The Metrics-Based Process Map and Non-Functional Map gave us ideas on how we can speed up the development cycle and improve security, maintainability, operability, scalability, auditability, traceability, reusability, and just about anything else that ends with ability!</p>&#13;
			<p>The next step after the Discovery Loop is <a id="_idIndexMarker1391"/><a id="_idIndexMarker1392"/>the Options Pivot, where all the information from these practices that we've used gets boiled down to a list of options for actions to take and decisions to make on what to deliver next.</p>&#13;
			<p>The Options Pivot is the heart of the Mobius Loop. On the left-hand side of it is where we absorb all the learning and Target Outcomes we aligned on in the Discovery Loop. We generate further ideas. We refine ideas on what to deliver next and then choose the options to work on. Later in the book, in <em class="italics">Chapter 17, Improve It</em>, we'll look at the right-hand side of the Options Pivot. This is where we adapt our approach based on the measurements and learnings from a completed iteration of the Delivery Loop. We decide whether to do more Discovery, more Delivery, or Pivot completely. We refine what to discover or deliver next.</p>&#13;
			<p>Remember, we are working in fully autonomous, cross-functional teams. We don't have separate testing teams for performance or usability, so we can't assume work items associated with these functions will be dealt with on the other side of the wall! This makes our job difficult as we have to weigh up the relative values of different options. We have to decide between new feature development, urgent bug fixes, platform improvements to speed up development, usability improvements, enhancements to security, and many other aspects that will make our product better.</p>&#13;
			<p>In this chapter, we're going to do the following:</p>&#13;
			<ol>&#13;
				<li>Visualize all the work we might do using the <strong class="bold">User Story Mapping</strong> practice.</li>&#13;
				<li>Organize all our work into small, thin slices of value using the <strong class="bold">Value Slicing</strong> practice so that we can continuously deliver value.</li>&#13;
				<li>Start the <strong class="bold">Design of Experiments</strong> practice to test hypotheses that emerged during the Discovery Loop.</li>&#13;
				<li>Prioritize by exploring different practices that help us in the Options Pivot, including <strong class="bold">Impact and Effort Prioritization</strong>, <strong class="bold">How/Now/Wow Prioritization</strong>, and the <strong class="bold">Design Sprint</strong>.</li>&#13;
				<li>Form the initial <strong class="bold">Product Backlog</strong> with traceability to all preceding practices. </li>&#13;
				<li>Set up <strong class="bold">Product Backlog Refinement</strong> to happen on an ongoing basis.</li>&#13;
				<li>Apply <strong class="bold">Economic Prioritization</strong> to Product Backlog items.</li>&#13;
				<li>Explain the importance of the <strong class="bold">Product Owner</strong> role in achieving all of the above.</li>&#13;
				<li>Explore how experiments can be supported by some of the <strong class="bold">advanced deployment capabilities</strong> enabled by the OpenShift platform and how we can plan to use these to ensure we maximize learning from our Delivery Loops.</li>&#13;
			</ol>&#13;
			<p>Let's start with one of our favorite visualization practices to radiate and plan lots of small incremental releases by slicing value.</p>&#13;
			<h2 id="_idParaDest-226"><a id="_idTextAnchor260"/>Value Slicing</h2>&#13;
			<p>We are approaching the<a id="_idIndexMarker1393"/><a id="_idIndexMarker1394"/> part of the Mobius mental model where we will start delivering increments of our solution. They will vary from running short prototypes and technical experiments or spikes, to conducting defined user research, to implementing features that have resulted from Event Storming and other Discovery practices.</p>&#13;
			<p>An iteration of the Delivery Loop is not prescribed in length. If you are using a popular iterative agile delivery framework such as Scrum, an iteration of the Delivery Loop translates well to one sprint (a fixed time-box between one and four weeks). If you are using a more continuous delivery approach such as Kanban to enable an ongoing flow of value, each Delivery Loop may simply represent the processing of one Product Backlog item and delivering it into the product. You may even be using a non-agile delivery methodology such as Waterfall whereby the Delivery Loop is more singular and slower to move around. The Mobius Loop is agnostic to the delivery approach. But what is consistent regardless of the delivery approach is the idea that we seek to deliver high-value work sooner, establish important learning more quickly, and work in small batch sizes of delivery effort so we can measure and learn the impact to inform our next set of decisions.</p>&#13;
			<p>To help us break down all our work items and ensure they are grouped to a level that will form small increments of value, we use popular visualization and planning practices.</p>&#13;
			<p>Simple path mapping techniques break the work down by mapping back from the Target Outcomes to the least number of steps needed to deliver it. There are many other practices, such as journey mapping, story mapping, future state mapping, service blueprints, and more. Mobius is less concerned with the how, as long as you focus on finding the simplest way to deliver the outcomes. This technique we have found works very effectively is called Value Slicing.</p>&#13;
			<p>Let's look at how we approach Value Slicing.</p>&#13;
			<p>First, we note all of the<a id="_idIndexMarker1395"/><a id="_idIndexMarker1396"/> standalone work ideas that have been generated by the Discovery practices. Our focus here is now on Outputs (and not Outcomes) as we want to group all of our deliverables together and form an incremental release strategy that delivers the outcomes. A starting point is to copy each of the following from existing artifacts:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>Deliverables captured on the Impact Map</li>&#13;
				<li>Commands captured on the Event Storm</li>&#13;
				<li>Ideas and feedback captured on Empathy Maps</li>&#13;
				<li>Non-functional work needed to support decisions made on the Non-Functional Map</li>&#13;
				<li>Ideas and non-functional features captured during discussion of the <strong class="bold">Metrics-Based Process Map</strong> (<strong class="bold">MBPM</strong>)</li>&#13;
				<li>All the other features and ideas that have come up during any other Discovery Loop practices you may have used and the many conversations that occurred</li>&#13;
			</ul>&#13;
			<p>Here are a couple of tips we've picked up from our experience. First, don't simply move sticky notes from one artifact to this new space. You should keep the Impact Map, Event Storms, Empathy Maps, MBPMs, and other artifacts as standalone artifacts, fully intact in the original form. They will be very useful when we return to them after doing some Delivery Loops.</p>&#13;
			<p>Second, copy word-for-word the items you're picking up from those practices. As we'll see in the coming chapters, we will really benefit when we can trace work items through the Discovery Loop, Options Pivot, and Delivery Loop, so keeping language consistent will help with this. Some teams even invest in a key or coding system to show this traceability from the outset.</p>&#13;
			<div>&#13;
				<div id="_idContainer327" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_01.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.1: Collecting information and ideas from Discovery Loop practices</p>&#13;
			<p>To start with, simply spread all the items across a large work surface. There's something very satisfying about standing back and seeing all the possible work we know of in front of us. It can be<a id="_idIndexMarker1397"/><a id="_idIndexMarker1398"/> amazing to see just how much has been ideated from those few practices. It can also be a bit <a id="_idIndexMarker1399"/>chaotic and daunting. This is why we need to start organizing the work.</p>&#13;
			<p>If you're working virtually with people distributed, having a Canvas such as the following one (and available for download from the book's GitHub repository) may be helpful:</p>&#13;
			<div>&#13;
				<div id="_idContainer328" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_02.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.2: User Story and Value Slice Map template</p>&#13;
			<p>Next, remove any duplicates. For example, you may have identified a deliverable on your Impact Map and the same feature has ended up in your Event Storm. Your user interviews may also have found similar feature ideas captured on Empathy Maps. Where there are identical features, remove the duplicate. If the idea can be broken down into smaller standalone ideas, refactor and re-write your sticky notes to have these multiple ideas. The more the better in this practice!</p>&#13;
			<p>The next step is to categorize each of the items into some kind of common theme and give that theme a title. We're looking for something that brings all of the items together. If you were to put each item into a bucket, what would the label on the bucket be? A top tip is to start with the Target Outcomes that were derived from the Discovery Loop and set them as the headings to categorize each item under. The reason we do this is that we want to work with an outcome-driven mindset. We have agreed on some Target Outcomes so, really, every work item we are considering should be taking us to one or more of those outcomes. If we pick any one of the items and can't easily see an outcome it will help achieve, we should be questioning the value of doing that thing at all. (There are cases where such items that don't map to outcomes are still important, so if this does happen, just give them their own pile.)</p>&#13;
			<p>We should end up with all items in a neat, straight column directly beneath the Target Outcome they are categorized under.</p>&#13;
			<p>If we have a good, well-thought-out set of Primary Outcomes and Enabling Outcomes, it should be a very positive exercise mapping all of the features, experiments, research ideas, and so on to an outcome. This exercise should be collaborative and include all members of the cross-functional team. Developers, operators, designers, Product Owners, business SMEs, and so on <a id="_idIndexMarker1400"/><a id="_idIndexMarker1401"/>will all have been involved and provided input to the preceding Discovery Loop practices. They should remain included during the Options Pivot to ensure their ideas and initiatives are understood and included on the map.</p>&#13;
			<p>The resulting <a id="_idIndexMarker1402"/><a id="_idIndexMarker1403"/>visualization of work should include functional features and non-functional initiatives. All of the work that can take place on the platform to enable faster and safer development and quicker release of product features should be shown. If we stand back at the end of the exercise, we should start to see our delivery loops starting to emerge.</p>&#13;
			<div>&#13;
				<div id="_idContainer329" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_03.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.3: Clustering tasks under Target Outcomes</p>&#13;
			<p>The next step is to prioritize all tasks and items on the board. This is never easy but nearly always needed. If you have worked on a project where time has not been an issue and it's been obvious that the team will have all the time, they need to confidently deliver everything asked of them, you are in a unique position! That has never happened to us and there has always been a need to prioritize work and choose what not to do! This can start with the Product Owner deciding his or her perspective on priority. However, as we progress through this chapter, we'll look at a few practices and tools that you can bring out to help with prioritization in a collaborative environment and drive consensus. Executing those practices can then be reflected on this value map we're creating.</p>&#13;
			<p>We like to attempt to prioritize each column. So, take each Target Outcome with all of the features and other items that we believe will achieve them and prioritize them. The most important and compelling items should be at the top. These are the items that need to be prioritized above anything else if you are to achieve the outcome. The lesser understood or "nice to have" items should be further down the column.</p>&#13;
			<p>The final stage is to <a id="_idIndexMarker1404"/><a id="_idIndexMarker1405"/>slice value out of the value map. Using some sticky tape (ideally colored, such as painters' tape), we ask the person who holds overall responsibility for prioritizing work and articulating value (usually this is the <strong class="bold">Product Owner</strong> for a team using Scrum) to slice horizontally what they see as a slice of value for the whole product. This means looking at the most important items for each theme and combining them with some of the other highly important items from other themes.</p>&#13;
			<div>&#13;
				<div id="_idContainer330" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_04.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.4: Prioritizing work within clusters</p>&#13;
			<p>At this point, our Product Owner has a huge amount of power. They can prioritize within a given outcome. They can prioritize a whole outcome and move everything down or up. They can combine items together from different outcomes to form proposed releases. They can slice one, two, three, or fifty slices of value – each one containing one, two, or more items. Most importantly, they can facilitate conversations with all stakeholders and team members to arrive at a consensus on this two-dimensional Value Slice Map.</p>&#13;
			<div>&#13;
				<div id="_idContainer331" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_05.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.5: Two-dimensional Value Slice Map</p>&#13;
			<p>During many years of<a id="_idIndexMarker1406"/><a id="_idIndexMarker1407"/> using these practices, we've picked up a few facilitation tips to help explain them correctly. The first involves how you might visualize and plan two valuable activities.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-227" class="Author-Heading"><a id="_idTextAnchor261"/>The Beer and the Curry</h2>&#13;
			<div>&#13;
				<div id="_idContainer332" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/author_face_1.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			<p>In 2017, I led an engagement with a global oil company. Toward the end of the first week, the team was tired. It had been a busy, intensive week. We'd formed our team and built our foundation of culture. We'd run several practices of the Discovery Loop, including user Empathy Mapping and Event Storming, which involved lots of standing, lots of thinking, and lots of conversation.</p>&#13;
			<p>On Thursday afternoon, I was <a id="_idIndexMarker1408"/><a id="_idIndexMarker1409"/>facilitating User Story Mapping and Value Slicing based on all the items that had been captured on the Event Storm and Empathy Maps. This practice was new to the team. After we had gone through the first few steps by putting all the work on the wall and organizing it against the outcomes, I talked about the need to slice and prioritize.</p>&#13;
			<p>I started by saying, <em class="italics">Obviously, we'd like to do all this work,</em> after which one of the senior stakeholders interrupted and said, <em class="italics">YES! We need to do all this work.</em> I could sense there was some discomfort among stakeholders, as if I was doing a typical consultants' effort on locking down scope when the stakeholders wanted everything built. Perhaps my leading choice of words could have been better.</p>&#13;
			<div>&#13;
				<div id="_idContainer333" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_06.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Figure 11.6: Explaining Value Slicing</p>&#13;
			<p>But I wasn't trying to decide what was in and out of scope. My whole agile mindset is based on flexible scope, the ability to adapt and change scope as we learn more, and always ensuring we're delivering the next most valuable and important work.</p>&#13;
			<p>To explain my mindset, my thoughts fast-forwarded to a team social we had planned for later that day. It had been a long week and we had planned to go for a few drinks and a curry – again boosting our cultural foundation further by allowing the team to relax and get to know each other a bit better.</p>&#13;
			<p>I was looking forward to having a beer and having a curry after that beer. In fact, I was really looking forward to that beer. I felt we'd really earned it that week and it was going to be great to raise a glass and say cheers with my new team! But that didn't mean that the curry wasn't important. Nor did it mean that the curry was not going to happen. We were going to have a beer first followed by a curry. That was how we'd prioritized the evening. We hadn't de-scoped anything nor were we planning to. The beer was in my top slice of value. The curry was in my second slice of value.</p>&#13;
			<p>The team felt more relaxed understanding we were not de-scoping any work at all using this practice but simply organizing by value. The team also felt very relaxed and enjoyed both a beer and a curry!</p>&#13;
			</div>&#13;
			<p>We've also learned a few simple tricks that can <a id="_idIndexMarker1410"/><a id="_idIndexMarker1411"/>help set up the Value Slicing practice to work effectively. </p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-228" class="Author-Heading"><a id="_idTextAnchor262"/>One to Few to Many Slices of Value – Continuous Delivery</h2>&#13;
			<div>&#13;
				<div id="_idContainer334" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/author_face_1.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			<p>I've learned various tricks over the years of facilitating this exercise.</p>&#13;
			<p>One of the first times I ran it, we had organized all the work into columns linked to Target Outcomes and we progressed to the slicing part of the practice. I placed one slice of tape on the wall and asked the Product Owner and stakeholders to move the sticky notes they deemed the most valuable above that line of tape and the less valuable ones beneath that line.</p>&#13;
			<p>As I observed the team working through this process, I realized that the single line of tape had generated a misleading point of this practice. There was a reluctance to put anything beneath the line because there was a perception that this meant <strong class="bold">out of scope</strong>. I explained this was not the case and what I was trying to do was slice out the <strong class="bold">Minimal Viable Product</strong> or <strong class="bold">MVP</strong>. MVP defines the minimum number of features that could form the product that could be released to users to learn from and build upon. In reality, many stakeholders see defining the MVP as something negative as it's where they lose all the great innovative featuresthat they may want but are not collectively deemed important. I actually try to avoid using the term MVP, as it is often greeted with some negative emotion.</p>&#13;
			<p>I learned from this facilitation that one slice should never be used as we are not defining things as in or out of scope and we are not defining just the MVP.</p>&#13;
			<p>Working with another customer in Finland, I took this learning and adapted my facilitation approach. With all the items that had been captured from the Discovery Loop on the map, I produced three slices of tape. Hopefully now the Product Owner and stakeholders would not fall into the in-scope/out-of-scope trap. However, now there was a new misunderstanding! For this particular engagement, which was an immersive four-week Open Innovation Labs residency focused on improved operations, we had planned three one-week sprints. By coincidence, I had produced three slices of tape for Value Slicing. So, the stakeholders and Product Owner assumed that whatever we put in the first slice would form the scope for Sprint 1, the second slice would be Sprint 2, and the third slice would be Sprint 3.</p>&#13;
			<div>&#13;
				<div id="_idContainer335" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_07.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Figure 11.7: Value Slicing of the items captured from the Discovery Loop </p>&#13;
			<p>I explained that this was not the case. We do not yet know how long it will take the team to deliver each item in each slice. We will use other practices in the Delivery Loop to help us understand that. We could end up delivering more than one slice in one sprint. Or, it may take more than one sprint to deliver one slice. We just don't know yet.</p>&#13;
			<p>Since then, I have tweaked my facilitation further. When making the slices available, I now produce lots of them – at least 10, sometimes more than 20. I also make the roll of tape accessible and tell the Product Owner to use as many slices as they would like – the more the better, in fact! I've found Value Slice Maps now often have many more slices.</p>&#13;
			<p>A Product Owner from a UK defensecompany once remarked to me that you could argue that each item on the Value Slice board could be its own slice of value. I celebrated with a massive smile when I heard this. Yes! When we reach that mindset and approach, we truly are reaching the goal of continuous delivery.</p>&#13;
			<div>&#13;
				<div id="_idContainer336" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_08.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Figure 11.8: Value Slicing with many slices</p>&#13;
			</div>&#13;
			<p>Visualizing and slicing increments of value has evolved from the amazing thinking and work produced <a id="_idIndexMarker1412"/><a id="_idIndexMarker1413"/>by Jeff Patton in his book <em class="italics">User Story Mapping</em><span id="footnote-052-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-052">1</a></span> published in 2008. User Story Mapping is an effective practice for creating lightweight release plans that can drive iterative and incremental delivery practices. We highly recommend reading Patton's book and trying out the exercise he describes in his fifth chapter about visualizing and slicing out the value of something very simple, like everything you do in the morning to get up, get ready, and travel to work. We use this exercise in our enablement workshops and find it really brings the practice to life well. </p>&#13;
			&#13;
			<p>Let's look at how the PetBattle team approached Value Slicing.</p>&#13;
			<div id="footnote-052" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-052-backlink">1</a>	<a href="https://www.jpattonassociates.com/user-story-mapping/">https://www.jpattonassociates.com/user-story-mapping/</a></p>&#13;
			</div>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-229" class="Author-Heading"><a id="_idTextAnchor263"/>PetBattle – Slicing Value towards Continuous Delivery</h2>&#13;
			<p>The PetBattle team reviewed all of the artifacts they produced during their first Discovery Loop.</p>&#13;
			<p>The Impact Map identified "Increasing <a id="_idIndexMarker1414"/><a id="_idIndexMarker1415"/>Site Engagement" for Uploaders as the place they wanted to invest in running experiments and building initial features. The Empathy Map of Mary, their user, added further support to building tournament services and a live leaderboard. The team Event Stormed the idea of Mary entering the daily tournament and winning a prize to break down the event flow to identify commands, read models, some UI ideas, and aggregates. The Metrics-Based Process Map identified some bottlenecks in the existing PetBattle deployment steps, mainly due to a lack of automation. Finally, the team brainstormed all the non-functional considerations they had.</p>&#13;
			<p>They copied all of the features that had resulted from these onto fresh sticky notes and spread them across the wall.</p>&#13;
			<p>Then it was time to consider the headings for their Value Slicing Map. The team recalled that they distilled all of the Discovery Loop information and learning into three primary Target Outcomes:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>PetBattle is generating revenue from an increased active user base.</li>&#13;
				<li>PetBattle is always online.</li>&#13;
				<li>Improved team satisfaction with excitement to build and run PetBattle.</li>&#13;
				</ul>&#13;
				<p>They also identified an additional Enabling Outcome:</p>&#13;
				<ul style="list-style-type:disc;">&#13;
				<li>Reduce Operational Incidents with impact to customers.</li>&#13;
				</ul>&#13;
				<p>These four outcomes formed the backbone of the PetBattle Value Slice Map.</p>&#13;
<div id="_idContainer337" class="IMG---Figure"><img src="../Images/B16297_11_09.jpg" alt=""/></div>&#13;
<p>Figure 11.9: Target Outcomes backbone</p>&#13;
<p>As the team explored these four outcomes further, they thought it might help to break them down a bit further to help with shared understanding with stakeholders. The Impact Map had driven focus on four outcomes:</p>&#13;
				<ul style="list-style-type:disc;">&#13;
				<li>Increased participation rate of the casual viewer</li>&#13;
				<li>Increased uploads</li>&#13;
				<li>Increased site engagement of the uploaders</li>&#13;
				<li>Increased number of sponsored competitions</li>&#13;
				</ul>&#13;
				<p>Collectively, these would all help with the first primary outcome where PetBattle would be generating revenue from an increased active user base. So, these were added to the Value Slice Map:</p>&#13;
<div id="_idContainer338" class="IMG---Figure"><img src="../Images/B16297_11_10.jpg" alt=""/></div>&#13;
<p>Figure 11.10: First Target Outcome broken down</p>&#13;
<p>The second primary outcome was that PetBattle would be online.</p>&#13;
<p>The team reflected on the sections of their Non-Functional Map and recognized three outcomes that would help achieve this:</p>&#13;
<ul style="list-style-type:disc;">&#13;
				<li>Improve Site Reliability</li>&#13;
				<li>Improve Maintainability and Supportability</li>&#13;
				<li>Increase Auditability and Observability</li>&#13;
				</ul>&#13;
				<div id="_idContainer339" class="IMG---Figure"><img src="../Images/B16297_11_11.jpg" alt=""/></div>&#13;
<p>Figure 11.11: Second Target Outcome broken down</p>&#13;
<p>As the team discussed the third primary outcome, Improved team satisfaction with excitement to build and run PetBattle, their conversations were all about achieving great testability. Having a foundation of technical practices that would allow them to automate different levels of tests and also user-test, utilizing advanced deployment techniques, would make them very happy. They also reflected on some of the ideas they came up with when they were forming as a team and building their foundation of culture – socials, having breakfast and lunches together, and starting a book club were just a few ideas that would help improve team culture. So, they added these important headings:</p>&#13;
<div id="_idContainer340" class="IMG---Figure"><img src="../Images/B16297_11_12.jpg" alt=""/></div>&#13;
<p>Figure 11.12: Third Target Outcome broken down</p>&#13;
<p>Finally, they had their Enabling Outcome, whereby reducing operational incidents with impact to customers would help drive all the other outcomes. This could also be broken into three areas:</p>&#13;
				<ul style="list-style-type:disc;">&#13;
				<li>Reduce Security Risks</li>&#13;
				<li>Improve Reusability</li>&#13;
				<li>Enhance Performance and Scalability&#13;
				</li>&#13;
				</ul>&#13;
				<div id="_idContainer341" class="IMG---Figure"><img src="../Images/B16297_11_13.jpg" alt=""/></div>&#13;
<p>Figure 11.13: Fourth Target Outcome broken down</p>&#13;
<p>So, they had a huge collection of outputs spread over one wall and an organized set of outcomes as headings on another wall:</p>&#13;
<div id="_idContainer342" class="IMG---Figure"><img src="../Images/B16297_11_14.jpg" alt=""/></div>&#13;
<p>Figure 11.14: All Target Outcomes at two levels</p>&#13;
<p>It was time to connect the outputs to the outcomes by forming columns beneath each outcome.</p>&#13;
<p>They started with the first primary outcome. The outputs sourced here were mainly commands from the Event Storm, supported by<a id="_idIndexMarker1416"/><a id="_idIndexMarker1417"/> focused impacts on the Impact Map and high motivations captured on the Empathy Map.</p>&#13;
<div id="_idContainer343" class="IMG---Figure"><img src="../Images/B16297_11_15.jpg" alt=""/></div>&#13;
<p>Figure 11.15: Outputs to deliver first Target Outcome</p>&#13;
<p>The outputs moved under the second and fourth outcomes were sourced from the MBPM and Non-Functional Map. This was also true for the third outcome, which also included some of the ideas captured during the early social contract and real-time retrospective that was started when building the cultural foundation.</p>&#13;
<p>The team ended up with a UserStory Map that showed the initial journey through PetBattle as well as the journey the team would go on to deliver and support it:</p>&#13;
<div id="_idContainer344" class="IMG---Figure"><img src="../Images/B16297_11_16.jpg" alt=""/></div>&#13;
<p>Figure 11.16: PetBattle User Story Map</p>&#13;
<p>This is the first information radiator that shows functional features of an application, work to build, operate, and improve the platform and generate an enthusiastic, high-performing team.</p>&#13;
<p>The final step is to start slicing valuable increments of the whole engagement. Working with Product Ownership, the team was keen to ensure all outcomes were being tackled early in some minimal form and they would continue to improve every outcome as they delivered more slices.</p>&#13;
<div id="_idContainer345" class="IMG---Figure"><img src="../Images/B16297_11_17.jpg" alt=""/></div>&#13;
<p>Figure 11.17: Value Slicing the PetBattle User Map</p>&#13;
<p>Looking at the top slice of value brought a feeling of excitement. The team could see the first items they were going to do to make the PetBattle vision a reality!</p>&#13;
				</div>&#13;
			<p>There is a growing set of interesting links, conversations, and further information on these practices in the Open<a id="_idIndexMarker1418"/><a id="_idIndexMarker1419"/> Practice Library at <a href="http://openpracticelibrary.com/practice/user-story-mapping">openpracticelibrary.com/practice/user-story-mapping</a>. Take a look and, if you have a story or experience to share, you can help improve the practice further.</p>&#13;
			<p>Now we've seen the powerful User Story Mapping and Value Slicing technique, we're going to explore a few other practices that will help make this even more successful and collaborative. We often find that people have two <a id="_idIndexMarker1420"/><a id="_idIndexMarker1421"/>challenges with User Story Mapping. First, they don't know how to get everything onto the User Story Map in the first place. Second, the approach to prioritization and slicing out value can be difficult for some and can also lack collaboration.</p>&#13;
			<p>Let's look at the first challenge first.</p>&#13;
			<p>When we introduced the User Story Mapping practice, we said we start by copying all of the outputs, the deliverables, the features, and the ideas that had surfaced from the practices used on the Discovery Loop. That sounds very simple and straightforward. In fact, it really just calls for a human copy-and-paste function to replicate all the deliverables captured on the Impact Map, all the commands captured on the Event Storm, and all the ideas and non-functional work captured during discussion of the MBPM.</p>&#13;
			<p>But is that enough? Are<a id="_idIndexMarker1422"/><a id="_idIndexMarker1423"/> we shutting off the potential for increased innovation by simply relying on the inspiration that happened a few days ago? A slightly different approach is to not just think of User Story Mapping and Value Slicing to be about delivering features. We can try moving to a more experimental mindset where, during the Options Pivot, we really want to design experiments we can run during the Delivery Loop.</p>&#13;
			<h2 id="_idParaDest-230"><a id="_idTextAnchor264"/>Design of Experiments</h2>&#13;
			<p>All our ideas for new products, services, features, and indeed any changes we can introduce to make things better (more growth, increased revenue, enhanced experience, and so on) start off as a hypothesis or an assumption. In a traditional approach to planning, a team may place bets on which experiment to run based on some form of return on investment-style analysis, while making further assumptions in the process.</p>&#13;
			<p><strong class="bold">Design of Experiments</strong> is an alternative to<a id="_idIndexMarker1424"/><a id="_idIndexMarker1425"/> this approach, in which we try to validate as many of the important ideas/hypotheses/assumptions we are making as early as possible. Some of those objects of the experiments we may want to keep <strong class="bold">open</strong> until we get some real-world proof, which can be done through some of the advanced deployment capability (such as A/B Testing) that we'll explore later in this chapter.</p>&#13;
			<p>Design of Experiments is a practice we use to turn ideas, hypotheses, or assumptions into concrete, well-defined sets of experiments that can be carried out in order to achieve validation or invalidation – that is, provide us with valuable learning.</p>&#13;
			<p>Design of Experiments is a fail-safe way to advance a solution and learn fast. It can provide a quick way to evolve a product, helps drive innovation in existing as well as new products, and enables autonomous teams to deliver on leadership intent by placing small bets.</p>&#13;
			<p>You may need more than one experiment for each item (idea, hypothesis, assumption). An experiment usually only changes a small part of the product or service in order to understand how this change could influence our Target Outcomes. The number of experiments is really defined based on what you want to learn and how many distinctive changes you will be introducing.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-231" class="Author-Heading"><a id="_idTextAnchor265"/>Qualitative versus Quantitative Feedback</h2>&#13;
			<div>&#13;
				<div id="_idContainer346" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/Author_4.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Working on a Labs<a id="_idIndexMarker1426"/><a id="_idIndexMarker1427"/> residency with a road and travel insurance provider in 2018 provided us with an opportunity to design experiments on an early <a id="_idIndexMarker1428"/><a id="_idIndexMarker1429"/>prototype of rebuilding the mobile application with an improved user experience and increased conversation.</p>&#13;
			<p>We wanted to measure the current application versus some ideas brainstormed with business stakeholders for improved experience, so we designed an experiment for our test users. We advised them to behave as if this was a real-life situation, stop where they would normally stop, read how they would normally read, and so on, when navigating through the application.</p>&#13;
			<p>The role of this application was to guide the user through the car insurance booking process. To complete this process, they needed their license plate number, social security number, and residential zip code.</p>&#13;
			<p>Each user was guided to follow a URL (ideally on mobile) for the deployment of the application running on OpenShift. They were instructed to select a car and try to compare and buy what seemed to be the best insurance for the user. The experiment ended at the point where they had purchased insurance. (Note – each user was told that this was a test and that the payment details provided to them were for a test credit card and no monies would be moved.)</p>&#13;
			<p>The A/B Test meant different approaches for displaying the page could be used with different users so we could test different prototypes in user interviews.</p>&#13;
			<p>Quantitative data from the experiment showed the duration of the journey through the application, drop-off rates, and completion rates.</p>&#13;
			<p>Qualitative data from the associated users highlighted pain points in the user experience, where there remained some confusion, and validated some of the positive experiences.</p>&#13;
			<p>The qualitative and quantitative feedback combined provided confirmation of which approach was the most suitable. This meant the product team could confidently code the "best" approach as validated by data.</p>&#13;
			<p>This process, from end to end, took one week.</p>&#13;
			</div>&#13;
			<p>The format of the experiment<a id="_idIndexMarker1430"/><a id="_idIndexMarker1431"/> documentation is really as important as the content. It is the content that tells you how well you have designed the experiment; for example, does the experimental design allow for too many opportunities where the outcome may be ambiguous?</p>&#13;
			<p>Good experiments need the<a id="_idIndexMarker1432"/><a id="_idIndexMarker1433"/> following minimum details to be successful:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li><strong class="bold">Hypothesis</strong>: Formulated as a sentence, often expressing an assumption.</li>&#13;
				<li><strong class="bold">Current condition</strong>: What is the situation now (as measurable as possible)?</li>&#13;
				<li><strong class="bold">Target condition</strong>: What are we trying to achieve (as measurable as possible)?</li>&#13;
				<li><strong class="bold">Obstacles</strong>: What could prevent us from achieving the target condition? What could cause interference or noise?</li>&#13;
				<li><strong class="bold">Pass</strong>: How can we define a positive pass? If the target condition may not always be achieved, then what do we consider a significant enough change to conclude the experiment is confirming the hypothesis, that is, passing with a positive outcome?</li>&#13;
				<li><strong class="bold">Measures</strong>: How can we measure the progress?</li>&#13;
				<li><strong class="bold">Learning</strong>: Always capture outcomes and learning, which should ideally lead to more experiments of higher order.</li>&#13;
			</ul>&#13;
			<p>Once described, the experiments can be implemented, tracked, and measured in order to analyze the outcomes. In an ideal world, an experiment will have binary success/failure criteria, but most often we need to analyze data using statistical methods to find out if there is a significant correlation between the change introduced with the experiment and the change in the Target Outcome.</p>&#13;
			<h4>NOTE</h4>&#13;
			<p class="callout">Successful experiments are not experiments that have proven our assumption is correct. Successful experiments are those that provide valid and reliable data that shows a statistically significant conclusion.</p>&#13;
			<p>Design of Experiments is nothing without Discovery or Delivery, which is the main reason for combining this practice with others. Experiments are sourced from the information collected during <a id="_idIndexMarker1434"/><a id="_idIndexMarker1435"/>practices on the Discovery Loop. Hypotheses are formed during Impact Mapping. Assumptions are noted <a id="_idIndexMarker1436"/><a id="_idIndexMarker1437"/>during Event Storming, Empathy Mapping, and other human-centered design practices. Ideas are captured in all Discovery practices.</p>&#13;
			<p>Experiments need to be prioritized as we can only do so much in the time we have. Combining this practice <a id="_idIndexMarker1438"/><a id="_idIndexMarker1439"/>with the various prioritization matrices, such as <strong class="bold">Impact-Effort Prioritization</strong> or <strong class="bold">How-Now-Wow Prioritization</strong>, or even economic prioritization practices such as <strong class="bold">Weighted-Shortest-Job-First</strong>, helps a lot. We are about to explore each of these in the next part of this chapter.</p>&#13;
			<p>Experiments are often realized first through rapid prototyping, which requires user research and user testing, which<a id="_idIndexMarker1440"/><a id="_idIndexMarker1441"/> we do on the Delivery Loop. This combination provides for fast learning even before a single line of code is written.</p>&#13;
			<p>Experiments can be run in production as well. In fact, tests in production are the ultimate form of validation of ideas/hypotheses/assumptions as the validation is supported by real data and real customer actions and behavior. The A/B Testing practice provides a very valuable combination.</p>&#13;
			<p>Often, you may have a set of experiments go through a sequence of Rapid Prototyping/Prototyping with User Research, and then a subset of successful experiments would be carried forward to production to pass through A/B Testing. There are other mechanisms of controlling deployments that will enable measuring and learning from real customer behavior – we'll introduce all of these later in this chapter.</p>&#13;
			<p>You can read and discuss<a id="_idIndexMarker1442"/><a id="_idIndexMarker1443"/> this practice further at <a href="http://openpracticelibrary.com/practice/design-of-experiments">openpracticelibrary.com/practice/design-of-experiments</a>.</p>&#13;
			<p>Designed experiments should end up on a User Story Map and Value Slice Map so that they can be prioritized against all other work.</p>&#13;
			<p>Let's look at a couple of other tools that can help with the prioritization discussions, starting with the Impact and Effort Prioritization Matrix.</p>&#13;
			<h2 id="_idParaDest-232"><a id="_idTextAnchor266"/>Impact and Effort Prioritization Matrix</h2>&#13;
			<p>The Impact and Effort Prioritization Matrix is a decision-making/prioritization practice for the selection of ideas (such as functional feature ideas, performance ideas, other non-functional ideas, platform growth ideas, and so on).</p>&#13;
			<p>This practice opens up <a id="_idIndexMarker1444"/><a id="_idIndexMarker1445"/>product development for the whole team (which really understands effort) and connects them to stakeholders (who really understand impact). Developing new products goes hand in hand with the generation of ideas, hypotheses, and their testing/validation. Unfortunately, it is mostly impossible to test and evaluate all the ideas and hypotheses we can come up with. This requires us to filter and prioritize which of them to work on.</p>&#13;
			<p>This matrix is simple, easy to understand, and very visual, and can include the whole team in the process of transparent selection of ideas and hypotheses to work on first. It also helps Product Owners and Product Managers build the product roadmaps and Product Backlogs and explains priorities to stakeholders.</p>&#13;
			<p>This practice is very <a id="_idIndexMarker1446"/><a id="_idIndexMarker1447"/>powerful in helping to identify direction and ideas for pivoting purely from the visualization.</p>&#13;
			<div>&#13;
				<div id="_idContainer347" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_18.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.18: Two-by-two matrix comparing Impact versus Effort</p>&#13;
			<p>Four separate groups of ideas have <a id="_idIndexMarker1448"/><a id="_idIndexMarker1449"/>emerged from this practice:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li><strong class="bold">The Best Ideas to Focus on</strong>: High Impact / Low Effort – These should be considered in the higher slices of the Value Slice Map.</li>&#13;
				<li><strong class="bold">Research Required</strong>: High Impact / High Effort – These should be considered in the higher slices of the Value Slice Map but, in later Product Backlog Refinement practices, may be deemed lower priority given it will take longer to realize the value.</li>&#13;
				<li><strong class="bold">Follow Up</strong>: Low Impact / Low Effort – These should be low down on the Value Slice Map and either followed up if time permits or removed completely.</li>&#13;
				<li><strong class="bold">No Way – Bad Ideas</strong>: Low Impact / High Effort – These should be low down on the Value Slice Map or removed completely.</li>&#13;
			</ul>&#13;
			<p>The sources of ideas and hypotheses are all the Discovery practices, such as Event Storming, Impact Mapping, and Empathy Mapping. While we perform those aforementioned practices, often ideas may emerge for possible improvements or new hypotheses may form. </p>&#13;
			<p>Before adding any of them as items to the Product Backlog, these ideas and hypotheses would typically need some research, analysis, and further elaboration.</p>&#13;
			<p>Once prioritized, these ideas and hypothesis may lead to:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>New features being added through <a id="_idIndexMarker1450"/><a id="_idIndexMarker1451"/>the User Story Map and Value Slice board</li>&#13;
				<li>Complete new features being broken down into smaller features or User Stories and refactored on the Value Slice board</li>&#13;
				<li>User Research</li>&#13;
				<li>Design of Experiments</li>&#13;
				<li>Technical Spikes and UI Prototypes</li>&#13;
			</ul>&#13;
			<p>The Impact and Effort Prioritization <a id="_idIndexMarker1452"/><a id="_idIndexMarker1453"/>matrix has its own Open Practice Library page at <a href="http://openpracticelibrary.com/practice/impact-effort-prioritization-matrix/">openpracticelibrary.com/practice/impact-effort-prioritization-matrix/</a> – a great place to continue the learning and discussion about this prioritization practice.</p>&#13;
			<p>A slightly different perspective on prioritization is achieved using the How-Now-Wow Prioritization practice. Whereas the previous practice is used to filter out and prioritize the very high-impacting features, this practice is used to identify and prioritize the quick wins and base features needed for a product.</p>&#13;
			<h2 id="_idParaDest-233">H<a id="_idTextAnchor267"/>ow-Now-Wow Prioritization</h2>&#13;
			<p>How-Now-Wow is an idea selection tool that is often combined with Brainstorming, <strong class="bold">How-Might-We</strong><span id="footnote-051-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-051">2</a></span> (<strong class="bold">HMW</strong>), and Design of Experiments. It compares and plots ideas on a 2x2 matrix by comparing the idea's difficulty to implement with its novelty/originality.</p>&#13;
			&#13;
			<p>Similar to the Impact and Effort <a id="_idIndexMarker1454"/><a id="_idIndexMarker1455"/>Prioritization Matrix, How-Now-Wow Prioritization is simple, easy to understand, and very visual, and can include the whole team in the process of transparent selection of ideas/hypotheses to work on first.</p>&#13;
			<div>&#13;
				<div id="_idContainer348" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_19.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.19: How-Now-Wow Prioritization map</p>&#13;
			<p>Again, the sources of ideas and hypotheses are all the Discovery practices, such as Event Storming, Impact Mapping, HMW, and Empathy Mapping. When we perform those aforementioned practices, often ideas will emerge for possible improvements or new hypotheses may form.</p>&#13;
			<p>We can plot each of these on the How-Now-Wow matrix by assessing each item and considering how easy or difficult it is to implement (using team members to collaborate and align on this) and how new and innovative the feature is.</p>&#13;
			<div id="footnote-051" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-051-backlink">2</a>	<a href="https://openpracticelibrary.com/practice/hmw/">https://openpracticelibrary.com/practice/hmw/</a></p>&#13;
			</div>&#13;
			<p>Three separate groups of ideas <a id="_idIndexMarker1456"/><a id="_idIndexMarker1457"/>have emerged from this practice. There are three we're particularly interested in:</p>&#13;
			<ol>&#13;
				<li value="1"><strong class="bold">Now Ideas</strong>: Easy to implement and considered normal ideas for the product. These should be considered in the higher slices of the Value Slice Map and are ideas we would expect to deliver.</li>&#13;
				<li><strong class="bold">Wow Ideas</strong>: Easy to implement and considered highly innovative or new for the product. These should be considered as potential ideas for the higher slices of the Value Slice Map and would be particularly valuable if innovation and market differentiation were deemed high-priority focus areas. If the Priority Sliders practice has already been used, it may provide some direction here.</li>&#13;
				<li><strong class="bold">How Ideas</strong>: Hard to implement and considered highly innovative or new for the product. These would benefit from further research to understand the implementation difficulty and potential impact further. Design of Experiments, prototyping, and further User Research will help validate whether this innovation is something that would be well received. Technical Spikes and research will help establish confidence and potentially easier solutions to implement.</li>&#13;
				<li><strong class="bold">Other ideas</strong>: Hard to implement and not particularly innovative or new for the product. We're not interested in these ideas at all.</li>&#13;
			</ol>&#13;
			<p>Once placed on the How-Now-Wow matrix, these ideas <a id="_idIndexMarker1458"/><a id="_idIndexMarker1459"/>and hypotheses may lead to:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>New features being added through the User Story Map and Value Slice board</li>&#13;
				<li>Complete new features being broken down into smaller features or User Stories and refactored on the Value Slice board</li>&#13;
				<li>User Research</li>&#13;
				<li>Design of Experiments</li>&#13;
				<li>Technical Spikes and UI Prototypes</li>&#13;
			</ul>&#13;
			<p>For more information on the <a id="_idIndexMarker1460"/><a id="_idIndexMarker1461"/>How-Now-Wow Prioritization practice and to start a conversation about how to best use it, have a look at <a href="http://openpracticelibrary.com/practice/how-now-wow-prioritization-matrix">openpracticelibrary.com/practice/how-now-wow-prioritization-matrix</a>.</p>&#13;
			<p>Our primary motivation behind using practices such as Impact and Effort Prioritization and How-Now-Wow Prioritization is to facilitate conversation. Practices that get business folks talking to each other and aligning on an approach with some shared understandings are great. Practices that get techie folks collaborating and gaining a common understanding of the implementation approach and complexity are also great. Practices that get business people and techie people all collaborating to reach a consensus and a common view of both the business context and implementation approach are amazing. These two practices are examples of those.</p>&#13;
			<div>&#13;
				<div id="_idContainer349" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_20.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.20: Different stakeholders collaborating to gain a better understanding of the product</p>&#13;
			<p>Both practices highlighted <a id="_idIndexMarker1462"/><a id="_idIndexMarker1463"/>some features to do more research on. Practices categorized in the How quadrant of the How-Now-Wow matrix will benefit from additional research. Practices categorized in the High Effort / High Impact quadrant of the Impact and Effort Prioritization matrix will benefit from additional research.</p>&#13;
			<p>Many of the human-centered design practices outlined in <em class="italics">Chapter 8, Discovering the Why and Who</em>, will help with this research. This includes Empathy Mapping, qualitative user research, conceptual design, prototyping, and interaction design. If the feature area is of very high importance, it may be valuable to invest in a specific practice that will really further the understanding of the feature – the Design Sprint.</p>&#13;
			<h2 id="_idParaDest-234">The<a id="_idTextAnchor268"/> Design Sprint</h2>&#13;
			<p>The Design Sprint has become a popular <a id="_idIndexMarker1464"/><a id="_idIndexMarker1465"/>practice to support product research. It is a five-day customer-centric process for rapidly solving a key challenge, creating new products, or improving existing<a id="_idIndexMarker1466"/><a id="_idIndexMarker1467"/> ones. Design Sprints enable you to:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>Clarify the problem at hand and identify the needs of potential users.</li>&#13;
				<li>Explore solutions through brainstorming<a id="_idIndexMarker1468"/><a id="_idIndexMarker1469"/> and sketching exercises.</li>&#13;
				<li>Distill your ideas into one or two solutions that you can test.</li>&#13;
				<li>Prototype your solution and bring it to life.</li>&#13;
				<li>Test the prototype with people who would use it.</li>&#13;
			</ul>&#13;
			<p>The process phases include Understand, Define, Sketch, Decide, Prototype, and Validate.</p>&#13;
			<p>The aim is to fast-forward into the future to see your finished product and customer reactions, before making any expensive commitments. It is a simple and cheap way to validate major assumptions and the big question(s) and point to the different options to explore further through delivery. This set of practices reduces risks when bringing a new product, service, or feature to the market. Design Sprints are the fastest way to find out if a product or project is worth undertaking, if a feature is worth the effort, or if your value proposition is really valid. For the latter, you should also consider running a Research Sprint.<span id="footnote-050-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-050">3</a></span> It compresses work into one week and most importantly tests the design idea and provides real user feedback in a rapid fashion.</p>&#13;
						<p>By now, there are many different variations of the Design Sprint format. You may come across the Google Ventures variation – the Design Sprint 2.0 – which is the agenda shown below. The best thing to do is to try different variations and judge which one works for what context.</p>&#13;
						<div id="footnote-050" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-050-backlink">3</a>	<a href="https://library.gv.com/the-gv-research-sprint-a-4-day-process-for-answering-important-startup-questions-97279b532b25">https://library.gv.com/the-gv-research-sprint-a-4-day-process-for-answering-important-startup-questions-97279b532b25</a></p>&#13;
			</div>&#13;
			&#13;
			<div>&#13;
				<div id="_idContainer1000" class="IMG---Figure">&#13;
					<img src="../Images/B16297_Table_11.1.png" alt="" style="height:400px; width:500px;"/>&#13;
				</div>&#13;
			</div>&#13;
			&#13;
			<p class="figure">Table 11.1: A five-day Design Sprint</p>&#13;
			<p>Effectively, we are <a id="_idIndexMarker1470"/><a id="_idIndexMarker1471"/>using the same Mobius Loop mental model as used throughout this book but micro-focused on a particular option in order to refine understanding and conduct further research about its value. That improved understanding of relative value then filters back into the overall Mobius Loop that classified this as an option worthy of a Design Sprint.</p>&#13;
			<div>&#13;
				<div id="_idContainer350" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_21.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.21: The Design Sprint – quick trip round the Mobius Loop</p>&#13;
			<p>A Design Sprint will <a id="_idIndexMarker1472"/><a id="_idIndexMarker1473"/>really help refine the shared understanding of the value a feature or group of features may offer in a product. They may be functional user features. They may also be non-functional features that are more focused on improving the platform and improving the development experience. The same agenda as above can apply where "users" are developers or operators and the Design Sprint is focused on researching some potential work that will improve their development or operations experience.</p>&#13;
			<p>This practice will help elaborate and refine the information that is pushed through the User Story Map and Value Slicing Map. We see it as a practice on the Options Pivot because it will help decide whether or not to proceed with the delivery of the associated features.</p>&#13;
			<p>Read more about the practice, add <a id="_idIndexMarker1474"/><a id="_idIndexMarker1475"/>your own experiences, or raise any questions you might have at <a href="http://openpracticelibrary.com/practice/design-sprint/">openpracticelibrary.com/practice/design-sprint/</a>.</p>&#13;
			<p>The User Story Mapping practice helps us visualize our work into a story with a clear backbone. Value Slicing allows us to form incremental release plans that can be delivered in iterations. The Impact and Effort Prioritization and How-Now-Wow Prioritization practices help provide alternate perspectives to help with the Value Slicing. The Design Sprint allows us to dive deeper into a specific feature area to research it further, so we can prioritize with increased confidence.</p>&#13;
			<p>All of these practices (and many others you'll find in the Open Practice Library) are homing in on us being able to produce an initial <strong class="bold">Product Backlog</strong> – a single, one-dimensional list<a id="_idIndexMarker1476"/><a id="_idIndexMarker1477"/> of stuff we're going to take into the Delivery Loop.</p>&#13;
			<p>Let's now look at how we translate the information from our Value Slices into a Product Backlog and how we can continue to prioritize it.</p>&#13;
			<h2 id="_idParaDest-235">F<a id="_idTextAnchor269"/>orming the Initial Product Backlog</h2>&#13;
			<p>Here's some good news. Forming the <a id="_idIndexMarker1478"/><a id="_idIndexMarker1479"/>Product Backlog is really, really easy. If you've run some Discovery Loop practices and then run User Story Mapping and Value Slicing of the resulting learning, all the hard thinking, collaboration, and alignment has been done.</p>&#13;
			<div>&#13;
				<div id="_idContainer351" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_22.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.22: Value Slices to drive the initial Product Backlog</p>&#13;
			<p>This has been a great blend of practices and, if there was strong collaboration and a sense of alignment throughout (which is facilitated by having a strong foundation of open culture), the Value Slice Map should represent a combined, shared view of work and how it can be incrementally released.</p>&#13;
			<p>To create the Product Backlog, we simply copy each sticky note in the top slice from left to right and place them in a single column.</p>&#13;
			<div>&#13;
				<div id="_idContainer352" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_23.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.23: The initial Product Backlog</p>&#13;
			<p>The sticky note on the left of the top slice will be <a id="_idIndexMarker1480"/><a id="_idIndexMarker1481"/>copied and placed as the item at the top of the Product Backlog. The sticky note to the right of it on the top slice will be the second item on the Product Backlog. Once we've copied all items in the top slice, we move to the second slice of value and, again, copy each of the items from left to right onto the Product Backlog.</p>&#13;
			<div>&#13;
				<div id="_idContainer353" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_24.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.24: Summary of the Value Slicing practice</p>&#13;
			<div>&#13;
				<div id="_idContainer354" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_25.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.25: Creating a Product Backlog from the Value Slicing Canvas</p>&#13;
			<p>We end up with a single column <a id="_idIndexMarker1482"/><a id="_idIndexMarker1483"/>of Product Backlog items that have been sourced and prioritized through a collection of robust practices. That traceability is important because we can trace back to the Discovery Loop practice that generated the idea and the value it is intended to deliver.</p>&#13;
			<p>Let's look at that traceability in action with our PetBattle organization.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-236" class="Author-Heading"><a id="_idTextAnchor270"/>PetBattle — Tracing Value through Discovery and Delivery Practices</h2>&#13;
			<p>We saw earlier in this chapter how slices of value were created from the User Story Map. We also saw how the User Story Map was built up entirely from the learning captured through Discovery Loop practices.</p>&#13;
			<p>Translating this to a Product Backlog is easy. </p>&#13;
			<div>&#13;
				<div id="_idContainer355" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_26.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Figure 11.26: Transforming Value Slices into a Product Backlog</p>&#13;
			<p>This is the beginning of the life of the PetBattle Product Backlog. It will remain living, breathing, and always ready for updates as long as the PetBattle product is in operation.</p>&#13;
			<p>In fact, the team immediately sees some early prioritization needed and recommends moving the CI/CD workshop and team lunch/breakfast items to the top. They all agreed there was no point writing any code or building any features until they had CI/CD in place and a fed and watered team!</p>&#13;
			</div>&#13;
			<p>The Product Backlog is a living, breathing artifact. It should never be static. It should never be done. It is a tool that is always available for teams and stakeholders to reference and, in collaboration with Product Owners, a place to add ideas, elaborate on existing ideas, and continue to prioritize work items relative to each other.</p>&#13;
			<p>From this moment onward, we will start and continue the practice of Product Backlog Refinement.</p>&#13;
			<h3 id="_idParaDest-237"><a id="_idTextAnchor271"/>Product Backlog Refinement</h3>&#13;
			<p>The Product Backlog Refinement <a id="_idIndexMarker1484"/><a id="_idIndexMarker1485"/>practice sits at the heart of the Mobius Loop. We use it coming out of a Discovery Loop. We use it coming out of a Delivery Loop. We use it all the time.</p>&#13;
			<p>It is perhaps the one practice that sits on the Mobius Loop that does not have a suggested or directed time-box to execute it in. There is also not a suggested or directed number of times you would run it or when you would run it. Product Backlog Refinement should occur as often or as little as needed to get to a backlog that stakeholders and team members have confidence in. You can even use the Confidence Voting practice (as introduced in <em class="italics">Chapter 4, Open Culture</em>) to measure this.</p>&#13;
			<p>There is also no defined agenda for a Product Backlog Refinement session and it can be attended by a variety of different people, such as development and operational team members, business stakeholders, and <a id="_idIndexMarker1486"/><a id="_idIndexMarker1487"/>leadership. The activities that take place in Product Backlog Refinement include:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>Talking through and<a id="_idIndexMarker1488"/><a id="_idIndexMarker1489"/> refining the collective shared understanding of an item on the backlog, its value to users, and the implementation needs that need to be satisfied</li>&#13;
				<li>Re-writing and refining the title of a Product Backlog item to better reflect the collective understanding</li>&#13;
				<li>Writing acceptance criteria for a specific item on the Product Backlog</li>&#13;
				<li>Doing some relative estimation of the effort required to deliver a feature from the backlog to satisfy the acceptance criteria</li>&#13;
				<li>Splitting an item on the backlog into two (or more) smaller items</li>&#13;
				<li>Grouping items together into a more standalone item that will deliver a stronger unit of value</li>&#13;
				<li>Capturing new ideas and feedback on the Product Backlog</li>&#13;
				<li>Prioritizing and re-ordering items on the Product Backlog</li>&#13;
			</ul>&#13;
			<p>All of the artifacts we've generated on the Discovery Loop and Options Pivot are useful to look at, collaborate on, and refine further when performing Product Backlog Refinement. They too are all living, breathing artifacts and, often, conversations during Product Backlog Refinement trigger further updates to these. So, for example, we may add a new deliverable to our Impact Map and connect it to an impact and actor to test with. We may elaborate on some details on the Event Storm as we start to consider the implementation details of an associated backlog item. As new items are captured from Product Backlog Refinement, the Impact and Effort Prioritization Matrix, How-Now-Wow Prioritization Matrix, and Value Slice board artifacts are all available to relatively plot the new item against existing items. In <em class="italics">Chapter 17, Improve It</em>, we'll return to the Options Pivot following an iteration of the Delivery Loop and look at how the measurements and learning captured from delivery can drive further Product Backlog Refinement.</p>&#13;
			<p>Arguably one of the most important aspects of Product Backlog Refinement is prioritization and, in particular, prioritizing what is toward the top of the Product Backlog. This is what the team will <strong class="bold">pull</strong> from when planning their next iteration of the Delivery Loop. So, it's important that the items at the very top of the backlog truly reflect what is most valuable and help generate the outcomes that matter.</p>&#13;
			<p>For more details on Product Backlog Refinement and to converse with the community, take a look at the Open Practice Library page at <a href="http://openpracticelibrary.com/practice/backlog-refinement">openpracticelibrary.com/practice/backlog-refinement</a>.</p>&#13;
			<p>We've already seen a few tools that help with initial Product Backlog generation and giving the first set of priorities. Let's look at a few more that will help with ongoing Product Backlog prioritization.</p>&#13;
			<h2 id="_idParaDest-238"><a id="_idTextAnchor272"/>Prioritization</h2>&#13;
			<p>Throughout this chapter, we've used the terms <strong class="bold">features</strong> and <strong class="bold">Product Backlog items</strong> to explain the different units of work that we capture through Discovery and prioritize and decide which to work <a id="_idIndexMarker1490"/><a id="_idIndexMarker1491"/>on first in the Options Pivot. An important clarification that's needed is that this does not just mean functional features. We are not just deciding which shiny new feature the end users are going to get next. We need to balance customer value against risk mitigation; we need to balance functional against non-functional work. We do that by balancing research, experimentation, and implementation.</p>&#13;
			<h3 id="_idParaDest-239"><a id="_idTextAnchor273"/>Value versus Risk</h3>&#13;
			<p>When we prioritize Product <a id="_idIndexMarker1492"/><a id="_idIndexMarker1493"/>Backlog items, we are relatively assessing all options available to us. That does include new features we're going to implement. It also includes defects and problems in production that need to be fixed. It includes non-functional improvements to the architecture to make future development and operations simpler and stronger. It includes the experiments we might want to execute or further research we want to do in the form of a user interface prototype or a technical spike. It's really anything that will consume the time of some of the cross-functional product team members.</p>&#13;
			<p>When we prioritize, we need to think about the relative value delivering the item will bring as compared to the risk it might mitigate through acquiring additional learning and confidence. There are different kinds of risk, including:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li><strong class="bold">Business Risk:</strong> Are we building the right thing?</li>&#13;
				<li><strong class="bold">Technical Risk:</strong> Will this thing work on the platform and will it scale?</li>&#13;
				<li><strong class="bold">Cost and Schedule Risk:</strong> Will we deliver within the right time-box to meet market needs? Will we be able to meet any cost constraints?</li>&#13;
			</ul>&#13;
			<p>Running Technical Spikes and proving some of the non-functional aspects of the platform early can provide the knowledge and confidence value, which can be equally, if not more, important than customer value achieved from delivering functional features. In fact, this non-functional work helps us achieve the Enabling Outcomes outlined in <em class="italics">Chapter 10, Setting Outcomes</em>, whereas the functional implementations are more focused on achieving the primary outcomes. </p>&#13;
			<p>Let's look at an economic prioritization model that can help us quantify risk, knowledge value, and customer value. It can be used by a Product Owner in collaboration with wider groups of team members and stakeholders and presented to the wider organization. <a id="_idTextAnchor274"/></p>&#13;
			<h3 id="_idParaDest-240"><a id="_idTextAnchor275"/>Cost of Delay and WSJF</h3>&#13;
			<p><strong class="bold">Weighted Shortest Job First</strong> (<strong class="bold">WSJF</strong>) is an<a id="_idIndexMarker1494"/><a id="_idIndexMarker1495"/> economic prioritization model. It is a very popular<a id="_idIndexMarker1496"/><a id="_idIndexMarker1497"/> practice in the <strong class="bold">Scaled Agile Framework</strong> (<strong class="bold">SAFe</strong>), but works very well as a standalone practice with any size <a id="_idIndexMarker1498"/><a id="_idIndexMarker1499"/>of product or organization.</p>&#13;
			<p>Many organizations <a id="_idIndexMarker1500"/><a id="_idIndexMarker1501"/>struggle to prioritize risk mitigation action, learning initiatives, or delivery value using any scientific approach. Instead, prioritization comes down to meetings <a id="_idIndexMarker1502"/><a id="_idIndexMarker1503"/>in a room <a id="_idIndexMarker1504"/><a id="_idIndexMarker1505"/>where the <strong class="bold">Loudest Voice Dominates</strong> (<strong class="bold">LVD</strong>) and/or decisions are made by the <strong class="bold">Highest Paid Person's Opinion</strong> (<strong class="bold">HIPPO</strong>).</p>&#13;
			<div>&#13;
				<div id="_idContainer356" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_27.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.27: Decisions are made based on the HIPPO</p>&#13;
			<p>So, what is WSJF? It is based on Don Reinertsen's research on the Cost of Delay and the subject of his book <em class="italics">The Principles of Product Development Flow – Second Generation Lean Product Development</em>. Reinertsen famously said, <em class="italics">If you quantify one thing, quantify the cost of delay.</em> Josh Arnold<span class="P---Superscript"> </span>explains <a id="_idIndexMarker1506"/><a id="_idIndexMarker1507"/>how the <em class="italics">Cost of Delay is calculated by assessing the impact of not having something when you need it. As a typical example this might be the cost incurred while waiting to deliver a solution that improves efficiency. It is the opportunity cost between having the same thing now, or getting it later.</em><span id="footnote-049-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-049">4</a></span></p>&#13;
			<div id="footnote-049" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-049-backlink">4</a>	<a href="http://coactivation.com/safecity/">Source: Mark Richards, SAFe City Simulation Version 2.0</a></p>&#13;
			</div>&#13;
			<p>The core thinking behind the Cost of Delay is value foregone over time. For every day we don't have an item in the market, what is it costing the organization? If the value of the item is a cost-saving initiative, how much money is the organization not saving by not implementing this feature? If the value of the item is revenue-related, what is the additional revenue they're missing out on by not implementing it?</p>&#13;
			<p>The Cost of Delay can be <a id="_idIndexMarker1508"/><a id="_idIndexMarker1509"/>sensitive to time. There are seasonal influences – for example, shipping in retail can be very time-sensitive around, say, the holiday season. Changes may be needed for legislation and compliance. The cost can be very high if something is not delivered by a certain date when new legislation kicks in. The Cost of Delay will be nothing in advance of this date and very high after this date.</p>&#13;
			<p>There are three primary<a id="_idIndexMarker1510"/><a id="_idIndexMarker1511"/> components that contribute to the Cost of Delay:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li><strong class="bold">Direct business value</strong> either to the customer and/or the organization. This reflects preferences users might have that will drive up their customer satisfaction. It will also reflect relative financial reward or cost reduction that the item is expected to drive. </li>&#13;
				<li><strong class="bold">Time criticality</strong> to<a id="_idIndexMarker1512"/><a id="_idIndexMarker1513"/> implementing the solution now or at a later date. This incorporates any seasonal or regulation factors that might drive time criticality, as well as whether customers are likely to wait for solutions or if there is a compelling need for it now.</li>&#13;
				<li><strong class="bold">Risk reduction and opportunity enablement</strong> is the<a id="_idIndexMarker1514"/><a id="_idIndexMarker1515"/> indirect business value this might bring to the organization. It considers the hidden benefits this might bring in the future as well as reducing the risk profile.</li>&#13;
			</ul>&#13;
			<p>Using Cost of Delay to <a id="_idIndexMarker1516"/><a id="_idIndexMarker1517"/>prioritize work in agile backlogs will result in items being prioritized by value and sensitivity to time. It also allows us to have a lens on direct business value (such as new functional feature development) and indirect business value (such as non-functional improvements to the OpenShift platform).</p>&#13;
			<p style="text-align:center;"><em class="italics">Cost of Delay = Business Value + Timing Value + Risk Reduction/Opportunity Enablement Value</em></p>&#13;
			<p>WSJF adds a further dimension to this by considering the cost of implementation. Reinertsen said <em class="italics">it is critical to remember that we block a resource whenever we service a job. The benefit of giving immediate service to any job is its cost-of-delay savings, and the cost is the amount of time (duration) we block the resources. Both cost and benefit must enter into an economically correct sequencing.</em><span id="footnote-048-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-048">5</a></span></p>&#13;
						<p style="text-align:center;"><em class="italics">Weighted Shortest Job First (WSJF) = Cost of Delay (COD) / Duration</em></p>&#13;
						<div id="footnote-048" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-048-backlink">5</a>	<a href="http://lpd2.com/">The Principles of Product Development Flow – Second Generation Lean Product Development by Donald G Reinertsen</a></p>&#13;
			</div>&#13;
			<p>What unit do we use for the three components in Cost of Delay and Duration? It's arbitrary. The actual numbers are meaningless by themselves. The agile practice we use to support COD and WSJF is Relative Estimation,<span id="footnote-047-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-047">6</a></span> whereby we are relatively assessing the magnitude of business value, timing value, and risk reduction/opportunity enablement for each item on the Product Backlog relative to each other item. This allows us to prioritize the Product Backlog according to WSJF.</p>&#13;
			&#13;
			<p>We've now introduced several practices on this first trip to the Options Pivot that help us generate more ideas from discovery, refine them, prioritize them, and, ultimately, decide which options we're going to take into a Delivery Loop next. But who makes this decision? The term <strong class="bold">we</strong> has been used a lot in this chapter, emphasizing the importance of collaboration. But what happens when we don't have a consensus? Who gets the final say? This is where the<a id="_idIndexMarker1518"/><a id="_idIndexMarker1519"/> importance of great production ownership comes in.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-241" class="Author-Heading"><a id="_idTextAnchor276"/>PetBattle – Prioritizing using WSJF</h2>&#13;
			<p>The PetBattle team gathered to conduct a WSJF session on all of the features and work they'd captured on the Value Slice board.</p>&#13;
			<p>They chose to use this practice in addition to the Impact and Effort Prioritization and Value Slicing because they felt they needed a way to quantify both risk reduction and timeliness of upcoming work. As they had several Enabling Outcomes that are more non-functional based, the team felt that the Cost of Delay and WSJF would allow them to correctly articulate the value of this work relative to functional features.</p>&#13;
			<p>For each item, the team would spend one minute talking about their understanding of the feature. Each team member would then write down four values – business value, time criticality, risk and opportunity enablement, and duration. The first<a id="_idIndexMarker1520"/><a id="_idIndexMarker1521"/> three values would be given a rating of 1 to 10. The duration used a modified Fibonacci sequence<span id="footnote-046-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-046">7</a></span> and could either be 1, 2, 3, 5, 8, or 13.</p>&#13;
			&#13;
			<p>The team members would reveal individual scores to each other and a conversation would follow to converge and align on the team's assessment for each score.</p>&#13;
			<p>This resulted in a Cost of Delay value and a WSJF value for each item.</p>&#13;
			<div>&#13;
				<div id="_idContainer357" class="IMG---Figure">&#13;
					<img src="../Images/B16297_Table_11.2.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Table 11.2: Calculating WSJF for PetBattle work</p>&#13;
			<p>Some of the conclusions drawn out during the conversation included:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>Most of the functional features were of high business value and of high time criticality to launch the minimal version of this application.</li>&#13;
				<li>The non-functional work driven by Enabling Outcomes was deemed of high value for risk reduction and of lower (but some) business value.</li>&#13;
				<li>Some non-functional work was clearly more time-critical than others, such as having automated deployment.</li>&#13;
				<li>Most work was relatively similar in size with the exception of the Verify Image feature, which has some uncertainty around the solution.</li>&#13;
			</ul>&#13;
			<p>The team agreed this had been a useful Product Backlog Refinement exercise and would help with overall prioritization.</p>&#13;
			</div>&#13;
			<div id="footnote-047" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-047-backlink">6</a>	<a href="https://openpracticelibrary.com/practice/relative-estimation/">https://openpracticelibrary.com/practice/relative-estimation/</a></p>&#13;
			</div>&#13;
			<div id="footnote-046" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-046-backlink">7</a>	<a href="https://www.mountaingoatsoftware.com/blog/why-the-fibonacci-sequence-works-well-for-estimating">https://www.mountaingoatsoftware.com/blog/why-the-fibonacci-sequence-works-well-for-estimating</a></p>&#13;
			</div>&#13;
			<p>The previous <a id="_idIndexMarker1522"/><a id="_idIndexMarker1523"/>sections on forming the product backlog, refining it and prioritization are all key responsibilities of Product Ownership which we will now explore further.</p>&#13;
			<h2 id="_idParaDest-242"><a id="_idTextAnchor277"/>Product Ownership</h2>&#13;
			<p>Everything in this <a id="_idIndexMarker1524"/><a id="_idIndexMarker1525"/>chapter is about Product Ownership. Everything in the previous chapters about Discovery is Product Ownership. Prioritizing early efforts to build a foundation of open culture, open leadership, and open technology practices requires strong Product Ownership from the outset.</p>&#13;
			<p>There are whole books and training courses written about Product Ownership, Product Owners, and Product Managers. Much of our thinking has been inspired by the amazing work of Henrik Kniberg. If you have not seen his 15-minute video on YouTube entitled <em class="italics">Product Ownership in a Nutshell</em>,<span id="footnote-045-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-045">8</a></span> please put this book down, go and get a cup of tea, and watch the video now. Maybe even watch it two or three times. We, the four authors of this book, reckon we've collectively seen this video over 500 times now!</p>&#13;
			<div id="footnote-045" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-045-backlink">8</a>	<a href="https://www.youtube.com/watch?v=502ILHjX9EE">https://www.youtube.com/watch?v=502ILHjX9EE</a></p>&#13;
			</div>&#13;
			<p>Some say it is the best 15-minute video on the internet, which is quite an accolade! It packs in so many important philosophies around Product Ownership in such a short amount of time. We tend to show this video during our DevOps Culture and Practice Enablement sessions, when we start a new engagement with a new team, or simply to kick-start a conversation with a stakeholder on what agile is really about.</p>&#13;
			<p>The resulting graphic is well worth printing out and framing on the wall!</p>&#13;
			<p> </p>&#13;
			<div>&#13;
				<div id="_idContainer358" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_28.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.28: Agile Product Ownership in a Nutshell, courtesy of Henrik Kniberg</p>&#13;
			<p>During our time <a id="_idIndexMarker1526"/><a id="_idIndexMarker1527"/>working on hundreds of different engagements, we've seen some examples of amazing Product Ownership. We've also seen some really bad examples.</p>&#13;
			<p>Let's look at some of the patterns that we've observed, starting with Product Owners.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-243" class="Author-Heading"><a id="_idTextAnchor278"/>Experimenting with Different Product Owners</h2>&#13;
			<div>&#13;
				<div id="_idContainer359" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/author_face_1.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Working with a UK retail organization in the mid-2010s, we were using the Scrum framework to deliver a four-tier IBM WebSphere Commerce and MobileFirst platform.</p>&#13;
			<p>This was the first time this organization had attempted an agile delivery and it was complex due to multiple Scrum teams, one Waterfall team, multiple suppliers, multiple time zones, multiple technology vendors including some immature technology, multiple business units, and so on.</p>&#13;
			<p>The first Product Owner assigned to the engagement was a contractor who had no prior history or engagement with the organization. We quickly learned that he had no empowerment to make decisions as he constantly had to assemble meetings with stakeholders any time a Scrum team needed clarification or asked to do some Product Backlog refinement. Product Owners need to be empowered.</p>&#13;
			<p>The organization did adapt and re-staffed the Product Owner role to be a very senior business-focused person who was a direct report of the CIO. This was better as he certainly was empowered to make fast decisions and prioritization choices. The challenge this time was getting access to him regularly. He promised us one hour per week. With a Product Backlog that needed a lot of refinement and a lot of clarification to development teams, this was nowhere near enough. Product Owners need to be available to their team(s).</p>&#13;
			<p>There was a further adaptation and the Product Owner role was given to a long-standing and highly respected technical architect who was dedicated to the project. This worked really well as he had a great relationship with both technology and business stakeholders, knew the organization's strategy and priorities really well, and had a great personality that people felt very comfortable collaborating with. Product Owners need to understand the business.</p>&#13;
			<p>Over time, the need for direct access to this Product Owner diminished. It is a pattern I've noticed working with several organizations where Product Ownership has been particularly strong. Great Product Owners democratize Product Ownership and provide a direct connection between teams and stakeholders. Product Owners should see their current role as one to self-destruct and not be needed in the long term.</p>&#13;
			</div>&#13;
			<p>Next, let's look at <a id="_idIndexMarker1528"/><a id="_idIndexMarker1529"/>how great Product Owners have approached their first iterations and what they've prioritized to form their <a id="_idIndexMarker1530"/><a id="_idIndexMarker1531"/>first iteration goals.</p>&#13;
			&#13;
<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-244" class="Author-Heading"><a id="_idTextAnchor279"/>Patterns of Early Sprints and the Walking Skeleton</h2>&#13;
			<div>&#13;
				<div id="_idContainer360" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/author_face_1.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			<p>In the next <a id="_idIndexMarker1532"/><a id="_idIndexMarker1533"/>chapter, we're going to switch to the Delivery Loop and talk about the practices we use to plan, deliver, showcase, and learn from iterations of the delivery loop.</p>&#13;
			<p>Thinking specifically about the first time a team does an iteration of delivery for a new product, I've noted a consistent pattern in what great teams have as their first delivery goal. I've worked on several engagements where the goal has been virtually identical. This may be my coaching and I have influenced this, but there is always a sense of alignment and confidence that this is the best way to de-risk, learn, and set up for faster delivery in subsequent iterations.</p>&#13;
			<p>An example first iteration goal from a European automotive organization was:</p>&#13;
			<p style="text-align:center;"><em class="italics">Set up our workspace, provide a walking skeleton connecting the frontend to API to database underpinned by CI/CD.</em></p>&#13;
			<p>Several other engagements have had almost identical goals, and the pattern is strong because:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>The team wants to set up their workspace. That may be their physical workspace with lots of information radiators and collaboration space. It may be a virtual workspace with digital tooling. It may be a development environment using code-ready workspaces and being familiar with all tools to be used.</li>&#13;
				<li>The plan to build <a id="_idIndexMarker1534"/><a id="_idIndexMarker1535"/>a walking skeleton. This is a thin slice of the whole architecture delivered in one iteration. There won't be any fancy frontend or complex backend processing. They will prove full-stack development and that the cross-functional team representing all parts of the logical architecture<a id="_idIndexMarker1536"/><a id="_idIndexMarker1537"/> can deliver working software together. It's a walking skeleton because it is a fully working product. It just doesn't do very much yet!</li>&#13;
				<li>Their work will be underpinned by continuous integration and continuous delivery. This green-from-go practice means they are set up for success when it comes to automating builds, tests, and deployments. If they prove this and learn this for a thin slice, it will become increasingly valuable as we start to put all the flesh and organs into the walking skeleton!</li>&#13;
			</ul>&#13;
			</div>&#13;
			<p>The final part of this chapter shifts the focus from what we're deciding to deliver next to how we're going to measure and learn from our experiments and the features we deliver. The OpenShift platform enables our teams to consider several advanced deployment capabilities.</p>&#13;
			<h2 id="_idParaDest-245"><a id="_idTextAnchor280"/>Advanced Deployment Considerations</h2>&#13;
			<p>Earlier in this chapter, we explained the practice of <strong class="bold">Design of Experiments</strong> and how we intend to take an experimental mindset to our development, especially where assumptions and hypotheses have been formed in our Discovery Loop practices.</p>&#13;
			<p>The OpenShift platform enables several different deployment strategies that support the implementation of experiments. When we are on the Options Pivot, we should consider these strategies and which (if any) we should plan with the delivery of the associated Product <a id="_idIndexMarker1538"/><a id="_idIndexMarker1539"/>Backlog item. The advanced deployment strategies we can consider include:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>A/B Testing</li>&#13;
				<li>Blue/Green Deployments</li>&#13;
				<li>Canary Releases</li>&#13;
				<li>Dark Launches</li>&#13;
				<li>Feature Toggling</li>&#13;
			</ul>&#13;
			<p>We introduce these concepts here as, from an options planning perspective, this is where we need to be aware of them. We'll return to specific implementation details in <em class="italics">Section 6, Build It, Run It, Own It</em>, and we'll explore how we use the resulting metrics in <em class="italics">Section 7, Improve It, Sustain It</em>.</p>&#13;
			<h3 id="_idParaDest-246"><a id="_idTextAnchor281"/>A/B Testing</h3>&#13;
			<p>This is a randomized experiment<a id="_idIndexMarker1540"/><a id="_idIndexMarker1541"/> in which we compare and evaluate the performance of different versions of a product in pairs. Both product versions are available in production (live) and randomly <a id="_idIndexMarker1542"/><a id="_idIndexMarker1543"/>provided to different users. Data is collected about the traffic, interaction, time spent, and other relevant metrics, which will be used to judge the effectiveness of the two different versions based on the change in user behavior. The test determines which version is performing better in terms of the Target Outcomes you have started with.</p>&#13;
			<p>A/B <a id="_idIndexMarker1544"/><a id="_idIndexMarker1545"/>Testing is simple to apply, fast to execute, and often conclusions can be made simply by comparing the conversion/activity data between the two versions. It can be limiting as the two versions should not differ too much and more significant changes in the product may require a large number of A/B Tests to be performed. This is one of the practices that allows you to <em class="italics">tune the engine</em>, as <a id="_idIndexMarker1546"/><a id="_idIndexMarker1547"/>described in <em class="italics">The Lean Startup</em><span id="footnote-044-backlink"><a class="_idFootnoteLink _idGenColorInherit" href="#footnote-044">9</a></span> by <em class="italics">Eric Ries</em>.</p>&#13;
			<div id="footnote-044" class="_idFootnote" epub:type="footnote">&#13;
				<p class="FootNote"><a class="_idFootnoteAnchor _idGenColorInherit" href="#footnote-044-backlink">9</a>	<a href="http://theleanstartup.com/">http://theleanstartup.com/</a></p>&#13;
			</div>&#13;
			<div>&#13;
				<div id="_idContainer361" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_29.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.29: A/B Testing</p>&#13;
			<p>For more<a id="_idIndexMarker1548"/><a id="_idIndexMarker1549"/> information on this practice and to discuss it with community members or contribute your own<a id="_idIndexMarker1550"/><a id="_idIndexMarker1551"/> improvement to it, please look at <a href="http://openpracticelibrary.com/practice/split-testing-a-b-testing/">openpracticelibrary.com/practice/split-testing-a-b-testing/</a>.</p>&#13;
			<h3 id="_idParaDest-247">B<a id="_idTextAnchor282"/>lue/Green Deployments</h3>&#13;
			<p>Blue/Green Deployment is a<a id="_idIndexMarker1552"/><a id="_idIndexMarker1553"/> technique in software development that relies on two productive environments being available to the <a id="_idIndexMarker1554"/><a id="_idIndexMarker1555"/>team. One of them, let's call it <strong class="bold">green</strong>, is operational and takes load from the reverse proxy (load balancer/router). The other environment, let's call it <strong class="bold">blue</strong>, is a copy upgraded to a new version. It is disconnected from the load balancing while this upgrade is completed. </p>&#13;
			<div>&#13;
				<div id="_idContainer362" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_30.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.30: Blue/Green Deployments</p>&#13;
			<p>The team can perform all required tasks for an upgrade of the product version on the <strong class="bold">blue</strong> environment without the rush of downtime. Once the <strong class="bold">blue</strong> environment is ready and has passed all tests and checks, the team simply redirects the reverse proxy (load balancer/router) from the <strong class="bold">green</strong> environment to the <strong class="bold">blue</strong> environment.</p>&#13;
			<p>If everything works fine with the <strong class="bold">blue</strong> environment, the now outdated <strong class="bold">green</strong> can be prepared to be recycled to serve as the <strong class="bold">blue</strong> for the next release. If things go bad, the team can switch back to a<a id="_idIndexMarker1556"/><a id="_idIndexMarker1557"/> stable environment instantly using the reverse proxy/load balancer/router.</p>&#13;
			<p>This is a feedback loop practice that allows the team to get prompt feedback from the real-life use of their changes. It enables continuous delivery and provides safety for performing complex releases. It removes the time pressure and reduces the downtime to practically zero. This is beneficial for both technical teams and end users who will not notice glitches or unavailability of the service/product, provided that the new version is performing at par. In case of adverse effects, it allows the teams to have an instant roll-back alternative and limit the negative impact on customers.</p>&#13;
			<p>To explore this practice further, visit the <a id="_idIndexMarker1558"/><a id="_idIndexMarker1559"/>Open Practice Library page at <a href="http://openpracticelibrary.com/practice/blue-green-deployments/">openpracticelibrary.com/practice/blue-green-deployments/</a>.</p>&#13;
			<h3 id="_idParaDest-248">Ca<a id="_idTextAnchor283"/>nary Releases</h3>&#13;
			<p>In software development, this is a form <a id="_idIndexMarker1560"/><a id="_idIndexMarker1561"/>of continuous delivery in which only a small number of the real users of a product will be exposed to the new version of the product. The team monitors for regressions, performance issues, and other adverse effects and can easily move users<a id="_idIndexMarker1562"/><a id="_idIndexMarker1563"/> back to the working old version if issues are spotted.</p>&#13;
			<p>The term comes from the use of caged birds in coal mines to discover the buildup of dangerous gases early on. The gases would kill the bird long before they became life-threatening for the miners. As with the canary in the mine, this release practice provides an early warning mechanism for avoiding bigger issues.</p>&#13;
			<p>The canary release provides continuous delivery teams with safety by enabling them to perform a phased rollout, gradually increasing the number of users on a new version of a product. While rolling out the new version, the team will be closely monitoring the performance of the platform, trying to understand <a id="_idIndexMarker1564"/><a id="_idIndexMarker1565"/>the impacts of the new version, and assessing the risks of adverse effects such as regressions, performance issues, and even downtime. This approach allows the team to <strong class="bold">roll back</strong> the release as soon as such adverse effects are observed without the majority of the customers being impacted even for a limited amount of time.</p>&#13;
			<p>Canary Release is similar to A/B Testing in the sense that it is only exposing a part of the population to the new feature, but unlike A/B Testing, the new feature can and is typically a completely new feature and not just a small tweak of an existing one. The purpose is different too. A/B Testing looks to improve the product performance in terms of getting<a id="_idIndexMarker1566"/><a id="_idIndexMarker1567"/> business <a id="_idIndexMarker1568"/><a id="_idIndexMarker1569"/>outcomes, while the Canary Release is focused entirely on technical performance.</p>&#13;
			<div>&#13;
				<div id="_idContainer363" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_31.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.31: Canary deployments</p>&#13;
			<p>You can read <a id="_idIndexMarker1570"/><a id="_idIndexMarker1571"/>more about this practice, contribute improvements, or have a discussion with the wider community at <a href="http://openpracticelibrary.com/practice/canary-release">openpracticelibrary.com/practice/canary-release</a>.</p>&#13;
			<h3 id="_idParaDest-249">Dar<a id="_idTextAnchor284"/>k Launches</h3>&#13;
			<p>Dark Launches are another<a id="_idIndexMarker1572"/><a id="_idIndexMarker1573"/> continuous <a id="_idIndexMarker1574"/><a id="_idIndexMarker1575"/>delivery practice that release new features to a subset of end users and then captures their behaviors and feedback. They enable the team to understand the real-life impact of these new features, which may be unexpected for users in the sense that no<a id="_idIndexMarker1576"/><a id="_idIndexMarker1577"/> users asked for them. It is one of the last steps for validating a product/market fit for new features. Rather than launching the features to your entire group of users at once, this method allows you to test the waters to make sure your application works as planned before you go live.</p>&#13;
			<p>Dark Launches provide safety by limiting the impact of new features to only a subset of the users. They allow the team to build a better understanding of the impact created by the new feature and the ways the users would interact with it. Often novel ways of interaction can surface, ways that were not initially envisioned by the team. This can be both positive and negative, and the limited availability allows the team to draw conclusions from the real-life use and decide if the feature will be made widely available, further developed, or discontinued.</p>&#13;
			<div>&#13;
				<div id="_idContainer364" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_32.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.32: Dark Launches</p>&#13;
			<p>The Dark Launches practice has its own <a id="_idIndexMarker1578"/><a id="_idIndexMarker1579"/>Open Practice Library page at <a href="http://openpracticelibrary.com/practice/dark-launches/">openpracticelibrary.com/practice/dark-launches/</a>, so head there for further information, to start a conversation, or to improve the practice.</p>&#13;
			<h3 id="_idParaDest-250">Feat<a id="_idTextAnchor285"/>ure Flags</h3>&#13;
			<p>Feature Flags (also known as Feature Bits/Toggles/Flipping/Controls) are an engineering practice that can be <a id="_idIndexMarker1580"/><a id="_idIndexMarker1581"/>used to change your software's functionality without changing and re-deploying your code. They allow specific features of an application to be turned on and off for testing and maintenance purposes.</p>&#13;
			<p>In software, a flag is <em class="italics">one or more bits used to store binary values.</em> So, it's a Boolean that can either be true or false. A flag can <a id="_idIndexMarker1582"/><a id="_idIndexMarker1583"/>be checked with an if statement. A feature in software is a bit of functionality that delivers some kind of value. In its simplest form, a Feature Flag (or Toggle) is just an <strong class="inline">if</strong> statement surrounding a bit of functionality in your software.</p>&#13;
			<p>Feature Toggles are a foundational engineering practice and <a id="_idIndexMarker1584"/><a id="_idIndexMarker1585"/>provide a great way to manage the behavior of the product in order to perform experiments or safeguard performance when releasing fresh new features.</p>&#13;
			<div>&#13;
				<div id="_idContainer365" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_33.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.33: Feature Flags</p>&#13;
			<p>This practice has a page in the <a id="_idIndexMarker1586"/><a id="_idIndexMarker1587"/>Open Practice Library at <a href="http://openpracticelibrary.com/practice/feature-toggles">openpracticelibrary.com/practice/feature-toggles</a>, so have a look there <a id="_idIndexMarker1588"/><a id="_idIndexMarker1589"/>for more information or to engage with the community on it.</p>&#13;
			<p>Having introduced these advanced deployment considerations and how they support the Design of Experiments, let's look at how our <a id="_idIndexMarker1590"/><a id="_idIndexMarker1591"/>PetBattle team might use them.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-251" class="Author-Heading"><a id="_idTextAnchor286"/>PetBattle – Tech Spikes, Prototypes, Experiments, and Feature Implementations</h2>&#13;
			<p>The team gathered by the<a id="_idIndexMarker1592"/><a id="_idIndexMarker1593"/> new Product Backlog, which was, floor to ceiling, a huge column of sticky notes! In fact, they didn't all fit in a single column so the items toward the <a id="_idIndexMarker1594"/><a id="_idIndexMarker1595"/>bottom fanned out to produce what looked like a big funnel. It was nice and ordered at the top but the bottom would need some organizing. But that was OK as the team reckoned there was enough work on the backlog to keep them busy during the next few weeks, so they could refine the Product Backlog as they went along.</p>&#13;
			<p>Having attended a workshop on advanced deployment considerations, they decided to do some refinement on the functional features on the Product Backlog. They produced three columns on their whiteboard with the headings Research, Experiment, and Implement. They time-boxed the discussion for 45 minutes. There were 15 features to talk through, so on average, 3 minutes per item. Their goal was to put each feature in one of the columns with a short note on what their approach to the implementation was.</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li><strong class="bold">Open PetBattle:</strong> This was easy. Anyone using the app would need to open it. IMPLEMENT.</li>&#13;
				<li><strong class="bold">Display Leaders:</strong> Lots of questions about what and how to display. How many leaders? Should we add pagination or scroll? They decided some RESEARCH was needed – perhaps a UI prototype with some user testing.</li>&#13;
				<li><strong class="bold">Let me in please:</strong> The team had to go back to the Event Storm to remind themselves what this was about! Again, it was a simple feature of letting the user in to see Pets uploaded. IMPLEMENT.</li>&#13;
				<li><strong class="bold">Vote for Cat:</strong> This triggered some conversation. Do they vote up or down? Or do they just give a vote (or nothing at all)? The team was divided and had heard differing views from user interviews. They decided to EXPERIMENT with an A/B Test.</li>&#13;
				<li><strong class="bold">Add my Cat:</strong> Not much research or experimentation needed. A standard uploading tool was needed. Just IMPLEMENT.</li>&#13;
				<li><strong class="bold">Verify Image:</strong> This sounded a bit trickier. There were merging AI/ML patterns available. It needed some technical RESEARCH and probably a Technical Spike.</li>&#13;
				<li><strong class="bold">Enter cat into tournament:</strong> Not much ambiguity here. IMPLEMENT.</li>&#13;
				<li><strong class="bold">Display Tournament Cat:</strong> It wasn't clear if this was going to be well received or not. The team thought they could EXPERIMENT with a feature toggle and then it's easy enough to turn off.</li>&#13;
				<li><strong class="bold">Disable "Add my Cat":</strong> Some users have more than one cat and will want to add more than one. Let's EXPERIMENT with a Dark Launch of this feature to a small subset of users.</li>&#13;
				<li><strong class="bold">Vote for given cat:</strong> Once the team got the results from the A/B Test, they could EXPERIMENT further and launch as a Canary Test.</li>&#13;
				<li><strong class="bold">Update the Leaderboard:</strong> IMPLEMENT</li>&#13;
				<li><strong class="bold">End Competition:</strong> IMPLEMENT</li>&#13;
				<li><strong class="bold">Notify Players:</strong> Not clear how this would happen – SMS? Email? Other mechanisms? The team decided to do some user RESEARCH.</li>&#13;
				<li><strong class="bold">Deliver Prize to Winner:</strong> The prize strategy was still under consideration, so more RESEARCH would be needed.</li>&#13;
				<li><strong class="bold">Begin Next Tournament:</strong> This could either happen immediately or the next day. Perhaps another EXPERIMENT A/B Test would see what drop-off the team gets by waiting.</li>&#13;
			</ul>&#13;
			<p>The team finished in 40 minutes. It was a great discussion and they felt ready to do their first iteration planning with these decisions.</p>&#13;
			</div>&#13;
			<p>Let's look at another real-world experience to <a id="_idIndexMarker1596"/><a id="_idIndexMarker1597"/>see just how simple yet effective this experimental mindset can be.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-252" class="Author-Heading"><a id="_idTextAnchor287"/>Reframing the Question – How Much Can I Borrow or How Much House Can I Afford?</h2>&#13;
			<div>&#13;
				<div id="_idContainer366" class="IMG---Figure" style="float: right; margin: 6px; hight:6cm; width:6cm;">&#13;
					<img src="../Images/Donal.jpg" alt="" width="250" height="250"/>&#13;
				</div>&#13;
			</div>&#13;
			<p>It can be very easy to fall into the trap of recreating what you already have but with a shiny new frontend, but ultimately that may not solve problems that are more fundamental. While working for a bank, a small team of us were tasked with trying to find out why there was such a large drop-off in mortgage applications once people had used an online Mortgage Calculator. The calculator on the bank's site was pretty simple: you popped in your salary and it told you what you could borrow from them. There was no ability to add a deposit or specify a term length to see how it would reflect repayment rates or lending criteria. The calculator was also very slow and clunky, not mobile-friendly or responsive. The quick solution for the bank was to just reskin it to make these cosmetic fixes, but this didn't really help answer the question of why were they getting hundreds of people doing the calculation but only a tiny percentage of those people continuing to apply for a loan.</p>&#13;
			<p>The team was very small, just one designer, two engineers, a business analyst, and a Product Owner. As a small co-located team, buried in the heart of the bank, we were able to move fast! We interviewed people who had recently purchased mortgages with the bank to get insight into their motivations for using the tool. We did a load of research by going into the bank branches and asking people open-ended questions while they used the existing tool. We collated this information along with how they were accessing the calculator and if they were to complete an application, what device they would use,that is, their phone or their laptop.</p>&#13;
			<p>Through this research we stumbled upon an interesting fact – people were not interested in <em class="italics">How much could I borrow</em> but <em class="italics">How much house can I afford.</em> This simple difference might seem inconsequential but it massively affected how we rebuilt the bank's online mortgage calculator. It meant people wanted to be able to tailor their calculation to see how their rates and lending criteria could be affected by, for example, having more income. Or, if they were to continue to save for another year and have more of a deposit saved, could they get a better rate? This flip meant people were using the tool to not see if they could afford a given home but how much of a home could they afford and by when.</p>&#13;
			<p>It would have been very simple for us to just recreate the bank's existing calculator with a new skin that ran on a mobile – but this would not have addressed the core problem. By reframing the question, we were now in a position to create a simple calculator tailored to the needs of the bank's first-time buyers.</p>&#13;
			</div>&#13;
			<p>All these advanced deployment <a id="_idIndexMarker1598"/><a id="_idIndexMarker1599"/>considerations provide powerful tools for use in Options planning and how we can conduct research, experimentation, and implementation.</p>&#13;
			<h2 id="_idParaDest-253"><a id="_idTextAnchor288"/>Research, Experiment, Implement</h2>&#13;
			<p>This chapter has highlighted that, when considering our options, it's not just about prioritizing features and<a id="_idIndexMarker1600"/><a id="_idIndexMarker1601"/> implementing them. We need to balance feature implementation with <a id="_idIndexMarker1602"/><a id="_idIndexMarker1603"/>ongoing research and experimentation.</p>&#13;
			<p>A great way to summarize and visualize all of this is by using the <strong class="bold">Mobius Loop's Options Map</strong>.</p>&#13;
			<h2 id="_idParaDest-254"><a id="_idTextAnchor289"/>Creating an Options Map</h2>&#13;
			<p>We concluded <em class="italics">Section 3, Discover It</em>, with a Discovery Map – a single information radiator that summarized<a id="_idIndexMarker1604"/><a id="_idIndexMarker1605"/> the iteration of the Discovery Loop.</p>&#13;
			<p>We will conclude <em class="italics">Section 4, Prioritize It</em>, with an Options Map – this is another open-source artifact available in the Mobius Kit under Creative Commons that you can use to summarize all the learnings and decisions taken during your journey in the Options Pivot.</p>&#13;
			<p>This map should slot neatly next to your Discovery Map and is used to summarize:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>What have we just focused on in the Options Pivot?</li>&#13;
				<li>Which outcomes are we targeting?</li>&#13;
				<li>What ideas or hypotheses do we need to validate?</li>&#13;
				<li>How will we deliver the options?</li>&#13;
				<li>Which options do we want to work on first?</li>&#13;
			</ul>&#13;
			<p>When we return to the Options Pivot after an iteration of the Delivery Loop, we'll complete the final section of this map:</p>&#13;
			<ul style="list-style-type:disc;">&#13;
				<li>What did we learn?</li>&#13;
			</ul>&#13;
			<div>&#13;
				<div id="_idContainer367" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_34.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.34: The Options Map</p>&#13;
			<p>Now let's look<a id="_idIndexMarker1606"/><a id="_idIndexMarker1607"/> at PetBattle's Options Map.</p>&#13;
			<div style="background-color:#EEEEEE; display:block; overflow-x:auto; padding:.5em;margin: 5px;">&#13;
			<h2 id="_idParaDest-255" class="Author-Heading"><a id="_idTextAnchor290"/>PetBattle – The Options Map</h2>&#13;
			<p>There is a lot of detail captured in this map, so please feel free to explore the online version available<a id="_idIndexMarker1608"/><a id="_idIndexMarker1609"/> in the book's GitHub repository.</p>&#13;
			<div>&#13;
				<div id="_idContainer368" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_35.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p>Figure 11.35: The PetBattle Options Map</p>&#13;
			</div>&#13;
			<p>The Options Map <a id="_idIndexMarker1610"/><a id="_idIndexMarker1611"/>provides clarity and direction as to how the product priorities to help reach outcomes. It helps form our delivery strategy.</p>&#13;
			<h2 id="_idParaDest-256"><a id="_idTextAnchor291"/>Conclusion</h2>&#13;
			<p>In this chapter, we focused on how we are going to deliver the outcomes set in the previous section.</p>&#13;
			<div>&#13;
				<div id="_idContainer369" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_36.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.36: Adding practices to navigate us through Options</p>&#13;
			<p>We explored the User Story Mapping and Value Slicing practices and how we take all of the information captured in Discovery practices and push it through these tools. We also showed how using some helpful practices to look at the same information with slightly different lenses –Impact versus Effort Prioritization and How/Now/Wow Prioritization – can help improve Value Slicing. Where proposed feature areas would benefit from a deeper dive to understand the value, we recommended the Design Sprint as an option.</p>&#13;
			<p>We showed how these practices drive the initial Product Backlog prioritized by value and how this produces a living, breathing artifact that will be subject to continuous Product Backlog Refinement as we gather more learning, feedback, and metrics for our delivery. The economic prioritization model WSJF, which is based on Cost of Delay, provides a repeatable and quantifiable tool to drive this. It's one of many prioritization tools that can help the Product Ownership function work smoothly and effectively.</p>&#13;
			<p>Finally, we looked at the advanced deployment considerations that should be taken when designing experiments and how platforms such as OpenShift enable powerful evidence-based testing to be conducted in production with users. A/B Testing, Blue/Green Deployments, Canary Releases, Dark Launches, and Feature Flags were all introduced from a business perspective. We will return to the implementation details of these in <em class="italics">Section 6, Build It, Run It, Own It</em> and explore how we interpret the measures from them in <em class="italics">Section 7, Improve It, Sustain It.</em></p>&#13;
			<div>&#13;
				<div id="_idContainer370" class="IMG---Figure">&#13;
					<img src="../Images/B16297_11_37.jpg" alt=""/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure">Figure 11.37: Practices used to complete a Discovery Loop and Options Pivot on a foundation of culture and technology</p>&#13;
			<p>In the next chapter, we will shift to the Delivery Loop. We'll look at agile delivery and where and when it is applicable according to levels of complexity and simplicity. We'll also look at Waterfall and the relative merits and where it might be appropriate. We'll explore different <a id="_idIndexMarker1612"/><a id="_idIndexMarker1613"/>agile frameworks out there and how all of them relate to the Open Practice Library and Mobius Loop. We'll explore the importance of visualization and of capturing measurements and learning during our iterations of the Delivery Loop.</p>&#13;
		</div>&#13;
</body></html>