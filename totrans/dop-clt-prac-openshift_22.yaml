- en: 15\. Run It
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 15\. 运行它
- en: There is a saying that *your code has no value until it runs in production*.
    The sentiment here is that until your customers use your software, it's of limited
    value for your business or organization. It is certainly a broad generalization!
    However, it does speak to the essential nature of software that its utility is
    directly related to being able to run it for whatever purposes it was ultimately
    written for. To reach production with the quality of service that our customers
    expect, all of the code must be put through its paces.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 有句话说，*直到代码在生产环境中运行，它才有价值*。这里的意思是，直到客户使用你的软件，它对你的业务或组织的价值是有限的。这当然是一个广泛的概括！然而，这确实反映了软件的本质——其效用直接与能够运行它以实现最终编写目的相关。为了在生产环境中达到客户预期的服务质量，所有的代码都必须经过严格的测试。
- en: In this chapter, we are going to explore how the PetBattle team tests their
    software so they have greater confidence in its ability to run as expected in
    production. Testing is multifaceted, as we discussed in *Chapter 7*, *Open Technical
    Practices – The Midpoint*, and we are going to cover in some detail the types
    and scope of testing, from unit tests to end-to-end testing, through to security
    checks and more.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨PetBattle团队如何测试他们的软件，以便在生产环境中能够更有信心地运行。正如我们在*第七章*、*开放技术实践——中期*中讨论的，测试是多方面的，我们将详细介绍测试的类型和范围，从单元测试到端到端测试，再到安全检查等。
- en: When the hobbyist version of the application went live, the PetBattle founders
    soon discovered that malicious content was being uploaded to the site. As part
    of this chapter, we'll look at a modern-day solution to this problem using a trained
    AI-ML model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用的爱好者版本上线后，PetBattle的创始人很快发现恶意内容被上传到站点。作为本章的一部分，我们将探讨使用训练过的AI-ML模型来解决这个问题的现代方案。
- en: In the last section of this chapter, we explore some common cloud deployment
    patterns and demonstrate A/B testing and experimentation, for gaining insight
    into how we can safely measure and learn the impact of deploying new features
    in production.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后部分，我们将探讨一些常见的云部署模式，并展示A/B测试和实验，以便深入了解如何安全地衡量和学习在生产环境中部署新特性所带来的影响。
- en: The Not Safe For Families (NSFF) Component
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不适合家庭的内容（NSFF）组件
- en: As we mentioned earlier, one of the major issues that we faced when running
    the first generation of PetBattle was online trolls uploading inappropriate images
    to the system. This added to the operational overhead of running the platform
    because the PetBattle founders would have to search MongoDB for the offending
    images and remove them by hand—very tedious!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，在运行第一代PetBattle时，我们面临的一个主要问题是在线恶搞者上传不当图片到系统。这增加了平台的运营开销，因为PetBattle的创始人必须手动在MongoDB中查找并删除这些违规图片——非常繁琐！
- en: Ever innovating, the team decided to try and come up with an automated solution
    to this problem. One approach we decided to investigate was to use **artificial
    intelligence** (**AI**) to perform image classification on the uploaded images
    and incorporate this into the platform.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 一直在创新的团队决定尝试为这个问题提出一个自动化解决方案。我们决定调查的一个方法是使用**人工智能**（**AI**）对上传的图片进行分类，并将其集成到平台中。
- en: The field of AI in itself is a fascinating area of expertise that we won't even
    slightly go into here, other than to say that we are using a pre-trained image
    classification model served by the open source TensorFlow machine learning platform.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能本身是一个极具吸引力的领域，在这里我们不会深入探讨，只是提到我们正在使用由开源TensorFlow机器学习平台提供的预训练图像分类模型。
- en: Great, but how do we go about running this on OpenShift?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，但我们如何在OpenShift上运行这个应用？
- en: 'The plan is to:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 计划如下：
- en: Generate or obtain a pre-trained image classification model.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成或获取一个预训练的图像分类模型。
- en: Build containers containing the TensorFlow serving component that can serve
    up the model and make predictions based on our uploaded images.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建包含TensorFlow服务组件的容器，可以为我们上传的图片提供模型服务并进行预测。
- en: Deploy and run the container on OpenShift in a "scale to zero" deployment model,
    aka Serverless.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在OpenShift上以“按需扩展”部署模型（即无服务器架构）部署并运行容器。
- en: Why Serverless?
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么选择无服务器架构？
- en: When deploying a container on a Kubernetes-based platform, such as OpenShift,
    Kubernetes takes on the responsibility of managing the running container and,
    by default, restarting it if it terminates due to an error. Basically, there's
    always a container running. This is all good and fine for containers that are
    constantly receiving and processing traffic, but it's a waste of system resources
    constantly running a container that receives traffic either occasionally or in
    bursts.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于 Kubernetes 的平台上部署容器时，例如 OpenShift，Kubernetes 负责管理运行中的容器，并且默认情况下，如果容器因错误终止，它会重新启动。基本上，容器始终处于运行状态。这对于那些持续接收和处理流量的容器来说是没问题的，但对于那些偶尔或突发性接收流量的容器来说，持续运行它会浪费系统资源。
- en: What we'd like to achieve is to deploy a container and have it start up only
    when needed, that is, during incoming requests. Once active, we want it to process
    the incoming requests and then, after a period of no traffic, shut down gracefully
    until further incoming requests are received. We'd also like the container instances
    to scale up in the event of a surge of incoming requests.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望实现的是，在需要时才启动容器，也就是说，在接收到请求时启动。容器启动后，我们希望它处理进入的请求，然后在一段时间没有流量后，优雅地关闭，直到收到进一步的请求。我们还希望容器实例在接收到大量请求时能够自动扩展。
- en: It is possible to automate the scaling up and down of the number of container
    instances running on the platform using the Kubernetes Horizontal Pod Autoscaler;
    however, this does not scale to zero. We could also use something like the `oc
    scale` command, but this requires a fair amount of scripting and component integration.
    Thankfully, the Kubernetes community thought about this and came up with a solution
    called Knative.[1](#footnote-149)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Kubernetes 水平 Pod 自动扩缩器（Horizontal Pod Autoscaler）自动化平台上容器实例数量的增加和减少；然而，这并不能扩展到零。我们也可以使用类似
    `oc scale` 命令的工具，但这需要大量的脚本编写和组件集成。幸运的是，Kubernetes 社区考虑到了这一点，并提出了解决方案，称为 Knative。[1](#footnote-149)
- en: Knative has two major components, **Knative Serving** and **Knative Eventing**.
    Serving is used to spin up (and down) containers depending on HTTP traffic. Knative
    Eventing is somewhat equivalent but is focused on spinning up containers based
    on events and addresses broader use cases. For the purposes of this book, we are
    going to focus on using Knative Serving. However, we will also give an example
    of how Knative Eventing could be used.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Knative 主要有两个组件，**Knative Serving** 和 **Knative Eventing**。Serving 用于根据 HTTP
    流量启动（和关闭）容器。Knative Eventing 功能类似，但它专注于基于事件启动容器，覆盖了更广泛的使用场景。本书的重点将放在使用 Knative
    Serving 上。不过，我们也会提供一个示例，展示如何使用 Knative Eventing。
- en: Generating or Obtaining a Pre-trained Model
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成或获取预训练模型
- en: We had been experimenting with image classification for a while. We started
    using some of the components from the Open Data Hub community ([https://opendatahub.io/](https://opendatahub.io/))
    and trained out models on top of pre-existing open source models that were available.
    We eventually generated a trained data model that could classify images that we
    deemed NSFF based on an implementation of Yahoo's Open NSFW Classifier,[2](#footnote-148)
    which was rewritten with TensorFlow. While it was not perfect, it was a good enough
    model to start with.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经进行了图像分类实验一段时间了。我们开始使用来自 Open Data Hub 社区的一些组件（[https://opendatahub.io/](https://opendatahub.io/)），并在现有的开源模型基础上训练我们的模型。最终，我们生成了一个训练好的数据模型，能够根据
    Yahoo 的 Open NSFW 分类器[2](#footnote-148)（已用 TensorFlow 重写）对图像进行分类，判断其是否为 NSFF。尽管这个模型并不完美，但它足够用于入门。
- en: A common pattern in the data science community is to serve up trained data models
    using tools such as Seldon,[3](#footnote-147) which are part of Open Data Hub.
    For our purposes though, a simple object storage tool was all that was required.
    So, we chose MinIO,[4](#footnote-146) a Kubernetes native object store. We decided
    we could scale that out later if needed, using more advanced storage mechanisms,
    for example, OpenShift Container Storage or AWS S3.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学社区中常见的模式是使用像 Seldon[3](#footnote-147) 这样的工具来服务训练好的数据模型，而这些工具是 Open Data
    Hub 的一部分。然而，对于我们的需求来说，只需要一个简单的对象存储工具。因此，我们选择了 MinIO[4](#footnote-146)，这是一个 Kubernetes
    原生对象存储工具。我们决定，如果需要的话，稍后可以使用更先进的存储机制扩展它，比如 OpenShift 容器存储或 AWS S3。
- en: '[1](#footnote-149-backlink) [https://knative.dev/](https://knative.dev/)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[1](#footnote-149-backlink) [https://knative.dev/](https://knative.dev/)'
- en: '[2](#footnote-148-backlink) [https://github.com/yahoo/open_nsfw](https://github.com/yahoo/open_nsfw)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[2](#footnote-148-backlink) [https://github.com/yahoo/open_nsfw](https://github.com/yahoo/open_nsfw)'
- en: '[3](#footnote-147-backlink) [https://www.seldon.io/](https://www.seldon.io/)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[3](#footnote-147-backlink) [https://www.seldon.io/](https://www.seldon.io/)'
- en: '[4](#footnote-146-backlink) [https://min.io/](https://min.io/)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[4](#footnote-146-backlink) [https://min.io/](https://min.io/)'
- en: 'We loaded the trained data model into MinIO and it looked as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将训练好的数据模型加载到MinIO中，看起来是这样的：
- en: '![](img/B16297_15_01.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_01.jpg)'
- en: 'Figure 15.1: TensorFlow data model saved in MinIO'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.1：TensorFlow数据模型保存在MinIO中
- en: The saved model is something we can serve up using TensorFlow Serving,[5](#footnote-145)
    which basically gives us an API endpoint to call our saved model with. There is
    an open source TensorFlow serving image we can deploy and it's a matter of configuring
    that to find our saved model in our S3 storage location.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所保存的模型是我们可以使用TensorFlow Serving提供的服务之一，[5](#footnote-145)这基本上为我们提供了一个调用我们保存模型的API端点。我们可以部署一个开源的TensorFlow
    Serving镜像，并且只需配置它来找到我们在S3存储位置中的保存模型即可。
- en: We have glossed over the large portion of engineering that goes into making
    AI, ML, and Ops pipelines not because it is not an interesting subject, but mainly
    because it would require a whole other book to do it justice! If this subject
    is close to your heart, then take a look at the Open Data Hub project.[6](#footnote-144)
    This is an open source project based on Kubeflow,[7](#footnote-143) providing
    tools and techniques for building and running AI and ML workloads on OpenShift.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经忽略了大部分工程化过程，这些过程使得AI、ML和Ops管道变得更加完善，这并不是因为这不是一个有趣的主题，而主要是因为这需要另一本完全不同的书来充分阐述！如果这个主题对你很重要，那么请看一下Open
    Data Hub项目。[6](#footnote-144) 这是一个基于Kubeflow的开源项目，提供工具和技术来构建和运行OpenShift上的AI和ML工作负载。
- en: '[5](#footnote-145-backlink) [https://www.tensorflow.org/tfx/guide/serving](https://www.tensorflow.org/tfx/guide/serving)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[5](#footnote-145-backlink) [https://www.tensorflow.org/tfx/guide/serving](https://www.tensorflow.org/tfx/guide/serving)'
- en: '[6](#footnote-144-backlink) [http://opendatahub.io/](http://opendatahub.io/)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[6](#footnote-144-backlink) [http://opendatahub.io/](http://opendatahub.io/)'
- en: '[7](#footnote-143-backlink) [https://www.kubeflow.org/](https://www.kubeflow.org/)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[7](#footnote-143-backlink) [https://www.kubeflow.org/](https://www.kubeflow.org/)'
- en: The OpenShift Serverless Operator
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenShift Serverless Operator
- en: Before we start deploying our application software for the NSFF service, we
    need to add the OpenShift Serverless Operator[8](#footnote-142) to our PetBattle
    Bootstrap. The operator is installed at the cluster scope so that any project
    that wants to use the Knative components Knative Serving and Knative Eventing
    may do so.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始为NSFF服务部署我们的应用软件之前，我们需要将OpenShift无服务器操作员[8](#footnote-142)添加到我们的PetBattle引导程序中。该操作员安装在集群范围内，以便任何想要使用Knative组件Knative
    Serving和Knative Eventing的项目都可以这样做。
- en: 'Let''s use GitOps, ArgoCD, and Kustomize to configure and install the serverless
    operator. First, we can test out the configuration with ArgoCD. Log in using ArgoCD
    from the command line. Add the Git repository that contains the Knative serverless
    operator YAML subscription and create the application:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用GitOps、ArgoCD和Kustomize来配置和安装无服务器操作员。首先，我们可以使用ArgoCD测试配置。使用命令行从ArgoCD登录。添加包含Knative无服务器操作员YAML订阅的Git存储库并创建应用程序：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[8](#footnote-142-backlink) [https://github.com/openshift-knative/serverless-operator](https://github.com/openshift-knative/serverless-operator)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[8](#footnote-142-backlink) [https://github.com/openshift-knative/serverless-operator](https://github.com/openshift-knative/serverless-operator)'
- en: 'Once installed, you should be able to see this installed successfully in the
    `openshift-serverless` namespace:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，您应该能够在`openshift-serverless`命名空间中成功看到此安装。
- en: '![](img/B16297_15_02.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_02.jpg)'
- en: 'Figure 15.2: The OpenShift Serverless Operator (Knative)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.2：OpenShift无服务器操作员（Knative）
- en: 'We can also put this in our PetBattle UJ bootstrap from *Chapter 7*, *Open
    Technical Practices – The Midpoint*, so that we don''t need to run these commands
    manually. Add the following to our `values-tooling.yaml` and check it into Git:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将其放入我们的PetBattle UJ引导程序中，*第7章*，*开放技术实践 - 中点*，这样我们就不需要手动运行这些命令了。将以下内容添加到我们的`values-tooling.yaml`并将其提交到Git中：
- en: '[PRE15]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The operator is now ready for us to use to deploy our Knative service.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，操作员已准备好供我们使用，以部署我们的Knative服务。
- en: Deploying Knative Serving Services
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署Knative Serving服务
- en: 'There are a few ways in which to create Knative Serving services. We can create
    the Knative service definition and install that into our cluster. We have packaged
    this up as a Helm chart for easy installation:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以创建Knative Serving服务。我们可以创建Knative服务定义并将其安装到我们的集群中。我们已将其打包为Helm图表，以便轻松安装：
- en: '[PRE24]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'It may take a minute or so for the containers to start up and load the model
    data into MinIO; they may restart a few times while doing this. The output of
    the `oc get pods` command should look like this once successful – the MinIO S3
    pod and its completed data load and a TensorFlow Knative service pod:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 容器启动并将模型数据加载到 MinIO 中可能需要一分钟左右；在此过程中它们可能会重启几次。`oc get pods` 命令的输出应该是这样的：MinIO
    S3 pod 和其完成的数据加载，以及一个 TensorFlow Knative 服务 pod：
- en: '[PRE28]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'After a couple of minutes, the Knative Serving TensorFlow pod will terminate
    because it is not yet being called. This is what''s called Serverless scale to
    zero, that is, when there are no calling workloads there is no need to run the
    service. An equivalent service can also be created using the Knative command-line
    tool **kn**, which can be downloaded and installed from the OpenShift[9](#footnote-141)
    console. This is useful if you want to create a new service or are developing
    a service from scratch:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，Knative Serving TensorFlow pod 将终止，因为它尚未被调用。这就是所谓的无服务器（Serverless）缩放至零，即当没有调用工作负载时，服务不需要运行。可以使用
    Knative 命令行工具**kn**来创建等效的服务，该工具可以从 OpenShift[9](#footnote-141) 控制台下载并安装。如果您希望创建新服务或从头开始开发服务，这是很有用的：
- en: '[PRE33]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[9](#footnote-141-backlink) [https://docs.openshift.com/container-platform/4.7/serverless/serverless-getting-started.html](https://docs.openshift.com/container-platform/4.7/serverless/serverless-getting-started.html)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[9](#footnote-141-backlink) [https://docs.openshift.com/container-platform/4.7/serverless/serverless-getting-started.html](https://docs.openshift.com/container-platform/4.7/serverless/serverless-getting-started.html)'
- en: Here, we use command-line arguments and environment variables to tell the TensorFlow
    serving image how to run. The `--image` field specifies the container image and
    version we wish to run – in this case, the latest TensorFlow serving image. The
    `--cmd` field specifies the binary in the image we wish to run, for example, the
    model server command `tensorflow_model_server`. The `--arg` and `––env` variables
    specify the configuration. The trained model is served from the `S3 minio` service
    so we specify how to access the S3 endpoint. There are many configurations available
    to Knative Serving, such as autoscaling global defaults, metrics, and tracing.
    The `--autoscale-window` defines the amount of data that the autoscaler takes
    into account when scaling, so in this case, if there has been no traffic for two
    minutes, scale the pod to 0.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用命令行参数和环境变量来告诉 TensorFlow serving 镜像如何运行。`--image` 字段指定我们希望运行的容器镜像及版本——在这种情况下，是最新的
    TensorFlow serving 镜像。`--cmd` 字段指定我们希望运行的镜像中的二进制文件，例如，模型服务器命令 `tensorflow_model_server`。`--arg`
    和 `--env` 变量指定配置。训练好的模型从 `S3 minio` 服务提供，因此我们指定如何访问 S3 端点。Knative Serving 提供了许多配置选项，如自动扩缩的全局默认设置、指标和追踪。`--autoscale-window`
    定义了自动扩缩器在进行扩缩时所考虑的数据量，因此，在这种情况下，如果两分钟内没有流量，则将 pod 扩缩到 0。
- en: 'The Knative website[10](#footnote-140) goes into a lot more detail about the
    serving resources that are created when using Knative Serving and the configuration
    of these. To find the URL for our service, we can use this command:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Knative 网站[10](#footnote-140)提供了关于使用 Knative Serving 时创建的服务资源以及这些资源配置的更多细节。要查找我们的服务的
    URL，可以使用以下命令：
- en: '[PRE50]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'This gives us the HTTP URL endpoint to test our service with. It is worth noting
    that we can have multiple revisions of a service and that within the route mentioned
    previously, we can load balance traffic across multiple revisions. The following
    diagram depicts how this works in practice:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了测试服务的 HTTP URL 端点。值得注意的是，我们可以拥有多个服务版本，并且在前面提到的路由中，可以在多个版本之间进行流量负载均衡。下图展示了这种做法的实际工作原理：
- en: '![](img/B16297_15_03.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_03.jpg)'
- en: 'Figure 15.3: Knative routing for multiple application revisions'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.3：Knative 对多个应用版本的路由
- en: '[10](#footnote-140-backlink) [https://knative.dev/docs/serving/](https://knative.dev/docs/serving/)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[10](#footnote-140-backlink) [https://knative.dev/docs/serving/](https://knative.dev/docs/serving/)'
- en: Kourier[11](#footnote-139) is a lightweight ingress router based on an Envoy
    gateway. Using Knative service configuration, a user can specify routing rules
    that Knative Serving applies. This can be very useful when we're experimenting
    with different AI models or wanting to do A/B, Blue/Green, or Canary-type deployments,
    for example.[12](#footnote-138)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Kourier[11](#footnote-139)是一个基于 Envoy 网关的轻量级入口路由器。使用 Knative 服务配置，用户可以指定 Knative
    Serving 应用的路由规则。这在我们实验不同的 AI 模型或希望进行 A/B、蓝绿部署（Blue/Green）或金丝雀发布（Canary）时非常有用，例如[12](#footnote-138)。
- en: Invoking the NSFF Component
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调用 NSFF 组件
- en: 'A simple HTTP GET request on the route is all that''s required to invoke the
    component. The pod spins up and services the request usually within a couple of
    seconds and then spins down after a period of time (the `--autoscale-window` specified
    in the `kn` command-line argument, that is, 120 seconds). Using the output from
    the `kn list route` command, let''s check if the AI TensorFlow model is available.
    The `state` should read `AVAILABLE`:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 通过路由上的简单HTTP GET请求即可调用组件。Pod会在几秒钟内启动并处理请求，然后在一段时间后（即`--autoscale-window`，即`kn`命令行参数中指定的120秒）关闭。使用`kn
    list route`命令的输出，让我们检查AI TensorFlow模型是否可用。`state`应为`AVAILABLE`：
- en: '[PRE51]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[11](#footnote-139-backlink) [https://developers.redhat.com/blog/2020/06/30/kourier-a-lightweight-knative-serving-ingress/](https://developers.redhat.com/blog/2020/06/30/kourier-a-lightweight-knative-serving-ingress/)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[11](#footnote-139-backlink) [https://developers.redhat.com/blog/2020/06/30/kourier-a-lightweight-knative-serving-ingress/](https://developers.redhat.com/blog/2020/06/30/kourier-a-lightweight-knative-serving-ingress/)'
- en: '[12](#footnote-138-backlink) [https://medium.com/@kamesh_sampath/serverless-blue-green-and-canary-with-knative-kn-ad49e8b6aa54](https://medium.com/@kamesh_sampath/serverless-blue-green-and-canary-with-knative-kn-ad49e8b6aa54)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[12](#footnote-138-backlink) [https://medium.com/@kamesh_sampath/serverless-blue-green-and-canary-with-knative-kn-ad49e8b6aa54](https://medium.com/@kamesh_sampath/serverless-blue-green-and-canary-with-knative-kn-ad49e8b6aa54)'
- en: 'We should also see a pod spinning up to serve the request, using:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该看到一个Pod正在启动来处理请求，使用：
- en: '[PRE66]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: It then scales down to 0 after two minutes.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在两分钟后缩小到0。
- en: We want to test that our NSFF service works by sending it some images. We have
    two test sample images that have been encoded so they can be uploaded to the NSFF
    service.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望通过发送一些图像来测试我们的NSFF服务是否有效。我们有两个经过编码的测试样本图像，可以上传到NSFF服务。
- en: '![](img/B16297_15_04.1.jpg)![](img/B16297_15_04.2.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_04.1.jpg)![](img/B16297_15_04.2.jpg)'
- en: 'Figure 15.4: NSFF test images'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.4：NSFF测试图像
- en: 'Let''s download these images for testing:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们下载这些图像进行测试：
- en: '[PRE71]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Now submit these to our NSFF service using a simple `curl` command:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用简单的`curl`命令将它们提交到我们的NSFF服务：
- en: '[PRE73]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: The response from our model is a `predictions` array containing two numbers.
    The first is a measure of **Safe for Families**, the second is a measure of **Not
    Safe for Families**, and they add up to 1.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模型的响应是一个包含两个数字的`predictions`数组。第一个是**适合家庭**的度量，第二个是**不适合家庭**的度量，它们加起来为1。
- en: So, we can see that Daisy Cat has a very high safe for families rating (0.993)
    compared to our wrestlers (0.014) and we can use this in our PetBattle API to
    determine whether any given image is safe to display. By arbitrary testing, we
    have set a limit of >=0.6 for images we think are safe to view in the PetBattle
    UI.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到Daisy Cat与我们的摔跤手相比具有非常高的适合家庭评级（0.993），我们可以在PetBattle API中使用这一点，以确定是否可以显示任何给定的图像。通过任意测试，我们已经设定了对于我们认为适合在PetBattle
    UI中查看的图像，安全限制为>=0.6。
- en: 'We can redeploy our PetBattle API service to call out to the NSFF service by
    setting the `nssf.enabled` feature flag to `true` and using the hostname from
    the Knative service from a bash shell using the command line:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将`nssf.enabled`特性标志设置为`true`并在bash shell中使用Knative服务的主机名，使用以下命令行重新部署我们的PetBattle
    API服务，以调用NSFF服务：
- en: '[PRE85]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'If we now upload these test images to PetBattle via the UI and check the API
    server, we can see that the boxing picture has a `ISSFF` (Is Safe for Families)
    flag and Daisy Cat has a **true** value:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在通过UI上传这些测试图像到PetBattle并检查API服务器，我们可以看到拳击图片具有`ISSFF`（适合家庭）标志，Daisy Cat有一个**true**值：
- en: '![](img/B16297_15_05.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_05.jpg)'
- en: 'Figure 15.5: PetBattle API saved images with the ISSFF flag'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.5：PetBattle API保存带有ISSFF标志的图像
- en: 'The API code will not return any pictures to the PetBattle UI that are deemed
    NSFF. For example, the API code to return all pets in the PetBattle database is
    filtered by the `ISSFF` flag being set to `true`:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: API代码将不会返回任何被视为NSFF的图片到PetBattle UI。例如，返回PetBattle数据库中所有宠物的API代码会通过将`ISSFF`标志设置为`true`进行过滤：
- en: '[PRE91]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: Now that we have the API up and running it's time to test it and see if it performs
    as we expect.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的API已经运行起来了，是时候测试它，看它是否按我们的预期运行。
- en: Let's Talk about Testing
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 让我们谈谈测试
- en: In our experience with working with many developer teams, nothing can dampen
    the mood of many developers quite like a discussion on the subject of testing
    that their software does what it's supposed to do.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们与许多开发团队合作的经验，没有什么能像讨论软件是否按预期工作的测试主题一样，能够阻碍许多开发人员的情绪。
- en: For many developers, testing is the equivalent of getting a dental checkup—few
    like doing it but all of us need to do it a lot more. It's a set of bridges that
    have to be crossed (often under duress) before our precious, handcrafted, artisan-designed
    piece of software excellence is accepted into the nirvana that is production.
    Testers are seen as the other team that ensures that we've dotted our I's and
    crossed our T's, and they don't appreciate how hard we've suffered for our art.
    Basically, we write it, *throw it over the fence to test*, and they check it.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多开发人员来说，测试就像是进行牙科检查——很少有人喜欢做，但我们都知道必须做，而且得做得更多。这是一系列必须跨越的桥梁（通常是在压力下）才能让我们精心制作的、手工设计的、工艺精湛的软件作品被接受并进入生产环境。测试人员被视为另一个团队，他们确保我们已经检查了每一个细节，而他们并不欣赏我们为艺术所付出的辛苦。基本上，我们编写代码，*把它扔给测试团队*，然后他们检查它。
- en: If you're reading the preceding paragraph and mentally going *yep, yep, that's
    us, that's us, that's how we roll*, we've got really bad news for you. *You're
    basically doing it wrong*. It may have made sense when big bang software releases
    happened every 6-12 months, but in more agile organizations with faster, more
    frequent releases into production, this approach is considered cumbersome and
    archaic. There are always exceptions to this, for example, critical control systems,
    highly regulated environments, and so on, but for the majority of enterprise developers,
    this isn't the case.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在阅读前面的段落，并且在心里想“是的，是的，就是我们，就是这样做的”，那我们有个非常坏的消息告诉你。*你基本上是在做错事*。当每6-12个月就进行一次大规模的软件发布时，这种做法或许是有意义的，但在如今更为敏捷、发布频率更高、更快速的组织中，这种做法被认为是笨重且过时的。当然，也有一些例外情况，比如关键控制系统、严格监管的环境等，但对于大多数企业开发人员来说，情况并非如此。
- en: 'The quality of software is the responsibility of the delivery team, from the
    Product Owner writing user stories to the engineers writing code and the associated
    tests. As a wise delivery manager once said, "testing is an activity, not a role."
    In effective software delivery teams, testing is a continuous activity that spans
    the entire software development life cycle. There are a number of principles that
    we try to adhere to when it comes to testing:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 软件的质量是交付团队的责任，从产品负责人编写用户故事到工程师编写代码及相关测试。正如一位睿智的交付经理曾经说过，“测试是一项活动，而不是一个角色。”在高效的软件交付团队中，测试是贯穿整个软件开发生命周期的持续活动。关于测试，我们有一些原则是我们尽量遵守的：
- en: Automate as much as possible, but not so much that there's no human oversight.
    There's always value in having users interact with the application under test,
    in particular when it comes to end-to-end, acceptance, and exploratory testing.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽可能进行自动化，但不要自动化到没有人工监督的程度。让用户与待测试的应用程序进行交互总是有价值的，尤其是在进行端到端测试、验收测试和探索性测试时。
- en: Testing code is as important as production code—both need to be kept up to date
    and removed/deprecated when not adding value.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试代码与生产代码同样重要——两者都需要保持更新，并在不再添加价值时被移除或弃用。
- en: One meaningful test can be worth more than hundreds of scripted test cases.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一次有意义的测试可能比数百个脚本化的测试用例更有价值。
- en: In *Chapter 7*, *Open Technical Practices – The Midpoint*, we introduced the
    idea of the Automation Test Pyramid. For each of the different types of tests
    defined in the pyramid, there are several testing tools and frameworks we use
    across our PetBattle application.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第七章*，*开放技术实践——中点*中，我们介绍了自动化测试金字塔的概念。对于金字塔中定义的每种不同类型的测试，我们在PetBattle应用程序中使用了多种测试工具和框架。
- en: 'Generally speaking, we have chosen to use what are considered the default test
    tools for each of the application technology stacks as these are the simplest
    to use, are the best supported, have good user documentation, and are generally
    easy to adopt if people are new to them:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，我们选择使用各个应用技术栈中被认为是默认的测试工具，因为这些工具最简单易用，支持最好，用户文档齐全，而且如果有人是新手，通常也很容易上手：
- en: '![](img/B16297_Table_15.1.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_Table_15.1.png)'
- en: 'Table 15.1: Test Frameworks in use'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 表15.1：使用的测试框架
- en: Let's take a look at some of these tests in more detail.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地了解一些这些测试。
- en: Unit Testing with JUnit
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用JUnit进行单元测试
- en: 'In both the API and Tournament applications, we have different examples of
    standard unit tests. Quarkus testing[13](#footnote-137) has great support for
    the standard unit test framework JUnit.[14](#footnote-136) The anatomy of all
    unit tests using this framework is very similar. Let''s take a look at the API
    application `CatResourceTest.java`[15](#footnote-135) as an example:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在 API 和 Tournament 应用程序中，我们有不同的标准单元测试示例。Quarkus 测试[13](#footnote-137)对标准单元测试框架
    JUnit[14](#footnote-136)提供了很好的支持。使用此框架的所有单元测试的结构非常相似。让我们以 API 应用程序中的 `CatResourceTest.java`[15](#footnote-135)
    为例：
- en: '[PRE100]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[13](#footnote-137-backlink) [https://quarkus.io/guides/getting-started-testing](https://quarkus.io/guides/getting-started-testing)'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '[13](#footnote-137-backlink) [https://quarkus.io/guides/getting-started-testing](https://quarkus.io/guides/getting-started-testing)'
- en: '[14](#footnote-136-backlink) [https://junit.org/junit5/](https://junit.org/junit5/)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '[14](#footnote-136-backlink) [https://junit.org/junit5/](https://junit.org/junit5/)'
- en: '[15](#footnote-135-backlink) [https://github.com/petbattle/pet-battle-api/blob/master/src/test/java/app/battle/CatResourceTest.java](https://github.com/petbattle/pet-battle-api/blob/master/src/test/java/app/battle/CatResourceTest.java)'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[15](#footnote-135-backlink) [https://github.com/petbattle/pet-battle-api/blob/master/src/test/java/app/battle/CatResourceTest.java](https://github.com/petbattle/pet-battle-api/blob/master/src/test/java/app/battle/CatResourceTest.java)'
- en: In Java, we use annotations to make our Java class objects (POJOs) into tests.
    We use the `@QuarkusTest` annotation to bring in the JUnit framework for this
    class and we can think of the class as a test suite that contains lots of individual
    tests. Each method is a single test that is annotated with `@Test`. For this unit
    test, we don't have a database running, so we use mocks[16](#footnote-134) for
    the `Cat.class`. A mock is a fake object. It does not connect to a real database,
    and we can use it to test the behavior of the `Cat` class. In this case, we are
    asserting in our test that when we call the method `Cat.count()`, which corresponds
    to the number of likes of our pet image in PetBattle, we receive back the expected
    number (`23`). We use the `Uni` and `await()` functions because we are using the
    reactive programming model in our Quarkus application.[17](#footnote-133)
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Java 中，我们使用注解将 Java 类对象（POJO）转化为测试。我们使用 `@QuarkusTest` 注解将 JUnit 框架引入该类，并且我们可以将该类视为一个包含多个单独测试的测试套件。每个方法都是一个单独的测试，并使用
    `@Test` 注解。在这个单元测试中，我们没有运行数据库，因此我们使用 `Cat.class` 的 mocks[16](#footnote-134) 进行模拟。mock
    是一个虚拟对象，它不会连接到真实的数据库，我们可以用它来测试 `Cat` 类的行为。在此案例中，我们在测试中断言，当我们调用方法 `Cat.count()`（该方法对应于
    PetBattle 中宠物图片的点赞数量）时，我们会收到预期的数字（`23`）。我们使用 `Uni` 和 `await()` 函数，因为我们在 Quarkus
    应用程序中使用了响应式编程模型。[17](#footnote-133)
- en: We run these unit tests as part of the automated continuous deployment pipeline
    and visualize and report on the tests' success and history using our CI/CD tools,
    including Jenkins, Tekton, and a test report tool such as Allure.[18](#footnote-132)
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些单元测试作为自动化持续部署管道的一部分运行，并使用我们的 CI/CD 工具（包括 Jenkins、Tekton 和 Allure 等测试报告工具）来可视化和报告测试的成功和历史记录。[18](#footnote-132)
- en: '![](img/B16297_15_06.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_06.jpg)'
- en: 'Figure 15.6: Visualization of tests using Allure'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.6：使用 Allure 可视化测试
- en: In the next section, we'll continue with service and component testing with
    REST Assured and Jest.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将继续使用 REST Assured 和 Jest 进行服务和组件测试。
- en: Service and Component Testing with REST Assured and Jest
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 REST Assured 和 Jest 进行服务和组件测试
- en: Jest and REST Assured are **Behavior-Driven Development** (**BDD**) frameworks
    for JavaScript and Java. We covered BDD in *Chapter 7*, *Open Technical Practices
    – The Midpoint*. These frameworks make it super easy for developers to write tests
    where the syntax is obvious and easy to follow.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: Jest 和 REST Assured 是 JavaScript 和 Java 的**行为驱动开发**（**BDD**）框架。我们在*第七章*，*开放技术实践
    – 中期*中讨论了 BDD。这些框架使得开发者能够轻松编写测试，语法直观且容易跟随。
- en: '[16](#footnote-134-backlink) [https://quarkus.io/guides/mongodb-panache](https://quarkus.io/guides/mongodb-panache)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '[16](#footnote-134-backlink) [https://quarkus.io/guides/mongodb-panache](https://quarkus.io/guides/mongodb-panache)'
- en: '[17](#footnote-133-backlink) [https://quarkus.io/guides/getting-started-reactive#mutiny](https://quarkus.io/guides/getting-started-reactive#mutiny)'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[17](#footnote-133-backlink) [https://quarkus.io/guides/getting-started-reactive#mutiny](https://quarkus.io/guides/getting-started-reactive#mutiny)'
- en: '[18](#footnote-132-backlink) [https://github.com/allure-framework](https://github.com/allure-framework)'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[18](#footnote-132-backlink) [https://github.com/allure-framework](https://github.com/allure-framework)'
- en: 'We are going to cover the basics of component testing the PetBattle user interface[19](#footnote-131)
    using Jest. The user interface is made of several components. The first one you
    see when landing on the application is the home page. For the home page component,
    the test class[20](#footnote-130) is called `home.component.spec.ts`:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Jest 覆盖 PetBattle 用户界面的组件测试基础知识[19](#footnote-131)。该用户界面由多个组件组成。你在打开应用程序时看到的第一个组件是主页。对于主页组件，测试类[20](#footnote-130)被命名为
    `home.component.spec.ts`：
- en: '[PRE110]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: '[PRE116]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '[PRE117]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '[PRE118]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: '[PRE119]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: '[PRE120]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'Each test has a similar anatomy:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 每个测试有一个相似的结构：
- en: '`describe()`: The name of the test suite and test specification argument'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`describe()`: 测试套件的名称以及测试规格参数'
- en: '`beforeEach()`: Runs the function passed as an argument before running each
    test'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beforeEach()`: 在每个测试运行之前，执行作为参数传入的函数'
- en: '`it()`: Defines a single test with a required expectation and a function with
    logic and assertions'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`it()`: 定义一个单一的测试，要求有期望值，并且包含逻辑和断言的函数'
- en: '`expect()`: Creates an expectation for the test result, normally with a matching
    function such as `toEqual()`'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`expect()`: 为测试结果创建期望，通常会配合 `toEqual()` 等匹配函数使用'
- en: So in this case, the unit test will expect the `HomeComponent` to be created
    correctly when the test is run.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这个情况下，单元测试会期望 `HomeComponent` 在测试运行时被正确创建。
- en: '[19](#footnote-131-backlink) [https://angular.io/guide/testing](https://angular.io/guide/testing)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[19](#footnote-131-backlink) [https://angular.io/guide/testing](https://angular.io/guide/testing)'
- en: '[20](#footnote-130-backlink) [https://github.com/petbattle/pet-battle/blob/master/src/app/home/home.component.spec.ts](https://github.com/petbattle/pet-battle/blob/master/src/app/home/home.component.spec.ts)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '[20](#footnote-130-backlink) [https://github.com/petbattle/pet-battle/blob/master/src/app/home/home.component.spec.ts](https://github.com/petbattle/pet-battle/blob/master/src/app/home/home.component.spec.ts)'
- en: 'Similarly, within the API application, REST Assured is a testing tool that
    allows us to write tests using the familiar `Given,` `When,` `Then` syntax from
    *Chapter 7*, *Open Technical Practices – The Midpoint*. Let''s examine one of
    the service API tests in the test suite `CatResourceTest.java`[21](#footnote-129):'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，在 API 应用程序中，REST Assured 是一个测试工具，允许我们使用熟悉的 `Given,` `When,` `Then` 语法编写测试，语法来自
    *第七章*，*开放技术实践——中期*。我们来查看一下测试套件 `CatResourceTest.java`[21](#footnote-129) 中的一个服务
    API 测试：
- en: '[PRE121]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: '[PRE122]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '[PRE124]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: '[PRE126]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: '[PRE128]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '[PRE129]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: '[PRE130]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: '[PRE131]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: '[PRE132]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '[PRE133]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: '[PRE134]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: 'In this test, we are creating a `Cat` object. The `Cat` class is the data object
    in PetBattle that contains the pet''s uploaded image, along with its PetBattle
    vote count, and is stored in MongoDB. In the test, given the `Cat` object, we
    use an `HTTP POST` to the `/cats` endpoint and expect a return status code of
    (`201`), which is `CREATED`. We also test the HTTP response body is not empty.
    It should contain the ID of the newly created `Cat`:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个测试中，我们创建了一个 `Cat` 对象。`Cat` 类是 PetBattle 中的数据对象，包含了宠物的上传图片以及其 PetBattle 投票数，并存储在
    MongoDB 中。在测试中，给定一个 `Cat` 对象，我们使用 `HTTP POST` 请求 `/cats` 端点，并期望返回状态码为 (`201`)，即
    `CREATED`。我们还测试了 HTTP 响应体不为空，它应包含新创建的 `Cat` 的 ID：
- en: '[PRE135]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: '[PRE136]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: '[PRE137]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: '[PRE138]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: '[PRE139]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: '[21](#footnote-129-backlink) [https://github.com/petbattle/pet-battle-api/blob/master/src/test/java/app/battle/CatResourceTest.java](https://github.com/petbattle/pet-battle-api/blob/master/src/test/java/app/battle/CatResourceTest.java)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[21](#footnote-129-backlink) [https://github.com/petbattle/pet-battle-api/blob/master/src/test/java/app/battle/CatResourceTest.java](https://github.com/petbattle/pet-battle-api/blob/master/src/test/java/app/battle/CatResourceTest.java)'
- en: 'In this service test, we make use of the `@QuarkusTestResource` annotation
    to create and start an embedded MongoDB for testing against. So, this test is
    a bit more sophisticated than the basic unit test that was using mocks only. We
    also track the execution of these service tests using our test report tool:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个服务测试中，我们使用了 `@QuarkusTestResource` 注解来创建并启动一个嵌入式的 MongoDB 进行测试。因此，这个测试比仅使用
    mock 的基本单元测试要更复杂一些。我们还使用我们的测试报告工具来跟踪这些服务测试的执行情况：
- en: '![](img/B16297_15_07.jpg)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_07.jpg)'
- en: 'Figure 15.7: Visualization of service tests using Allure'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.7：使用 Allure 可视化服务测试
- en: Now we have seen what unit tests look like, let's move up the test pyramid to
    have a look at service-level testing.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了单元测试的样子，接下来我们将提升测试层级，看看服务级别的测试。
- en: Service Testing with Testcontainers
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Testcontainers 进行服务测试
- en: 'Integration testing is always substantially harder than unit testing as more
    components have to be either stood up or simulated/mocked. The next level of testing
    in our test pyramid is integration testing using a Java framework called **Testcontainers**.[22](#footnote-128)
    Testcontainers allows us to easily create and start components such as MongoDB,
    **KeyCloak**, and **Infinispan** and perform tests using those components. The
    following classes instantiate and manage the containers and inject them into the
    testing life cycle of the Quarkus framework:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 集成测试通常比单元测试更为复杂，因为需要启动或模拟/虚拟化更多的组件。我们测试金字塔的下一个层级是使用一个名为**Testcontainers**的Java框架进行集成测试。[22](#footnote-128)
    Testcontainers允许我们轻松地创建和启动MongoDB、**KeyCloak**和**Infinispan**等组件，并使用这些组件执行测试。以下类实例化并管理这些容器，并将其注入到Quarkus框架的测试生命周期中：
- en: '[PRE140]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: '[PRE141]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: 'Within the integration test code at `ITPetBattleAPITest.java`, we just inject
    the previously created containers and use them as resources during the test:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ITPetBattleAPITest.java`的集成测试代码中，我们仅仅是注入了之前创建的容器，并在测试期间将它们作为资源使用：
- en: '[PRE142]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: '[PRE143]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: '[PRE144]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: '[PRE145]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: '[PRE146]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: '[PRE147]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: '[PRE148]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: '[PRE149]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: '[PRE150]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: '[22](#footnote-128-backlink) [https://www.testcontainers.org/](https://www.testcontainers.org/)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[22](#footnote-128-backlink) [https://www.testcontainers.org/](https://www.testcontainers.org/)'
- en: This is a great example of how containers can be used as part of a testing phase.
    The containers are spun up, the tests are run, and the containers are removed.
    The only real prerequisite is that the Docker daemon is run on the machine running
    the tests. To run the integration tests use the command `mvn clean verify -Pintegration`.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的例子，展示了如何在测试阶段使用容器。这些容器被启动，测试执行完毕后，容器被移除。唯一的真正前提是运行测试的机器上需要运行Docker守护进程。要运行集成测试，可以使用命令`mvn
    clean verify -Pintegration`。
- en: End-to-End Testing
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 端到端测试
- en: Our application is made up of a frontend written in Angular, which makes calls
    for data to two APIs. One is for tournaments and the other is for cats. We can
    think of the interplay between these components as the system as a whole. Any
    time a change is made to either of these individual applications, it should require
    revalidating the whole system. The end-to-end automated testing is performed primarily
    in the user interface but exercises the underlying services layer.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的应用程序由一个用Angular编写的前端组成，该前端向两个API发起数据请求。一个是用于比赛的，另一个是用于猫的。我们可以将这些组件之间的相互作用看作是整个系统的一部分。每次对这些独立应用程序中的任何一个进行更改时，都应要求重新验证整个系统。端到端的自动化测试主要在用户界面中执行，但也涵盖了底层服务层。
- en: There are loads of tools to do testing from the user interface level. Some of
    the more popular ones are things like Selenium and Cypress, which are used to
    drive a web application and simulate user behavior. There are pros and cons to
    each – Selenium is just browser automation so you need to bring your own test
    frameworks, whereas Cypress is an all-in-one testing framework. Selenium Grid,
    when running on Kubernetes, allows us to test against multiple browsers in parallel
    by dynamically provisioning the browser on each test execution, meaning we don't
    have browsers waiting idly for us to use them.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多工具可以从用户界面层面进行测试。比较流行的工具包括Selenium和Cypress，它们用于驱动Web应用程序并模拟用户行为。每个工具都有优缺点——Selenium仅仅是浏览器自动化，所以你需要自己带上测试框架，而Cypress是一个一体化的测试框架。当Selenium
    Grid在Kubernetes上运行时，可以通过在每次测试执行时动态地为每个测试分配浏览器来让我们并行地在多个浏览器上进行测试，这意味着我们不需要让浏览器闲置等待使用。
- en: For our end-to-end testing, we're using Protractor from the Angular team. We
    already deployed an instance of Selenium Grid built for Kubernetes by the Zalando
    team (called Zalenium [https://opensource.zalando.com/zalenium/](https://opensource.zalando.com/zalenium/))
    when we deployed our tooling. Zalenium is pretty handy as it allows us to play
    back previous test runs and watch them live. In your cluster, if you get the route
    for Zalenium (`oc get routes -n labs-ci-cd`) and append `/grid/admin/live`, you
    can follow the tests as they execute or go to /dashboard to watch the historical
    test executions.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的端到端测试，我们使用了Angular团队的Protractor。我们在部署工具时，已经部署了由Zalando团队为Kubernetes构建的Selenium
    Grid实例（称为Zalenium [https://opensource.zalando.com/zalenium/](https://opensource.zalando.com/zalenium/)）。Zalenium非常方便，因为它允许我们回放之前的测试并实时观看它们。在你的集群中，如果你获取Zalenium的路由（`oc
    get routes -n labs-ci-cd`）并附加`/grid/admin/live`，你可以在测试执行时跟踪它们，或者访问`/dashboard`观看历史测试执行。
- en: '![](img/B16297_15_08.jpg)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_08.jpg)'
- en: 'Figure 15.8: Zalenium dashboard showing test history and video playback'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.8：Zalenium仪表板，显示测试历史和视频回放
- en: Our `system-tests` project ([https://github.com/petbattle/system-tests](https://github.com/petbattle/system-tests))
    has all of the system tests that we should execute after any change is pushed
    to the frontend or backend services. The tests are written using Cucumber-style
    BDD. In fact, we should be able to connect the BDD to the acceptance criteria
    from our PetBattle Sprint items.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`system-tests`项目（[https://github.com/petbattle/system-tests](https://github.com/petbattle/system-tests)）包含了在每次推送到前端或后端服务后需要执行的所有系统测试。测试是使用
    Cucumber 风格的 BDD 编写的。实际上，我们应该能够将 BDD 与 PetBattle Sprint 项目的接受标准连接起来。
- en: '![](img/B16297_15_09.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_09.jpg)'
- en: 'Figure 15.9: Example of BDD written as acceptance criteria on a Sprint board
    for PetBattle'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.9：在 PetBattle 的 Sprint 看板上，作为接受标准编写的 BDD 示例
- en: 'Here''s a test for a tournament feature written in the `Given,` `When,` `Then`
    syntax:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个使用 `Given,` `When,` `Then` 语法编写的比赛功能测试：
- en: '[PRE151]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '[PRE152]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE152]'
- en: '[PRE153]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE153]'
- en: '[PRE154]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE154]'
- en: '[PRE155]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE155]'
- en: '[PRE156]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE156]'
- en: The `system-test` project has its own Jenkinsfile, so it's already connected
    to Jenkins via our seed job. We won't go through the contents of this Jenkinsfile
    in detail. Suffice to say, the pipeline has two stages, as per our Big Picture,
    one to run the tests and the other to promote the app if the tests have passed.
    Explore the code for this in the accompanying Git repo [https://github.com/petbattle/system-tests](https://github.com/petbattle/system-tests).
    To extend our Jenkinsfile for `pet-battle` to trigger our system test job, we
    just need to add another stage to trigger the job. We could use the Jenkins `post{}`
    block, but we only want to trigger the system tests if we're on `master` or `main`
    and producing a release candidate.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '`system-test` 项目有自己的 Jenkinsfile，因此它已经通过我们的种子任务连接到 Jenkins。我们不会详细介绍这个 Jenkinsfile
    的内容。简单来说，管道有两个阶段，符合我们的大致图景，一个用于运行测试，另一个用于在测试通过时提升应用程序。在随附的 Git 仓库中探索此代码：[https://github.com/petbattle/system-tests](https://github.com/petbattle/system-tests)。为了扩展我们
    `pet-battle` 的 Jenkinsfile 以触发我们的系统测试任务，我们只需要添加另一个阶段来触发该任务。我们可以使用 Jenkins 的 `post{}`
    块，但我们只希望在 `master` 或 `main` 上并生成候选发布版本时触发系统测试。'
- en: '![](img/B16297_15_10.jpg)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_10.jpg)'
- en: 'Figure 15.10: The trigger for connecting our pipelines in Jenkins'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.10：在 Jenkins 中触发连接我们管道的触发器
- en: 'There are a few parameters that are passed between the jobs:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些参数会在任务之间传递：
- en: '`APP_NAME`: Passed to the job so if the tests are successful, the promote stage
    knows what app to deploy.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`APP_NAME`：传递给任务，因此如果测试成功，提升阶段就知道要部署哪个应用。'
- en: '`CHART_VERSION & VERSION`: Any update to the chart or app needs to be patched
    in Git so this information is passed by the job that triggers the system tests.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CHART_VERSION & VERSION`：对图表或应用的任何更新都需要在 Git 中修补，因此这些信息会由触发系统测试的任务传递。'
- en: 'We can run the system tests job manually by supplying this information to the
    job, but each service with a Jenkinsfile should be able to pass these to the system
    tests. This job can also be triggered from Tekton too if we were to mix the approach
    to the pipelines. With the two pipelines wired together, we can trigger one if
    the webhook is set up by running the following command:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过向任务提供这些信息手动运行系统测试任务，但每个具有 Jenkinsfile 的服务应该能够将这些信息传递给系统测试。此任务也可以从 Tekton
    触发，如果我们混合使用管道方法。将两个管道连接起来后，只需在设置好 webhook 后运行以下命令即可触发其中一个：
- en: '[PRE157]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE157]'
- en: 'If we now check in the Jenkins Blue Ocean Web UI, we should see the following:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在检查 Jenkins Blue Ocean Web UI，我们应该看到以下内容：
- en: '![](img/B16297_15_11.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_11.jpg)'
- en: 'Figure 15.11: The system tests pipeline'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.11：系统测试管道
- en: On Jenkins, we should see the system tests pipeline running and promoting if
    successful. The Cucumber reports are also included for the job.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Jenkins 中，我们应该看到系统测试管道在运行并在成功时进行提升。该任务还包括 Cucumber 报告。
- en: '![](img/B16297_15_12.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_12.jpg)'
- en: 'Figure 15.12: The Cucumber report in Jenkins'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.12：Jenkins 中的 Cucumber 报告
- en: These provide insight into which cases were executed for what browser and report
    any failures that may have occurred. Let's switch gear a little now and take a
    look at non-functional testing.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 这些报告提供了有关为哪个浏览器执行了哪些用例的见解，并报告任何可能发生的失败。现在让我们稍作调整，看看非功能性测试。
- en: Pipelines and Quality Gates (Non-functionals)
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道与质量门（非功能性测试）
- en: Quality is often just focused on whether tests pass or not. However there's
    also the concept of code quality. The code may perform as expected but the manner
    in which it's been written could be so poor that it could be a future source of
    problems when changes are added. So now it's time to check the quality of our
    code.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 质量通常只是关注测试是否通过。然而，也有代码质量的概念。代码可能按预期执行，但编写方式可能非常糟糕，以至于在添加新更改时，未来可能成为问题的源头。所以现在是时候检查我们代码的质量了。
- en: SonarQube
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SonarQube
- en: 'As part of the Ubiquitous Journey, we have automated the Helm chart deployment
    of SonarQube, which we are using to test and measure code quality. In `values-tooling.yaml`,
    the SonarQube stanza references the Helm chart and any extra plugins that are
    required. Many of the common language profile plugins are already deployed with
    the base version of SonarQube, for example, Java, JavaScript, and Typescript.
    We add in extra plugin entries for Checkstyle, our Java formatting check tool,
    and a dependency checker for detecting publicly disclosed vulnerabilities contained
    within project dependencies:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 作为普适之旅的一部分，我们已经自动化了 SonarQube 的 Helm 图表部署，利用它来测试和衡量代码质量。在 `values-tooling.yaml`
    文件中，SonarQube 语句引用了 Helm 图表以及所需的额外插件。许多常见的语言配置插件已经随着 SonarQube 基础版本一同部署，例如 Java、JavaScript
    和 Typescript。我们为 Checkstyle（我们的 Java 格式化检查工具）和一个用于检测项目依赖项中公开披露的漏洞的依赖检查器，添加了额外的插件条目：
- en: '[PRE158]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE158]'
- en: '[PRE159]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE159]'
- en: '[PRE160]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE160]'
- en: '[PRE161]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE161]'
- en: '[PRE162]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE162]'
- en: '[PRE163]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE163]'
- en: '[PRE164]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE164]'
- en: '[PRE165]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE165]'
- en: '[PRE166]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE166]'
- en: '[PRE167]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE167]'
- en: '[PRE168]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE168]'
- en: '[PRE169]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE169]'
- en: '[PRE170]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE170]'
- en: '[PRE171]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE171]'
- en: 'With the basic SonarQube pod deployed, there is one more piece of configuration
    we need to automate – the creation of a code quality gate. The quality gate is
    the hurdle our code must pass before it is deemed ready to release. This boils
    down to a set of conditions defined in code that specify particular measurements,
    for example:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署了基本的 SonarQube Pod 后，我们需要自动化的最后一部分配置——创建代码质量关卡。质量关卡是代码必须通过的门槛，才能被认为准备好发布。这归结为在代码中定义的一组条件，指定了特定的测量标准，例如：
- en: Do we have new blocking issues with the code that was just added?
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们添加的代码是否有新的阻塞问题？
- en: Is the code test coverage higher than a given percentage?
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码的测试覆盖率是否高于指定的百分比？
- en: Are there any identifiable code vulnerabilities?
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否存在可识别的代码漏洞？
- en: SonarQube lets us define these quality gates[23](#footnote-127) using its REST
    API. For PetBattle, we use a Kubernetes job to define our quality gate `AppDefault`
    and package it as a Helm chart for deployment. The chart is deployed using Ubiquitous
    Journey and ArgoCD.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: SonarQube 让我们通过其 REST API 定义这些质量关卡[23](#footnote-127)。对于 PetBattle，我们使用 Kubernetes
    作业来定义我们的质量关卡 `AppDefault`，并将其打包为 Helm 图表进行部署。该图表通过普适之旅和 ArgoCD 部署。
- en: '![](img/B16297_15_13.jpg)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_13.jpg)'
- en: 'Figure 15.13: A SonarQube quality gate definition'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.13：SonarQube 质量关卡定义
- en: The SonarQube server can be queried via a REST API, whether a recent report
    against a particular project has passed or failed this quality gate. We have configured
    a Tekton step and task in our pipelines to automatically check this each time
    we run a build.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: SonarQube 服务器可以通过 REST API 查询，查看特定项目的最近报告是否通过了质量关卡。我们在管道中配置了一个 Tekton 步骤和任务，以便每次运行构建时自动检查这一点。
- en: 'Our PetBattle Java applications are configured using Maven to talk to our SonarQube
    server pod and generate the SonarQube formatted reports during each build, bake,
    and deploy. In the reusable `maven-pipeline.yaml`, we call the following target
    to generate these reports:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 PetBattle Java 应用程序使用 Maven 配置，连接到我们的 SonarQube 服务器 Pod，并在每次构建、打包和部署时生成
    SonarQube 格式的报告。在可重用的 `maven-pipeline.yaml` 文件中，我们调用以下目标来生成这些报告：
- en: '[PRE172]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE172]'
- en: '[PRE173]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE173]'
- en: '[PRE174]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE174]'
- en: '[PRE175]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE175]'
- en: '[PRE176]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE176]'
- en: '[PRE177]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE177]'
- en: '[PRE178]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE178]'
- en: '[PRE179]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE179]'
- en: '[PRE180]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE180]'
- en: '[PRE181]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE181]'
- en: '[PRE182]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE182]'
- en: '[PRE183]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE183]'
- en: '[PRE184]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE184]'
- en: '[PRE185]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE185]'
- en: '[PRE186]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE186]'
- en: '[PRE187]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE187]'
- en: '[PRE188]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE188]'
- en: '[PRE189]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE189]'
- en: '[PRE190]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE190]'
- en: '[PRE191]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE191]'
- en: '[PRE192]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE192]'
- en: '[PRE193]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE193]'
- en: '[PRE194]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE194]'
- en: '[PRE195]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE195]'
- en: '[PRE196]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE196]'
- en: '[PRE197]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE197]'
- en: '[PRE198]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE198]'
- en: '[PRE199]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE199]'
- en: '[PRE200]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE200]'
- en: '[23](#footnote-127-backlink) [https://docs.sonarqube.org/latest/user-guide/quality-gates/](https://docs.sonarqube.org/latest/user-guide/quality-gates/)'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '[23](#footnote-127-backlink) [https://docs.sonarqube.org/latest/user-guide/quality-gates/](https://docs.sonarqube.org/latest/user-guide/quality-gates/)'
- en: Similarly, for the PetBattle UI using `nodejs`, we can configure the client
    to call SonarQube as part of its Tekton pipeline. Once these steps have successfully
    run, we can explore the SonarQube Web UI and drill down into any areas to find
    out more information.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，对于使用 `nodejs` 的 PetBattle UI，我们可以配置客户端在其 Tekton 管道中调用 SonarQube。一旦这些步骤成功执行，我们可以探索
    SonarQube Web UI，并深入了解任何区域以获取更多信息。
- en: '![](img/B16297_15_14.jpg)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16297_15_14.jpg)'
- en: 'Figure 15.14: SonarQube project view'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.14：SonarQube 项目视图
- en: In a bit of recent development for A/B testing support in the PetBattle UI,
    some code bugs seemed to have crept in! Developers can drill down and see exactly
    what the issues are and remediate them in the code base. SonarQube ranks issues
    based on severity defined in the Language Quality Profile, which can be altered
    to suit your development code quality needs.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_15.jpg)'
  id: totrans-366
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.15: SonarQube drilling into some bug details'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: SonarQube also reports on the last run's code testing coverage. On the code
    base side, you generate coverage reports using the `LCOV`[24](#footnote-126) format,
    so in Java, this is done by `JaCoCo`[25](#footnote-125) and in JavaScript, the
    coverage reports are produced by the `mocha`/`jasmine` modules. These reports
    are uploaded into SonarQube and give the team visibility into which parts of their
    code base need more testing. A nice way to view this information is using the
    heatmap, which visualizes the bits of code that have near 100% coverage (green),
    down to areas that are not covered at all 0% (red). The statistics are also reported
    – the percentage coverage overall, the number of lines covered, and so on.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_16.jpg)'
  id: totrans-369
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.16: SonarQube test coverage heatmap for PetBattle'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: '[24](#footnote-126-backlink) [https://github.com/linux-test-project/lcov](https://github.com/linux-test-project/lcov)'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: '[25](#footnote-125-backlink) [https://www.eclemma.org/jacoco/](https://www.eclemma.org/jacoco/)'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: The last plugin we use for our Java applications is the OWASP Dependency-Check
    plugin.[26](#footnote-124) We move security checking "left" in our pipeline. In
    other words, we want to discover early in the development process when security
    vulnerabilities or CVEs are creeping into our applications' dependencies. By identifying
    which dependencies are vulnerable to a CVE early as part of the build cycle, developers
    are in a much better position to update them, rather than finding there are issues
    once our applications are deployed.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_17.jpg)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.17: Dependency-Check plugin report'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: The plugin sources data from multiple open source resources including the US
    National Vulnerability Database[27](#footnote-123) and Sonatype OSS Index.[28](#footnote-122)
    In conjunction with security team members, developers can verify known vulnerabilities
    and suppress any false positives using a configuration file. The report is very
    detailed and includes links to these sites to assist CVE identification and reporting.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: '[26](#footnote-124-backlink) [https://github.com/dependency-check/dependency-check-sonar-plugin](https://github.com/dependency-check/dependency-check-sonar-plugin)'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: '[27](#footnote-123-backlink) [https://nvd.nist.gov/](https://nvd.nist.gov/)'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: '[28](#footnote-122-backlink) [https://ossindex.sonatype.org/](https://ossindex.sonatype.org/)'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: Perf Testing (Non-Functional)
  id: totrans-380
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of our favorite command-line tools for getting fast feedback on the performance
    of REST APIs is a tool called **hey**.[29](#footnote-121) There are a lot of similar
    tools available. Apache Bench[30](#footnote-120) is probably the most venerable.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_18.jpg)'
  id: totrans-382
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.18: A simple hey run'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: '[29](#footnote-121-backlink) [https://github.com/rakyll/hey](https://github.com/rakyll/hey)'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: '[30](#footnote-120-backlink) [https://httpd.apache.org/docs/2.4/programs/ab.html](https://httpd.apache.org/docs/2.4/programs/ab.html)'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: 'We like `hey` on the command line to call the PetBattle API and list all of
    the pets. We pass in some parameters that represent:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: '`-c`: Number of workers to run concurrently'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-n`: Number of requests to run'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-t`: Timeout for each request in seconds'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can see the summary statistics reported, and this is the bit we love – a
    histogram of latency distribution, HTTP status code distribution, as well as DNS
    timing details. This is super rich information. Histograms are graphs that display
    the distribution of the continuous response latency data. A histogram reveals
    properties about the response times that the summary statistics cannot. In statistics,
    summary data is used to describe the complete dataset – minimum, maximum, mean,
    and average, for example. **Hey** gives us these summary statistics at the top
    of the output.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: The graph brings the data to life as we can start to understand the distribution
    of the latency response over the time the test ran. Over the 4.2 seconds it took
    to send the 100 requests, we can see that most of the data is clustered around
    the 0.4-second mark, which is nearly 50% of all traffic. Often, in service performance
    design, we are interested in what the 95% or 99% percentile number is. That is,
    for all of the sample data, what the response latency is for 95% (or 99%) of the
    traffic. In this test run, it is measured at 0.57 seconds – in other words, 95%
    of the data was at or below this mark.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: The shape of the histogram is also important. Where are the response latencies
    grouped? We can easily see if the response times are distributed evenly around
    the mean (Gaussian) or if they have a longer or shorter tail. This can help us
    characterize the performance of the service under various loads. There are many
    types of load profiles you could use, for example, burst loads where we throw
    a lot of instantaneous traffic at our API, compared to more long-lived soak tests
    under a lower load. You might even have known loads from similar applications
    in production already. A great open source tool for designing these types of test
    loads, which can model threading and ramping really well, is Apache JMeter[31](#footnote-119)
    and we highly recommend it as a tool to have in your toolbox. To keep things simple,
    we won't cover that tool here.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: '[31](#footnote-119-backlink) [https://jmeter.apache.org/](https://jmeter.apache.org/)'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: 'The two diagrams shown in *Figure 15.19* display simple load tests. The one
    on the left is a burst type of test – 300 consecutive users calling 900 times
    to our PetBattle API. We can see the 95% is 15.6 seconds – this is quite a long
    time for users to wait for their cats! The one on the right is a soak test – 50
    consecutive users calling 10,000 times to our PetBattle API. A very different
    set of statistics: a test duration of 461 seconds, and the 95% is 2.8 sec—much
    better from an end user''s perspective.'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: At this point, it is important to think about what the test is actually doing
    and how it relates to the PetBattle application suite in general. If we think
    about it, the test may not be totally indicative of the current user interface
    behavior. For example, we do not perform a call to return all of the images in
    our MongoDB at once but rather page the results. And there are of course other
    API endpoints to test, for example, the `topcats` API, which returns the top three
    most popular pets and is called every time you visit the home page. We are returning
    the test dataset we have loaded into PetBattle, that is, around 15 pet images,
    so it is not a massive amount of data. It's important to always step back and
    understand this wider context when we run performance tests so we don't end up
    testing the wrong thing!
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_19.jpg)'
  id: totrans-396
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.19: Burst and soak tests against the PetBattle API'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, this is good data to ponder. A good result is that both the soak
    and burst tests only returned HTTP 200 response statuses – there were no error
    responses from the API. That gives us confidence that we have not broken anything
    or reached any internal system limits yet. We can also examine the details to
    make sure DNS resolution is not causing issues from the client-calling perspective.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are familiar with the client or calling side of performance testing,
    let''s switch to the PetBattle API application running on the server side. If
    we browse to the Developer view and select the `pet-battle-api` pod in the `labs-test`
    namespace, we can see some important server-side information:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: The PetBattle API is autoscaled to two pods.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring metrics for the pods (check the appendix if you haven't enabled this
    for CRC).
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a developer, we have configured the PetBattle API application to use the
    **Horizontal Pod Autoscaler** (**HPA**). This specifies how the OpenShift Container
    Platform can automatically increase or decrease the scale of a replication controller
    or deployment configuration, the number of running pods, based on the metrics
    collected from the pods that belong to our application.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_20.jpg)'
  id: totrans-403
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.20: PetBattle API pod in the labs-test namespace'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: 'In our PetBattle API Helm chart, we specified the HPA with configurable values
    for minimum pods, maximum pods, as well as the average CPU and memory targets.
    Using hey, we can now test out various scenarios to help us tune the PetBattle
    API application under load:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE201]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE201]'
- en: '[PRE202]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE202]'
- en: '[PRE203]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE203]'
- en: '[PRE204]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE204]'
- en: '[PRE205]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE205]'
- en: '[PRE206]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE206]'
- en: '[PRE207]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE207]'
- en: '[PRE208]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE208]'
- en: '[PRE209]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE209]'
- en: '[PRE210]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE210]'
- en: '[PRE211]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE211]'
- en: '[PRE212]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE212]'
- en: '[PRE213]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE213]'
- en: '[PRE214]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE214]'
- en: '[PRE215]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE215]'
- en: '[PRE216]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE216]'
- en: '[PRE217]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE217]'
- en: '[PRE218]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE218]'
- en: '[PRE219]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE219]'
- en: '[PRE220]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE220]'
- en: '[PRE221]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE221]'
- en: '[PRE222]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE222]'
- en: '[PRE223]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE223]'
- en: '[PRE224]'
  id: totrans-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE224]'
- en: '[PRE225]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE225]'
- en: '[PRE226]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE226]'
- en: '[PRE227]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE227]'
- en: '[PRE228]'
  id: totrans-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE228]'
- en: '[PRE229]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE229]'
- en: '[PRE230]'
  id: totrans-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE230]'
- en: '[PRE231]'
  id: totrans-436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE231]'
- en: We initially took a rough guess at these settings in our HPA, for example, `min
    replicas = 2`, `max replicas =6`, `CPU = 200m`, `mem = 300Mi`, and set the resource
    limits and requests in our Deployment appropriately. We always have a minimum
    of two pods, for high availability reasons. The HPA is configured to scale based
    on the average memory and CPU loads. We don't yet understand whether the application
    is memory- or CPU-intensive, so choose to scale based on both these measurements.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_21.jpg)'
  id: totrans-438
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.21: PetBattle API HPA in action, scaling pods under load'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
- en: We use hey to start a burst workload, 400 concurrent requests, and watch the
    behavior of the HPA as it starts more pods to keep to the specified memory and
    CPU averages. Once the test concludes, the HPA scales our workload back down to
    the minimum as the application recovers resources, in this case through Java garbage
    collection. OpenShift supports custom metrics for the HPA as well as other types
    of pod scalers, for example, the Vertical Pod Autoscaler.[32](#footnote-118)
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: To conclude this section, we want to point out one more Kubernetes object that
    the developer needs in their toolbelt – the **Pod Disruption Budget** (**PDB**).
    Again, using a Helm chart template for the PDB, we can limit the number of concurrent
    disruptions that the PetBattle API application experiences. By setting up a PDB,
    we can allow for higher availability while permitting the cluster administrator
    to manage the life cycle of the cluster nodes.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: '[32](#footnote-118-backlink) [https://docs.openshift.com/container-platform/4.7/nodes/pods/nodes-pods-using.html](https://docs.openshift.com/container-platform/4.7/nodes/pods/nodes-pods-using.html)'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: 'If the cluster is being updated and nodes are being restarted, we want a minimum
    of one `pet-battle-api` pod available at all times:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE232]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE232]'
- en: '[PRE233]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE233]'
- en: '[PRE234]'
  id: totrans-446
  prefs: []
  type: TYPE_PRE
  zh: '[PRE234]'
- en: This ensures a high level of business service for our PetBattle API. We can
    see `ALLOWED_DISRUPTIONS` is set to 1 – this is because, at the time, the HPA
    had scaled the number of available replicas to 3 and this will change as the number
    of available pods changes.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: One of the great things about performance testing applications on OpenShift
    is that all of the tools are at a developer's fingertips to be able to configure,
    test, measure, and tune their applications to achieve high availability and performance
    when under load. Each application service is independently scalable, tunable,
    and deployable, which makes for a faster and targeted feedback loop when dealing
    with scale and performance issues.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we are going to take a look at what makes a good OpenShift
    Kubernetes citizen, automating Kubernetes resource validation as part of our pipeline.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: Resource Validation
  id: totrans-450
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One aspect of testing that doesn't yet get much thought is the quality of the
    Kubernetes resources being deployed on the cluster. For applications to be considered
    *good citizens* on Kubernetes, there are a number of deployment best practices
    to be followed—including health checks, resource limits, labels, and so on—and
    we will go through a number of these in in *Chapter 16, Own It*. However, we need
    to validate the resource definitions being applied to the cluster to ensure a
    high level of compliance to not only industry recommendations but also any other
    resource recommendations that we see fit to add. This is where **Open Policy Agent**
    (**OPA**)[33](#footnote-117) and associated tools can come into play. This enables
    us to validate resource definitions during a CI pipeline and also when applying
    resources to a cluster. OPA by itself is a policy validator and the policies are
    written using a language called Rego. Additional OPA tools such as Conftest[34](#footnote-116)
    and Gatekeeper[35](#footnote-115) add a lot of value and governance from a usability
    and deployment perspective. OPA is also embeddable into other third-party tools
    such as KubeLinter.[36](#footnote-114)
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: '[33](#footnote-117-backlink) [https://www.openpolicyagent.org/](https://www.openpolicyagent.org/)'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: '[34](#footnote-116-backlink) [https://github.com/open-policy-agent/conftest](https://github.com/open-policy-agent/conftest)'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: '[35](#footnote-115-backlink) [https://github.com/open-policy-agent/gatekeeper](https://github.com/open-policy-agent/gatekeeper)'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: '[36](#footnote-114-backlink) [https://github.com/stackrox/kube-linter](https://github.com/stackrox/kube-linter)'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: We haven't used OPA's server-side validation component, Gatekeeper,[37](#footnote-113)
    as part of PetBattle but there are example Rego policies in the Red Hat Community
    of Practice GitHub repo[38](#footnote-112) that are definitely worth exploring.
    If this is something of interest to you, definitely check out the blog on OpenShift.com
    that details setting up all of these components.[39](#footnote-111)
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: However, to show how easy it is to use client-side resource validation and why
    you should include at least some resource validation in a pipeline, a simple Rego
    example has been created. Rego policies are easy enough to write and the Rego
    playground[40](#footnote-110) is a great place to write and verify policies, so
    check it out.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: Let's get into an example. In our Non-Functional Requirements Map, we said we
    wanted to be consistent with our labeling. It makes sense that we should adopt
    the Kubernetes best practice that suggests the `app.kubernetes.io/instance` label
    should be on all resources, so let's see how we can write a test to this effect
    and add it to our pipeline in Jenkins.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
- en: 'The makeup of a policy that denies the creation of a resource is simple enough.
    A message is formed and passed back to the interpreter if all of the statements
    are true in the rule. For example, we have written a policy that checks that all
    resources conform to Kubernetes best practice for naming conventions. The policy
    here is checking whether `app.kubernetes.io/instance` exists on the resource supplied
    to it (`input`). If each statement is true, then a message is returned as the
    error, guiding someone to fix the issue:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE235]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE235]'
- en: '[PRE236]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE236]'
- en: '[PRE237]'
  id: totrans-462
  prefs: []
  type: TYPE_PRE
  zh: '[PRE237]'
- en: '[PRE238]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE238]'
- en: '[PRE239]'
  id: totrans-464
  prefs: []
  type: TYPE_PRE
  zh: '[PRE239]'
- en: '[PRE240]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE240]'
- en: '[37](#footnote-113-backlink) [https://github.com/open-policy-agent/gatekeeper](https://github.com/open-policy-agent/gatekeeper)'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: '[38](#footnote-112-backlink) [https://github.com/redhat-cop/rego-policies](https://github.com/redhat-cop/rego-policies)'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: '[39](#footnote-111-backlink) [https://www.openshift.com/blog/automate-your-security-practices-and-policies-on-openshift-with-open-policy-agent](https://www.openshift.com/blog/automate-your-security-practices-and-policies-on-openshift-with-open-policy-agent)'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: '[40](#footnote-110-backlink) [https://play.openpolicyagent.org/](https://play.openpolicyagent.org/)'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: 'We can combine this rule with Conftest and a Helm template to create a way
    to statically validate our resources. In the PetBattle frontend code, there is
    a policy folder that has a few more policies to check whether all the standard
    Kubernetes labels[41](#footnote-109) are set on our generated resources after
    we run the `helm template` command. By running a few commands, we can verify these
    are in place. First, we template our chart to produce the Kubernetes resources
    we will apply in deploying our software, and secondly, we tell Conftest to check
    each file generated against the rule:'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE241]'
  id: totrans-471
  prefs: []
  type: TYPE_PRE
  zh: '[PRE241]'
- en: '[PRE242]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE242]'
- en: '[PRE243]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE243]'
- en: '[PRE244]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE244]'
- en: '[PRE245]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE245]'
- en: '[PRE246]'
  id: totrans-476
  prefs: []
  type: TYPE_PRE
  zh: '[PRE246]'
- en: '[PRE247]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE247]'
- en: '[PRE248]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE248]'
- en: '[PRE249]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE249]'
- en: '[PRE250]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE250]'
- en: When executing the rules from the command line, we get a good insight into what's
    missing from our chart. Of course, we could just assume that we'd always make
    our charts adhere to the best practices, but the `jenkins-agent-helm` has also
    got the Conftest binary so we can execute the preceding statements in our Jenkins
    pipeline too. This example might seem simple but, hopefully, it gives you some
    idea of the things that can be automated and tested that might seem less obvious.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: '[41](#footnote-109-backlink) [https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/#labels](https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/#labels)'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: Image Scanning
  id: totrans-483
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Red Hat provides the Quay Container Security Operator in OpenShift to bring
    Quay and Clair image scanning and vulnerability information into our OpenShift
    cluster. Any container image that is hosted on [Quay.io](http://Quay.io) is scanned
    by Clair.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_22.jpg)'
  id: totrans-485
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.22: Quay Container Security Operator'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
- en: Any image vulnerability data is exposed back in the OpenShift Web UI so that
    users and administrators can easily view which images are considered vulnerable
    and which namespace they are deployed to.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_23.jpg)'
  id: totrans-488
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.23: Vulnerable container images'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: With this operator deployed, the OpenShift overview status displays image vulnerability
    data, which an operator can drill into to find out the status of container images
    running on the platform. For PetBattle, we don't have any enforcement for image
    vulnerabilities discovered in our cluster. If we wanted to move the security scanner
    "left" in our deployment pipeline, there are some great open source scanning tools
    available on the OpenSCAP website.[42](#footnote-108)
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: Other Non-functional Testing
  id: totrans-491
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are lots of other types of testing we can do to validate our application.
    In this section are some of the things we feel are important to include in a pipeline,
    but the reality is there is much more than just this list and books could be written
    on this topic in and of itself!
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: Linting
  id: totrans-493
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A linter is a static code analysis tool that can check a code base for common
    pitfalls in design or stylistic errors. This does not check the compiled application,
    but the structure of the application. This is super important for languages that
    are not compiled, such as JavaScript. Browsers can interpret JavaScript in different
    ways so consistency is super critical.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: If you think about a large enterprise application, there could be hundreds of
    developers working on the one code base. These developers could even be globally
    distributed with different teams looking after different parts of the application's
    life cycle. Having consistency in the approach to writing the software can dramatically
    improve maintenance costs. JavaScript is very flexible in how you can write it,
    whether this is from a functional programming standpoint or object-oriented, so
    it is important to get this consistency right.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: The PetBattle frontend uses TSLint/ESLint[43](#footnote-107) to check the style
    of the code adheres to a standard set of rules. These rules can be manipulated
    by the team, but the rules are checked into Git so if someone was to disable them
    or manipulate them, it would be noticed. Our Jenkins pipeline is configured to
    automatically check the code base using the `npm lint` command and our build will
    fail if a developer does not adhere to the standard.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
- en: '[42](#footnote-108-backlink) [https://www.open-scap.org](https://www.open-scap.org)'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: '[43](#footnote-107-backlink) [https://eslint.org/](https://eslint.org/)'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_24.jpg)'
  id: totrans-499
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.24: Linting PetBattle''s frontend locally scans both the JavaScript
    and HTML'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: For Java Quarkus apps, Checkstyle[44](#footnote-106) is used to analyze the
    code base.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: For Kubernetes resources, the aforementioned Open Policy Agent can assist, and
    Helm also has the `helm lint`[45](#footnote-105) command to validate your charts.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: Code Coverage
  id: totrans-503
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So, you've written a load of tests and you think things are going great – but
    how do you know your tests are any good and covering all parts of the code base?
    Allow me to introduce code coverage metrics! A code coverage reporter is a piece
    of software that runs alongside your unit test suites to see what lines of code
    are executed by the tests and how many times. Coverage reports can also highlight
    when if/else control flows within an application are not being tested. This insight
    can provide valuable feedback as to areas of a system that remain untested and
    ultimately reduce the number of bugs.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: '[44](#footnote-106-backlink) [https://checkstyle.sourceforge.io/](https://checkstyle.sourceforge.io/)'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: '[45](#footnote-105-backlink) [https://helm.sh/docs/helm/helm_lint/](https://helm.sh/docs/helm/helm_lint/)'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
- en: Our PetBattle frontend is configured to run a coverage report when our Jest
    tests execute. Jest makes generating the report very simple as it has a flag that
    can be passed to the test runner to collect the coverage for us. The coverage
    report is run on every execution of the build and so should be reported through
    Jenkins.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_25.jpg)'
  id: totrans-508
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.25: Code coverage report from the frontend unit tests locally'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
- en: When executing our tests in the Jenkins pipeline, we have configured Jest to
    produce an HTML report that can be reported by Jenkins on the jobs page. For any
    build execution, the report is added to the jobs home page. The report will allow
    us to discover what lines are being missed by our tests. Being able to drill into
    a report like this can give a good insight into where our testing is lacking.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_26.jpg)'
  id: totrans-511
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.26: Code coverage report in Jenkins gives us detailed insight'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
- en: So, what should I do with these results? Historically, we have worked where
    coverage is low. It can serve as a great talking point to bring up in a Retrospective.
    Printing out the reports and discussing them as a team is a great way to assess
    why the team is struggling to write enough tests. Sometimes teams are drowning
    by being overwhelmed with pressure to churn out features and so testing can slip
    to the wayside. Having a coverage reporter in your build can help keep a team
    honest. You could even set thresholds so that if testing coverage falls below
    a certain percentage (some teams aim for 80% and above), the build will fail,
    thus blocking the pipeline until the quality is increased.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
- en: Untested Software Watermark
  id: totrans-514
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](img/Author_26.jpg)'
  id: totrans-515
  prefs: []
  type: TYPE_IMG
- en: I worked on a project a long time ago that was poorly structured. I was a member
    of the DevOps team, which I know now is an antipattern in most implementations!
    This project had many issues, the team had planned three Sprints in advance but
    hadn’t allocated enough time for testing. It was always the thing that got squeezed.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
- en: Through Retrospectives with the teams, we discovered that there was simply not
    enough time for tests. This may sound hard to hear, but the root cause for this
    was not laziness by the team or a lack of skills; it really was time. The project
    was running in 8-week blocks that were pre-planned from the beginning with a fixed
    output at the end. The team thought they were doing Scrum, but in actual fact,
    they had milestones of functionality to accomplish each sprint and there was no
    feedback loop. Of course, none of the Scrum team members were involved in the
    sizing or planning ceremonies either. This meant the teams were constantly under
    pressure to deliver.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Draft.jpg)'
  id: totrans-518
  prefs: []
  type: TYPE_IMG
- en: Through a Retrospective, we decided to try to radiate some of this pressure
    the teams were under as we were not happy that quality was being sacrificed for
    some arbitrary deadlines. Knowing that failing the pipeline simply would not work
    for these customers, we had to get creative in showing the software quality. We
    decided to inject a watermark into any application that had low test coverage.
    This watermark resembled a DRAFT logo you would find on any document, but ours
    was a little different.
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
- en: A large banner reading UNTESTED SOFTWARE was placed across the applications
    that failed the tests. This watermark did not affect the user behavior of the
    app; it was just an overlay but it was an amazing way to get people talking. Seeing
    a giant banner saying UNTESTED is a surefire way to have people question why things
    have gotten this way.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at some other ways we can visualize risks during continuous delivery.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
- en: The OWASP Zed Attack Proxy (ZAP)
  id: totrans-522
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Security scanning is always a hot topic. From image scanning, which we discussed
    earlier, to dependency checking for our application that happens in our pipelines,
    there are limitless numbers of things to automate from a security perspective.
    Let's take another example of something that can be useful to include in a pipeline
    – the OWASP Zed Attack Proxy.[46](#footnote-104)
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
- en: 'From their website: *The OWASP Zed Attack Proxy (ZAP) is one of the world''s
    most popular free security tools which lets you automatically find security vulnerabilities
    in your applications. This allows the developers to automate* *penetration testing
    and security regression testing of the application in the CI/CD pipeline.*'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
- en: Adding the ZAP security scanning tool to our pipelines is simple. Just add the
    following `stage` and add the URL you want to test. The source code for this image
    is available, like our other Jenkins images from the Red Hat CoP.[47](#footnote-103)
    The ZAP scan in Jenkins will produce a report showing some potential vulnerabilities
    in our application.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE251]'
  id: totrans-526
  prefs: []
  type: TYPE_PRE
  zh: '[PRE251]'
- en: '[PRE252]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE252]'
- en: '[PRE253]'
  id: totrans-528
  prefs: []
  type: TYPE_PRE
  zh: '[PRE253]'
- en: '[PRE254]'
  id: totrans-529
  prefs: []
  type: TYPE_PRE
  zh: '[PRE254]'
- en: '[PRE255]'
  id: totrans-530
  prefs: []
  type: TYPE_PRE
  zh: '[PRE255]'
- en: '[PRE256]'
  id: totrans-531
  prefs: []
  type: TYPE_PRE
  zh: '[PRE256]'
- en: '[PRE257]'
  id: totrans-532
  prefs: []
  type: TYPE_PRE
  zh: '[PRE257]'
- en: '[PRE258]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE258]'
- en: '[PRE259]'
  id: totrans-534
  prefs: []
  type: TYPE_PRE
  zh: '[PRE259]'
- en: '[PRE260]'
  id: totrans-535
  prefs: []
  type: TYPE_PRE
  zh: '[PRE260]'
- en: '[PRE261]'
  id: totrans-536
  prefs: []
  type: TYPE_PRE
  zh: '[PRE261]'
- en: '[PRE262]'
  id: totrans-537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE262]'
- en: '[PRE263]'
  id: totrans-538
  prefs: []
  type: TYPE_PRE
  zh: '[PRE263]'
- en: '[PRE264]'
  id: totrans-539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE264]'
- en: '[PRE265]'
  id: totrans-540
  prefs: []
  type: TYPE_PRE
  zh: '[PRE265]'
- en: '[PRE266]'
  id: totrans-541
  prefs: []
  type: TYPE_PRE
  zh: '[PRE266]'
- en: '[PRE267]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE267]'
- en: '[PRE268]'
  id: totrans-543
  prefs: []
  type: TYPE_PRE
  zh: '[PRE268]'
- en: '[PRE269]'
  id: totrans-544
  prefs: []
  type: TYPE_PRE
  zh: '[PRE269]'
- en: '[PRE270]'
  id: totrans-545
  prefs: []
  type: TYPE_PRE
  zh: '[PRE270]'
- en: '[PRE271]'
  id: totrans-546
  prefs: []
  type: TYPE_PRE
  zh: '[PRE271]'
- en: '[PRE272]'
  id: totrans-547
  prefs: []
  type: TYPE_PRE
  zh: '[PRE272]'
- en: '[46](#footnote-104-backlink) [https://www.zaproxy.org/](https://www.zaproxy.org/)'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
- en: '[47](#footnote-103-backlink) [https://github.com/redhat-cop/containers-quickstarts/tree/master/jenkins-agents](https://github.com/redhat-cop/containers-quickstarts/tree/master/jenkins-agents)'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
- en: In doing so, the web report that's created can be viewed in Jenkins, which gives
    great details on the cause of the security vulnerability as well as any action
    that should be taken to remedy it.
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_27.jpg)'
  id: totrans-551
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.27: Example Zap report for PetBattle'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
- en: In the final non-functional testing section, let's have a look at deliberately
    breaking our code using a technique called chaos engineering.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
- en: Chaos Engineering
  id: totrans-554
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Chaos engineering is the process of deliberately breaking, hobbling, or impacting
    a system to see how it performs and whether it recovers in the ensuing "chaos."
    While most testing is seen as an endeavor to understand how a system performs
    in a known, stable state, chaos engineering is the computing equivalent of setting
    a bull free in a fine-china shop—you know it's going to end badly but you just
    don't know exactly the magnitude of how bad it's going to be.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of chaos engineering is to build confidence in the resiliency of
    the system. It also allows you to better understand where breakage points occur
    and the blast radius of any failures. There are many resilience features built
    into the Kubernetes API specification. Pod replicas are probably the simplest
    mechanism, having more than one of your applications running at any given time.
    It is also desirable to use application-specific mechanisms such as circuit breakers,
    which prevent failures from spreading throughout your system. Chaos engineering
    takes these ideas one step further and tests a system when one or more components
    fully or partially fail, such as when CPU or memory resources are low.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
- en: The basic premise is that the system under test is observed in a stable working
    state, then a fault is injected. The system is then observed to see if it recovers
    successfully from the fault or not. Outcomes from such testing are a potential
    list of areas to tune/fix as well as an understanding of the **Mean Time to Recovery**
    (**MTTR**) of a system. It's important to note that chaos engineering is focused
    on the system as a whole—both application and infrastructure performance need
    to be considered and tested.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
- en: One of the key mantras behind chaos engineering is contained in its defining
    principles[48](#footnote-102) – *The need to identify weaknesses before they manifest
    in system-wide, aberrant behaviors*.
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
- en: This is one of the most important aspects to be considered when adopting this
    approach. You don't want to be learning about weaknesses during a production-impacting
    incident. It's similar to the rationale behind regularly testing disaster recovery
    plans. To paraphrase, a colleague of ours here at Red Hat said, "*When the excrement
    hits the fan, the first thing to do is turn off the fan!*" Not much time for learning
    there.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a number of tools and frameworks that can help with setting up a
    chaos engineering practice. Here''s some to get started with (though there are
    others):'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
- en: Litmus Chaos[49](#footnote-101)
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kraken[50](#footnote-100)
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chaos Mesh[51](#footnote-099)
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48](#footnote-102-backlink) [https://principlesofchaos.org/](https://principlesofchaos.org/)'
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
- en: '[49](#footnote-101-backlink) [https://litmuschaos.io/](https://litmuschaos.io/)'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
- en: '[50](#footnote-100-backlink) [https://github.com/cloud-bulldozer/kraken](https://github.com/cloud-bulldozer/kraken)'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
- en: '[51](#footnote-099-backlink) [https://chaos-mesh.org/](https://chaos-mesh.org/)'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
- en: In a world where practices such as everything-as-code and GitOps are our only
    way to build software and the systems that support them, a great way to validate
    the ability to respond to missing items is to redeploy everything, including your
    infrastructure, from scratch every week or every night! This might seem extreme,
    but it's a great way to validate that there is no hidden magic that someone has
    forgotten to write down or codify.
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
- en: Accidental Chaos Testing
  id: totrans-569
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](img/Donal.jpg)'
  id: totrans-570
  prefs: []
  type: TYPE_IMG
- en: This is a story that I used to be reluctant to share, but over the years (and
    having done it twice), I realized it was actually a good thing to have done.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
- en: While working for an airline, I accidentally deleted the `labs-ci-cd` project
    along with a few other namespaces where our apps were deployed, including the
    authentication provider for our cluster. At the time, we were several weeks into
    our development. We were used to re-deploying applications and it was not a big
    deal for us to delete CI tools such as Nexus or Jenkins, knowing that our automation
    would kick back in swiftly to redeploy them.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
- en: However, on this engagement, we were also using GitLab and, unfortunately for
    me, GitLab was in the same project as these other tools!
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
- en: I checked with the team first and asked whether it was OK to rebuild everything
    in our tooling namespace. I got a resounding "yes" from my teammates, so proceeded
    to delete some of the things I thought needed to be cleared out and accidentally
    removed a few extra projects. About 30 seconds later, someone on the team perked
    up and asked, *Is Git down for anyone else?* This was promptly followed by another
    person saying, *Is anyone else not able to log in to the cluster?* My face lit
    up red as I immediately realized what I'd just done. Git, as we keep saying in
    the book, is our single source of truth. *If it's not in Git, it's not real* is
    our mantra! We even had it written on the walls! But I had just deleted it.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
- en: So, what happens when some silly person accidentally deletes it? After the initial
    shock and panic, the team pulled the Andon Cord. We quickly stormed together to
    see what exactly had happened in order to plan how we could recover not just Git
    but all the things we'd added to the cluster. Luckily for us, everything we had
    done was stored in Git so we were able to redeploy our tools and push our local,
    distributed copies of the software and infrastructure back into the shared Git
    repository.
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
- en: The team was cross-functional and had all the tools and access we needed to
    be able to respond to this. Within 1 hour, we had fully restored all our applications
    and tools with all of our automation running smoothly again.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
- en: I think the real power in this example is how, given the right equipment and
    the right ownership, an empowered team can have it all. We acted as one unit fixing
    things at lightning speed. We were not stuck waiting in a queue or having to raise
    a ticket on another team to restore our infrastructure. We could do it for ourselves
    within minutes – not days or weeks later.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
- en: Another thing I learned was not to keep Git in the same project as the other
    tools in case another person like me comes along. I also learned to be mindful
    of the permissions we have within a cluster. As an administrator, I was able to
    remove things that perhaps I should not have been playing with.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
- en: So we've written the code, tested, quality-checked it and even scanned it for
    vulnerabilities. Now it's time to deploy it onto the cluster. Let's explore one
    of the key areas of benefit of using Kubernetes - the different ways you can deploy
    applications depending on your needs and perform user-driven experiments to determine
    what features your users prefer.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
- en: Advanced Deployments
  id: totrans-580
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The time between software being written and tested till it is deployed in production
    should be as short as possible. That way your organization is able to realize
    value from the software changes as quickly as possible. The modern approach to
    this problem is, of course, through automation. There are simply too many details
    and configuration items that need to be changed when deploying to production that
    even for a small application suite like PetBattle, manual deployment becomes error-prone
    and tedious. This drive to reduce manual toil is at the heart of many of the DevOps
    practices we have been discovering in this book.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
- en: 'We can minimize the downtime (ideally to zero!) during software deployment
    changes by adopting the right application architecture and combining that with
    the many platform capabilities that OpenShift offers. Let''s look at some common
    deployment strategies that OpenShift supports:'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
- en: 'Rolling deployment:'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spin up a pod of the new version and then spin down a pod of the existing old
    version automatically. Very useful for a zero-downtime approach.
  id: totrans-584
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Canary deployment:'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spin up a single pod of the new version, perform testing to ensure that everything
    is working correctly, and then replace all the old pods with new ones.
  id: totrans-586
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Blue/Green deployment:'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a parallel deployment and verify that everything is working correctly
    before switching traffic over.
  id: totrans-588
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Service Mesh traffic mirroring functionality can be useful with this approach
    to validate that the new version is working as expected.
  id: totrans-589
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Recreate deployment:'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basically, scale the existing pods down to zero and then spin up the new version.
  id: totrans-591
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use where an application must be restarted, for example, to migrate database
    schema or tables.
  id: totrans-592
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Think of this as a Ripley deployment: "take off and nuke the entire site from
    orbit. It''s the only way to be sure."[52](#footnote-098)'
  id: totrans-593
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We can roll back to previous deployment versions using the Helm chart life cycle
    or the out-of-the-box `oc rollback` support. Images and configuration are versioned
    and cached in OpenShift to easily support rolling back to previous versions.
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
- en: '[52](#footnote-098-backlink) [https://en.wikiquote.org/wiki/Aliens_(film)](https://en.wikiquote.org/wiki/Aliens_(film))'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
- en: A/B Testing
  id: totrans-596
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A/B testing an application is an amazing way to test or validate a new feature
    in production. The process is pretty simple: you deploy two (or more) different
    versions of your application to production, measure some aspect, and see which
    version performs *better*. Given that A/B testing is primarily a mechanism of
    gauging user experience, *better* depends on what aspect/feature you''re experimenting
    with. For example, you could make a subtle change to a web page layout and measure
    how long it takes for the user to navigate to some button or how long the user
    continues to interact with specific items on the page.'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
- en: It's a brilliant way to de-risk a new release or validate some new business
    or UI features with a smaller audience before releasing to a wider group. User
    behavior can be captured and experiments can be run to make informed decisions
    about what direction a product should take.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
- en: The Experiment
  id: totrans-599
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s cast our minds back to the earlier chapters where we spoke about generating
    options. There we spoke about the importance of experiments and our Value Slicing
    board included an item for which we could do an A/B test. One experiment that
    came up was to assess how users would vote for cats in the competition. Should
    they just be able to upvote (with a 👍) or should they be able to downvote (👎)
    too? We can build and deploy two versions of our application: one with the ability
    to both upvote and downvote, and one with just the ability to upvote. Our experiment
    is simple: to track how often people actually use the downvote button, so we can
    decide whether it''s a feature we need or whether we should focus on building
    different functionality.'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_28.jpg)'
  id: totrans-601
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.28: Experiment defined on a Value Slicing board'
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
- en: Let's now look at how we could set up a simple experiment to deploy both variants
    of the application and route traffic between each deployed instance to generate
    some data to help inform our decision-making.
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
- en: Matomo – Open Source Analytics
  id: totrans-604
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OpenShift provides us with a mechanism to push traffic to different versions
    of an application. This in itself is useful, but it provides no information that
    we can base a decision on. For this, we need to measure how the users interact
    with the platform. To do this, we're going to introduce user analytics, which
    records metrics on the users' interactions with the website. We're going to use
    the open source Matomo[53](#footnote-097) platform. There are others we could
    have used but, at the time of writing, this was our choice as it was open source
    and quite feature-complete. Let's add Matomo to our Big Picture for consistency.
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/figure-15-29.jpg)'
  id: totrans-606
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.29: Big Picture with added tools including Matomo'
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
- en: '[53](#footnote-097-backlink) [https://matomo.org/](https://matomo.org/)'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
- en: 'So how do we install the Matomo platform? Here comes Helm to the rescue again.
    We automated this installation as part of the PetBattle platform by just enabling
    it in our Ubiquitous Journey project. It''s deployed by default into our `labs-ci-cd`
    namespace from this configuration in `ubiquitous-journey/values-tooling.yaml`:'
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE273]'
  id: totrans-610
  prefs: []
  type: TYPE_PRE
  zh: '[PRE273]'
- en: '[PRE274]'
  id: totrans-611
  prefs: []
  type: TYPE_PRE
  zh: '[PRE274]'
- en: '[PRE275]'
  id: totrans-612
  prefs: []
  type: TYPE_PRE
  zh: '[PRE275]'
- en: '[PRE276]'
  id: totrans-613
  prefs: []
  type: TYPE_PRE
  zh: '[PRE276]'
- en: '[PRE277]'
  id: totrans-614
  prefs: []
  type: TYPE_PRE
  zh: '[PRE277]'
- en: '[PRE278]'
  id: totrans-615
  prefs: []
  type: TYPE_PRE
  zh: '[PRE278]'
- en: '[PRE279]'
  id: totrans-616
  prefs: []
  type: TYPE_PRE
  zh: '[PRE279]'
- en: '[PRE280]'
  id: totrans-617
  prefs: []
  type: TYPE_PRE
  zh: '[PRE280]'
- en: '[PRE281]'
  id: totrans-618
  prefs: []
  type: TYPE_PRE
  zh: '[PRE281]'
- en: '[PRE282]'
  id: totrans-619
  prefs: []
  type: TYPE_PRE
  zh: '[PRE282]'
- en: '[PRE283]'
  id: totrans-620
  prefs: []
  type: TYPE_PRE
  zh: '[PRE283]'
- en: '[PRE284]'
  id: totrans-621
  prefs: []
  type: TYPE_PRE
  zh: '[PRE284]'
- en: '[PRE285]'
  id: totrans-622
  prefs: []
  type: TYPE_PRE
  zh: '[PRE285]'
- en: '[PRE286]'
  id: totrans-623
  prefs: []
  type: TYPE_PRE
  zh: '[PRE286]'
- en: 'However, if you want to just install the tool without involving ArgoCD, you
    can just clone the repository and install it manually. This chart has been forked
    from an existing chart[54](#footnote-096) to tweak it for easier installation
    on OpenShift. Specifically, the security contexts in the MariaDB and Redis dependencies
    have been disabled so that the deployment will automatically use the target namespace
    default service account and associated `anyuid`. Also, an OpenShift route has
    been added to the chart to allow ingress traffic to the application:'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE287]'
  id: totrans-625
  prefs: []
  type: TYPE_PRE
  zh: '[PRE287]'
- en: '[PRE288]'
  id: totrans-626
  prefs: []
  type: TYPE_PRE
  zh: '[PRE288]'
- en: '[PRE289]'
  id: totrans-627
  prefs: []
  type: TYPE_PRE
  zh: '[PRE289]'
- en: '[PRE290]'
  id: totrans-628
  prefs: []
  type: TYPE_PRE
  zh: '[PRE290]'
- en: With the Matomo analytics deployed, we just need to configure the frontend to
    connect to it. To do this just update the config map's `matomoUrl` in the `chart/values.yaml`
    in the frontend to have the tracking code automatically track the site. This will
    provide basic site tracking such as the time spent on a page or the number of
    pages visited.
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
- en: '[54](#footnote-096-backlink) [https://gitlab.com/ideaplexus/helm/matomo](https://gitlab.com/ideaplexus/helm/matomo)'
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_30.jpg)'
  id: totrans-631
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.30: Configuring the config_map for matomoUrl'
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
- en: 'For a more meaningful test, we might want to capture specific user behavior.
    The application has been instrumented to report certain events back to the Matomo
    server, such as mouse clicks. Whenever a user clicks the button to vote for a
    cat, it will capture it and report it in Matomo for us. It''s very simple to do
    this – we just add a one-liner to the event we want to track:'
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE291]'
  id: totrans-634
  prefs: []
  type: TYPE_PRE
  zh: '[PRE291]'
- en: Deploying the A/B Test
  id: totrans-635
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In PetBattle land, let's see how we could configure the deployments of the frontend
    to run this simple A/B test. Luckily for us, OpenShift makes this super easy by
    having a way to expose a `route` and connect it to more than one service, using
    the `alternateBackends` array to configure additional services to send traffic
    to. We can then apply `weights` to each service defined here in order to set the
    percentage of the traffic to either service that's deployed, A or B. The weights
    can be set between 0 and 256, and if a service is reduced to 0 then it carries
    on serving existing connections but no new ones. In fact, OpenShift allows us
    to do more than just an A or B test – also C and D, as `alternateBackends` supports
    up to three services!
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s deploy our A/B experiment for `pet-battle`. We could integrate these
    steps with ArgoCD but to keep things nice and easy for illustrative purposes,
    let''s just stick with using our trusty friend Helm to deploy things. We''ve prebuilt
    an image that has no ability to downvote on the home page `quay.io/petbattle/pet-battle:no-down-vote`.
    Let''s deploy this image to our cluster by running a simple Helm command (make
    sure to set the config map to the correct endpoints for your cluster):'
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE292]'
  id: totrans-638
  prefs: []
  type: TYPE_PRE
  zh: '[PRE292]'
- en: '[PRE293]'
  id: totrans-639
  prefs: []
  type: TYPE_PRE
  zh: '[PRE293]'
- en: '[PRE294]'
  id: totrans-640
  prefs: []
  type: TYPE_PRE
  zh: '[PRE294]'
- en: With this command, we're deploying a new instance of the `pet-battle` frontend
    by setting the image to the prebuilt one and disabling the OpenShift route for
    this as it's not needed. We'll configure our route to production by updating our
    `prod` app.
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
- en: 'Running `oc get pods` should show the app started and if you check for routes,
    you should see none exposed:'
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE295]'
  id: totrans-643
  prefs: []
  type: TYPE_PRE
  zh: '[PRE295]'
- en: NAME READY STATUS RESTARTS AGE
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE296]'
  id: totrans-645
  prefs: []
  type: TYPE_PRE
  zh: '[PRE296]'
- en: '[PRE297]'
  id: totrans-646
  prefs: []
  type: TYPE_PRE
  zh: '[PRE297]'
- en: 'Let''s deploy our `prod` version of the `pet-battle` application and add the
    `no-down-vote` app as one of the services we''ll connect to. Our Helm chart is
    configured to accept the name of the service and the weight we want to apply to
    the experiment feature via `a_b_deploy.svc_name` and `a_b_deploy.weight`. It''s
    defaulted to be a 50/50 round-robin split. Let''s deploy it with this setup:'
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE298]'
  id: totrans-648
  prefs: []
  type: TYPE_PRE
  zh: '[PRE298]'
- en: '[PRE299]'
  id: totrans-649
  prefs: []
  type: TYPE_PRE
  zh: '[PRE299]'
- en: '[PRE300]'
  id: totrans-650
  prefs: []
  type: TYPE_PRE
  zh: '[PRE300]'
- en: '[PRE301]'
  id: totrans-651
  prefs: []
  type: TYPE_PRE
  zh: '[PRE301]'
- en: '[PRE302]'
  id: totrans-652
  prefs: []
  type: TYPE_PRE
  zh: '[PRE302]'
- en: '[PRE303]'
  id: totrans-653
  prefs: []
  type: TYPE_PRE
  zh: '[PRE303]'
- en: '[PRE304]'
  id: totrans-654
  prefs: []
  type: TYPE_PRE
  zh: '[PRE304]'
- en: '[PRE305]'
  id: totrans-655
  prefs: []
  type: TYPE_PRE
  zh: '[PRE305]'
- en: '[PRE306]'
  id: totrans-656
  prefs: []
  type: TYPE_PRE
  zh: '[PRE306]'
- en: '[PRE307]'
  id: totrans-657
  prefs: []
  type: TYPE_PRE
  zh: '[PRE307]'
- en: Navigate to the `pet-battle` UI and you should see on refreshing that there
    is a 50/50 chance that you will get the upvote-only version. If you open up incognito
    mode or a different browser and try to hit the frontend, you should get the alternative
    one. A different browser session is required, as the OpenShift router will by
    default return you to the same pod, so you'll always land on the same site version.
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_31.jpg)'
  id: totrans-659
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.31: The no-downvote PetBattle frontend'
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
- en: 'Running `oc get routes` should show one route and more than one service connected
    to it with a 50/50 `split prod-pet-battle(50%),no-down-vote-pet-battle(50%)`.
    You can view the weights set as 100 each by running `oc get route prod-pet-battle
    -o yaml`:'
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE308]'
  id: totrans-662
  prefs: []
  type: TYPE_PRE
  zh: '[PRE308]'
- en: '[PRE309]'
  id: totrans-663
  prefs: []
  type: TYPE_PRE
  zh: '[PRE309]'
- en: '[PRE310]'
  id: totrans-664
  prefs: []
  type: TYPE_PRE
  zh: '[PRE310]'
- en: '[PRE311]'
  id: totrans-665
  prefs: []
  type: TYPE_PRE
  zh: '[PRE311]'
- en: '[PRE312]'
  id: totrans-666
  prefs: []
  type: TYPE_PRE
  zh: '[PRE312]'
- en: '[PRE313]'
  id: totrans-667
  prefs: []
  type: TYPE_PRE
  zh: '[PRE313]'
- en: 'The weights for the traffic routed to each application can be updated quite
    easily using Helm:'
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE314]'
  id: totrans-669
  prefs: []
  type: TYPE_PRE
  zh: '[PRE314]'
- en: '[PRE315]'
  id: totrans-670
  prefs: []
  type: TYPE_PRE
  zh: '[PRE315]'
- en: '[PRE316]'
  id: totrans-671
  prefs: []
  type: TYPE_PRE
  zh: '[PRE316]'
- en: '[PRE317]'
  id: totrans-672
  prefs: []
  type: TYPE_PRE
  zh: '[PRE317]'
- en: Understanding the results
  id: totrans-673
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If we play around with the two versions that are deployed, we can see how the
    results of clicking the buttons are captured. If you open the Matomo app and log
    in, you will see some statistics there. The default password for Matomo, as set
    in the chart, is `My$uper$ecretPassword123#`. This might not be exactly secure
    out of the box but it can easily be changed via the Helm chart's values.
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_32.jpg)'
  id: totrans-675
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.32: Matomo showing the number of clicks for UP_VOTE versus DOWN_VOTE'
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
- en: It might take a few minutes for Matomo to render the pie chart. Our simple experiment
    shows that more people use the UP_VOTE feature than the DOWN_VOTE feature. By
    connecting the A/B test to the data captured in Matomo, we can now make more informed
    decisions about the next actions that need to be taken for our product.
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
- en: This experiment proves how easy it is to set up an A/B test. We can use the
    OpenShift platform to dynamically route users to multiple application versions
    concurrently deployed while we collect data about what is working well and what
    is not. There is some thinking that needs to be put into how we instrument the
    application to collect specific data, but the open source tooling available to
    us makes this easy too!
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
- en: Blue/Green deployments
  id: totrans-679
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Blue/Green deployment strategy is one of the fundamental deployment strategies
    that every team deploying applications into production should know about. Using
    this strategy minimizes the time it takes to perform a deployment cutover by ensuring
    you have two versions of the application available during deployment. It is also
    advantageous in that you can quickly roll back to the original version of the
    application without having to roll back any changes.
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_33.jpg)'
  id: totrans-681
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.33: The canonical Blue/Green deployment'
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
- en: The trade-off here is that you need to have enough resources to be able to run
    two versions of the application stack you are deploying. If your application has
    persistent state, for example, a database or non-shared disk, then the application
    architecture and constraints must be able to accommodate the two concurrent versions.
    This is normally not an issue for smaller microservices and is one of the benefits
    of choosing that style of deployment.
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s run through Blue/Green deployment using the PetBattle API as the example
    application stack. In this case, we are going to deploy two full stacks, that
    is, both the application and MongoDB. Let''s deploy the blue version of our application:'
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE318]'
  id: totrans-685
  prefs: []
  type: TYPE_PRE
  zh: '[PRE318]'
- en: '[PRE319]'
  id: totrans-686
  prefs: []
  type: TYPE_PRE
  zh: '[PRE319]'
- en: '[PRE320]'
  id: totrans-687
  prefs: []
  type: TYPE_PRE
  zh: '[PRE320]'
- en: 'Now deploy the green application stack. Note that we have a different tagged
    image version for this:'
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE321]'
  id: totrans-689
  prefs: []
  type: TYPE_PRE
  zh: '[PRE321]'
- en: '[PRE322]'
  id: totrans-690
  prefs: []
  type: TYPE_PRE
  zh: '[PRE322]'
- en: '[PRE323]'
  id: totrans-691
  prefs: []
  type: TYPE_PRE
  zh: '[PRE323]'
- en: '[PRE324]'
  id: totrans-692
  prefs: []
  type: TYPE_PRE
  zh: '[PRE324]'
- en: '[PRE325]'
  id: totrans-693
  prefs: []
  type: TYPE_PRE
  zh: '[PRE325]'
- en: 'Next, we expose our production URL endpoint as a route that points to the blue
    service:'
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE326]'
  id: totrans-695
  prefs: []
  type: TYPE_PRE
  zh: '[PRE326]'
- en: '[PRE327]'
  id: totrans-696
  prefs: []
  type: TYPE_PRE
  zh: '[PRE327]'
- en: '[PRE328]'
  id: totrans-697
  prefs: []
  type: TYPE_PRE
  zh: '[PRE328]'
- en: 'Finally, we can switch between the two using the `oc patch` command:'
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE329]'
  id: totrans-699
  prefs: []
  type: TYPE_PRE
  zh: '[PRE329]'
- en: '[PRE330]'
  id: totrans-700
  prefs: []
  type: TYPE_PRE
  zh: '[PRE330]'
- en: '[PRE331]'
  id: totrans-701
  prefs: []
  type: TYPE_PRE
  zh: '[PRE331]'
- en: '[PRE332]'
  id: totrans-702
  prefs: []
  type: TYPE_PRE
  zh: '[PRE332]'
- en: '[PRE333]'
  id: totrans-703
  prefs: []
  type: TYPE_PRE
  zh: '[PRE333]'
- en: '[PRE334]'
  id: totrans-704
  prefs: []
  type: TYPE_PRE
  zh: '[PRE334]'
- en: 'If you browse to the `bluegreen` route endpoint, you should be able to easily
    determine the application stack:'
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_34.jpg)'
  id: totrans-706
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.34: Blue/Green deployment for the PetBattle API'
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
- en: Even though this is somewhat of a contrived example, you can see the power of
    developers being allowed to manipulate the OpenShift routing tier in a self-service
    manner. A similar approach could be used to deploy the NSFF feature as an example
    – use the Helm chart parameters `--set nsff.enabled=true` to deploy an NSFF-enabled
    version. You can also point both applications to the same database if you want
    to with similar manipulation of the Helm chart values.
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
- en: If you have more complex use cases where you need to worry about long-running
    transactions in the original blue stack, that is, you need to drain them, or you
    have data stores that need migrating alongside the green rollout, there are several
    other more advanced ways of performing Blue/Green deployments. Check out the ArgoCD
    rollout capability, which has a ton of advanced features,[55](#footnote-095) the
    Knative Blue/Green rollout capability, or indeed Istio[56](#footnote-094) for
    more ideas.
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
- en: Deployment previews
  id: totrans-710
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We should think of OpenShift as something of a playground that we can use to
    deploy our applications for production all the way down to a developer preview.
    Gone are the days when a development team needed to raise a ticket to provision
    a server and manually configure it to show off their applications. Building applications
    in containers allows us to make shippable applications that can be repeatedly
    deployed in many environments. Our automation for PetBattle in Jenkins is configured
    to run on every commit. For Jenkins, we're using the multi-branch plugin so anytime
    a developer pushes a new feature to a branch, it will automatically scaffold out
    a new pipeline and deploy the latest changes for that feature.
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
- en: When this was discussed in the previous chapter, about sandbox builds, you may
    have thought this was overkill and a bit of a waste. Why not just build on a pull
    request? It's a valid question to ask and depending on the objective you're trying
    to achieve, building on a pull request is probably sufficient. We have used the
    sandbox builds as another way to introduce feedback loops.
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
- en: '[55](#footnote-095-backlink) [https://argoproj.github.io/argo-rollouts](https://argoproj.github.io/argo-rollouts)'
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
- en: '[56](#footnote-094-backlink) [https://github.com/hub-kubernetes/istio-blue-green-deployment](https://github.com/hub-kubernetes/istio-blue-green-deployment)'
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
- en: Developers do not exist in isolation; they are surrounded by other members of
    the team, including Product Owners and Designers. Our ability to dynamically spin
    up a new deployment of a feature from our pipeline means we can connect the coding
    efforts to the design team really easily. Developers can get very fast feedback
    by sharing a link to the latest changes or the implementation of a new feature
    with the design team. This feedback loop can quickly allow subtle changes and
    revisions to be made before the engineer loses the context of the piece of work.
    Creating deployment previews from every commit also allows a developer to very
    quickly share two versions of what an app might look like with a Product Owner
    while they make their decision about which to choose.
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
- en: From our Jenkins pipeline, there is a branch called `cool-new-cat`. When this
    is built, it will push a new version of the app to the `dev` environment. The
    change in the app is subtle for illustrative purposes, but we can see the banner
    has been changed. With this new version of the app in the `dev` environment, we
    can get some feedback prior to merging it to master and generating a release candidate.
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_15_35.jpg)'
  id: totrans-717
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.35: New feature deployed to the sandbox generating a deploy preview
    to collect feedback'
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 15.35* shows the sandbox version of the being deployed along with it''s
    associated route, service and configmap.'
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-720
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Congratulations! You've just finished the most technologically focused chapter
    of this book so far. Please don't go off and think that you have to use each and
    every technology and technique that has been mentioned—that's not the point. Investigate,
    evaluate, and choose which of these technologies applies to your own use cases
    and environment.
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
- en: Several of the testing practices are part of our technical foundation. Unit
    testing, non-functional testing, and measuring code coverage are all critical
    practices for helping build quality into our applications and products from the
    start. We covered many small but invaluable techniques, such as resource validation,
    code linting, and formatting, that help make our code base less of a burden to
    maintain.
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
- en: We covered a number of different approaches for deployments, including A/B,
    Canary, Blue/Green, and Serverless. These core techniques allow us to deliver
    applications more reliably into different environments. We even briefly covered
    artificial intelligence for reducing unwanted images uploaded into our PetBattle
    product. By focusing our efforts on what happens when things go wrong, we can
    more easily embrace and prepare for failures—big and small.
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
