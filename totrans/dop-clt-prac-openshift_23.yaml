- en: 16\. Own It
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"*Annnddd we''re live! PetBattle is finally in production, we can crack open
    the Champagne and toast our success*." But now what? How do we know that the site
    is doing what we expect it to do and, more importantly, how will we know when
    it isn''t performing as we intended? Do we just sit around waiting for customers
    to complain that the site is down or that errors are happening? Not exactly a
    good user experience model—or a good use of our time.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss the tools and techniques that can be utilized
    to monitor the site and notify us when things start to go wrong so we can react
    before the entire site goes down. We will also discuss advanced techniques, such
    as Operators, that can help you automate a lot of the day-to-day operations.
  prefs: []
  type: TYPE_NORMAL
- en: Observability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Observability[1](#footnote-181) is the process of instrumenting software components
    to assist with extracting data. This data can then be used to determine how well
    a system is functioning and subsequently be used to notify administrators in the
    event of issues.
  prefs: []
  type: TYPE_NORMAL
- en: '[1](#footnote-181-backlink) [https://en.wikipedia.org/wiki/Observability](https://en.wikipedia.org/wiki/Observability)'
  prefs: []
  type: TYPE_NORMAL
- en: 'When it comes to observing the state of our PetBattle applications, there are
    a number of aspects to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: How do we know if an application instance is initialized and ready to process
    traffic?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we know if the application has failed without crashing, such as by becoming
    deadlocked or blocked?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we access the application logs?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we access the application metrics?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we know what version of the application is running?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's start by exploring some application health checks.
  prefs: []
  type: TYPE_NORMAL
- en: Probes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Hello, hello?... Is this thing on?* In Kubernetes, the health of an application
    is determined by a set of software *probes* that are periodically invoked by the
    kubelet. A probe is basically an action invoked by the platform on each Pod that
    either returns a success value or a failure value.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Probes can be configured to perform one of the following types of actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Connect to a specific TCP port that the container is listening on. If the port
    is open, the probe is considered successful.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Invoke an HTTP endpoint, if the HTTP response code is 200 or greater but less
    than 400.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shell into a container and execute a command—this may involve checking for a
    specific file in the directory. This enables probes to be placed on applications
    that don't natively provide health checks out of the box. If the command exits
    with a status code of 0, then the probe is successful.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a probe fails a configured number of times, the kubelet managing the Pod
    will take a pre-determined action, for example, by removing the Pod from the service
    or restarting the Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes currently supports three different kinds of probes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Readiness**: This decides whether the Pod is ready to process incoming requests.
    If the application needs some time to start up, this probe ensures that no traffic
    is sent to the Pod until this probe passes. Also, if the probe fails while it''s
    running, the platform stops sending any traffic to the Pod until the probe once
    again succeeds. Readiness probes are key to ensuring a zero-downtime experience
    for the user when scaling up or upgrading Pods.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Liveness**: This checks to see whether a Pod has a process deadlock or it''s
    crashed without exiting; if so, the platform will kill the Pod.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Startup**: This is used to prevent the platform from killing a Pod that is
    initializing but is slow in starting up. When the startup probe is configured,
    the readiness and liveness probes are disabled until the startup probe passes.
    If the startup probe never passes, the Pod is eventually killed and restarted.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Most of the time, you will probably only utilize the readiness and liveness
    probes, unless you have a container that's very slow in starting up.
  prefs: []
  type: TYPE_NORMAL
- en: In the PetBattle Tournament Service component, the liveness and readiness probes
    are configured as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `DeploymentConfig` (or the Deployment), the `/health/live` and `/health/ready`
    URLs are automatically created by the Quarkus framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Different probes can invoke the same action, but we consider this bad practice.
    The semantics of a readiness probe are different from those of a liveness probe.
    It's recommended that liveness and readiness probes invoke different endpoints
    or actions on the container.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a readiness probe can invoke an action that verifies whether an
    application can accept requests. If during the Pod's lifetime the readiness probe
    fails, Kubernetes will stop sending requests to the Pod until the probe is successful
    again.
  prefs: []
  type: TYPE_NORMAL
- en: A liveness probe is one that verifies whether an application can process a request
    successfully; for example, if an application were blocked or accepting a request
    but waiting a long time for a database connection to become available, the probe
    would fail and Kubernetes would restart the Pod. Think of liveness probes as the
    Kubernetes equivalent of the IT Crowd[2](#footnote-180) way of working.
  prefs: []
  type: TYPE_NORMAL
- en: Domino Effect
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One question that we get asked a lot is, should a health check reflect the state
    of the application's downstream dependencies as well as the application itself?
    The absolute, definitive answer is *it depends*. Most of the time, a health check
    should only focus on the application, but there are always scenarios where this
    isn't the case.
  prefs: []
  type: TYPE_NORMAL
- en: If your health check functionality does a deep check of downstream systems,
    this can be expensive and result in cascading failures, where a downstream system
    has an issue and an upstream Pod is restarted due to this downstream issue. Some
    legacy downstream systems may not have health checks, and a more appropriate approach
    in this scenario is to add resilience and fault tolerance to your application
    and architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Fault Tolerance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A key aspect of this is to utilize a **circuit breaker** pattern when invoking
    dependencies. Circuit breakers can *short circuit* the invocation of downstream
    systems when they detect that previous calls have failed. This can give the downstream
    system time to recover or restart without having to process incoming traffic.
  prefs: []
  type: TYPE_NORMAL
- en: The basic premise of a circuit breaker is that in the case of the failure of
    a downstream system, the upstream system should just assume that the next request
    will fail and not send it. It potentially also takes appropriate actions for recovery
    by, say, returning a default value.
  prefs: []
  type: TYPE_NORMAL
- en: After a given period of time, known as the backoff period, the upstream system
    should try sending a request to the downstream system, and if that succeeds, it
    reverts to normal processing. The rationale behind the backoff period is to avoid
    the situation where the upstream systems overwhelm the downstream systems with
    requests as soon as it starts up.
  prefs: []
  type: TYPE_NORMAL
- en: '[2](#footnote-180-backlink) [https://www.quotes.net/mquote/901983](https://www.quotes.net/mquote/901983)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Circuit breaker functionality can be performed at an individual level within
    an application''s code: multiple frameworks such as Quarkus, Netflix Hystrix,
    and Apache Camel support circuit breakers and other fault-tolerant components.
    Check out the Quarkus fault tolerance plugin for more details.[3](#footnote-179)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Platform-level circuit breaker functionality is provided by the **service mesh**
    component within OpenShift. This has various substantial advantages over application-level
    circuit breakers:'
  prefs: []
  type: TYPE_NORMAL
- en: It can be used on any container communicating via HTTP/HTTPS. A sidecar proxy
    is used to inject the circuit breaker functionality without having to modify the
    code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It provides dynamic configuration of the circuit breaker functionality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It provides metrics and visibility of the state of circuit breakers throughout
    the platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service mesh also provides other fault-tolerance functionalities, such as timeout
    and retries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Ahh, logging!* No *true* developer[4](#footnote-178) has earned their stripes
    until they''ve spent countless hours of their existence trawling through production
    logs trying to figure out exactly what went wrong when a user clicked "Confirm".
    If you have managed to do this across multiple log files, all hosted on separate
    systems via multiple terminal windows, then you are truly righteous in the eyes
    of the IDE-bound masses.'
  prefs: []
  type: TYPE_NORMAL
- en: The good news is that application logging on Kubernetes is a first-class citizen
    on the platform—just configure your application to write its logs to STDOUT and
    the platform will pick it up and you can view/trawl through them. OpenShift goes
    one level deeper by shipping an aggregated logging stack with EFK (Elasticsearch,
    Fluentd, and Kibana) out of the box. This allows developers to search and view
    logs across multiple containers running on multiple nodes across the cluster.
    If you want to give this a try, follow the documentation at [https://docs.openshift.com/container-platform/4.7/logging/cluster-logging-deploying.html](https://docs.openshift.com/container-platform/4.7/logging/cluster-logging-deploying.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[3](#footnote-179-backlink) [https://quarkus.io/guides/smallrye-fault-tolerance](https://quarkus.io/guides/smallrye-fault-tolerance)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4](#footnote-178-backlink) [https://en.wikipedia.org/wiki/No_true_Scotsman](https://en.wikipedia.org/wiki/No_true_Scotsman)'
  prefs: []
  type: TYPE_NORMAL
- en: Tracing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So, first things first: no, tracing is not application logging running at the
    trace log level. When it comes to OpenShift, tracing is the functionality added
    to the Kubernetes platform that enables developers to trace a request across a
    distributed set of application components running in different containers on different
    nodes of a cluster. Tracing is an exceptionally useful tool used to determine
    and visualize inter-service/component dependencies and performance/latency blackholes
    throughout a distributed system.'
  prefs: []
  type: TYPE_NORMAL
- en: Tracing is provided as part of the OpenShift service mesh component. The underlying
    tracing functionality is provided by the Jaeger[5](#footnote-177) distributed
    tracing platform. To support tracing, applications must include a client library
    that sends instrumented request metadata to a Jaeger collector, which in turn
    processes it and stores the data. This data can then be queried to help visualize
    the end-to-end request workflow. The Jaeger client libraries are language-specific
    and utilize the vendor-neutral OpenTracing specification.
  prefs: []
  type: TYPE_NORMAL
- en: If you're thinking, "*Woah!* *Collecting metadata for every request would be
    very expensive to store and process*," you'd be right. Jaeger *can* do this, but
    for scale purposes it's better to record and process a *sample* of requests, rather
    than each and every one of them.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Probes are useful for telling when an application is ready to accept traffic,
    or whether it is stuck. Tracing is great at providing a measure of latency throughout
    a distributed system, while logging is a great tool to retrospectively understand
    exactly what occurred and when it occurred.
  prefs: []
  type: TYPE_NORMAL
- en: However, to comprehend the deep state (no, not *that* deep state!) of a system
    and potentially predict its future state after a period of time, you need to measure
    some of the key quantitative characteristics of the system and visualize/compare
    them over a period of time.
  prefs: []
  type: TYPE_NORMAL
- en: The good news is that metrics are relatively easy to obtain; you can get them
    from infrastructure components and software components such as JVM, and you can
    also add domain-specific/custom metrics to your application.
  prefs: []
  type: TYPE_NORMAL
- en: '[5](#footnote-177-backlink) [https://www.jaegertracing.io/](https://www.jaegertracing.io/)'
  prefs: []
  type: TYPE_NORMAL
- en: Given the multitude of metrics available, the hard bit is figuring out which
    metrics are valuable to your role and need to be retained; for example, for application
    operator connection pool counts, JVM garbage collection pause times are invaluable.
    For a Kubernetes platform operator, JVM garbage collection pause times are less
    critical, but metrics from platform components, such as etcd-related metrics,
    are crucial.
  prefs: []
  type: TYPE_NORMAL
- en: The good news is that OpenShift provides metrics for both the cluster and the
    applications running on it. In this section, we're going to focus on the application-level
    perspective. In the Kubernetes community, the *de facto* approach is to use Prometheus[6](#footnote-176)
    for gathering and Grafana[7](#footnote-175) for the visualization of metrics.
    This doesn't mean that you can't use other metrics solutions, and there are some
    very good ones out there with additional features.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift ships with both Prometheus and Grafana as the default metrics stack.
    Additionally, it also ships with the Prometheus Alertmanager. The Alertmanager
    facilitates the sending of notifications to operators when metric values indicate
    that something is going or has gone wrong and *la merde* has or is about to hit
    the fan. Examples of this include a high number of threads or large JVM garbage
    collection pause times.
  prefs: []
  type: TYPE_NORMAL
- en: 'Great, so how do we enable this for PetBattle? It is relatively straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: Use a metrics framework in your application that records metrics and exposes
    the metrics to Prometheus.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure Prometheus to retrieve the metrics from the application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Visualize the metrics in OpenShift.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the metrics are being retrieved, the final step is to configure an alert
    using the Prometheus Alertmanager.
  prefs: []
  type: TYPE_NORMAL
- en: Gather Metrics in the Application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Taking the PetBattle Tournament service component as an example, this is developed
    using the Quarkus Java framework. Out of the box, Quarkus supports/recommends
    the use of the open-source Micrometer metrics framework.[8](#footnote-174)
  prefs: []
  type: TYPE_NORMAL
- en: '[6](#footnote-176-backlink) [https://prometheus.io/](https://prometheus.io/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[7](#footnote-175-backlink) [https://grafana.com/oss/](https://grafana.com/oss/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[8](#footnote-174-backlink) [https://micrometer.io/](https://micrometer.io/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'To add this to the Tournament service, we simply need to add the dependency
    to the Maven POM along with the Prometheus dependency. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Then, we configure a Prometheus registry, which is used to store the metrics
    locally in the application before being retrieved by the Prometheus collector.
    This is done in the `src/main/resources/application.properties` file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'With this configuration, the Prometheus endpoint is exposed by the application
    Pod. Let''s go ahead and test it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: If successful, you should get an output similar to the above. Notice that you're
    not just getting the application-level metrics—the MongoDB connection pool metrics
    are also there. These are automatically added by the Quarkus framework once configured
    in the `application.properties` file.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Prometheus To Retrieve Metrics From the Application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Prometheus is somewhat unusual in its mode of operation. Rather than having
    some sort of agent pushing metrics to a central collector, it uses a pull model
    where the collector retrieves/scrapes metrics from a known HTTP/HTTPS endpoint
    exposed by the applications. In our case, as seen above, we're exposing metrics
    using the `/metrics` endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: So how does the Prometheus collector know when, where, and how to gather these
    metrics? OpenShift uses a Prometheus operator[9](#footnote-173) that simplifies
    configuring Prometheus to gather metrics. We just need to deploy a `ServiceMonitor`
    object to instruct Prometheus on how to gather our application metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '[9](#footnote-173-backlink) [https://github.com/prometheus-operator/prometheus-operator](https://github.com/prometheus-operator/prometheus-operator)'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few things to note that might save you some time when trying to
    understand this configuration: basically, this configuration will scrape associated
    components every 30 seconds using the default HTTP path `/metrics`. Now, `port:
    tcp-8080` is mapped to the port name in the service—see below, highlighted in
    bold. If the service had a port name of `web`, then the configuration would be
    `port: web`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: User workload monitoring needs to be enabled at the cluster level before ServiceMonitoring
    will work.[10](#footnote-172) This is also a classic demonstration of two of the
    major, powerful, misunderstood, and unused features of Kubernetes, *labels* and
    *label selectors*.
  prefs: []
  type: TYPE_NORMAL
- en: '[10](#footnote-172-backlink) [https://docs.openshift.com/container-platform/4.7/monitoring/enabling-monitoring-for-user-defined-projects.html](https://docs.openshift.com/container-platform/4.7/monitoring/enabling-monitoring-for-user-defined-projects.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following line means that Prometheus will attempt to retrieve metrics from
    all components that have the label `app.kubernetes.io/component: pet-battle-tournament`.
    We don''t need to list each component independently; we just need to ensure that
    the component has the correct *label*, and that the *selector* is used to match
    that label. If we add a new component to the architecture, then all we have to
    do is ensure that it has the correct label. Of course, all of this assumes that
    the method of scraping the metrics is consistent across all of the selected components;
    that they are all using the `tcp-8080 port`, for example.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re big fans of labels and their associated selectors. They''re very powerful
    as a method of grouping components: Pods, Services, and so on. It''s one of those
    hidden gems that you wish you knew of earlier.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the Metrics in OpenShift
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once we have our metrics retrieved, we need to interpret the information that
    they're conveying about the system.
  prefs: []
  type: TYPE_NORMAL
- en: Querying using Prometheus
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To visualize the metrics, go into the developer console and click on **Monitoring
    (1)**, as shown in *Figure 16.1*. Then click on **Custom Query (2)** in the dropdown,
    and enter a query using the **Prometheus query language (PromQL) (3)**. In the
    following example, we've used the *http_server_requests_seconds_count* metric,
    but there are others as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_16_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.1: PetBattle tournament metrics'
  prefs: []
  type: TYPE_NORMAL
- en: Let's explore some of the built-in dashboards OpenShift provides for monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing Metrics Using Grafana
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OpenShift comes with dedicated Grafana dashboards for cluster monitoring. It
    is not possible to modify these dashboards and add custom application metrics,
    but it is possible to deploy an application-specific Grafana instance and customize
    that as we see fit. To do this, we first need to ensure that the Grafana Operator
    is installed in the namespace that we're using.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will then deploy a custom Grafana setup by deploying the following custom
    resources:'
  prefs: []
  type: TYPE_NORMAL
- en: A *Grafana resource* used to create a custom *grafana* instance in the namespace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A *GrafanaDataSource resource* to pull metrics from the cluster-wide Prometheus
    instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A *GrafanaDashboard* resource for creating the dashboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The good news is that all of this is done via Helm charts, so you just have
    to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: Open `grafana-route` in a browser, log in, *et voila*! It should look something
    like that shown in *Figure 16.2\.* If there is an error with no data, check the
    BEARER_TOKEN is in place. This can be fixed manually by running the commands at
    [https://github.com/petbattle/pet-battle-infra/blob/main/templates/insert-bearer-token-hook.yaml#L80](https://github.com/petbattle/pet-battle-infra/blob/main/templates/insert-bearer-token-hook.yaml#L80)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_16_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.2: PetBattle metrics in Grafana'
  prefs: []
  type: TYPE_NORMAL
- en: We will now take a look at some of the tools that can help us further with observability.
  prefs: []
  type: TYPE_NORMAL
- en: Metadata and Traceability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the adoption of independently deployable services-based architectures,
    the complexity of managing these components and their inter-relationships is becoming
    problematic. In the following sections, we will outline a number of techniques
    that can assist you with this.
  prefs: []
  type: TYPE_NORMAL
- en: Labels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As mentioned earlier, labels and label selectors are among the more powerful
    *metadata management* features of Kubernetes. At its core, labels are a collection
    of text-based key/value pairs that can be attached to one or more objects: Pods,
    services, Deployments, and so on. Labels are intended to add information/semantics
    to objects that are relevant to the user and not the core Kubernetes system. A
    label selector is a method by which a user can group items together that have
    the same labels.'
  prefs: []
  type: TYPE_NORMAL
- en: One of the most common uses of labels and label selectors in Kubernetes is the
    way that services use label selectors to group related Pods as endpoints for the
    service.
  prefs: []
  type: TYPE_NORMAL
- en: It's probably better shown by way of an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s start with our three Infinispan Pods. Given that the Infinispan
    operator deploys its Pods via StatefulSets, the Pod names are pretty straightforward:
    `infinispan-0`, `infinispan-1`, `infinispan-2`. Take note of the labels attached
    to the Pods (highlighted in bold).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: When the Tournament service wants to connect to one of these Infinispan pods,
    it uses the Infinispan service that is also created and managed by the operator.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'If we go into the definition of the service, we''ll see the selector (highlighted
    in bold):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: 'This adds the Pods with the labels `app=infinispan-pod,clusterName=infinispan`
    into the service as endpoints. Two things to note here: the selector didn''t use
    all the labels assigned to the Pod; and if we scaled up the number of Infinispan
    Pods, the selector would be continuously assessed and the new Pods automatically
    added to the service. The preceding example is a pretty basic example of a selector;
    in fact, selectors are far more powerful, with equality- and set-based operations
    also available. Check out the examples in the Kubernetes documentation for more
    information.[11](#footnote-171)'
  prefs: []
  type: TYPE_NORMAL
- en: '[11](#footnote-171-backlink) [https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/)'
  prefs: []
  type: TYPE_NORMAL
- en: Great, so now what? What information could you use to label a resource? It depends
    on what your needs are. As demonstrated previously in the monitoring section,
    labels and selectors can be useful in configuring Prometheus. Labels can also
    be useful in grouping components together, as in the components that comprise
    a distributed application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes has a set of recommended labels[12](#footnote-170) that we''ve used
    when building and deploying the PetBattle application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_Table_16.1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Table 16.1: Kubernetes-recommended labels'
  prefs: []
  type: TYPE_NORMAL
- en: '[12](#footnote-170-backlink) [https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/](https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'With these labels in place, it is possible to retrieve and view the components
    of the application using selectors, such as to show the component parts of the
    PetBattle application without the supporting application infrastructure, that
    is, Infinispan or Keycloak. The following command demonstrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: NAME AGE
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: NAME AGE
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: Let's look at other mechanisms we can use to enhance traceability.
  prefs: []
  type: TYPE_NORMAL
- en: Software Traceability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the issues that we've observed from customers over the years is the reliance
    that people have on the name of the software artifact that they're putting into
    production, such as `super-important-app-1.2.99.0.bin or critical-service-1.2.jar`.
    While this works 99.9% of the time, occasionally we've noticed issues where an
    incorrect version has been deployed with interesting outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: In the land of containers, your deployment is a versioned artifact that contains
    a version of your software, and this in turn may be deployed using a versioned
    Helm chart via a GitOps approach. A good build and deployment pipeline will ensure
    that these levels of artifact versioning will always be consistent and provide
    traceability. As a backup, we also add additional traceability to the deployed
    artifacts as annotations on the resources and build info logging in the application
    binary.
  prefs: []
  type: TYPE_NORMAL
- en: Annotations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Annotations are similar to Kubernetes labels—that is, string-based key/value
    pairs—except that they're not used to group or identify objects via selectors.
    Annotations can be used to store different types of information; in our case,
    we're going to use annotations to store Git information to help with software
    traceability.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: The annotations are automatically added as part of the Maven build process using
    the Quarkus Maven plugin. Also notice the annotations are used to provide scrape
    information for Prometheus, as can be seen highlighted in the preceding code.
  prefs: []
  type: TYPE_NORMAL
- en: Build Information
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An approach that has nothing to do with Kubernetes per se, but we strongly recommend
    to be used in general, is to output source control and build information as part
    of the application startup. An example of this is embedded into the Tournament
    service.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: We use the Maven plugin `git-commit-id-plugin` to generate a file containing
    the Git information and package that file as part of the **Java archive** (**jar**).
    On startup, we simply read this file and output its contents to the console. Very
    simple stuff, but very effective and a lifesaver when needed. When running on
    OpenShift, this information will be picked up by the OpenShift logging components.
  prefs: []
  type: TYPE_NORMAL
- en: Alerting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So we have all the metrics to provide us with some insight into how the system
    is performing. We've got spectacular graphs and gauges in Grafana but we're hardly
    going to sit watching them all day to see if something happens. It's time to add
    alerting to the solution.
  prefs: []
  type: TYPE_NORMAL
- en: What Is an Alert?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An alert is an event that is generated when some measurement threshold (observed
    or calculated) is about to be or has been breached. The following are some examples
    of alerts:'
  prefs: []
  type: TYPE_NORMAL
- en: The average system response time in the last five minutes goes above 100 milliseconds.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of currently active users on the site falls below a certain threshold.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application memory usage is approaching its maximum limit.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alerts usually result in notifications being sent to human operators, whether
    that is through an email or instant message, say. Notifications can also be sent
    to trigger automation scripts/processes to deal with the alert. Service owners
    can analyze their existing alerts to help improve the reliability of their services
    and systems and reduce the manual work associated with remediating problems.
  prefs: []
  type: TYPE_NORMAL
- en: Why Alert?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Alerts call for human action when a situation has arisen within the system that
    cannot be automatically handled. This may include scenarios where automatic resolution
    of the problem is deemed too risky and human intervention is required to help
    triage, mitigate, and resolve the issue. Alerting can also be an issue by causing
    concern for site reliability engineers who manage and operate the system, particularly
    when alerts are numerous, misleading, or don't really help in problem cause analysis.
    They may generate benign alerts that don't prompt any action.
  prefs: []
  type: TYPE_NORMAL
- en: There are certain qualities that make up a *good alert*. Alerts should be actionable
    by the human beings who respond to them. To be actionable, the alert must also
    have arrived in time for something to be done about it and it should be delivered
    to the correct team or location for triaging. Alerts can also include helpful
    metadata such as documentation links to assist in making triage faster.
  prefs: []
  type: TYPE_NORMAL
- en: Alert Types
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can think of alerts as falling into three broad categories.[13](#footnote-169)
    The first are **proactive** alerts, meaning that your business service or system
    is not in danger yet but may be in trouble after some period of time. A good example
    of this is where your system response time is degrading but it is not at a stage
    where external users would be aware of the issue yet. Another example may be where
    your disk quota is filling up but is not 100% full yet, but it may do in a few
    days' time.
  prefs: []
  type: TYPE_NORMAL
- en: A **reactive** alert means your business service or system is in immediate danger.
    You are about to breach a service level and immediate action is needed to prevent
    the breach.
  prefs: []
  type: TYPE_NORMAL
- en: An **investigative** alert is one where your business service or system is in
    an unknown state. For example, it may be suffering a form of partial failure or
    there may be unusual errors being generated. Another example may be where an application
    is restarting too many times, which is indicative of an unusual crash situation.
  prefs: []
  type: TYPE_NORMAL
- en: Each of these alerts may also be directed to different teams, depending on their
    severity. Not all alerts need to be managed with the same level of urgency. For
    example, some alerts must be handled by an on-call human resource immediately,
    while for others it may be fine to handle them during business hours by an application
    business support team the following day. Let's explore how we can easily configure
    and add alerting to our applications using the OpenShift platform features to
    help us out.
  prefs: []
  type: TYPE_NORMAL
- en: '[13](#footnote-169-backlink) [https://www.oreilly.com/content/reduce-toil-through-better-alerting/](https://www.oreilly.com/content/reduce-toil-through-better-alerting/)'
  prefs: []
  type: TYPE_NORMAL
- en: Managing Alerts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OpenShift has platform monitoring and alerting that supports both built-in platform
    components and user workloads. The product documentation is the best place to
    start when looking to configure these.[14](#footnote-168) As we outlined earlier,
    monitoring and alerting make use of the Prometheus monitoring stack. This is combined
    with an open-source tool called Thanos[15](#footnote-167) that aggregates and
    provides access to multiple instances of Prometheus in our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: A basic configuration for the PetBattle application suite consists of creating
    two ConfigMaps for user workload monitoring and alerting. We use ArgoCD and a
    simple kustomize YAML configuration to apply these ConfigMaps using GitOps. If
    we open up the ubiquitous journey `values-day2ops.yaml` file, we can create an
    entry for user workload monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE159]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE163]'
  prefs: []
  type: TYPE_PRE
- en: The next step is to make use of application metrics and a ServiceMonitor and
    configure specific Prometheus alerts for our PetBattle suite.
  prefs: []
  type: TYPE_NORMAL
- en: User-Defined Alerts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the *Metrics* section, we created ServiceMonitors for our API and Tournament
    applications that allow us to collect the micrometer metrics from our Quarkus
    applications. We want to use these metrics to configure our alerts. The simplest
    approach is to browse to the Thanos query endpoint that aggregates all of our
    Prometheus metrics. You can find this in the `openshift-monitoring` project.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE164]'
  prefs: []
  type: TYPE_PRE
- en: '[14](#footnote-168-backlink) [https://docs.openshift.com/container-platform/4.7/monitoring/configuring-the-monitoring-stack.html#configuring-the-monitoring-stack](https://docs.openshift.com/container-platform/4.7/monitoring/configuring-the-monitoring-stack.html#configuring-the-monitoring-stack)'
  prefs: []
  type: TYPE_NORMAL
- en: '[15](#footnote-167-backlink) [https://github.com/thanos-io/thanos](https://github.com/thanos-io/thanos)'
  prefs: []
  type: TYPE_NORMAL
- en: We want to create a simple reactive alert based on whether the PetBattle API,
    Tournament, and UI Pods are running in a certain project. We can make use of Kubernetes
    Pod labels and the Prometheus query language to test whether our Pods are running.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_16_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.3: Thanos query interface'
  prefs: []
  type: TYPE_NORMAL
- en: For this use case, we combine the `kube_pod_status_ready and kube_pod_labels`
    query for each Pod and namespace combination and create a PrometheusRule to alert
    us when a condition is not met. We wrapped the generation of the alerts in a Helm
    chart so we can easily template the project and alert severity values[16](#footnote-166)
    and connect the deployment with our GitOps automation.
  prefs: []
  type: TYPE_NORMAL
- en: '[16](#footnote-166-backlink) [https://github.com/petbattle/ubiquitous-journey/blob/main/applications/alerting/chart/templates/application-alerts.yaml](https://github.com/petbattle/ubiquitous-journey/blob/main/applications/alerting/chart/templates/application-alerts.yaml)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE165]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE166]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE167]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE168]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE169]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE170]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE171]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE172]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE173]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE174]'
  prefs: []
  type: TYPE_PRE
- en: The firing alerts can be seen in the OpenShift web console as seen in *Figure
    16.4*. In this example, we have configured the `labs-dev` alerts to only have
    a severity of *info* because they are not deemed as crucial deployments in that
    environment. The severity may be set as *info, warning*, or *critical*, and we
    use *warning* for our `labs-test` *and* `labs-staging` environments, for example.
    These are arbitrary but standard severity levels, and we can use them for routing
    alerts, which we will cover in a moment.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_16_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.4: PetBattle alerts firing in OpenShift'
  prefs: []
  type: TYPE_NORMAL
- en: We can use the same method to create an investigative or proactive alert. This
    time we wish to measure the HTTP request time for our API application. During
    testing, we found that if API calls took longer than ~1.5 sec, the user experience
    in the PetBattle frontend was deemed too slow by end users and there was a chance
    they would disengage from using the web application altogether.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_16_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.5: Maximum request time alert rule'
  prefs: []
  type: TYPE_NORMAL
- en: In this alert, we use the Prometheus query language and the `http_server_requests_seconds_max`
    metric for the PetBattle API application to test whether the maximum request time
    over the last five-minute period exceeded our 1.5 sec threshold. If this alert
    starts to fire, possible remediation actions might include manually scaling up
    the number of API Pods or perhaps increasing the database resources if that is
    seen to be slow for some reason. In future iterations, we may even try to automate
    the application scale-up by using a Horizontal Pod Autoscaler, a Kubernetes construct
    that can scale our applications automatically based on metrics.
  prefs: []
  type: TYPE_NORMAL
- en: In this way, we can continue to build on our set of alerting rules for our PetBattle
    application suite, modifying them as we run the applications in different environments,
    and learn what conditions to look out for while automating as much of the remediation
    as we can.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift Alertmanager
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we have seen, OpenShift supports three severity levels of alerting: *info*,
    *warning*, and *critical*. We can group and route alerts based on their severity
    as well as on custom labels—that is, project or application labels. In the OpenShift
    administrator console,[17](#footnote-165) you can configure the Alertmanager under
    **Cluster Settings**.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_16_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.6: Alertmanager routing configuration'
  prefs: []
  type: TYPE_NORMAL
- en: Alerts may be grouped and filtered using labels and then routed to specific
    receivers, such as PagerDuty, Webhook, Email, or Slack. We can fine-tune the routing
    rules so that the correct teams receive the alerts in the correct channel, based
    on their urgency. For example, all *info* and *warning* severity alerts for the
    PetBattle UI application may be routed to the *frontend developers* Slack channel,
    whereas all *critical* alerts are routed to the on-call PagerDuty endpoint as
    well as the Slack channel.
  prefs: []
  type: TYPE_NORMAL
- en: '[17](#footnote-165-backlink) [https://docs.openshift.com/container-platform/4.7/monitoring/managing-alerts.html](https://docs.openshift.com/container-platform/4.7/monitoring/managing-alerts.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Alerting is a critical component to successfully manage the operational aspects
    of a system but you should be careful and ensure that the operations team isn't
    overwhelmed with alerts. Too many alerts or many minor or false-positive alerts
    can lead to *alert fatigue*, where it becomes an established practice within a
    team to ignore alerts, thus robbing them of their importance to the successful
    management of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Service Mesh
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Service mesh functionality has been one of the largest additions/extensions
    to Kubernetes in its short history. There's a lot of debate around the additional
    complexity of using a service mesh and whether all the features are even required.
  prefs: []
  type: TYPE_NORMAL
- en: For the purposes of this book, we're going to focus on the service mesh provided
    out of the box within OpenShift, which is based on the open-source Istio project.
    There are other implementations, such as Linkerd, SuperGloo, and Traefik, out
    there that are excellent and offer similar functionality to Istio.
  prefs: []
  type: TYPE_NORMAL
- en: 'The OpenShift service mesh provides the following features out of the box:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Security**: Authentication and authorization, mutual TLS (encryption), policies'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Traffic management**: Resiliency features, virtual services, policies, fault
    injection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Observability**: Service metrics, call tracing, access logs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why Service Mesh?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We previously talked about resiliency and how patterns like circuit breakers
    can help systems recover from downstream failures. A circuit breaker can be added
    in the scope of application code through frameworks such as **SmallRye Fault Tolerance**
    or **Spring Cloud Circuit Breaker** for Java projects; similar frameworks such
    as **Polly**[18](#footnote-164) exist for .NET, **PyBreaker**[19](#footnote-163)
    for Python, and **Opossum**[20](#footnote-162) for Node.js. A key requirement
    for all of these frameworks is that they have to be added to the existing source
    code of the application, and the application needs to be rebuilt. When using a
    service mesh, a circuit breaker is external to the application code and no changes
    are required at the application level to take advantage of this feature.
  prefs: []
  type: TYPE_NORMAL
- en: '[18](#footnote-164-backlink) [https://github.com/App-vNext/Polly](https://github.com/App-vNext/Polly)'
  prefs: []
  type: TYPE_NORMAL
- en: '[19](#footnote-163-backlink) [https://pypi.org/project/pybreaker/](https://pypi.org/project/pybreaker/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[20](#footnote-162-backlink) [https://nodeshift.dev/opossum/](https://nodeshift.dev/opossum/)'
  prefs: []
  type: TYPE_NORMAL
- en: The same is true with **Mutual TLS** (**mTLS**), which is used for encrypting
    traffic between services. Operators such as CertManager or CertUtil can assist
    with managing and distributing certificates, but modification of the application
    code is still required to use the feature. Service meshes simplify this as the
    inter-component traffic is sent via a *sidecar proxy* and functionality such as
    mTLS is *automagically* added to this—once again, without having to change the
    application code.
  prefs: []
  type: TYPE_NORMAL
- en: The Istio component of a service mesh also manages TLS certificate generation
    and distribution so that it helps reduce the management overhead when using mTLS.
  prefs: []
  type: TYPE_NORMAL
- en: So how does a service mesh perform all of this magical functionality? Basically,
    the service mesh operator adds a service proxy container (based on the Envoy project)
    to the application Pod and configures the application traffic to be routed through
    this proxy. The proxy registers with the Istio control plane and configuration
    settings, certificates, and routing rules are retrieved and the proxy configured.
    The Istio documentation goes into much more detail.[21](#footnote-161)
  prefs: []
  type: TYPE_NORMAL
- en: Aside – Sidecar Containers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A common object that people visualize when they hear the word *sidecar* is that
    of a motorbike with a single-wheel passenger car—a *pod*—attached to it. Being
    attached to the bike, the pod goes wherever the bike goes—except in comedy sketches
    where the bike and sidecar separate and rejoin, but that's another subject entirely.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Kubernetes, a sidecar is a container that runs in the same Kubernetes Pod
    as the main application container. The containers share the same network and ICP
    namespace and can also share storage. In OpenShift, when using the service mesh
    functionality, a Pod annotated with the correct annotation `sidecar.istio.io/inject:
    "true"` will have an Istio proxy automatically injected as a sidecar alongside
    the application container. All subsequent communications between the application
    and external resources will flow through this sidecar proxy and hence enable the
    usage of features such as circuit breakers, tracing, and TLS, as and when they
    are needed. As the great Freddie Mercury once said, "*It''s a kind of magic*."'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE175]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE176]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE177]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE178]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE179]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE180]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE181]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE182]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE183]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE184]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE185]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE186]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE187]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE188]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE189]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE190]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE191]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE192]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE193]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE194]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE195]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE196]'
  prefs: []
  type: TYPE_PRE
- en: '[21](#footnote-161-backlink) [https://istio.io/latest/docs/](https://istio.io/latest/docs/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is possible to have more than one sidecar container if required. Each container
    can bring different features to the application Pod: for example, one for Istio,
    another for log forwarding, another for the retrieval of security credentials,
    and so on. It''s easy to know when a Pod is running more than a single container;
    for example, the `READY` column indicates how many containers are available per
    Pod and how many are ready—that is, its readiness probe has passed.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE197]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE198]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE199]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE200]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE201]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE202]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE203]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE204]'
  prefs: []
  type: TYPE_PRE
- en: Be aware, though, that there is a temptation to try and utilize all the service
    mesh features at once, known as the *ooh… shiny* problem.
  prefs: []
  type: TYPE_NORMAL
- en: Here Be Dragons!
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The adoption of a service mesh isn't a trivial exercise when it comes to complex
    solutions with multiple components and development teams. One thing to understand
    about a service mesh is that it crosses a lot of team boundaries and responsibilities.
    It includes features that are focused on the developer, operations, and security
    teams; all of these teams/personnel need to work together to understand and get
    the best out of using the features provided by the mesh. If you're just starting
    out, our advice is to start small and figure out what features are necessary in
    production and iterate from there.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of PetBattle, we decided that we were going to primarily focus on
    using some of the features in the areas of traffic management and observability.
    The rationale behind this was that Keycloak already addressed many of the security
    requirements, and we also wanted to finish the book before the end of the decade.
  prefs: []
  type: TYPE_NORMAL
- en: Service Mesh Components
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The functionality of the service mesh is made up of a number of independent
    components:'
  prefs: []
  type: TYPE_NORMAL
- en: Jaeger and Elasticsearch provide the call tracing functionality and logging
    functionality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kiali provides the mesh visualization functionality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenShift Service Mesh provides the core Istio functionality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The good news is that all of these components are installed and managed by Operators,
    so installation is reasonably straightforward. These components are installed
    via Helm, and if you want to know more about how they are installed, then the
    Red Hat OpenShift documentation will have the relevant details.
  prefs: []
  type: TYPE_NORMAL
- en: One key thing to note is that at the time of writing this book, OpenShift Service
    Mesh ships with a downstream version of Istio called Maistra. This is primarily
    due to the out-of-the-box multi-tenancy nature of OpenShift, as well as limiting
    the scope of Istio cluster-scoped resources. OpenShift Service Mesh also ships
    with an **Istio** **OpenShift Routing** (**IOR**) component that maps the Istio
    gateway definitions onto OpenShift routes. Note that Istio is still the upstream
    project and bugs/feature requests are fixed/implemented, as necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'For traffic management, Istio has the following core set of resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Gateways**: Controls how traffic gets into the mesh from the outside, akin
    to OpenShift routes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Virtual service**: Controls how traffic is routed within the service mesh
    to a destination service. This is where functionality such as timeouts, context-based
    routing, retries, mirroring, and so on, are configured.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Destination rule**: Service location where traffic is routed to once traffic
    rules have been applied. Destination rules can be configured to control traffic
    aspects such as load balancing strategies, connection pools, TLS setting, and
    outlier detection (circuit breakers).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are other resources such as service entry, filters, and workloads, but
    we're not going to cover them here.
  prefs: []
  type: TYPE_NORMAL
- en: PetBattle Service Mesh Resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We'll briefly introduce some of the resources that we use in PetBattle and explain
    how we use them.
  prefs: []
  type: TYPE_NORMAL
- en: Gateways
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The gateway resource, as stated earlier, is used to create an ingress route
    for traffic coming into the service mesh.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE205]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE206]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE207]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE208]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE209]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE210]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE211]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE212]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE213]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE214]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE215]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE216]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE217]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE218]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE219]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE220]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE221]'
  prefs: []
  type: TYPE_PRE
- en: A few things to note with this definition is that it will create an OpenShift
    route in the *istio-system* namespace and not the local namespace. Secondly, the
    route itself will use SSL, but it won't be able to utilize the OpenShift router
    certificates by default. Service mesh routes have to provide their own certificates.
    As part of writing this book, we took the pragmatic approach and copied the OpenShift
    router certificates into the *istio-system* namespace and provided them to the
    gateway via the *pb-ingressgateway-certs* secret. Note that this is for demonstration
    purposes only—*do not try this in production*. The correct approach for production
    is to generate and manage the PKI using as-a-service certificates.
  prefs: []
  type: TYPE_NORMAL
- en: Virtual services
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: PetBattle contains a number of VirtualServices, such as *pet-battle-cats-tls,
    pet-battle-main-tls,* and *pet-battle-tournament-tls.*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE222]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE223]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE224]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE225]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE226]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE227]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE228]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE229]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE230]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE231]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE232]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE233]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE234]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE235]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE236]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE237]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE238]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE239]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE240]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE241]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE242]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE243]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE244]'
  prefs: []
  type: TYPE_PRE
- en: 'The VirtualServices are all similar in function in that they are all configured
    to:'
  prefs: []
  type: TYPE_NORMAL
- en: Match a specific URI; in the example above, `/cats`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once matched, route the traffic to a specific destination.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Handle specific errors by performing a fixed number of request retries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Destination Rule
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, the traffic is sent to a destination or even distributed to a set of
    destinations depending on the configuration. This is where DestinationRules come
    into play.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE245]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE246]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE247]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE248]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE249]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE250]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE251]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE252]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE253]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE254]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE255]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE256]'
  prefs: []
  type: TYPE_PRE
- en: In our example, the traffic sent to a specific port is load balanced based on
    a simple strategy that selects the Pod with the least number of active requests.
    There are many load balancing strategies that can be used here, depending on the
    needs of the application—everything from simple round robin to advanced consistent
    hashing load balancing strategies, which can be used for session affinity. As
    ever, the documentation goes into far greater detail.[22](#footnote-160)
  prefs: []
  type: TYPE_NORMAL
- en: 'We can visualize the flow of traffic from the above example, as seen in *Figure
    16.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_16_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.7: PetBattle traffic flow'
  prefs: []
  type: TYPE_NORMAL
- en: '[22](#footnote-160-backlink) [https://istio.io/latest/docs/](https://istio.io/latest/docs/)'
  prefs: []
  type: TYPE_NORMAL
- en: Note that *Figure 16.7* shows an example of how destination rules can be used
    to send traffic to an alternative version of the service. This can be useful for
    advanced deployment strategies such as Canary, Blue/Green, and so on. We haven't
    discussed how to do this with OpenShift Service Mesh in this book, but the reader
    is encouraged to explore this area in more detail. A good place to start is the
    aforementioned Istio documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Managing all of these resources is reasonably simple when it's just a few services,
    and PetBattle utilizes service mesh functionality in a very basic manner. However,
    when there are many services and features, such as multiple destinations used
    in advanced deployment models, the amount of settings and YAML to interpret can
    be overwhelming. This is where mesh visualization functionality can be useful
    to visualize how all of this works together. For this, we use the Kiali functionality,
    which is part of OpenShift Service Mesh. *Figure 16.8* shows how PetBattle is
    visualized using Kiali.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_16_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.8: Kiali service graph for PetBattle'
  prefs: []
  type: TYPE_NORMAL
- en: Kiali can be very useful for diagnosing the current state of the mesh, as it
    can dynamically show where traffic is being sent as well as the state of any circuit
    breakers being used. It also integrates with Jaeger for tracing requests across
    multiple systems. Kiali can also help prevent configuration issues by semantically
    validating the deployed service mesh resources.
  prefs: []
  type: TYPE_NORMAL
- en: Next we're going to explore one of the most powerful features of OpenShift 4
    - Operators.
  prefs: []
  type: TYPE_NORMAL
- en: Operators Everywhere
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fundamental to the OpenShift 4 platform is the concept of *Operators*. So far,
    we have used them without talking about why we need them and what they actually
    represent on a Kubernetes platform such as OpenShift. Let's cover this briefly
    without totally rewriting the book on the subject.[23](#footnote-159)
  prefs: []
  type: TYPE_NORMAL
- en: At its heart, the Operator is a software pattern that codifies knowledge about
    the running and operation of a particular software application. That application
    could be a distributed key value store, such as etcd. It might be a web application
    such as the OpenShift web console. Fundamentally, the operator can represent *any*
    application domain that could be codified. A good analogy for an operator is the
    *expert system*, a rules-based bit of software that represents knowledge about
    a certain thing that is put to work in a meaningful way. If we take a database
    as an example, the Operator might codify what a real human database administrator
    does on a day-to-day basis, such as the deployment, running, scaling, backup,
    patching, and upgrading of that database.
  prefs: []
  type: TYPE_NORMAL
- en: The physical runtime for an operator is nothing more than a Kubernetes Pod,
    that is, a collection of containers that run on a Kubernetes platform such as
    OpenShift. Operators work by extending or adding new APIs to the existing Kubernetes
    and OpenShift platform APIs. This new endpoint is called a **Custom Resource**
    (**CR**). CRs are one of the many extension mechanisms in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_16_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.9: The Operator pattern'
  prefs: []
  type: TYPE_NORMAL
- en: '[23](#footnote-159-backlink) [https://www.redhat.com/en/resources/oreilly-kubernetes-operators-automation-ebook](https://www.redhat.com/en/resources/oreilly-kubernetes-operators-automation-ebook)'
  prefs: []
  type: TYPE_NORMAL
- en: A **Custom Resource Definition** (**CRD**) defines what the CR is. Think of
    it as the definition or schema for the CR. The Operator Pod *watches* for events
    on the platform that are related to their custom resources and takes *reconciliation*
    actions to achieve the desired state of the system. When an Operator Pod stops
    or is deleted from the cluster, the application(s) that it manages should continue
    to function. Removing a CRD from your cluster does affect the application(s) that
    it manages. In fact, deleting a CRD will in turn delete its CR instances. This
    is the Operator pattern.
  prefs: []
  type: TYPE_NORMAL
- en: With Operators, all of the operational experience required to run/manage a piece
    of software can be packaged up and delivered as a set of containers and associated
    resources. In fact, the whole of the OpenShift 4 platform exists as a collection
    of operators! So, as the platform owner, you are receiving the most advanced administrator
    knowledge bundled up through Operators. Even better, Operators can become more
    advanced over time as new features and capabilities are added to them. A good
    understanding of how to configure Operators is required for OpenShift platform
    administrators. This usually involves setting properties in the OpenShift cluster
    global configuration web console, setting CR property values, using ConfigMaps,
    or similar approaches. The product documentation[24](#footnote-158) is usually
    the best place to find out what these settings are for each Operator.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16297_16_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16.10: OpenShift Cluster Settings—configuring platform Operators'
  prefs: []
  type: TYPE_NORMAL
- en: '[24](#footnote-158-backlink) [https://docs.openshift.com/container-platform/4.7](https://docs.openshift.com/container-platform/4.7)'
  prefs: []
  type: TYPE_NORMAL
- en: In OpenShift, the lifecycle management (upgrading, patching, managing) of Operators
    themselves is automated through the **Operator Lifecycle Manager** (**OLM**).
    These components make upgrading the OpenShift platform itself a lot more reliable
    and easier to manage from a user's perspective; it massively reduces the operational
    burden. Because Operators themselves are delivered as versioned images, we get
    the same benefits from immutable container images that we do for our own applications,
    i.e., the same image version can be run consistently in multiple cloud environments
    increasing quality and eliminating snowflakes (unique applications for unique
    environments).
  prefs: []
  type: TYPE_NORMAL
- en: And it is not just the OpenShift platform itself that can take advantage of
    Operators. The sharing and distribution of software using Operators via the Operator
    Hub[25](#footnote-157) is open to software developers and vendors from all over
    the world. We use OLM and Operator *subscriptions* to deploy these into our cluster.
    The tooling required to build and develop Operators (the SDK) is open source and
    available to all.[26](#footnote-156)
  prefs: []
  type: TYPE_NORMAL
- en: So, should *all* applications be delivered as Operators? The short answer is
    no. The effort required to code, package, test, and maintain an Operator may be
    seen as overkill for many applications. For example, if your applications are
    not being distributed and shared with others, and you only need to build, package,
    deploy, and configure your application in a few clusters, there are many simpler
    ways this can be achieved, such as using container images, Kubernetes, and OpenShift
    native constructs (BuildConfigs, Deployments, ReplicaSets, ConfigMaps, Secrets,
    and more) with tools such as Helm to achieve your goals.
  prefs: []
  type: TYPE_NORMAL
- en: Operators Under the Hood
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To fully understand how operators work, you need to understand how the Kubernetes
    control loop works.
  prefs: []
  type: TYPE_NORMAL
- en: Control Loops
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In very basic terms, core Kubernetes is just a **Key-Value** (**KV**) store—an
    etcd datastore with an API. Processes use this API to perform **Create**, **Read**,
    **Update**, and **Delete** (**CRUD**) actions on keys within the KV store. Processes
    can also register with the KV store to be notified when there are value changes
    to keys or sets of keys that they're interested in.
  prefs: []
  type: TYPE_NORMAL
- en: '[25](#footnote-157-backlink) [https://operatorhub.io](https://operatorhub.io)'
  prefs: []
  type: TYPE_NORMAL
- en: '[26](#footnote-156-backlink) [https://github.com/operator-framework/operator-sdk](https://github.com/operator-framework/operator-sdk)'
  prefs: []
  type: TYPE_NORMAL
- en: When these processes get a change notification, they react to that notification
    by performing some activity, such as configuring iptables rules, provisioning
    storage, and so on. These processes understand the current state of the system
    and the desired state and work toward achieving that desired state. In other words,
    these processes are performing the role of a *control loop*, meaning they attempt
    to bring the state of the system to a desired state from where it currently resides.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the *process* is a controller that observes the state of a
    resource or set of resources and then makes changes to move the resource state
    closer to the desired state. As consumers of Kubernetes, we constantly use controllers.
    For example, when we instruct Kubernetes to deploy a Pod, the Pod controller works
    to make that a reality. Control loops are key to the operation on Kubernetes and
    it's a declarative and, eventually, consistent approach. For much more information,
    take a look at the Kubernetes Controller docs[27](#footnote-155) and the OpenShift
    blog site for recommendations on how to build your own Operator.[28](#footnote-154)
  prefs: []
  type: TYPE_NORMAL
- en: Operator Scopes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Operators can either be cluster-scoped or namespace-scoped. A cluster-scoped
    operator is installed once in a namespace and can create and manage resources
    in other namespaces; that is, cluster-wide. The OpenShift service mesh operator
    and its related operators such as Kiali and Jaeger are cluster-scoped. They are
    installed by default into the `openshift-operators` or `openshift-operators-redhat`
    namespace and create and manage resources when a related CRD is deployed in another
    namespace, such as PetBattle.
  prefs: []
  type: TYPE_NORMAL
- en: A namespace-scoped operator is one that is deployed in a namespace and only
    manages resources in that namespace. We use a number of these in PetBattle, such
    as Cert-Utils and Keycloak.
  prefs: []
  type: TYPE_NORMAL
- en: All Operators are installed via a CRD called a **Subscription**. Without going
    into too much detail (see the official documentation for more), a Subscription
    describes how to retrieve and install an instance of an operator. The following
    is an example of a Subscription that we use to install the Grafana operator.
  prefs: []
  type: TYPE_NORMAL
- en: '[27](#footnote-155-backlink) [https://kubernetes.io/docs/concepts/architecture/controller/](https://kubernetes.io/docs/concepts/architecture/controller/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[28](#footnote-154-backlink) [https://www.openshift.com/blog/kubernetes-operators-best-practices](https://www.openshift.com/blog/kubernetes-operators-best-practices)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE257]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE258]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE259]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE260]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE261]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE262]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE263]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE264]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE265]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE266]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE267]'
  prefs: []
  type: TYPE_PRE
- en: To see some of the namespace-scoped operators that PetBattle needs, run the
    following command.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE268]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE269]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE270]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE271]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE272]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE273]'
  prefs: []
  type: TYPE_PRE
- en: Let us now take a look at how operators can be used by our PetBattle team.
  prefs: []
  type: TYPE_NORMAL
- en: Operators in PetBattle
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We use operators to create and manage resources such as Infinispan cache and
    Keycloak SSO instances. We simply install the Infinispan operator and deploy a
    relevant custom resource to tell it to create and manage a replicated cache. We
    don't have to know about spinning up Infinispan Pods or creating SSL certificates
    or provisioning storage space. The operator will do all of this for us, and if
    something fails or is accidentally deleted, the operator will look after the recreation
    of the resource. In the Infinispan example, if we delete the Infinispan K8s service,
    the operator will be notified about its deletion and recreate the service automatically.
    As developers, we don't have to worry about managing it.
  prefs: []
  type: TYPE_NORMAL
- en: It is simpler to think of Operators as *looking after stuff so you don't have
    to*. It is also possible to use multiple operators in combination to automate
    complex workflows. For example, we use Keycloak for its SSO gateway and user management
    functionality. The Keycloak instance is deployed and managed via a Keycloak Operator.
    We just need to build and send a custom resource to the API and the operator will
    do the rest. One of the resources managed by the Operator is a Kubernetes Secret
    that contains the TLS certificates and keys, which clients interacting with the
    Keycloak instance will need to use. Given that Keycloak is the security gateway
    to our application, it is prudent to ensure that all communications are encrypted.
    However, this causes issues for Java-based applications; to use SSL, the JVM requires
    that it be provided with a Java TrustStore containing the SSL/TLS certificates
    and keys so that the JVM can trust them.
  prefs: []
  type: TYPE_NORMAL
- en: So, how do we take the Secret with the TLS certificates and keys and convert
    that into a TrustStore that the Java applications can use? We could do a whole
    heap of scripting with Bash, the Java Keytool, and potentially other tools to
    extract the certs/keys, creating the TrustStore, converting, and finally injecting
    the certs/keys into said TrustStore. This is manual, complex, and error-prone
    work. We will also have to recreate these TrustStores for each environment and
    handle lifecycle events such as certificate expiry.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, we could use an operator, in this case, the *Cert-Utils* operator.
    We first install the *Cert-Utils* operator in the PetBattle namespace. This Operator
    was developed by the Red Hat Consulting PAAS Community of Practice[29](#footnote-153)
    to help manage certificates and JVM Keystores, along with TrustStores.
  prefs: []
  type: TYPE_NORMAL
- en: To use this Operator, we first create a ConfigMap containing a set of specific
    annotations. The Cert-Utils operator will detect these annotations and create
    a TrustStore containing the relevant certificates and keys; it will also add the
    TrustStore to the ConfigMap. Finally, we can mount the ConfigMap into a Deployment
    and instruct the JVM to use that TrustStore. The following resource definition
    will create the TrustStore with the relevant certificates and keys.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE274]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE275]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE276]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE277]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE278]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE279]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE280]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE281]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE282]'
  prefs: []
  type: TYPE_PRE
- en: '[29](#footnote-153-backlink) [https://github.com/redhat-cop/cert-utils-operator](https://github.com/redhat-cop/cert-utils-operator)'
  prefs: []
  type: TYPE_NORMAL
- en: 'This does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The `service.beta.openshift.io/inject-cabundle` annotation will inject the service
    signing certificate bundle into the ConfigMap as a `service-sa.crt` field.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `cert-utils-operator.redhat-cop.io` annotation will create the Java TrustStore
    in the ConfigMap under the name `truststore.jks` with the `jkpassword` password.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the Tournament service, the following Quarkus configuration will mount the
    `java-truststore` ConfigMap and configure the JVM accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE283]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE284]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE285]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE286]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE287]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE288]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE289]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE290]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE291]'
  prefs: []
  type: TYPE_PRE
- en: We've only just scratched the surface of operators. OpenShift ships with a number
    of supported operators and there are many community operators available as well.
    We used many community-based operators in this book, such as the Infinispan operator
    and Keycloak operator; there are productized versions of these operators available
    as well. There are many more operators from multiple vendors available from OperatorHub.[30](#footnote-152)
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible to write your own operators if required. The OperatorFramework[31](#footnote-151)
    is an open-source SDK with which you can write your own operators using either
    Go, Ansible, or Helm.
  prefs: []
  type: TYPE_NORMAL
- en: '[30](#footnote-152-backlink) [https://operatorhub.io/](https://operatorhub.io/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[31](#footnote-151-backlink) [https://operatorframework.io/](https://operatorframework.io/)'
  prefs: []
  type: TYPE_NORMAL
- en: Service Serving Certificate Secrets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Keycloak uses an OpenShift feature called *service serving certificate secrets*.[32](#footnote-150)
    This is used for traffic encryption. Using this feature, OpenShift automatically
    generates certificates signed by the OpenShift certificate authority and stores
    them in a secret. The application, in this case Keycloak, can then mount this
    secret and use these certificates to encrypt traffic. Any application interacting
    with a Keycloak instance then just has to trust these certificates. OpenShift
    also manages the lifecycle of these certificates and automatically generates new
    certificates when the existing certificates are about to expire.
  prefs: []
  type: TYPE_NORMAL
- en: 'To turn on this feature, simply add the following annotation to a service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE292]'
  prefs: []
  type: TYPE_PRE
- en: 'In the case of Keycloak, the operator does this as part of its processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE293]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE294]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE295]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE296]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE297]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE298]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE299]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE300]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE301]'
  prefs: []
  type: TYPE_PRE
- en: 'The secret contains the actual certificate and associated key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE302]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE303]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE304]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE305]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE306]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE307]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE308]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE309]'
  prefs: []
  type: TYPE_PRE
- en: '[32](#footnote-150-backlink) [https://docs.openshift.com/container-platform/4.7/security/certificates/service-serving-certificate.html](https://docs.openshift.com/container-platform/4.7/security/certificates/service-serving-certificate.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'And it contains the certificate details as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE310]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE311]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE312]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE313]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE314]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE315]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE316]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE317]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE318]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE319]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE320]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE321]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE322]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE323]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE324]'
  prefs: []
  type: TYPE_PRE
- en: Such Operator patterns simplify the burden of running complex middleware infrastructure
    applications on the OpenShift platform.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To be able to successfully run your software at scale in production, a good
    understanding of the instrumentation that surrounds the software stack is required.
    OpenShift is a modern platform that provides all of the capabilities required
    to observe and, in a lot of cases, automatically heal your applications while
    they're running.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we have discussed many common technical patterns that allow
    application developers to make use of these common platform capabilities. For
    example, one of the simplest patterns is to always log to STDOUT so the platform
    logging mechanisms can be leveraged. With containers, it becomes an antipattern
    to log to specific files mounted in a temporary filesystem within your container,
    because they are not clearly visible.
  prefs: []
  type: TYPE_NORMAL
- en: More complex patterns are also important to keep your business service applications
    running, even during disruption and change. Correctly configuring liveness, readiness,
    and startup probes so that your application can deploy without loss of service,
    configuring Pod disruption budgets for when nodes are restarted. Using application
    features to expose Prometheus metric endpoints for alerting and monitoring on
    the platform is a great way to alert teams when human interaction is required.
  prefs: []
  type: TYPE_NORMAL
- en: 'The service mesh is an advanced extension to OpenShift, extrapolating many
    features that would have traditionally been packaged into your applications so
    they can be more efficiently managed at the platform level. This is a common theme:
    taking application and development cross-cutting features and leveraging them
    to the benefit of all platform services.'
  prefs: []
  type: TYPE_NORMAL
- en: The Operator pattern eases the operational burden of running complex middleware
    infrastructure applications on the OpenShift platform, packaging all the years
    of expert knowledge as software. It is no secret that OpenShift itself uses this
    fantastic pattern for all of its core capabilities. The real power comes in being
    able to lifecycle manage this complexity in an automated manner. Human toil is
    massively reduced because the system can self-heal and auto-upgrade without interference.
    Doing more with less is still the name of the game.
  prefs: []
  type: TYPE_NORMAL
- en: As a cross-functional product team, once you have learned and mastered these
    capabilities, it really does become possible to *give the developers the pagers*.
    The quality of any business service delivery starts with business discovery, which
    then transitions to application software, expands through to platform capabilities,
    and finally on and out into the world of networking and end user devices connected
    via the internet. Once developers and cross-functional product teams are empowered
    to build, run, and own their software—in every environment that it is required
    to run in—only then will they fully equate and connect happy customers with the
    software supply chain that they code, automate, and continuously deliver.
  prefs: []
  type: TYPE_NORMAL
