<html><head></head><body>
		<div>
			<h2 class="introHdg"><a id="_idTextAnchor069"/>Introducing Sean Hull</h2>
			<p class="intro"><a id="_idTextAnchor070"/>A seasoned industry advisor, author, speaker, and entrepreneur with over 20 years' of experience, Sean Hull specializes in DevOps cloud automation, scalabili<a id="_idTextAnchor071"/>ty, Docker, and Kubernetes. His experience scales from small start-ups to Fortune 500 companies. You can follow him on Twitter at <code class="inline">@hullsean</code>.</p>
			<h2 class="introHdg">Sean Hull and the world of databases</h2>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: To kick things off, tell us a little bit about yourself and how you got involved in DevOps.</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: I'm based in New York, and I've been working in technology and alongside start-ups for over a decade. I got my start back when I did database work, scalability, and performance tuning for high-scale websites, such as the <em class="italics">Hollywood Reporter</em> and <em class="italics">Billboard</em>, sites that got a hundred million unique visitors per month. Back when Amazon started getting bigger, a lot of start-up companies were either migrating to the cloud or natively deploying their applications in the cloud, and so I saw an opportunity there to specialize in automation.</p>
			<p class="normal indent end">My background really is in Unix and Linux, and so it was a good match for me to shift gears and pivot in that direction, but I still do a lot of database-related work with MySQL, Postgres, and Redshift. These days I also do a lot of Python programming and all the automation stuff like CloudFormation and Terraform, which allows you to script all the objects in your cloud or in your AWS account, and that in turn allows you to version all the changes that you're making.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: I always get asked the same question in every talk I do: what do we do with databases?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: I read articles sometimes about people trying to put MySQL databases inside of a Docker container and the horrible performance that results, so that's absolutely a good question. A lot of the types of things that automation attempts to remedy with repeatability and so forth don't necessarily apply equally to databases. For instance, if you have a large MySQL database made up of users and activity, those tables have evolved over time. I mean, you have inserts, you have deletes, and the database tunes and optimizes a lot of that I/O to the disk based on usage.</p>
			<p class="normal indent end">Now, if you were to go ahead and rebuild that database, the layout on the disk would be different. So, the presumption is that a rebuilt database is exactly the same as the other, which isn't necessarily the case. In microservices, when you do a backup, you have to either version or timestamp all of those backups, and then the question arises of how do you restore across your entire application at a particular point in time. It might potentially become much more difficult when you have 10 microservices databases if you wanted to restore them all.</p>
			<h2 class="introHdg">Dev versus Ops – how to define DevOps</h2>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: Moving on to a more general subject, how would you define DevOps? I've gotten a different answer from every single person I've asked.</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: I have a lot of opinions about it actually. I wrote an article on my blog a few years ago called <em class="italics">The Four-Letter Word Dividing Dev and Ops</em>, with the implication being that the four-letter word might be a swear word, akin to the development team swearing at the operations team, and the operations team swearing at the development team. But the four-letter word I was referring to was "risk."</p>
			<p class="normal indent">To summarize my article, in my view, the development and the operations teams of old were separate silos in business, and they had very different mandates. Developers are tasked with writing code to build a product and to answer the needs of the customers, while directly building change into and facilitating a more sophisticated product. So, their thinking from day to day is about change and answering the requirements of the products team.</p>
			<p class="normal indent">On the other hand, the operations team's mandate is stability. It's "I don't want these systems going down at 2:00 a.m." So, over the long term, the operations teams are thinking about being as conservative as possible and having fewer moving parts, less code, and less new technologies. The simpler your stack is, the more reliable it is and the more robust and less likely it is to fail. I think the traditional reason why developers and operations teams were separated into silos was because of those two very different mandates.</p>
			<p class="normal indent end">They're two different ways of prioritizing your work and your priorities when you think about the business and the technology. However, the downside was that those teams didn't really communicate very well, and they were often at each other's throats, pushing each other in opposite directions. But to answer your question, "What is DevOps?," I think of it as a cultural movement that has made efforts to allow those teams to communicate better, and that's a really good thing.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: What about infrastructure?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: What I see happening is that as the infrastructure code has caught on, a lot of companies don't have operations at all, or DBAs, or even operations teams. All they have are developers. That's fine insofar as you can build the infrastructure, but we've lost some of that mindset of stability, reliability, and the conservative thinking that would have come out of the operations teams. And now everything is on a developer's shoulders to not only write the code but often to deploy the infrastructure as well.</p>
			<p class="normal indent end">In larger companies, there is a separate DevOps team, so hopefully, they still carry some of those operations, but I'm thinking in terms of keeping things simple. "What is DevOps?" is an interesting question. I think it means different things to different people.</p>
			<div>
				<div class="qtFrm" id="_idContainer163">
					<p class="qt">"It [DevOps] means different things to different people."</p>
					<p class="qt">—Sean Hull</p>
				</div>
			</div>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: I agree. Everybody has a different answer, so nobody knows what it is. What you just said leads me to an interesting, or rather horrifying—I don't know which—case that I once heard. I was speaking with a guy who said, "Oh I love that. That's really interesting for us because if we implement the serverless approach, we can get rid of all the operations because we would have no servers." What do you think of that?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: Actually, that's a great question, but it's a bit more complicated than that. I wrote an article called <em class="italics">The 30 Questions To Ask a Serverless Fanboy</em> where I talked in-depth about the question of whether we have to worry about anything if we're serverless. While being serverless definitely does simplify operations, there's still a lot to be mindful of. For instance, in a serverless framework, you may have one service to do authentication, and another, let's say DynamoDB or Firebase, as your data store. And then you have your Lambda functions that are running. As you add more components into the mix, you have more surface areas that become vulnerable to malicious code.</p>
			<p class="normal indent">For example, in the traditional three-tier, the database is hidden behind a VPC. But in serverless, that database is on the internet, so how do you test and deploy your API gateway changes? In a traditional application, you have the web server, and you deploy your application code and so forth—while in serverless, you have to deploy the API gateway configuration.</p>
			<p class="normal indent end">For Lambda, there's a serverless framework that takes a serverless YAML file that you can configure the API gateway for and then when you deploy it, it will do all that for you using CloudFormation. But testing is another area that's more complex in serverless applications. You can test locally to some degree, but it's quite a bit different than testing an application that runs with the database on which you can run those web servers and databases locally.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: But with serverless, you're typically tying into a database somewhere else, so where do you run that development database?</p>
			<p class="normal end"><strong class="bold">Sean Hull</strong>: You may not be able to have all those components running locally, because it turns out the serverless framework has built stubs to provide Amazon-types of resources running locally on your computer. In terms of the management of a serverless framework, I definitely think that serverless simplifies certain things but makes other things more complex.</p>
			<h2 class="introHdg">Exploring serverless functions, SQL, and the cloud</h2>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: How do you load-test serverless functions?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: You're paying every time that function is called, so do you really want to load-test it on a hundred thousand customers? I don't know. Then, there are timeout questions. You have resource limitations across your AWS account, so maybe you're going to hit a wall because you can only run a certain number of Lambda functions for the month, or you have 10 Lambda functions, and one function runs off the rails, which then takes all the other ones offline because you've hit some resource limit.</p>
			<p class="normal indent end">I think that there are still things to manage, for sure. I think that DevOps, infrastructure as code, and serverless have changed the nature of systems administration, site reliability engineers, and operational engineers. It changes their day-to-day jobs, but I still think there's a lot of work to do.</p>
			<div>
				<div class="qtFrm" id="_idContainer164">
					<p class="qt">"DevOps, infrastructure as code, and serverless have changed the nature of systems administration, site reliability engineers, and operational engineers."</p>
					<p class="qt">—Sean Hull</p>
				</div>
			</div>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: How can we integrate database processes with all the automation that we're doing?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: Database management is quite a bit more complex than automating, say, a web server deployment, a caching server, Memcached, Redis, or even a search server or any of the other types of components. There's definitely more complexity. Another thing too with continuous integration is that your code is often deployed with code that affects the database.</p>
			<p class="normal indent">For example, maybe you have a user's table, and a cell phone number, and you want to add a work phone number. So, you write the code around that, and then you write the DDL, the SQL statements that add the column, and you deploy those together, with the Python or Node.js code along with SQL. Those are called migrations. So, you're migrating the version of the database forward in time so that now that table can support that additional column.</p>
			<p class="normal indent">The thing is, migration scripts typically include a roll forward and a roll backward script. But with a database, you can see how with code that's no problem. You roll back to an older version. That's not a big deal. However, if you roll back the database now, you may have data in that additional column. </p>
			<p class="normal indent">If you've just added a work phone number, and maybe 10,000 of your users added their work phone numbers, if you roll back, you would drop that column and lose the data.</p>
			<p class="normal indent end">In some cases, roll forward and rollback scripts are managed by a DBA or somebody who's tasked with managing the database. But if you're an enterprise who's built your own application, then you don't have the luxury of that. Maybe you write your code blindly, and it drops the column, and you lose data? That's just another example of how the automation that we do in other parts of the enterprise doesn't necessarily always work the same way around with the database tier.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: As I said, it's not my expertise, but I always have the impression that I would prefer not to have a rollback feature at all rather than having people relying on such a thing with databases. It seems more dangerous than actually having any real value. The moment that the first transaction enters your system, how do you roll back? You can't.</p>
			<p class="normal end"><strong class="bold">Sean Hull</strong>: That's definitely a complicated question, and one that lots of folks have thought about. But at the same time, it used to be that database schema changes were done sort of ad hoc, in that you'd hand the script to the DBA and say, "Hey, add these columns," and it was not tightly bound to the version control system, because it's hard to do that. Databases don't have versioned schemas—at least MySQL and Postgres don't—and as far as I know, Redshift doesn't either. So, at this point, they're not really supporting that.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: Do you have a preferred tool, or just plain SQL, when you're doing migrations?</p>
			<p class="normal end"><strong class="bold">Sean Hull</strong>: Some languages support that. For example, Ruby has migrations built in, so when you're making code changes you can also deploy SQL. The response is that those chunks of SQL DDL (data definition language) commands are then set alongside the other branches of code, so that when you check out a particular version of the application, you're also checking out a version of the database.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: How about zero-downtime deployments of applications, where people are using a blue-green deployment or rolling updates, which effectively means that you will have multiple versions of your application running at the same time. How do you handle that on a database level?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: That's another good question. A lot of companies are using Amazon Relational Database Service (RDS) now. It's a managed MySQL, Postgres, or Oracle, and because it's managed, you don't have access to the command line, or to the server itself.</p>
			<p class="normal indent">A few years back, I was working for a company called ROBO, and I had to do a database upgrade of RDS. With a MySQL installation, you log into the command line, and you have direct access to the MySQL instance. With this, you can restart it in a matter of seconds, and with replication you can have two masters. One is read-only, and you're replicating data back and forth so that you can do both zero-downtime deployments and zero-downtime upgrades while having the database set in read-only mode for a very short period of time.</p>
			<p class="normal indent end">My experience in trying to upgrade RDS was that it took at least five minutes to restart after the upgrade and we didn't really have much visibility in terms of what was going on behind the scenes because Amazon controlled the server. We only had access to the MySQL database; we didn't have access to the instance, so we couldn't really see what the status of that restart and that upgrade was, and whether it was held up by something such as corrupted data.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: So, how did you deal with that?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: We ran through a number of fire drills, and created the database on another AWS account, then upgraded it and timed it to see how long it took. It's a very cumbersome way to go about upgrading a database, and not only was it not zero downtime, it was in fact guaranteed downtime. There was no real way to avoid that. For some start-ups it's worth it because you have this managed solution: the database is always running, you have a dashboard, and you can see what's going on.</p>
			<p class="normal indent end">However, if you don't have a database expert around to manage your database, it's a lot simpler. But if you do have a DBA, it's much better to roll your own MySQL or Postgres and manage it because you can reduce your downtime quite a bit.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: How about the other case? Let's say we're not upgrading the database, but instead, are rolling out a new release of an application that speaks to the database and potentially changes the schema. In that case, we would have two releases of an application that potentially requires a different schema. Let's say that release 1 and release 2 introduced a new column. Do you have any suggestions about how to handle that?</p>
			<p class="normal end"><strong class="bold">Sean Hull</strong>: Yes, so the migration scripts that I was talking about before, alongside your code changes; so, when you check out that newer version of the application, you would also check out a newer version of the SQL and the DDL statements that add that column. So, if you're starting from scratch, you would start from a database dump and then apply all the migration scripts that point to that.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: Would those changes need to be backward-compatible with the previous version of the application, or would you just go straight ahead with a new schema?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: Usually you're rolling forward. If you were to go backward, you may or may not need to apply the dropped column because, for example, in the case where I described before, we added the user's cell phone and work phone numbers. If you go back to a previous version of the application, it just won't access the work phone.</p>
			<p class="normal indent end">It won't be a problem if that extra column is there, except in one particular case if you do <code class="inline">select *</code> in your application, and the <code class="inline">select *</code> is very frowned upon for exactly that reason. If you're selecting star and you change the database columns, you're going to get a different number of columns back, and your code could break. You never want to use a select star; you want to specify all the columns that you're accessing.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: Definitely. So, in your experience, when companies you've worked with are migrating to the cloud, what would you identify as the biggest problem that's waiting around the corner for them?</p>
			<div>
				<div class="qtFrm" id="_idContainer165">
					<p class="qt">"I think the biggest obstacle is cultural; everything is done completely differently in the cloud now."</p>
					<p class="qt">—Sean Hull</p>
				</div>
			</div>
			<p class="normal"><strong class="bold">Sean Hull</strong>: I think the biggest obstacle is cultural; everything is done completely differently in the cloud now. In the traditional computing world, you have physical servers where you set up the server, you give it a name, plug it into your network, and you configure all those things the same way you would in the real world. It's almost like physical things have names.</p>
			<p class="normal indent end">Before we had managed hosting, people had a cage or a closet in their business, and you could physically see the machine to plug a cable into. But in the cloud, everything's virtualized, and that ends up being a completely new paradigm that doesn't only challenge the business people, it also challenges the technology people to think in a new way.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: You say challenges, like security?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: Yes, let's take security. In AWS, you have VPCs, and it's like virtual networking, so you can set up private and public subnets, and you can control access to servers inside of those subnets through two methods: one being security groups, and the other being access control lists. That's very different from the way you would control access to servers in the old world where you need to have a firewall, which the networking team manages and configures, and/or you would have a firewall on each server like, for example, iptables.</p>
			<p class="normal indent">In the Amazon world, it's definitely as sophisticated, but the configuration of those firewalls is in the form of security groups and ACLs on your VPC, so its virtualized networking is very powerful, but it's also very complex and troubleshooting is difficult. When you try to access the server, and you get no response, and you're trying to figure out what could be the cause of that through debugging and troubleshooting, those problems are big challenges.</p>
			<p class="normal indent end">But back to your question, the biggest challenge to migrating to the cloud is that for enterprises, there's a big learning curve, not only in understanding how an EC2 server spins up and how it uses disk, but how it accesses Amazon's Elastic Block Store (EBS), how it stores files in S3, and how you write Lambda functions that respond to events taking action in that environment. It's a completely new paradigm and a new set of technologies, so it's a big learning curve for both the engineers and the business folks.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: I've seen quite a few of these tools that tell you if you buy our tool, we're going to transfer whatever you have to the cloud. For example, Docker announced in the last DockerCon that they're going to put in containers without a single change and everything will work. What do you think about that?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: Salespeople often simplify things quite a bit in order to sell a product; in my experience, the devil is in the detail. It's not to say that an automation tool like that might not be valuable and useful. It might be a good first step to getting your application in the cloud, and it might be an easier way than to rebuild everything one by one. But I doubt that it's going to work magically just with one script.</p>
			<p class="normal indent end">EC2 instances, for example, have different performance characteristics, not only in terms of the disk I/O, memory, and CPU, but in smaller instances, they actually throttle network access so you might spin up an instance and it just might not behave well. It might take time. In fact, all sorts of things could happen. You might have written MySQL scripts that assume you have root access to the server and then you rebuild that in an RDS and you get errors because you don't have access to those resources on the RDS. There's a lot of things to consider.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: How about applications? Say I'm a company and I have OpenFrame applications that were developed in the last 10 years. Does that require some kind of changing paradigm or architecture? What are your thoughts on that?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: It may. For example, a lot of applications might use shared storage. Amazon now has something called Elastic File System (EFS), which is meant to mirror the functionality that you see in traditional datacenters. But really, the right way to do it is to store your assets and your content on S3, but S3 didn't exist in those old applications in that environment, so you have to rewrite portions of your application to use S3. I worked with a media publishing company last year that used an NFS server to store some of their content.</p>
			<div>
				<div class="qtFrm" id="_idContainer166">
					<p class="qt">"A number of years have passed since a lot of companies were locked in with Oracle, and so much time has passed that there's a new generation of folks that haven't been bitten by that."</p>
					<p class="qt">—Sean Hull</p>
				</div>
			</div>
			<p class="normal indent end">The right way to do that would be to use the plugin—in this case, it was WordPress—to access those files in S3. But they wanted to move it to Amazon with a fewer number of changes. For the short term, we set up EFS, which is Amazon's version of NFS. The only reason Amazon built EFS in the cloud is because, exactly as in the use case you're talking about where you have applications, you're moving them, and you don't want to. The native way to do it in Amazon would be to store it in S3 because S3 has life cycle control and infrequent access. It also has Glacier and all the rest so that would be the native way to do it in the cloud.</p>
			<h2 class="introHdg">Vendor lock-in, AWS, and keeping up with the DevOps world</h2>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: With the companies you work with, do they express concern about vendor lock-in, for example, when they go to Amazon?</p>
			<p class="normal end"><strong class="bold">Sean Hull</strong>: Yes, actually I think a number of years have passed since a lot of companies were locked in with Oracle, and so much time has passed that there's a new generation of folks that haven't been bitten by that. I sense that there's less fear right now around Amazon lock-in than maybe there should be. There are tools like Terraform that can plug into Google Cloud; it can talk to the IBM Cloud, Azure, and AWS, among others, so you can deploy resources in any of those clouds if you've built your infrastructure code in Terraform. Terraform is like a layer on top of CloudFormation that implements that stuff in a generic way.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: What's your take on container schedulers: Kubernetes, Mesos, Swarm, and so on?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: I haven't done much with Kubernetes and Docker Swarm. Docker is awesome, and containerization has been around for a long time, since the late 1970s. In fact, I think there was an original BSD project that really popularized containers, but obviously, Docker is the modern version that everybody knows so well, and it does a lot of powerful things.</p>
			<p class="normal indent end">You can spin up development environments and QA test very easily, and so you can encapsulate all the code to rebuild everything you need to get your application working, and that makes everything more repeatable, and so forth. I don't think containers are going away anytime soon because they serve a really big need.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: I have the impression that the speed with which new things are coming is only increasing. How do you keep up with it, and how do companies you work with keep up with all that?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: I don't think they do keep up. I've gone to a lot of companies where they've never used serverless. None of their engineers know serverless at all. Lambda, web tasks, and Google Cloud functions have been out for a while, but I think there are very few companies that are able to really take advantage of them. I wrote another article blog post called <em class="italics">Is Amazon Web Services Too Complex for Small Dev Teams?</em> where I sort of implied that it is.</p>
			<p class="normal indent end">I do find a lot of companies want the advantage of on-demand computing, but they really don't have the in-house expertise yet to really take advantage of all the things that Amazon can do and offer. That's exactly why people aren't up to speed on the technology, as it's just changing so quickly. I'm not sure what the answer is. For me personally, there's definitely a lot of stuff that I don't know. I know I'm stronger in Python than I am with Node.js. Some companies have Node.js, and you can write Lambda functions in Java, Node.js, Python, and Go. So, I think Amazon's investment in new technology allows the platform to evolve faster than a lot of companies are able to really take advantage of it.</p>
			<div>
				<div class="qtFrm" id="_idContainer167">
					<p class="qt">"Amazon's investment in new technology allows the platform to evolve faster than a lot of companies are able to really take advantage of it."</p>
					<p class="qt">—Sean Hull</p>
				</div>
			</div>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: That was my impression when I heard the announcements from their conference. I was like, it would take me a year just to go, and if I would dedicate a year, I would still have trouble keeping up with everything they announced in just a single day.</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: I had a customer recently ask me if I have experience with Lambda. I said, "Yes," and he said, "We want to use something called Lambda@Edge," and I said, "I have no idea what Lambda@Edge is as I've never even heard of it." It turned out Lamba@Edge is a product released four or five months ago that is actually kind of cool. Normally, in your applications, your content is either fed off of the web server or in S3, and then you have CDNs that can then fetch that content and keep it closer to where the traffic is coming from.</p>
			<p class="normal indent end">Say I'm hosting an application in New York, but I have a customer in Japan, and they're hitting that piece of content. They would hit a CDN endpoint that's closer to Japan, and therefore the application would be quicker. All the graphical images and CSS and the other things that it can cache, it would keep them cached at the endpoint. Lambda@Edge allows you to write Lambda code that executes at the edge, so you can examine a cookie that the user authenticated with and then see at the CDN if they have permission to access something. You can write Lambda code that executes at the edge, hence further speeding up your application. If most of your application is in Lambda, you'd be completely distributed at point, and you'd see really huge performance improvement there.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: I haven't even heard about Lambda@Edge until today.</p>
			<p class="normal end"><strong class="bold">Sean Hull</strong>: Lambda@Edge exposes four new events: there's both a before and after endpoint, and a before and after origin, so you can respond just like any other Lambda code would respond to events in the AWS world, and Lambda@Edge exposes those four new events to allow you to write code that runs at the CDN endpoint.</p>
			<h2 class="introHdg">The future of DevOps and closing remarks</h2>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: I'm going to ask you a question now that I hate being asked, so you're allowed not to answer. Where do you see the future, let's say a year from now?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: I see more fragmentation happening across the technology landscape, and I think that that is ultimately making things more fragile because, for example, with microservices, companies don't think twice about having Ruby, Python, Node.js, and Java. They have 10 different stacks, so when you hire new people, either you have to ask them to learn all those stacks or you have to hire people with each of those individual areas of expertise. The same is true with all these different clouds with their own sets of features: there's a fragmentation happening.</p>
			<p class="normal indent">Let's look at the iPhone as an example. Think about how complex application testing is for Android versus the iPhone. I mean, <a id="_idTextAnchor072"/>you have hundreds of different smartphones that run Android, all with different screen sizes, different hardware, different amounts of memory, and the underlying stuff. Some may even have some extra chips that others don't have, so how do you test your application across all those different platforms?</p>
			<div>
				<div class="qtFrm" id="_idContainer168">
					<p class="qt">"You have hundreds of different smartphones that run Android, all with different screen sizes, different hardware, different amounts of memory, and the underlying stuff. […] How do you test your application across all those different platforms?"</p>
					<p class="qt">—Sean Hull</p>
				</div>
			</div>
			<p class="normal indent">When you have fragmentation like that, it means the applications end up not working as well. I think the same thing is happening across the technology spectrum today that happened 10 to 15 years ago, where for your database backend there was Oracle, SQL Server, MySQL, and Postgres. Maybe somebody who's a DB2 enterprise customer uses DB2, but now there are hundreds of open source databases, graph databases, and DynamoDB versus Cassandra, and so on and so on. There's no real deep expertise in any of those databases.</p>
			<p class="normal indent">What ends up<a id="_idIndexMarker034"/> happening is you have cases like what happened with customers who were using MongoDB. They found out the hard way about all of the weird behaviors and performance problems it had, because there just weren't people around with deep knowledge of what was happening behind the scenes, whereas in Oracle's space, for example, there are career DBAs that are performance experts that specialize in Oracle internals, so you can hire somebody to solve particular problems in that space.</p>
			<p class="normal indent end">There aren't, as far as I know, a lot of people with MongoDB internals expertise. You'd have to call MongoDB themselves; maybe they have a few engineers that they can send out, so what's the future? I see a lot of fragmentation and complexity, and that makes the internet and internet applications more fragile, more brittle, and more prone to failure.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: Do you think that trend will continue, or will it kind of reverse itself?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: I don't know if it would or how it could reverse itself; it seems like it's a more general trend of all human knowledge. Look at science and the different specializations; that have gotten more complex across the spectrum, and I think that complexity can lead to very unexpected surprises.</p>
			<p class="normal indent end">For example, I recently read a research paper that talked about depression among teens. I know this is a long side note, but the researchers believe teenage depression is related to the overuse of smartphone devices, because they're messing up how people socialize. I think that more complex fragmentation across the technology spectrum can lead to<a id="_idIndexMarker035"/> very unexpected surprises. I don't know how we wrestle that and how we rein that in, because it just seems to be growing more and more every day.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: I share the same impression. I think that nothing ever goes away, like how we still have mainframes to think about as well. But to finish up, is there anything else you would like to talk about?</p>
			<p class="normal"><strong class="bold">Sean Hull</strong>: Not long ago I wrote an article titled <em class="italics">How is Automation Impacting the DBA Role?</em>. I was talking to a colleague of mine who works in the Oracle space, and they were lamenting how things are changing so quickly, and a lot of companies don't hire a traditional DBA role anymore. That's partly because there are managed services like Amazon RDS that simplify that process, so you don't need a dedicated resource person just for that role.</p>
			<p class="normal indent">To summarize, in the article I wrote that there's a lot of opportunity for people with deep database knowledge, but they need to step up, pivot, and present their skills and their knowledge and frame it in a new way.</p>
			<p class="normal indent end">I do think that deep database knowledge is very valuable for companies, especially as they adopt microservices and try to put databases into containers, and you have other weird performance issues around multi-tenant, Amazon-related stuff. I think someone who has deep database knowledge and performance should still be able to apply that and be of value in today's technology landscape. I just think it's a matter of packaging it and selling yourself in a new way.</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: I have the same impression. I think it actually goes way beyond specific examples like databases. I feel the same thing is happening in other areas, and I'm seeing more and more Java developers who actually know how to write getters and setters and stuff like that. I have the impression that's happening all around, and to me, this is a very big warning that we might get into trouble.</p>
			<p class="normal end"><strong class="bold">Sean Hull</strong>: I think<a id="_idIndexMarker036"/> what is happening is that hiring managers are starting to realize that they're not going to find somebody with the exact specific skill that they're looking for, and they have to look for a more general skillset and someone with more general computing understanding and knowledge. Once they've found them, they need to ask, "Hey, do you want to step up and learn this new stuff, or do you feel confident to solve this problem?"</p>
			<p class="normal end"><strong class="bold">Viktor Farcic</strong>: That's a great place to end the interview. Thank you.</p>
		</div>
	</body></html>