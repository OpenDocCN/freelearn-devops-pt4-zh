<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">DevOps with Azure Functions</h1>
                </header>
            
            <article>
                
<p><span>Microsoft Azure is the number two cloud service provider, just behind AWS. But, until 2015, they hadn't provided API services, but they were excelling in other cloud services like AWS and </span>Google<span> </span>Cloud Functions<span>. Then, eventually, they decided to invest in functions. So, Azure Functions is the answer to AWS Lambda, but the underlying technology is different, which we will cover in upcoming chapters. Azure Functions sit on top of the Azure app service and WebJobs SDK. Azure Functions support a lot of languages like </span><span>F#, Python, Batch, PHP, and PowerShell, but C# and Node.js are officially supported. We will be using Node.js for all our tutorials throughout this chapter and more details on the Azure Functions can be found on Microsoft link: <a href="https:/%20/%20msdn.%20microsoft.%20com/%20en-%20us/%20magazine/%20mt793269.%20aspx">https:/ / msdn. microsoft. com/ en- us/ magazine/ mt793269. aspx</a>.</span></p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Building a simple Azure function</li>
<li>Continuous integration and continuous delivery with Azure Functions</li>
<li>Continuous deployment to Azure Functions</li>
<li>Blue green deployment in Azure Functions</li>
<li>Monitoring and logging</li>
<li>Best practice</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a simple Azure function</h1>
                </header>
            
            <article>
                
<p><span>We will first try to create a simple Azure function through the portal and then we will automate the build and deployment process using</span> S tools <span>and framework. So, to start playing with</span> Azure Functions, we need to create an Azure Cloud service account first. Microsoft provides one month of free subscription and we will be using the Node.js scripts for all the DevOps-related examples and demos.</p>
<div class="packt_infobox">Azure Cloud account creation<br/>
<a href="https://azure.microsoft.com/free/?ref=microsoft.com&amp;utm_source=microsoft.com&amp;utm_medium=docs&amp;utm_campaign=visualstudio">https://azure.microsoft.com/free/?ref=microsoft.com&amp;utm_source=microsoft.com&amp;utm_medium=docs&amp;utm_campaign=visualstudio</a><a href="https://azure.microsoft.com/free/?ref=microsoft.com&amp;utm_source=microsoft.com&amp;utm_medium=docs&amp;utm_campaign=visualstudio"/></div>
<p>Once the account is created, follow these steps:</p>
<ol>
<li>Log into the Azure portal (Azure portal: <a href="https://portal.azure.com/">https://portal.azure.com/</a>).</li>
</ol>
<p style="padding-left: 90px">On successful login, we will be redirected to the homepage of the Azure portal.</p>
<ol start="2">
<li>Now, we need to create resources for Azure Function. So let's click on the button <span class="packt_screen">Create a Resource</span>, which will take us to the Azure marketplace page.</li>
<li>Here, we need to create a <span><span class="packt_screen">Compute</span></span> by clicking on the link <span class="packt_screen">Compute</span> within the Azure marketplace.</li>
<li>Then we can go ahead to create a function through the link <span class="packt_screen">Function App</span> (which will open a new window where we have to feed details for the <span class="packt_screen">Function App</span>.).</li>
</ol>
<p style="padding-left: 90px">The following screenshot gives us the details of how we move through the screen while creating a simple Azure Function: </p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c306dcf6-46cf-4872-9eda-f48a31e022ef.png" style="width:55.25em;height:43.17em;"/></p>
<p class="mce-root"/>
<ol start="5">
<li>After clicking the link, a page will open on which we need to feed in details about the <span class="packt_screen">Function App</span>. So let's name it <kbd>mySampleAppName</kbd>. The Function App name must be unique, because the Azure Function does not allow a duplicate app name across the Azure Cloud. On acceptance of the app name, we will see a green tick mark on the <span class="packt_screen">App name</span> column. Then we will add <span class="packt_screen">Subscription</span>, <span class="packt_screen">Resource Group</span> (we can use the default value or add an existing resource group), <span class="packt_screen">OS</span> , <span class="packt_screen">Hosting Plan</span>, <span class="packt_screen">Storage</span> (we can create new storage or use the existing one).</li>
</ol>
<p style="padding-left: 60px">Let's keep the other details as default and create a <span class="packt_screen">Function App</span>: </p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/a88e694c-6a49-409d-bcd0-c615dc3a3a09.png" style="width:37.33em;height:50.92em;"/></div>
<p style="padding-left: 90px">This will create a <span class="packt_screen">Function App</span>, where the function will be residing. After successful creation of the <span class="packt_screen">Function App</span>, if you click on <strong>All Resources</strong>,<strong> </strong>you<strong> </strong>should be able to see the Function App. We will go ahead and create the application, then Azure will create resources for the function which is a storage account and Function App.</p>
<ol start="6">
<li>Let's now go to <strong>Function Apps</strong> and, on the right-hand side at the <span class="packt_screen">Function App</span> tab, we should be able to see our function. Let's click on it and hover the mouse and we should see <strong>+</strong>. We can create a new function by clicking on the <span class="packt_screen">+</span>; we can only see <span class="packt_screen">+</span> after hovering over the <span class="packt_screen">Functions</span> tab. This will open a tab on the right-hand side which will provide multiple options to create an Azure Function. We will go ahead and choose Scenario as our <strong>Webhook + API </strong>and <span>JavaScript</span> as our language, and then click on <strong>Create this function</strong>: </li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/b8bf1b8f-ac14-422b-a800-511130384f61.png" style="width:68.33em;height:46.17em;"/></p>
<div class="CDPAlignCenter CDPAlign"/>
<p>At the click of the button, a UI will open with an embedded sample Node.js function in it. We can run the same Azure Function to check how it performs.</p>
<p><span>We can run the function with two methods, one is the <span class="packt_screen">POST</span></span> <span>method and another is</span> the <span class="packt_screen">GET</span> <span>method. By default, the function runs with the <span class="packt_screen">POST</span> method. So let's click on the <strong>Run</strong> button. In the next window, replace <strong>Request Body </strong>with the JSON value and click on <strong>Run again</strong>. </span></p>
<p>In the <span class="packt_screen">POST</span> method, let's add the following JSON details:</p>
<pre> {<br/>    "name": "My Azure Function"<br/> }</pre>
<p><span><span class="packt_screen">Run</span> will trigger the function and display the output in the request body, as displayed in the following screenshot:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d2eca40b-52d4-48f0-adb1-00441742dd9b.png" style="width:67.00em;height:32.75em;"/></p>
<p>And, as we change the <strong>HTTP method</strong> to GET,<strong> </strong>we need to feed in a query parameter. To do this, click on <strong>+ Add Parameter</strong> in Query and fill in the key as <strong>name</strong> and value as <strong>DevOps </strong>and then click on <strong>Run</strong>.<strong> </strong>After the successful execution of this, we can see the output log in the log window as <strong>Hello DevOps. </strong></p>
<p>So, in the previous tutorial, we learned how to create a simple hello world azure function and execute the same with the POST and GET methods. In further chapters, we will looking at how to automate the deployment. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing continuous integration and continuous delivery with Azure Functions</h1>
                </header>
            
            <article>
                
<p>Now that we have created a simple application through the Azure portal, the next question is how do we add a multiple number of functions, source code them and set up automated build and deployment. We do this, of course, through DevOps and automation. Let's start with continuous integration. As we know, continuous integration is an integral part of DevOps, where an application is integrated to work as one unit. We have to achieve the continuous integration, automated testing and continuous deployment for Azure Functions through automation. </p>
<p>To start, we will first create an assembly line. The assembly line starts with a code repository like GitHub or SVN and concludes with production deployment. Everything within this has to be automated with almost minimal manual intervention through a pipeline. We will be covering pipelines in detail in the next chapter.</p>
<p>To achieve continuous integration, we need to start with pushing the code into the GitHub repository. The developer should start building the application by creating a featured branch for building each piece of a functions module, then all the featured branches should be reviewed and merged to develop branch and finally to master branch for clean code building. All the featured branches should go through a continuous integration process , that is, a functions code will go through unit testing , state code analysis and various other testing in an automated way. Then code from the featured branch should be merged into the master. The master branch is used to build and deploy to a UAT or OAT environment, where performance testing should be performed and further deployed into production.</p>
<p>The continuous delivery process kicks in at the moment the developer checks in code into the local or featured branch. The automated build will be triggered, which is followed by unit testing and integration testing. Even though the code is very well tested, it still needs to be tested for usability and acceptance testing. So, a successful exit from the continuous integration process will trigger a continuous delivery process and delivery to QA staging. The QA environment normally resembles a production environment. This is where automated and manual acceptance testing kicks in. Having continuous delivery in place, we should be able to release the environment daily, weekly or fortnightly, or whatever suits the business requirement. But we should be able to deploy to production without much effort or manual deployment. </p>
<p>Let's look at an example which follows the continuous integration and delivery. In this example, we will be using open source DevOps tools to actually test and deploy the application on the Azure Cloud. We need tools like Jenkins, which is a popular open source orchestration tool, and the serverless framework which we used for AWS deployment, and the Node.js module for unit testing the code.</p>
<p>For my feasibility, I have used Docker for setting up the Jenkins instance with Node.js and npm installed on it. I have pushed the Dockerfile for this on the Git repository where all the example files reside on the GitHub link below, and also my tutorials are built on Linux: <a href="https://github.com/shzshi/azure-helloworld-ci.git">https://github.com/shzshi/azure-helloworld-ci.git</a></p>
<p>If you are using the Dockerfile from the Git repository, then make sure Docker is installed on your laptop/PC. We will first clone the previous mentioned Git repository and build the Docker image with jenkins, serverless framework, and all the required dependencies for Azure Functions deployment, with the following command:</p>
<pre><strong>$ git clone https://github.com/shzshi/azure-helloworld-ci.git</strong><br/><strong>$ cd azure-helloworld-ci</strong><br/><strong>$ docker build -t chapter4jenkins:latest .</strong></pre>
<p>Then run the Docker container with the following command, this will create a container with Jenkins, Node.js 8.9, Serverless Framework 2.5 and npm 5.6:</p>
<pre><strong>$ docker run --rm -d -p 50000:50000 -p 8080:8080 chapter4jenkins:latest</strong></pre>
<div class="CDPAlignLeft CDPAlign packt_infobox">If you already have Jenkins set up, then make sure you have Node.js 8.9, npm 5.6, and serverless framework 2.5 installed on the server for the previous example to work. </div>
<p class="mce-root CDPAlignLeft CDPAlign">Once Jenkins is up and running, we will create a job in Jenkins which will run the unit test and then deploy the Azure Function through a serverless framework to the Azure Cloud. Once successfully deployed, we will invoke the function through a serverless framework.</p>
<p class="mce-root CDPAlignLeft CDPAlign">Use the following steps in order:</p>
<ol>
<li>The following is the screenshot of the Jenkins homepage. We will create a new job, so click on the link <span class="packt_screen">New Item</span> and create a new job:</li>
</ol>
<p class="mce-root CDPAlignCenter CDPAlign"><img src="assets/c277d547-bf8b-4020-b284-389063b6bef7.png" style="width:38.92em;height:32.33em;"/></p>
<ol start="2">
<li>Create a job name, whatever suits, and select <span class="packt_screen">Freestyle project</span> and submit <span class="packt_screen">OK</span>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/cd91530d-4403-4866-a099-385c0dc43c97.png" style="width:59.00em;height:41.50em;"/></div>
<ol start="3">
<li>Then we will redirect to the configure page for the job, where we will add the Git repository for cloning, click on the <strong>Source Code Management</strong> tab, and add details in the Git repository as shown here: </li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/1490dd3e-1d32-4672-85cf-74c2ed53bfa2.png" style="width:68.92em;height:46.00em;"/></div>
<p class="mce-root"/>
<ol start="4">
<li>Then click the <strong>Build</strong> tab and create an execute shell, and, through the <strong>Add build step</strong> drop-down menu, we add <kbd>npm install</kbd> to install the required Node.js modules from the internet, and then run the Node.js test, which will unit test the Azure library function and give us the result.</li>
</ol>
<p style="padding-left: 90px">We can add many unit tests to test our function, before deploying it to Azure Cloud, to make sure the app is unit tested before it goes on to the cloud:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/73314152-0c4e-4a49-a6a4-e9b91ced140c.png" style="width:57.67em;height:43.58em;"/></div>
<p style="padding-left: 90px"><span>Make sure you have the <span class="packt_screen">Publish HTML report</span> plugin already installed through steps <strong>Jenkins Home</strong></span> | <span><strong>Manage Jenkins</strong></span> | <span><strong>Manage Plugins</strong>. </span></p>
<ol start="5">
<li class="mce-root CDPAlignLeft CDPAlign">Once we run the preceding job, then a unit test is performed and the report is generated for the unit test, which we can view by configuring post-build action. So, let's click on the <strong>Post-build Actions</strong> tab, then click on the dropdown <strong>Add post-build action</strong> and select <strong>Publish HTML reports</strong>, click on <strong>Add</strong> and then configure it as per the following screenshot: </li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/1579513f-2027-4f7c-b842-4f6de84343a9.png" style="width:56.92em;height:40.33em;"/></div>
<ol start="6">
<li class="mce-root CDPAlignLeft CDPAlign"><strong>Save</strong> the job and run the build. Once the job has built successfully, we should be able to view the code coverage HTML view, from the job's homepage. The coverage will look like the following screenshot, which should give us a good view of how our unit test has performed:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/2052f9b0-1da3-45a0-a3df-4d91c32e8a3d.png"/></div>
<p>In the previous section, we unit tested our function and looked at coverage of the function. Next we will configure deployment onto the cloud. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Continuous integration with Azure Functions</h1>
                </header>
            
            <article>
                
<p>Now, moving on to deploying to Azure Cloud Functions, we will be using a serverless framework. The framework will be doing all the heavy lifting, but it needs a few pre-requisites to make it work. They are: <strong>serverless-azure-functions </strong>and <strong>cli az login</strong> to get the required credentials and account details. Please use the following steps to do this in the pre-requisites section: </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Prerequisites</h1>
                </header>
            
            <article>
                
<p>We can install <kbd>serverless-azure-functions</kbd> through the npm. The following command will install the latest version of the plugin, but if you are using the docker image which is created above, it already has the plugin added to it: </p>
<pre><strong>$ npm i --save serverless-azure-functions</strong></pre>
<p>But, to interface with the Azure platform, we need to set up <span>Azure subscription credentials locally.  For the </span><kbd>serverless-azure-functions</kbd><span> plugin to work we need to set up a service principal, which can done through the Azure portal URL as seen in the following:</span></p>
<p><span><a href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-create-service-principal-portal" target="_blank">https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-create-service-principal-portal</a></span></p>
<p><span>However,  if you are using PowerShell cmdlets, then use the following:</span></p>
<p><span><a href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-authenticate-service-principal" target="_blank">https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-authenticate-service-principal</a> </span></p>
<p><span>I will be using CLI for our tutorial , but you are free to use whichever fits best.  or through Azure CLI , </span>Please follow the given steps to get the Azure CLI locally:</p>
<p><a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest" target="_blank">https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest</a></p>
<p>Alternatively, you can use the Azure Cloud Shell, as follows:</p>
<p><a href="https://docs.microsoft.com/en-us/azure/cloud-shell/overview" target="_blank">https://docs.microsoft.com/en-us/azure/cloud-shell/overview</a></p>
<p>Once the Azure CLI is successfully installed we should be able to access <kbd>login</kbd> by using the following command: </p>
<pre><strong>$ az login</strong></pre>
<p>The previous command  will prompt us to visit <kbd>https://aka.ms/devicelogin</kbd> and provide us with a code and with Azure identity. We will then be able to access our account through the CLI. We will be provided with account details like the following one on the command line: </p>
<pre>{<br/>  "cloudName": "AzureCloud",<br/>   "id": "c6e5c9a2-a4dd-4c81b4-6bed04f913ea",<br/>   "isDefault": true,<br/>   "name": "My Azure Subscription",  <br/>   "state": "Enabled",<br/>    "tenantId": "5bc108159c-4cbe-a7c9-bce05cb065c1",<br/>    "user": {<br/>      "name": "hello@example.com",<br/>        "type": "user" <br/>    }<br/> }</pre>
<p>We also need to get subscription details through the following command:</p>
<pre><strong>$ az account list</strong></pre>
<p>Next, we need to create a service principal. We can do this by running the following command. It will provide us with a JSON object that we will need to authenticate with Azure Cloud:  </p>
<pre>$ az ad sp create-for-rbac<br/> Retrying role assignment creation: 1/36<br/> {<br/>   "appId": "e28115c2-ba87-4ddb-b3fb-62c91ade4a2e",<br/>   "displayName": "azure-cli-2018-01-30-01-28-48",<br/>   "name": "http://azure-cli-2018-01-30-01-28-48",<br/>   "password": "e87a0489-63a7-41a1-b0ef-9054eda5b8c8",<br/>   "tenant": "0a76ffdc-0cda-4d93-850f-025f940889dc"<br/> }</pre>
<p>And the last pre-requisite we need is for an <strong>EnvInject </strong>plugin to be installed in Jenkins to mask the Azure credentials. So please make sure that it is added. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setting up environment variables</h1>
                </header>
            
            <article>
                
<p>Finally, we create environment variables with subscription ID, tenant, name, and password. We need to export this on the Jenkins node and set up a deployment. So let's do that: </p>
<ol>
<li>Open the Jenkins in browser and add a new job with a click on <strong>New Item</strong>. Enter the item name <strong>myAzureFunctionDeploy </strong>and select <strong>Freestyle project</strong>,<strong> </strong>and click <strong>OK</strong>.</li>
<li>On the job configuration page, tick <strong>This project is parameterised </strong>and add <strong>Password Parameter</strong> below the name and default values retrieved from the Azure commands as follows: </li>
</ol>
<pre style="padding-left: 60px">azureServicePrincipalTenantId<br/>azureServicePrincipalClientId<br/>azureServicePrincipalPassword<br/>azureSubId</pre>
<ol start="3">
<li>Let's click on the <strong>Source Code Management</strong> tab and add the repository URL as <a href="https://github.com/shzshi/azure-helloworld-ci.git">https://github.com/shzshi/azure-helloworld-ci.git</a>, the repository has the required files. </li>
<li>In <strong>Build Environment</strong> select <strong><span>Inject passwords to the build as environment</span></strong> <span><strong>variables</strong>. We are doing this to mask the Azure credentials and other details. </span></li>
<li>Next, click on the <strong>Build</strong> tab and, in the execute shell, add the steps mentioned in the following example, and then click on <strong>Save. </strong></li>
</ol>
<pre style="padding-left: 60px">export azureSubId=${azureSubId}<br/>export azureServicePrincipalTenantId=${azureServicePrincipalTenantId}<br/>export azureServicePrincipalClientId=${azureServicePrincipalClientId}<br/>export azureServicePrincipalPassword=${azureServicePrincipalPassword}<br/>serverless deploy</pre>
<ol start="6">
<li>Let's click on <strong>Build with parameters</strong>.<strong> </strong>Then click on <strong>Build </strong>the job will build, create a package and deploy the functions onto the Azure portal. We can test the function on the cloud. Once the function is deployed we can invoke or run through a serverless command prompt. We can integrate this in smoke testing or functional testing, so we test the running of the function in actuality through command line or adding the same line into Jenkins job, as seen in the following:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ serverless invoke -f hello --data {"name": "DevOps"}</strong></pre>
<p>We can also stream the logs of the function, to check how functions got deployed, or how it performed while it ran:</p>
<pre><strong>$ serverless logs -f &lt;function_name&gt;</strong></pre>
<p>We can change the code in the source code repository and run these commands individually, or through orchestrating tools like Jenkins to perform perfect continuous integration and continuous delivery.</p>
<p>We can integrate removal of the function from the Azure Function through the following command. This can be integrated within the Jenkins pipeline to undeploy or to rollback the function to a previous version:</p>
<pre><strong>$ serverless remove</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Continuous deployment to Azure Functions</h1>
                </header>
            
            <article>
                
<p><strong>Continuous deployment</strong> means that every code we commit should go through an automated unit, integration, and performance testing, and also go through an automated source code analysis and be successfully deployed all the way to production without manual intervention. But, in some cases we should be able to roll back the deployment because of some bugs or issues in the production. Rollback can be automated, but usually rollback is done manually. We can set up a continuous delivery pipeline through the Azure portal. Let's set up a simple continuous delivery pipeline. Azure Cloud has an out-of-the-box feature to set up a pipeline for Azure Function. It integrates with a good number of source code managements, such as Git, GitHub, Bitbucket, Visual Studio team services, and a few others. The continuous deployment is set up on a per function app basis and also a function code can be maintained through a source repository, and the code within the portal becomes read only. So, the moment the code is updated and committed into the source code repository, the function code is automatically built and deployed on the portal.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setting up a continuous deployment Azure deployment tool</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">Here we will demonstrate to how to set up continuous delivery with a GitHub repository through the Azure portal:</p>
<ol>
<li class="mce-root CDPAlignLeft CDPAlign">Log into the Azure portal (<a href="https://portal.azure.com" target="_blank">https://portal.azure.com</a>). On successful login click on the <span class="packt_screen">All resources</span><strong> </strong>link. We should be able to see the <span class="packt_screen">Function App</span> created:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/dfaa8e44-2324-4872-b672-0a33cced3a1a.png" style="width:60.83em;height:31.50em;"/></div>
<ol start="2">
<li>Select the app for which we need to set up the continuous deployment, as per my example. I will pick up <strong>azure-helloword-ci</strong> which takes me to the function apps windows. Then, on the function apps windows, we will select <span class="packt_screen">Platform features</span> on the top right hand side tab and then click on <span class="packt_screen">Deployment options</span>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7dfa0eac-c4ef-4686-b0fc-35a54c574271.png" style="width:70.17em;height:38.08em;"/></div>
<ol start="3">
<li class="mce-root CDPAlignLeft CDPAlign">Then, in the deployment section, click on <span class="packt_screen">setup</span>. Then another window will slide, with the heading <span class="packt_screen">Deployment option</span>. Click on the link <span class="packt_screen">Choose source</span>, then in the next window, we will see options to add the <span class="packt_screen">Source control</span>. Let's select <span class="packt_screen">GitHub</span>.</li>
<li class="mce-root CDPAlignLeft CDPAlign">Then we will get options to configure GitHub repositories where we will be asked to authorize Azure Functions to access our private or public repositories.  Please make sure you use your own account's public repository.</li>
<li class="mce-root CDPAlignLeft CDPAlign">Once configured, we need to select the repository where we have to fill in choose source, authorization, choose your organization, choose project repository, branch and can configure performance test. We will be taken to the GitHub portal to put in our GitHub credentials to connect to the GitHub repository. After that, once we click <span class="packt_screen">OK</span>, the repository will be configured with Azure Function and <span>all the file changes in the GitHub are copied to the function app and a full site deployment is triggered.</span></li>
<li class="mce-root CDPAlignLeft CDPAlign">We can set up performance testing with the button <strong>Configure Performance Test</strong>. We can create multiple environments by creating different branches, and by merging the code to the master branch for production deployment. </li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Blue-green deployment in Azure Functions</h1>
                </header>
            
            <article>
                
<p>There are multiple deployment patterns in DevOps: canary deployment and blue green deployments. We will be talking about blue green deployment for Azure Functions in this book. Blue green deployment technique reduces the downtime and risk by having two identical production environments with the names blue and green. One environment will go live whilst the other is used for staging new changes. And there is workflow designed to switch between live and staging. Initially, a new version of the application is deployed to the blue environment with all the user traffic being redirected to the blue environment. After the next version of application has been developed, it is deployed to a staging environment (green) for testing. After the testing of the new version of the software is considered satisfactory, then all the traffic is redirected to the green environment and is considered as live.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The deployment dashboard</h1>
                </header>
            
            <article>
                
<p>The development team always need to keep track of deployment and the health of the development pipeline. It also needs to know the track of deployment failure, the number of releases done, the number of check-ins, and many other metrics which are very important for the development cycle.  There is one open source which can help to track all these details and it is Hygieia. Hygieia is an open source tool available for a holistic view on the single screen for tracking build, deployment, quality control, and application performance. It also helps to track deployment versions, and also the health of the application.</p>
<p><strong>Hygieia</strong> is a DevOps dashboard tool, developed by Capital One, and the company has open-sourced the tool.</p>
<p>The Hygieia dashboard has two views, one is a widget and other is a pipeline. The widget view displays information about features in the current sprint, code contribution activities, continuous integration activities, code analysis, security analysis, unit and functional test results, deployment, and environment status. The pipeline view has components of the deployment life cycle which show progression through development, Int, QA, performance, and production. Hygieia also has product dashboard which displays a collaborative dashboard for multiple applications within each product.    </p>
<p>Hygieia has lots of plugins which integrate or get the logs from many DevOps tools like Jira, Subversion, Jenkins, Sonar, IBM UrbanCode Deploy and, as Hygieia is an open source, we can build our own plugin and widget for the Hygieia.</p>
<p>Out of the box, the Hygieia dashboard application integrates with VersionOne, Jira, Subversion, GitHub, Hudson/Jenkins, Sonar, HP Fortify, Cucumber/Selenium and IBM Urbancode Deploy.</p>
<p>Hygieia is built on Java and plugins run through a Java command line. We can set up a whole Hygieia dashboard over the docker containers. Please follow the link for setup and integration: <a href="https://github.com/capitalone/Hygieia">https://github.com/capitalone/Hygieia</a>.<a href="https://github.com/capitalone/Hygieia"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring and logging</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">Serverless applications help speed up development and independence and allow the execution which triggers events, but when these function do not work as expected, how do we verify that events are activating the right functions? With serverless applications, the root cause analysis becomes more complicated, because services are small and their functionality is very precise. While trying to track down the fault source, neither the services involved nor any of the integration points actually exist, and when there is more than one function which takes part in the operation, the investigation becomes very difficult.</span></p>
<p class="p1"><span class="s1">That is where the logs plays a vital role, but there are some unique considerations which need to be taken into account when logging into a serverless architecture.<br/>
And it is normal for several functions to fail and not to deliver the requested functionality, or for the logs contain a unified identifier for the transaction, so when function logs are analysed, the transaction failure can be detected easily and the failure problem can be fixed.<br/></span></p>
<p class="p1"><span class="s1">In Azure Functions we can get logs in many ways. The easiest way is to log in to the Azure portal, go to the respective function and select the <span class="packt_screen">Monitor</span> tab.<span class="Apple-converted-space"> </span>Here we will see a list of function invocations, their status, and last run with duration.<span class="Apple-converted-space"> </span></span><span class="s1">If we select the invocation that has failed, then, on the right-hand side, we can see the exact log and other required information.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Accessing logs through Kudu</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">We can access the logs through Kudu. Kudu was developed to access the Microsoft Azure web apps environment. As Azure Function runs on a web app, we can use Kudu to access the logs of the Azure Functions. Kudu can access environment information, and also details of the actual filesystem which is attached to the function while running.</span></p>
<p class="p1"><span class="s1">Kudu can be accessed through a web browser. The link for the same would be</span><span class="s1"> <a href="https://myAzureFunction.scm.azurewebsites.net/"><span class="s2">https://myAzureFunction.scm.azurewebsites.net</span></a><span class="s2">.</span><span class="s2"> </span>We have to replace the <kbd>myAzureFunction</kbd> with our web app name. The best part of Kudu, is that it will give us the actual file system access of our function environment, either through shell or through browsing, which makes it easier to get to root cause of the failure.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logging information via table storage</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">All logging and timing information of the function is stored in the storage account that we created earlier while creating our function app. We can access the log through Visual Studio if we have Azure SDK installed. We can also access the logs through </span> <span class="s1">Cloud Explorer Window.</span> <span class="s3"> </span><span class="s3">(If you have multiple Azure Function apps then it might be a bit tricky to remember which one belongs to which function app, but you can discover that by looking in your <span class="packt_screen">Application Settings</span> at the contents of the </span><kbd><span class="s4">AzureWebJobsStorage</span></kbd><span class="s3"> setting).<br/></span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring the Azure Function</h1>
                </header>
            
            <article>
                
<p>Monitoring the function is essential. It will give a good view of how our function or app is performing with traffic and also when it scales and descales. Azure Function has built-in integration with Azure application insight.  Application insight<strong> </strong>is built in an APM (application performance management) service by Azure. We can configure application insight during the creation of a function app and send the telemetric data to <span class="packt_screen">Application Insights</span>. Create a new function app and set the <span class="packt_screen">Application Insights</span> switch <span class="packt_screen">On</span> and the <span class="packt_screen">Application Insights</span><span class="packt_screen"> Location</span>:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/a704ec70-de78-4ace-9231-45ea43d6be50.png" style="width:23.92em;height:45.58em;"/></div>
<p>We can see the performance graph in the <span class="packt_screen">Metrics Explorer</span> of the Azure Cloud portal to monitor the function health:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ed017e46-6087-4837-b7ab-f97fb2644e1c.png" style="width:63.00em;height:51.17em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Integrating with New Relic</h1>
                </header>
            
            <article>
                
<p class="p1">New Relic provides integration for Azure Function that does the following functions:</p>
<ul>
<li class="p1">Reports data from Azure Functions to New Relic products.</li>
<li class="p1">Reports metric data, like the count of functions executed, bytes sent and received, and HTTP errors.</li>
<li class="p1">Collects inventory data about the status and configuration of the service.</li>
</ul>
<p>You can monitor and alert on your Azure Functions data from<span> New Relic</span>, and you can create custom queries and chart dashboards.</p>
<div class="packt_infobox"><span>To activate the Azure Functions integration, follow the Azure Integration Activation through the link: </span><a href="https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/getting-started/activate-azure-integrations">https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/getting-started/activate-azure-integrations</a>.<a href="https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/getting-started/activate-azure-integrations"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Best practice</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">DevOps for serverless is pretty young and evolving. Serverless itself is emerging at a fast pace, and, within that framework, to automate deployment and integration with other DevOps, it is changing faster. Talking about best practice for smooth code deployment from development to production, we need to look at various tenants of DevOps for Azure Function and learn from the mistakes <span>during implementation</span>. But because serverless is still evolving, and DevOps with serverless is still niche, we would not be able to highlight every aspect of DevOps. However,  we will look at some of the main tenants and talk about them in detail here. So the main tenant for DevOps with serverless are: source code management, build, deployment, release management, monitoring, and logging, which is almost the same as application. But because serverless are micro services, there is bit of a change when we apply DevOps to it. So let's look at each aspect of it and learn the best way of applying DevOps to the Azure Functions.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Source code management</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">Developers write the code and work together to perform a task, but developers keep adding to the new features, or they update the code to perform better, or to enhance the functionality. This is why we need source code management. Git is one of most popular source code management tools available. So we have to set up various strategies for efficient management of the code. But before that we need to set up a folder structure for Azure Function.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Folder structure</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">All the functions codes of a specific function app would be located in the root folder with one or many subfolders and a host configuration file. The <kbd>host.json</kbd> file will contain runtime specific configurations. And each function folder will have one or more code files, <kbd>function.json</kbd>, configurations, and other function dependencies:</span></p>
<pre class="p1">wwwroot<br/>| - host.json<br/>| - myazurenodefunction<br/>| | - function.json<br/>| | - index.js<br/>| | - node_modules|<br/>| | - ... packages ...<br/>| | - package.json<br/>| - myazurecsharpfunction<br/>| | - function.json<br/>| | - run.csx</pre>
<p class="p1"><span class="s1">With the folder structure we need to apply the best method of branching strategy for robust development and smooth deployment. The best practice is to have multiple branches with a master, which is a default branch, for easy development, and future easy release into production. Those branches are feature, develop, release, and hot fixes branches.</span></p>
<p class="p1"><span class="s1">The feature branch helps easy tracking of a feature, as well as aiding parallel development between team members. A feature branch might branch from a develop branch, but should always merge back to a develop branch. The next main branch would be a develop branch and this branch lives through the life cycle of project development and support. When the source code from a develop branch is stable, then it is merged back to the master branch, after successful release, and every merge to the master will trigger a production release.</span></p>
<p class="p1"><span class="s1">A release branch may be from a develop branch, but they must merge back to the develop and master branches. The release branch is used for preparation of new production release. The release branch is used for next big release. It provides with us room for minor bug fixes, and for setting up meta data for release. When the release branch is ready to be a real release then we need to make sure it is merged with the master and the commit must be tagged for future historical versions. Finally, the release branch should be merged with the develop branch, so that we get all the changes of this release in future releases.</span></p>
<p class="p1"><span class="s1">Last of all is the hotfix branch. This is almost the same as the release branch, as it helps us in production release. Hotfix is actually useful when production deployment fails and you need to hotfix production, so that we can get it back live. So to resolve the production failure, we branch hotfix branch off a production tag from the master branch, so that one team can fix the production failure and rest of the team can continue development on the develop branch. The rule of thumb is that the hotfix branch might branch from a master and then, once hotfix is successful, the changes are merged back to the master. They also need to merge to the develop branch, to make sure we have these hotfix changes in future releases.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Testing and static code analysis</h1>
                </header>
            
            <article>
                
<p>Testing is an essential part of development, it is must when we develop any application. It helps to mitigate most of the bugs and performance issues before going to production. There are many types of testing involved in application development. These include, unit testing, integration testing and performance testing. They integrated into different stages of the environment deployment. Unit testing is integrated in the development stage. </p>
<p><span>The serverless handler should always be a thin layer that uses modules out of your code library. And modules should be well-covered with unit tests; then testing of the serverless application will be easy during the integration tests.</span></p>
<p><span>We should try to run unit tests and integration test the modules and function locally, this will help to run the tests faster, and find issues in code base easily, and without deploying to cloud. We should run them remotely as well, because remote infrastructure is a bit different from local infrastructure. We can achieve both by setting up a pipeline and staging them as different environments (development, stage, user acceptance testing, pre-production and production), where development and stage testing should be invoked locally, and same testing with better performance is tested remotely on the rest of the environment. </span></p>
<p><span>Static code analysis is the process of analyzing source code to flag programming errors, bugs, stylistic errors, and suspicious constructs. We have to make sure we have to integrate linting tool for serverless function in the pipeline stage. This helps to keep the code clean, less buggy and perfectly indented. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deployment and release</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">There are various types of deployment pattern, but we should select one which fits our case, and which uses all the functions together in one go: blue-green and canaries, and also lots of complexities, such as redundancy, high availability, rollback, A/B testing and incremental roll outs. All these need to be considered during deployment, and deployment should be achieved with ease and flexibility. So it should always be better to decide on the pattern before starting the automation.</span></p>
<p class="p1"><span class="s1">We have to make sure deployment is constantly monitored and deployment failures are analysed and improved with time. All the deployment should be triggered through automated pipelines with minimal manual intervention, attached to a GitHub repository, with strict branching strategy. We can also package the function app and upload into Nexus to set up easier roll back. All the deployment should have a feedback loop all the way to project tracking tools like JIRA/rally. This will make it easier to trace the failure. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>To summarize, we covered continuous integration, continuous deployment, logging, and monitoring of Azure Functions and also fleshed out best practices around how to manage the Azure Functions in a source code repository, the importance of testing and automated deployment. Serverless or functions with Azure Cloud are still an early development but improving as each day passes. There is still lots to achieve in terms of adoption and improvement. But once adoption of serverless grows, DevOps practices around it will improve and become robust. In the next chapter, we will learn how to apply DevOps to OpenWhisk, another serverless provider. </p>


            </article>

            
        </section>
    </body></html>