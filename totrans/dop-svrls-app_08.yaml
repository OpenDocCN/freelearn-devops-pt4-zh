- en: Best Practices and the Future of DevOps with Serverless
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DevOps 与无服务器的最佳实践及未来
- en: In the previous chapters, we learned what serverless is and the multiple different
    service providers for serverless features. We also looked at how to build, test,
    and deploy a serverless application, as well as how to monitor and log the execution.
    But this chapter is pretty interesting, because in this chapter, we will go one
    step further to learn some best practices for serverless. We will also learn the
    best practices for building, deploying, monitoring, logging, and securing our
    serverless application. We will also examine how DevOps works with serverless.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们了解了无服务器（serverless）是什么，以及无服务器功能的多个不同服务提供商。我们还探讨了如何构建、测试和部署无服务器应用程序，以及如何监控和记录执行过程。但是本章非常有趣，因为我们将进一步深入，学习一些关于无服务器的最佳实践。我们还将学习如何构建、部署、监控、记录和保护我们的无服务器应用程序的最佳实践。我们还将研究
    DevOps 如何与无服务器一起工作。
- en: Important aspects of DevOps
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DevOps 的重要方面
- en: The two important tenets of DevOps are automation and process. We have to automate
    every bit of development from the nonproduction environment to production, and
    at the same time we have to maintain continuous feedback, with information moving
    back and forth, while also logging everything. Let's look at some best practices
    of how to do this.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps 的两个重要原则是自动化和流程。我们必须自动化从非生产环境到生产环境的每一部分开发，同时要保持持续的反馈，信息在各个环节之间往返流动，同时也要记录一切。让我们看看如何实现这一点的一些最佳实践。
- en: Collaboration and tools strategy
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协作与工具策略
- en: The DevOps team needs to come up with a common tool strategy across the organization,
    and they should collaborate with different teams—such as development, testing,
    and infrastructure—and agree upon the business objectives of DevOps. There should
    be seamless collaboration and integration between the teams. The objective is
    to automate everything, so the ideal goal should be one-click deployment from
    development to production, with very minimal human intervention.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps 团队需要制定一个跨组织的统一工具策略，并且应该与不同团队（如开发、测试和基础设施）进行协作，共同商定 DevOps 的业务目标。团队之间应该实现无缝协作和集成。目标是实现一切自动化，因此理想的目标是从开发到生产的“一键部署”，并尽量减少人为干预。
- en: Agile development
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 敏捷开发
- en: There are many Agile methodologies available. Scrum, XP, and Kanban are a few
    of the more popular ones. You can use one of these development methodologies to
    give you a more flexible option to plan, create a faster output, and give you
    clear focus and transparency throughout the development of your project. Agile
    methodologies help to limit the work in progress, which in turn helps maintain
    a balanced flow so that we don't attempt to do too much at once.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多敏捷方法论可供选择。Scrum、XP 和 Kanban 是其中一些更受欢迎的选择。你可以选择这些开发方法之一，给你提供一个更灵活的选项来规划、创造更快的输出，并在项目开发过程中保持清晰的聚焦和透明度。敏捷方法论有助于限制进行中的工作，这反过来有助于保持平衡的流程，以避免我们一次性做得过多。
- en: Version control everything
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 版本控制所有内容
- en: When we talk about version control, the first thing that comes to our mind is
    application source code versioning, which is a practice that we are well accustomed
    to. But with source code versioning, we should version control the database, the
    build artifacts, the dependencies, and everything that is involved in the application.
    This ensures that every aspect of the application can be historically tracked
    through the single origin that is the repository.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈到版本控制时，首先浮现在我们脑海中的往往是应用程序源代码的版本管理，这是我们非常熟悉的一项实践。但在源代码版本控制的基础上，我们还应该对数据库、构建产物、依赖项以及与应用程序相关的所有内容进行版本控制。这确保了应用程序的各个方面都可以通过存储库这一单一来源进行历史追踪。
- en: Capture every request
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 捕获每一个请求
- en: We should make sure that no ad hoc work or changes happen outside of DevOps,
    and that there should be a change request raised and maintained for every functional
    and nonfunctional requirement. These change requests should be captured and maintained
    within the tool.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该确保没有临时的工作或变更发生在 DevOps 之外，并且每个功能和非功能需求都应提出并维护变更请求。这些变更请求应该在工具中进行捕获和管理。
- en: Automate test and source code analysis
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化测试和源代码分析
- en: When we talk about automating the test, this does not mean just automating the
    testing. The test automation should include provisioning test data and running
    the standard test to ensure that the standard of the code meets the enterprise
    service level agreement. The testing must be continuous and should run 100 or
    1,000 times, and then, upon successful completion, should automatically be promoted
    to a higher environment. The quality of the code should be checked regularly and
    returned back to the developer to be reworked if the code coverage, source code
    analysis, and performance of the code are not up to the baseline.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论自动化测试时，这并不仅仅意味着测试的自动化。测试自动化应该包括预置测试数据并运行标准测试，以确保代码符合企业服务水平协议的标准。测试必须是持续的，应运行
    100 次或 1,000 次，然后在成功完成后，自动提升到更高的环境。代码的质量应定期检查，并在代码覆盖率、源代码分析和代码性能未达到基准时返回给开发人员进行重构。
- en: Continuous feedback
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持续反馈
- en: The feedback loop is very a important aspect of DevOps. It plays a very important
    role for the success of DevOps. The feedback loop consists of automated communication
    between an issue registered during development and the human element of the DevOps
    process. It should be managed by a tool, through which issues must be registered
    manually or via an automated mechanism. The issue should also be tagged with an
    artifact that developers can use to trace what occurred, why it occurred, and
    where in the process it occurred. The tool should help to define the chain of
    communication with all automated and human elements in the loop.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈循环是 DevOps 的一个非常重要的方面，它对 DevOps 成功起着至关重要的作用。反馈循环由开发过程中注册的一个问题与 DevOps 流程中的人类元素之间的自动化通信组成。它应由工具管理，通过该工具，问题必须手动或通过自动化机制进行注册。问题还应该标记一个工件，开发人员可以利用它追踪问题发生的原因、发生的时机以及发生的位置。该工具应有助于定义所有自动化和人类元素在循环中的沟通链条。
- en: Time to market and the cycle time
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 市场上线时间和周期时间
- en: During the DevOps process, we will get a rich array of metrics and real-time
    reports about our process, and we will want to measure the time to market and
    the cycle time of the application, because these two metrics play a very important
    role in how fast and efficiently we make new features available to customers.
    Time to market measures end-to-end efficiency in bringing valuable new features
    to market, and the cycle time is the measurement of the engineering team's process,
    which, once the feature is defined, indicates when it becomes available to move
    to production. It helps in understanding the efficiency of the team and improving
    it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在 DevOps 流程中，我们将获得丰富的指标和实时报告，帮助我们衡量应用的市场上线时间和周期时间，因为这两个指标在我们将新功能提供给客户的速度和效率上起着至关重要的作用。市场上线时间衡量的是从头到尾将有价值的新功能推向市场的效率，而周期时间是衡量工程团队流程的指标，一旦功能定义完成，它就表示功能何时可以进入生产环境。它有助于理解团队的效率并加以改进。
- en: Log metrics
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志指标
- en: We should always track the productivity of DevOps processes, both automated
    and manual, and determine whether they working in favor of the organization. We
    need to define which metrics are relevant for the DevOps process, such as the
    deployment speed, the testing errors found, or the build time. With this definition,
    automated processes can correct these issues without manual intervention.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应始终跟踪 DevOps 流程的生产力，包括自动化和手动流程，并确定这些流程是否有利于组织。我们需要定义哪些指标与 DevOps 流程相关，比如部署速度、测试中发现的错误或构建时间。通过这个定义，自动化流程可以在没有人工干预的情况下解决这些问题。
- en: We skimmed through general DevOps practices that can be applied to application
    development, but when it comes to serverless applications, we need to add more
    specific best practices in terms of tools and process. We will look into each
    service provider and funnel the best practices for the serverless applications,
    as well for DevOps with serverless.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经简要介绍了可以应用于应用开发的一般 DevOps 实践，但当涉及到无服务器应用时，我们需要在工具和流程方面增加一些更具体的最佳实践。我们将深入了解每个服务提供商，并筛选出适用于无服务器应用的最佳实践，以及
    DevOps 与无服务器架构的最佳实践。
- en: Best practices for Serverless
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无服务器架构的最佳实践
- en: As we know, the serverless architecture consists of a small piece of code called
    a function, which runs in a stateless container. One major purpose of this architecture
    is to scale and descale as and when required. So, bearing this in mind, our best
    practices are more or less focused on this aspect of serverless. So let's look
    at a few of the best practices involved with the serverless concept.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: One function, one task
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we start building functions, we might end up with monolithic functions
    behind the proxy route and use a `switch` statement. So, if we have one or a few
    functions to run our whole app, then we are actually scaling the whole application
    instead of scaling a specific element of the application. This should be avoided,
    as scaling would be a problem in this instance, and we also might end up with
    large and complex functions.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Functions call other functions
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We should avoid calling a function within another function because we will end
    up paying more for this, and debugging would be a headache. We lose the value
    of isolating the functions. If required, it would be ideal to trigger another
    function if more work has to be done.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Minimize libraries
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we write a function, we might need libraries to make it run. But adding
    a huge set of libraries to the function would make it really slow. There are two
    types of starts when using functions—one is the cold start, which is function
    that is started for the first time, and the other is the warm start, which is
    function that has already been started and is ready to be executed from the pool.
    So in theory, a larger number of libraries will be slower during the cold start
    and will also impact the scaling of the application. With each increase in scale,
    the function has to perform a cold start, and so, as the cold start is slower,
    the scaling is slower.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Also, as the number of libraries rises, the less secure our code will be, so
    security testing has to be performed for each set of libraries added. They also
    need to be trusted before you actually start using them.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: With HTTP –  one function per route
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We should avoid using single-function proxy if possible while using http route,
    as this hinders in scaling of the function, and also makes debugging tedious.
    There are occasions where we can avoid it, where a functionality of a series of
    routes is tied to a single table, and it's very much decoupled from the rest of
    the application.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Database connection to RDBMS
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The concept of a serverless application is designed to work very well with services,
    so establishing the connection to RDMBS within the function could be troublesome,
    as the parts of the services are still relied upon to provide the fast responses.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: As function scales with RDBMS connections, the number of connections grows with
    the scale,  and we might end up introducing a bottleneck and an I/O wait into
    the cold start of the function.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: So Serverless architecture makes us rethink the data layer, so if we try using
    serverless with the existing data layer (RDBMS), then you will see a performance
    lag in your overall application performance. This might also be the reason why
    DynamoDB works so well with Serverless.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Use messages and queues
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A serverless application works efficiently when the application is asynchronous,
    but with web applications, this is not that simple, because web applications require
    lots of request–response interactions and lots of querying. Going back to functions
    not calling other functions, it’s important to point out that this is how you
    chain functions together. Queues act as circuit breakers in the chaining scenario,
    so if the function fails, we can easily drill down to the failed queue and investigate
    the failure, which could be the result of pushing messages that failed to a dead-letter
    queue.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: With applications that have serverless as the backend, it would be ideal to
    use CQRS, which separates out the conceptual model of input and output in a single
    model into separate models for the purposes of updates and displaying changes
    to the user.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Data in motion
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a serverless system, the data is in motion. It flows through the system,
    but it might end up in a datalake. Nevertheless, while in a serverless system
    it should in flow, so make sure that you keep all the data in motion instead of
    a datalake. Avoid querying from the datalake while using the serverless environment.
    It is not always possible to keep data in motion, but it is best to try.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Measure the scale
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main feature of serverless is efficient scaling, but we should code it so
    that it scales efficiently. We could avoid calling a direct data connection within
    the function, or avoid adding huge numbers of dependency libraries. So, in short,
    the lighter the function, the faster the cold start is, and eventually it will
    scale much faster. Also make sure that functions are load tested before they reach
    production for efficient scaling.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we looked into the various best practices that make serverless
    functions perform and scale very efficiently. Although this is not the complete
    list, these are a few of the very important ones. In the next section, we will
    learn the best practices for each cloud provider and also understand how best
    practices with DevOps will help make serverless development and deployment faster
    and more efficient.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: DevOps best practices and troubleshooting for AWS Lambda
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have learned the best practices for using DevOps and designing the
    architecture of a serverless application. We also looked at the best ways of writing
    functions to make them scalable and have a faster cold start. Going forward, we
    will learn how to apply the best practices for a specific cloud provider.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: AWS Lambda is a very popular and mature serverless platform. Because of this,
    most serverless best practices are aligned with Lambda, and there are a number
    of tools and processes that align functions perfectly well with AWS Lambda. In
    this section, when we talk about DevOps, we will look at the source code versioning,
    building, testing, the package itself, releasing, monitoring, security, and controlling
    the cost aspects of DevOps. All of these aspects of DevOps are stitched together
    to perform as a single platform. This needs a lot of hard work and patience from
    us if we are to reach the nirvana of DevOps.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda是一个非常流行且成熟的无服务器平台。正因如此，大多数无服务器的最佳实践都与Lambda保持一致，并且有许多工具和流程能够很好地将功能与AWS
    Lambda对接。在本节中，当我们谈论DevOps时，我们将关注源代码版本控制、构建、测试、打包、发布、监控、安全性以及成本控制等DevOps方面。这些DevOps的各个方面被整合在一起，作为一个统一的平台运行。如果我们想要达到DevOps的极乐境界，这需要我们付出大量的努力和耐心。
- en: Source code versioning
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 源代码版本控制
- en: Source code versioning is a very important part of development. If the code
    is not versioned, then it might as well not exist. There are many tools available
    for source code versioning, but these days, Git and Apache Subversion are the
    most popular ones. It is always good to have one repository for each application
    and then create multiple branches for development. With respect to Git, when we
    create a repository, there is already a master branch. The master holds the golden
    copy of the code, which is usually used as a benchmark and can also be used as
    a production copy. We can also create many other branches for the feature, release,
    and development versions of the code for efficient development and deployment.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码版本控制是开发中的一个非常重要的部分。如果代码没有版本控制，那它就等同于不存在。现在有许多工具可用于源代码版本控制，但如今Git和Apache Subversion是最受欢迎的工具。通常，最好为每个应用创建一个代码库，然后为开发创建多个分支。关于Git，当我们创建一个代码库时，已经有了一个主分支（master）。主分支保存着代码的黄金副本，通常用于基准参考，也可以作为生产副本。我们还可以为代码的功能、发布和开发版本创建其他多个分支，以实现高效的开发和部署。
- en: So the best practices concerning the source code management is to commit often
    and also make sure that you raise the pull request every time you start your day.
    This allows us to avoid wasting time on merging the code and also prevents us
    from breaking the build. Usually, we have a huge team of developers in various
    parts of the globe building different modules for the application. If we forgot
    to commit one day, then the next morning we would have to waste lots of time merging
    our code before we actually started development. We should also make sure that
    we always inspect before we commit, because otherwise we might commit a whole
    bunch of junk, unwanted libraries, or JAR or debug files into the repository,
    which will clog the repository, as well as make our function bigger, eventually
    degrading the performance.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，关于源代码管理的最佳实践是经常提交，并且每次开始工作时都确保发起拉取请求（pull request）。这样可以避免浪费时间进行代码合并，并且防止我们破坏构建。通常，我们有一个庞大的开发团队，分布在全球不同的地方，为应用构建不同的模块。如果我们某天忘记提交代码，那么第二天早晨我们就得浪费大量时间合并代码，才能开始开发。我们还应确保在提交前始终进行检查，否则我们可能会将一大堆垃圾、不需要的库、JAR文件或调试文件提交到代码库，这会导致代码库被塞满，并且让我们的功能变得更庞大，最终降低性能。
- en: We should also make sure that we add the commit message while we commit the
    code. The comment should explain why we committed the code because this will help
    us to easily trace whether something failed, and also makes it easier for us to
    roll back if we committed buggy code, or if some functionality changes. When we
    add the commit message, we should make sure that it is not too generic or lacking
    in information. We should also ensure that it is fixed, that it works, and that
    it has no typos, because this won't help us to trace it back if we have introduced
    a bug or an issue. In addition, it is not good practice to have the same commit
    message appear after a previous commit, as we usually commit because something
    has changed in the code compared to the previous commit.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该确保在提交代码时添加提交信息。评论应该解释我们为什么提交这段代码，因为这将帮助我们轻松追踪问题是否出现，也使得我们在提交了有bug的代码或某些功能发生变化时，能够更容易地回滚。当我们添加提交信息时，应该确保信息不太笼统或缺乏内容。我们还应确保它是固定的、有效的，并且没有拼写错误，因为如果我们引入了bug或问题，这将无法帮助我们追溯。除此之外，在前一次提交后再出现相同的提交信息也不是一种好习惯，因为我们通常提交代码是因为与前一次提交相比，代码发生了变化。
- en: We should avoid committing a build artifact or compiled dependencies like `.dll`
    or `.jar` into the source control as this could well irritate your coworkers,
    as they will have to check out a huge list of files or have his on local environment
    corrupted by downloading these dependencies. Another way to avoid commit issues
    would be to write precommit hooks, which can mitigate most of the commit issues.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应避免将构建产物或编译的依赖项（如 `.dll` 或 `.jar`）提交到源代码控制中，因为这可能会惹恼你的同事，因为他们需要检出大量文件，或者因为下载这些依赖项而导致本地环境被破坏。另一种避免提交问题的方法是编写预提交钩子，这可以缓解大多数提交问题。
- en: We have talked about versioning, but we should also talk about the version database
    component. Like the UI, application, and testing code, the database component
    should be versioned for stable deployment and application. If we don't version
    the database, then we might run the application with old data or an old configuration.
    It is also easier to track what DDL and DML statement were used in a particular
    release version.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经谈到过版本控制，但我们还应该讨论版本数据库组件。像 UI、应用程序和测试代码一样，数据库组件也应该进行版本控制，以确保稳定的部署和应用。如果我们不对数据库进行版本控制，可能会导致应用程序使用旧数据或旧配置运行。通过版本控制，我们也能更容易地追踪特定版本发布中使用了哪些
    DDL 和 DML 语句。
- en: So, in short, we should always remember to commit regularly, know what are we
    committing, add a valid commit message, and ensure that sure we do it ourselves.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们应该始终记住定期提交，知道我们在提交什么，添加有效的提交信息，并确保我们自己执行这些操作。
- en: 'AWS also supports the versioning of the functions. The Lambda function is versioned
    through publishing. One of the AWS Lambda consoles is specifically dedicated to
    publishing the new version of the Lambda function, and we can create multiple
    versions of the same function. Each Lambda function version is provided with a
    unique ARN, and becomes immutable postpublishing. Lambda also allows us to create
    aliases (as shown in the following screenshot), which are pointers to specific
    Lambda function versions. Each alias will have a unique ARN and can only point
    to one function version, and not to another alias:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 还支持 Lambda 函数的版本控制。Lambda 函数通过发布来进行版本控制。AWS Lambda 控制台中有一个专门用于发布新版本的界面，我们可以为同一个函数创建多个版本。每个
    Lambda 函数版本都有一个唯一的 ARN，并且发布后是不可变的。Lambda 还允许我们创建别名（如下图所示），这些别名指向特定的 Lambda 函数版本。每个别名将拥有一个唯一的
    ARN，并且只能指向一个函数版本，而不能指向另一个别名：
- en: '![](img/01781fec-f67b-44c9-bc46-5cdaa3281039.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/01781fec-f67b-44c9-bc46-5cdaa3281039.png)'
- en: Let's look at an example of AWS Lambda versioning. Say that we have an AWS S3
    bucket that is an event source for a Lambda function, so whenever any new item
    is added to the bucket, the Lambda function is triggered and executed. The event
    source mapping information is stored in the bucket notification configuration,
    and in that configuration, we can identify the Lambda function ARN that S3 can
    invoke. But the newly published version is not automatically updated, so we have
    to make sure that this is updated every time a new version of the function is
    created.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个 AWS Lambda 版本管理的例子。假设我们有一个 AWS S3 桶，它是 Lambda 函数的事件源，因此每当桶中添加新的项目时，Lambda
    函数会被触发并执行。事件源映射信息存储在桶的通知配置中，在该配置中，我们可以识别 S3 可以调用的 Lambda 函数 ARN。但是，新发布的版本不会自动更新，因此每当创建新版本的函数时，我们必须确保更新这个版本。
- en: 'If we are using the Serverless Framework, the new version is created through
    the deployment. There is also the provision to roll back to a previous version
    through the following command line:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用的是 Serverless 框架，新的版本是通过部署来创建的。还可以通过以下命令行回滚到先前的版本：
- en: '[PRE0]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Build
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建
- en: In programming terms, the build is the version of the program or product, but
    the term is also used to refer to the continuous integration of DevOps. So we
    should be sure of the build of the code is built each time code is committed into
    the Git repository. The reason for this is because there are many developers involved
    in such projects, working individually on their own machines, which might work
    fine. But until the code is committed and built on the continuous integration
    server, which will trigger source code analysis and unit testing on the committed
    code, we won't know if we have pushed broken code. So it is essential to trigger
    a build with every commit.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: The artifact of a successful build should always be versioned. The best practice
    is to version them on the Nexus repository, so that all the nonproduction builds
    should be pushed into snapshot repositories of the nexus and the release candidate
    should be pushed into the release repository of the nexus. This process will help
    us to keep the release build separate from the snapshot build, which is temporary
    and should be regularly purged, as it is created for each build and will not be
    needed later.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: The build should also trigger source code analysis, which could be linting for
    a Node.js and Python application, and if you are using Java or C#, then there
    are lots of tools available for source code analysis. The source code analysis
    will make sure that the proper coding standards are followed by developers. It
    also performs security checks and checks for cyclomatic complexity within the
    code. The tools will generate reports as well, and we can also set a threshold
    for the source code analysis pass parameters that will eventually pass the build. So
    if the source code analysis checks are below the baseline set, then the build
    will fail and then the developer will have to fix the issue.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: If we are using Java as a language for serverless, then there are many open
    source tools available for us to use, such as PMD, Checkmarx, Checkstyle, FindBugs,
    and SonarQube. **SonarQube** is a popular tool for source code analysis. It supports
    lots of languages, such as Java, C# , Node.js, and Python. It also has a lovely
    dashboard and is pretty easy to install and configure. The SonarQube official
    image is there on Docker Hub. You can set it up and give it a try.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: You can find the SonarQube image on Docker Hub at [https://hub.docker.com/_/sonarqube/](https://hub.docker.com/_/sonarqube/).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Test
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing is one of the essential parts of the development cycle. Testing ensures
    that bug-free and secure code is deployed to the higher environment, and we should
    make sure that the testing should be automated as much as possible. Testing should
    be combined with the continuous integration process and eventually with continuous
    deployment. The benefit of testing is that it saves lots time and money for organizations
    because it mitigates most of the bugs and errors at the initial stage of development.
    There are many different levels of testing, such as unit testing, integration
    testing, functional testing, and performance testing.  Let's look at the best
    practices around these levels.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 测试是开发周期中的重要部分。测试确保无错误且安全的代码被部署到更高的环境，我们应该尽可能地将测试自动化。测试应与持续集成过程结合，并最终与持续部署相结合。测试的好处在于它为组织节省了大量时间和金钱，因为它能在开发初期阶段减少大多数
    bug 和错误。测试有许多不同的层次，例如单元测试、集成测试、功能测试和性能测试。让我们看看这些层次的最佳实践。
- en: Unit testing
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单元测试
- en: Unit testing is the foundation level of testing when testing software. It basically
    means testing the units of your code to check the correctness of its functioning.
    During unit testing, the code is tested in a test environment using simulated
    input. The output of the execution is then compared with the expected output,
    and if the output matches the expected output, then the test passes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 单元测试是测试软件时的基础层次。它基本上是指测试代码单元，以检查其功能的正确性。在单元测试过程中，代码在测试环境中使用模拟输入进行测试。然后将执行的输出与预期的输出进行比较，如果输出与预期输出匹配，则测试通过。
- en: 'With respect to the serverless concept, we do not have to worry about Lambda
    functions or handlers or events; we just need to organize our code base for easy
    integration of unit testing. If you look at the following code, you can see that
    we are separating our core logic into separate modules instead of within the handler
    so that they can be unit tested individually:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 就无服务器概念而言，我们不需要担心 Lambda 函数、处理程序或事件；我们只需要组织好代码库，以便于单元测试的集成。如果你查看以下代码，你会看到我们将核心逻辑分离成独立的模块，而不是放在处理程序内，这样它们就可以单独进行单元测试：
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: So, it always better to separate your business logic so that it is independent
    of the service provider, reusable, and more easily testable. With this separation
    of business logic, the unit testing would be easier to write and run, and it would
    also take less effort to move to a different provider.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，最好将业务逻辑分离，使其独立于服务提供商、可重用，并且更容易进行测试。通过这种业务逻辑的分离，单元测试将更容易编写和运行，而且迁移到不同的提供商时也会花费更少的精力。
- en: There are many unit-testing frameworks available for Node.js and Python, but
    the ones we will look at are **Mocha** and **Jest**. There are serverless framework
    plugins available for these two frameworks.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js 和 Python 都有许多单元测试框架，但我们将要讨论的是 **Mocha** 和 **Jest**。这两个框架都有可用的无服务器框架插件。
- en: 'The following code shows the Mocha serverless plugin installation and usage.
    It can be installed locally as a service or included within the `serverless.yml`,
    as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了 Mocha 无服务器插件的安装和使用。它可以作为服务本地安装，也可以包含在 `serverless.yml` 中，如下所示：
- en: '[PRE2]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Likewise, we can add the Jest serverless plugin into the `serverless.yml`,
    as shown in the following code:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以将 Jest 无服务器插件添加到 `serverless.yml` 中，如以下代码所示：
- en: '[PRE3]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Similarly, **Nose** is a popular framework for Python serverless applications.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，**Nose** 是一个流行的 Python 无服务器应用框架。
- en: In addition to this, we can use **LocalStack **for mocking an AWS environment.
    LocalStack helps us to create a local testing environment that is similar to AWS.
    It spins up a core Cloud API for us to test our functions locally.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，我们还可以使用 **LocalStack** 来模拟 AWS 环境。LocalStack 帮助我们创建一个类似于 AWS 的本地测试环境，它为我们启动核心云
    API，以便我们在本地测试我们的函数。
- en: Integration testing
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成测试
- en: Integration testing is basically when tests cover more than one unit. Our Lambda
    function must be integrated with third-party code dependencies, which have to
    be tested thoroughly. That's where integration testing comes into play. Integration
    testing plays a very important role in the serverless world, but it is also expensive
    if you are always doing it over the cloud. But we can reduce the cost by mocking,
    as we talked about when looking at the LocalStack framework. Using this method,
    we can put it to use mocking a large number of AWS resources.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, we can invoke the Lambda function locally using the `serverless invoke
    local`, and if our functions need to read/ write from DynamoDB, then this can
    also be mocked using `dynamodb-local` Node.js libraries.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: While these methods don’t emulate Lambda 100%, we’ll still be able to find issues
    in our code base quickly without having to wait for a deployment.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Performance testing
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Performance testing is a type of testing where we check how our application
    is performing with an expected workload. This is a very essential type of testing
    for our type of application because performance testing will provide us with an
    opportunity to improve the performance of our functions, and will also help to
    improve the speed of scaling. Scaling is a very important feature of functions,
    but it is our responsibility to code it in a fashion that will help it scale faster.
    This is where performance testing will help.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: One of the very popular tools for performance testing is **Jmeter**. It is widely
    used across the industry. The Jmeter stress test will examine load-testing KPIs,
    such as the response time, error rate, memory leaks, slowness, security issues,
    and data corruption. Jmeter requires a performance parameter script. We can start
    creating the script with the BlazeMeter Chrome extension.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'Another popular tool is **Artillery**, which can be used for performance testing,
    load testing, and functional testing. It is an open source tool, and is built
    over Node.js. It can generate a load for an application and can simulate virtual
    users. You can run through this simple installation using the following code:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: There is also a combination of Serverless Framework and Artillery, called `serverless-artillery`.
    This package will help us to deploy the function and run the performance test
    through a single Node.js package, and makes it easier to integrate it into our
    CI/CD pipeline. More information can be found at: [//github.com/Nordstrom/serverless-artillery](http://://github.com/Nordstrom/serverless-artillery).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'Testing is very important in order to weed out defects and errors in the early
    stages of development, but we have to make sure that it is introduced very early
    in the development cycle, and should be performed until production. But it is
    equally important to automate it, and it should be integrated with the continuous
    integration and continuous delivery cycle. But serverless testing has its challenges,
    as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Serverless architecture is actually an integration of separate, distributed
    services that need to be tested both together and independently.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器架构实际上是独立分布式服务的集成，这些服务需要同时和独立地进行测试。
- en: We can test the serverless functions locally, but it is hard to emulate them
    completely locally, and it is equally important to test them over the cloud. This
    process should be automated.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以在本地测试无服务器函数，但完全在本地模拟它们很困难，因此在云上测试它们同样重要。这个过程应该是自动化的。
- en: The serverless architecture can feature event-driven, asynchronous workflows,
    and testing them thoroughly is not that easy.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器架构可以具有事件驱动、异步的工作流，彻底测试这些工作流并非易事。
- en: Monitoring
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控
- en: When we think of monitoring, the first thing that comes into our mind is observing
    and tracking the operations and activities of the software application regularly
    and setting up an alarm to trigger upon a system or application failure. Monitoring
    should begin right from the start of the development, in such instances as the
    monitoring of the speed of the application or monitoring how many resources a
    developed piece of code is using. This monitoring system should be coupled with
    a notification system, triggering a notification such as an email when memory
    is used beyond a defined threshold.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想到监控时，首先浮现在我们脑海中的就是定期观察和追踪软件应用程序的操作和活动，并在系统或应用程序失败时设置触发报警。监控应该从开发的开始就启动，例如监控应用程序的速度或监控已开发的代码片段使用了多少资源。这个监控系统应与通知系统相结合，当内存使用超过定义的阈值时触发通知，比如发送电子邮件。
- en: But monitoring serverless functions is more tricky. In server monitoring, we
    monitor the performance of the server, network latency, and CPU, but these details
    are irrelevant with respect to serverless as the infrastructure is completely
    managed by the service provider. But then what should we monitor with respect
    to serverless? We can still monitor memory and concurrency rate. Although the
    service provider handles the provisioning and execution of Lambda functions, there
    is still a limit to the amount of memory that can be used and the concurrent executions
    allocated to the function.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 但是监控无服务器函数更加棘手。在服务器监控中，我们监控服务器的性能、网络延迟和CPU，但这些细节对于无服务器而言是无关紧要的，因为基础设施完全由服务提供商管理。那么我们在无服务器中应该监控什么呢？我们仍然可以监控内存和并发率。尽管服务提供商处理Lambda函数的资源分配和执行，但仍然有内存使用和函数分配的并发执行次数的限制。
- en: To perform serverless monitoring, there are number of tools available. There
    are a few out-of-the-box tools from AWS, such as **AWS CloudWatch**, which involves
    all the AWS resources feeding into AWS CloudWatch. CloudWatch will be our first
    tool to monitor the Lambda functions. CloudWatch tracks metrics such as the latency
    of execution, number of functions executed, and errors made during the execution.
    But we can go beyond this by setting up custom metrics within CloudWatch. We also
    looked at the CloudWatch dashboard for use with the Lambda function.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行无服务器监控，有很多工具可用。AWS提供了几个开箱即用的工具，例如**AWS CloudWatch**，它将所有AWS资源输入到AWS CloudWatch中。CloudWatch将是我们监控Lambda函数的第一个工具。CloudWatch跟踪执行延迟、执行的函数数量以及执行过程中的错误等指标。但我们可以通过在CloudWatch中设置自定义指标来超越这些。我们还查看了与Lambda函数一起使用的CloudWatch仪表板。
- en: AWS provides another powerful tool for the application performance of the lambda
    function, and that tool is X-ray. X-ray is a tracing tool that is integrated with
    AWS Lambda out of the box. It provides an end-to-end view of requests as they
    move. With X-ray, we can analyse how lambda functions and their connected services
    are performing. We can identify and troubleshoot the root causes of performance
    issues and errors, and with the map view of the application, we can see all of
    its components.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: AWS为Lambda函数的应用性能提供了另一个强大的工具，那就是X-ray。X-ray是一个与AWS Lambda开箱即用集成的追踪工具。它提供了请求流动的端到端视图。通过X-ray，我们可以分析Lambda函数及其关联服务的性能。我们可以识别并排除性能问题和错误的根本原因，并且通过应用程序的地图视图，我们可以看到它的所有组件。
- en: Thundra is another monitoring tool that can be used as an application performance
    monitoring tool for AWS Lambda. It asynchronously publishes the data from CloudWatch
    into Thundra using functions and agents to send the monitoring data into the application.
    It has some really good charts that cover many metrics, such as the invocation
    counts, cold-start invocation counts and durations, error counts by error types
    and function names, and many more.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get the latest version of the Lambda function for execution, they should
    be deployed on the cloud. In this way, if our deployment package is heavier, then
    deployment will be slower. This will eventually degrade the performance of the
    function as it unpacks when it is invoked. The packing of our function also affects
    our execution. For example, if we are using Java, then packaging the function
    with all the dependencies grouped together as one function is slower compared
    to putting the dependencies within the `lib` folder.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: There are many tools that are available for deployment, but Serverless Framework
    is one of the main candidates for this job. Of course, there is lot that we still
    have to achieve, but this is still a far more mature solution than any other open
    source option available on the market.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Also with respect to deployment , it should be orchestrated and should go through
    lots of approval and change request process with respect to UAT and prod environment.
    Deployment in production should be managed through service-now change request
    and CAB approvals.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The runtime language for Lambda provides a mechanism for your function to deliver
    logged statements to CloudWatch logs. We need any type of application to make
    the best use of its logs, not just serverless applications. With other applications,
    we can retrieve the logs from the server in which the application is deployed.
    However, with serverless applications that is not possible, as there is no server,
    and present, we don't have the ability to "step through" the code of a live, running
    lambda function. As a result, we are heavily dependent on the logs that we create
    to inform our investigation of our functions' behavior. Because of this, we have
    to make sure that any logs generated should have the right balance of verbosity
    to triage the issues without demanding too much computing time. It is recommended
    that we use an environment variable to create a `loglevel` variable.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: The appropriate use of log levels can ensure that we have the ability to selectively
    incur the additional compute and storage cost only during an operational triage that
    our function can refer to so that it can determine which log statements to create
    during runtime.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Security
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Security should be first in our list of priorities while designing and implementing
    functions. One of the major differences between serverless applications and server-based
    applications is that with a serverless application, we do not have control over
    the servers, so we must bake in most of the securities within our code. So while
    coding the serverless application, we should make sure that we write a secure
    code so that all the third-parties' security configuration is validated. Let's
    look at some of the best practices that are essential for implementing this secure
    code.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: An IAM role per function
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is advisable that you create a role for each function, because this would
    decouple the IAM roles. This would also enable least privilege to be provided
    to individual functions. Say, for example, that a function is using a KMS key
    within its code. If we have a common role for the KMS key, then all the other
    functions would have access to the KMS key.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: No long-lived credentials
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using temporary AWS credentials with lambda function code is always secure. This
    is where static analysis configuration plays an important role. It best to create
    an AWS service client within the function code through AWS SDK without providing
    any credentials. The SDK should automatically manage the retrieval and rotation
    of the credentials for the alloted role.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Do not persist secrets
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is best practice to not persist the secrets. However, our function might
    need some secrets to be long lived, such as database credentials and dependency
    service access keys. Because of this requirement, it is recommended that you encrypt
    these secrets. There are a few options available to us, such as using the lambda
    environment variable with encryption and the Amazon EC2 systems manager's parameter
    store.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Secrets should not be saved or persisted on memory. Instead, the function should
    retrieve temporary credentials and keep rotating them, revoking them from time
    to time. API interaction with the lambda function should be authenticated and
    authorized.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Lambda in VPC
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When using Lambda functions in VPC, we should follow the best practices of using network
    security by using least-privilege security groups, lambda-function-specific subnets,
    and route tables to allow traffic specific to our lambda function, if we have
    used resources from the VPC.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: AWS Lambda best practices
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far we learned about the best practice for DevOps with respect to AWS Lambda,
    but I feel that this chapter cannot end without knowing the best practices for
    the lambda function. These best practices will eventually help us to develop efficient
    lambda functions, and will also help us to achieve faster deployment. Let's look
    at these best practices individually.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Keep the handler independent of business logic
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is always advisable to keep business logic outside the handler because this
    will decouple our business logic from the lambda function runtime environment,
    reuse the business logic functions, and make it easier to test our written unit
    test, as we discussed earlier in the chapter.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Keep warm containers alive
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we code, we have to make sure that our code is be written in such a way
    that it uses the resources of a warm container instead of doing a cold start.
    This means that we have to scope our variables in such a way that they can be
    reused multiple times on subsequent invocations wherever possible. We should reuse
    our connection (such as an HTTP or a database connection) that was established
    in a previous invocation.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Dependency control
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lambda needs many libraries during invocation. Lambda will always look for the
    latest libraries and security updates, but this will also bring changes in the
    behavior of the lambda function. As a result, it is best to package the dependencies
    along with the functions and deploy them. They should also be controlled and managed
    for the sake of performance within the lower environments.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Shorter timeout for dependencies
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need to configure a shorter timeout for all external dependencies. We cannot
    allow them to run while they are continuously looking for dependencies because
    Lambda is billed based on the duration of the execution of the function. The larger
    the execution time, the higher the are charges.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Exception handling
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We should evaluate what the failure behavior of our functions should be, and
    accordingly, our functions should throw the correct exceptions back for faster
    resolution.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Recursive coding
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We should avoid recursive code within our lambda function because the function
    will call itself recursively until a criteria is met. But this will lead to multiple
    volumes of invocation and increased cost. If we still accidentally do it, then
    we should set the function's concurrent execution limit to `0` to immediately
    throttle all invocations to the function while you update the code.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: High availability
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we go into production, high availability becomes essential, and with respect
    to serverless applications, high availability depends on the number of zones in
    which the lambda functions can be executed. If our function uses the default network,
    then it is automatically able to execute within all available zones in that region.
    Nothing else is required to configure the high availability for the function in
    the default network environment. Therefore, while designing the VPC, it is important
    to include the subnets from multiple availability zones.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Runtime language
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Choosing a runtime language is quite tricky when we start designing a serverless
    application. But we can always seek comfort in our skills sets when we decide
    on the runtime language. But the runtime language also determines the performance
    of our application. For example, if we use Java or .NET (the compiled language)
    as our runtime language, then this incurs the largest initial startup cost for
    a container's first invocation, but the performance will improve for subsequent
    invocations. Interpreted languages, such as Node.js or Python, have very fast
    initial invocation times compared to compiled languages, but they cannot output
    the maximum performance compared to complied languages. So if the application
    is latency sensitive or very spiky, then it is recommended that you use an interpreted
    language, and if the application does not experience large peaks or valleys within
    its traffic, or if user experience is not blocked with the lambda functions response
    time, then we can choose any language as the runtime language.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Code for cold and warm containers
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The performance of the lambda function is dictated by the logic that we code
    within it and the dependencies we call. So the best practice to code the lambda
    function would be to consider the cold and warm start of the containers.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: For improved performance for warm starting the container, make sure that you
    store and reference any externalized configurations or dependencies that your
    code retrieves locally. Limit the reinitialization of the variables/objects on
    every invocation that uses global and static variables. Keep the HTTP and database
    connections alive.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: For better performance for cold starting the container, it is always better
    to use the default network environment, unless connectivity to a resource within
    a VPC via a private IP is required. Choose an interpreted runtime language over
    a complied language. Keep the function code package as small as possible, as this
    will reduce the time to download, unpack the code from the S3 bucket, and invoke
    it.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Cost optimizing
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s an antipattern to assume that the smallest resource size available to your
    function will provide the lowest total cost. If your function’s resource size
    is too small, you could pay more because of a longer execution time than if more
    resources were available that allowed your function to complete more quickly.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: You don’t need to implement all use cases through a series of blocking/synchronous
    API requests and responses. If you are able to design your application to be asynchronous,
    you might find that each decoupled component of your architecture takes less compute
    time to conduct its work than tightly coupled components that spend CPU cycles
    awaiting responses to synchronous requests. Many of the Lambda event sources fit
    well with distributed systems, and can be used to integrate your modular and decoupled
    functions in a more cost-effective manner.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Some Lambda event sources allow you to define the batch size for the number
    of records that are delivered on each function invocation (for example, Kinesis
    and DynamoDB). You should run tests to find the optimal number of records for
    each batch size so that the polling frequency of each event source is tuned to
    how quickly your function can complete its task.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: The variety of event sources available to integrate with Lambda means that you
    often have a variety of solutions available to meet your requirements. Depending
    on your use case and requirements (request scale, volume of data, latency required,
    and so on), there might be a nontrivial difference in the total cost of your architecture
    based on which AWS services you choose as the components that surround your Lambda
    function.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for Azure functions
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With respect to other cloud providers, such as Azure, the best practices should
    align with the Lambda function. In this section, we will look at a few of these
    best practices for Azure that are closely related to Lambda functions.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Avoid large and long-running functions
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Large and long-running functions can cause unexpected timeout issues  and A
    function can become large because of many Node.js dependencies. Specially Importing
    dependencies can also cause increased load times that result in unexpected timeouts.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Whenever possible, we should refactor large functions into smaller function
    sets that work together and return responses fast.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Cross-function communication
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we are not using durable functions or logic apps to integrate multiple functions,
    it is generally a best practice to use storage queues for cross-function communication.
    The storage queues are cheaper and much easier to provision.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Individual messages in a storage queue are limited in size to 64 KB. If we need
    to pass larger messages between functions, an Azure Service Bus queue could be
    used to support message
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: functions should be be stateless
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is recommended that functions are stateless and idempotent where ever possible.
    Associate any required state information with your data. For example, an order
    that is being processed will likely have an associated state member. A function
    could process an order based on that state while the function itself remains stateless.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: and very importantly it is recommended that idempotent functions have timer
    triggers. For example, if you have something that absolutely must run once a day,
    we should write it so that it can run at any time during the day with the same
    results. The function can skip when there is no work for a particular day. Also,
    if a previous run failed to complete, then the next run should pick up where it
    left off.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: functions is defensive
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is always good to design our functions with the ability to continue from
    a previous fail point during the next execution.  It is recommended to write the
    function with proper error handling considering networking outages, reached quota
    limits, or made any other kind of mistake. All of these issues can affect our
    function at any time. we need to design our functions to be prepared for such
    things.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Let assume our code fails after inserting 2000 items into the a queue for processing,
    we should be able to track the items in a set that is been completed or else we
    might end up inserting them again.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: How does your code react if a failure occurs after inserting 5,000 of these
    items into a queue for processing? You should track items in a set that you’ve
    completed. Otherwise, you might insert them again next time. This can have a serious
    impact on your work flow.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: The same function app should not have code for test and production
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We should not mix, test and production functions or resources within the same
    function app, the performance might be degraded because functions within the function
    app shares resources, for example memory is shared. So we should be careful what
    we load in our production function apps as memory is averaged across each function
    in the function app
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Use asynchronous code, but avoid blocking calls
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Asynchronous programming is a recommended best practice. However, always avoid
    referencing the `Result` property, or calling the `Wait` method on a `Task` instance.
    This approach can lead to thread exhaustion.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Configure host behaviors to better handle concurrency
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `host.json` file in the function app allows for the configuration of the
    host runtime and trigger behaviors. In addition to batching behaviors, you can
    manage concurrency for a number of triggers. Often, adjusting the values in these
    options can help each instance scale appropriately for the demands of the invoked
    functions.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: The settings in the `hosts` file apply across all functions within the app,
    within a *single instance* of the function. For example, if you had a function
    app with 2 HTTP functions and concurrent requests set to 25, a request to either
    HTTP trigger would count towards the shared 25 concurrent requests. If that function
    app scaled to 10 instances, the 2 functions would effectively allow 250 concurrent
    requests (10 instances X 25 concurrent requests per instance).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for Google Functions
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the best practices are same across the Serverless functions even though
    the service providers are different , but I would still like to list some of them
    here.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Code idempotent functions
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The functions should produce the same result even after calling them multiple
    times. This helps in retrying an invocation if the previous invocation fails partway
    through our code.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Signal the completion of function calls
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Signal the completion of your function, failing to do so can result in your
    function executing until a timeout is hit. If a timeout occurs, you will be charged
    for the entire timeout time. Timeouts may also cause subsequent invocations to
    require a cold start, which results in additional latency.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Do not start background activities
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A function invocation finishes once termination is signaled. Any code run after
    graceful termination cannot access the CPU, and will not make any progress. In
    addition, when a subsequent invocation is executed in the same environment, your
    background activity resumes, interfering with the new invocation. This may lead
    to unexpected behavior and errors that are hard to diagnose. Accessing the network
    after a function finishes usually leads to connections being reset (and the `ECONNRESET`
    error code).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Background activity is anything that happens after your function has terminated.
    It can often be detected in logs from individual invocations by finding anything
    that is logged after the line saying that the invocation finished. Background
    activity can sometimes be buried deeper in the code, especially when asynchronous
    operations such as callbacks or timers are present. Review your code to make sure
    that all asynchronous operations finish before you terminate the function.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: Always delete temporary files
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Local disk storage in the temporary directory is an in-memory filesystem. Files
    that you write consume memory available to your function, and sometimes persist
    between invocations. Failing to explicitly delete these files may eventually lead
    to an out-of-memory error and a subsequent cold start.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: You can see the memory used by an individual function by selecting it in the
    list of functions ([https://console.cloud.google.com/getting-started](https://console.cloud.google.com/getting-started))
    in the GCP console and choosing the Memory usage plot.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Do not attempt to write outside of the temporary directory, and be sure to use
    platform/OS-independent methods to construct file paths.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: You can bypass the size restrictions on temporary files by using `pipelining`.
    For example, you can process a file on Cloud Storage by creating a read stream,
    passing it through a stream-based process, and writing the output stream directly
    to Cloud Storage.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Local development
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Function deployment takes a bit of time, so it is often faster to test the code
    of your function locally using a **shim**.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Error reporting
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Do not throw uncaught exceptions, because they force cold starts in future invocations.
    See the **Error Reporting guide** ([https://cloud.google.com/functions/docs/monitoring/error-reporting](https://cloud.google.com/functions/docs/monitoring/error-reporting))
    for information on how to properly report errors.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Use SendGrid to send emails
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud Functions does not allow outbound connections on port 25, so you cannot
    make nonsecure connections to an SMTP server. Instead, you should use `SendGrid`
    to send emails.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Use dependencies wisely
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Because functions are stateless, the execution environment is often initialized
    from scratch (during a cold start). When a cold start occurs, the global context
    of the function is evaluated.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: If your functions import modules, the load time for those modules can add to
    the invocation latency during a cold start. You can reduce this latency, as well
    as the time needed to deploy your function, by loading the dependencies correctly
    and not loading dependencies that your function doesn't use.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Use global variables to reuse objects in future invocations
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is no guarantee that the state of a Cloud function will be preserved for
    future invocations. However, Cloud Functions often recycles the execution environment
    of a previous invocation. If you declare a variable with a global scope, its value
    can be reused in subsequent invocations without having to be recomputed.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: This way, you can cache objects that may be expensive to recreate on each function
    invocation. Moving such objects from the function body to a global scope may result
    in significant performance improvements.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Do lazy initialization of global variables
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you initialize variables with a global scope, the initialization code will
    always be executed via a cold start invocation, increasing your function's latency.
    If some objects are not used in all code paths, consider initializing them lazily
    on demand.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As its name implies, this chapter was all about learning the troubleshooting
    techniques and best practices to apply when using DevOps to construct serverless
    architecture. In the next chapter, we will talk about the various use cases of
    AWS Lambda, Azure Functions, and open source versions, and how DevOps fits in
    to it all.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
