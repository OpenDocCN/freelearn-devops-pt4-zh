<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Use Cases and Add-Ons</h1>
                </header>
            
            <article>
                
<p><span>In the previous chapter, we learned how to apply some best practices in relation to serverless functions and DevOps. We understood how important it is to build light and secure serverless functions. We also learned about some best practices for monitoring and logging a serverless application. So, moving forward, let's look at the big picture of how serverless can be used in the real world and also learn how we can implement end-to-end DevOps around it. </span></p>
<p>As developers are moving from monolithic application toward the serverless architecture more and more use cases are coming into existence. But it is getting equally more difficult to build, test and deploy them. So, in this chapter, we will learn few serverless use cases and also learn how to set up end-to-end deployment pipeline. </p>
<p>This chapter will cover the following topics:</p>
<ul>
<li>AWS Lambda use cases and add-ons</li>
<li>Azure Functions add-ons</li>
<li>Google Functions add-ons</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">AWS Lambda use cases and add-ons</h1>
                </header>
            
            <article>
                
<p>Our journey so far has been about what AWS Lambda is , and how we can build ,test, deploy, monitor, and log it. We also looked at some best practices for AWS Lambda in general and also for DevOps. So now, here in this chapter, it is time to bring them all together as one use case. Before we cover the use case for DevOps with AWS Lambda, let's start to first look at use cases where Lambda can be efficiently used and then let's look at how DevOps can make life easier for developers and business users. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">AWS Lambda use cases</h1>
                </header>
            
            <article>
                
<p>As we know, serverless architecture was introduced to help businesses to focus on application development and not to worry about the underlying servers. Reducing the cost and shortening the deployment cycle, the adoption rate for serverless is growing exponentially. Now lots of companies are adopting serverless as a way to ensure rapid auto scaling and descaling. Let's look at some of the useful applications of serverless that are being adopted across the industry. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Serverless website</h1>
                </header>
            
            <article>
                
<p>The best model for serverless adoption would be websites that want to take advantage of AWS Lambda and AWS S3. Both of these resources provided by AWS are very cheap. Also, with AWS Lambda, it can scale on demand and descale as demand slows downs. So they do not have to pay big money for keeping a server up and running all the time. So we can consider hosting the static content or the frontend on the S3 bucket and these frontend applications can send requests to Lambda functions via the API gateway HTTPS endpoints and Lambda does all the heavy lifting of the application logic and persists the data to a a fully-managed database service (<strong>RDBMS</strong> (<strong>relational databases</strong>) or <strong>DynamoDB</strong> (<strong>non-relational databases</strong>) ). We can host our Lambda function within VPCs to isolate them from different other networks and it is also cheaper, as we pay only for the traffic incurred by AWS S3 and AWS Lambda with the extra cost for the database service. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Video and image processing</h1>
                </header>
            
            <article>
                
<p>With Instagram becoming more popular, a lot can be done with images and videos, but it is equally expensive to process or resize them. The traditional way of editing the videos and images would be to host a VM that is always running and when an image or video arrives for editing then running the application within the VM. But we have to incur costs for running the VM 24/7 without it being used all the time. Serverless could be the best option for these types of jobs. Serverless services can be used to dynamically resize the image or change the video transcoding for different target devices.</p>
<p>Also, with serverless, we can tap into the Google Vision API or Amazon Recognition to recognize faces and images or flat <span>inappropriate content</span><span>. In the AWS chapter, we created a tutorial where an image is uploaded into one S3 bucket and then Lambda is automatically triggered when the image is uploaded to the S3 bucket to resize it and push it to another bucket. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logs Processing and notification</h1>
                </header>
            
            <article>
                
<p>We can use Lambda functions to harvest the logs from CloudTrail and CloudWatch, Lambda watches for specific triggers and log entries and invokes an SNS notification on the event. These notifications can be configured and sent to Slack, Jabber, or other support systems. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Controlling the IoT</h1>
                </header>
            
            <article>
                
<p>The <strong>Internet of things</strong> (<strong>IoT</strong>) is the latest trend in the market, where lots of smart gadgets at home and in the office can be controlled through Alexa. But how do they work ? So, it is Alexa with Lambda that controls these smart devices. Say we have to light an LED bulb that is controlled by Alexa through a voice message, the event is triggered on the Alexa, and the Lambda function is invoked to perform the action to switch on or switch off the light. So, serverless could become the backend for all the IoT calls. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Backup and daily tasks</h1>
                </header>
            
            <article>
                
<p>Lambda functions can plays an important role with backups and daily tasks. We can schedule the Lambda functions to do repetitive tasks, such as checking for idle resources, creating backups, generating daily reports ,and various other routine jobs. The old school involved installing a task manager application that was running on the server all the time and performing the task when required. But with Lambda, functions are invoked only at a certain event or schedule. They also scale horizontally when required and also it costs less.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Continuous integration and continuous deployment</h1>
                </header>
            
            <article>
                
<p>The ability to rapidly iterate software is more important than it has ever been. CI/CD pipelines allow you to ship code in small increments, so that bug fixes and other updates can be shipped on a daily basis.</p>
<p>Serverless can automate many of these processes. Code check-ins can trigger website builds and automatic redeploys, or PRs can trigger running automated tests to make sure the code is well-tested before human review.</p>
<p>When you think about automation possibilities with serverless applications, it becomes easy to cut manual tasks out of your workflow.</p>
<p>So, we have looked at different use cases where we can use AWS Lambda functions that can perform better jobs than transitional servers or virtual machines. Currently we have a small number of serverless being used in real life, but this certainly will grow in coming years.</p>
<p>But as the use of serverless grows, managing them becomes really tedious. For example, if we use serverless for a share market portal or any ticketing application, then these applications will have many functions to work together, as the applications and <span>functions have to be versioned, built, tested , deployed, and rolled back. This is where continuous integration and continuous delivery plays a role. So, our DevOps use case would be how to set up efficient CI/CD for Lambda functions. </span></p>
<p class="mce-root">Starting with development locally, the serverless framework provides an interesting plugin, which is <strong>serverless offline.</strong> This plugin emulates AWS Lambda and the AWS API gateway locally, which helps to develop and test code locally without uploading to the AWS Cloud before we have thoroughly tested our code locally. </p>
<p>To demonstrate this, I used our earlier task pipeline and modified it to work with serverless offline with DynamoDB in local node. Interestingly, AWS provides a downloadable version of DynamoDB files that allows us to set up the DynamoDB server locally on our development area. So, this will allow us to develop a DynamoDB application locally without paying for data storage and data transfer and it also does not need internet access. You can find more information about setting up this at the following link: <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html</a>.</p>
<p>I have simply used the serverless plugin name <kbd><span>serverless</span><span>-</span><span>dynamodb</span><span>-</span><span>local</span></kbd><strong><span> </span></strong><span>to set it up locally. It is much easier to set up along with Jenkins. I created an extra stage within the</span> Jenkins<span>file</span><span>. So, here in this stage, I am installing <kbd>serverless-dynamodb-local</kbd>, <kbd>serverless-offline</kbd>, and also <kbd>serverless-mocha-plugin</kbd>, which are required plugins for us to unit test our</span> functions<span> locally before we push them into the AWS Cloud. I have added the code snippet for this and have put the code in the Git repository (<a href="https://github.com/shzshi/aws-lambda-devops-usecase.git">https://github.com/shzshi/aws-lambda-devops-usecase.git</a>): </span></p>
<div>
<pre><span>#Jenkinsfile<br/><br/>stage (</span><span>'Dev init'</span><span>)<br/></span><span>{<br/>    </span><span>nodejs </span><span>--</span><span>version<br/>    </span><span>npm install serverless</span><span>-</span><span>dynamodb</span><span>-</span><span>local </span><span>--</span><span>save</span><span>-</span><span>dev<br/>    </span><span>npm install serverless</span><span>-</span><span>offline </span><span>--</span><span>save</span><span>-</span><span>dev<br/>    </span><span>npm install serverless</span><span>-</span><span>mocha</span><span>-</span><span>plugin </span><span>--</span><span>save</span><span>-</span><span>dev<br/>    </span><span>npm install<br/>    </span><span>serverless dynamodb install<br/>    </span><span>chmod </span><span>755</span><span> startOffline</span><span>.</span><span>sh<br/>    </span><span>chmod </span><span>755</span><span> stopOffline</span><span>.</span><span>sh<br/></span><span>}</span></pre></div>
<p>In the next Jenkins stage, I am installing DynamoDB locally and adding the path local API task endpoint to the Jenkins job and invoking the serverless test. I have updated the <kbd>serverless.yml</kbd> handle and <span>also made sure to update</span> <kbd>TASKS_ENDPOINT</kbd><strong><span> </span></strong><span>within the Jenkinsfile, so the rest of the pipeline should be same as that in <a href="e7282c95-dfff-4ed6-91e2-92224fa414bf.xhtml">Chapter 3</a>, <em>Applying DevOps to AWS Lambda Applications</em>: </span></p>
<div>
<pre><span># serverless.yml<br/>plugins</span><span>:<br/>    </span><span>- </span><span>serverless-dynamodb-local<br/>    </span><span>- </span><span>serverless-offline<br/>    </span><span>- </span><span>serverless-mocha-plugin<br/></span>custom<span>:<br/>    </span>serverless-mocha-plugin<span>:<br/>        </span>preTestCommands<span>: <br/>            </span>- <span>bash startOffline.sh<br/>        </span>postTestCommands<span>:<br/>            </span>- <span>bash stopOffline.sh<br/>    </span>dynamodb<span>:<br/>      </span>stages<span>:<br/>        </span>- <span>dev<br/>      </span>start<span>:<br/>        </span>migrate<span>: </span><span>true</span></pre></div>
<div>
<pre># jenkinsfile<br/>stage ('Dev init')
        {
            steps {
                
                deleteDir()
                
                checkout scm
                
                sh '''
                    nodejs --version
                    npm cache clean --force
                    npm install serverless-offline --save-dev
                    npm install serverless-mocha-plugin --save-dev
                    serverless plugin install -n serverless-dynamodb-local
                    npm install
                '''
            }
        }

        stage ('System Test on Dev') {
             
             steps {
                sh ''' 
                    sls dynamodb remove
                    serverless dynamodb install
                    chmod 755 startOffline.sh
                    chmod 755 stopOffline.sh
                    export TASKS_ENDPOINT=http://localhost:3000
                    serverless invoke test
                '''
                }
        }<span> </span></pre></div>
<p>And the Jenkins log should look something like this: </p>
<pre>Installation complete!
+ chmod 755 startOffline.sh
+ chmod 755 stopOffline.sh
+ export TASKS_ENDPOINT=http://localhost:3000
+ serverless invoke test
Serverless: Tests being run with nodejs6.14,  service is using nodejs6.10. Tests may not be reliable.
Serverless: Run command: bash startOffline.sh


  Create, Delete
    ✓ should create a new Task, &amp; delete it (198ms)

  Create, List, Delete
    ✓ should create a new task, list it, &amp; delete it (180ms)

  Create, Read, Delete
    ✓ should create a new task, read it, &amp; delete it (133ms)


  3 passing (523ms)</pre>
<p class="CDPAlignLeft CDPAlign">And once the pipeline succeeds, it should look like the following diagram: </p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5207f5fb-0376-4a20-8622-598297b8b149.png"/></p>
<p>So, now we can develop and test our functions locally as a part of continuous integration and then move to the cloud for other non-production and production environments. But one thing that can further be automated is our Lambda API path over the cloud , as when the function is deployed to the AWS Cloud, then we will get the random hostname for the API gateway:</p>
<pre class="console-output">api keys:
  None
endpoints:
  POST - https://ax1hlqv0vl.execute-api.us-east-1.amazonaws.com/sit/mytasks
  GET - https://ax1hlqv0vl.execute-api.us-east-1.amazonaws.com/sit/mytasks
  GET - https://ax1hlqv0vl.execute-api.us-east-1.amazonaws.com/sit/mytasks/{id}
  PUT - https://ax1hlqv0vl.execute-api.us-east-1.amazonaws.com/sit/mytasks/{id}
  DELETE - https://ax1hlqv0vl.execute-api.us-east-1.amazonaws.com/sit/mytasks/{id}
functions:</pre>
<p>We have updated the task endpoint for the API hostname within our Jenkins pipeline Jenkinsfile. That is because the hostname provided by the API gateway is not static and also because every time we redeploy or remove our service the hostname will change and, accordingly, we have to to change it where ever we are using it. So, how to we resolve this problem? This can be automated through the dynamic allocation of the static domain. This is easily possible through the serverless framework, using one of its plugin, and that plugin is <kbd><span>serverless-domain-manager</span></kbd><strong><span>.</span></strong><span> Let's look at how that can be achieved. </span></p>
<p><span>Before we start using the plugin, there are a few pre-requisites: </span></p>
<ul>
<li>We need to register a desired domain name through the following link: <a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/registrar.html">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/registrar.html</a></li>
<li>We need to make sure we have have our domain name in the registered domain in Route 53 ( <a href="https://console.aws.amazon.com/route53/home?#DomainListing">https://console.aws.amazon.com/route53/home?#DomainListing</a>)</li>
<li>We need to request a new certificate for the domain we have created, which can be created through this link: <a href="https://console.aws.amazon.com/acm/home?region=us-east-1#/wizard/">https://console.aws.amazon.com/acm/home?region=us-east-1#/wizard/</a></li>
</ul>
<p>Once the pre-requisites are successfully completed, we need to install the serverless domain manager plugin:</p>
<pre><strong><span>$ npm install serverless-domain-manager --save-dev</span></strong></pre>
<p>Then within the <kbd>serverless.yml</kbd> file, we add two sections. First we add <kbd>serverless-domain-manager</kbd> in the plugins block , and then we configure the plugin with <kbd>customDomain</kbd> via the <strong>Custom</strong> block. The <kbd>basePath</kbd> attribute will be prefixed to every route of our service. Say, for example, our function is <kbd>helloworld</kbd> and we add <kbd>basePath</kbd> as <kbd>serverless</kbd><strong>, </strong>then the route that is registered as <kbd>/helloworld</kbd> will be accessed through <kbd>serverless/helloworld</kbd>. </p>
<p>For example, <kbd>https://api.&lt;registered_domain_name&gt;/serverless/helloword:</kbd></p>
<pre><span class="hljs-attr">plugins:</span><span> </span><span class="hljs-bullet"> <br/>    -</span><span> </span><span class="hljs-string">serverless-domain-manager<br/></span><span><br/></span><span class="hljs-attr">custom:</span><span> </span><span class="hljs-attr"> <br/>    customDomain:</span><span> </span><span class="hljs-attr"> <br/>        domainName:</span><span> 'api.</span><span class="hljs-string">&lt;registered_domain_name&gt;'</span><span> </span><span class="hljs-attr"> <br/>        basePath:</span><span> </span><span class="hljs-string">'&lt;my_base_path&gt;'</span><span> </span><span class="hljs-attr"> <br/>        stage:</span><span> </span><span class="hljs-string">${self:provider.stage}</span><span> </span><span class="hljs-attr">                                    createRoute53Record:</span><span> </span><span class="hljs-literal">true</span></pre>
<p>We can also set up source code analysis by integrating SonarQube or ESlint within the Jenkins pipeline. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring</h1>
                </header>
            
            <article>
                
<p>When we talk about monitoring serverless applications , we do not need to worry about monitoring CPU usage or memory usage, and we don't need to update our system package, as all these are managed by AWS. But the Lambda function still needs to be monitored for execution failures, because in a production environment one single function failure could be a disaster. </p>
<p>CloudWatch, by default, provides metrics for Lambda functionsand these metrics are: </p>
<ul>
<li><strong>Invocation</strong>: Number of times the functions were invoked </li>
<li><strong>Errors</strong>: Number of times the functions failed due to various errors, timeouts, unhandled exceptions, memory problems, and other issues</li>
<li><strong>Throttles</strong>: Number of times functions throttled, as AWS limits the number of concurrent executions per function and if we exceed the limit the function is throttled</li>
<li><strong>Duration:</strong> Invocation time of the function</li>
</ul>
<p>And errors and throttles are to be monitored 24/7 and we cannot be watching CloudWatch all the time, but we can set an alerti for all the errors and throttles. If we are using the serverless framework, then this can be managed through a plugin named <kbd>serverless-plugin-aws-alerts</kbd><span>.It makes it easy to set up alerts for the services. </span></p>
<p>To set up alerting, we need to install the plugin within our serverless framework service:</p>
<pre><strong><span>$ npm install serverless-plugin-aws-alerts --save-dev</span></strong></pre>
<p>Then we need to add it to the plugins sections and set the alerts details in the custom section within <kbd>serverless.yml</kbd>. So, this setup adds alerts to all the functions in our service when deployed to the production stage. Then we configure subscriptions for our SNS topics and each subscription has to have a protocol, which, in our case, is the email and endpoint, which is email address: </p>
<pre><span class="hljs-attr"># serverless.yml<br/>plugins:</span><span> <br/></span><span class="hljs-bullet">    -</span><span> </span><span class="hljs-string">serverless-plugin-aws-alerts</span><span> <br/></span><span class="hljs-attr">custom:</span><span> </span><span class="hljs-attr"> <br/>    alerts:</span><span> </span><span class="hljs-attr"> <br/>        stages:</span><span> </span><span class="hljs-bullet"> <br/>            -</span><span> </span><span class="hljs-string">production</span><span class="hljs-attr"><br/>         topics:</span><span> </span><span class="hljs-attr"> <br/>             alarm:</span><span> </span><span class="hljs-attr"> <br/>                topic:</span><span> </span><span class="hljs-string">${self:service}-${opt:stage}-alerts-alarm<br/>                </span><span class="hljs-attr">notifications:</span><span> </span><span class="hljs-attr"> <br/>                    - protocol:</span><span> </span><span class="hljs-string">email</span><span> </span><span class="hljs-attr"> <br/>                      endpoint:</span><span> </span><span class="hljs-string">myemail@domain.com</span><span> </span><span> </span><span class="hljs-attr"> <br/>                alarms:</span><span> </span><span class="hljs-bullet"> <br/>                    -</span><span> </span><span class="hljs-string">functionErrors</span><span> </span><span class="hljs-bullet"> <br/>                    -</span><span> </span><span class="hljs-string">functionThrottles</span></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Static website</h1>
                </header>
            
            <article>
                
<p>AWS Lambda function will play the role of the backbone of our web application. We also need a cosmetic frontend too to be deployed along with the Lambda function and there is a serverless framework plugin available that can perform this task with ease. That plugin is <kbd>serverless-finch</kbd>. This plugin will upload static assets of our web application into AWS s3. </p>
<p>Let's look at how it works. To use this plugin, we need to first install it and then configure it into our <kbd>serverless.yml</kbd> file:</p>
<pre><strong>$ npm install --save serverless-finch</strong></pre>
<p>So once the plugin is installed, we first need to create a distribution folder that, by default, would be <span><kbd>client</kbd>/<kbd>dist</kbd>, which is also configurable through a <kbd>custom</kbd> tag. So, all our static content will reside in the <kbd>client</kbd>/<kbd>dist</kbd> folder: </span></p>
<pre><span class="pl-ent">custom</span>:
  <span class="pl-ent">client</span>:
    <span class="pl-s">...</span>
    <span class="pl-ent">distributionFolder</span>: <span class="pl-s">[path/to/files]</span>
    <span class="pl-s">...</span></pre>
<p><span>Then next we need to mention the S3 bucket name within the custom tag to which static files will be uploaded:  </span></p>
<pre><span class="pl-ent">custom</span>:
  <span class="pl-ent">client</span>:
    <span class="pl-ent">bucketName</span>: <span class="pl-s">[unique-s3-bucketname]</span></pre>
<p><span> So, ideally <kbd>serverless.yml</kbd> should look something like this, where we define the provider, add the plugin configuration for <kbd>serverless-finch</kbd>, and define the client details with the <kbd>custom</kbd> tag. The <kbd>indexDocument</kbd> parameter is for the index page and the <kbd>errorDocument</kbd> parameter is for the error page:<br/></span></p>
<pre>service: my-static-website

frameworkVersion: "=1.26.0"

provider:
  name: aws
  runtime: nodejs6.10
  stage: dev
  region: us-east-1
  profile: dev-profile

plugins:
  - serverless-finch

custom:
  client:
    bucketName: my-static-pages-bucket
    distributionFolder: client/dist 
    indexDocument: index.html
    errorDocument: index.html
  </pre>
<p><span>Finally, to deploy the content, we have run the following command and we should be able to see the location of the newly deployed website on the console output of the serverless application:</span></p>
<pre><strong>$ serverless client deploy </strong></pre>
<p><span>There are many more configuration parameters and features that are provided by this plugin. You can find them through at the link:  <a href="https://github.com/fernando-mc/serverless-finch">https://github.com/fernando-mc/serverless-finch</a>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Warm-up</h1>
                </header>
            
            <article>
                
<p>A cold start is one of the major issues with respect to serverless function. The warmer the functions are, the better performance we get. But how do we keep our functions warm all the time? The serverless framework provide a plugin to help us do that. The plugin's name is Serverless WarmUP <span>Plugin</span><span>.</span><span> So, how does this plugin work? </span></p>
<p>The plugin creates a scheduled event Lambda that invokes all the service Lambdas we select in the time interval. So this plugin will keep the function warm by forcing the underlying container's to stay alive. To set up this plugin, we need to first install it:</p>
<pre><strong>$ npm install serverless-plugin-warmup --save-dev</strong></pre>
<p>Then in <kbd>serverless.yml</kbd>, we can configure it by calling it under the plugins section. We need to mention which environment warm-up should be run, which can be single or multiple. Then in the custom section, we need to define the configuration for the warm Lambda function to run. It can be further configured and details of those configuration can be found at the link: <a href="https://github.com/FidelLimited/serverless-plugin-warmup">https://github.com/FidelLimited/serverless-plugin-warmup</a>.</p>
<pre><span class="pl-ent"># serverless.yml<br/>plugins</span>:
  - <span class="pl-s">serverless-plugin-warmup<br/></span><span class="pl-ent">functions</span>:
  <span class="pl-ent">hello</span>:
    <span class="pl-ent">warmup</span>:
      - <span class="pl-s">production</span>
      - <span class="pl-s">staging<br/></span><span class="pl-ent">custom</span>:
  <span class="pl-ent">warmup</span>:
    <span class="pl-ent">folderName</span>: <span class="pl-s"><span class="pl-pds">'</span>_warmup<span class="pl-pds">'</span></span> <span class="pl-s">// Name of the folder created for the generated warmup </span>
    <span class="pl-ent">cleanFolder</span>: <span class="pl-c1">false</span>
    <span class="pl-ent">memorySize</span>: <span class="pl-c1">256</span>
    <span class="pl-ent">name</span>: <span class="pl-s"><span class="pl-pds">'</span>warm-my-lambdas<span class="pl-pds">'</span></span>
    <span class="pl-ent">role</span>: <span class="pl-s">myCustRole0</span>
    <span class="pl-ent">schedule</span>: <span class="pl-s"><span class="pl-pds">'</span>cron(0/5 8-17 ? * MON-FRI *)<span class="pl-pds">'</span></span> <span class="pl-s">// Run WarmUP every 5 minutes Mon-Fri between 8:00am and 5:55pm (UTC)</span>
    <span class="pl-ent">timeout</span>: <span class="pl-c1">20</span>
    <span class="pl-ent">prewarm</span>: <span class="pl-s">true // Run WarmUp immediately after a deploymentlambda</span>
    <span class="pl-ent">tags</span>:
      <span class="pl-ent">Project</span>: <span class="pl-s">foo</span>
      <span class="pl-ent">Owner</span>: <span class="pl-s">bar  </span></pre>
<p>These are a few add-ons for Lambda functions that can help us to make things easier to create and maintain serverless functions. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Azure Functions add-ons</h1>
                </header>
            
            <article>
                
<p>In DevOps, it is very important to make sure development is smoother and faster and that we deploy bug-free applications to production. It is possible if we can develop, debug, and test the application locally. But with respect to Azure functions, to test and debug the functions, we need to deploy it on the Azure Cloud each time. The good news is that, like AWS Lambda, Azure functions can be debugged and tested locally by means of the <strong>Azure functions core tools </strong>.</p>
<p>With Azure functions tools, we can create, develop, test, run, and debug the Azure functions locally. They can be installed on Windows, macOS, and Linux.  We can visit the GitHub link for how to set them up: <a href="https://github.com/Azure/azure-functions-core-tools">https://github.com/Azure/azure-functions-core-tools</a></p>
<p>After, we have installed the tools, we need to first create the<kbd>create function</kbd> app. By default, this will also create a local Git repository that can skipped by passing a parameter, <kbd>-n</kbd>:</p>
<pre>$ mkdir my-local-azure-function<br/>$ cd my-local-azure-function<br/>$ func init -n <br/>Writing .gitignore<br/>Writing host.json<br/>Writing local.settings.json<br/>Created launch.json</pre>
<p>The next step is to create the function by executing <kbd>f<span>unc new</span></kbd><span>. We will be asked few options with respect to the type of function we want to create and what type of</span> language<span> we want choose for our function and then a function folder is created with three files, <kbd>function.json</kbd>, <kbd>index.js</kbd>, and <kbd>sample.dat</kbd>:</span></p>
<pre><strong>$ func new</strong><br/><strong>Select a language:</strong><br/><strong>1. C#</strong><br/><strong>2. JavaScript</strong><br/><strong>Choose option: 2</strong><br/><strong>JavaScript</strong><br/><strong>Select a template:</strong><br/><strong>1. Blob trigger</strong><br/><strong>2. Cosmos DB trigger</strong><br/><strong>3. Event Grid trigger</strong><br/><strong>4. HTTP trigger</strong><br/><strong>5. Queue trigger</strong><br/><strong>6. SendGrid</strong><br/><strong>7. Service Bus Queue trigger</strong><br/><strong>8. Service Bus Topic trigger</strong><br/><strong>9. Timer trigger</strong><br/><strong>Choose option: 4</strong><br/><strong>HTTP trigger</strong><br/><strong>Function name: [HttpTriggerJS] my-azure-func-use-case</strong><br/><strong>Writing /Users/shashi/Documents/packt/chapter4/tutorial1/mylocalfunction/myLocalFunction/index.js</strong><br/><strong>Writing /Users/shashi/Documents/packt/chapter4/tutorial1/mylocalfunction/myLocalFunction/sample.dat</strong><br/><strong>Writing /Users/shashi/Documents/packt/chapter4/tutorial1/mylocalfunction/myLocalFunction/function.json</strong></pre>
<p>As we have the function baked in through a template, we can now invoke the function locally by <kbd>func start</kbd> and this command will start the function app locally and provide us with the API URL: </p>
<pre><strong>$ func start</strong><br/><strong>%%%%%%</strong><br/><strong> %%%%%%</strong><br/><strong> @ %%%%%% @</strong><br/><strong> @@ %%%%%% @@</strong><br/><strong> @@@ %%%%%%%%%%% @@@</strong><br/><strong> @@ %%%%%%%%%% @@</strong><br/><strong> @@ %%%% @@</strong><br/><strong> @@ %%% @@</strong><br/><strong> @@ %% @@</strong><br/><strong> %%</strong><br/><strong> %</strong><br/><strong>[09/20/2018 20:57:09] Reading host configuration file '/Users/shashi/Documents/packt/chapter9/my-local-azure-function/host.json'</strong><br/><strong>[09/20/2018 20:57:09] Host configuration file read:</strong><br/><strong>[09/20/2018 20:57:09] {}</strong><br/><strong>info: Worker.Node.769f18ed-34f3-4813-9e9f-b4d43ea01191[0]</strong><br/><strong> Start Process: node --inspect=5858 "/usr/local/lib/node_modules/azure-functions-core-tools/bin/workers/node/dist/src/nodejsWorker.js" --host 127.0.0.1 --port 65058 --workerId 769f18ed-34f3-4813-9e9f-b4d43ea01191 --requestId 964f6629-d61a-4006-a293-e0438da20e45</strong><br/><strong>info: Worker.Node.769f18ed-34f3-4813-9e9f-b4d43ea01191[0]</strong><br/><strong> Debugger listening on ws://127.0.0.1:5858/0d0bfa98-d2a3-4af2-8c5c-3a2cc346b1fc</strong><br/><strong>info: Worker.Node.769f18ed-34f3-4813-9e9f-b4d43ea01191[0]</strong><br/><strong> For help see https://nodejs.org/en/docs/inspector</strong><br/><strong>[09/20/2018 20:57:10] Generating 1 job function(s)</strong><br/><strong>[09/20/2018 20:57:10] Starting Host (HostId=shashismacbookpro-628939497, Version=2.0.11415.0, ProcessId=5072, Debug=False, ConsecutiveErrors=0, StartupCount=1, FunctionsExtensionVersion=)</strong><br/><strong>[09/20/2018 20:57:10] Found the following functions:</strong><br/><strong>[09/20/2018 20:57:10] Host.Functions.my-azure-func-use-case</strong><br/><strong>[09/20/2018 20:57:10]</strong><br/><strong>[09/20/2018 20:57:10] Job host started</strong><br/><strong>info: Worker.Node.769f18ed-34f3-4813-9e9f-b4d43ea01191[0]</strong><br/><strong> Worker 769f18ed-34f3-4813-9e9f-b4d43ea01191 connecting on 127.0.0.1:65058</strong><br/><strong>Listening on http://localhost:7071/</strong><br/><strong>Hit CTRL-C to exit...</strong><br/><strong>Http Functions:</strong><br/><strong>my-azure-func-use-case: http://localhost:7071/api/my-azure-func-use-case</strong></pre>
<p class="CDPAlignLeft CDPAlign"><span>What the function does when invoked from <kbd>http</kbd> is to retrieve request data via the <kbd>req</kbd> parameter and look for the <kbd>name</kbd> parameter in the request body and, on successful execution, add some response text: </span></p>
<p class="CDPAlignCenter CDPAlign"><span><img src="assets/8a9432c0-91cc-4342-8e47-7199b52611b4.png" style="width:61.42em;height:5.58em;"/></span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Google Functions add-ons</h1>
                </header>
            
            <article>
                
<p>When we decide to move toward a cloud infrastructure or decide to use Google Functions, then we start with a proof of concept or minimal viable product, to prove our application can perform better in the cloud and that we do not have to worry about infrastructure. Also, if the number of the functions is small at the the time of POC, it is easier to develop, test, and deploy them manually, but as they grow, it become quite difficult to manage development, testing and development. Integrating them together to work as an application is another challenge. So, for smoother development, Google also has introduced the Node.js emulator for Google cloud functions. Although currently it is released as the alpha phase, it is still good to iron out quite a number of the issues locally. </p>
<p>The Node.js emulator for Google Functions is distributed as an npm standard package, so it has to be installed through the <kbd>npm</kbd> command:</p>
<pre class="devsite-code-button-clone"><strong>$ npm install -g @google-cloud/functions-emulator</strong></pre>
<p>After installation there are many commands that can be used for setting up local environments for testing and debugging the Google Functions. More details can be found at <a href="https://cloud.google.com/functions/docs/emulator">https://cloud.google.com/functions/docs/emulator</a></p>
<p>In the chapter, <em>DevOps with Google Functions</em>, we learned how to deploy using Google Cloud's out-of-the box tools, but they can also be deployed in the serverless framework, which also provides templates to start with.</p>
<p>To use the serverless framework, we need to first install the framework plugin. The name of the plugin is <kbd>serverless-google-cloudfunctions</kbd>. So, if we need to do a quick start with Google Functions , then we should start with the following command that will create a simple <kbd>helloworld</kbd> Google Function with the filenames as <kbd>index</kbd>, <kbd>serverless.yml</kbd>, and <kbd>package.json</kbd>. Currently the serverless framework supports just Node.js at runtime:</p>
<pre><strong>$ <span>serverless create --template google-nodejs --path my-service-name</span></strong></pre>
<p>In <kbd>serverless.yml</kbd>, we need to configure the Google project name and credentials. The credentials JSON file needs to be the absolute path. But for security reason, it should be kept somewhere really safe within the server path:</p>
<pre><span>provider</span><span>:<br/>    </span><span>name</span><span>: </span><span>google<br/>    </span><span>runtime</span><span>: </span><span>nodejs<br/>    </span><span>project</span><span>: </span><span>my-serverless-function-usecase<br/>    </span><span># the path to the credentials file needs to be absolute<br/>    </span><span>credentials</span><span>: ~/.gcloud</span><span>/Serverless-SIT.json<br/></span><span>plugins</span><span>:<br/>    </span><span>- </span><span>serverless-google-cloudfunctions</span></pre>
<p>Then deploy it on to the google cloud through Serverless command</p>
<pre>$ serverless deploy -v<br/>Serverless: Packaging service...<br/>Serverless: Excluding development dependencies...<br/>Serverless: Compiling function "first"...<br/>Serverless: Uploading artifacts...<br/>Serverless: Artifacts successfully uploaded...<br/>Serverless: Updating deployment...<br/>Serverless: Checking deployment update progress...<br/>...............<br/>Serverless: Done...<br/>Service Information<br/>service: my-g-function-usecase<br/>project: serverless-sit-217120<br/>stage: dev<br/>region: us-central1<br/>Deployed functions<br/>first<br/> https://us-central1-serverless-sit-217120.cloudfunctions.net/http</pre>
<p>Once deployed successfully, we should get the API link in the deployment output and which can we used and in our we can browse it through the browser and the screen should display </p>
<p><strong>Hello World!</strong></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we looked at some popular use cases for serverless and also some essentials that can improve the development and deployment. In the next and the final chapter, we will see how serverless will shape the DevOps and how DevOps has to change its track with the adoption of serverless.</p>


            </article>

            
        </section>
    </body></html>