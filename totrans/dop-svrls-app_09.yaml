- en: Use Cases and Add-Ons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned how to apply some best practices in relation
    to serverless functions and DevOps. We understood how important it is to build
    light and secure serverless functions. We also learned about some best practices for
    monitoring and logging a serverless application. So, moving forward, let's look
    at the big picture of how serverless can be used in the real world and also learn
    how we can implement end-to-end DevOps around it.
  prefs: []
  type: TYPE_NORMAL
- en: As developers are moving from monolithic application toward the serverless architecture
    more and more use cases are coming into existence. But it is getting equally more
    difficult to build, test and deploy them. So, in this chapter, we will learn few
    serverless use cases and also learn how to set up end-to-end deployment pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: AWS Lambda use cases and add-ons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Functions add-ons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Functions add-ons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS Lambda use cases and add-ons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our journey so far has been about what AWS Lambda is , and how we can build
    ,test, deploy, monitor, and log it. We also looked at some best practices for
    AWS Lambda in general and also for DevOps. So now, here in this chapter, it is
    time to bring them all together as one use case. Before we cover the use case
    for DevOps with AWS Lambda, let's start to first look at use cases where Lambda
    can be efficiently used and then let's look at how DevOps can make life easier
    for developers and business users.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Lambda use cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we know, serverless architecture was introduced to help businesses to focus
    on application development and not to worry about the underlying servers. Reducing
    the cost and shortening the deployment cycle, the adoption rate for serverless
    is growing exponentially. Now lots of companies are adopting serverless as a way
    to ensure rapid auto scaling and descaling. Let's look at some of the useful applications
    of serverless that are being adopted across the industry.
  prefs: []
  type: TYPE_NORMAL
- en: Serverless website
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The best model for serverless adoption would be websites that want to take advantage
    of AWS Lambda and AWS S3\. Both of these resources provided by AWS are very cheap.
    Also, with AWS Lambda, it can scale on demand and descale as demand slows downs.
    So they do not have to pay big money for keeping a server up and running all the
    time. So we can consider hosting the static content or the frontend on the S3
    bucket and these frontend applications can send requests to Lambda functions via
    the API gateway HTTPS endpoints and Lambda does all the heavy lifting of the application
    logic and persists the data to a a fully-managed database service (**RDBMS** (**relational
    databases**) or **DynamoDB** (**non-relational databases**) ). We can host our
    Lambda function within VPCs to isolate them from different other networks and
    it is also cheaper, as we pay only for the traffic incurred by AWS S3 and AWS
    Lambda with the extra cost for the database service.
  prefs: []
  type: TYPE_NORMAL
- en: Video and image processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With Instagram becoming more popular, a lot can be done with images and videos,
    but it is equally expensive to process or resize them. The traditional way of
    editing the videos and images would be to host a VM that is always running and
    when an image or video arrives for editing then running the application within
    the VM. But we have to incur costs for running the VM 24/7 without it being used
    all the time. Serverless could be the best option for these types of jobs. Serverless
    services can be used to dynamically resize the image or change the video transcoding
    for different target devices.
  prefs: []
  type: TYPE_NORMAL
- en: Also, with serverless, we can tap into the Google Vision API or Amazon Recognition
    to recognize faces and images or flat inappropriate content. In the AWS chapter,
    we created a tutorial where an image is uploaded into one S3 bucket and then Lambda
    is automatically triggered when the image is uploaded to the S3 bucket to resize
    it and push it to another bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Logs Processing and notification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can use Lambda functions to harvest the logs from CloudTrail and CloudWatch,
    Lambda watches for specific triggers and log entries and invokes an SNS notification
    on the event. These notifications can be configured and sent to Slack, Jabber,
    or other support systems.
  prefs: []
  type: TYPE_NORMAL
- en: Controlling the IoT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Internet of things** (**IoT**) is the latest trend in the market, where
    lots of smart gadgets at home and in the office can be controlled through Alexa.
    But how do they work ? So, it is Alexa with Lambda that controls these smart devices.
    Say we have to light an LED bulb that is controlled by Alexa through a voice message,
    the event is triggered on the Alexa, and the Lambda function is invoked to perform
    the action to switch on or switch off the light. So, serverless could become the
    backend for all the IoT calls.
  prefs: []
  type: TYPE_NORMAL
- en: Backup and daily tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lambda functions can plays an important role with backups and daily tasks. We
    can schedule the Lambda functions to do repetitive tasks, such as checking for
    idle resources, creating backups, generating daily reports ,and various other
    routine jobs. The old school involved installing a task manager application that
    was running on the server all the time and performing the task when required.
    But with Lambda, functions are invoked only at a certain event or schedule. They
    also scale horizontally when required and also it costs less.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous integration and continuous deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ability to rapidly iterate software is more important than it has ever been.
    CI/CD pipelines allow you to ship code in small increments, so that bug fixes
    and other updates can be shipped on a daily basis.
  prefs: []
  type: TYPE_NORMAL
- en: Serverless can automate many of these processes. Code check-ins can trigger
    website builds and automatic redeploys, or PRs can trigger running automated tests
    to make sure the code is well-tested before human review.
  prefs: []
  type: TYPE_NORMAL
- en: When you think about automation possibilities with serverless applications,
    it becomes easy to cut manual tasks out of your workflow.
  prefs: []
  type: TYPE_NORMAL
- en: So, we have looked at different use cases where we can use AWS Lambda functions
    that can perform better jobs than transitional servers or virtual machines. Currently
    we have a small number of serverless being used in real life, but this certainly
    will grow in coming years.
  prefs: []
  type: TYPE_NORMAL
- en: But as the use of serverless grows, managing them becomes really tedious. For
    example, if we use serverless for a share market portal or any ticketing application,
    then these applications will have many functions to work together, as the applications
    and functions have to be versioned, built, tested , deployed, and rolled back.
    This is where continuous integration and continuous delivery plays a role. So,
    our DevOps use case would be how to set up efficient CI/CD for Lambda functions.
  prefs: []
  type: TYPE_NORMAL
- en: Starting with development locally, the serverless framework provides an interesting
    plugin, which is **serverless offline.** This plugin emulates AWS Lambda and the
    AWS API gateway locally, which helps to develop and test code locally without
    uploading to the AWS Cloud before we have thoroughly tested our code locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate this, I used our earlier task pipeline and modified it to work
    with serverless offline with DynamoDB in local node. Interestingly, AWS provides
    a downloadable version of DynamoDB files that allows us to set up the DynamoDB
    server locally on our development area. So, this will allow us to develop a DynamoDB
    application locally without paying for data storage and data transfer and it also
    does not need internet access. You can find more information about setting up
    this at the following link: [https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'I have simply used the serverless plugin name `serverless-dynamodb-local`to
    set it up locally. It is much easier to set up along with Jenkins. I created an
    extra stage within the Jenkinsfile. So, here in this stage, I am installing `serverless-dynamodb-local`,
    `serverless-offline`, and also `serverless-mocha-plugin`, which are required plugins
    for us to unit test our functions locally before we push them into the AWS Cloud.
    I have added the code snippet for this and have put the code in the Git repository
    ([https://github.com/shzshi/aws-lambda-devops-usecase.git](https://github.com/shzshi/aws-lambda-devops-usecase.git)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next Jenkins stage, I am installing DynamoDB locally and adding the
    path local API task endpoint to the Jenkins job and invoking the serverless test.
    I have updated the `serverless.yml` handle and also made sure to update `TASKS_ENDPOINT`within
    the Jenkinsfile, so the rest of the pipeline should be same as that in [Chapter
    3](e7282c95-dfff-4ed6-91e2-92224fa414bf.xhtml), *Applying DevOps to AWS Lambda
    Applications*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'And the Jenkins log should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'And once the pipeline succeeds, it should look like the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5207f5fb-0376-4a20-8622-598297b8b149.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So, now we can develop and test our functions locally as a part of continuous
    integration and then move to the cloud for other non-production and production
    environments. But one thing that can further be automated is our Lambda API path
    over the cloud , as when the function is deployed to the AWS Cloud, then we will
    get the random hostname for the API gateway:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We have updated the task endpoint for the API hostname within our Jenkins pipeline
    Jenkinsfile. That is because the hostname provided by the API gateway is not static
    and also because every time we redeploy or remove our service the hostname will
    change and, accordingly, we have to to change it where ever we are using it. So,
    how to we resolve this problem? This can be automated through the dynamic allocation
    of the static domain. This is easily possible through the serverless framework,
    using one of its plugin, and that plugin is `serverless-domain-manager`**.** Let's
    look at how that can be achieved.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we start using the plugin, there are a few pre-requisites:'
  prefs: []
  type: TYPE_NORMAL
- en: We need to register a desired domain name through the following link: [https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/registrar.html](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/registrar.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to make sure we have have our domain name in the registered domain in
    Route 53 ( [https://console.aws.amazon.com/route53/home?#DomainListing](https://console.aws.amazon.com/route53/home?#DomainListing))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to request a new certificate for the domain we have created, which can
    be created through this link: [https://console.aws.amazon.com/acm/home?region=us-east-1#/wizard/](https://console.aws.amazon.com/acm/home?region=us-east-1#/wizard/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once the pre-requisites are successfully completed, we need to install the
    serverless domain manager plugin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Then within the `serverless.yml` file, we add two sections. First we add `serverless-domain-manager`
    in the plugins block , and then we configure the plugin with `customDomain` via
    the **Custom** block. The `basePath` attribute will be prefixed to every route
    of our service. Say, for example, our function is `helloworld` and we add `basePath` as
    `serverless`**, **then the route that is registered as `/helloworld` will be accessed
    through `serverless/helloworld`.
  prefs: []
  type: TYPE_NORMAL
- en: For example, `https://api.<registered_domain_name>/serverless/helloword:`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We can also set up source code analysis by integrating SonarQube or ESlint within
    the Jenkins pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we talk about monitoring serverless applications , we do not need to worry
    about monitoring CPU usage or memory usage, and we don't need to update our system
    package, as all these are managed by AWS. But the Lambda function still needs
    to be monitored for execution failures, because in a production environment one
    single function failure could be a disaster.
  prefs: []
  type: TYPE_NORMAL
- en: 'CloudWatch, by default, provides metrics for Lambda functionsand these metrics
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Invocation**: Number of times the functions were invoked'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Errors**: Number of times the functions failed due to various errors, timeouts,
    unhandled exceptions, memory problems, and other issues'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Throttles**: Number of times functions throttled, as AWS limits the number
    of concurrent executions per function and if we exceed the limit the function
    is throttled'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Duration:** Invocation time of the function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And errors and throttles are to be monitored 24/7 and we cannot be watching
    CloudWatch all the time, but we can set an alerti for all the errors and throttles.
    If we are using the serverless framework, then this can be managed through a plugin
    named `serverless-plugin-aws-alerts`.It makes it easy to set up alerts for the
    services.
  prefs: []
  type: TYPE_NORMAL
- en: 'To set up alerting, we need to install the plugin within our serverless framework
    service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we need to add it to the plugins sections and set the alerts details in
    the custom section within `serverless.yml`. So, this setup adds alerts to all
    the functions in our service when deployed to the production stage. Then we configure
    subscriptions for our SNS topics and each subscription has to have a protocol,
    which, in our case, is the email and endpoint, which is email address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Static website
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS Lambda function will play the role of the backbone of our web application.
    We also need a cosmetic frontend too to be deployed along with the Lambda function
    and there is a serverless framework plugin available that can perform this task
    with ease. That plugin is `serverless-finch`. This plugin will upload static assets
    of our web application into AWS s3.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at how it works. To use this plugin, we need to first install it
    and then configure it into our `serverless.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'So once the plugin is installed, we first need to create a distribution folder
    that, by default, would be `client`/`dist`, which is also configurable through
    a `custom` tag. So, all our static content will reside in the `client`/`dist`
    folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then next we need to mention the S3 bucket name within the custom tag to which
    static files will be uploaded:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'So, ideally `serverless.yml` should look something like this, where we define
    the provider, add the plugin configuration for `serverless-finch`, and define
    the client details with the `custom` tag. The `indexDocument` parameter is for
    the index page and the `errorDocument` parameter is for the error page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, to deploy the content, we have run the following command and we should
    be able to see the location of the newly deployed website on the console output
    of the serverless application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: There are many more configuration parameters and features that are provided
    by this plugin. You can find them through at the link:  [https://github.com/fernando-mc/serverless-finch](https://github.com/fernando-mc/serverless-finch).
  prefs: []
  type: TYPE_NORMAL
- en: Warm-up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A cold start is one of the major issues with respect to serverless function.
    The warmer the functions are, the better performance we get. But how do we keep
    our functions warm all the time? The serverless framework provide a plugin to
    help us do that. The plugin's name is Serverless WarmUP Plugin. So, how does this
    plugin work?
  prefs: []
  type: TYPE_NORMAL
- en: 'The plugin creates a scheduled event Lambda that invokes all the service Lambdas
    we select in the time interval. So this plugin will keep the function warm by
    forcing the underlying container''s to stay alive. To set up this plugin, we need
    to first install it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Then in `serverless.yml`, we can configure it by calling it under the plugins
    section. We need to mention which environment warm-up should be run, which can
    be single or multiple. Then in the custom section, we need to define the configuration
    for the warm Lambda function to run. It can be further configured and details
    of those configuration can be found at the link: [https://github.com/FidelLimited/serverless-plugin-warmup](https://github.com/FidelLimited/serverless-plugin-warmup).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: These are a few add-ons for Lambda functions that can help us to make things
    easier to create and maintain serverless functions.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Functions add-ons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In DevOps, it is very important to make sure development is smoother and faster
    and that we deploy bug-free applications to production. It is possible if we can
    develop, debug, and test the application locally. But with respect to Azure functions,
    to test and debug the functions, we need to deploy it on the Azure Cloud each
    time. The good news is that, like AWS Lambda, Azure functions can be debugged
    and tested locally by means of the **Azure functions core tools **.
  prefs: []
  type: TYPE_NORMAL
- en: With Azure functions tools, we can create, develop, test, run, and debug the
    Azure functions locally. They can be installed on Windows, macOS, and Linux. 
    We can visit the GitHub link for how to set them up: [https://github.com/Azure/azure-functions-core-tools](https://github.com/Azure/azure-functions-core-tools)
  prefs: []
  type: TYPE_NORMAL
- en: 'After, we have installed the tools, we need to first create the`create function`
    app. By default, this will also create a local Git repository that can skipped
    by passing a parameter, `-n`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to create the function by executing `func new`. We will be
    asked few options with respect to the type of function we want to create and what
    type of language we want choose for our function and then a function folder is
    created with three files, `function.json`, `index.js`, and `sample.dat`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'As we have the function baked in through a template, we can now invoke the
    function locally by `func start` and this command will start the function app
    locally and provide us with the API URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'What the function does when invoked from `http` is to retrieve request data
    via the `req` parameter and look for the `name` parameter in the request body
    and, on successful execution, add some response text:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8a9432c0-91cc-4342-8e47-7199b52611b4.png)'
  prefs: []
  type: TYPE_IMG
- en: Google Functions add-ons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we decide to move toward a cloud infrastructure or decide to use Google
    Functions, then we start with a proof of concept or minimal viable product, to
    prove our application can perform better in the cloud and that we do not have
    to worry about infrastructure. Also, if the number of the functions is small at
    the the time of POC, it is easier to develop, test, and deploy them manually,
    but as they grow, it become quite difficult to manage development, testing and
    development. Integrating them together to work as an application is another challenge.
    So, for smoother development, Google also has introduced the Node.js emulator
    for Google cloud functions. Although currently it is released as the alpha phase,
    it is still good to iron out quite a number of the issues locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Node.js emulator for Google Functions is distributed as an npm standard
    package, so it has to be installed through the `npm` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: After installation there are many commands that can be used for setting up local
    environments for testing and debugging the Google Functions. More details can
    be found at [https://cloud.google.com/functions/docs/emulator](https://cloud.google.com/functions/docs/emulator)
  prefs: []
  type: TYPE_NORMAL
- en: In the chapter, *DevOps with Google Functions*, we learned how to deploy using
    Google Cloud's out-of-the box tools, but they can also be deployed in the serverless
    framework, which also provides templates to start with.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use the serverless framework, we need to first install the framework plugin.
    The name of the plugin is `serverless-google-cloudfunctions`. So, if we need to
    do a quick start with Google Functions , then we should start with the following
    command that will create a simple `helloworld` Google Function with the filenames
    as `index`, `serverless.yml`, and `package.json`. Currently the serverless framework
    supports just Node.js at runtime:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In `serverless.yml`, we need to configure the Google project name and credentials.
    The credentials JSON file needs to be the absolute path. But for security reason,
    it should be kept somewhere really safe within the server path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Then deploy it on to the google cloud through Serverless command
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Once deployed successfully, we should get the API link in the deployment output
    and which can we used and in our we can browse it through the browser and the
    screen should display
  prefs: []
  type: TYPE_NORMAL
- en: '**Hello World!**'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at some popular use cases for serverless and also
    some essentials that can improve the development and deployment. In the next and
    the final chapter, we will see how serverless will shape the DevOps and how DevOps
    has to change its track with the adoption of serverless.
  prefs: []
  type: TYPE_NORMAL
