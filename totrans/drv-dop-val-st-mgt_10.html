<html><head></head><body>
		<div id="_idContainer082">
			<h1 id="_idParaDest-169"><em class="italic"><a id="_idTextAnchor209"/></em><a href="B17087_08_Final_PD_epub.xhtml#_idTextAnchor209"><em class="italic">Chapter 8</em></a>: Identifying Lean Metrics  (VSM Step 5)</h1>
			<p>Having completed the current value stream map, we now turn our attention to evaluating potential future state opportunities to synchronize our flows and eliminate waste, in order to increase value for our customers. But first, we must identify our objectives in the form of quantifiable and measurable Lean metrics, which will be the fifth VSM step and is introduced in this chapter.  </p>
			<p>It's difficult to improve things without having measures of the current state and desired future states. It's like driving in a car to a new destination without an address or a map. Without these items, you don't know which roads to take, how far you have to go, or even how to know when you have arrived. This chapter helps you identify the key metrics that will inform your decisions in building the value stream maps that define your desired future destinations. </p>
			<p>After reading this chapter, you will know the basic Lean metrics that help organizations and VSM teams assess areas for improvement across virtually any value stream. You will also learn the metrics that most apply to assessing the performance of modern DevOps-based software delivery teams and pipelines. Finally, you will learn about the tools that support the gathering of Lean metrics.</p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Defining universal Lean metrics</li>
				<li>Assessing Lean performance</li>
				<li>Measuring key software delivery metrics</li>
				<li>Adding flow metrics and analytics to VSM</li>
				<li>Implementing the tools of Lean metrics</li>
			</ul>
			<h1 id="_idParaDest-170"><a id="_idTextAnchor210"/>Defining universal Lean metrics</h1>
			<p>We've already introduced<a id="_idIndexMarker771"/> some Lean metrics in the previous chapter on current-state value stream mapping. However, we did not take the time to define Lean metrics other than metrics explicitly related to software delivery performance. Additionally, there are many traditional Lean metrics that you and your VSM team need to understand how to use, as identified in the following list:</p>
			<ul>
				<li><strong class="bold">Cycle time </strong>(<strong class="bold">CT</strong>): The CT<a id="_idIndexMarker772"/> is the timespan between starting<a id="_idIndexMarker773"/> and finishing a process or a value stream activity. The CT is actually a measure of throughput (units per period of time). So, if we can produce 40 widgets in a 40-hour work week, our cycle time is<img src="image/B17087_08_001.png" alt=""/> The VSM team only includes working time and does not include <strong class="bold">work in progress</strong> (<strong class="bold">WIP</strong>), nor<a id="_idIndexMarker774"/> the waiting time between value stream activities. However, the CT is not always all <strong class="bold">value-adding time</strong> (<strong class="bold">VT</strong>). There<a id="_idIndexMarker775"/> can be elements of non-value-adding work within the activity in the form of waste. This waste includes defects, inventory, motion, over-processing, overproduction, transport, and waiting.<p>For example, suppose an operator pulls a work item but must wait to retrieve information, materials, or reviewing information to start their work. In that case, that type of waiting is still part of the activity's CT. Additionally, time spent setting up equipment or changing materials is part of the CT.</p><p>Using a real-life example, I recently had some landscape work done in my backyard. The materials vendor dropped the items off on pallets in my driveway. I had to pay the landscaping contractor for their team's labor hours to break down pallets and manually move the materials into my backyard. As a paying customer, I preferred that the pallets were dropped off directly in my backyard. As a result, the CT I paid for included the value-adding landscaping work, plus the non-value-adding work of moving the materials, this being a Lean-oriented waste in the form of motion. </p></li>
				<li><strong class="bold">Days of inventory on hand</strong>: This is the amount of material, parts, or products stored and quantified<a id="_idIndexMarker776"/> in daily production usage. For example, if we use 20 widgets per day and have 100 widgets in inventory, we have 5 days of widget inventory on hand.</li>
				<li><strong class="bold">Defects per million opportunities</strong> (<strong class="bold">DPMO)</strong>:  This is a measure of how many defects<a id="_idIndexMarker777"/> occur in every million opportunities<a id="_idIndexMarker778"/> to have a defect. For example, we might have 40 defects per every one million activities. Or, we might have 40 defects per every one million lines of code produced. Therefore, we need to be concise in explaining what type of defect ratio the DPMO is measuring. <p>Our quality objective is always to strive to eliminate all defects and causes of errors or failures. We want to monitor and record defects against a control chart with min and max levels in any highly repetitive and continuous flow to see when our processes are beginning to fail. As our measures trend toward the upper or lower limits, we still have time to correct the problems before the issues become catastrophic. </p><p>For example, Lean production practitioners often employ a Six Sigma calculation measure in Lean production processes as a desired quality goal. A Six Sigma quality goal is a measure of 3.4 defects per million opportunities.</p></li>
				<li><strong class="bold">Downtime</strong>: This is the opposite<a id="_idIndexMarker779"/> of uptime. Downtime<a id="_idIndexMarker780"/> is a ratio that measures the percentage of unplanned time during which equipment is not available to perform work when compared to the total time. </li>
				<li><strong class="bold">First-time-through capability</strong> (also known as <strong class="bold">first-time-through yield</strong>, or <strong class="bold">FTT</strong>): This<a id="_idIndexMarker781"/> is a measure<a id="_idIndexMarker782"/> of how many products<a id="_idIndexMarker783"/> are produced correctly without defects, bugs, or rework required, expressed as a percentage of total units produced across the value stream. An FTT of 80% means 80 products out of every 100 produced do not have bugs or defects that require rework. </li>
				<li><strong class="bold">Inventory or work item turns</strong>: The number of times that materials, parts, or products<a id="_idIndexMarker784"/> are used or sold over a specific period. This metric is an essential measure as more frequent turns correlates to better flows, higher returns, and reduced inventory carrying costs.</li>
				<li><strong class="bold">Lead time </strong>(<strong class="bold">LT</strong>): This is the sum<a id="_idIndexMarker785"/> measure of total cycle times and<a id="_idIndexMarker786"/> waiting times from when an order is received until it reaches its internal or external customer. In this context, LTs technically apply to entire value streams, business processes, or even between one or more activities within a value stream. Regardless, LTs include the sum of both waiting and cycle times for the span of work measured. </li>
				<li><strong class="bold">Mean time between failures </strong>(<strong class="bold">MTBF</strong>): This is a time-based measure of the frequency<a id="_idIndexMarker787"/> at<a id="_idIndexMarker788"/> which an activity or process fails, usually measured in hours. For example, an MTBF of 89 indicates we can expect the activity or equipment to fail once, on average, every 89 hours. <p>Of course, things are never perfect. We should also measure the variances and probability distributions to gain better insights into our failure frequency. We also want to look at the causes of our failures to see how we can reduce or eliminate them.</p><p>The VSM team should assess MTBF metrics for value stream equipment, software releases, and downtimes due to security breaches and network or computing system failures. </p></li>
				<li><strong class="bold">Meantime to recover/repair </strong>(<strong class="bold">MTTR</strong>): This is a measure of the time between discovering<a id="_idIndexMarker789"/> a problem or failure and the point at which<a id="_idIndexMarker790"/> we have a working remedy that allows us to keep working. MTTR values often apply to our value stream's equipment, but they also apply to the availability of our software products and our IT infrastructures and security. </li>
				<li><strong class="bold">On-time delivery</strong>: This is a measure<a id="_idIndexMarker791"/> of how well<a id="_idIndexMarker792"/> we are meeting our customer demands, expressed as the percentage of finished goods or services across all orders delivered to customers on time, as complete orders, and without errors or omissions.</li>
				<li><strong class="bold">Overall equipment efficiency</strong> (<strong class="bold">OEE</strong>): This is a quantifiable expression of the percentage<a id="_idIndexMarker793"/> of effectiveness<a id="_idIndexMarker794"/> of industrial machinery or equipment in a Lean value stream consisting of quality, speed, and availability measures. Precisely, OEE calculates equipment efficiencies by multiplying the metrics as percentages for quality, speed, and availability, as we can see here:</li>
			</ul>
			<p><img src="image/B17087_08_002.png" alt=""/></p>
			<p>As an example, an OEE of 100% means that an operation produces good parts with 100% favorable quality, at 100% of the operation's maximum production rate and without interruption 100% of the time. But note what happens if quality, speed, and availability all drop down to 90% each. In that scenario, the OEE drops down to 72.9% (giving an OEE of .729).</p>
			<p>In other words, even though all factors achieve a 90% efficiency rate, the measured value stream activity or equipment efficiency drops down to an overall productivity efficiency rate of just 73%.</p>
			<ul>
				<li><strong class="bold">Queue (waiting or wait) time</strong>: This is the amount<a id="_idIndexMarker795"/> of time that materials, parts, products, or information spend waiting on a downstream process. Waiting occurs in both push- and pull-oriented production control systems when there are mismatched batch sizes and cycle times across value stream activities. <p>Pull-oriented production processes help reduce waiting and inventories so long as the operators are disciplined in limiting buffer sizes and pulling in new work when they are ready to perform the work. Any waiting time that occurs is expressed as delays between activities until the work items at upstream activities are pulled into the next downstream activity.</p><p>You can expect to have significantly higher waiting times and queues with push-oriented production scheduling processes. Having value streams with mismatched cycle times and batch sizes makes it more difficult to reduce inventories and waiting times. Having product lines with different flows across the same work cells or equipment further exacerbates these problems, as it becomes exceedingly difficult to predict which work items will show up at which work stations, and at what times. </p></li>
				<li><strong class="bold">Reportable health and safety events</strong>: In the United States, the <strong class="bold">Occupational Safety and Health Administration</strong><em class="italic"> </em>(<strong class="bold">OSHA</strong>)<em class="italic"> </em>implements health and safety<a id="_idIndexMarker796"/> regulations. But it's not just the law we are concerned with, as any safety issue represents productivity, financial, and legal liabilities to the entity. If an event is so egregious that it needs to be reported, then we should measure it and take actions to reduce, if not eliminate, the causes. </li>
				<li><strong class="bold">Total value stream WIP</strong>: In Lean, the ideal<a id="_idIndexMarker797"/> state is to have one work item flowing between our activities across our value stream, in what is known as <em class="italic">single-piece flow</em>. If we have 10 distinct activities in our value stream, the preference is to have no more than 10 work items in total<a id="_idIndexMarker798"/> as WIP. That objective may not be possible in the short term, but our objective is to monitor, control, and limit WIP across our value stream.</li>
				<li><strong class="bold">Total cycle time </strong>(<strong class="bold">TCT</strong>): This is the sum of all cycle times for all activities across a value<a id="_idIndexMarker799"/> stream. As with<a id="_idIndexMarker800"/> activity-specific cycle times, we do not include the time work items spend waiting between activities, but we do include the time associated with non-value-adding work. </li>
				<li><strong class="bold">Total lead time </strong>(<strong class="bold">TLT</strong>): This is the sum<a id="_idIndexMarker801"/> of all cycle times and queue times<a id="_idIndexMarker802"/> across the value stream. This metric gives you an idea of how long your value stream takes to deliver a customer order, from receipt of the order to delivery. TLTs can be measured across value streams for internal or external customers.<p>Note that the TLT value may also encompass the LTs across multiple developments and operations-oriented value streams that participate in the delivery. Whatever the case, it's essential that the map clearly states the span of the value streams and activities associated with<a id="_idTextAnchor211"/> the specified TLT measure.</p></li>
				<li><strong class="bold">Uptime</strong>: This is an expression of availability, calculated as the ratio of the total time that equipment<a id="_idIndexMarker803"/> is available<a id="_idIndexMarker804"/> to conduct work across the desired time. Note, the measure of available time does not include planned downtimes (also known as nonproductive activities), such as preventative maintenance, equipment setup, or work item changeovers. Whether the planned work is value-adding or nonproductive is not the concern, just whether or not the equipment is available.</li>
				<li><strong class="bold">Value-adding time </strong>(<strong class="bold">VT</strong>): This is the CT<a id="_idIndexMarker805"/> of a value stream<a id="_idIndexMarker806"/> activity or process minus all time spent on waste elements. The idealized goal is to have an activity CT that is 100% VT. (This would mean designing an activity without defects, inventory, motion, over-processing, overproduction, transport, and waiting.) Unfortunately, we can<a id="_idIndexMarker807"/> rarely achieve that ideal goal, but we continuously try to improve our efforts to eliminate all waste forms.  </li>
			</ul>
			<p>The previous list of standard Lean metrics applies reasonably well to any Lean improvement initiative, regardless of the value stream type. However, four critical metrics tend to best predict an IT organization's software delivery value stream's performance. We'll discuss this in the section titled <em class="italic">Measuring software delivery performance</em>. But, before we get to that topic, let's review the concerns a VSM team needs to keep in mind when evaluating and gathering Lean metrics. </p>
			<h2 id="_idParaDest-171"><a id="_idTextAnchor212"/>Gathering Lean metrics</h2>
			<p>As your VSM team<a id="_idIndexMarker808"/> reviews which Lean metrics best support your current VS mapping exercise, keep the following in mind:</p>
			<ul>
				<li>Review your team's charter for the strategic direction and desired outcomes.</li>
				<li>Assess the value stream from the perspective of eliminating waste and delivering customer-centric value.</li>
				<li>Determine which Lean metrics you need to collect.</li>
				<li>Get management buy-in for the metrics your team chooses.</li>
				<li>Calculate the best possible outcomes based on standardized processes or activity data. </li>
				<li>Make your metrics visible and readily available to all team members, operators, and stakeholders.</li>
			</ul>
			<p>Now that you know<a id="_idIndexMarker809"/> the standard metrics that are useful to assess all value streams and strategies for gathering them, let's look at those that have proven to be most effective in evaluating IT value stream performance. </p>
			<h2 id="_idParaDest-172"><a id="_idTextAnchor213"/>Analyzing current value stream map metrics</h2>
			<p>Back on our current<a id="_idIndexMarker810"/> state VS map in <a href="B17087_07_Final_PD_epub.xhtml#_idTextAnchor183"><em class="italic">Chapter 7</em></a><em class="italic">, Mapping the Current State (VSM Step 4)</em>, depicted in <em class="italic">Figure 7.4</em>, we included metrics for LTs, VTs, percentage complete and accurate, and rolled complete and accurate. Now let's begin to use that information to analyze the performance of the value stream.</p>
			<p>The following table displays<a id="_idIndexMarker811"/> the <strong class="bold">total lead time</strong> (<strong class="bold">TLT</strong>), the <strong class="bold">total value-adding time</strong> (<strong class="bold">TVA</strong>), and<a id="_idIndexMarker812"/> the rolled complete and accurate percentage across the value stream:</p>
			<div>
				<div id="_idContainer075" class="IMG---Figure">
					<img src="image/B17087_Figure_8.1.jpg" alt="Figure 8.1 – Table of TLT, TVA, and rolling C/A&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.1 – Table of TLT, TVA, and rolling C/A</p>
			<p>The table is divided into three data rows, these being for TLT, TVA, and rolling C/A values across three parts of the IT value stream. The first section of data in the table shown in <em class="italic">Figure 8.1</em> spans the product backlog's refinement and design of work item activities. The second data column spans all the development activities, from planning through provisioning. The third data column includes the activities related to releasing products into production environments.</p>
			<p>Now let's take a closer<a id="_idIndexMarker813"/> look at the details across the IT value-stream delivery activities. <em class="italic">Figure 8.2</em> summarizes the Lean metrics and information captured by the VSM team, which spans all the activities across the entire IT value stream for software deliveries. The values and information are broken separately into work-related categories spanning backlog refinement, development, and release, as shown in the following figure:</p>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="image/B17087_Figure_8.2.jpg" alt="Figure 8.2 – Table of Lean metrics across the IT value stream&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.2 – Table of Lean metrics across the IT value stream</p>
			<p>It's possible that some of the release tasks, such as developing guides and training aids, can be performed in parallel. But the IT value stream also accumulates features into planned bi-weekly releases, which is the reason for the 80-hour lead times. In effect, the release process is a transition or integration point between IT development and ops staff. It involves people from both sides of the IT organization, but the work is more operations-oriented and broken out accordingly. </p>
			<p>Note that the TLT<a id="_idIndexMarker814"/> from planning through to release is 328 hours, or a little more than 8 weeks in duration from when a requirement comes into the product backlog until it's released into production as a feature or function. Yet, the total value-adding work time is only 57 hours (or roughly 1.5 weeks). While we don't know why yet, there is too much waiting built into our IT value delivery system. </p>
			<p>Much of the non-value-added time for the work items accumulate at the product backlog – 168 hours in total. This is where the items wait in a queue based on their priorities. Recall the previous statement that the refinement and design processes are challenging to estimate and control due to that type of work's creative aspects. That may account for some of the delays. However, the large discrepancy between TLT and VA times for the product refinement and design activities suggests we have throughput issues in the downstream development and release activities. </p>
			<p>Still, the lead times for work items in both the development and release segments of the IT value stream add another 80 hours each, or nearly a month, to the overall product lead times. So, we have a lot of built-in waiting in those activities as well. Based on this date, it appears we may have some built-in constraints that are hindering our flows in development and release. Perhaps we have equipment and resource limitations and approvals that hinder our flows. </p>
			<p>We now leave the topic of analyzing current value stream map metrics to look more closely at the time elements that form the CT metrics. </p>
			<h2 id="_idParaDest-173"><a id="_idTextAnchor214"/>Breaking down CTs</h2>
			<p>Looking across our VA times for the entire IT delivery value stream, we can see that Refine activities account for the largest amount of effort, followed by Release and finally Test activities. Those are three areas<a id="_idIndexMarker815"/> we need to improve to reduce costs and increase flow. </p>
			<p>As we begin to look more closely at the VA times, we'll want to explore several non-value adding activities that contribute to waste, such as the following:  </p>
			<ul>
				<li><strong class="bold">Time spent waiting</strong>: This includes the times where materials or work items sit in queues waiting to be processed. Waiting can occur for a variety of reasons. One prominent reason for waiting is when production control pushes more products into the value stream or a value stream activity than it can handle. Another reason for time spent waiting is when multiple activities feed into a single activity faster than the single activity can handle. And, waiting occurs when a given value stream activity is slower than the upstream activities.</li>
				<li><strong class="bold">Time spent walking</strong>: This is a Lean form of waste referred to as motion. Motion is non-value-added time and effort. The goal is to eliminate motion as much as possible. Ways to accomplish that goal include moving work activities closer together and possibly reconfiguring the layout of work cells within the value stream's location.</li>
				<li><strong class="bold">Time spent entering data</strong>: This is non-value-added work but often necessary work. Using bar codes, image scanners, and <strong class="bold">radio frequency identification</strong> (<strong class="bold">RFID</strong>) tags<a id="_idIndexMarker816"/> and readers can dramatically shorten the time required for data entry. </li>
				<li><strong class="bold">Time spent retrieving files</strong>: This is another form of waiting. It is also non-value-added work. However, both materials and operators are waiting on the information necessary to complete the activity in this situation.</li>
				<li><strong class="bold">Time spent sending and reviewing email, or other messages</strong>: This is precisely what it sounds like – the information needed to conduct value-adding work is not available when and where it is needed. This problem is similar to the issues associated with lengthy file downloads.</li>
				<li><strong class="bold">Value-adding work:</strong> This is, unlike all the previous list items, the only effort that adds value to the product.</li>
			</ul>
			<p>We've now looked at the lead times and cycle times for our current VS map. Now, let's look at the percent complete to accurate metrics. </p>
			<h2 id="_idParaDest-174"><a id="_idTextAnchor215"/>Improving percent complete to accurate (%C/A) metrics</h2>
			<p>One final issue that we need to look at is the rolled C/A values. The %C/A values in <em class="italic">Figure 8.2</em>, at first glance, all appear relatively reasonable across each activity. But take a closer look at the impact testing. The 77% C/A ratio has an oversized impact on the final rolled average (in this case 41%). The percent <strong class="bold">complete to accurate</strong> (<strong class="bold">%C/A</strong>) metric, more<a id="_idIndexMarker817"/> simply put, is a measure of the number of times out of 100 that a work item or information is reprocessed through an activity, or a series of activities, without requiring rework or error corrections. </p>
			<p>Each activity has a %C/A value, while the rolled %C/A measure multiplies all %C/A figures across all the series' activities. As a result, just one outlier can have a tremendously negative effect. Additionally, a low %C/A value in testing is another area we need to look at in our future state mapping exercise.  </p>
			<p>Now that we've reviewed the metrics used in our current value stream map, let's review the tools needed to assess Lean performance across our value streams<a id="_idTextAnchor216"/>.</p>
			<h1 id="_idParaDest-175"><a id="_idTextAnchor217"/>Assessing Lean performance</h1>
			<p>The Lean metrics<a id="_idIndexMarker818"/> identified so far help us evaluate the efficiencies of flow across our value streams and act as a means to identify areas of waste. But we also need methods to assess the areas that require the most attention in order to eliminate waste as part of our ongoing Kaizen efforts. A practical way to do this is by developing<a id="_idIndexMarker819"/> a <strong class="bold">Lean assessment radar chart</strong>.</p>
			<p>The Lean assessment radar chart maps specific Lean objectives that you've already learned to a grid, radiating outward like spokes from a central hub. A completed radar chart looks a bit like a spider's web, as depicted in <em class="italic">Figure 8.3</em>. This figure contains a graphical display of an example Lean assessment radar chart:</p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="image/B17087_Figure_8.3.jpg" alt="Figure 8.3 – Lean assessment radar chart&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.3 – Lean assessment radar chart</p>
			<p>A radar chart implements scales to rank capabilities ranging from no commitments at the center of the hub to a level representing world-class capabilities at the outer radius. The example in <em class="italic">Appendix C</em> starts at 0 (no commitment) and radiates outward across four improved capability levels.</p>
			<p>In our Lean assessment<a id="_idIndexMarker820"/> radar chart example, shown in <em class="italic">Figure 8.3</em>, the spokes have the following rankings:</p>
			<p>0: No commitment.</p>
			<p>1: Beginning to implement Lean.</p>
			<p>2: Changes are becoming visible.</p>
			<p>3: Results improving at all levels.</p>
			<p>4: World-class status.</p>
			<p>A quick look at the radar chart in <em class="italic">Figure 8.3</em> shows our most significant improvement needs lie in continuous flows, quality, and visual controls. In contrast, implementation of the five S's system and training seem to both be well in hand. </p>
			<p>Without Lean metrics identified as goals, the measure becomes subjective. The VSM team must strive to determine what world-class performance looks like across each of the assessed Lean practices. The Lean assessment metrics evaluated in our sample radar chart include the following:</p>
			<ul>
				<li><strong class="bold">Continuous flow</strong>: This<a id="_idIndexMarker821"/> represents the degree of synchronization and efficiencies in flow with the ideal goal of achieving single-piece flows.</li>
				<li><strong class="bold">Five S's of Lean</strong>: This is the<a id="_idIndexMarker822"/> degree to which the value stream's work area is clean, uncluttered, safe, well organized, with the 5S practices implemented, scheduled, and visually displayed.</li>
				<li><strong class="bold">Order leveling</strong>: The degree<a id="_idIndexMarker823"/> to which the organization employs Heijunka and other Lean leveling practices.</li>
				<li><strong class="bold">Quality</strong>: The degree to which the value stream meets its established<a id="_idIndexMarker824"/> quality metrics, while always working toward the ideal goal of no errors, defects, rework, or failures.</li>
				<li><strong class="bold">Training</strong>: All value stream members have completed Lean<a id="_idIndexMarker825"/> training and have access to coaches and mentors, plus access to Lean training aids on demand.</li>
				<li><strong class="bold">Team member involvement</strong>: The degree<a id="_idIndexMarker826"/> to which VSM team members and VS operators participate in following the value stream's standard lean practices, participate in Lean assessments meetings, apply 5S practices, participate in Lean training programs, and support continuous improvement objectives.</li>
				<li><strong class="bold">Visual controls</strong>: The degree to which the VSM team and VA operators and managers maintain<a id="_idIndexMarker827"/> and display their Lean metrics, 5S standards, and standard activity information. </li>
				<li><strong class="bold">Work unit movement</strong>: The degree<a id="_idIndexMarker828"/> to which the value stream limits waiting, applies just-in-time and pull-oriented scheduling concepts, and matches flow to Takt time. </li>
			</ul>
			<p>Before their Gemba walks, the VSM team should discuss and decide what the values 0 through 4 should look like for each Lean assessment category. They also need to determine what things they plan to look at to assess each category properly. </p>
			<p>For example, let's say that for the 5S category, each positive observation of the five "S" practices within<a id="_idIndexMarker829"/> the value stream earns .8 points toward the total possible 4 points. As a result, the VSM team obtained multiple numerical values for each category, and the averages, therefore, end up with decimal point values.  </p>
			<p>These Lean assessment metrics are an essential basis behind our Kaizen efforts. As with Agile teams, Lean teams must strive to improve their value stream activities and flow continuously. The Lean assessment metrics help us see where the team can improve their activities.</p>
			<p>We are just about finished with the Lean metrics section. But before we leave, let's quickly review the tools associated with gathering and applying Lean metrics.</p>
			<h1 id="_idParaDest-176"><a id="_idTextAnchor218"/>Measuring key software delivery metrics </h1>
			<p>So far, the metrics<a id="_idIndexMarker830"/> assigned to the activities are relatively traditional Lean metrics, applicable across any organizational value stream. However, Nicole Forsgren, Jez Humble, and Gene Kim, in the book <em class="italic">Accelerate: Building and Scaling High Performing Technology Organizations</em>, identified a shortlist of key metrics that predict software delivery performance (2018, pages 17-19). Based on their detailed statistical analysis, spanning 23,000 survey responses across 2,000 unique organizations, they found that the following four measures are most critical in measuring software delivery performance:</p>
			<ul>
				<li>Delivery lead time</li>
				<li>Deployment frequency</li>
				<li><strong class="bold">Mean time to restore</strong> (<strong class="bold">MTTR</strong>)</li>
				<li>Change fail percentage</li>
			</ul>
			<p>Their work continued under the direction<a id="_idIndexMarker831"/> of the <strong class="bold">DevOps Research and Assessment </strong>(<strong class="bold">DORA</strong>) team. This Google<a id="_idIndexMarker832"/> research group conducted a 6-year program to measure and understand DevOps practices and capabilities across the IT industry. DORA's research was presented in the annual<a id="_idIndexMarker833"/> State of DevOps Reports from 2014 – 2019 and is available at <a href="https://cloud.google.com/devops/state-of-devops">https://cloud.google.com/devops/state-of-devops</a>. </p>
			<p>We'll take a closer look at each of these metrics in the four subsections that follow.</p>
			<h2 id="_idParaDest-177"><a id="_idTextAnchor219"/>Delivery lead time</h2>
			<p><strong class="bold">Delivery lead time </strong>is the total amount of time required to take a customer requirement from ideation to customer satisfaction. In software development, satisfaction means the product enhancement meets its <em class="italic">definition of Done</em>. In other words, both the team and the customer have agreed a deliverable item meets its defined acceptance criteria.</p>
			<p>But the calculation for a delivery lead time as a Lean-oriented metric is tricky. In <a href="B17087_07_Final_PD_epub.xhtml#_idTextAnchor183"><em class="italic">Chapter 7</em></a>, <em class="italic">Mapping the Current State (VSM Step 4)</em>, and specifically in the <em class="italic">Preparing to map</em> section, you learned that the activities to define and validate requirements and designs are creative tasks. The time and effort required to perform creative endeavors are challenging to predict compared to the relatively standardized work of developing and testing code, provisioning, and deployment. When we speak about using a delivery lead time to measure software delivery performance, it's usually best to start the clock when a requirement within the product backlog is sufficiently refined to begin coding efforts. </p>
			<p>High-performance<a id="_idIndexMarker834"/> software<a id="_idIndexMarker835"/> delivery organizations can develop, test, and deliver a new requirement as working code into the main branch of their repository in less than one hour. In contrast, the lowest performers deploy working code into their main branch only once per week to once per month in the most recent data (2017), and as much as once every 6 months in previous years.</p>
			<h2 id="_idParaDest-178"><a id="_idTextAnchor220"/>Deployment frequency</h2>
			<p>The <strong class="bold">deployment frequency</strong> is how<a id="_idIndexMarker836"/> often code is released into a production environment or sent to an app store. As noted<a id="_idIndexMarker837"/> previously, coding and testing smaller increments of functionality is superior to building and deploying large-scale code changes all at once. The lowest performers tend to take on bigger bites of functionality, increasing the complexity of their coding, testing, and debugging activities and thereby delaying their deployment frequencies to a range of 1 to 4 weeks. In contrast, the highest performers take in new requirements on demand, build functionality in smaller incremental chunks, and release multiple deployments per day.</p>
			<p>Note that software development value streams are equivalent to the idealized production flow concept<a id="_idIndexMarker838"/> of <em class="italic">single-piece flows</em>. Single-piece flows occur in software delivery when the organization automates the DevOps<a id="_idIndexMarker839"/> pipeline from <em class="italic">code</em> to <em class="italic">release-to-production</em> activities. Single-piece flows are the ultimate goal of CI/CD pipelines. In other words, each commit of software code into the SCM repository can automatically flow through the pipeline and into the production environments without manual intervention. </p>
			<p>In theory, it's still an example of continuous flow to stop at the preproduction environments for final approval. But if that step also involves staging and releasing multiple features, that part of the process now becomes a batch process. Regardless of the reason or merits, all batch processing impedes the flow of value to our customers. </p>
			<h2 id="_idParaDest-179"><a id="_idTextAnchor221"/>Mean time to restore</h2>
			<p><strong class="bold">Mean time to restore</strong> is a critical metric as it represents the amount of time an application<a id="_idIndexMarker840"/> or system has failed and is<a id="_idIndexMarker841"/> not providing service to its customer(s). Usually, when a system or feature fails, we have no choice but to roll back the changes until we can identify and fix the problem. So, the key is to rapidly discover the failures and execute a rollback to the previous working release. Ideally, we want to see this MTTR number in under one hour. Low performers take between a day and a week to restore failed services.  </p>
			<h2 id="_idParaDest-180"><a id="_idTextAnchor222"/>Change failure rates</h2>
			<p><strong class="bold">Change failure rates</strong> specify the percentage of time taken until a change to the code results in a failure, usually<a id="_idIndexMarker842"/> detected in the form<a id="_idIndexMarker843"/> of a bug or a defect. With modern pipeline deployment capabilities, a new release may only involve rolling back new releases of functionality. But a failure can also take the form of a system-wide crash and loss of services. Regardless, low performers had change failure rates of 31% to 45%, while the highest performers had 0 to 15% (Forsgren et al., 2018). Improvements in writing test scripts, such as test-driven development and test automation capabilities, help lower change failure rate numbers.</p>
			<p>You now have a thorough<a id="_idIndexMarker844"/> understanding<a id="_idIndexMarker845"/> of both common value stream metrics and the four metrics that most often define the performance level for software development organizations. In the following subsection, we'll explore how to use state value stream metrics to analyze the current state.</p>
			<h2 id="_idParaDest-181"><a id="_idTextAnchor223"/>Adding flow metrics and analytics to VSM</h2>
			<p>Beyond the <strong class="bold">DORA Four</strong>, the trend in software development is to implement <strong class="bold">flow metrics and analytics</strong> capabilities to provide visibility to business leaders, product managers, and value stream teams to continuously improve their processes. Suboptimal processes and team performance can negatively impact the organization's Lean-Agile transformation efforts.</p>
			<p>Alternatively, organizations can guide improvement activities and coaching when they have access to accurate and consistent metrics visibility of their business operations and value streams. The metrics must be available, up to date, and visible to all stakeholders at all times. </p>
			<p>Modern VSM tools make it easy to capture value stream metrics. This is because they act as automated activities, devoid of human manipulations and reporting that might cloud the findings. Automating data capture makes the information increasingly available, timely, accurate, and usable. Business leaders, team members, and other stakeholders must have confidence in the data and its accuracy.</p>
			<p>Data may come from many disparate tools or systems that participate in a value stream pipeline flow. Modern VSM tools apply a <strong class="bold">common data model</strong> that<a id="_idIndexMarker846"/> normalizes the data to provide an end-to-end view of the data across a value stream pipeline. In addition, analytical tools, some employing artificial intelligence capabilities, make it easier for executives and VSM team members to evaluate the flows across current-state activities, then assess alternative future-state scenarios. </p>
			<p>Additionally, portfolio managers and product owners can use these same flow metrics and analytical capabilities to assess progress against their product and release roadmaps. Therefore, business owners and stakeholders will therefore have increased visibility on the delivery status of products and their related production costs.  </p>
			<h2 id="_idParaDest-182"><a id="_idTextAnchor224"/>Going beyond the DORA Four</h2>
			<p>The DORA Four metrics<a id="_idIndexMarker847"/> are beneficial because they help identify the critical metrics that define best-in-class software delivery<a id="_idIndexMarker848"/> capabilities. They also provide a valuable set of metrics as targets for the software development team during their transformations to Lean-Agile practices.</p>
			<p>Still, in a Lean-Agile enterprise, there are many other metrics an organization should track to identify areas for continuous improvements and verify the achievement of its improvement goals. For example, Gartner analyst Bill Swanton identifies 18 flow metrics in the<a id="_idIndexMarker849"/> <strong class="bold">Gartner Report</strong> titled<em class="italic"> How Software Engineering Leaders Can Use Value Stream Metrics to Improve Agile Effectiveness</em>. These areas are shown in the following figure:</p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="image/B17087_Figure_8.4.jpg" alt="Figure 8.4 – List of Gartner-identified flow metrics&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.4 – List of Gartner-identified flow metrics</p>
			<p>Swanton says these are some examples of flow metrics that should be considered, noting: "<em class="italic">Much like the metrics in a lean manufacturing process, they measure how smoothly work is flowing through the system and how responsive teams are to changing demand</em>." </p>
			<p>He further points out that: "<em class="italic">Vendors are starting to offer systems that integrate with your software development, infrastructure and monitoring tools (version control, work management, test management, etc.) to collect, calculate and pr<a id="_idTextAnchor225"/>esent the metrics continuously</em>." </p>
			<p>One company that has done<a id="_idIndexMarker850"/> a great deal of work<a id="_idIndexMarker851"/> in this area is Tasktop, with their <strong class="bold">Flow Framework</strong>®, under<a id="_idIndexMarker852"/> the leadership of Mik Kersten, the company's CEO.</p>
			<h2 id="_idParaDest-183"><a id="_idTextAnchor226"/>Implementing the Flow Framework</h2>
			<p>Tasktop VSM tools are introduced in more detail in <a href="B17087_12_Final_PD_epub.xhtml#_idTextAnchor342"><em class="italic">Chapter 12</em></a><em class="italic">, Introducing the Leading VSM Tool Vendors</em>. However, given the Flow Framework's relevance to this section, we'll take a moment to explain how modern VSM tools can help capture and analyze Flow Metrics. </p>
			<p>The concepts behind flow metrics and the Flow Framework<a id="_idIndexMarker853"/> were<a id="_idIndexMarker854"/> initially introduced in the book <em class="italic">Project to Product</em> by Dr. Mik Kersten (2018). IT leaders have since adopted these concepts worldwide in order to bridge the gap between technologists and business stakeholders. Specifically, the Flow Framework provides both a methodology and vocabulary to systematically discover and eliminate bottlenecks that slow down software delivery and negatively impact business results.</p>
			<p>The goal of the Flow Framework is to ensure that business-level frameworks and transformation initiatives are connected to technical ones associated with implementing Agile and DevOps, as well as future methodologies still to arrive. The Tasktop's Flow Framework scales<a id="_idIndexMarker855"/> the <strong class="bold">Three Ways of DevOps</strong> – <strong class="bold">flow</strong> (accelerate delivery through the development, operations, and on to the customer), <strong class="bold">feedback</strong> (create<a id="_idIndexMarker856"/> safer systems of work), and <strong class="bold">continuous learning and experimentation</strong> (fostering trust and a scientific approach<a id="_idIndexMarker857"/> to organizational improvements and risk-taking) – to the entire business. These concepts were introduced in the book <em class="italic">The DevOps Handbook</em> (Kim et al., 2016). </p>
			<p>With modern VSM tools, every organization can gather hundreds of valuable metrics to evaluate improvements in process, productivity, quality, cost, revenue, and adherence to standards. The trick is to make sense of it all. Unfortunately, organizations often lack visibility into their end-to-end pipeline flows, making it difficult to answer the questions shown in the following figure:</p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="image/B17087_Figure_8.5.jpg" alt="Figure 8.5 – Flow Framework flow metrics&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.5 – Flow Framework flow metrics</p>
			<p>Flow metrics help identify<a id="_idIndexMarker858"/> and solve<a id="_idIndexMarker859"/> a system's bottleneck, eliminating the inefficient local optimizations that may be present when visibility is limited to siloed, in-tool data. They also provide a historical view of your performance, so you can understand how choices and changes impacted your flow.</p>
			<p>Four flow items constitute a unit of business value pulled by a stakeholder through a product's value stream. These are <strong class="bold">features</strong>, <strong class="bold">defects</strong>, <strong class="bold">risks</strong>, and <strong class="bold">debts</strong>, as shown in <em class="italic">Figure 8.6</em>. Flow metrics are measured for each of these flow items both individually and as a collective. The following figure shows these items:</p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="image/B17087_Figure_8.6.jpg" alt="Figure 8.6 – Four flow items&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.6 – Four flow items</p>
			<p>Flow items represent<a id="_idIndexMarker860"/> items of value<a id="_idIndexMarker861"/> to the organization. In other words, how we address the prioritization of features, defects, technical debt, and risks affects our ability to deliver customer value. Therefore, business and technology leaders must work in concert to analyze the flow, speed, and prioritization of all four value types. </p>
			<p>For example, frequently features have priority, but other times we need to fix bugs, reduce our technical debts, or address critical risks and issues. Eventually, we pay a heavy price if we don't balance the work associated with these four flow items.</p>
			<p>Despite the complexity and intangibility of software delivery work, the Flow Framework makes flow metrics (and the daily practice of VSM) attainable for any organization in any structure, by defining how the necessary data can be extracted from the execution tools<a id="_idIndexMarker862"/> (<strong class="bold">integration model</strong>). These are abstracted into flow items and flow<a id="_idIndexMarker863"/> states (<strong class="bold">activity model</strong>), presented in a view that is aligned with<a id="_idIndexMarker864"/> the business (<strong class="bold">product model</strong>). </p>
			<p>Thus presented and analyzed, flow metrics can then be used to inform the decision-making of leaders and teams to deliver targeted business outcomes. Tasktop's VSM platform provides these capabilities out of the box, through a point-and-click interface. <em class="italic">Figure 8.7</em> provides a poster view of the Flow Framework: </p>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="image/B17087_Figure_8.7.jpg" alt="Figure 8.7 – Flow Framework poster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.7 – Flow Framework poster</p>
			<p>Tasktop<a id="_idIndexMarker865"/> makes<a id="_idIndexMarker866"/> the<a id="_idIndexMarker867"/> point that there are other important frameworks (such as <strong class="bold">Disciplined Agile</strong> (<strong class="bold">DA</strong>), the <strong class="bold">Scaled Agile Framework®</strong> (<strong class="bold">SAFe®</strong>), <strong class="bold">Large-Scale Scrum</strong> (<strong class="bold">LeSS</strong>), and Nexus) that help organizations scale Agile and connect those practices to the goals<a id="_idIndexMarker868"/> of the<a id="_idIndexMarker869"/> business. You will recall that Agile is a set of values and principles that help an organization align its resources and activities around adding customer-centric value and nimbly responding to changes.  </p>
			<p>In contrast, VSM can increase the flow of business value, from the initial customer request to customer delivery. The Flow Framework is a structured, prescriptive approach to value stream management in software delivery organizations, created to provide a business with customer-centric view of flows across the entire software delivery process. Therefore, Agile helps ensure we deliver the correct customer-centric value at the right time, while VSM helps ensure we deliver that value rapidly and efficiently.</p>
			<h2 id="_idParaDest-184"><a id="_idTextAnchor227"/>Creating a safe work environment</h2>
			<p>Remaining<a id="_idIndexMarker870"/> consistent with the values<a id="_idIndexMarker871"/> and principles of Agile, we must never use the flow metrics as a tool to punish or even reward individuals and teams. Instead, their purpose is to help guide our continuous improvement efforts. </p>
			<p>Lean-Agile practices emphasize team-based performance, and when thing<a id="_idTextAnchor228"/>s<a id="_idTextAnchor229"/> go awry – which inevitably they will – we need an all-hands approach to resolve the issues at hand. If teams and individuals fear punishment, you can expect that they will avoid speaking out and may even hide critical information about issues that impact their ability to deliver software value effectively, rapidly, and efficiently.  </p>
			<p>Therefore, when our value stream flows are interrupted, we need to stop everything and have all team members work together to solve the problem. Attempts to keep production flowing lead to queuing, activity waiting, product delays, and possibly the accumulation of more defects, all of which can only serve to increase our costs. </p>
			<p>The benefit of having access to real-time flow metrics is that we can spot issues immediately when they arise. This allows us to address them sooner and therefore reduce our lost production times and other waste. In addition, these metrics and analytics help the team<a id="_idIndexMarker872"/> evaluate<a id="_idIndexMarker873"/> problems and root causes, as well as brainstorm alternative resolution strategies. </p>
			<h1 id="_idParaDest-185"><a id="_idTextAnchor230"/>Implementing the tools of Lean metrics</h1>
			<p>In this chapter<a id="_idIndexMarker874"/> on Lean metrics, you learned about metrics commonly applied to measure Lean production practices. You also learned about the four specific metrics that give the best prediction of a software delivery teams' performance. Traditional VSM practices implemented manual tools to capture and analyze value stream metrics. In addition, you also learned how modern VSM tools, flow metrics, and analytics help improve the speed and efficiency of software delivery, while ensuring software development stays in alignment with the goals and objectives of the business. </p>
			<p>As regards manual tools, you learned how to use a large whiteboard or chart, or electronic screen, to make your metrics highly visible. You also learned how to make updates to your VSM Storyboard in order to keep all your VSM team data contained and available from a single source. Finally, you learned how to assess a value stream's Lean practices. These span eight categories and are displayed in a Lean assessment radar chart format. These are all manual tools that evolved concurrently with VSM practices. </p>
			<p>The advantages of modern VSM tools are their ability to capture end-to-end pipeline information and provide analytical tools that work across a common data model. In their modern rebirth, VSM tool vendors implement capabilities to capture and analyze metrics to support CI/CD and DevOps pipeline flows, using the very same concepts and types of metrics employed across all other organizational value streams. Therefore, analysts can evaluate the performance of the pipeline activities, in part or whole, no matter how many third-party tools become integrated into the CI/CD or DevOps pipeline.</p>
			<p>But the modern VSM tools go beyond data capture and analysis. They also support the <strong class="bold">integration</strong>, <strong class="bold">automation</strong>, and <strong class="bold">orchestration</strong> of pipeline flows. We'll start to get into these topics in the next chapter on future state mapping and delve into much greater detail in <em class="italic">Section 3</em> of this book on VSM vendors. </p>
			<p>This section ends our discussion on Lean metrics, the fifth step in our VSM methodology. In the next chapter, <a href="B17087_09_Final_PD_epub.xhtml#_idTextAnchor234"><em class="italic">Chapter 9</em></a>, <em class="italic">Mapping the Future State (VSM Step 6)</em>, we'll start to map the desired future state<a id="_idIndexMarker875"/> in three phases: evaluating alignment with customer demands, implementing continuous flows, and production flow leveling through production control and orchestration strategies.</p>
			<h1 id="_idParaDest-186"><a id="_idTextAnchor231"/>Summary</h1>
			<p>This chapter provided instruction on the critical metrics that help us evaluate the effectiveness of our value streams from a Lean-oriented perspective. You also learned how to go about gathering useful Lean metrics (step five in our generic VSM methodology). </p>
			<p>While VSM teams can gather and analyze metrics manually, this is a labor-intensive process. In contrast, modern VSM tools have become increasingly important, in large part because of their ability to capture and display such information in real time. Moreover, the analytics and what-if capabilities of VSM tools support future state analysis.  </p>
			<p>In the next chapter, you will learn how to conduct future state mapping exercises across three distinct phases spanning customer demand, continuous flows, and leveling. Before we get to that chapter, take a couple of moments to answer the following questions. Don't worry if you don't recall the information or quite understand all of the questions. Going back to find the answers will help both your understanding and ability to retain the knowledge.</p>
			<h1 id="_idParaDest-187"><a id="_idTextAnchor232"/>Questions</h1>
			<p>Please answer the following 10 questions:</p>
			<ol>
				<li>Why is the identification of Lean metrics such a crucial concern? </li>
				<li>What is <strong class="bold">cycle time</strong> (<strong class="bold">CT</strong>)?  </li>
				<li>Is CT the same as <strong class="bold">value-adding time</strong> (<strong class="bold">VT</strong>)? </li>
				<li>What is the relevance of Six Sigma?</li>
				<li>What are the four most important metrics in Lean software delivery?</li>
				<li>List the types of non-value-adding activities that contribute to waste.</li>
				<li>What is the relevance of change failure rates? </li>
				<li>What is the essential Lean assessment tool?</li>
				<li>What are the typical radials on the Lean assessment radar chart?</li>
				<li>In its modern rebirth, VSM tool vendors implement platforms with metrics and analytics to support what three functions? </li>
			</ol>
			<h1 id="_idParaDest-188"><a id="_idTextAnchor233"/>Further reading</h1>
			<ul>
				<li><em class="italic">Tapping, D., Luyster, T., Shuker, T. (2002) Value Stream Management: Eight Steps to Planning, Mapping, and Sustaining Lean Improvements. Productivity Press. New York, NY</em></li>
				<li><em class="italic">Tapping, D., Luyster, T., Shuker, T. (2003) Value Stream Management for the Lean Office: Eight Steps to Planning, Mapping, and Sustaining Lean Improvements. Productivity Press. New York, NY</em></li>
				<li><em class="italic">Tapping, D., Kozlowski, S., Archbold, L., Sperl, T. (2009) Value Stream Management for Lean Healthcare: Four steps to Planning, Mapping, Implementing, and Controlling Improvements in all types of Healthcare Environments. MCS Media, Inc. Chelsea, MI</em></li>
				<li><em class="italic">Forsgren, N., Humble, J., Kim, G. (2018) Accelerate: Building and Scaling High performing Technology Organizations. IT Revolution. Portland, OR.</em></li>
				<li><em class="italic">Kim, G., Humble, J., Debois, P., Willis, J. (2016) The DevOps Handbook: How to Create World-Class Agility, Reliability, &amp; Security in Technology Organizations. IT Revolutions. Portland, OR</em></li>
				<li><em class="italic">Kersten, M. (2018) Project to Product: How to Survive and Thrive in the Age of Digital Disruption with the Flow Framework. IT Revolution. Portland, OR</em></li>
			</ul>
		</div>
	</body></html>