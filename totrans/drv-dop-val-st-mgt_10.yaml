- en: '[*Chapter 8*](B17087_08_Final_PD_epub.xhtml#_idTextAnchor209): Identifying
    Lean Metrics (VSM Step 5)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having completed the current value stream map, we now turn our attention to
    evaluating potential future state opportunities to synchronize our flows and eliminate
    waste, in order to increase value for our customers. But first, we must identify
    our objectives in the form of quantifiable and measurable Lean metrics, which
    will be the fifth VSM step and is introduced in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: It's difficult to improve things without having measures of the current state
    and desired future states. It's like driving in a car to a new destination without
    an address or a map. Without these items, you don't know which roads to take,
    how far you have to go, or even how to know when you have arrived. This chapter
    helps you identify the key metrics that will inform your decisions in building
    the value stream maps that define your desired future destinations.
  prefs: []
  type: TYPE_NORMAL
- en: After reading this chapter, you will know the basic Lean metrics that help organizations
    and VSM teams assess areas for improvement across virtually any value stream.
    You will also learn the metrics that most apply to assessing the performance of
    modern DevOps-based software delivery teams and pipelines. Finally, you will learn
    about the tools that support the gathering of Lean metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining universal Lean metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assessing Lean performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring key software delivery metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding flow metrics and analytics to VSM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the tools of Lean metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining universal Lean metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ve already introduced some Lean metrics in the previous chapter on current-state
    value stream mapping. However, we did not take the time to define Lean metrics
    other than metrics explicitly related to software delivery performance. Additionally,
    there are many traditional Lean metrics that you and your VSM team need to understand
    how to use, as identified in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cycle time** (**CT**): The CT is the timespan between starting and finishing
    a process or a value stream activity. The CT is actually a measure of throughput
    (units per period of time). So, if we can produce 40 widgets in a 40-hour work
    week, our cycle time is![](img/B17087_08_001.png) The VSM team only includes working
    time and does not include **work in progress** (**WIP**), nor the waiting time
    between value stream activities. However, the CT is not always all **value-adding
    time** (**VT**). There can be elements of non-value-adding work within the activity
    in the form of waste. This waste includes defects, inventory, motion, over-processing,
    overproduction, transport, and waiting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, suppose an operator pulls a work item but must wait to retrieve
    information, materials, or reviewing information to start their work. In that
    case, that type of waiting is still part of the activity's CT. Additionally, time
    spent setting up equipment or changing materials is part of the CT.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Using a real-life example, I recently had some landscape work done in my backyard.
    The materials vendor dropped the items off on pallets in my driveway. I had to
    pay the landscaping contractor for their team's labor hours to break down pallets
    and manually move the materials into my backyard. As a paying customer, I preferred
    that the pallets were dropped off directly in my backyard. As a result, the CT
    I paid for included the value-adding landscaping work, plus the non-value-adding
    work of moving the materials, this being a Lean-oriented waste in the form of
    motion.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Days of inventory on hand**: This is the amount of material, parts, or products
    stored and quantified in daily production usage. For example, if we use 20 widgets
    per day and have 100 widgets in inventory, we have 5 days of widget inventory
    on hand.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Defects per million opportunities** (**DPMO)**: This is a measure of how
    many defects occur in every million opportunities to have a defect. For example,
    we might have 40 defects per every one million activities. Or, we might have 40
    defects per every one million lines of code produced. Therefore, we need to be
    concise in explaining what type of defect ratio the DPMO is measuring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our quality objective is always to strive to eliminate all defects and causes
    of errors or failures. We want to monitor and record defects against a control
    chart with min and max levels in any highly repetitive and continuous flow to
    see when our processes are beginning to fail. As our measures trend toward the
    upper or lower limits, we still have time to correct the problems before the issues
    become catastrophic.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For example, Lean production practitioners often employ a Six Sigma calculation
    measure in Lean production processes as a desired quality goal. A Six Sigma quality
    goal is a measure of 3.4 defects per million opportunities.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Downtime**: This is the opposite of uptime. Downtime is a ratio that measures
    the percentage of unplanned time during which equipment is not available to perform
    work when compared to the total time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**First-time-through capability** (also known as **first-time-through yield**,
    or **FTT**): This is a measure of how many products are produced correctly without
    defects, bugs, or rework required, expressed as a percentage of total units produced
    across the value stream. An FTT of 80% means 80 products out of every 100 produced
    do not have bugs or defects that require rework.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inventory or work item turns**: The number of times that materials, parts,
    or products are used or sold over a specific period. This metric is an essential
    measure as more frequent turns correlates to better flows, higher returns, and
    reduced inventory carrying costs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lead time** (**LT**): This is the sum measure of total cycle times and waiting
    times from when an order is received until it reaches its internal or external
    customer. In this context, LTs technically apply to entire value streams, business
    processes, or even between one or more activities within a value stream. Regardless,
    LTs include the sum of both waiting and cycle times for the span of work measured.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mean time between failures** (**MTBF**): This is a time-based measure of
    the frequency at which an activity or process fails, usually measured in hours.
    For example, an MTBF of 89 indicates we can expect the activity or equipment to
    fail once, on average, every 89 hours.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, things are never perfect. We should also measure the variances and
    probability distributions to gain better insights into our failure frequency.
    We also want to look at the causes of our failures to see how we can reduce or
    eliminate them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The VSM team should assess MTBF metrics for value stream equipment, software
    releases, and downtimes due to security breaches and network or computing system
    failures.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Meantime to recover/repair** (**MTTR**): This is a measure of the time between
    discovering a problem or failure and the point at which we have a working remedy
    that allows us to keep working. MTTR values often apply to our value stream''s
    equipment, but they also apply to the availability of our software products and
    our IT infrastructures and security.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**On-time delivery**: This is a measure of how well we are meeting our customer
    demands, expressed as the percentage of finished goods or services across all
    orders delivered to customers on time, as complete orders, and without errors
    or omissions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overall equipment efficiency** (**OEE**): This is a quantifiable expression
    of the percentage of effectiveness of industrial machinery or equipment in a Lean
    value stream consisting of quality, speed, and availability measures. Precisely,
    OEE calculates equipment efficiencies by multiplying the metrics as percentages
    for quality, speed, and availability, as we can see here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B17087_08_002.png)'
  prefs: []
  type: TYPE_IMG
- en: As an example, an OEE of 100% means that an operation produces good parts with
    100% favorable quality, at 100% of the operation's maximum production rate and
    without interruption 100% of the time. But note what happens if quality, speed,
    and availability all drop down to 90% each. In that scenario, the OEE drops down
    to 72.9% (giving an OEE of .729).
  prefs: []
  type: TYPE_NORMAL
- en: In other words, even though all factors achieve a 90% efficiency rate, the measured
    value stream activity or equipment efficiency drops down to an overall productivity
    efficiency rate of just 73%.
  prefs: []
  type: TYPE_NORMAL
- en: '**Queue (waiting or wait) time**: This is the amount of time that materials,
    parts, products, or information spend waiting on a downstream process. Waiting
    occurs in both push- and pull-oriented production control systems when there are
    mismatched batch sizes and cycle times across value stream activities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pull-oriented production processes help reduce waiting and inventories so long
    as the operators are disciplined in limiting buffer sizes and pulling in new work
    when they are ready to perform the work. Any waiting time that occurs is expressed
    as delays between activities until the work items at upstream activities are pulled
    into the next downstream activity.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can expect to have significantly higher waiting times and queues with push-oriented
    production scheduling processes. Having value streams with mismatched cycle times
    and batch sizes makes it more difficult to reduce inventories and waiting times.
    Having product lines with different flows across the same work cells or equipment
    further exacerbates these problems, as it becomes exceedingly difficult to predict
    which work items will show up at which work stations, and at what times.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Reportable health and safety events**: In the United States, the **Occupational
    Safety and Health Administration**(**OSHA**)implements health and safety regulations.
    But it''s not just the law we are concerned with, as any safety issue represents
    productivity, financial, and legal liabilities to the entity. If an event is so
    egregious that it needs to be reported, then we should measure it and take actions
    to reduce, if not eliminate, the causes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total value stream WIP**: In Lean, the ideal state is to have one work item
    flowing between our activities across our value stream, in what is known as *single-piece
    flow*. If we have 10 distinct activities in our value stream, the preference is
    to have no more than 10 work items in total as WIP. That objective may not be
    possible in the short term, but our objective is to monitor, control, and limit
    WIP across our value stream.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total cycle time** (**TCT**): This is the sum of all cycle times for all
    activities across a value stream. As with activity-specific cycle times, we do
    not include the time work items spend waiting between activities, but we do include
    the time associated with non-value-adding work.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total lead time** (**TLT**): This is the sum of all cycle times and queue
    times across the value stream. This metric gives you an idea of how long your
    value stream takes to deliver a customer order, from receipt of the order to delivery.
    TLTs can be measured across value streams for internal or external customers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that the TLT value may also encompass the LTs across multiple developments
    and operations-oriented value streams that participate in the delivery. Whatever
    the case, it's essential that the map clearly states the span of the value streams
    and activities associated with the specified TLT measure.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Uptime**: This is an expression of availability, calculated as the ratio
    of the total time that equipment is available to conduct work across the desired
    time. Note, the measure of available time does not include planned downtimes (also
    known as nonproductive activities), such as preventative maintenance, equipment
    setup, or work item changeovers. Whether the planned work is value-adding or nonproductive
    is not the concern, just whether or not the equipment is available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Value-adding time** (**VT**): This is the CT of a value stream activity or
    process minus all time spent on waste elements. The idealized goal is to have
    an activity CT that is 100% VT. (This would mean designing an activity without
    defects, inventory, motion, over-processing, overproduction, transport, and waiting.)
    Unfortunately, we can rarely achieve that ideal goal, but we continuously try
    to improve our efforts to eliminate all waste forms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The previous list of standard Lean metrics applies reasonably well to any Lean
    improvement initiative, regardless of the value stream type. However, four critical
    metrics tend to best predict an IT organization's software delivery value stream's
    performance. We'll discuss this in the section titled *Measuring software delivery
    performance*. But, before we get to that topic, let's review the concerns a VSM
    team needs to keep in mind when evaluating and gathering Lean metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Gathering Lean metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As your VSM team reviews which Lean metrics best support your current VS mapping
    exercise, keep the following in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: Review your team's charter for the strategic direction and desired outcomes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assess the value stream from the perspective of eliminating waste and delivering
    customer-centric value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determine which Lean metrics you need to collect.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get management buy-in for the metrics your team chooses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate the best possible outcomes based on standardized processes or activity
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make your metrics visible and readily available to all team members, operators,
    and stakeholders.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you know the standard metrics that are useful to assess all value streams
    and strategies for gathering them, let's look at those that have proven to be
    most effective in evaluating IT value stream performance.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing current value stream map metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Back on our current state VS map in [*Chapter 7*](B17087_07_Final_PD_epub.xhtml#_idTextAnchor183)*,
    Mapping the Current State (VSM Step 4)*, depicted in *Figure 7.4*, we included
    metrics for LTs, VTs, percentage complete and accurate, and rolled complete and
    accurate. Now let's begin to use that information to analyze the performance of
    the value stream.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table displays the **total lead time** (**TLT**), the **total
    value-adding time** (**TVA**), and the rolled complete and accurate percentage
    across the value stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Table of TLT, TVA, and rolling C/A'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17087_Figure_8.1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.1 – Table of TLT, TVA, and rolling C/A
  prefs: []
  type: TYPE_NORMAL
- en: The table is divided into three data rows, these being for TLT, TVA, and rolling
    C/A values across three parts of the IT value stream. The first section of data
    in the table shown in *Figure 8.1* spans the product backlog's refinement and
    design of work item activities. The second data column spans all the development
    activities, from planning through provisioning. The third data column includes
    the activities related to releasing products into production environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s take a closer look at the details across the IT value-stream delivery
    activities. *Figure 8.2* summarizes the Lean metrics and information captured
    by the VSM team, which spans all the activities across the entire IT value stream
    for software deliveries. The values and information are broken separately into
    work-related categories spanning backlog refinement, development, and release,
    as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Table of Lean metrics across the IT value stream'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17087_Figure_8.2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 – Table of Lean metrics across the IT value stream
  prefs: []
  type: TYPE_NORMAL
- en: It's possible that some of the release tasks, such as developing guides and
    training aids, can be performed in parallel. But the IT value stream also accumulates
    features into planned bi-weekly releases, which is the reason for the 80-hour
    lead times. In effect, the release process is a transition or integration point
    between IT development and ops staff. It involves people from both sides of the
    IT organization, but the work is more operations-oriented and broken out accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the TLT from planning through to release is 328 hours, or a little
    more than 8 weeks in duration from when a requirement comes into the product backlog
    until it's released into production as a feature or function. Yet, the total value-adding
    work time is only 57 hours (or roughly 1.5 weeks). While we don't know why yet,
    there is too much waiting built into our IT value delivery system.
  prefs: []
  type: TYPE_NORMAL
- en: Much of the non-value-added time for the work items accumulate at the product
    backlog – 168 hours in total. This is where the items wait in a queue based on
    their priorities. Recall the previous statement that the refinement and design
    processes are challenging to estimate and control due to that type of work's creative
    aspects. That may account for some of the delays. However, the large discrepancy
    between TLT and VA times for the product refinement and design activities suggests
    we have throughput issues in the downstream development and release activities.
  prefs: []
  type: TYPE_NORMAL
- en: Still, the lead times for work items in both the development and release segments
    of the IT value stream add another 80 hours each, or nearly a month, to the overall
    product lead times. So, we have a lot of built-in waiting in those activities
    as well. Based on this date, it appears we may have some built-in constraints
    that are hindering our flows in development and release. Perhaps we have equipment
    and resource limitations and approvals that hinder our flows.
  prefs: []
  type: TYPE_NORMAL
- en: We now leave the topic of analyzing current value stream map metrics to look
    more closely at the time elements that form the CT metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Breaking down CTs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Looking across our VA times for the entire IT delivery value stream, we can
    see that Refine activities account for the largest amount of effort, followed
    by Release and finally Test activities. Those are three areas we need to improve
    to reduce costs and increase flow.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we begin to look more closely at the VA times, we''ll want to explore several
    non-value adding activities that contribute to waste, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Time spent waiting**: This includes the times where materials or work items
    sit in queues waiting to be processed. Waiting can occur for a variety of reasons.
    One prominent reason for waiting is when production control pushes more products
    into the value stream or a value stream activity than it can handle. Another reason
    for time spent waiting is when multiple activities feed into a single activity
    faster than the single activity can handle. And, waiting occurs when a given value
    stream activity is slower than the upstream activities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time spent walking**: This is a Lean form of waste referred to as motion.
    Motion is non-value-added time and effort. The goal is to eliminate motion as
    much as possible. Ways to accomplish that goal include moving work activities
    closer together and possibly reconfiguring the layout of work cells within the
    value stream''s location.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time spent entering data**: This is non-value-added work but often necessary
    work. Using bar codes, image scanners, and **radio frequency identification**
    (**RFID**) tags and readers can dramatically shorten the time required for data
    entry.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time spent retrieving files**: This is another form of waiting. It is also
    non-value-added work. However, both materials and operators are waiting on the
    information necessary to complete the activity in this situation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time spent sending and reviewing email, or other messages**: This is precisely
    what it sounds like – the information needed to conduct value-adding work is not
    available when and where it is needed. This problem is similar to the issues associated
    with lengthy file downloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Value-adding work:** This is, unlike all the previous list items, the only
    effort that adds value to the product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We've now looked at the lead times and cycle times for our current VS map. Now,
    let's look at the percent complete to accurate metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Improving percent complete to accurate (%C/A) metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One final issue that we need to look at is the rolled C/A values. The %C/A values
    in *Figure 8.2*, at first glance, all appear relatively reasonable across each
    activity. But take a closer look at the impact testing. The 77% C/A ratio has
    an oversized impact on the final rolled average (in this case 41%). The percent
    **complete to accurate** (**%C/A**) metric, more simply put, is a measure of the
    number of times out of 100 that a work item or information is reprocessed through
    an activity, or a series of activities, without requiring rework or error corrections.
  prefs: []
  type: TYPE_NORMAL
- en: Each activity has a %C/A value, while the rolled %C/A measure multiplies all
    %C/A figures across all the series' activities. As a result, just one outlier
    can have a tremendously negative effect. Additionally, a low %C/A value in testing
    is another area we need to look at in our future state mapping exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've reviewed the metrics used in our current value stream map, let's
    review the tools needed to assess Lean performance across our value streams.
  prefs: []
  type: TYPE_NORMAL
- en: Assessing Lean performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Lean metrics identified so far help us evaluate the efficiencies of flow
    across our value streams and act as a means to identify areas of waste. But we
    also need methods to assess the areas that require the most attention in order
    to eliminate waste as part of our ongoing Kaizen efforts. A practical way to do
    this is by developing a **Lean assessment radar chart**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Lean assessment radar chart maps specific Lean objectives that you''ve
    already learned to a grid, radiating outward like spokes from a central hub. A
    completed radar chart looks a bit like a spider''s web, as depicted in *Figure
    8.3*. This figure contains a graphical display of an example Lean assessment radar
    chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Lean assessment radar chart'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17087_Figure_8.3.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.3 – Lean assessment radar chart
  prefs: []
  type: TYPE_NORMAL
- en: A radar chart implements scales to rank capabilities ranging from no commitments
    at the center of the hub to a level representing world-class capabilities at the
    outer radius. The example in *Appendix C* starts at 0 (no commitment) and radiates
    outward across four improved capability levels.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our Lean assessment radar chart example, shown in *Figure 8.3*, the spokes
    have the following rankings:'
  prefs: []
  type: TYPE_NORMAL
- en: '0: No commitment.'
  prefs: []
  type: TYPE_NORMAL
- en: '1: Beginning to implement Lean.'
  prefs: []
  type: TYPE_NORMAL
- en: '2: Changes are becoming visible.'
  prefs: []
  type: TYPE_NORMAL
- en: '3: Results improving at all levels.'
  prefs: []
  type: TYPE_NORMAL
- en: '4: World-class status.'
  prefs: []
  type: TYPE_NORMAL
- en: A quick look at the radar chart in *Figure 8.3* shows our most significant improvement
    needs lie in continuous flows, quality, and visual controls. In contrast, implementation
    of the five S's system and training seem to both be well in hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Without Lean metrics identified as goals, the measure becomes subjective. The
    VSM team must strive to determine what world-class performance looks like across
    each of the assessed Lean practices. The Lean assessment metrics evaluated in
    our sample radar chart include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Continuous flow**: This represents the degree of synchronization and efficiencies
    in flow with the ideal goal of achieving single-piece flows.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Five S''s of Lean**: This is the degree to which the value stream''s work
    area is clean, uncluttered, safe, well organized, with the 5S practices implemented,
    scheduled, and visually displayed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Order leveling**: The degree to which the organization employs Heijunka and
    other Lean leveling practices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quality**: The degree to which the value stream meets its established quality
    metrics, while always working toward the ideal goal of no errors, defects, rework,
    or failures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training**: All value stream members have completed Lean training and have
    access to coaches and mentors, plus access to Lean training aids on demand.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Team member involvement**: The degree to which VSM team members and VS operators
    participate in following the value stream''s standard lean practices, participate
    in Lean assessments meetings, apply 5S practices, participate in Lean training
    programs, and support continuous improvement objectives.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visual controls**: The degree to which the VSM team and VA operators and
    managers maintain and display their Lean metrics, 5S standards, and standard activity
    information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Work unit movement**: The degree to which the value stream limits waiting,
    applies just-in-time and pull-oriented scheduling concepts, and matches flow to
    Takt time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before their Gemba walks, the VSM team should discuss and decide what the values
    0 through 4 should look like for each Lean assessment category. They also need
    to determine what things they plan to look at to assess each category properly.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let's say that for the 5S category, each positive observation of
    the five "S" practices within the value stream earns .8 points toward the total
    possible 4 points. As a result, the VSM team obtained multiple numerical values
    for each category, and the averages, therefore, end up with decimal point values.
  prefs: []
  type: TYPE_NORMAL
- en: These Lean assessment metrics are an essential basis behind our Kaizen efforts.
    As with Agile teams, Lean teams must strive to improve their value stream activities
    and flow continuously. The Lean assessment metrics help us see where the team
    can improve their activities.
  prefs: []
  type: TYPE_NORMAL
- en: We are just about finished with the Lean metrics section. But before we leave,
    let's quickly review the tools associated with gathering and applying Lean metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring key software delivery metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, the metrics assigned to the activities are relatively traditional Lean
    metrics, applicable across any organizational value stream. However, Nicole Forsgren,
    Jez Humble, and Gene Kim, in the book *Accelerate: Building and Scaling High Performing
    Technology Organizations*, identified a shortlist of key metrics that predict
    software delivery performance (2018, pages 17-19). Based on their detailed statistical
    analysis, spanning 23,000 survey responses across 2,000 unique organizations,
    they found that the following four measures are most critical in measuring software
    delivery performance:'
  prefs: []
  type: TYPE_NORMAL
- en: Delivery lead time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment frequency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mean time to restore** (**MTTR**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change fail percentage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Their work continued under the direction of the **DevOps Research and Assessment**
    (**DORA**) team. This Google research group conducted a 6-year program to measure
    and understand DevOps practices and capabilities across the IT industry. DORA's
    research was presented in the annual State of DevOps Reports from 2014 – 2019
    and is available at [https://cloud.google.com/devops/state-of-devops](https://cloud.google.com/devops/state-of-devops).
  prefs: []
  type: TYPE_NORMAL
- en: We'll take a closer look at each of these metrics in the four subsections that
    follow.
  prefs: []
  type: TYPE_NORMAL
- en: Delivery lead time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Delivery lead time** is the total amount of time required to take a customer
    requirement from ideation to customer satisfaction. In software development, satisfaction
    means the product enhancement meets its *definition of Done*. In other words,
    both the team and the customer have agreed a deliverable item meets its defined
    acceptance criteria.'
  prefs: []
  type: TYPE_NORMAL
- en: But the calculation for a delivery lead time as a Lean-oriented metric is tricky.
    In [*Chapter 7*](B17087_07_Final_PD_epub.xhtml#_idTextAnchor183), *Mapping the
    Current State (VSM Step 4)*, and specifically in the *Preparing to map* section,
    you learned that the activities to define and validate requirements and designs
    are creative tasks. The time and effort required to perform creative endeavors
    are challenging to predict compared to the relatively standardized work of developing
    and testing code, provisioning, and deployment. When we speak about using a delivery
    lead time to measure software delivery performance, it's usually best to start
    the clock when a requirement within the product backlog is sufficiently refined
    to begin coding efforts.
  prefs: []
  type: TYPE_NORMAL
- en: High-performance software delivery organizations can develop, test, and deliver
    a new requirement as working code into the main branch of their repository in
    less than one hour. In contrast, the lowest performers deploy working code into
    their main branch only once per week to once per month in the most recent data
    (2017), and as much as once every 6 months in previous years.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment frequency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **deployment frequency** is how often code is released into a production
    environment or sent to an app store. As noted previously, coding and testing smaller
    increments of functionality is superior to building and deploying large-scale
    code changes all at once. The lowest performers tend to take on bigger bites of
    functionality, increasing the complexity of their coding, testing, and debugging
    activities and thereby delaying their deployment frequencies to a range of 1 to
    4 weeks. In contrast, the highest performers take in new requirements on demand,
    build functionality in smaller incremental chunks, and release multiple deployments
    per day.
  prefs: []
  type: TYPE_NORMAL
- en: Note that software development value streams are equivalent to the idealized
    production flow concept of *single-piece flows*. Single-piece flows occur in software
    delivery when the organization automates the DevOps pipeline from *code* to *release-to-production*
    activities. Single-piece flows are the ultimate goal of CI/CD pipelines. In other
    words, each commit of software code into the SCM repository can automatically
    flow through the pipeline and into the production environments without manual
    intervention.
  prefs: []
  type: TYPE_NORMAL
- en: In theory, it's still an example of continuous flow to stop at the preproduction
    environments for final approval. But if that step also involves staging and releasing
    multiple features, that part of the process now becomes a batch process. Regardless
    of the reason or merits, all batch processing impedes the flow of value to our
    customers.
  prefs: []
  type: TYPE_NORMAL
- en: Mean time to restore
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Mean time to restore** is a critical metric as it represents the amount of
    time an application or system has failed and is not providing service to its customer(s).
    Usually, when a system or feature fails, we have no choice but to roll back the
    changes until we can identify and fix the problem. So, the key is to rapidly discover
    the failures and execute a rollback to the previous working release. Ideally,
    we want to see this MTTR number in under one hour. Low performers take between
    a day and a week to restore failed services.'
  prefs: []
  type: TYPE_NORMAL
- en: Change failure rates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Change failure rates** specify the percentage of time taken until a change
    to the code results in a failure, usually detected in the form of a bug or a defect.
    With modern pipeline deployment capabilities, a new release may only involve rolling
    back new releases of functionality. But a failure can also take the form of a
    system-wide crash and loss of services. Regardless, low performers had change
    failure rates of 31% to 45%, while the highest performers had 0 to 15% (Forsgren
    et al., 2018). Improvements in writing test scripts, such as test-driven development
    and test automation capabilities, help lower change failure rate numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: You now have a thorough understanding of both common value stream metrics and
    the four metrics that most often define the performance level for software development
    organizations. In the following subsection, we'll explore how to use state value
    stream metrics to analyze the current state.
  prefs: []
  type: TYPE_NORMAL
- en: Adding flow metrics and analytics to VSM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Beyond the **DORA Four**, the trend in software development is to implement
    **flow metrics and analytics** capabilities to provide visibility to business
    leaders, product managers, and value stream teams to continuously improve their
    processes. Suboptimal processes and team performance can negatively impact the
    organization's Lean-Agile transformation efforts.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, organizations can guide improvement activities and coaching when
    they have access to accurate and consistent metrics visibility of their business
    operations and value streams. The metrics must be available, up to date, and visible
    to all stakeholders at all times.
  prefs: []
  type: TYPE_NORMAL
- en: Modern VSM tools make it easy to capture value stream metrics. This is because
    they act as automated activities, devoid of human manipulations and reporting
    that might cloud the findings. Automating data capture makes the information increasingly
    available, timely, accurate, and usable. Business leaders, team members, and other
    stakeholders must have confidence in the data and its accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Data may come from many disparate tools or systems that participate in a value
    stream pipeline flow. Modern VSM tools apply a **common data model** that normalizes
    the data to provide an end-to-end view of the data across a value stream pipeline.
    In addition, analytical tools, some employing artificial intelligence capabilities,
    make it easier for executives and VSM team members to evaluate the flows across
    current-state activities, then assess alternative future-state scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, portfolio managers and product owners can use these same flow
    metrics and analytical capabilities to assess progress against their product and
    release roadmaps. Therefore, business owners and stakeholders will therefore have
    increased visibility on the delivery status of products and their related production
    costs.
  prefs: []
  type: TYPE_NORMAL
- en: Going beyond the DORA Four
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The DORA Four metrics are beneficial because they help identify the critical
    metrics that define best-in-class software delivery capabilities. They also provide
    a valuable set of metrics as targets for the software development team during
    their transformations to Lean-Agile practices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Still, in a Lean-Agile enterprise, there are many other metrics an organization
    should track to identify areas for continuous improvements and verify the achievement
    of its improvement goals. For example, Gartner analyst Bill Swanton identifies
    18 flow metrics in the **Gartner Report** titled *How Software Engineering Leaders
    Can Use Value Stream Metrics to Improve Agile Effectiveness*. These areas are
    shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – List of Gartner-identified flow metrics'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17087_Figure_8.4.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.4 – List of Gartner-identified flow metrics
  prefs: []
  type: TYPE_NORMAL
- en: 'Swanton says these are some examples of flow metrics that should be considered,
    noting: "*Much like the metrics in a lean manufacturing process, they measure
    how smoothly work is flowing through the system and how responsive teams are to
    changing demand*."'
  prefs: []
  type: TYPE_NORMAL
- en: 'He further points out that: "*Vendors are starting to offer systems that integrate
    with your software development, infrastructure and monitoring tools (version control,
    work management, test management, etc.) to collect, calculate and present the
    metrics continuously*."'
  prefs: []
  type: TYPE_NORMAL
- en: One company that has done a great deal of work in this area is Tasktop, with
    their **Flow Framework**®, under the leadership of Mik Kersten, the company's
    CEO.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the Flow Framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tasktop VSM tools are introduced in more detail in [*Chapter 12*](B17087_12_Final_PD_epub.xhtml#_idTextAnchor342)*,
    Introducing the Leading VSM Tool Vendors*. However, given the Flow Framework's
    relevance to this section, we'll take a moment to explain how modern VSM tools
    can help capture and analyze Flow Metrics.
  prefs: []
  type: TYPE_NORMAL
- en: The concepts behind flow metrics and the Flow Framework were initially introduced
    in the book *Project to Product* by Dr. Mik Kersten (2018). IT leaders have since
    adopted these concepts worldwide in order to bridge the gap between technologists
    and business stakeholders. Specifically, the Flow Framework provides both a methodology
    and vocabulary to systematically discover and eliminate bottlenecks that slow
    down software delivery and negatively impact business results.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of the Flow Framework is to ensure that business-level frameworks and
    transformation initiatives are connected to technical ones associated with implementing
    Agile and DevOps, as well as future methodologies still to arrive. The Tasktop's
    Flow Framework scales the **Three Ways of DevOps** – **flow** (accelerate delivery
    through the development, operations, and on to the customer), **feedback** (create
    safer systems of work), and **continuous learning and experimentation** (fostering
    trust and a scientific approach to organizational improvements and risk-taking)
    – to the entire business. These concepts were introduced in the book *The DevOps
    Handbook* (Kim et al., 2016).
  prefs: []
  type: TYPE_NORMAL
- en: 'With modern VSM tools, every organization can gather hundreds of valuable metrics
    to evaluate improvements in process, productivity, quality, cost, revenue, and
    adherence to standards. The trick is to make sense of it all. Unfortunately, organizations
    often lack visibility into their end-to-end pipeline flows, making it difficult
    to answer the questions shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Flow Framework flow metrics'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17087_Figure_8.5.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.5 – Flow Framework flow metrics
  prefs: []
  type: TYPE_NORMAL
- en: Flow metrics help identify and solve a system's bottleneck, eliminating the
    inefficient local optimizations that may be present when visibility is limited
    to siloed, in-tool data. They also provide a historical view of your performance,
    so you can understand how choices and changes impacted your flow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Four flow items constitute a unit of business value pulled by a stakeholder
    through a product''s value stream. These are **features**, **defects**, **risks**,
    and **debts**, as shown in *Figure 8.6*. Flow metrics are measured for each of
    these flow items both individually and as a collective. The following figure shows
    these items:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Four flow items'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17087_Figure_8.6.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.6 – Four flow items
  prefs: []
  type: TYPE_NORMAL
- en: Flow items represent items of value to the organization. In other words, how
    we address the prioritization of features, defects, technical debt, and risks
    affects our ability to deliver customer value. Therefore, business and technology
    leaders must work in concert to analyze the flow, speed, and prioritization of
    all four value types.
  prefs: []
  type: TYPE_NORMAL
- en: For example, frequently features have priority, but other times we need to fix
    bugs, reduce our technical debts, or address critical risks and issues. Eventually,
    we pay a heavy price if we don't balance the work associated with these four flow
    items.
  prefs: []
  type: TYPE_NORMAL
- en: Despite the complexity and intangibility of software delivery work, the Flow
    Framework makes flow metrics (and the daily practice of VSM) attainable for any
    organization in any structure, by defining how the necessary data can be extracted
    from the execution tools (**integration model**). These are abstracted into flow
    items and flow states (**activity model**), presented in a view that is aligned
    with the business (**product model**).
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus presented and analyzed, flow metrics can then be used to inform the decision-making
    of leaders and teams to deliver targeted business outcomes. Tasktop''s VSM platform
    provides these capabilities out of the box, through a point-and-click interface.
    *Figure 8.7* provides a poster view of the Flow Framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Flow Framework poster'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17087_Figure_8.7.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.7 – Flow Framework poster
  prefs: []
  type: TYPE_NORMAL
- en: Tasktop makes the point that there are other important frameworks (such as **Disciplined
    Agile** (**DA**), the **Scaled Agile Framework®** (**SAFe®**), **Large-Scale Scrum**
    (**LeSS**), and Nexus) that help organizations scale Agile and connect those practices
    to the goals of the business. You will recall that Agile is a set of values and
    principles that help an organization align its resources and activities around
    adding customer-centric value and nimbly responding to changes.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, VSM can increase the flow of business value, from the initial customer
    request to customer delivery. The Flow Framework is a structured, prescriptive
    approach to value stream management in software delivery organizations, created
    to provide a business with customer-centric view of flows across the entire software
    delivery process. Therefore, Agile helps ensure we deliver the correct customer-centric
    value at the right time, while VSM helps ensure we deliver that value rapidly
    and efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a safe work environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Remaining consistent with the values and principles of Agile, we must never
    use the flow metrics as a tool to punish or even reward individuals and teams.
    Instead, their purpose is to help guide our continuous improvement efforts.
  prefs: []
  type: TYPE_NORMAL
- en: Lean-Agile practices emphasize team-based performance, and when things go awry
    – which inevitably they will – we need an all-hands approach to resolve the issues
    at hand. If teams and individuals fear punishment, you can expect that they will
    avoid speaking out and may even hide critical information about issues that impact
    their ability to deliver software value effectively, rapidly, and efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, when our value stream flows are interrupted, we need to stop everything
    and have all team members work together to solve the problem. Attempts to keep
    production flowing lead to queuing, activity waiting, product delays, and possibly
    the accumulation of more defects, all of which can only serve to increase our
    costs.
  prefs: []
  type: TYPE_NORMAL
- en: The benefit of having access to real-time flow metrics is that we can spot issues
    immediately when they arise. This allows us to address them sooner and therefore
    reduce our lost production times and other waste. In addition, these metrics and
    analytics help the team evaluate problems and root causes, as well as brainstorm
    alternative resolution strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the tools of Lean metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter on Lean metrics, you learned about metrics commonly applied
    to measure Lean production practices. You also learned about the four specific
    metrics that give the best prediction of a software delivery teams' performance.
    Traditional VSM practices implemented manual tools to capture and analyze value
    stream metrics. In addition, you also learned how modern VSM tools, flow metrics,
    and analytics help improve the speed and efficiency of software delivery, while
    ensuring software development stays in alignment with the goals and objectives
    of the business.
  prefs: []
  type: TYPE_NORMAL
- en: As regards manual tools, you learned how to use a large whiteboard or chart,
    or electronic screen, to make your metrics highly visible. You also learned how
    to make updates to your VSM Storyboard in order to keep all your VSM team data
    contained and available from a single source. Finally, you learned how to assess
    a value stream's Lean practices. These span eight categories and are displayed
    in a Lean assessment radar chart format. These are all manual tools that evolved
    concurrently with VSM practices.
  prefs: []
  type: TYPE_NORMAL
- en: The advantages of modern VSM tools are their ability to capture end-to-end pipeline
    information and provide analytical tools that work across a common data model.
    In their modern rebirth, VSM tool vendors implement capabilities to capture and
    analyze metrics to support CI/CD and DevOps pipeline flows, using the very same
    concepts and types of metrics employed across all other organizational value streams.
    Therefore, analysts can evaluate the performance of the pipeline activities, in
    part or whole, no matter how many third-party tools become integrated into the
    CI/CD or DevOps pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: But the modern VSM tools go beyond data capture and analysis. They also support
    the **integration**, **automation**, and **orchestration** of pipeline flows.
    We'll start to get into these topics in the next chapter on future state mapping
    and delve into much greater detail in *Section 3* of this book on VSM vendors.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section ends our discussion on Lean metrics, the fifth step in our VSM
    methodology. In the next chapter, [*Chapter 9*](B17087_09_Final_PD_epub.xhtml#_idTextAnchor234),
    *Mapping the Future State (VSM Step 6)*, we''ll start to map the desired future
    state in three phases: evaluating alignment with customer demands, implementing
    continuous flows, and production flow leveling through production control and
    orchestration strategies.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provided instruction on the critical metrics that help us evaluate
    the effectiveness of our value streams from a Lean-oriented perspective. You also
    learned how to go about gathering useful Lean metrics (step five in our generic
    VSM methodology).
  prefs: []
  type: TYPE_NORMAL
- en: While VSM teams can gather and analyze metrics manually, this is a labor-intensive
    process. In contrast, modern VSM tools have become increasingly important, in
    large part because of their ability to capture and display such information in
    real time. Moreover, the analytics and what-if capabilities of VSM tools support
    future state analysis.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how to conduct future state mapping exercises
    across three distinct phases spanning customer demand, continuous flows, and leveling.
    Before we get to that chapter, take a couple of moments to answer the following
    questions. Don't worry if you don't recall the information or quite understand
    all of the questions. Going back to find the answers will help both your understanding
    and ability to retain the knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please answer the following 10 questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Why is the identification of Lean metrics such a crucial concern?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is **cycle time** (**CT**)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is CT the same as **value-adding time** (**VT**)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the relevance of Six Sigma?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the four most important metrics in Lean software delivery?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List the types of non-value-adding activities that contribute to waste.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the relevance of change failure rates?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the essential Lean assessment tool?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the typical radials on the Lean assessment radar chart?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In its modern rebirth, VSM tool vendors implement platforms with metrics and
    analytics to support what three functions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Tapping, D., Luyster, T., Shuker, T. (2002) Value Stream Management: Eight
    Steps to Planning, Mapping, and Sustaining Lean Improvements. Productivity Press.
    New York, NY*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Tapping, D., Luyster, T., Shuker, T. (2003) Value Stream Management for the
    Lean Office: Eight Steps to Planning, Mapping, and Sustaining Lean Improvements.
    Productivity Press. New York, NY*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Tapping, D., Kozlowski, S., Archbold, L., Sperl, T. (2009) Value Stream Management
    for Lean Healthcare: Four steps to Planning, Mapping, Implementing, and Controlling
    Improvements in all types of Healthcare Environments. MCS Media, Inc. Chelsea,
    MI*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Forsgren, N., Humble, J., Kim, G. (2018) Accelerate: Building and Scaling
    High performing Technology Organizations. IT Revolution. Portland, OR.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kim, G., Humble, J., Debois, P., Willis, J. (2016) The DevOps Handbook: How
    to Create World-Class Agility, Reliability, & Security in Technology Organizations.
    IT Revolutions. Portland, OR*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kersten, M. (2018) Project to Product: How to Survive and Thrive in the Age
    of Digital Disruption with the Flow Framework. IT Revolution. Portland, OR*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
