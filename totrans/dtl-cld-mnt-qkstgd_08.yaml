- en: '*Chapter 7*: Monitors and Alerts'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last chapter, we learned how infrastructure is monitored using Datadog.
    The modern, cloud-based infrastructure is far more complex and virtual than the
    data center-based, bare-metal compute, storage, and network infrastructure. Datadog
    is designed to work with cloud-centric infrastructure, and it meets most of the
    infrastructure monitoring needs out of the box, be it a bare-metal or public cloud-based
    infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: A core requirement of any monitoring application is to notify you about an ongoing
    issue. Ideally, before that issue results in a service outage. In previous chapters,
    we discussed metrics and how they are generated, viewed, and charted on dashboards.
    An important use of metrics is to predict an upcoming issue. For example, by tracking
    the `system.disk.free` metric on a storage device, it is easy to notify when it
    reaches a certain point. By combining the `system.disk.total` metric to that equation,
    it's also possible to track the available storage as a percentage.
  prefs: []
  type: TYPE_NORMAL
- en: A monitor typically tracks a time-series value of a metric, and it sends out
    a notification when the metric value is abnormal with reference to a threshold
    during a specified time window. The notification that it sends out is called a
    warning or alert notification. Such notifications are commonly referred to as
    alerts. Thresholds for warning and critical statuses are set on the monitor. For
    example, from the disk storage metrics mentioned earlier, the percentage of free
    storage available can be calculated. The warning threshold could be set at 30
    percent and the critical threshold could be set at 20 percent.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about monitors and alerts and how they are implemented
    in Datadog, in detail. Specifically, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up monitors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing monitors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributing notifications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring downtime
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To try out the examples mentioned in this book, you need to have the following
    tools installed and resources available:'
  prefs: []
  type: TYPE_NORMAL
- en: A Datadog account and a user with admin-level access.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Datadog Agent running at host level or as a microservice depending on the
    example, pointing to the Datadog account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up monitors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a generic monitoring system, a monitor is usually tied to metrics or events,
    and Datadog covers these and much more. There are multiple monitor types based
    on the data sources defined in Datadog. Some of the most important ones include
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Metric**: As mentioned at the beginning of this chapter, metrics are the
    most common type of information used to build monitors. A metric type monitor
    is based on the user-defined thresholds set for the metric value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event**: This monitors the system events tracked by Datadog.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Host**: This checks whether the Datadog agent on the host reports into the
    Datadog **Software as a Service** (**SaaS**) backend.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Live process**: This monitors whether a set of processes at the operating
    system level are running on one or a group of hosts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Process check**: This monitors whether a process tracked by Datadog is running
    on one or a group of hosts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network**: These monitors check on the status of the TCP/HTTP endpoints.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Custom check**: These monitors are based on the custom checks run by the
    Datadog agent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, we will look at how monitors of these types are created and what sort of
    instrumentation needs to be done to support them on the Datadog agent side.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a new monitor, on the Datadog dashboard, navigate to **Monitors**
    | **New Monitor**, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – The New Monitor menu item'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.1_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.1 – The New Monitor menu item
  prefs: []
  type: TYPE_NORMAL
- en: 'It will provide the option to select the monitor type, as shown in *Figure
    7.2*. In this example, we will create a metric type monitor:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Choosing a metric type monitor'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.2_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.2 – Choosing a metric type monitor
  prefs: []
  type: TYPE_NORMAL
- en: 'By clicking on this option, you will get to an elaborate form where all the
    information needed for the monitor will be provided to create it. As there are
    several options available when setting up a monitor, this form is rather long.
    We will view it in the following screenshots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – The New Monitor form – selecting the detection method and metric'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.3_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.3 – The New Monitor form – selecting the detection method and metric
  prefs: []
  type: TYPE_NORMAL
- en: The first step is to select the detection method. In this example, as shown
    in *Figure 7.3*, the detection method is selected as **Threshold Alert**. This
    is the usual detection method in which the metric value is compared with a static
    threshold value to trigger an alert.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following list highlights other detection methods that are available:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Change Alert**: This compares the current metric value with a past value
    in the time series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anomaly Detection**: This detects any abnormality in the metric time series
    data based on past behavior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outliers Alert**: This alerts you about the unusual behavior of a member
    in a group. For example, increased usage of memory on a specific host in a cluster
    of hosts grouped by a tag.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Forecast Alert**: This is similar to a threshold alert; however, a forecasted
    metric value is compared with the static threshold.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The selection of the monitor type is important, as the behavior and use of a
    monitor largely depend on the type of monitor.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Note that only the threshold alert is a standard method that you can find in
    other monitoring systems; the rest of them are Datadog-specific. Usually, some
    customization will be needed to implement these detection methods in a generic
    monitoring system, which Datadog supports out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the second step, the metric used for the monitor is selected, and filter
    conditions are added using tags to define the scope of the monitor. Let''s take
    a look at each field, in this section, to understand all of the available options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Metric**: The metric used for the monitor is selected here. It should be
    one of the metrics that is reported by the Datadog agent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`host` and `device_name` tags, the monitor is defined specifically for a disk
    partition on a host.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**excluding**: Tags could be selected here to exclude more entities explicitly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the filter condition (set in the `system.disk.free` values from multiple
    hosts and devices, one of the aggregate functions, `average`, `maximum`, `minimum`,
    or `sum`, will be selected to specify which value can be used for metric value
    comparisons. Picking the correct aggregate function and tags for grouping is important.
    If the filter condition returns only one value already, then this setting is irrelevant.
  prefs: []
  type: TYPE_NORMAL
- en: The alert triggered by this monitor could be configured as **Simple Alert**
    or **Multi Alert** (in *Figure 7.3*, **Simple Alert** is selected). When the scope
    of the monitor is a single source, such as a storage device on a host, a simple
    alert is chosen. If there are multiple sources involved and the **Simple Alert**
    option is chosen for the monitor, an aggregated alert notification is sent out
    for all the sources, and an alert notification that is specific to each source
    is sent out if the **Multi Alert** option is chosen.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section of the form, the configurations mentioned earlier are all done
    under the **Edit** tab. By clicking on the **Source** tab, you can view the configurations
    you have done in the underlying Datadog definition language, as shown in the following
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In the third part of this form, primarily, threshold values and related configurations
    for the monitor are set, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.4 – The New Monitor form – Set alert conditions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.4_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.4 – The New Monitor form – Set alert conditions
  prefs: []
  type: TYPE_NORMAL
- en: In Datadog terminology, an alert indicates a critical status, and a warning
    is termed as such. In the sample monitor, we are building the **Alert threshold**,
    which is set at 0.5 GB, and the **Warning threshold**, which is set at 1 GB. This
    means that you will get a warning notification when the free space on the disk
    falls to 1 GB, and you will receive a notification with a critical status when
    the free space on the disk falls to 0.5 GB. The warning and alert statuses not
    only differ in terms of the content of the notifications triggered by the monitor,
    but the response to the alerts could also be configured differently. We will look
    at how that can be done later when we learn about configuring alert notifications.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at other options that could be set in the section of the form.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top of the section, in the first line itself, you can configure three
    items, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`above`, `or equal to`, `below`, or `below or equal to`. In our example, we
    need to pick `below`, as the objective of the monitor is to check whether the
    free storage on the disk goes below the certain threshold values that have been
    set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`1 minute` to `1 day`, and there is also a **custom** option. Metric values
    from this time window are checked with reference to the nature of the occurrence
    setting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`on average`, `at least once`, `at all times`, or `in total`. As the options
    suggest, the metric values from the specified time window are checked for possible
    issues, warnings, or alerts, based on this setting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The monitor is marked as recovered from either the warning or alert state when
    the related conditions are no longer satisfied. However, you can add optional
    thresholds that are specific to recovery using **Alert recovery threshold** and
    **Warning recovery threshold**.
  prefs: []
  type: TYPE_NORMAL
- en: The data window can be chosen as **Require** or **Do not require**. If **Require**
    is selected, the monitor will wait for a full window of data to run the checks.
    This option must be selected if the source is expected to report metric values
    regularly. Select **Do not require** if the expectation is to run the checks with
    whatever data points are available during the data window specified on the monitor.
  prefs: []
  type: TYPE_NORMAL
- en: Besides the **warning** and **alert** notifications, the monitor can also report
    on missing data. If the **Notify** option is selected, a notification will be
    sent by the monitor when the metric values are not reported during the specified
    time window in minutes. This option is chosen when the sources are expected to
    report metric values during normal operational conditions, and a **no data** alert
    indicates some issue in the application system monitored by Datadog. If the sources
    selected in the monitor are not expected to report metric values regularly, choose
    the **Do not notify** option. The no data alert could be set to resolve automatically
    after a specified time window. Usually, this is set to **Never** unless there
    is a special case of it being automatically resolved.
  prefs: []
  type: TYPE_NORMAL
- en: Using the **Delay evaluation** option, the metric values used to evaluate various
    thresholds set in the monitor can be offset by a specified number of seconds.
    For example, if a 60-second evaluation delay is specified, at 10:00, the checks
    for the monitor will be run on the data reported from 9:54 to 9:59 for a 5-minute
    data window. In a public cloud environment, Datadog recommends as much as a 15-minute
    delay to reliably ensure that the metric values are available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the thresholds set for the monitor, the live status is charted at
    the top of the form, and the following screenshot shows how the sample monitor
    depicts the status it determined:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.5 – The New Monitor form – the thresholds chart'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.5_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.5 – The New Monitor form – the thresholds chart
  prefs: []
  type: TYPE_NORMAL
- en: The light yellow area of the chart shows the range for the warning threshold,
    and the light purple area indicates the critical (alert) threshold. The bold blue
    line above these areas tracks the current value of the metric, and of course,
    it is well above the danger zone. While building a new monitor interactively,
    this chart is helpful to set realistic thresholds on the monitor.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the fourth section of the **New Monitor** form, the notification to be sent
    out when a warning or critical (alert) state is triggered by the monitor. It is
    presented with a template, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.6 – The New Monitor form – the notification template'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.6_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.6 – The New Monitor form – the notification template
  prefs: []
  type: TYPE_NORMAL
- en: 'The notification can have a title and body, just like an email message. Template
    variables and conditionals could also be used to make them dynamic. The following
    screenshot indicates what an actual notification template might look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.7 – The New Monitor form – an example notification'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.7_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.7 – The New Monitor form – an example notification
  prefs: []
  type: TYPE_NORMAL
- en: 'In the example notification shown in *Figure 7.7*, you can see how template
    and tag variables and conditionals are used in the notification message. With
    the use of `is_warning` and `is_alert` messages, a message specific warning or
    alert could be sent out. Let''s take a look at some of the important variables
    and conditionals that can be used in the message:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Value`: This is the metric value that will trigger the alert.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`threshold`: This is the threshold for triggering an alert that the metric
    value is compared against.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`warn_threshold`: This is similar to the threshold but set for triggering a
    warning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`last_triggered_at`: This details the time when the alert was triggered in
    UTC.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the `TAG_KEY.name` in the notification message. Click on the **Use message
    template variables** help link to know which tags are available for use.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using conditionals, custom notifications can be sent out based on the nature
    of the alert triggered. In the example message template in *Figure 7.7*, you can
    see that part of the message is specific to a warning or an alert. The following
    is a list of the main conditionals that can be used in the message template:'
  prefs: []
  type: TYPE_NORMAL
- en: '`is_alert`: This is used if the notification is triggered by an alert.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_warning`: This is used if the notification is triggered by a warning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_no_data`: This is used if the notification is triggered as a result of
    reporting no metric data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_recovery`: This is used if the notification is triggered when a warning,
    alert, or no data state is recovered to normal.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Please refer to the Datadog documentation for a full set of template variables
    and how they are used at [https://docs.datadoghq.com/monitors/notifications](https://docs.datadoghq.com/monitors/notifications).
  prefs: []
  type: TYPE_NORMAL
- en: The notification message could be formatted as well, and the details of the
    markdown format can be viewed by following the **Markdown Formatting Help** link
    on the form.
  prefs: []
  type: TYPE_NORMAL
- en: The recipients of the notification can be specified using *@*, as mentioned
    in the example template. Usually, an email address or distribution list follows
    *@*. The notification message can be tested by clicking on the **Test Notifications**
    button at the bottom of the form, as shown in *Figure 7.9*. You should see a pop-up
    window where one or more test scenarios can be selected, and the test messages
    will be sent out to recipients accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: You can tag a new monitor to help with searching for and grouping monitors later.
    The tag `monitor-type` with a value `infra` has been added to the sample monitor
    by typing in the tag key and value in the **Tags** field.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `renotify if the monitor has not been resolved` option must be used for
    escalating an issue if no action is taken to resolve the state in the application
    system that triggered the alert. An additional message template must be added
    to the monitor if the renotify option is selected, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.8 – The New Monitor form – alert escalation template'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.8_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.8 – The New Monitor form – alert escalation template
  prefs: []
  type: TYPE_NORMAL
- en: 'In the final part of the **New Monitor** form, the notification rules are configured,
    as shown in *Figure 7.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.9 – The New Monitor form – the Notify your team and Save monitor'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.9_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.9 – The New Monitor form – the Notify your team and Save monitor
  prefs: []
  type: TYPE_NORMAL
- en: The recipient list specified by *@* in the message template in section *4* automatically
    shows up in this section and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to configure the monitor to notify the alert recipients of any
    changes with the monitor definition itself using the **alert recipients when this
    alert is modified** option.
  prefs: []
  type: TYPE_NORMAL
- en: Access to edit the monitor can also be restricted using the **editing this monitor
    to its creator or administrators** option.
  prefs: []
  type: TYPE_NORMAL
- en: The monitor we built in the preceding example is a metric type monitor, which
    is the most common type of monitor available on all monitoring platforms, including
    Datadog. The creation of all of these kinds of monitors is similar, and so, we
    will not look at every step that is needed to set up the remaining monitor types.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the main features of other monitor types and the scenarios
    in which they might be useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '`host` tag.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event**: In this monitor type, Datadog provides a keyword-based search of
    events during a time window and allows you to set warning and alert thresholds
    based on the number of events found in the search result. Setting up an event
    monitor would be useful if it was also possible to track an issue based on the
    event descriptions posted to Datadog.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`&&`), OR (`||`), and NOT (`!`). For example, if a, b, and c are existing monitors,
    you can create a composite monitor using the following condition:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This monitor will trigger when either `a` or `b` triggers and `c` doesn't.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`sshd`, and the alert threshold, `below 1`, are enough to set up the monitor.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`process.up`; however, it''s more organized. The processes to be monitored
    using this type of monitor must be defined in the `conf.d/process.yaml` file on
    the Datadog agent side.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`conf.d/tcp_check.d/conf.yaml` file, and the HTTP checks are defined in the
    `conf.d/http_check.d/conf.yaml` file. The HTTP check also covers SSL certificate-related
    verifications for an HTTPS URL.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The network checks return `OK`, `WARN`, or `CRITICAL`. The threshold is set
    for how many such status codes must be returned consecutively for the monitor
    to trigger a warning or alert.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Integration**: Third-party applications, such as Docker and NGINX, provide
    integrations with Datadog that are available out of the box, and they only need
    to be enabled when required. Once enabled and configured by the Datadog agent,
    the integrations will publish domain-specific metrics and status check results
    into Datadog, and these will be available to monitors of this type.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a monitor of this kind is created, either the integration-specific metric
    or a status check can be used as the source of information to be tracked by the
    monitor.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Custom Check**: When a certain status cannot be checked using various information
    reported by a Datadog agent out of the box with or without some configuration
    changes, or by the use of integrations, custom scripts can be written and deployed
    with the Datadog agent. We will discuss the details of doing that in [*Chapter
    8*](B16483_08_Final_VK_ePub.xhtml#_idTextAnchor248)*, Integrating with Platform
    Components*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This monitor type is similar to the integration monitor, in which a custom check
    is selected for the status check.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Watchdog**: A Watchdog monitor will report on any abnormal activity in the
    system monitored by Datadog. Datadog provides various problem scenarios that cover
    both computational infrastructures and integrations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have looked at how to set up new monitors at great length, and we have also
    reviewed different types of monitors that can cater to all possible requirements
    you might have. In the next section, we will learn how these monitors can be maintained
    in a large-scale environment, where some automation might also be required.
  prefs: []
  type: TYPE_NORMAL
- en: Managing monitors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By navigating to **Monitors** | **Manage Monitors** on the Datadog dashboard,
    you can list all of the existing monitors, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.10 – List of monitors'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.10_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.10 – List of monitors
  prefs: []
  type: TYPE_NORMAL
- en: As shown in *Figure 7.10*, a number of options are available to either mute
    or resolve the monitor. By muting a monitor, you can stop the monitor from triggering
    a warning or alert. Additionally, a monitor can be marked as resolved without
    waiting for the underlying issue to be resolved and the status to be reflected
    in Datadog.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides the obvious **Edit** and **Delete** options, a monitor can be cloned
    using the **Clone** option, as shown in the following screenshot, and it could
    be modified to make a new monitor that could use some features of the source monitor:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.11 – Cloning a monitor'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.11_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.11 – Cloning a monitor
  prefs: []
  type: TYPE_NORMAL
- en: The definition of a monitor can be exported into JSON format and maintained
    in a source code control system as a backup or as a template to derive similar
    monitors from later.
  prefs: []
  type: TYPE_NORMAL
- en: 'To export the definition, open the monitor in **Edit window** and use the **Export
    Monitor** button at the very bottom of the form. A window will pop up, as shown
    in the following screenshot, and you can copy the code using the **Copy** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.12 – Exporting the monitor into JSON'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.12_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.12 – Exporting the monitor into JSON
  prefs: []
  type: TYPE_NORMAL
- en: In the **New Monitor** workflow, using the **Import Monitor from JSON** option,
    a new monitor can be created from the JSON. This provides a textbox where the
    monitor definition in JSON format can be inputted, and, if successful, it will
    take you to the **New Monitor** form prefilled with the details from the JSON.
    Additional modifications can be done before the monitor is saved. The JSON for
    any new monitors created using this method is developed by modifying the JSON
    exported from a similar monitor.
  prefs: []
  type: TYPE_NORMAL
- en: Earlier, we learned how alert notifications can be forwarded to email addresses
    and distribution lists by adding them to the message template using an *@* sign.
    In the next section, we will explore how notifications can be distributed to a
    wide range of communication platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Distributing notifications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's recap some of the concepts that we have discussed in this chapter to reiterate
    the related workflows. A monitor triggers a warning or an alert when some threshold
    or state that the monitor is tracking in the system has been reached. Notifications
    about this change in status, from **OK** to **Warning** or **Alert**, and then
    recovering back to **OK**, can be sent out to different communication platforms
    such as email, Slack, Jira, and PagerDuty. These notifications can also be posted
    to any system that supports Webhooks.
  prefs: []
  type: TYPE_NORMAL
- en: We have already learned that just by prefixing a personal or group email address
    with *@*, the notifications could be forwarded to them. It's always a best practice
    to forward these notifications to a group email or a distribution list, as they
    must be addressed by someone on the team.
  prefs: []
  type: TYPE_NORMAL
- en: 'The integrations with other tools facilitate the distribution and escalation
    of alert notifications for systematic tracking and the closure of issues. Let''s
    take a look at some of the important tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Jira**: Atlassian''s Jira is a popular issue tracking tool. By enabling this
    integration, a Jira ticket can be created for every alert notification the monitors
    generate. Additionally, the creation of the Jira ticket is tracked in Datadog
    as an event.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PagerDuty**: Tools such as PagerDuty are used by support teams to escalate
    issues systematically. An alert notification needs to be distributed to the right
    resource in order to triage the related issue, and if that person is not available,
    another resource must be notified or the issue has to be escalated. PagerDuty
    is good at taking care of such tasks, and it can be configured to implement complex
    escalation needs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Slack**: IRC-style team communication platforms such as **Slack** have been
    very popular, and they cover many messaging requirements that email used to address
    before. Once integrated, many Datadog tasks, such as muting monitors, can be initiated
    from a Slack channel. These options are available in addition to the core feature
    of forwarding the alert notifications to Slack channels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Webhooks**: While Datadog supports integrations with popular issue tracking
    and communication platforms such as PagerDuty, Jira, and Slack, it also provides
    a custom integration option using **w****ebhooks**. If specified in the alert
    notification template, a webhook will post alert-related JSON data into the target
    application. It''s up to that application to consume the alert data and take any
    action based on that. In [*Chapter 8*](B16483_08_Final_VK_ePub.xhtml#_idTextAnchor248),
    *Integrating with Platform Components*, we will learn, in detail, how webhooks
    are set up in Datadog for integration with other applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitors can send out lots of notifications via multiple channels based on the
    integrations in place, and it might be necessary to mute the monitors at times,
    in situations such as maintenance or deployment. In the next section, you will
    learn how that can be accomplished.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring downtime
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the options provided by Datadog, a group of monitors can be muted during
    a scheduled period. Typically, such downtime is needed when you make a change
    to the computing infrastructure or deploy some code. Until such changes are completed,
    and the impacted environments are stabilized, it might not make much sense to
    monitor the software system in production. Additionally, by disabling the monitors,
    you can avoid receiving alert notifications in emails, texts, and even phone calls
    depending on what integrations are in place.
  prefs: []
  type: TYPE_NORMAL
- en: 'To schedule downtime, navigate to **Monitors** | **Manage Downtime**, and you
    should see a form, as shown in the following screenshot, where the existing scheduling
    will be listed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.13 – Managing monitor downtime'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.13_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.13 – Managing monitor downtime
  prefs: []
  type: TYPE_NORMAL
- en: 'By clicking on the **Schedule Downtime** button, you can add a new downtime
    schedule, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.14 – Scheduling a new downtime'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.14_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.14 – Scheduling a new downtime
  prefs: []
  type: TYPE_NORMAL
- en: 'The following options are available for scheduling a downtime:'
  prefs: []
  type: TYPE_NORMAL
- en: The downtime can be defined for all monitors or a group of monitors identified
    by names or tags.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The downtime can be one-time or recurring. A recurring downtime is useful when
    some of the services being monitored will be unavailable periodically, such as
    some applications that are shut down during the weekend.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A notification message template and recipient list can be specified, similar
    to alert notifications, to send out notifications about the downtime.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have looked at the process of configuring the downtime of a monitor, and
    that concludes this chapter. Next, let's take a look at the best practices related
    to setting up and maintaining monitors and alerts.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s review the best practices related to monitors and alerts:'
  prefs: []
  type: TYPE_NORMAL
- en: Define a comprehensive list of monitors that will cover all aspects of the working
    of the software system that Datadog is monitoring.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's possible that you might only be using Datadog to address a certain part
    of the monitoring requirement, and, in that case, make sure that the monitors
    defined cover your area of focus.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To avoid alert fatigue, make sure that all alert notifications are actionable,
    and the remediation steps are documented in the notification itself or in a runbook.
    Continue fine-tuning the thresholds and data window size until you start getting
    credible alert notifications. If monitors are too sensitive, they can start generating
    noise.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If any amount of fine-tuning is not enough to tame a monitor from sending out
    too many alerts, consider deleting it, and plan to monitor the related scenario
    in some other reasonable way.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrate monitors with your company's choice of tools for incident tracking,
    escalation, and team communication. Email notifications must be a backup, and
    those notifications must be sent out to user groups and not individuals. Email
    alerts should also serve as a historical record that can be used as evidence for
    postmortems (or the **Root Cause Analysis** or **RCA** of production incidents)
    and third-party audits such as those required for **SOC 2 Type** 2 compliance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Back up monitors as code by exporting out the JSON definition and maintaining
    it inside a source control system such as Git. If possible, maintain monitors
    in a code repository by defining monitors in Terraform or Ansible or Datadog's
    JSON format.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Socialize the downtime feature and practice it while doing maintenance. Without
    that, the alert notifications can become a nuisance, and the credibility of the
    monitoring system itself can take a hit.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have learned how to create a new Datadog monitor based
    on the variety of information available in Datadog about the software system and
    the infrastructure that Datadog monitors. Additionally, we learned how those monitors
    could be maintained manually or maintained as code using the options available.
    We looked at different methods available to integrate the monitors with communication
    tools to distribute the alert notifications widely. Finally, you learned how the
    downtime feature could be used effectively during maintenance and shutdown periods.
  prefs: []
  type: TYPE_NORMAL
- en: We already discussed a number of third-party tools in the context of using or
    monitoring them with Datadog. In the next chapter, we will learn how such integrations
    are used in Datadog and how custom integrations can be rolled out.
  prefs: []
  type: TYPE_NORMAL
