<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer126">
			<h1 id="_idParaDest-142"><em class="italic"><a id="_idTextAnchor248"/>Chapter 8</em>: Integrating with Platform Components</h1>
			<p>We learned about monitors and alerts, key elements of a monitoring infrastructure that are central to the 24x7 monitoring of software systems in production, in the last chapter. Earlier in the book, we saw how infrastructure resources, the basic building blocks of any computational environment that runs a software system, are monitored by Datadog.</p>
			<p>In <a href="B16483_01_Final_VK_ePub.xhtml#_idTextAnchor014"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Monitoring</em>, we discussed various types of monitoring and briefly mentioned platform monitoring, the monitoring of software and cloud computing components that are used to build the computing platform where application software runs. In a public cloud environment, there are overlaps between infrastructure and platform components because compute, storage, and network components are software-defined in those environments, and, for monitoring purposes, they could be treated as a platform component such as <strong class="bold">MySQL Database</strong> or the <strong class="bold">RabbitMQ</strong> messaging system.</p>
			<p>However, it's not difficult to differentiate infrastructure resources from platform components. A cloud platform is essentially a software layer running on top of infrastructure resources and applications either run them or use them at runtime. Typically, the infrastructure resources are provisioned on the public cloud, and the platform components are provided by third-party software vendors or open source communities and the applications are built by another company. Please note that a popular public cloud provider such as AWS also offers services that can be substituted for platform components. Examples on AWS are <strong class="bold">Relational Database Service </strong>(<strong class="bold">RDS</strong>), <strong class="bold">Amazon MQ</strong>, and <strong class="bold">Elastic Kubernetes Service</strong> (<strong class="bold">EKS</strong>).</p>
			<p>We learned earlier, in <a href="B16483_06_Final_VK_ePub.xhtml#_idTextAnchor214"><em class="italic">Chapter 6</em></a>, <em class="italic">Infrastructure Monitoring</em>, that most of the infrastructure monitoring is covered by Datadog out of the box with minimal configuration requirements. While most features of infrastructure resources are standard, the same could not be said about platform components, which basically are software applications that perform a specific set of tasks and the monitoring requirements are feature-dependent.</p>
			<p>Datadog addresses platform monitoring in two ways:</p>
			<ul>
				<li>Shipping integrations with popular platform software components. With these integrations available out of the box, the users only need to enable whichever integrations are needed for the platform components used in their applications.</li>
				<li>Providing the option to run custom checks that can be used to monitor platform components that may not have integrations readily available out of the box.</li>
			</ul>
			<p>In this chapter, we will learn about the details of platform monitoring using the integration options available in Datadog as outlined above. Specifically, we will cover these topics:</p>
			<ul>
				<li>Configuring an integration</li>
				<li>Tagging an integration </li>
				<li>Reviewing supported integrations</li>
				<li>Implementing custom checks</li>
			</ul>
			<h1 id="_idParaDest-143"><a id="_idTextAnchor249"/>Technical requirements</h1>
			<p>To try out the examples mentioned in this book, you need to have the following tools installed and resources available:</p>
			<p>- An Ubuntu 18.04 environment with Bash shell. The examples might work on other Linux distributions  as well but suitable changes must be done to the Ubuntu specific commands.</p>
			<p>- A Datadog account and a user with admin-level access.</p>
			<p>- A Datadog Agent running at host level or as a microservice depending on the example, pointing to the Datadog account.</p>
			<h1 id="_idParaDest-144"><a id="_idTextAnchor250"/>Configuring an integration</h1>
			<p>Datadog provides integration with most of the popular platform components and they need to be <a id="_idIndexMarker443"/>enabled as needed. We will see the general steps involved in enabling integration with an example.</p>
			<p>The available integrations are listed on the <strong class="bold">Integrations</strong> dashboard as in the following screenshot, and it's directly accessible from the main menu:</p>
			<div>
				<div id="_idContainer118" class="IMG---Figure">
					<img src="Images/Figure_8.1_B16483.jpg" alt="Figure 8.1 – List of available integrations&#13;&#10;" width="1643" height="992"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.1 – List of available integrations</p>
			<p>As you can see, in <em class="italic">Figure 8.1</em>, the third-party software components are listed on the <strong class="bold">Integrations</strong> dashboard. Using the search option available at the top of this dashboard, the <a id="_idIndexMarker444"/>integrations that are already installed can be filtered out. Also, the available integrations can be looked up using keywords.</p>
			<p>By clicking on a specific integration listing, you can get all the details related to that integration. For example, the following screenshot provides such details for integration with NGINX, a popular web server:</p>
			<div>
				<div id="_idContainer119" class="IMG---Figure">
					<img src="Images/Figure_8.2_B16483.jpg" alt="Figure 8.2 – Overview of NGINX integration&#13;&#10;" width="1648" height="867"/>
				</div>
			</div>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Figure 8.2 – Overview of NGINX integration</p>
			<p>From this dashboard, we can get the complete list of metrics that will be published by the integration <a id="_idIndexMarker445"/>once that is enabled. Also, this specific integration provides a few monitors, which is an optional feature. The main objective of using an integration is to get access to the platform's component-related metrics that could be used in custom-built monitors, dashboards, and other Datadog resources.</p>
			<p>The configuration of an integration requires two main steps:</p>
			<ol>
				<li><strong class="bold">Install integration</strong>: An integration can be installed in your account by just clicking on the <strong class="bold">Install</strong> button available, as in the following screenshot, pertaining to NGINX integration:<div id="_idContainer120" class="IMG---Figure"><img src="Images/Figure_8.3_B16483.jpg" alt="Figure 8.3 – Install an integration&#13;&#10;" width="960" height="754"/></div><p class="figure-caption">Figure 8.3 – Install an integration</p><p>The <strong class="bold">Install</strong> button will be displayed when you move the cursor over an available integration.</p></li>
				<li><strong class="bold">Configure integration</strong>: Configuration of the integration is the main part of rolling out an integration in a Datadog account. The steps to do that are provided under the <strong class="bold">Configuration</strong> tab of the integration (see <em class="italic">Figure 8.2</em>). These steps are platform component dependent and would require changes in the Datadog monitoring infrastructure. For example, if the component runs on a host, such as the NGINX web server, the changes will be needed in the configuration of the Datadog agent running on that host.</li>
			</ol>
			<p>Now let's see <a id="_idIndexMarker446"/>how the NGINX integration is configured to get it enabled for a specific NGINX instance and that will demonstrate the general steps involved in configuring any integration.</p>
			<p>The first step is to enable the integration in your account and that can be accomplished by just clicking the <strong class="bold">Install</strong> button on the integration listing as you can see in <em class="italic">Figure 8.3</em>.</p>
			<p>In the sample case here, we will try to enable the integration for an open source version of an NGINX instance <a id="_idIndexMarker447"/>running on an <strong class="bold">AWS EC2</strong> host that runs on the Linux <a id="_idIndexMarker448"/>distribution <strong class="bold">Ubuntu 16.04</strong>. Note that the actual configuration steps would also differ depending on the operating system where the platform component and Datadog agent run, and these steps are specific to the environment described previously:</p>
			<ol>
				<li value="1">Make sure that both the Datadog Agent and NGINX services are running on the host. This could be checked as follows on Ubuntu 16.04:<p class="source-code"><strong class="bold">$ sudo service nginx status</strong></p></li>
				<li>	You will see a status similar to the following if the service runs OK:<p class="source-code"><strong class="bold">Active: active (running) since Mon 2021-01-04 03:50:39 UTC; 1min 7s ago</strong></p><p class="source-code"><strong class="bold">$ sudo service datadog-agent status</strong></p><p class="source-code"><strong class="bold">Active: active (running) since Sun 2021-01-03 21:12:26 UTC; 6h ago</strong></p><p><em class="italic">(Only the line corresponding to service status is provided here for brevity.)</em></p><p>Let's do the configuration changes needed on the NGINX side first.</p></li>
				<li>Check if the <a id="_idIndexMarker449"/>stub status module is installed with the NGINX instance that is needed for the integration to work:<p class="source-code"><strong class="bold">$ nginx -V 2&gt;&amp;1| grep -o http_stub_status_module</strong></p><p class="source-code"><strong class="bold">http_stub_status_module</strong></p></li>
				<li>Under the NGINX configuration directory <strong class="source-inline">/etc/nginx/conf.d/</strong>, create a new file, <strong class="source-inline">status.conf</strong>, and add the following configuration:<p class="source-code">server {</p><p class="source-code">           listen 81;</p><p class="source-code">           server_name localhost;</p><p class="source-code">           access_log off;</p><p class="source-code">                allow 127.0.0.1;</p><p class="source-code">                deny all;</p><p class="source-code">                 location /nginx_status {</p><p class="source-code">      # Choose your status module</p><p class="source-code">      # freely available with open source NGINX</p><p class="source-code">      stub_status;</p><p class="source-code">      # for open source NGINX &lt; version 1.7.5</p><p class="source-code">      # stub_status on;</p><p class="source-code">      # available only with NGINX Plus</p><p class="source-code">             # status;</p><p class="source-code">             # ensures the version information can be retrieved</p><p class="source-code">             server_tokens on;</p><p class="source-code">  }</p><p class="source-code">}</p></li>
				<li>Reload the <a id="_idIndexMarker450"/>configuration change in NGINX:<p class="source-code"><strong class="bold">$ sudo nginx -t &amp;&amp; sudo nginx -s reload</strong></p><p class="source-code"><strong class="bold">nginx: the configuration file /etc/nginx/nginx.conf syntax is ok</strong></p><p class="source-code"><strong class="bold">nginx: configuration file /etc/nginx/nginx.conf test is successful</strong></p></li>
				<li>To complete the configuration changes, they must be done on the Datadog Agent side also. Let's do that next. For each integration supported by Datadog, a configuration directory is available under <strong class="source-inline">/etc/datadog-agent/conf.d/</strong>. For NGINX integration, it's <strong class="source-inline">nginx.d</strong>. Usually, a sample configuration file is available in this directory that can be customized for your specific requirements. To keep it simple, we will make a copy of the sample file that already contains the basic configuration needed for getting this integration working, and then restart Datadog Agent:<p class="source-code"><strong class="bold">$ sudo cp conf.yaml.example conf.yaml</strong></p><p class="source-code"><strong class="bold">$ sudo service datadog-agent restart</strong></p></li>
				<li>To check if <a id="_idIndexMarker451"/>the integration works correctly, you can look at the related information in the Datadog Agent status:<p class="source-code"><strong class="bold">$ sudo datadog-agent status</strong></p><p class="source-code">Getting the status from the agent.</p><p class="source-code">nginx (3.8.0)</p><p class="source-code">-------------</p><p class="source-code">      Instance ID: nginx:16eb944e0b242d7 [OK]</p><p class="source-code">Configuration Source: file:/etc/datadog-agent/conf.d/nginx.d/conf.yaml</p><p class="source-code">      Total Runs: 5</p><p class="source-code">      Metric Samples: Last Run: 7, Total: 35</p><p class="source-code">      Events: Last Run: 0, Total: 0</p><p class="source-code">      Service Checks: Last Run: 1, Total: 5</p><p class="source-code">      Average Execution Time : 4ms</p><p class="source-code">      Last Execution Date : 2021-01-04 04:00:29.000000 UTC</p><p class="source-code">      Last Successful Execution Date : 2021-01-04 04:00:29.000000 UTC</p><p class="source-code">      metadata:</p><p class="source-code">        version.major: 1</p><p class="source-code">        version.minor: 10</p><p class="source-code">        version.patch: 3</p><p class="source-code">        version.raw: 1.10.3 (Ubuntu)</p><p class="source-code">        version.scheme: semver</p></li>
			</ol>
			<p><em class="italic">(The preceding output is only an excerpt related to NGINX integration status.)</em></p>
			<p>When the configurations on the host are done and we've checked that it's working successfully, we can expect to see the related NGINX metrics to be available on the Datadog UI for use in monitors and dashboards. The easiest way to verify that is to search for some <a id="_idIndexMarker452"/>sample metrics on the <strong class="bold">Metrics Explorer</strong> dashboard as in the following screenshot, in which the metric <strong class="source-inline">nginx.net.connections</strong> is looked up and located successfully:</p>
			<div>
				<div id="_idContainer121" class="IMG---Figure">
					<img src="Images/Figure_8.4_B16483.jpg" alt="" width="1622" height="778"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.4 – NGINX metrics in Metrics Explorer</p>
			<p>This way, any metric supported by the integration, as documented under the <strong class="bold">Metrics</strong> tab on the dashboard for the integration, can be looked up. If you are looking for metrics published from a specific host to verify a new rollout of the integration for that host, the metrics listing could be filtered down by selecting the specific host in the <strong class="bold">Over</strong> field as shown in the preceding screenshot.</p>
			<p>We just looked at the generic steps of rolling out an agent-based integration and how to verify whether that is working. In a real-life production environment, there would be multiple such integrations enabled for many platform components such as NGINX. Even the same component could be used for multiple purposes. For example, NGINX could be used as an HTTP server serving a simple web application or as a proxy server directing web traffic to <a id="_idIndexMarker453"/>more complex computing environments such as a cluster of hosts running JVM or a Kubernetes cluster. In such cases, there must be some means to differentiate the source of metrics easily without depending on the hostnames, as the life of a host in a public cloud environment is not long-term. We already saw in <a href="B16483_05_Final_VK_ePub.xhtml#_idTextAnchor178"><em class="italic">Chapter 5</em></a>, <em class="italic">Metrics, Events, and Tags</em>, how metrics are tagged to facilitate filtering and aggregation. We will revisit that in the next section in the context of rolling out an integr<a id="_idTextAnchor251"/>ation.</p>
			<h1 id="_idParaDest-145"><a id="_idTextAnchor252"/>Tagging an integration</h1>
			<p>The metrics published by an integration can be tagged at the integration level for better visibility with Datadog resources where those metrics will be used eventually. We will see how that's <a id="_idIndexMarker454"/>done with the intention of implementing the best practices for effectiveness. We already learned in <a href="B16483_02_Final_VK_ePub.xhtml#_idTextAnchor115"><em class="italic">Chapter 2</em></a>, <em class="italic">Deploying Datadog Agent</em>, and, in <a href="B16483_05_Final_VK_ePub.xhtml#_idTextAnchor178"><em class="italic">Chapter 5</em></a>, <em class="italic">Metrics, Events, and Tags</em>, that host-level, custom tags can be added by using the tags configuration item in the <strong class="source-inline">datadog.yaml</strong> file. Custom tags added using this option will be available on all the metrics generated by various integrations running on that host. The tagging option is available at the integration level also, and the related tags will be applied only on the integration-specific metrics.</p>
			<p>In the use case that was mentioned in the previous section related to using NGINX for different roles, this multi-level tagging method will be useful to filter the NGINX metrics originating from multiple hosts. For example, at the host level, it can be identified as a web server or proxy server with the tag <strong class="source-inline">role:proxy-server</strong> or <strong class="source-inline">role:web-server</strong>, and at the integration level, more tags can be applied indicating the specific name of the component with the tag <strong class="source-inline">component:nginx</strong>. Note that this approach provides the flexibility to <a id="_idIndexMarker455"/>track the role of platform components such as <strong class="bold">HAProxy</strong>, NGINX, and <strong class="bold">Apache</strong> that could <a id="_idIndexMarker456"/>be used for a variety of HTTP and proxy serving roles in the entire application system. </p>
			<p>Now, let's see how this tagging strategy we just discussed could be implemented in the sample case from the last section.</p>
			<p>In the <strong class="source-inline">datadog.yaml</strong> file, the following tag is added:</p>
			<p class="source-code">tags:</p>
			<p class="source-code">    - role:proxy-server</p>
			<p>In the <strong class="source-inline">conf.d/nginx.d/conf.yaml</strong> file, the following two tags are added:</p>
			<p class="source-code">tags:</p>
			<p class="source-code">        - component:nginx</p>
			<p class="source-code">        - nginx-version:open-source</p>
			<p>Note that the <a id="_idIndexMarker457"/>additional tag <strong class="source-inline">nginx-version</strong> will help to identify what kind of NGINX is used. To start applying these tags to the metrics, the Datadog Agent has to be restarted. After that, you can filter the metrics using these tags as in the following examples.</p>
			<p>In the first example, as shown in the following screenshot in <em class="italic">Figure 8.5</em>, you can see that an integration metric, <strong class="source-inline">nginx.net.connections</strong>, is tagged with a host-level tag, <strong class="source-inline">proxy-server</strong>. Note that all the host-level metrics and the metrics from other integrations will also be tagged in the same fashion. For example, the system-level metric <strong class="source-inline">system.mem.used</strong> will also be tagged with <strong class="source-inline">role:proxy-server</strong> once that is enabled:</p>
			<div>
				<div id="_idContainer122" class="IMG---Figure">
					<img src="Images/Figure_8.5_B16483.jpg" alt="Figure 8.5 – Host-level tag applied on an integration metric&#13;&#10;" width="1650" height="764"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.5 – Host-level tag applied on an integration metric</p>
			<p>In the next <a id="_idIndexMarker458"/>example, shown in <em class="italic">Figure 8.6</em>, the integration-level tags, <strong class="source-inline">component:nginx</strong> and <strong class="source-inline">nginx-version:open-source</strong>, are available only for filtering integration-level metrics. You cannot filter a host-level metric like <strong class="source-inline">system.mem.used</strong> using those tags:</p>
			<div>
				<div id="_idContainer123" class="IMG---Figure">
					<img src="Images/Figure_8.6_B16483.jpg" alt="Figure 8.6 – Integration-level tag&#13;&#10;" width="1650" height="712"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.6 – Integration-level tag</p>
			<p>In the last two sections, we have learned the basics of how to enable an integration and how to tag the <a id="_idIndexMarker459"/>metrics published by an integration. With that basic understanding, we will dig deeper into the broader picture of the Datadog support for third-party applications and how they are integrated and organized. We will also look at some of the important integrations that we will see ourselves using most of the time with Datadog as they are the common platform components used to build a variety of software applicatio<a id="_idTextAnchor253"/>n systems.</p>
			<h1 id="_idParaDest-146"><a id="_idTextAnchor254"/>Reviewing supported integrations</h1>
			<p>It has been already mentioned that Datadog provides integrations for a lot of third-party platform <a id="_idIndexMarker460"/>components. Some of them, such as Apache, NGINX, Docker, MySQL, and the like, are more important than the rest because of their ubiquitous use across a variety of software applications. In this section, we will look at the important integrations and call out points of any importance.</p>
			<p>Datadog provides three different options for integrating platform components:</p>
			<ul>
				<li><strong class="bold">Agent-based</strong>: In the example we saw earlier in this chapter, the Datadog Agent configuration had to be updated to enable the integration. That is required <a id="_idIndexMarker461"/>because the platform component, NGINX in the example, runs on a host. It could be run as a microservice also and yet an agent is needed to monitor that environment. Essentially, the integration in that case is managed by the local agent. The Datadog Agent is shipped with official integrations and they are readily available as we saw in the example on NGINX. There are more integrations available that are community-built and they can be checked out at <a href="https://github.com/DataDog/integrations-extras">https://github.com/DataDog/integrations-extras</a> on GitHub. Each integration is documented in its own README file there.</li>
				<li><strong class="bold">Crawler-based</strong>: A software platform is not always built using components running <a id="_idIndexMarker462"/>only locally. Some services could be cloud-based and Datadog provides integrations with popular <a id="_idIndexMarker463"/>services such as GitHub, <strong class="bold">Slack</strong>, and <strong class="bold">PagerDuty</strong>. In such cases, credentials <a id="_idIndexMarker464"/>to access those service accounts are provided to Datadog and it will crawl the account to report metrics related to the given service account.</li>
				<li><strong class="bold">Custom integration</strong>: Custom integration options are extensive with Datadog and they <a id="_idIndexMarker465"/>are general-purpose in nature and not specific to integrating platform components. The option to run custom checks from a Datadog Agent is the easiest option available to integrate a platform component for which official support is not available or adequate. We will see how that could be implemented in a sample later in this section. The following are the other options that can be used for rolling out a custom integration.</li>
				<li><strong class="bold">Use the Datadog API</strong>: One of the major attractions of using Datadog for monitoring <a id="_idIndexMarker466"/>is its extensive REST API support. While you need a skilled team to roll out integrations using the Datadog API, having that option makes your monitoring infrastructure extensible and flexible.</li>
				<li><strong class="bold">Build your own integration</strong>: Datadog provides a developer toolkit to build your own <a id="_idIndexMarker467"/>integration following the Datadog norms. The details can be checked out at <a href="https://docs.datadoghq.com/developers/integrations/new_check_howto">https://docs.datadoghq.com/developers/integrations/new_check_howto</a>.</li>
				<li><strong class="bold">Publish metrics using StatsD</strong>: We will look at this generic integration option <a id="_idIndexMarker468"/>in detail in <a href="B16483_10_Final_VK_ePub.xhtml#_idTextAnchor302"><em class="italic">Chapter 10</em></a>, <em class="italic">Working with Monitoring Standards</em>.</li>
			</ul>
			<p>Now let's look at some of the important integrations that are shipped with the Datadog Agent and available for users to enable and use:</p>
			<ul>
				<li><strong class="bold">Integrations with the public cloud</strong>: Datadog supports integrations with major <a id="_idIndexMarker469"/>public cloud platforms <a id="_idIndexMarker470"/>such as <strong class="bold">AWS</strong>, <strong class="bold">Azure</strong>, and <strong class="bold">GCP</strong> and the individual services offered <a id="_idIndexMarker471"/>on those platforms. These crawler-based integrations <a id="_idIndexMarker472"/>require access to your public cloud account and that can be provided in different ways.</li>
				<li><strong class="bold">Microservices resources</strong>: Both <strong class="bold">Docker</strong> and <strong class="bold">Kubernetes</strong> are key components <a id="_idIndexMarker473"/>in building a <a id="_idIndexMarker474"/>microservices infrastructure. Integrations for both these platform <a id="_idIndexMarker475"/>components and related products are supported by Datadog.</li>
				<li><strong class="bold">Proxy and HTTP services</strong>: Apache, <strong class="bold">Tomcat</strong>, NGINX, HAProxy, <strong class="bold">Microsoft IIS</strong>, and <strong class="bold">Memcached</strong> are <a id="_idIndexMarker476"/>popular in <a id="_idIndexMarker477"/>this category <a id="_idIndexMarker478"/>and integrations <a id="_idIndexMarker479"/>are available for these components.</li>
				<li><strong class="bold">Messaging services</strong>: Popular <a id="_idIndexMarker480"/>messaging software and cloud services such as RabbitMQ, IBM MQ, Apache Active MQ, and Amazon MQ are supported.</li>
				<li><strong class="bold">RDBMS</strong>: Almost <a id="_idIndexMarker481"/>every <a id="_idIndexMarker482"/>popular <strong class="bold">Relational Database Management System </strong>(<strong class="bold">RDBMS</strong>), such as <strong class="bold">Oracle</strong>, <strong class="bold">SQL Server</strong>, <strong class="bold">MySQL</strong>, <strong class="bold">PostgreSQL</strong>, and <strong class="bold">IBM DB2</strong>, is supported. Monitoring databases is an important <a id="_idIndexMarker483"/>requirement as <a id="_idIndexMarker484"/>databases are central to <a id="_idIndexMarker485"/>many software <a id="_idIndexMarker486"/>applications. These integrations <a id="_idIndexMarker487"/>supply a variety of metrics that could be used to monitor the workings and performance of databases.</li>
				<li><strong class="bold">NoSQL and Big Data</strong>: NoSQL <a id="_idIndexMarker488"/>databases are widely used in big data and cloud-based applications due to <a id="_idIndexMarker489"/>their flexibility <a id="_idIndexMarker490"/>and scalability. Popular software such as <strong class="bold">Redis</strong>, <strong class="bold">Couchbase</strong>, <strong class="bold">Cassandra</strong>, <strong class="bold">MongoDB</strong>, <strong class="bold">Hadoop</strong>, and related <a id="_idIndexMarker491"/>products from <a id="_idIndexMarker492"/>this category are supported <a id="_idIndexMarker493"/>by Datadog.</li>
				<li><strong class="bold">Monitoring tools</strong>: It's common to have multiple monitoring tools in use as part of rolling <a id="_idIndexMarker494"/>out a comprehensive monitoring solution for a target environment. In such a scenario, Datadog will be one of the services in the mix, and it's a good platform to aggregate inputs from other monitoring systems due to its superior UI and dashboarding features. Datadog also provides integrations with other monitoring <a id="_idIndexMarker495"/>tools to facilitate <a id="_idIndexMarker496"/>that consolidation. Currently, integrations <a id="_idIndexMarker497"/>for monitoring applications such as <strong class="bold">Catchpoint</strong>, <strong class="bold">Elasticsearch</strong>, <strong class="bold">Nagios</strong>, <strong class="bold">New Relic</strong>, <strong class="bold">Pingdom</strong>, <strong class="bold">Prometheus</strong>, <strong class="bold">Splunk</strong>, and <strong class="bold">Sumo Logic</strong> are available. </li>
			</ul>
			<p>If the Datadog-supplied <a id="_idIndexMarker498"/>integrations don't <a id="_idIndexMarker499"/>meet an important <a id="_idIndexMarker500"/>custom requirement, you can extend Datadog to cover that by <a id="_idIndexMarker501"/>implementing a <a id="_idIndexMarker502"/>custom check. In the next section, you will learn how to implement a sample custom check using a<a id="_idTextAnchor255"/> simple Python script that publishes a custom metric.</p>
			<h1 id="_idParaDest-147"><a id="_idTextAnchor256"/>Implementing custom checks</h1>
			<p>Custom checks can be used to monitor a platform component if the available integration <a id="_idIndexMarker503"/>features are not adequate or an integration doesn't exist at all for that component. The Datadog API could be used as well in reporting custom-generated metrics to Datadog. We will explore this option with an example.</p>
			<p>The process involved in implementing a check that publishes custom metrics is simple in Datadog and we can learn about that from the following example.</p>
			<p>Continuing with the example of NGINX from the previous sections in this chapter, we will try to extend that integration by adding a custom metric to Datadog. This custom metric, <strong class="source-inline">kurian.nginx.error_log.size</strong>, tracks the size of the NGINX error log file. It's better to begin the metric name with a namespace specific to your company or department, as the metric is labeled in this example, to filter custom metrics easily.</p>
			<p>Manually, the file size information could be gathered by running the command <strong class="source-inline">ls -al</strong> on any UNIX-compatible shell. The same command could be run from the Datadog custom check also and the output can be parsed to obtain the desired result.</p>
			<p>Let's call this custom check <strong class="source-inline">custom_nginx</strong>. The configuration steps largely follow those we did for enabling the NGINX integration earlier. In this case, the configuration directory and related resources have to be created:</p>
			<ol>
				<li value="1">Create a configuration directory and set up a configuration file for the check:<p class="source-code"><strong class="bold">$ cd /etc/datadog-agent/conf.d</strong></p><p class="source-code"><strong class="bold">$ sudo mkdir custom_nginx.d</strong></p></li>
				<li>Create a <strong class="source-inline">custom_nginx.yaml</strong> file in the new directory and save the following string in it:<p class="source-code"><strong class="bold">instances: [{}]</strong></p><p class="source-code"><strong class="bold">$ sudo chown -R dd-agent:dd-agent custom_nginx.d</strong></p></li>
				<li>Install the Python script in <strong class="source-inline">/etc/datadog-agent/checks.d</strong>:<p>Save the following script as <strong class="source-inline">custom_nginx.py</strong>. Note that the naming convention <a id="_idIndexMarker504"/>matters as that's how the Datadog Agent relates the custom check to the script:</p><p class="source-code"># Based on the sample code provided in Datadog documentation.</p><p class="source-code">try:</p><p class="source-code">    from datadog_checks.base import AgentCheck</p><p class="source-code">except ImportError:</p><p class="source-code">    from checks import AgentCheck</p><p class="source-code"># Value set on __version__ will be shown in the Agent status page</p><p class="source-code">__version__ = "v1.0"</p><p class="source-code">from datadog_checks.base.utils.subprocess_output import get_subprocess_output</p><p class="source-code">class NginxErrorCheck(AgentCheck):</p><p class="source-code">    def check(self, instance):</p><p class="source-code">        file_info err, retcode = get_subprocess_output(["ls", "-al","/var/log/nginx/error.log"], self.log, raise_on_empty_output=True)</p><p class="source-code">        file_size = file_info.split(" ")[4];</p><p class="source-code">        self.gauge("kurian.nginx.error_log.size", file_size,tags=['component:nginx'])</p><p>Besides the template requirements of the script, it does the following tasks:</p><p>A. Runs the <strong class="source-inline">ls -al</strong> command on the <strong class="source-inline">/var/log/nginx/error.log</strong> file</p><p>B. Parses the file size from the command output</p><p>C. Reports the file size as a metric value to Datadog with the <strong class="source-inline">component:nginx</strong> tag applied </p></li>
				<li>Restart the Datadog Agent to enable the custom check. To check if it runs successfully, you <a id="_idIndexMarker505"/>can run the <strong class="source-inline">status check</strong> command and look for the status related to the custom check:<p class="source-code">      $ sudo datadog-agent status</p><p class="source-code">      </p><p class="source-code">     Running Checks</p><p class="source-code">  ==============</p><p class="source-code">    </p><p class="source-code">    custom_nginx (1.0.0)</p><p class="source-code">    --------------------</p><p class="source-code">      Instance ID: custom_nginx:d884b5186b651429 [OK]</p><p class="source-code">      Configuration Source: file:/etc/datadog-agent/conf.d/custom_nginx.d/custom_nginx.yaml</p><p class="source-code">      Total Runs: 1</p><p class="source-code">      Metric Samples: Last Run: 1, Total: 1</p><p class="source-code">      Events: Last Run: 0, Total: 0</p><p class="source-code">      Service Checks: Last Run: 0, Total: 0</p><p class="source-code">      Average Execution Time : 2ms</p><p class="source-code">      Last Execution Date : 2021-01-04 10:03:18.000000 UTC</p><p class="source-code">      Last Successful Execution Date : 2021-01-04 10:03:18.000000 UTC</p></li>
				<li>Once you have verified the working of the custom check on the server side, you can expect the custom metric to be available on the Datadog UI, and it can be verified as in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer124" class="IMG---Figure">
					<img src="Images/Figure_8.7_B16483.jpg" alt="Figure 8.7 – Looking up the custom metric on Metrics Explorer&#13;&#10;" width="1650" height="727"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.7 – Looking up the custom metric on Metrics Explorer</p>
			<p>A custom check <a id="_idIndexMarker506"/>typically goes through this sequence with varying methods to collect values for the related custom metrics it supports. By default, the check will be run every 15 seconds, and that behavior can be controlled by setting the configuration item <strong class="source-inline">min_collection_interval</strong>.</p>
			<p>Defining metrics with a custom namespace has other advantages also. The custom check will be identified as an <strong class="bold">App</strong> on the host dashboard, as you can see in the following screenshot, where the custom check and the metric it generates are identified using the namespace used:</p>
			<div>
				<div id="_idContainer125" class="IMG---Figure">
					<img src="Images/Figure_8.8_B16483.jpg" alt="Figure 8.8 – Custom check listed as an app&#13;&#10;" width="1253" height="662"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.8 – Custom check listed as an app</p>
			<p>The dashboard <a id="_idIndexMarker507"/>also tracks the NGINX integration as one of the apps on the host dashboard.</p>
			<p>Now let's look at the best practices related to the topics that w<a id="_idTextAnchor257"/>e have covered in this chapter in the following section.</p>
			<h1 id="_idParaDest-148"><a id="_idTextAnchor258"/>Best practices</h1>
			<p>Between the Datadog-provided integrations and the hooks it provides to roll out your own custom integrations, there are many options available to you and so it's better to follow the best practices instead of implementing something that works but is suboptimal:</p>
			<ul>
				<li>Explore all the Datadog-provided integrations fully and check whether you could meet the monitoring requirements using those. Custom code and configurations are costly to develop, error-prone, and hard to deploy and maintain, in the context of monitoring, and you should consider writing custom code as the last resort.</li>
				<li>If Datadog-supported integrations are not readily available, check in the big collection of community-maintained integrations.</li>
				<li>If you need to tweak a community-maintained integration to get it working for you, consider collaborating on that project and commit the changes publicly, as that will help to obtain useful feedback from the Datadog community.</li>
				<li>Come up with a strategy for naming tags and custom metrics before you start using them with integrations. Systematic naming of metrics with appropriate namespaces will help to organize and aggregate them easily.</li>
				<li>Maintain the custom code and configurations used for enabling and implementing integrations in the source code control system as a backup and, optionally, use that as the source for automated provisioning of Datadog resources using tools such as Terraform and Ansible. This best practice is not specific to integrations; it has to be followed whenever custom code and configurations are involved in setting up anything.</li>
				<li>In a public cloud environment, the host-level configurations needed for enabling integrations must be baked into the machine image. For example, in AWS, such configurations and custom code, along with the Datadog Agent software, can be rolled <a id="_idTextAnchor259"/>out as part of the related AMI used for spinning a host.</li>
			</ul>
			<h1 id="_idParaDest-149"><a id="_idTextAnchor260"/>Summary</h1>
			<p>We have looked at both Datadog-supplied integrations and the options to implement integrations on your own. A Datadog environment that monitors a large-scale production environment would use a mixed bag of out-of-the-box integrations and custom checks. Though it's easy to roll out custom checks in Datadog, it is advised to look at the total cost of doing so. In this chapter, you have learned how to select the right integrations and how to configure them. Also, you learned how to do custom checks if that is warranted, in the absence of an out-of-the-box integration.</p>
			<p>Continuing with the discussion on extending Datadog beyond the out-of-the-box features available to you, in the next chapter, we will look at how the Datadog API can be used to access Datadog features and use them for implementing custom integrations.</p>
		</div>
	</div></body></html>