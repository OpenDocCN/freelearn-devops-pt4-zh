- en: '*Chapter 8*: Integrating with Platform Components'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We learned about monitors and alerts, key elements of a monitoring infrastructure
    that are central to the 24x7 monitoring of software systems in production, in
    the last chapter. Earlier in the book, we saw how infrastructure resources, the
    basic building blocks of any computational environment that runs a software system,
    are monitored by Datadog.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 1*](B16483_01_Final_VK_ePub.xhtml#_idTextAnchor014), *Introduction
    to Monitoring*, we discussed various types of monitoring and briefly mentioned
    platform monitoring, the monitoring of software and cloud computing components
    that are used to build the computing platform where application software runs.
    In a public cloud environment, there are overlaps between infrastructure and platform
    components because compute, storage, and network components are software-defined
    in those environments, and, for monitoring purposes, they could be treated as
    a platform component such as **MySQL Database** or the **RabbitMQ** messaging
    system.
  prefs: []
  type: TYPE_NORMAL
- en: However, it's not difficult to differentiate infrastructure resources from platform
    components. A cloud platform is essentially a software layer running on top of
    infrastructure resources and applications either run them or use them at runtime.
    Typically, the infrastructure resources are provisioned on the public cloud, and
    the platform components are provided by third-party software vendors or open source
    communities and the applications are built by another company. Please note that
    a popular public cloud provider such as AWS also offers services that can be substituted
    for platform components. Examples on AWS are **Relational Database Service** (**RDS**),
    **Amazon MQ**, and **Elastic Kubernetes Service** (**EKS**).
  prefs: []
  type: TYPE_NORMAL
- en: We learned earlier, in [*Chapter 6*](B16483_06_Final_VK_ePub.xhtml#_idTextAnchor214),
    *Infrastructure Monitoring*, that most of the infrastructure monitoring is covered
    by Datadog out of the box with minimal configuration requirements. While most
    features of infrastructure resources are standard, the same could not be said
    about platform components, which basically are software applications that perform
    a specific set of tasks and the monitoring requirements are feature-dependent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Datadog addresses platform monitoring in two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Shipping integrations with popular platform software components. With these
    integrations available out of the box, the users only need to enable whichever
    integrations are needed for the platform components used in their applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing the option to run custom checks that can be used to monitor platform
    components that may not have integrations readily available out of the box.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about the details of platform monitoring using
    the integration options available in Datadog as outlined above. Specifically,
    we will cover these topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring an integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tagging an integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing supported integrations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing custom checks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To try out the examples mentioned in this book, you need to have the following
    tools installed and resources available:'
  prefs: []
  type: TYPE_NORMAL
- en: '- An Ubuntu 18.04 environment with Bash shell. The examples might work on other
    Linux distributions as well but suitable changes must be done to the Ubuntu specific
    commands.'
  prefs: []
  type: TYPE_NORMAL
- en: '- A Datadog account and a user with admin-level access.'
  prefs: []
  type: TYPE_NORMAL
- en: '- A Datadog Agent running at host level or as a microservice depending on the
    example, pointing to the Datadog account.'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring an integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Datadog provides integration with most of the popular platform components and
    they need to be enabled as needed. We will see the general steps involved in enabling
    integration with an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The available integrations are listed on the **Integrations** dashboard as
    in the following screenshot, and it''s directly accessible from the main menu:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – List of available integrations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.1_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.1 – List of available integrations
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, in *Figure 8.1*, the third-party software components are listed
    on the **Integrations** dashboard. Using the search option available at the top
    of this dashboard, the integrations that are already installed can be filtered
    out. Also, the available integrations can be looked up using keywords.
  prefs: []
  type: TYPE_NORMAL
- en: 'By clicking on a specific integration listing, you can get all the details
    related to that integration. For example, the following screenshot provides such
    details for integration with NGINX, a popular web server:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Overview of NGINX integration'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.2_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 – Overview of NGINX integration
  prefs: []
  type: TYPE_NORMAL
- en: From this dashboard, we can get the complete list of metrics that will be published
    by the integration once that is enabled. Also, this specific integration provides
    a few monitors, which is an optional feature. The main objective of using an integration
    is to get access to the platform's component-related metrics that could be used
    in custom-built monitors, dashboards, and other Datadog resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration of an integration requires two main steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Install integration**: An integration can be installed in your account by
    just clicking on the **Install** button available, as in the following screenshot,
    pertaining to NGINX integration:![Figure 8.3 – Install an integration'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_8.3_B16483.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.3 – Install an integration
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The **Install** button will be displayed when you move the cursor over an available
    integration.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Configure integration**: Configuration of the integration is the main part
    of rolling out an integration in a Datadog account. The steps to do that are provided
    under the **Configuration** tab of the integration (see *Figure 8.2*). These steps
    are platform component dependent and would require changes in the Datadog monitoring
    infrastructure. For example, if the component runs on a host, such as the NGINX
    web server, the changes will be needed in the configuration of the Datadog agent
    running on that host.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now let's see how the NGINX integration is configured to get it enabled for
    a specific NGINX instance and that will demonstrate the general steps involved
    in configuring any integration.
  prefs: []
  type: TYPE_NORMAL
- en: The first step is to enable the integration in your account and that can be
    accomplished by just clicking the **Install** button on the integration listing
    as you can see in *Figure 8.3*.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the sample case here, we will try to enable the integration for an open
    source version of an NGINX instance running on an **AWS EC2** host that runs on
    the Linux distribution **Ubuntu 16.04**. Note that the actual configuration steps
    would also differ depending on the operating system where the platform component
    and Datadog agent run, and these steps are specific to the environment described
    previously:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make sure that both the Datadog Agent and NGINX services are running on the
    host. This could be checked as follows on Ubuntu 16.04:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will see a status similar to the following if the service runs OK:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*(Only the line corresponding to service status is provided here for brevity.)*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let's do the configuration changes needed on the NGINX side first.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Check if the stub status module is installed with the NGINX instance that is
    needed for the integration to work:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Under the NGINX configuration directory `/etc/nginx/conf.d/`, create a new
    file, `status.conf`, and add the following configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reload the configuration change in NGINX:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To complete the configuration changes, they must be done on the Datadog Agent
    side also. Let''s do that next. For each integration supported by Datadog, a configuration
    directory is available under `/etc/datadog-agent/conf.d/`. For NGINX integration,
    it''s `nginx.d`. Usually, a sample configuration file is available in this directory
    that can be customized for your specific requirements. To keep it simple, we will
    make a copy of the sample file that already contains the basic configuration needed
    for getting this integration working, and then restart Datadog Agent:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To check if the integration works correctly, you can look at the related information
    in the Datadog Agent status:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*(The preceding output is only an excerpt related to NGINX integration status.)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'When the configurations on the host are done and we''ve checked that it''s
    working successfully, we can expect to see the related NGINX metrics to be available
    on the Datadog UI for use in monitors and dashboards. The easiest way to verify
    that is to search for some sample metrics on the `nginx.net.connections` is looked
    up and located successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Figure_8.4_B16483.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – NGINX metrics in Metrics Explorer
  prefs: []
  type: TYPE_NORMAL
- en: This way, any metric supported by the integration, as documented under the **Metrics**
    tab on the dashboard for the integration, can be looked up. If you are looking
    for metrics published from a specific host to verify a new rollout of the integration
    for that host, the metrics listing could be filtered down by selecting the specific
    host in the **Over** field as shown in the preceding screenshot.
  prefs: []
  type: TYPE_NORMAL
- en: We just looked at the generic steps of rolling out an agent-based integration
    and how to verify whether that is working. In a real-life production environment,
    there would be multiple such integrations enabled for many platform components
    such as NGINX. Even the same component could be used for multiple purposes. For
    example, NGINX could be used as an HTTP server serving a simple web application
    or as a proxy server directing web traffic to more complex computing environments
    such as a cluster of hosts running JVM or a Kubernetes cluster. In such cases,
    there must be some means to differentiate the source of metrics easily without
    depending on the hostnames, as the life of a host in a public cloud environment
    is not long-term. We already saw in [*Chapter 5*](B16483_05_Final_VK_ePub.xhtml#_idTextAnchor178),
    *Metrics, Events, and Tags*, how metrics are tagged to facilitate filtering and
    aggregation. We will revisit that in the next section in the context of rolling
    out an integration.
  prefs: []
  type: TYPE_NORMAL
- en: Tagging an integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The metrics published by an integration can be tagged at the integration level
    for better visibility with Datadog resources where those metrics will be used
    eventually. We will see how that's done with the intention of implementing the
    best practices for effectiveness. We already learned in [*Chapter 2*](B16483_02_Final_VK_ePub.xhtml#_idTextAnchor115),
    *Deploying Datadog Agent*, and, in [*Chapter 5*](B16483_05_Final_VK_ePub.xhtml#_idTextAnchor178),
    *Metrics, Events, and Tags*, that host-level, custom tags can be added by using
    the tags configuration item in the `datadog.yaml` file. Custom tags added using
    this option will be available on all the metrics generated by various integrations
    running on that host. The tagging option is available at the integration level
    also, and the related tags will be applied only on the integration-specific metrics.
  prefs: []
  type: TYPE_NORMAL
- en: In the use case that was mentioned in the previous section related to using
    NGINX for different roles, this multi-level tagging method will be useful to filter
    the NGINX metrics originating from multiple hosts. For example, at the host level,
    it can be identified as a web server or proxy server with the tag `role:proxy-server`
    or `role:web-server`, and at the integration level, more tags can be applied indicating
    the specific name of the component with the tag `component:nginx`. Note that this
    approach provides the flexibility to track the role of platform components such
    as **HAProxy**, NGINX, and **Apache** that could be used for a variety of HTTP
    and proxy serving roles in the entire application system.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's see how this tagging strategy we just discussed could be implemented
    in the sample case from the last section.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `datadog.yaml` file, the following tag is added:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `conf.d/nginx.d/conf.yaml` file, the following two tags are added:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Note that the additional tag `nginx-version` will help to identify what kind
    of NGINX is used. To start applying these tags to the metrics, the Datadog Agent
    has to be restarted. After that, you can filter the metrics using these tags as
    in the following examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the first example, as shown in the following screenshot in *Figure 8.5*,
    you can see that an integration metric, `nginx.net.connections`, is tagged with
    a host-level tag, `proxy-server`. Note that all the host-level metrics and the
    metrics from other integrations will also be tagged in the same fashion. For example,
    the system-level metric `system.mem.used` will also be tagged with `role:proxy-server`
    once that is enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Host-level tag applied on an integration metric'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.5_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.5 – Host-level tag applied on an integration metric
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next example, shown in *Figure 8.6*, the integration-level tags, `component:nginx`
    and `nginx-version:open-source`, are available only for filtering integration-level
    metrics. You cannot filter a host-level metric like `system.mem.used` using those
    tags:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Integration-level tag'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.6_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.6 – Integration-level tag
  prefs: []
  type: TYPE_NORMAL
- en: In the last two sections, we have learned the basics of how to enable an integration
    and how to tag the metrics published by an integration. With that basic understanding,
    we will dig deeper into the broader picture of the Datadog support for third-party
    applications and how they are integrated and organized. We will also look at some
    of the important integrations that we will see ourselves using most of the time
    with Datadog as they are the common platform components used to build a variety
    of software application systems.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing supported integrations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It has been already mentioned that Datadog provides integrations for a lot of
    third-party platform components. Some of them, such as Apache, NGINX, Docker,
    MySQL, and the like, are more important than the rest because of their ubiquitous
    use across a variety of software applications. In this section, we will look at
    the important integrations and call out points of any importance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Datadog provides three different options for integrating platform components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Agent-based**: In the example we saw earlier in this chapter, the Datadog
    Agent configuration had to be updated to enable the integration. That is required
    because the platform component, NGINX in the example, runs on a host. It could
    be run as a microservice also and yet an agent is needed to monitor that environment.
    Essentially, the integration in that case is managed by the local agent. The Datadog
    Agent is shipped with official integrations and they are readily available as
    we saw in the example on NGINX. There are more integrations available that are
    community-built and they can be checked out at [https://github.com/DataDog/integrations-extras](https://github.com/DataDog/integrations-extras)
    on GitHub. Each integration is documented in its own README file there.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Crawler-based**: A software platform is not always built using components
    running only locally. Some services could be cloud-based and Datadog provides
    integrations with popular services such as GitHub, **Slack**, and **PagerDuty**.
    In such cases, credentials to access those service accounts are provided to Datadog
    and it will crawl the account to report metrics related to the given service account.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Custom integration**: Custom integration options are extensive with Datadog
    and they are general-purpose in nature and not specific to integrating platform
    components. The option to run custom checks from a Datadog Agent is the easiest
    option available to integrate a platform component for which official support
    is not available or adequate. We will see how that could be implemented in a sample
    later in this section. The following are the other options that can be used for
    rolling out a custom integration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use the Datadog API**: One of the major attractions of using Datadog for
    monitoring is its extensive REST API support. While you need a skilled team to
    roll out integrations using the Datadog API, having that option makes your monitoring
    infrastructure extensible and flexible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Build your own integration**: Datadog provides a developer toolkit to build
    your own integration following the Datadog norms. The details can be checked out
    at [https://docs.datadoghq.com/developers/integrations/new_check_howto](https://docs.datadoghq.com/developers/integrations/new_check_howto).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Publish metrics using StatsD**: We will look at this generic integration
    option in detail in [*Chapter 10*](B16483_10_Final_VK_ePub.xhtml#_idTextAnchor302),
    *Working with Monitoring Standards*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now let''s look at some of the important integrations that are shipped with
    the Datadog Agent and available for users to enable and use:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Integrations with the public cloud**: Datadog supports integrations with
    major public cloud platforms such as **AWS**, **Azure**, and **GCP** and the individual
    services offered on those platforms. These crawler-based integrations require
    access to your public cloud account and that can be provided in different ways.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Microservices resources**: Both **Docker** and **Kubernetes** are key components
    in building a microservices infrastructure. Integrations for both these platform
    components and related products are supported by Datadog.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Proxy and HTTP services**: Apache, **Tomcat**, NGINX, HAProxy, **Microsoft
    IIS**, and **Memcached** are popular in this category and integrations are available
    for these components.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Messaging services**: Popular messaging software and cloud services such
    as RabbitMQ, IBM MQ, Apache Active MQ, and Amazon MQ are supported.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RDBMS**: Almost every popular **Relational Database Management System** (**RDBMS**),
    such as **Oracle**, **SQL Server**, **MySQL**, **PostgreSQL**, and **IBM DB2**,
    is supported. Monitoring databases is an important requirement as databases are
    central to many software applications. These integrations supply a variety of
    metrics that could be used to monitor the workings and performance of databases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NoSQL and Big Data**: NoSQL databases are widely used in big data and cloud-based
    applications due to their flexibility and scalability. Popular software such as
    **Redis**, **Couchbase**, **Cassandra**, **MongoDB**, **Hadoop**, and related
    products from this category are supported by Datadog.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring tools**: It''s common to have multiple monitoring tools in use
    as part of rolling out a comprehensive monitoring solution for a target environment.
    In such a scenario, Datadog will be one of the services in the mix, and it''s
    a good platform to aggregate inputs from other monitoring systems due to its superior
    UI and dashboarding features. Datadog also provides integrations with other monitoring
    tools to facilitate that consolidation. Currently, integrations for monitoring
    applications such as **Catchpoint**, **Elasticsearch**, **Nagios**, **New Relic**,
    **Pingdom**, **Prometheus**, **Splunk**, and **Sumo Logic** are available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the Datadog-supplied integrations don't meet an important custom requirement,
    you can extend Datadog to cover that by implementing a custom check. In the next
    section, you will learn how to implement a sample custom check using a simple
    Python script that publishes a custom metric.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing custom checks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Custom checks can be used to monitor a platform component if the available integration
    features are not adequate or an integration doesn't exist at all for that component.
    The Datadog API could be used as well in reporting custom-generated metrics to
    Datadog. We will explore this option with an example.
  prefs: []
  type: TYPE_NORMAL
- en: The process involved in implementing a check that publishes custom metrics is
    simple in Datadog and we can learn about that from the following example.
  prefs: []
  type: TYPE_NORMAL
- en: Continuing with the example of NGINX from the previous sections in this chapter,
    we will try to extend that integration by adding a custom metric to Datadog. This
    custom metric, `kurian.nginx.error_log.size`, tracks the size of the NGINX error
    log file. It's better to begin the metric name with a namespace specific to your
    company or department, as the metric is labeled in this example, to filter custom
    metrics easily.
  prefs: []
  type: TYPE_NORMAL
- en: Manually, the file size information could be gathered by running the command
    `ls -al` on any UNIX-compatible shell. The same command could be run from the
    Datadog custom check also and the output can be parsed to obtain the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s call this custom check `custom_nginx`. The configuration steps largely
    follow those we did for enabling the NGINX integration earlier. In this case,
    the configuration directory and related resources have to be created:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a configuration directory and set up a configuration file for the check:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `custom_nginx.yaml` file in the new directory and save the following
    string in it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install the Python script in `/etc/datadog-agent/checks.d`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Save the following script as `custom_nginx.py`. Note that the naming convention
    matters as that''s how the Datadog Agent relates the custom check to the script:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Besides the template requirements of the script, it does the following tasks:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A. Runs the `ls -al` command on the `/var/log/nginx/error.log` file
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Parses the file size from the command output
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Reports the file size as a metric value to Datadog with the `component:nginx`
    tag applied
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Restart the Datadog Agent to enable the custom check. To check if it runs successfully,
    you can run the `status check` command and look for the status related to the
    custom check:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once you have verified the working of the custom check on the server side,
    you can expect the custom metric to be available on the Datadog UI, and it can
    be verified as in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Looking up the custom metric on Metrics Explorer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.7_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.7 – Looking up the custom metric on Metrics Explorer
  prefs: []
  type: TYPE_NORMAL
- en: A custom check typically goes through this sequence with varying methods to
    collect values for the related custom metrics it supports. By default, the check
    will be run every 15 seconds, and that behavior can be controlled by setting the
    configuration item `min_collection_interval`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Defining metrics with a custom namespace has other advantages also. The custom
    check will be identified as an **App** on the host dashboard, as you can see in
    the following screenshot, where the custom check and the metric it generates are
    identified using the namespace used:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8 – Custom check listed as an app'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.8_B16483.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.8 – Custom check listed as an app
  prefs: []
  type: TYPE_NORMAL
- en: The dashboard also tracks the NGINX integration as one of the apps on the host
    dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's look at the best practices related to the topics that we have covered
    in this chapter in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Between the Datadog-provided integrations and the hooks it provides to roll
    out your own custom integrations, there are many options available to you and
    so it''s better to follow the best practices instead of implementing something
    that works but is suboptimal:'
  prefs: []
  type: TYPE_NORMAL
- en: Explore all the Datadog-provided integrations fully and check whether you could
    meet the monitoring requirements using those. Custom code and configurations are
    costly to develop, error-prone, and hard to deploy and maintain, in the context
    of monitoring, and you should consider writing custom code as the last resort.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If Datadog-supported integrations are not readily available, check in the big
    collection of community-maintained integrations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you need to tweak a community-maintained integration to get it working for
    you, consider collaborating on that project and commit the changes publicly, as
    that will help to obtain useful feedback from the Datadog community.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Come up with a strategy for naming tags and custom metrics before you start
    using them with integrations. Systematic naming of metrics with appropriate namespaces
    will help to organize and aggregate them easily.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintain the custom code and configurations used for enabling and implementing
    integrations in the source code control system as a backup and, optionally, use
    that as the source for automated provisioning of Datadog resources using tools
    such as Terraform and Ansible. This best practice is not specific to integrations;
    it has to be followed whenever custom code and configurations are involved in
    setting up anything.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a public cloud environment, the host-level configurations needed for enabling
    integrations must be baked into the machine image. For example, in AWS, such configurations
    and custom code, along with the Datadog Agent software, can be rolled out as part
    of the related AMI used for spinning a host.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have looked at both Datadog-supplied integrations and the options to implement
    integrations on your own. A Datadog environment that monitors a large-scale production
    environment would use a mixed bag of out-of-the-box integrations and custom checks.
    Though it's easy to roll out custom checks in Datadog, it is advised to look at
    the total cost of doing so. In this chapter, you have learned how to select the
    right integrations and how to configure them. Also, you learned how to do custom
    checks if that is warranted, in the absence of an out-of-the-box integration.
  prefs: []
  type: TYPE_NORMAL
- en: Continuing with the discussion on extending Datadog beyond the out-of-the-box
    features available to you, in the next chapter, we will look at how the Datadog
    API can be used to access Datadog features and use them for implementing custom
    integrations.
  prefs: []
  type: TYPE_NORMAL
