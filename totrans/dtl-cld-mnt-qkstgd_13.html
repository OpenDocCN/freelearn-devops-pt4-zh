<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer144">
			<h1 id="_idParaDest-183"><em class="italic"><a id="_idTextAnchor323"/>Chapter 11</em>: Integrating with Datadog</h1>
			<p><a id="_idTextAnchor324"/>In the previous chapter, you learned about some of the important monitoring standards and how they are implemented in Datadog, with the objective of extending the features of the Datadog monitoring platform. So far, in this part of the book, we have been looking only at extending the monitoring capabilities of an organization focused on Datadog. The integration with Datadog can happen both ways – in addition to populating Datadog with monitoring related data for use with various Datadog features, the information available in Datadog could be utilized by other internal applications also.</p>
			<p><a id="_idTextAnchor325"/><a id="_idTextAnchor326"/>To roll out such general-purpose integrations between applications, a rich set of APIs should be available. We have already seen that the Datadog REST API is a comprehensive programming interface that other applications can use to access the Datadog platform to publish and extract information. We have also looked at DogStatsD as one of the methods to publish information to the Datadog platform, and we will learn more about how that interface can be used from other applications. We will also review other methods, which are mainly community-based efforts that are not officially shipped with the Datadog product suite but are very useful in rolling out custom integrations.</p>
			<p><a id="_idTextAnchor327"/><a id="_idTextAnchor328"/>In this chapter, you will learn about the commonly used libraries for Datadog integration and cover these topics specifically:</p>
			<ul>
				<li><a id="_idTextAnchor329"/>Using client libraries</li>
				<li><a id="_idTextAnchor330"/>Evaluating community projects</li>
				<li>Developing integrations</li>
			</ul>
			<h1 id="_idParaDest-184"><a id="_idTextAnchor331"/>Technical requirements</h1>
			<p>To implement the examples given in this chapter, you need to have an environment with the following tools installed:</p>
			<ul>
				<li>The Datadog Agent</li>
				<li><strong class="bold">Python 3.8</strong> or higher and <strong class="source-inline">pip3</strong></li>
				<li><strong class="bold">Python 2.7</strong> (optional)</li>
				<li>The Datadog developer toolkit</li>
				<li>A Git client</li>
			</ul>
			<h1 id="_idParaDest-185"><a id="_idTextAnchor332"/>Using client libraries</h1>
			<p><a id="_idTextAnchor333"/>In this section, we will look at <a id="_idIndexMarker611"/>two different client libraries – the first group consists of libraries that are wrappers for the Datadog REST API, and the second group of libraries are <a id="_idIndexMarker612"/>native <strong class="bold">DogStatsD</strong> client libraries. Both these groups of libraries are available for popular programming languages such as <strong class="bold">C++</strong>, <strong class="bold">Java</strong>, <strong class="bold">Python</strong>, <strong class="bold">Java</strong>, and <strong class="bold">Go</strong>.<a id="_idTextAnchor334"/><a id="_idTextAnchor335"/> </p>
			<p>Datadog provides both categories of libraries for most programming languages. While a lot of community libraries are listed on the official Datadog website, we will only look at those that are actively maintained.<a id="_idTextAnchor336"/> </p>
			<h2 id="_idParaDest-186"><a id="_idTextAnchor337"/>REST API-based client libraries</h2>
			<p>The basic Datadog client library is the <a id="_idIndexMarker613"/>REST API set, and the programming language-specific libraries are essentially wrappers on top of the <a id="_idIndexMarker614"/>REST APIs that facilitate the usage of APIs. In this section, we will look at some of the important client libraries specific to programming languages, and wherever relevant, we will look at sample code al<a id="_idTextAnchor338"/>so.</p>
			<h3>The Datadog Python library</h3>
			<p>We have already <a id="_idIndexMarker615"/>seen this library in action earlier in the sample programs in <a href="B16483_09_Final_VK_ePub.xhtml#_idTextAnchor261"><em class="italic">Chapter 9</em></a><em class="italic">, Using the Datadog API</em>. This official library <a id="_idIndexMarker616"/>supports both REST APIs and DogStatsD to interact with Datadog programmatically.</p>
			<p>The library can be installed into your Python environment using the Python installation tool <strong class="source-inline">pip</strong> as follows:</p>
			<p class="source-code">$ pip install datadog</p>
			<p>The code is available on GitHub at <a href="https://github.com/DataDog/datadogpy">https://github.com/DataDog/datadogpy</a> and the library can be installed from the <a id="_idIndexMarker617"/>source code as well. To do that, clone the code repository to your local environment and run the setup program as follows:</p>
			<p class="source-code">$ git clone https://github.com/DataDog/datadogpy.git</p>
			<p class="source-code">$ cd datadogpy</p>
			<p class="source-code">$ python setup.py install</p>
			<p>Once installed, the <a id="_idIndexMarker618"/>REST API-specific calls can be done from the program by importing the <strong class="source-inline">API</strong> module, and the DogStatsD specific calls can be done by importing the <strong class="source-inline">statsd</strong> module into the Python envir<a id="_idTextAnchor339"/>onment.</p>
			<h3>The Python API client for Datadog</h3>
			<p>This is an official <a id="_idIndexMarker619"/>Python library that maps to a <a id="_idIndexMarker620"/>collection of all public Datadog REST APIs. On GitHub, it is <a id="_idIndexMarker621"/>available at <a href="https://github.com/DataDog/datadog-api-client-python">https://github.com/DataDog/datadog-api-client-python</a>. Using <strong class="source-inline">pip</strong>, this library can be installed in a compatible Python environment as follows:</p>
			<p class="source-code">$ pip3 install datadog-api-client</p>
			<p>As of now, it is compatible only with <strong class="bold">Python 3.6</strong> <a id="_idTextAnchor340"/>and above.</p>
			<h3>The Java client for Datadog</h3>
			<p>When it comes to <a id="_idIndexMarker622"/>developing enterprise applications, Java is one of the most popular programming languages. Therefore, if a <a id="_idIndexMarker623"/>Java application needs to be integrated directly with Datadog, this official Java client library, which is a wrapper for the core Datadog REST API, is the default choice.</p>
			<p>The code repository <a id="_idIndexMarker624"/>related to this client library is available on GitHub at <a href="https://github.com/DataDog/datadog-api-client-java">https://github.com/DataDog/datadog-api-client-java</a>. Review the documentation available there to understand how this Java library can be built and installed in Java development <a id="_idIndexMarker625"/>environments using build tools <a id="_idIndexMarker626"/>such as <strong class="bold">Ma<a id="_idTextAnchor341"/>ven</strong> and <strong class="bold">Gradle</strong>.</p>
			<h3>The Go API client for Datadog</h3>
			<p>Go is a modern, compiled language <a id="_idIndexMarker627"/>that is fast but has the <a id="_idIndexMarker628"/>flexibility of an interpreted language such as Python. While it's a general-purpose programming language, it has been popular with systems programming and is used for <a id="_idIndexMarker629"/>building <strong class="bold">Command-Line Interface</strong> (<strong class="bold">CLI</strong>) tools in the DevOps space. For example, part of the latest version of the Datadog Agent itself is developed in Go.</p>
			<p>The officially supported Go client library for the <a id="_idIndexMarker630"/>Datadog REST API is maintained on GitHub at <a href="https://github.com/DataDog/datadog-api-client-go">https://github.com/DataDog/datadog-api-client-go</a>. The details of building and installing the library are available at<a id="_idTextAnchor342"/> the same location.</p>
			<h3>The Node.js client for Datadog</h3>
			<p>The Node.js platform is for <a id="_idIndexMarker631"/>running JavaScript on the server side, and it has been popular for developing web browser-based <a id="_idIndexMarker632"/>user interfaces. Datadog doesn't have an official client library to support this platform, and the <strong class="source-inline">node-dogapi</strong> code repository by <em class="italic">Brett Langdon</em> that is available on GitHub at <a href="https://github.com/brettlangdon/node-dogapi">https://github.com/brettlangdon/node-dogapi</a> could be <a id="_idIndexMarker633"/>used instead. The code base has not been updated recently and its compatibility with the Datadog API has to be verified <a id="_idTextAnchor343"/>for the intended uses.</p>
			<h3>WebService-DataDog – a Perl client</h3>
			<p>Before the <a id="_idIndexMarker634"/>widespread use of Python, <strong class="bold">Perl</strong> used to be the default scripting language for building systems tools, especially <a id="_idIndexMarker635"/>where the processing of logs and textual data was concerned. This Perl client library, maintained by <a id="_idIndexMarker636"/>Jennifer Pinkham, has not been updated recently, yet it's worth it for Perl enthusiasts to try out. The code repository is <a id="_idIndexMarker637"/>available on GitHub at <a href="https://github.com/jpinkham/webservice-datadog">https://github.com/jpinkham/webservice-datadog</a>, with steps on how to instal<a id="_idTextAnchor344"/>l the related Perl module.</p>
			<h3>Ruby client for Datadog API</h3>
			<p><strong class="bold">Ruby</strong> is a <a id="_idIndexMarker638"/>scripting language <a id="_idIndexMarker639"/>mostly used for <a id="_idIndexMarker640"/>building web applications, especially with the <a id="_idIndexMarker641"/>development framework <strong class="bold">Ruby on Rails</strong>. However, it's a general-purpose programming language like Python, PHP, and Perl. Datadog has an official client library for Ruby that is an abstraction on top of the Datadog REST API.</p>
			<p>The code repository is <a id="_idIndexMarker642"/>available at <a href="https://github.com/DataDog/dogapi-rb">https://github.com/DataDog/dogapi-rb</a> with steps for installing the library and code <a id="_idIndexMarker643"/>samples for how<a id="_idTextAnchor345"/> to use the Datadog API in Ruby.</p>
			<h2 id="_idParaDest-187"><a id="_idTextAnchor346"/>DogStatsD client libraries</h2>
			<p>As mentioned in <a href="B16483_10_Final_VK_ePub.xhtml#_idTextAnchor302"><em class="italic">Chapter 10</em></a>, <em class="italic">Working with Monitoring Standards</em>, DogStatsD is an implementation of the <a id="_idIndexMarker644"/>monitoring standard StatsD. Therefore, a general-purpose implementation of StatsD would work with the DogStatsD interface <a id="_idIndexMarker645"/>provided by the Datadog Agent. The community-based libraries reviewed here take advantage of that feature and thus provide a wrapper for <a id="_idTextAnchor347"/>the targeted programming language.</p>
			<h3>The C++ DataDog StatsD client</h3>
			<p>Using this library, metrics and events can be <a id="_idIndexMarker646"/>published into the <a id="_idIndexMarker647"/>Datadog backend via the StatsD interface. The code <a id="_idIndexMarker648"/>base is available at <a href="https://github.com/BoardiesITSolutions/cpp-datadogstatsd">https://github.com/BoardiesITSolutions/cpp-datadogstatsd</a> on GitHub.</p>
			<p>The code can be built into a shared library for the target operating system, typically a Linux distribution. Some Windows platforms are also supported. The custom application that needs to publish metrics data and events can be dynam<a id="_idTextAnchor348"/>ically linked to this shared library.</p>
			<h3>The Java DogStatsD client</h3>
			<p>For <strong class="bold">Java</strong>, Datadog provides an <a id="_idIndexMarker649"/>official DogStatsD client library and it's available at <a href="https://github.com/DataDog/java-dogstatsd-client">https://github.com/DataDog/java-dogstatsd-client</a> on <a id="_idIndexMarker650"/>GitHub. It supports more features than a standard StatsD library that is <a id="_idIndexMarker651"/>limited to publishing metrics data. Using the Java DogStatsD client, you can also maintain events and service checks.</p>
			<p>A specific version of the client JAR file could be imported into your project using Maven, through a configuration setting as given in the following example:</p>
			<p class="source-code">&lt;dependency&gt;</p>
			<p class="source-code">    &lt;groupId&gt;com.datadoghq&lt;/groupId&gt;</p>
			<p class="source-code">    &lt;artifactId&gt;java-dogstatsd-client&lt;/artifactId&gt;</p>
			<p class="source-code">    &lt;version&gt;2.11.0&lt;/version&gt;</p>
			<p class="source-code">&lt;/dependency&gt;</p>
			<p>The StatsD APIs can be called from the Java application and can be built once the preceding conf<a id="_idTextAnchor349"/>iguration is added to the Maven setting.</p>
			<h3>The DogStatsD client for C#</h3>
			<p><strong class="bold">C#</strong> is a general-purpose <a id="_idIndexMarker652"/>programming language like Java and <strong class="bold">C++</strong> and it is part of the <strong class="bold">.NET</strong> application development framework originally promoted by Microsoft. It is supported on Windows <a id="_idIndexMarker653"/>platforms and multiple distributions of Linux. This library is maintained by Datadog and its source code <a id="_idIndexMarker654"/>repository is available on GitHub at <a href="https://github.com/DataDog/dogstatsd-csharp-client">https://github.com/DataDog/dogstatsd-csharp-client</a>.</p>
			<p>This popular client library could be installed using the <a id="_idIndexMarker655"/>packages available at <strong class="bold">NuGet</strong> or using the source available on GitHub. As with the rest of the official DogStatsD client libraries, support is available for events and service checks in addition to the standard support for metrics. The details of installation and library usage are a<a id="_idTextAnchor350"/>vailable with the code repository on GitHub.</p>
			<h3>datadog-go </h3>
			<p><strong class="bold">datadog-go</strong> is a DogStatsD client library for the <a id="_idIndexMarker656"/>Go programming language and it is <a id="_idIndexMarker657"/>maintained by Datadog at <a href="https://github.com/DataDog/datadog-go">https://github.com/DataDog/datadog-go</a> on GitHub. As with other official DogStatsD client libraries, this also supports events and service checks in addition to metrics.</p>
			<p>The library <a id="_idIndexMarker658"/>officially supports <strong class="bold">Go</strong> versions <strong class="bold">1.12</strong> and above. The details of the installation and usage of the library <a id="_idTextAnchor351"/>are available in the code repository on GitHub.</p>
			<h3>dogstatsd-ruby</h3>
			<p><strong class="bold">dogstatsd-ruby</strong> is a <a id="_idIndexMarker659"/>DogStatsD client library for the <a id="_idIndexMarker660"/>Ruby programming language and it's maintained by <a id="_idIndexMarker661"/>Datadog at <a href="https://github.com/DataDog/dogstatsd-ruby">https://github.com/DataDog/dogstatsd-ruby</a> on GitHub. As with other official DogStatsD client libraries, this also supports events and service checks in addition to metrics.</p>
			<p>The details of the installation and usage of the library are available with the code repository on GitHub. Full API documentation is available at <a href="https://www.rubydoc.info/github/DataDog/dogstatsd-ruby/master/Datadog/Statsd">https://www.rubydoc.info/gi<span id="_idTextAnchor352"/>thub/DataDog/dogstatsd-ruby/master/Datadog/Statsd</a>.</p>
			<h3>Community DogStatsD client libraries</h3>
			<p>While there are DogStatsD client libraries <a id="_idIndexMarker662"/>available for popular programming languages that are maintained by Datadog, as with REST API-based client libraries, community efforts have been active to support other languages such as Node.js and Perl. In general, the community-based libraries are wrappers over the general-purpose StatsD libraries and they support only metrics. The following are some of the notable libraries:</p>
			<ul>
				<li><strong class="bold">Host-shots client library for Node.js</strong>: This is <a id="_idIndexMarker663"/>available at <a href="https://github.com/brightcove/hot-shots">https://github.com/brightcove/hot-shots</a> on <a id="_idIndexMarker664"/>GitHub. It's a <a id="_idIndexMarker665"/>general-purpose client library that supports other monitoring tools that provide a StatsD interface.</li>
				<li><strong class="bold">NodeDogStatsD</strong>: This is another <a id="_idIndexMarker666"/>Node.js client library and the <a id="_idIndexMarker667"/>code repository and documentation are <a id="_idIndexMarker668"/>available at <a href="https://github.com/mrbar42/node-dogstatsd">https://github.com/mrbar42/node-dogstatsd</a> on GitHub.</li>
				<li><strong class="bold">DataDog DogStatsD – A Perl module for DogStatsd</strong>: Using this module, metrics <a id="_idIndexMarker669"/>data can be <a id="_idIndexMarker670"/>published to Datadog from Perl programs. The code and documentation are <a id="_idIndexMarker671"/>available at <a href="https://github.com/binary-com/dogstatsd-perl">https://github.com/binary-com/dogstatsd-perl</a> on GitHub.</li>
			</ul>
			<p>For a complete and up-to-date list of client libraries, check out the official compilation at <a href="https://docs.datadoghq.com/developers/libraries/">https://docs.datadoghq.com/developers/libraries/</a>.</p>
			<p>In this section, you have become familiar with two groups of client libraries that could be used with major programming languages to access Datadog resources. Those client libraries are useful in building Datadog-specific features from a program or a script from the ground up, as part of integrating with the Datadog SaaS backend. In the next section, we will look at some of the tools that provide either well-integrat<a id="_idTextAnchor353"/>ed features or building blocks to develop such integrations.</p>
			<h1 id="_idParaDest-188"><a id="_idTextAnchor354"/>Evaluating community projects</h1>
			<p>There are tools developed by <a id="_idIndexMarker672"/>other companies and community groups that make your life easier with Datadog-related integration and automation. In this section, we will look at some o<a id="_idTextAnchor355"/>f the useful tools and frameworks available in that category.</p>
			<h2 id="_idParaDest-189"><a id="_idTextAnchor356"/>dog-watcher by Brightcove</h2>
			<p>In a large-scale environment with <a id="_idIndexMarker673"/>several dashboards and monitors <a id="_idIndexMarker674"/>built on Datadog for operational use, maintaining them could quickly become a major chore. This Node.js utility can be used to take backup of Datadog dashboards and monitors in JSON format and save it into a Git repository. Such backups are also very useful in recreating similar resources in the same account or elsewhere.</p>
			<p>The utility needs to be <a id="_idIndexMarker675"/>run as a Node.js service. The code and the details of <a id="_idIndexMarker676"/>configuring it to run are <a id="_idIndexMarker677"/>available on GitHub at <a href="https://github.com/brightcove/dog-watcher">https://github.com/brightcove/dog-watcher</a>. It could be scheduled to take periodic backups or take backups as and when there would<a id="_idTextAnchor357"/> be changes to the Datadog resources being tracked for backing up.</p>
			<h2 id="_idParaDest-190"><a id="_idTextAnchor358"/>kennel </h2>
			<p><strong class="bold">kennel</strong> is a utility <a id="_idIndexMarker678"/>developed in Ruby that can be <a id="_idIndexMarker679"/>used to manage <a id="_idIndexMarker680"/>Datadog monitors, dashboards, and <strong class="bold">Service Level Objects </strong>(<strong class="bold">SLOs</strong>) as code. Managing all kinds of infrastructure resources as code is a DevOps tenet and this tool is useful in implementing that. The code and detailed documentation on the <a id="_idTextAnchor359"/>utility are available on <a id="_idIndexMarker681"/>GitHub at <a href="https://github.com/grosser/kennel">https://github.com/grosser/kennel</a>.</p>
			<h2 id="_idParaDest-191"><a id="_idTextAnchor360"/>Managing monitors using Terraform</h2>
			<p><strong class="bold">Terraform</strong> is a general-purpose tool to <a id="_idIndexMarker682"/>stand up and maintain <strong class="bold">infrastructure as code</strong> (<strong class="bold">IaC</strong>). It can be used to manage <a id="_idIndexMarker683"/>Datadog monitors by <a id="_idIndexMarker684"/>defining the monitors in a <a id="_idIndexMarker685"/>Terraform configuration language.</p>
			<p>Terraform maintains the state of a resource it manages by bringing the current status of the resource to match with its definition in the code. If the resource doesn't exist, it will be created.</p>
			<p>A variety of Datadog resources and integrations can be managed using Terraform, and some of the important ones are the following:</p>
			<ul>
				<li>Users</li>
				<li>Roles</li>
				<li>Metrics</li>
				<li>Monitors</li>
				<li>Dashboards</li>
				<li>Downtimes</li>
				<li>Integrations with <a id="_idIndexMarker686"/>public <a id="_idIndexMarker687"/>cloud <a id="_idIndexMarker688"/>platforms</li>
			</ul>
			<p>The standard Terraform documentation about <a id="_idIndexMarker689"/>these resources is ava<a id="_idTextAnchor361"/>ilable at <a href="https://registry.terraform.io/providers/DataDog/datadog/latest/docs">https://registry.terraform.io/providers/DataDog/datadog/latest/docs</a>.</p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor362"/>Ansible modules and integration</h2>
			<p><strong class="bold">Ansible</strong> is a configuration management <a id="_idIndexMarker690"/>tool that is very popular with DevOps engineers <a id="_idIndexMarker691"/>due to its general-purpose utility in addition to its core configuration management features. When it comes to managing infrastructure, it's very similar to Terraform, with direct support for Datadog resources.</p>
			<p>In general, Ansible provides <a id="_idIndexMarker692"/>modules to support a certain type of <a id="_idIndexMarker693"/>infrastructure resource. Currently, there are Ansible modules available to publish events and manage monitors. Using these modules, Ansible playbooks can be built to manage events and monitors in a Datadog account.</p>
			<p>Datadog ships an official integration for Ansible also. It can be used to track the execution of Ansible playbooks using a callback mechanism. However, this is not very useful in terms of the information published to the Datadog platform.</p>
			<p>Datadog ships integrations for a lot of applications and public cloud platforms and services. It's possible to develop one if one is not available for a third-party tool of your choice or an internal application that needs to be monitored by Datadog. We will lear<a id="_idTextAnchor363"/>n the basics of developing and deploying a custom integration in the next section.</p>
			<h1 id="_idParaDest-193"><a id="_idTextAnchor364"/>Developing integrations</h1>
			<p>In <a href="B16483_08_Final_VK_ePub.xhtml#_idTextAnchor248"><em class="italic">Chapter 8</em></a>, <em class="italic">Integrating with Platforms Components</em>, you learned how to configure an integration. Datadog ships official integrations with a lot of third-party applications that are used to build the <a id="_idIndexMarker694"/>cloud platform where a software application runs. The best thing about using an official integration is that the metrics specific to that integration will be available for use in dashboards, monitors, and other Datadog resources after minimal configuration.</p>
			<p>Datadog lets you build custom integrations that would work exactly like the official ones. It would require DevOps expertise, especially coding skills in Python, and it's not easy to learn the procedure Datadog lays out to build an integration that would be compatible with the Datadog Agent. However, it might make sense to build an integration for the following reasons:</p>
			<ul>
				<li><strong class="bold">Building an integration for an internal application</strong>: Even though it is internally used, the application might be deployed at large scale in production, and a Datadog integration would help to standardize the monitoring requirements of the application.</li>
				<li><strong class="bold">Building an integration for a third-party application</strong>: The monitoring requirement is similar to that of an internal application as described in the last use case, but no official or community-level integration is available yet or the requirements aren't met.</li>
				<li><strong class="bold">Providing monitoring support for an application intended for external use</strong>: You may have an application that is intended for an external audience as third-party software, and providing Datadog with an integration could be part of the monitoring support strategy for that application.</li>
			</ul>
			<p>In this section, you will learn the steps to build an integration from scratch. Building a full-fledged integration is beyond the scope of t<a id="_idTextAnchor365"/>his chapter, but you will learn the general steps to do so with some hands-on work.</p>
			<h2 id="_idParaDest-194"><a id="_idTextAnchor366"/>Prerequisites</h2>
			<p>Some setup is needed in <a id="_idIndexMarker695"/>your local development environment for the integration to be developed, tested, built, packaged, and deployed:</p>
			<ul>
				<li>Python 3.8 and above, and optionally Python 2.7 installed.</li>
				<li>The developer toolkit. This can be installed using the <strong class="source-inline">pip3</strong> utility as follows:<p class="source-code"><strong class="bold">$ pip3 install "datadog-checks-dev[cli]"</strong></p><p>This will install a lot of things in the local Python 3 environment and the output will look like the following if everything goes well:</p><p class="source-code">Successfully installed PyYAML-5.3.1 Pygments-2.8.0 appdirs-1.4.4 atomicwrites-1.4.0 attrs-20.3.0 bcrypt-3.2.0 bleach-3.3.0 cached-property-1.5.2 certifi-2020.12.5 cffi-1.14.5 chardet-4.0.0 colorama-0.4.4 coverage-5.5 cryptography-3.4.6 datadog-checks-dev-9.0.0 distlib-0.3.1 distro-1.5.0 docker-4.4.4 docker-compose-1.28.5 dockerpty-0.4.1 docopt-0.6.2 docutils-0.16 filelock-3.0.12 idna-2.10 in-toto-1.0.1 iniconfig-1.1.1 iso8601-0.1.14 jsonschema-3.2.0 keyring-22.3.0 markdown-3.3.4 mock-4.0.3 packaging-20.9 paramiko-2.7.2 pathspec-0.8.1 pip-tools-5.5.0 pkginfo-1.7.0 pluggy-0.13.1 psutil-5.8.0 py-1.10.0 py-cpuinfo-7.0.0 pycparser-2.20 pygal-2.4.0 pygaljs-1.0.2 pynacl-1.4.0 pyparsing-2.4.7 pyperclip-1.8.2 pyrsistent-0.17.3 pytest-6.2.2 pytest-benchmark-3.2.3 pytest-cov-2.11.1 pytest-mock-3.5.1 python-dateutil-2.8.1 python-dotenv-0.15.0 readme-renderer-29.0 requests-2.25.1 requests-toolbelt-0.9.1 rfc3986-1.4.0 securesystemslib-0.20.0 semver-2.13.0 tenacity-6.3.1 texttable-1.6.3 toml-0.10.2 tox-3.22.0 tqdm-4.58.0 twine-3.3.0 urllib3-1.26.3 virtualenv-20.4.2 webencodings-0.5.1 websocket-client-0.57.0</p></li>
				<li>Docker, to <a id="_idIndexMarker696"/>run unit and integration tests.</li>
				<li>If the integration is to be tested by deploying with a Datadog Agent, have the Agent installed. Note that an integration package can be deployed anywhere, and so the Datadog Agent doesn't have to run locally where the integration is developed and tested for compatibility.</li>
			</ul>
			<p>The commands and output provided here are verified on a Unix-like system such as Linux or Mac. The development could be done on W<a id="_idTextAnchor367"/>indows as well; refer to the official documentation for platform-specific directions.</p>
			<h2 id="_idParaDest-195"><a id="_idTextAnchor368"/>Setting up the tooling</h2>
			<p>The <strong class="source-inline">integrations-extras</strong> code repository <a id="_idIndexMarker697"/>needs to be cloned from GitHub to the local environment to have all the scaffolding in place for developing and building the integration. Follow these steps to set that up:</p>
			<ol>
				<li>Create a directory for the development work in your home directory:<p class="source-code"><strong class="bold">$ mkdir dd</strong></p></li>
				<li>Clone the <strong class="source-inline">integrations-extras</strong> repository:<p class="source-code"><strong class="bold">$ cd dd</strong></p><p class="source-code"><strong class="bold">$ git clone https://github.com/DataDog/integrations-extras.git</strong></p></li>
				<li>Set <strong class="source-inline">integrations-extras</strong> as the default repository:<p class="source-code"><strong class="bold">$ cd integrations-extras</strong></p><p class="source-code"><strong class="bold">$ dd<a id="_idTextAnchor369"/>ev config set repo extras</strong></p></li>
			</ol>
			<p>Next, we will set up a dedicated folder for the integration.</p>
			<h2 id="_idParaDest-196"><a id="_idTextAnchor370"/>Creating an integration folder</h2>
			<p>For the new integration, the <a id="_idIndexMarker698"/>development kit can create the whole directory structure populated with template files. You can try a dry run to see the directory structure and files that would be created.</p>
			<p>For the purpose of describing the steps better, let's assume that you have an application named <em class="italic">CityWeather</em> that supplies a bunch of weather-related information for a specific city at any time of day. The objective of the integration is to get some of that weather info to be published into Datadog.</p>
			<p>The dry run of creating the directory can be done as follows:</p>
			<p class="source-code">$ ddev create -n CityWeather</p>
			<p>The output would show a hierarchical list of directories and files in the scaffolding; for brevity, it is not provided here.</p>
			<p>The directory structure can be created by running the same command without the <strong class="source-inline">-n</strong> option. Though the name used has mixed characters, the top-level directory name will be all lowercase. So, you can change directory into the newly created directory as follows:</p>
			<p class="source-code">$ cd cityweather</p>
			<p>In that directory, you will find these files and directories:</p>
			<ul>
				<li><strong class="source-inline">README.md</strong>: The README file used for documenting the new integration in Git. The template provided has the correct headers and formatting for the documentation to be standard.</li>
				<li><strong class="source-inline">manifest.json</strong>: The manifest describing the integration and file locations.</li>
				<li><strong class="source-inline">tests</strong>: The directory where unit and integration tests will be configured and maintained.</li>
				<li><strong class="source-inline">metadata.csv</strong>: Maintains the list of all collected metrics.</li>
				<li><strong class="source-inline">tox.ini</strong>: Now, <strong class="source-inline">tox</strong> is used to run the tests. Make sure that the Python version specified in this <a id="_idIndexMarker699"/>configuration file used by <strong class="source-inline">tox</strong> matches the Python versions available locally. For example, if Python 2.7 and Python 3.9 are used, the content of this file would look like the following and you would make changes as needed:<p class="source-code"><strong class="bold">[tox]</strong></p><p class="source-code"><strong class="bold">minversion = 2.0</strong></p><p class="source-code"><strong class="bold">skip_missing_interpreters = true</strong></p><p class="source-code"><strong class="bold">basepython = py39</strong></p><p class="source-code"><strong class="bold">envlist = py{27,39}</strong></p><p class="source-code"><strong class="bold">[testenv]</strong></p><p class="source-code"><strong class="bold">ensure_default_envdir = true</strong></p><p class="source-code"><strong class="bold">envdir =</strong></p><p class="source-code"><strong class="bold">    py27: {toxworkdir}/py27</strong></p><p class="source-code"><strong class="bold">    py39: {toxworkdir}/py39</strong></p><p class="source-code"><strong class="bold">dd_check_style = true</strong></p><p class="source-code"><strong class="bold">usedevelop = true</strong></p><p class="source-code"><strong class="bold">platform = linux|darwin|win32</strong></p><p class="source-code"><strong class="bold">deps =</strong></p><p class="source-code"><strong class="bold">    datadog-checks-base[deps]&gt;=6.6.0</strong></p><p class="source-code"><strong class="bold">    -rrequirements-dev.txt</strong></p><p class="source-code"><strong class="bold">passenv =</strong></p><p class="source-code"><strong class="bold">    DOCKER*</strong></p><p class="source-code"><strong class="bold">    COMPOSE*</strong></p><p class="source-code"><strong class="bold">commands =</strong></p><p class="source-code"><strong class="bold">    pip install -r requirements.in</strong></p><p class="source-code"><strong class="bold">    pytest -v {posargs}</strong></p></li>
			</ul>
			<p>Now, with the tooling for <a id="_idIndexMarker700"/>developing an integration in place locally, let's try running the rest of the steps using an existing integration that is available in the repository. Note that there are about 100 extra integrations available in this repository and you could use them by building the corresponding related package, a trick that you will learn soon.</p>
			<p>For the purposes of testing and deployment practice, let's select an <a id="_idIndexMarker701"/>integration available for <strong class="bold">Zabbix</strong>. This is a popular on-premises monitoring tool and is widely used in both data centers and cloud platforms. Many companies that are migrating to using Datadog might have Zabbix installations to deal with, and a more practical strategy would be to integrate with Zabbix rather than trying to replace it, with a focus on rolling out Datadog for monitoring any new infrastructure. In such scenarios, you will se<a id="_idTextAnchor371"/>e Datadog and Zabbix (or another on-premises monitoring application) running side by side.</p>
			<h2 id="_idParaDest-197"><a id="_idTextAnchor372"/>Running tests</h2>
			<p>For the code developed for the <a id="_idIndexMarker702"/>integration, both unit and integration tests can be run locally with the help of Docker. In the case of Zabbix integration, Zabbix will be run locally as a microservice on Docker and the tests will be run against that instance. The Zabbix deployment details are provided in a <strong class="source-inline">docker-compose.yml</strong> file.</p>
			<p>Follow these steps to <a id="_idIndexMarker703"/>deploy Zabbix and test the integration:</p>
			<ol>
				<li value="1">Change directory to the top level of the Git repository.</li>
				<li>Change directory to that of Zabbix integration:<p class="source-code"><strong class="bold">$ cd zabbix</strong></p></li>
				<li>Look up the <strong class="source-inline">docker-compose.yml</strong> file:<p class="source-code"><strong class="bold">$ cat tests/compose/docker-compose.yml </strong></p><p>The output is not provided here for brevity.</p></li>
				<li>Run the tests:<p class="source-code"><strong class="bold">$ ddev test zabbix</strong></p></li>
				<li>The output is verbose and it would end with messages similar to the following, indicating the success of the tests:<p class="source-code"><strong class="bold">  py39: commands succeeded</strong></p><p class="source-code"><strong class="bold">  style: commands succeeded</strong></p><p class="source-code"><strong class="bold">  congra<a id="_idTextAnchor373"/>tulations :)</strong></p><p class="source-code"><strong class="bold">Passed!</strong></p></li>
			</ol>
			<p>Next, let's see how to build a configuration file for the integration.</p>
			<h2 id="_idParaDest-198"><a id="_idTextAnchor374"/>Building a configuration file</h2>
			<p>The example configuration file <a id="_idIndexMarker704"/>available with an integration, <strong class="source-inline">conf.yaml.example</strong>, is generated from the template file available at <strong class="source-inline">assets/configuration/spec.yaml</strong>. After making changes to the template file, the sample configuration file can be generated as follows:</p>
			<p class="source-code">$ ddev validate config --sync zabbix</p>
			<p class="source-code">Validating default configuration files...</p>
			<p class="source-code">Writing config file to `/Users/thomastheakanath/dd/integrations-extras/zabbix/datadog_checks/zabbix/data/conf.yaml.example`</p>
			<p class="source-code">All 2 configuration fi<a id="_idTextAnchor375"/>les are valid!</p>
			<p>Next, let's look at how the integration code can be packaged for installation.</p>
			<h2 id="_idParaDest-199"><a id="_idTextAnchor376"/>Building a package</h2>
			<p>To deploy the integration, it <a id="_idIndexMarker705"/>needs to be packaged into a wheel, a format used for packing and distributing Python programs. The wheel will have only those files needed for the working of the integration, and it will not contain most of the source files used to build the integration. The integration can be built as follows:</p>
			<p class="source-code">$ ddev release build zabbix</p>
			<p class="source-code">Building `zabbix`...</p>
			<p class="source-code">'build/lib' does not exist -- can't clean it</p>
			<p class="source-code">'build/bdist.macosx-10.13-x86_64' does not exist -- can't clean it</p>
			<p class="source-code">'build/scripts-3.9' does not exist -- can't clean it</p>
			<p class="source-code">warning: no previously-included files matching '__pycache__' found anywhere in distribution</p>
			<p class="source-code">Build done, artifact(s) in: /Users/thomastheakanath/dd/integrations-extras/zabbix/dist</p>
			<p class="source-code">Success!</p>
			<p>The wheel file can be found at the location mentioned in the build command output:</p>
			<p class="source-code">$ ls dist/*.whl</p>
			<p class="source-code">dist/datadog_zabbix-1.0.0-py2.py3-n<a id="_idTextAnchor377"/>one-any.whl</p>
			<p>Next, let's look at how the <a id="_idIndexMarker706"/>integration is installed using the package just built.</p>
			<h2 id="_idParaDest-200"><a id="_idTextAnchor378"/>Deploying an integration</h2>
			<p>If the Datadog Agent runs locally, you can <a id="_idIndexMarker707"/>install it by pointing to the wheel built in the last step. The wheel must be copied to other locations wherever it is planned to be installed. Once the wheel file is available locally, it can be installed as follows:</p>
			<p class="source-code">$ sudo –u dd-agent datadog-agent integration install -w dist/datadog_zabbix-1.0.0-py2.py3-none-any.whl</p>
			<p class="source-code">For your security, only use this to install wheels containing an Agent integration and coming from a known source. The Agent cannot perform any verification on local wheels.</p>
			<p class="source-code">Processing  ./dist/datadog_zabbix-1.0.0-py2.py3-none-any.whl</p>
			<p class="source-code">Installing collected packages: datadog-zabbix</p>
			<p class="source-code">Successfully installed datadog-zabbix-1.0.0</p>
			<p class="source-code">Successfully copied configuration file conf.yaml.example</p>
			<p class="source-code">Successfully completed the installation of datadog-zabbix</p>
			<p>This will basically make the integration available to the Datadog Agent to be enabled as an official integration shipped with the Datadog Agent. Now if you check under the <strong class="source-inline">conf.d</strong> directory of the Datadog Agent home directory, you can see that <strong class="source-inline">zabbix.d</strong> is listed as follows: </p>
			<p class="source-code">$ ls zabbix.d</p>
			<p class="source-code">conf.yaml.example</p>
			<p>As with any other <a id="_idIndexMarker708"/>standard integration, to enable it, <strong class="source-inline">conf.yaml</strong> needs to be created from the sample file provided and the Datadog Agent service needs to be restarted.</p>
			<p>The complete procedure to build a Datadog integration is officially documented at <a href="https://docs.datadoghq.com/developers/integrations/new_check_howto">https://docs.datadoghq.com/developers/integrations/new_check_howto</a>. Refer to that documentation for finer details <a id="_idTextAnchor379"/><a id="_idTextAnchor380"/>and updates. Now, let's look at the best practices related to the topics you have just looked at.</p>
			<h1 id="_idParaDest-201"><a id="_idTextAnchor381"/>Best practices</h1>
			<p>The availability of <a id="_idIndexMarker709"/>client libraries and the option to build custom integrations add a lot of flexibility to your toolbox for integrating Datadog with another application or even a batch job. However, there are certain best practices that you need to look at before starting to implement automation or customization using one or more of those options:</p>
			<ul>
				<li>If you can choose the programming language, pick a language that is better supported and popular, such as Python for scripting and Java for enterprise applications. If the application to be integrated runs primarily runs on Microsoft Windows platforms, choosing C# would be wise.</li>
				<li>Choose a client library that is officially maintained. It's a no-brainer – you need to rely on a library that will keep up with the enhancements made to the Datadog platform and REST API.</li>
				<li>Plan to manage Datadog resources as code using Terraform. Ansible can help there too, but its support for Datadog is limited as of now.</li>
				<li>If you build an integration and if it has an external use, publish it to Datadog's <strong class="bold">integrations-extras</strong> repository on <a id="_idIndexMarker710"/>GitHub. Use by others can help to get valuable feedback and fixes to <a id="_idIndexMarker711"/>make it more robust and useful.</li>
			</ul>
			<p>Following these best practices and rela<a id="_idTextAnchor382"/>ted patterns will help you choose the right approach for implementing your integration requirements.</p>
			<h1 id="_idParaDest-202"><a id="_idTextAnchor383"/>Summary</h1>
			<p>By now, you should be aware of all the important integration options available in Datadog for a variety of use cases; let's recap what we covered in this chapter specifically.</p>
			<p>Many Datadog client libraries targeting popular programming languages are available, both officially maintained and at the community level. There are two types of client libraries – ones that provide a language wrapper to the Datadog REST API and libraries that provide support interfacing with Datadog via the StatsD-compatible DogStasD service. Also, there are community-level efforts to integrate with Datadog that are available on GitHub.</p>
			<p>There are other types of Datadog client libraries that are not discussed here, such as <strong class="bold">APM</strong> and <strong class="bold">distributed tracing libraries</strong>, libraries that support serverless computing resources such as <strong class="bold">AWS Lambda</strong>, and client libraries that specifically target the log management feature of Datadog. The usage of these libraries is not different from how the core API and DogStatsD libraries are used, and you should check those out if you have any related use cases.</p>
			<p>With this chapter, <em class="italic">Part 3</em> of this book, <em class="italic">Extending Datadog</em>, has been completed. In the next part of the book, you will learn more advanced monitoring concepts and features that are implemented by Datadog. We looked at monitoring microservices briefly earlier, and, in the next chapter, you will learn more about monitoring microservices, especially how this is done in an environment orchestrated by Kubernetes.</p>
		</div>
	</div></body></html>