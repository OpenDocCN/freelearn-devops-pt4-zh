<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer178">
			<h1 id="_idParaDest-227"><em class="italic"><a id="_idTextAnchor426"/>Chapter 14</em>: Miscellaneous Monitoring Topics</h1>
			<p>The core monitoring features, as they are implemented in Datadog, have been discussed up to this point in the book. In this chapter, you will learn about some of the monitoring features that have become available on the Datadog monitoring platform relatively recently. These features, especially <strong class="bold">Application Performance Monitoring</strong> (<strong class="bold">APM</strong>), security monitoring, and synthetic monitoring, are usually addressed by dedicated applications. <strong class="bold">AppDynamics</strong> in APM, various <strong class="bold">Security Information and Event Management</strong> (<strong class="bold">SIEM</strong>) applications in security monitoring, and <strong class="bold">Catchpoint</strong> in synthetic monitoring are examples of dedicated monitoring applications in the respective areas. With these features available on the Datadog platform, it is becoming a one-stop destination for all the monitoring requirements. </p>
			<p>In this chapter, you will learn about the following topics, specifically the following:</p>
			<ul>
				<li>Application Performance Monitoring (APM)</li>
				<li>Implementing observability</li>
				<li>Synthetic monitoring</li>
				<li>Security monitoring</li>
			</ul>
			<h1 id="_idParaDest-228"><a id="_idTextAnchor427"/>Technical requirements</h1>
			<p>To try out the examples mentioned in this book, you need to have the following tools installed and resources available:</p>
			<ul>
				<li>An Ubuntu 18.04 Linux environment with Bash shell. Other Linux distributions can be used, but make suitable changes to any Ubuntu-specific commands.</li>
				<li>A Datadog account and user with admin-level access.</li>
				<li>A Datadog Agent running, at host level or as microservice depending on the example, pointing to the Datadog account.</li>
				<li>curl and wget. </li>
			</ul>
			<h1 id="_idParaDest-229"><a id="_idTextAnchor428"/>Application Performance Monitoring (APM)</h1>
			<p>As the name indicates, an APM tool monitors the performance of an application using multiple <a id="_idIndexMarker788"/>methods. APM is a broad area by itself and, as mentioned earlier, dedicated products address it. APM could also stand for <strong class="bold">Application Performance Management</strong>, and adds some confusion to the discussions on APM. The consensus is that, in order to qualify as an application performance <a id="_idIndexMarker789"/>management solution, a monitoring tool should have features to handle the performance issues that would be unearthed by the monitoring features of the tool. Datadog only goes by the acronym APM, and we will review the features under that umbrella without worrying too much about the expansion of APM.</p>
			<p>The following <a id="_idIndexMarker790"/>are the features of a standard APM solution in general:</p>
			<ul>
				<li>Measuring end user experience</li>
				<li>Mapping application workflows initiated by users to the underlying infrastructure</li>
				<li>Measuring the performance of application workflows</li>
				<li>Tracing code to a user's interaction with the application</li>
				<li>Providing analytics and reporting options to tie all the preceding features and present insights on dashboards.</li>
			</ul>
			<p>As you can see, these are broad areas and every APM solution has its own way of implementing these features and more. You will also learn that observability and synthetic monitoring, two topics that will be discussed in dedicated sections later, are also related to APM. In the remainder of this section, we will see what APM features are available in Datadog and try to relate those to the broad categories mentioned in the preceding list, as much as possibl<a id="_idTextAnchor429"/>e.</p>
			<h2 id="_idParaDest-230"><a id="_idTextAnchor430"/>Sending traces to Datadog</h2>
			<p>A <a id="_idIndexMarker791"/>primary step in getting started using Datadog APM is configuring the application to send application traces to the Datadog backend for analysis. The detailed steps for doing this are unique to the programming language used to build the application and the application server environment where the application is run. The traces generated by an application instrumented for that purpose will be published in the Datadog backend and that information is the basis of measuring performance and building traceability of various services that make up the application.</p>
			<p>To understand the general steps involved in instrumenting an application for generating traces <a id="_idIndexMarker792"/>in Datadog APM, let's look at how it's done for a Java application. We can use <strong class="bold">Cassandra</strong> as the <a id="_idIndexMarker793"/>sample Java application that was introduced in <a href="B16483_10_Final_VK_ePub.xhtml#_idTextAnchor302"><em class="italic">Chapter 10</em></a>, <em class="italic">Working with Monitoring Standards</em>. The steps for installing Cassandra are already documented in that chapter. Here, you will learn how to instrument a Cassandra application for tracing:</p>
			<ol>
				<li>Stop the Cassandra service if it has been running:<p class="source-code"><strong class="bold">$ bin/nodetool stopdaemon</strong></p></li>
				<li>Download the Java library for Datadog tracing using <strong class="source-inline">wget</strong> or <strong class="source-inline">curl</strong>:<p class="source-code"><strong class="bold">$ wget -O dd-java-agent.jar https://dtdg.co/latest-java-tracer</strong></p></li>
				<li>Define tracing directives in the environment variable <strong class="source-inline">JAVA_OPTS</strong>:<p class="source-code"><strong class="bold">$ export JVM_OPTS="-javaagent:/&lt;PATH/TO&gt;/dd-java-agent.jar -Ddd.service=cassandra"</strong></p></li>
				<li>Start the Cassandra service:<p class="source-code"><strong class="bold">$ bin/cassandra</strong></p></li>
			</ol>
			<p>The sample commands are based on the assumption that the user is in the directory where the Cassandra installable is extracted, such as <strong class="source-inline">/home/ubuntu/apache-cassandra-3.11.10</strong>. Make suitable changes to the path related to the actual installation.</p>
			<p>In the preceding sample steps, it has been outlined how tracing is enabled for a Java application that runs at the host level. Similar steps are followed for instrumenting services running in the Docker and Kubernetes runtime environments, but with differences specific to the related platform. Also, note that the steps are unique to the programming language used for building the application. All those permutations are documented in the official documentation, starting at <a href="https://docs.datadoghq.com/tracing/">https://docs.datadoghq.com/tracing/</a>.</p>
			<p>Once tracing is enabled for the applications as outlined above, you can view those on the APM dashboard as in the following screenshot by navigating to <strong class="bold">APM</strong> | <strong class="bold">Traces</strong>:</p>
			<div>
				<div id="_idContainer164" class="IMG---Figure">
					<img src="Images/Figure_14.1_B16483.jpg" alt="Figure 14.1 – APM Traces dashboard&#13;&#10;" width="1650" height="821"/>
				</div>
			</div>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Figure 14.1 – APM Traces dashboard</p>
			<p>These <a id="_idIndexMarker794"/>traces published to the Datadog backend provide deep visibility into application-specific requests, errors, and latency. The application traces could be correlated with infrastructure-level metrics, processes running on the host, and various logs, and that would help to pinpoint performance bottlenecks at all lev<a id="_idTextAnchor431"/>els. </p>
			<h2 id="_idParaDest-231"><a id="_idTextAnchor432"/>Profiling an application </h2>
			<p>Using the <em class="italic">Continuous Profiler</em> feature of Datadog APM, the resource usage and I/O bottlenecks <a id="_idIndexMarker795"/>can be traced to the application code by drilling down to the class, method, and line number. Instrumentation is also required for enabling this feature, and let's try that with the Cassandra application.</p>
			<p>The steps to instrument an application for profiling is similar to how it was done for tracing. Actually, the latest agent for tracing also supports profiling, and both features could be enabled using the following command line:</p>
			<p class="source-code">$ export JVM_OPTS="-javaagent:/home/ubuntu/dd-java-agent.jar -Ddd.service=cassandra -Ddd.profiling.enabled=true"</p>
			<p class="source-code">$ bin/cassandra</p>
			<p>As you can observe in the command line, the environment variable, <strong class="source-inline">dd.profiling.enabled</strong>, is set to <strong class="source-inline">true</strong> for enabling the profiling feature, in addition to tracing.</p>
			<p>The <a id="_idIndexMarker796"/>profiling-related reports can be viewed on the <strong class="bold">Continuous Profiler</strong> dashboard by navigating to <strong class="bold">APM</strong> | <strong class="bold">Profiles</strong> in the following screenshot:</p>
			<div>
				<div id="_idContainer165" class="IMG---Figure">
					<img src="Images/Figure_14.2_B16483.jpg" alt="Figure 14.2 – Continuous Profiler dashboard&#13;&#10;" width="1650" height="757"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.2 – Continuous Profiler dashboard</p>
			<p>The profiles listed on this dashboard can be filtered by various tags, including the service name that usually identifies the application running at host level. In a microservices environment, an application would be made up of multiple services and can easily be tracked as a result of suitable tagging services belonging to an application. </p>
			<p>By clicking on a profile listed on the dashboard, performance metrics and insights based on the profiling data can be viewed, as in the following screenshot:</p>
			<div>
				<div id="_idContainer166" class="IMG---Figure">
					<img src="Images/Figure_14.3_B16483.jpg" alt="Figure 14.3 – Application profiling details&#13;&#10;" width="1650" height="595"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.3 – Application profiling details</p>
			<p>On the <a id="_idIndexMarker797"/>preceding dashboard, under the <strong class="bold">Performance</strong>, <strong class="bold">Analysis</strong>, <strong class="bold">Metrics</strong>, and <strong class="bold">Runtime Info</strong> tabs, a large amount of runtime information regarding the application is available for triaging performance issues and fine-tuning application performance and security in ge<a id="_idTextAnchor433"/>neral.</p>
			<h2 id="_idParaDest-232"><a id="_idTextAnchor434"/>Service Map</h2>
			<p>A Service Map <a id="_idIndexMarker798"/>will provide a pictorial representation of the services running in a runtime environment, such as <a id="_idIndexMarker799"/>a host or Kubernetes cluster, with the interaction between the services mapped out. The <strong class="bold">Service Map</strong> can be accessed by navigating to <strong class="bold">APM</strong> | <strong class="bold">Service Map</strong> and the dashboard will be rendered with the <strong class="bold">Services</strong> tab open, as in the following screenshot:</p>
			<div>
				<div id="_idContainer167" class="IMG---Figure">
					<img src="Images/Figure_14.4_B16483.jpg" alt="Figure 14.4 – Service Map dashboard&#13;&#10;" width="1538" height="749"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.4 – Service Map dashboard</p>
			<p>The Service Map will be very useful in a microservices environment, such as a Kubernetes cluster, for understanding the interaction between various components of an application. By enabling tracing and profiling for each microservice, a Service Map for the application system can be built that will provide valuable insights for fine-tuning the performance of the application. </p>
			<p>In this <a id="_idIndexMarker800"/>section, you have learned how various APM features are implemented in Datadog by way of instrumenting the applications for generating traces and profiles and aggregating those inputs to derive insights. Both observability and synthetic monitoring are discussed, along with APM usually, but we will look at those in separate sections as those topics are generic enough to be understood in a broader context of monitoring. </p>
			<p>In the next section, let's discuss observability and how that is implemented in <a id="_idTextAnchor435"/>Datadog.</p>
			<h1 id="_idParaDest-233"><a id="_idTextAnchor436"/>Implementing observability</h1>
			<p>Observability refers <a id="_idIndexMarker801"/>to the processes and methods involved in making the <a id="_idIndexMarker802"/>working of an application system more transparent and measurable. Increased observability of an application system will make it more monitoring-friendly. Observability is a property of the application system itself, while monitoring is an act that leverages that property for operational requirements.</p>
			<p>Observability is relatively new to the monitoring vocabulary, but it has been repurposed from system control theory. The concept of observability was introduced by Hungarian American engineer Rudolf E. Kálmán for linear dynamic systems, and it states that observability is a measure of how well internal states of a system can be inferred from knowledge of the system's external outputs. In the context of monitoring, the external outputs could be various metrics, logs, and traces. So, a monitoring tool with observability features should help with generating and analyzing various outputs related to making the working of an application system more transparent, implemented using a set of methods, processes, and dashboards for analysis. Such features would help with increasing the observability of the application system that the monitoring tool monitors.</p>
			<p>While it's <a id="_idIndexMarker803"/>obvious that adding observability is important for better monitoring, you may be wondering why observability is a relatively new monitoring terminology. One of the reasons is that modern application systems and the infrastructure they run on are far more complex now. Gone are the days when monolithic applications ran on a few bare-metal machines in a data center. The applications are highly distributed, they run on public clouds, and are managed by complex orchestration tools such as Kubernetes and Spinnaker. While the modern application systems are cutting-edge and far more flexible and scalable, the increased complexity of application systems reduces the overall observability. In such a scenario, deliberate steps need to be taken to improve observability, and that's why commercial monitoring tools are now shipped with such features. </p>
			<p>Metrics, logs, and traces are generally considered the three pillars of observability. Throughout this book, you have seen that Datadog features center around metrics and tags. Datadog monitoring features generate a variety of metrics out of the box. Datadog also provides options to create custom metrics and tags that will add more visibility to the working of an application or an infrastructure component. As seen in <a href="B16483_13_Final_VK_ePub.xhtml#_idTextAnchor402"><em class="italic">Chapter 13</em></a>, <em class="italic">Managing Logs Using Datadog</em>, Datadog's log management features are comprehensive in terms of managing a variety of logs, including those from the microservices platforms such as Docker and Kubernetes. Earlier in this chapter, in the section on APM, you have seen how Datadog could be used to generate, collect, and analyze traces from the applications. </p>
			<p>While Datadog has all the nuts and bolts necessary for implementing observability in an application, it's largely a custom effort that must be done for every application system. The application onboarding and deployment processes must be enhanced to include the instrumentation <a id="_idIndexMarker804"/>steps necessary for adding observability. Let's see which of those instrumentations are required in Datadog:</p>
			<ul>
				<li><strong class="bold">Add platform component-level metrics</strong>: This is usually done by using integrations <a id="_idIndexMarker805"/>supplied by Datadog. If it adds more value, consider adding custom metrics and using community-developed integrations. </li>
				<li><strong class="bold">Add application metrics</strong>: This is custom in nature and included in the development <a id="_idIndexMarker806"/>process. Just like unit tests are required in order to pass a build process, also make this a requirement for a new service to be approved at the build or release level.</li>
				<li><strong class="bold">Automate log management</strong>: Instrument the build and deployment manifests <a id="_idIndexMarker807"/>such as Dockerfiles and Kubernetes deployment scripts to get the logs published to the Datadog's Log Management backend. This must be automated at all levels as it won't scale up if done manually.</li>
				<li><strong class="bold">Automate the generation of traces and profiles</strong>: Enhance the build and deployment <a id="_idIndexMarker808"/>process to automate the generation of traces and profiling, so those will readily be available to the Datadog APM service for analysis and building Service Maps. APM is a key aspect of rolling out observability.</li>
				<li><strong class="bold">Use Datadog for all monitoring needs</strong>: There are dedicated applications for log management and APM by other vendors, as you have seen earlier in this chapter. One of <a id="_idIndexMarker809"/>the advantages of using Datadog is that both those features are provided by Datadog in addition to core monitoring. That opens up the opportunity to correlate various metrics, logs, and traces on a single platform using tagging and related constructs. If done right, this will enhance the observability of the applications by virtue of having all the information gathered in one place, and Datadog usually correlates monitoring information available across various features.</li>
			</ul>
			<p>It's evident that the ability of Datadog to consolidate all three pillars of observability – metrics, logs, and traces – is a major strength of that platform. To make use of the related out-of-the-box features, the application build and deployment processes must be enhanced <a id="_idIndexMarker810"/>and tooled so logs and traces are published to the Datadog backend automatically and seamlessly. </p>
			<p>In the next section, we will look at synthetic monitoring, which refers to the testing of an application live in production using requests and actions that simulate the<a id="_idTextAnchor437"/> user experience. </p>
			<h1 id="_idParaDest-234"><a id="_idTextAnchor438"/>Synthetic monitoring</h1>
			<p>In <strong class="bold">synthetic monitoring</strong>, the utilization of an application is simulated, typically by a robotic user, and the data collected from such simulations forms the basis of actionable steps, such as <a id="_idIndexMarker811"/>triggering an alert on an application performance attribute or the availability of the application itself. Generally, the following are the application states that can be monitored by using synthetic monitoring tools and methods:</p>
			<ul>
				<li>The application is available in all respects. This might involve checking on multiple web or API endpoints of the application.</li>
				<li>The application performance in terms of the velocity with which an application responds to user requests.</li>
				<li>The applications can execute the business transactions as designed. </li>
				<li>The third-party components used in building the application system are functioning.</li>
				<li>The desired performance of the application achieved is cost-effective and within budget.</li>
			</ul>
			<p>Most of these aspects are related to measuring user experience in terms of a set of metrics, and those metrics values are generated by the robotic usage of the application. The robotic access could be local where the application is hosted, in a data center or public cloud, or close to where actual users are located. The latter aspect of monitoring is known as last-mile monitoring, one of the types of monitoring that we discussed in <a href="B16483_01_Final_VK_ePub.xhtml#_idTextAnchor014"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Monitoring</em>. There are dedicated SaaS monitoring solutions that are available for addressing last-mile monitoring requirements. With Datadog's synthetic monitoring features, it is also possible to address typical last-mile monitoring requirements.</p>
			<p>The synthetic <a id="_idIndexMarker812"/>monitoring feature of Datadog provides a variety of checks that will simulate the end user experience. The tests are launched from Datadog-managed locations around the world, and you have the option to configure from where such tests originate. The following are the categories of checks that can be performed using Datadog's synthetic monitoring:</p>
			<ul>
				<li><strong class="bold">DNS</strong>: Checks <a id="_idIndexMarker813"/>whether domains are resolved and how quickly they are resolved in regions where users are located</li>
				<li><strong class="bold">ICMP</strong>: Pings the <a id="_idIndexMarker814"/>hosts that are enabled with an ICMP protocol for their availability and access from where the users are located </li>
				<li><strong class="bold">TCP</strong>: Verifies <a id="_idIndexMarker815"/>access to service ports, such as HTTP (<strong class="source-inline">80</strong>), HTTPS (<strong class="source-inline">443</strong>), and SSH (<strong class="source-inline">22</strong>), and any custom port</li>
				<li><strong class="bold">HTTP/HTTPS</strong>: Checks <a id="_idIndexMarker816"/>whether a web application endpoint is up and responds properly</li>
				<li><strong class="bold">HTTP workflow</strong>: Validates <a id="_idIndexMarker817"/>a multi-request workflow covering a full transaction by chaining HTTP requests</li>
				<li><strong class="bold">SSL</strong>: Validates <a id="_idIndexMarker818"/>and checks the expiration of SSL certificates associated with HTTPS endpoints</li>
			</ul>
			<p>Now, let's see whether some of these checks could be configured in Datadog. The synthetic monitoring-related options are accessible from the main menu, <strong class="bold">UX Monitoring</strong>. Navigate to <strong class="bold">UX Monitoring</strong> | <strong class="bold">New Test</strong> and then click on the <strong class="bold">Get Started</strong> link, and you will be presented with the options as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer168" class="IMG---Figure">
					<img src="Images/Figure_14.5_B16483.jpg" alt="Figure 14.5 – Synthetic monitoring options&#13;&#10;" width="1650" height="766"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.5 – Synthetic monitoring options</p>
			<p>Let's create a <a id="_idIndexMarker819"/>sample TCP test that will check the access to an SFTP host from Paris and Tokyo. To do that, the public IP address of the SFTP server or its domain name is needed to configure the test. As the SFTP service is available on port <strong class="source-inline">22</strong>, the check can be done on that port.</p>
			<p>Click on <strong class="bold">New API Test</strong> and select the <strong class="bold">TCP</strong> tab to get to the form where a TCP test can be configured. The first part of the form is shown in the following screenshot, where the name of the test and the information about the SFTP server can be provided:</p>
			<div>
				<div id="_idContainer169" class="IMG---Figure">
					<img src="Images/Figure_14.6_B16483.jpg" alt="Figure 14.6 – Creating a synthetic TCP test; server details&#13;&#10;" width="1224" height="1145"/>
				</div>
			</div>
			<p class="figure-caption">  </p>
			<p class="figure-caption">Figure 14.6 – Creating a synthetic TCP test; server details</p>
			<p>Using the <strong class="screen-inline">Test </strong><strong class="screen-inline"><a id="_idIndexMarker820"/></strong><strong class="screen-inline">URL</strong> link on the form, basic access to the server on port <strong class="source-inline">22</strong> can be verified. Access from specific regions can then be added to the test, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer170" class="IMG---Figure">
					<img src="Images/Figure_14.7_B16483.jpg" alt="Figure 14.7 – Creating a synthetic TCP test; selecting access locations&#13;&#10;" width="1151" height="857"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.7 – Creating a synthetic TCP test; selecting access locations</p>
			<p>Multiple Datadog-managed locations are available to choose from, as listed in the preceding screenshot. Access to the SFTP server will originate from the selected locations. The remainder <a id="_idIndexMarker821"/>of the options are similar to those available for setting up a standard Datadog monitor in general. </p>
			<p>The other <a id="_idIndexMarker822"/>types of TCP tests – <strong class="bold">HTTP</strong>, <strong class="bold">DNS</strong>, <strong class="bold">SSL</strong>, and <strong class="bold">ICMP</strong> – can be <a id="_idIndexMarker823"/>configured by following similar steps by selecting <a id="_idIndexMarker824"/>the related tab on the <strong class="bold">New API Test</strong> form.</p>
			<p>In a real-life <a id="_idIndexMarker825"/>scenario, there will be multiple tests such as this configured to verify that various components and workflows of an application are available to the end user in the regions where they are located. The availability status dashboard will look like the one in the following screenshot, and it can be accessed by navigating to <strong class="bold">UX Monitoring</strong> | <strong class="bold">Synthetic Tests</strong>:</p>
			<div>
				<div id="_idContainer171" class="IMG---Figure">
					<img src="Images/Figure_14.8_B16483.jpg" alt="Figure 14.8 – Synthetic Monitoring dashboard&#13;&#10;" width="1650" height="906"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.8 – Synthetic Monitoring dashboard</p>
			<p>The overall uptime <a id="_idIndexMarker826"/>status will be presented on this dashboard and the results can be filtered using different conditions, such as the region of test origination. The individual tests are listed at the bottom of this dashboard and by clicking a specific item, the details of that test can be viewed and updated, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer172" class="IMG---Figure">
					<img src="Images/Figure_14.9_B16483.jpg" alt="Figure 14.9 – Details of a synthetic TCP test&#13;&#10;" width="1650" height="1041"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.9 – Details of a synthetic TCP test</p>
			<p>From this page, the test can be paused or be run on an ad hoc basis without having to wait for the <a id="_idIndexMarker827"/>next scheduled run. These checks look simple, but are very powerful, because with these in place, you can access services as end users do using the application.</p>
			<p>Using the <em class="italic">Browser Test</em>, it is possible to simulate the device and the browser used by the user when accessing a web application. To create a <em class="italic">Browser Test,</em> navigate to <strong class="bold">UX Monitoring</strong> | <strong class="bold">New Test</strong> | <strong class="bold">New Browser Test</strong>, and you will be presented with the new test creation form, as indicated in the following screenshot:</p>
			<div>
				<div id="_idContainer173" class="IMG---Figure">
					<img src="Images/Figure_14.10_B16483.jpg" alt="Figure 14.10 – Synthetic test simulating browsers and devices used for access&#13;&#10;" width="1206" height="1094"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.10 – Synthetic test simulating browsers and devices used for access</p>
			<p>To complete <a id="_idIndexMarker828"/>the creation of this test, the browsers, devices, and locations need to be selected. Depending on the browser that you are using to access the Datadog dashboard, a Datadog-supplied browser plugin has to be installed as well for recording the website workflow that needs to be simulated by the test. You will get an option to record the workflow and save it as part of creating the test.</p>
			<p>Once the test results are in, you can view this on the dashboard, as in the following sample screenshot:</p>
			<div>
				<div id="_idContainer174" class="IMG---Figure">
					<img src="Images/Figure_14.11_B16483.jpg" alt="Figure 14.11 – A sample Browser Test result&#13;&#10;" width="1649" height="963"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.11 – A sample Browser Test result</p>
			<p>As you can see, there are multiple issues unearthed by the sample test. You can drill down to the <a id="_idIndexMarker829"/>report and view the details of each issue. A test result such as this is very valuable in terms of fine-tuning the web application as you are now able to see how the users access the application from a specific combination of computing device and browser.</p>
			<p>Synthetic monitoring is essentially about simulating the user experience that you can measure. That's why it's considered part of APM because the inputs from synthetic monitoring tests can be used to fine-tune the applications for a better user experience. In the next section, you will learn about the security monitoring features that the Datad<a id="_idTextAnchor439"/>og monitoring platform offers.</p>
			<h1 id="_idParaDest-235"><a id="_idTextAnchor440"/>Security monitoring</h1>
			<p>Cybersecurity is a far more important and essential area to cover in the cloud environment <a id="_idIndexMarker830"/>because the application needs to be accessed via the internet and, in most cases, the application itself is hosted in a public cloud. The security of running an application in your own data center and making it accessible only in your private network is no longer an option. The infrastructure and the applications that are exposed to external attacks should be protected and hardened. There is an ecosystem of software applications and services addressing a plethora of cybersecurity issues. </p>
			<p>Another aspect is the requirement of meeting security and privacy and compliance standards for doing business, especially if the application is catering to the healthcare and financial industries. Compliance requirements are dictated by laws applicable in the jurisdiction of doing business, and security standards are demanded by customers. Compliance requirements are usually audited by third-party service providers in that space, and those requirements must be monitored and recorded as evidence for the auditors. </p>
			<p>Datadog's <em class="italic">Security and Compliance Monitoring</em> feature has multiple options that can be rolled out in an organization to address common cybersecurity and compliance requirements. Also, Datadog enjoys the advantage of being a unified platform for various monitoring types. By combining the analysis of logs and traces that are sourced from the infrastructure and applications, and the powerful monitoring features such as alerting and event management, Datadog can also be configured as a SIEM platform. Having a SIEM tool is usually a requirement to demonstrate that an organization has a sound cybersecurity practice.</p>
			<p>Now, let's review the security features currently available on the Datadog platform and look at the general steps involved in starting to use those features. The security options can be accessed from the main <strong class="bold">Security</strong> menu, as in the following screenshot:</p>
			<div>
				<div id="_idContainer175" class="IMG---Figure">
					<img src="Images/Figure_14.12_B16483.jpg" alt="Figure 14.12 – Datadog Security and Compliance monitoring options&#13;&#10;" width="1241" height="461"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.12 – Datadog Security and Compliance monitoring options</p>
			<p>The general steps in enabling the security features are these: source the logs, define the security rules, and monitor for security signals that are flagged from the source information <a id="_idIndexMarker831"/>based on the security rules. The <strong class="bold">Runtime Security</strong> feature helps to detect threats to production infrastructure where the application workloads are run by monitoring system-level activities, such as changes in a file or process. The <strong class="bold">Compliance Findings</strong> feature helps to audit the production infrastructure <a id="_idIndexMarker832"/>for compliance with industry-standard security regimes, such as the <strong class="bold">Payment Card Industry</strong> (<strong class="bold">PCI</strong>) data security standard <a id="_idIndexMarker833"/>and the <strong class="bold">Center for Internet Security</strong> (<strong class="bold">CIS</strong>), which audits infrastructure for vulnerabilities. </p>
			<p>Now, let's look at how information is fed into Datadog for security analysis and use the insights for hardening the <a id="_idTextAnchor441"/>infrastructure and applications. </p>
			<h2 id="_idParaDest-236"><a id="_idTextAnchor442"/>Sourcing the logs</h2>
			<p>Datadog can <a id="_idIndexMarker834"/>consume logs from a variety of public cloud platforms and security products to look for security threats. The following screenshot lists the general category of sources that can be integrated with Datadog for sourcing the logs:</p>
			<div>
				<div id="_idContainer176" class="IMG---Figure">
					<img src="Images/Figure_14.13_B16483.jpg" alt="Figure 14.13 – Sources of logs for security analysis&#13;&#10;" width="1650" height="942"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.13 – Sources of logs for security analysis</p>
			<p>The following <a id="_idIndexMarker835"/>are the four categories of sources of <a id="_idIndexMarker836"/>logging information that Datadog can analyze for security threats:</p>
			<ul>
				<li>Public cloud platforms – AWS, Azure, and GCP</li>
				<li>Container products and services, such as <strong class="bold">Docker</strong>, <strong class="bold">Kubernetes</strong>, and <strong class="bold">Amazon EKS</strong></li>
				<li>Identity providers – <strong class="bold">Okta</strong>, <strong class="bold">Auth0</strong>, <strong class="bold">G Suite</strong>, and <strong class="bold">Azure Active Directory</strong>.</li>
				<li>Security products, mainly services available on <strong class="bold">AWS</strong>, and other products such as <strong class="bold">HashiCorp Vault</strong></li>
			</ul>
			<p>The integration methods are specific to each product, and by selecting a product listed on the preceding dashboard, the in<a id="_idTextAnchor443"/>stallation procedure can be viewed.</p>
			<h2 id="_idParaDest-237"><a id="_idTextAnchor444"/>Defining security rules</h2>
			<p>There are predefined rules available out of the box that can be used to analyze the logs collected by <a id="_idIndexMarker837"/>Datadog from the various sources mentioned in the last section. The security rules dashboard can be accessed by navigating to <strong class="bold">Security</strong> | <strong class="bold">Security Rules</strong> and the rules available are listed on the dashboard, as in the following screenshot:</p>
			<div>
				<div id="_idContainer177" class="IMG---Figure">
					<img src="Images/Figure_14.14_B16483.jpg" alt="Figure 14.14 – Security rules dashboard&#13;&#10;" width="1650" height="1013"/>
				</div>
			</div>
			<p class="figure-caption">Figure 14.14 – Security rules dashboard</p>
			<p>The rules can be enabled or disabled from this dashboard. Also, custom rules can b<a id="_idTextAnchor445"/>e added by using the <strong class="bold">New Rule</strong> link.</p>
			<h2 id="_idParaDest-238"><a id="_idTextAnchor446"/>Monitoring security signals</h2>
			<p>A security signal <a id="_idIndexMarker838"/>is created when a potential threat is located in the logs based on the active security rules. This is similar to generating an alert by a monitor when a metric value crosses a threshold. Like an alert, a signal can be broadcast to a variety of audiences. By navigating to <strong class="bold">Security</strong> | <strong class="bold">Security Signals</strong>, these signals can also be viewed on the <strong class="bold">Security Signals</strong> dashboard. </p>
			<p>We did a general overview of the security features available on the Datadog platform in this section. It's an area that's still a work in progress, but the general direction it has taken is very <a id="_idIndexMarker839"/>encouraging in terms of the usability of the available features and the simplicity of integration with sources of security information. In the next section, let's look at the best practices related to the topics that<a id="_idTextAnchor447"/> have been disc<a id="_idTextAnchor448"/>ussed in this chapter.</p>
			<h1 id="_idParaDest-239"><a id="_idTextAnchor449"/>Best practices</h1>
			<p>You have learned about advanced monitoring, APM, and the security features available on the Datadog platform, so now let's look at the related best practices in those areas:</p>
			<ul>
				<li>The instrumentation for generating application traces and profiling for APM must be incorporated in the build and deployment process.</li>
				<li>Define a complete set of application metrics for each service and expose those for easy consumption by Datadog.</li>
				<li>Plan to collect all application logs and, if needed, define new ones so that the application state can be observed easily.</li>
				<li>Determine the geographical locations of the users of the application for fine-tuning synthetic tests. </li>
				<li>Publish the list of supported devices and browsers. Based on the information available in synthetic monitoring reports, fine-tune the application for compatibility with access devices and browsers. </li>
				<li>For effective security monitoring, define custom security rules that are relevant to the organization. Disable out-of-the-box rules that might generate spurious messages.</li>
			</ul>
			<p>T<a id="_idTextAnchor450"/>his brings us to the summary section.</p>
			<h1 id="_idParaDest-240"><a id="_idTextAnchor451"/>Summary</h1>
			<p>In this chapter, you have learned about some of the monitoring features that are relatively new on the Datadog platform and that continue to evolve. Both observability and synthetic monitoring are discussed along with APM, but the related tools and concepts are generic enough to be applicable to a wider context of monitoring. </p>
			<p>With this chapter, the book is concluded and the recommended next step for you is to roll out Datadog in your environment to acquire expertise. With features available to cover almost every monitoring type, such as infrastructure monitoring, log aggregation and indexing, last-mile monitoring, APM, and security monitoring, Datadog is one the most comprehensive monitoring platforms available on the market. One of its major attractions is its ability to unify monitoring with the help of a variety of monitoring features available on the platform and its ability to correlate information across products. </p>
			<p>We wish you good luck with rolling out proactive monitoring using Datadog, which is an excellent choice for this purpose.</p>
		</div>
	</div></body></html>