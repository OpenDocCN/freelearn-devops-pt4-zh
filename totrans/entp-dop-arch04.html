<html><head></head><body>
		<div id="_idContainer029">
			<h1 id="_idParaDest-39"><em class="italic"><a id="_idTextAnchor040"/>Chapter 3</em>: Architecting for DevOps Quality</h1>
			<p>The overall aim of <strong class="bold">DevOps</strong> is to deliver high performance and quality to IT projects. In this chapter, you will learn how DevOps can add value to the quality of <strong class="bold">IT delivery</strong>. In this chapter, we will learn how to define test strategies, proving that quality has been delivered according to the <strong class="bold">Definition of Done</strong> (<strong class="bold">DOD</strong>). But what happens if something breaks? The golden rule in DevOps is you build it, run it, break it, and then you fix it. But then, we must detect what the issue is by executing a <strong class="bold">root cause analysis</strong> (<strong class="bold">RCA</strong>). In the final section, we will discuss <strong class="bold">remediation</strong> and, with that, <strong class="bold">continuous improvement</strong>. </p>
			<p>After completing this chapter, you will be able to identify and implement quality measures in DevOps projects. You will have learned what tests can be included, how the are organized, and what the value of these tests is, thus continuously improving the product or service. </p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Defining test strategies</li>
				<li>Implementing quality measures</li>
				<li>Designing test automation and execution</li>
				<li>Understanding root cause analysis</li>
				<li>Designing for remediation</li>
			</ul>
			<h1 id="_idParaDest-40"><a id="_idTextAnchor041"/>Defining test strategies</h1>
			<p>In the previous<a id="_idIndexMarker170"/> chapter, we concluded that testing is a crucial step in the CI/CD process to ensure the quality of the build. In this section, we will learn how to define test strategies in DevOps. </p>
			<p>First, DevOps requires a different approach to testing: it's part of the continuous deployment and integration of <em class="italic">builds</em>. The reason we should adopt DevOps is because enterprises want to speed up releases so that they can act much quicker to changing demands. For testing, this means that there is a shift from testing the end product to continuous testing, with a focus on reducing build and test times. </p>
			<p>In other words, testing is no longer just a matter of detecting the faults in the end product; it has become part of the full life cycle of the build, collecting feedback during this whole cycle. </p>
			<p><strong class="bold">Testers</strong> should <a id="_idIndexMarker171"/>be members of the DevOps team. Their responsibility is to constantly collect feedback, measure the cycle time, and find ways to reduce these times. Testers should be invited to monitor code during the whole build process so that they can look at errors and bugs as soon as they appear. This will give the team opportunities to fix issues before code is released to the next stage. The big benefit of this approach is that the end product will already have fewer issues and the total cycle time will be decreased during every iteration. </p>
			<p>Overall, we can say that the role of quality assurance is changing in DevOps. In traditional IT projects, quality assurance was done as soon as the product – for instance, an application – was delivered at the final stage. Testers would execute functional testing and<a id="_idIndexMarker172"/> involve a group of users to perform <strong class="bold">user acceptance tests</strong> (<strong class="bold">UAT</strong>). This <a id="_idIndexMarker173"/>was done for a given period, usually a week or two. Then, the results were handed back to the developers that would go over the findings and fix the issues. Then, the whole thing was submitted to testers again so that they could retest and validate whether all the findings had been addressed. In DevOps, we don't work that way anymore. Firstly, this is because it takes too much time, and secondly, there's hardly any interaction between the testers and the developers. </p>
			<p>What are the requirements for a test strategy in DevOps that ensures quality through the whole development cycle? They are as follows:</p>
			<ul>
				<li><strong class="bold">Create user story awareness</strong>: First, there needs to be a clear <strong class="bold">user story</strong>. The user story<a id="_idIndexMarker174"/> will drive the test scenarios.  This means that the team scopes the testing topics. <strong class="bold">TMAP</strong>, the <a id="_idIndexMarker175"/>most used testing framework, divides the topics into two categories: <em class="italic">organizing</em> and <em class="italic">performing</em>. Organizing topics cover the way tests are planned, prepared, and managed. Performing topics concern the tests themselves.</li>
				<li><strong class="bold">Create the strategy</strong>: In DevOps, the <strong class="bold">strategy</strong> should <a id="_idIndexMarker176"/>be that tests are executed throughout the whole build, which means that testers need to run automated test scripts on iterations of the build. In other words, code is constantly tested to verify it performs well without issues. This requires strong cooperation between the developers and the testers: during the build, developers will have to supply code to testers, as well as to interim builds, until the code is stable. <p>Obviously, there has to be a balance between the number of tests, the testing time, and the goals of the tests. Enterprises run tests to avoid risks such as materializing and causing damage. One of the first topics that needs to be addressed in defining a test strategy is creating a clear view of risks. </p><p>Be aware that this is not just something technical. It also involves soft skills in collaboration and communication. Where testers were used to get the whole package delivered at the end of the development cycle and then run their tests, they are now part of the DevOps team, continuously communicating about timing, the way <a id="_idIndexMarker177"/>of testing, and what will be tested. This is crucial for the success of DevOps. </p></li>
				<li><strong class="bold">Define tools and environments</strong>: Honestly, it's not about the tools – it's about the<a id="_idIndexMarker178"/> code and the level of <strong class="bold">standardization</strong>. Testers <a id="_idIndexMarker179"/>need to make sure they capture all the code: we refer to this as code coverage, which should be 100% or very near that at the least. Test cases must be<a id="_idIndexMarker180"/> automated. <strong class="bold">Automation</strong> requires standardization: code needs to be automatically deployed to standardized test environments where the pre-testing, cleanup, and post-testing tasks are automated. This will increase efficiency and reliability, preventing human errors in repetitive tasks, assuming that a number of tests will be executed more than once.  <p>A first test, very early in the development process, includes <em class="italic">static analysis</em> to check whether the code is complete. With static analysis, the code is not executed: tools validate that the code is complete and consistent. An example is when testers can use tools and scripts to validate that security policies have been applied to the code and that the code is compliant with industry standards. Reviewing the static analysis process should provide a detailed overview of the quality of the code and the surrounding documentation. </p></li>
				<li><strong class="bold">Execute</strong>: Test scenarios must be very well structured. This needs to be defined in the test design, which we will discuss in the <em class="italic">Designing test automation and execution</em> section. There, we will look at various executing techniques: <p>- Process focused</p><p>- Condition focused</p><p>- Data focused</p><p>- Experience focused</p><p>An important goal of DevOps is to speed up delivery by reducing waiting times between process steps. This also includes testing. We already noted that testers do not have to wait until the code is finally delivered, but that they can run automated tests in subsequent iterations of the build cycle. To reduce the test time – and with<a id="_idIndexMarker181"/> that, the whole build – <em class="italic">parallel execution</em> of tests is advised.</p><p>There's more<a id="_idIndexMarker182"/> that can be done to improve quality and tests and that's not the sole responsibility of quality engineers and testers. DevOps really is a team effort, encouraging all members to contribute to various steps and stages. Developers are therefore also invited to contribute and add test cases. It's good practice to collect cases, scripts, runbooks, reports, and other documentation in a quality repository. From this repository, quality engineers and testers can pick up cases and further automate these in the development and deployment process.  </p></li>
				<li><strong class="bold">Creating and interpreting reports</strong>: Test results must be evaluated. At the beginning of this section, we stated that tests are executed to identify, analyze, and mitigate risks. Test outcomes must match these risks, meaning that they should result in expected outcomes. If the outcomes are completely different, then the risks need to be investigated further. Only then will the tests really contribute to the quality. <p>So, testing is much more than just detecting bugs. Tests must be focused on the overall desired outcome of the build. Consequently, testers need to report on much more than purely the issues. Reporting is now really focusing on improving the quality of both the build and the build process. An example is when the test results may show where automation can be improved or code can be enhanced. The overall goal is to reduce risks. </p><p>Blocking issues – issues<a id="_idIndexMarker183"/> that inflict a big risk – must be reported instantly and looped back to the start of the development chain.  </p></li>
				<li><strong class="bold">Setting exit criteria</strong>: Results matter in tests and they lead to decisions about if and how to proceed. That's what <strong class="bold">exit criteria</strong> are for. If all the necessary tests have been conducted, the results should give you enough information to do a <em class="italic">go</em>/<em class="italic">no go</em> and push the software to the next stage, typically production.  </li>
			</ul>
			<p>In this section, you<a id="_idIndexMarker184"/> learned how to compose a quality and test strategy. Before we learn how to implement quality measures, we will briefly look at different types of tests.  </p>
			<h2 id="_idParaDest-41"><a id="_idTextAnchor042"/>Understanding types of tests</h2>
			<p>In this section, we <a id="_idIndexMarker185"/>will introduce the different, most commonly known types of tests. There are <a id="_idIndexMarker186"/>three tiers of testing: </p>
			<ul>
				<li><strong class="bold">Level 1</strong>: <strong class="bold">Small tests</strong> that focus on<a id="_idIndexMarker187"/> separate components. Unit tests are an example where small pieces of the code are tested.</li>
				<li><strong class="bold">Level 2</strong>: <strong class="bold">Integration tests</strong> that<a id="_idIndexMarker188"/> involve more than one component. Integration itself is tested, but also how components interact and if the integrated packages perform well. Integration and performance tests are executed at this level. </li>
				<li><strong class="bold">Level 3</strong>: <strong class="bold">Usability tests</strong> that<a id="_idIndexMarker189"/> focus on how easy the end product can be used – for example, using the graphical interface – and if it's easy to<a id="_idIndexMarker190"/> manage. The <strong class="bold">User Acceptance Test </strong>(<strong class="bold">UAT</strong>) is typically the final test at this level. To be clear, the UAT also involves performance testing from the end user's perspective.</li>
			</ul>
			<p>These three<a id="_idIndexMarker191"/> levels are shown in the following diagram: </p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="image/B17492_03_001.jpg" alt="Figure 3.1 – Levels of testing&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.1 – Levels of testing</p>
			<p>The complexity increases as testing moves from single components to a usability test, which involves the full stack of the solution. </p>
			<p>In the test strategy, the teams will define, based on the business requirements, what tests must be conducted and what the expected outcome must be to deploy a build successfully. </p>
			<p>A couple of specific tests have not been mentioned yet:</p>
			<ul>
				<li><strong class="bold">Regression test</strong>: These tests were very common in the traditional approach of software<a id="_idIndexMarker192"/> development. Functional and technical tests were re-executed to make sure that software – code – that was changed during the development cycle still performed without issues after the change. As we have seen, DevOps has changed the way we approach testing. It's not a one-time exercise anymore, where we run a regression test, find bugs, fix these, and rerun the tests. In DevOps, code is continuously tested and improved throughout the build. Regression tests have become <em class="italic">less important</em>. In some cases, it still might be valuable to execute regression tests. </li>
				<li><strong class="bold">Security test</strong>: The <a id="_idIndexMarker193"/>same applies to security tests that were often executed once the build was delivered. In DevOps, we check for vulnerabilities and compliancy issues during the first static analysis stage. In <a href="B17492_14_ePub_RK.xhtml#_idTextAnchor168"><em class="italic">Chapter 14</em></a>, <em class="italic">Integrating DevSecOps with DevOps</em>, we will go into this in more detail. </li>
			</ul>
			<p>Testing is about<a id="_idIndexMarker194"/> validating quality. In the next section, we will learn about quality measures and how to implement them in our DevOps projects. </p>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor043"/>Implementing quality measures</h1>
			<p>By now, it<a id="_idIndexMarker195"/> should be clear that everything in DevOps is about being <strong class="bold">continuous</strong>, which, in<a id="_idIndexMarker196"/> other <a id="_idIndexMarker197"/>words, means <strong class="bold">continuous deployment</strong>, <strong class="bold">continuous integration</strong>, <strong class="bold">continuous testing</strong>, and <strong class="bold">continuous quality</strong> engineering. DevOps <a id="_idIndexMarker198"/>projects constantly<a id="_idIndexMarker199"/> focus on <strong class="bold">quality</strong> at every stage of development and operations. It's different from traditional approaches where teams have a separate phase to fix issues. In DevOps, teams constantly measure the products and fix issues as soon as they occur. One of the six DevOps<a id="_idIndexMarker200"/> principles is <strong class="bold">continuous improvement</strong>, which refers to the feedback loop wherein products are improved in every iteration, but also to the DevOps process itself. </p>
			<p>A common practice in IT projects was to have a fixing phase, something that Gerald Weinberg describes in his book <em class="italic">Perfect Software and other illusions about testing</em>. The fixing phase was put at the end of the development phase before software was handed over to operations. In DevOps, we don't have a fixing phase because quality is measured and tested as teams go along, during the whole development and operations cycle. This can be seen in the following diagram:</p>
			<div>
				<div id="_idContainer024" class="IMG---Figure">
					<img src="image/B17492_03_002.jpg" alt="Figure 3.2 – Continuous testing (based on TMAP) &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.2 – Continuous testing (based on TMAP) </p>
			<p>How do you measure quality? First, what is quality? We started this book by saying that it all starts with the business. That's<a id="_idIndexMarker201"/> why <strong class="bold">enterprise architects</strong> have such an important role <a id="_idIndexMarker202"/>to play in DevOps. Enterprise architects have a major task in translating business needs into solutions. From business demand, the product portfolio should be clear about what standards these products should be delivered to. That's quality. It's a product or service that meets the needs and expectations of the user. Quality is a product or service that satisfies the users. Hence, testing is about validating if the user can be satisfied with the delivered product or service.</p>
			<p>What do enterprises measure in terms of DevOps quality? Two main things: the build itself and its <em class="italic">functional validation</em>. For the build itself, topics such as the number of successful builds, the total number of defects, and code coverage are important. For functional validation, the main topics are whether all the requirements have been tested and if all the identified risks have been covered.  </p>
			<p>In the next few sections, we will learn what instruments we can use to define quality and how to measure it, starting with acceptance criteria. </p>
			<h2 id="_idParaDest-43"><a id="_idTextAnchor044"/>Defining acceptance criteria</h2>
			<p>Before we can <a id="_idIndexMarker203"/>start testing, we need to know what we will be testing. That's why we need to define <strong class="bold">acceptance criteria</strong>. To put it very simply: when is good, <em class="italic">good enough?</em> Again, it starts with the user story, which defines what a product or service should include. The user story sets the scope and the specific functionality a product or service must have. </p>
			<p>How do you set acceptance criteria? The question is, <em class="italic">what is it that we're building?</em> "It" must be specified and with that, "it" must become tangible. The DevOps team looks at specifications from four angles:</p>
			<ul>
				<li><strong class="bold">Business</strong>: What does the business require?</li>
				<li><strong class="bold">Development</strong>: How can we build a solution that meets the business requirements?</li>
				<li><strong class="bold">Quality</strong>: How can we test the solution and validate that it meets the requirements?</li>
				<li><strong class="bold">Operations</strong>: How can we manage the solution so that it keeps meeting these requirements? </li>
			</ul>
			<p>In DevOps, we're<a id="_idIndexMarker204"/> not building the whole package at once, as in a waterfall type of project. The team starts with a minimal viable product and then iterates the product, continuously improving it. Acceptance criteria are set per requirement and thus, following the logic of DevOps and quality measures, each requirement is<a id="_idIndexMarker205"/> tested. This is what <strong class="bold">test-driven development</strong> (<strong class="bold">TTD</strong>) does. In TDD, the team writes the test case first and then the code. The code is written to the specifications of the test case, proving that the requirements have been met. The TDD flow is shown in the following diagram:</p>
			<div>
				<div id="_idContainer025" class="IMG---Figure">
					<img src="image/B17492_03_003.jpg" alt="Figure 3.3 – Test-driven development&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.3 – Test-driven development</p>
			<p>TDD is nothing <a id="_idIndexMarker206"/>new and has existed since the mid-fifties, but the most commonly used version is described by Kent Beck (refer to the <em class="italic">Further reading</em> section). The team picks a requirement, writes the test case, develops the code, and runs the test. When the tests are successful, the code is refactored or rewritten, meaning that the code is cleaned and remediated to the standards the architect has set for the code. After this step, the code is tested once more with the test case. This cycle is repeated for every requirement.  </p>
			<p>The next steps are<a id="_idIndexMarker207"/> assessing the Definition of Ready and agreeing on the Definition of<a id="_idIndexMarker208"/> Done. We will study them in the next section.</p>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor045"/>Defining the Definition of Ready and Definition of Done</h2>
			<p>In the <a id="_idIndexMarker209"/>previous section, we learned how to set acceptance<a id="_idIndexMarker210"/> criteria and how TDD can help in making sure that we meet a specific requirement. However, a product or service likely has many requirements before it can really be launched into production. </p>
			<p>In DevOps, we use two important processes to validate if a fully developed product or service is ready for production. These processes are the <strong class="bold">Definition of Ready </strong>(<strong class="bold">DoR</strong>) and the <strong class="bold">Definition of Done</strong> (<strong class="bold">DoD</strong>).</p>
			<p>To avoid mistakes, bear in mind that the acceptance criteria are not the same in both DoR and DoD:</p>
			<ul>
				<li><strong class="bold">Definition of Ready</strong>: To understand DoR, it's important to know how <em class="italic">Agile Scrum</em> works. DevOps<a id="_idIndexMarker211"/> teams typically work in sprints, a short period of time in which a piece of the product is developed. The work that needs to be done is defined in <strong class="bold">product backlog items</strong> (<strong class="bold">PBIs</strong>). The whole product or service is defined in a <a id="_idIndexMarker212"/>user story and then broken down into PBIs – tasks that a team can work on during a specific sprint and that can be completed during that sprint.  <p>Agile Scrum actually doesn't mention DoR. Yet, it has become a common practice to have a set of agreements to define when PBIs are ready to be picked up by the team. The problem with user stories is that, in some cases, they don't contain enough concrete information to start the build. The DoR contains entry criteria so that the team knows what to build. The process of defining the DoR is referred to as refinement. </p></li>
				<li><strong class="bold">Definition of Done</strong>: In <a id="_idIndexMarker213"/>contrast to DoR, the DoD is part of Agile Scrum and describes exactly what a <strong class="bold">Product Backlog Items </strong>(<strong class="bold">PBI)</strong> looks like when it's finished. So, the DoD is a very strong instrument for validating the quality of the builds. Developers commit to the DoD. They commit to the fact that they must be absolutely clear about what they need to build. In IT projects, the DoD <a id="_idIndexMarker214"/>must contain the following topics as a minimum:<p>- All the code has been written.</p><p>- All the code has been reviewed and validated.</p><p>- The relevant documentation has been written and made available.</p><p>- All the tests have been executed and signed off.</p><p>- All functionality has been proven to be delivered.</p><p>Where the DoR takes care of the entry criteria, the DoD contains the exit criteria – the statement <a id="_idIndexMarker215"/>of completion. All team members<a id="_idIndexMarker216"/> must agree upon the DoD: the business, developers, testers, and operations. Don't forget the last group, where operations need to sign off the DoD and run the software. For them, it's crucial to validate that the code and relevant documentation are completed. Furthermore, in true DevOps, we will not have separate developers, testers, or members doing operations. Instead, we will have members with skills in development or testing. </p></li>
			</ul>
			<p>So far, we have discussed the test strategy, the quality measures, and the acceptance criteria. In the next section, we will learn how to design test automation and execution. </p>
			<h1 id="_idParaDest-45"><a id="_idTextAnchor046"/>Designing test automation and execution</h1>
			<p>In this section, we<a id="_idIndexMarker217"/> will learn how to design and implement<a id="_idIndexMarker218"/> tests. We will study the most common different test varieties and learn where we can use them. When we start discussing testing in IT, we need to discuss and agree upon a test management approach. In this book, we will use TMAP, introduced by ICT service provider Sogeti in 1995 and widely accepted as the standard in software testing.</p>
			<p>The traditional phases of TMAP are as follows:</p>
			<ul>
				<li>Planning</li>
				<li>Preparation</li>
				<li>Specification</li>
				<li>Execution </li>
				<li>Evaluation</li>
			</ul>
			<p>In DevOps, this is not a one-off exercise; we will be working with continuous testing. One major difference with the traditional way of working is that there's no separate test unit with a manager and testers. These professionals are now part of the DevOps team and they do their work alongside the developers. Next, in DevOps, we are working according to<a id="_idIndexMarker219"/> the <em class="italic">everything as code</em> principle, thus allowing teams to automate as much as <a id="_idIndexMarker220"/>possible. </p>
			<p>Before we learn more about continuous testing, we need to understand the various types of testing. The most important ones are as follows:</p>
			<ul>
				<li><strong class="bold">Process focused</strong>: The test focuses on the paths and flows in software. In TMAP, this is<a id="_idIndexMarker221"/> called <strong class="bold">path coverage</strong>. The test covers the path that a transaction follows to reach a certain end stage. This can become very complicated when lots of paths need to be followed. In that case, the test covers all possible paths and various decision points.  </li>
				<li><strong class="bold">Condition focused</strong>: A condition can be a decision point. The test covers the decision points and the conditions that it points to be either <em class="italic">true</em> or <em class="italic">false</em>. The question is how that will influence the outcome of the test. Be aware that this is a very simple explanation. In theory, software will have many decision points with specific <a id="_idIndexMarker222"/>conditions, thus influencing the outcome of the test. In a <strong class="bold">Condition Decision Coverage</strong> (<strong class="bold">CDC</strong>) test, all decision points and decision outcomes will be tested against the condition <em class="italic">true</em> or <em class="italic">false</em>. </li>
				<li><strong class="bold">Data focused</strong>: This test uses data input to verify the test results. This type of test is commonly <a id="_idIndexMarker223"/>done through <strong class="bold">boundary value analysis</strong> (<strong class="bold">BVA</strong>). In the test, we enter the minimum and the maximum values, known as the <em class="italic">boundaries</em>. These can be numeric, but also <em class="italic">statements</em>. If we then, as a test case, enter a value that's outside these boundaries, the result should be "invalid." Any input within the range that is specified should lead to the result "valid."   </li>
				<li><strong class="bold">Experience focused</strong>: These are more often referred to as <strong class="bold">user experience</strong> (<strong class="bold">UX</strong>) tests. All <a id="_idIndexMarker224"/>of the previous tests are binary. The software follows the expected paths, the <a id="_idIndexMarker225"/>conditions of the decision points lead to<a id="_idIndexMarker226"/> expected results, and the entered data gives the expected results. Experience is something completely different since it's very subjective by nature. Yet, testers would like to know how the software "feels." Is it responsive enough, does it perform well, and is it easy to use? The basic question is: <em class="italic">is there a way to test experience in an objective manner?</em> There are some methodologies that aim for this, with one of them being the "experience honeycomb," which was developed in 2004 by Peter Morville. This can be seen in the following diagram:</li>
			</ul>
			<div>
				<div id="_idContainer026" class="IMG---Figure">
					<img src="image/B17492_03_004.jpg" alt="Figure 3.4 – The experience honeycomb&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.4 – The experience honeycomb</p>
			<p>Still, experience <a id="_idIndexMarker227"/>remains a bit intangible. It's very useful for finding <a id="_idIndexMarker228"/>out whether software is meeting the user's expectations, but to find faults and issues in the software, testers will need to perform more exact tests. Note that experience-oriented tests are very hard to automate. </p>
			<p>Again, testing in DevOps is not a one-off. In the next section, we will discuss continuous testing.</p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor047"/>Understanding the principles of continuous testing</h2>
			<p>In <a href="B17492_02_ePub_RK.xhtml#_idTextAnchor027"><em class="italic">Chapter 2</em></a>, <em class="italic">Managing DevOps from Architecture</em>, we learned about the CI/CD pipeline. We <a id="_idIndexMarker229"/>saw that testing was an integrated part of the pipeline. This assumes that all software is developed using CI/CD, which, in enterprises, is often not the case. There will still be, as an example, legacy systems that are not integrated in CI/CD. The same applies <a id="_idIndexMarker230"/>to <strong class="bold">Software as a Service</strong> (<strong class="bold">SaaS</strong>) applications: these are purchased as a service, and for that reason, not "developed" within the enterprise. However, they need to be tested. </p>
			<p>The first step in continuous testing is <a id="_idIndexMarker231"/>automating the <strong class="bold">test cases</strong>. This is easier said than done, but it's feasible if tests have been set up from known patterns – for instance, simulating how a user would use the application. If we have an application that processes purchases, we could think of three use patterns: </p>
			<ul>
				<li>Place an order</li>
				<li>Cancel an order</li>
				<li>Check the order's status</li>
			</ul>
			<p>Steps can be automated and with that, we can create a test case that can be executed. </p>
			<p>Once we have the test cases and the code that needs to be tested, we need an environment where we can execute the tests. This can also be automated. By using the public cloud, it's easy to create a (temporary) test environment on demand and decommission it automatically when the tests have run. It could even be part of the full test scenario, where you can spin up an environment in Azure, AWS, or any other cloud, deploy the code (or rather, a copy of the source code), run the tests, and decommission the environment after completion. This does require automated infrastructure to set up and <strong class="bold">Infrastructure as Code</strong> (<strong class="bold">IaC</strong>) to <a id="_idIndexMarker232"/>be implemented, something that we will discuss later in this section. </p>
			<p>In summary, continuous testing requires the following:</p>
			<ul>
				<li><em class="italic">Integrated quality engineering and testing</em>: Testing is an integrated part of the DevOps team – meaning that every member of the team is involved in testing. However, in large enterprises running multiple DevOps projects, it is recommended to have a quality team that helps implement quality measures and tests the strategies in these projects.  </li>
				<li><em class="italic">Automated test cases</em>: It's recommended to start small. Pick one test case and automate that. Set the baseline for this test case: what data is absolutely required to run a successful test? What metrics will be used and for how long will a test need to run? Don't make tests too big; use small test sets and run them for a short period of time. Evaluate and, if needed, adjust the test sets and their duration.  </li>
				<li><em class="italic">Test tools</em>: These tools need to integrate with the CI/CD pipelines. This book is not about test<a id="_idIndexMarker233"/> tooling, but some popular tools are <strong class="bold">Selenium</strong> and <strong class="bold">Micro Focus Unified Functional Testing</strong> (<strong class="bold">UFT</strong>). How do you pick the right tools? That<a id="_idIndexMarker234"/> really depends on your approach. Some enterprises prefer a single stack solution, meaning that one tool covers the whole testing strategy. Others have a toolset, using separate<a id="_idIndexMarker235"/> tools for test modeling and test execution. Again, integration with the CI/CD pipeline is crucial. </li>
				<li><em class="italic">Automated test environments</em>: Automate how the test data is provisioned, how the test case is executed, and how the test environments are provisioned using cloud services. Automating environments requires that we define everything as code:<p>a) <strong class="bold">Infrastructure as Code</strong> (<strong class="bold">IaC</strong>): Virtual <a id="_idIndexMarker236"/>machines, network <a id="_idIndexMarker237"/>components, containers, firewalls – everything<a id="_idIndexMarker238"/> is defined as code. In Azure, we use <strong class="bold">Azure Resource Manager</strong> (<strong class="bold">ARM</strong>) templates, and in AWS, the preferred way of working is to use <strong class="bold">CloudFormation</strong>. </p><p>b) <strong class="bold">Configuration as Code</strong> (<strong class="bold">CaC</strong>): As soon as infrastructure components are deployed, they<a id="_idIndexMarker239"/> need to be configured so that they match<a id="_idIndexMarker240"/> the standards and policies of the enterprise. Think of DNS settings, certificates, and security policies such as hardening and patching. Once the configuration has been applied, we reach the <strong class="bold">Desired State Configuration</strong> (<strong class="bold">DSC</strong>). </p><p class="callout-heading">Important Note</p><p class="callout">DSC is a term that is typically associated with Microsoft Azure. In this book, we will use DSC as a generic term to explain that the cloud infrastructure needs to meet specific requirements, as defined by the architecture, in order to be compliant.  </p><p>c) <strong class="bold">Pipeline as Code</strong> (<strong class="bold">PaC</strong>): Every<a id="_idIndexMarker241"/> step in the CI/CD process is defined in code, from pulling the source code to its actual deployment, including the test procedures.</p><p>d) <strong class="bold">Test as Code</strong> (<strong class="bold">TaC</strong>): Test as <a id="_idIndexMarker242"/>code refers to the test automation process itself, from collecting, assessing, and deploying test data to actually executing (running) the various tests and collecting the results. We can also validate the results automatically using <em class="italic">artificial intelligence</em> and <em class="italic">machine learning</em>.  </p></li>
			</ul>
			<p>In this section, we learned all about testing as a methodology to validate quality in DevOps projects. We saw that automation can bring a lot of value to our testing strategy. One<a id="_idIndexMarker243"/> important remark must be made as a conclusion: <em class="italic">it's not about automation itself</em>. The goal should be to optimize the builds and improve their quality. It's the quality value that matters, not the test itself. Tests will help teams improve the quality of their work by identifying risks and helping them understand how to mitigate issues. That's what we will talk about in the next section. We've found a problem – <em class="italic">now what?</em>  </p>
			<h1 id="_idParaDest-47"><a id="_idTextAnchor048"/>Understanding root cause analysis</h1>
			<p>In the previous <a id="_idIndexMarker244"/>sections, we discussed quality measures and testing to validate these criteria in a highly structured and automated way. Still, things can go wrong. The golden rule in DevOps is <em class="italic">you build it, you run it</em>, often followed by the statement <em class="italic">you break it, you fix it</em>. Or even it could be <em class="italic">you destroy it, you rebuild it better</em>. If something breaks, the team will need to find out what exactly happened. In this section, we will talk about <strong class="bold">root cause analysis</strong> (<strong class="bold">RCA</strong>) as one of the most important instruments for finding the cause of a problem. </p>
			<p>RCA is the methodology for finding the exact cause of an issue. With that, RCA provides insights on how the team can improve products or services. These can be quick fixes or long-term enhancements. RCA is more than just a way to find problems; it's the start of improvement. Important questions that need to be addressed in RCA are as follows:</p>
			<ul>
				<li>What is the problem?</li>
				<li>Where was it found?</li>
				<li>Why did the problem occur?</li>
				<li>What caused the problem?</li>
				<li>What improvements can we make to avoid the problem in the future?</li>
			</ul>
			<p>There are several ways to conduct an RCA. Popular methods are the <em class="italic">5 whys</em> and the <em class="italic">fishbone</em> diagram (also known as the <em class="italic">Ishikawa</em> diagram). The 5 whys method is an easy way to literally drill down to the root cause of a problem, simply by asking "why" five times. It's a bit like a little child that constantly repeats the same question up until the point where it's satisfied with the answer. </p>
			<p>The fishbone, invented by <a id="_idIndexMarker245"/>Professor Ishikawa, is more suitable for drilling down to more complex issues. Again, it starts with the problem and then the team identifies what could contribute to that problem: infrastructure, code, programmers, and so on. These are the "fish bones." Each of the bones is then analyzed. The basic diagram for this is as follows: </p>
			<div>
				<div id="_idContainer027" class="IMG---Figure">
					<img src="image/B17492_03_005.jpg" alt="Figure 3.5 – Fishbone diagram&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.5 – Fishbone diagram</p>
			<p>Regardless of the methodology, the basic steps for RCA are always the same, as shown in the following diagram:</p>
			<div>
				<div id="_idContainer028" class="IMG---Figure">
					<img src="image/B17492_03_006.jpg" alt="Figure 3.6 – Steps of RCA&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.6 – Steps of RCA</p>
			<p>The RCA starts by gathering data to find out what exactly happened. The next step is the problem statement: when did it happen, where, and what is the impact of the problem? The last question in particular – <em class="italic">what is the impact?</em> – is important. It drives prioritization in the project and the business case. If the impact is low but the mitigation solution will require a huge investment in time and thus costs, the team might decide to give it a low priority and put it on the backlog of the project. If the problem has a high impact, it might become an impediment. It needs to be solved before the team picks up any new tasks. It's one of the main principles in <em class="italic">Site Reliability Engineer</em>, which we will discuss in detail in <a href="B17492_05_ePub_RK.xhtml#_idTextAnchor066"><em class="italic">Chapter 5</em></a>, <em class="italic">Architecting Next-Level DevOps with SRE</em>. </p>
			<p>After analyzing the cause and the impact, the team can work on solutions to mitigate the problem. The last step is the final report. It's a common practice to test the solution first and validate if the solution is really solving the problem. RCA is a quality measure and quality<a id="_idIndexMarker246"/> measures need to be tested, as we learned in the previous sections. </p>
			<p>With that, we have discussed testing and how to handle RCA to improve the product by finding solutions for problems. But as with everything in DevOps, we are aiming for continuous improvement. That also includes roadmaps for improving the building blocks themselves, known as the infrastructure, the coding framework, and the DevOps environment. That's the topic of the next section.  </p>
			<h1 id="_idParaDest-48"><a id="_idTextAnchor049"/>Designing for remediation</h1>
			<p>So far, we've<a id="_idIndexMarker247"/> talked about coding the software, implementing the required infrastructure, automating it all through CI/CD pipelines, testing the environments, detecting issues, and, if needed, fixing the problems. But there's something that we haven't been discussing yet and that's the speed of software development and DevOps itself. </p>
			<p>DevOps is about learning. As the team and projects grow, they learn how to improve. They learn from the product itself and how it's used, and they learn from looking at other projects, technologies, and methodologies. These lessons are adopted and injected into their own project. The team doesn't need to start over, though – they can adopt and adapt as they proceed. We <a id="_idIndexMarker248"/>call this <strong class="bold">remediation</strong>, which is the process of improving an existing situation.   </p>
			<p>Remediation can take place on three levels, as follows: </p>
			<ul>
				<li><em class="italic">Infrastructure</em>: Assuming that we build everyone according to the "everything as code" principles in public clouds such as Azure or AWS, teams will have to take into account that these platforms evolve rapidly. It's the responsibility of the architect to "track" the roadmap of the cloud services, and then decide whether to include<a id="_idIndexMarker249"/> new features in the roadmap of the project and improve the infrastructure. </li>
				<li><em class="italic">Software/application code</em>: Software developers work in code frameworks or versions, such as <em class="italic">.NET</em>. The<a id="_idIndexMarker250"/> framework contains the <strong class="bold">Framework Class Library</strong> (<strong class="bold">FCL</strong>), which holds the languages that code can be written in to ensure interoperability between different platforms. By using compilers, code written in C#, VB.net, and J# (Java) is translated<a id="_idIndexMarker251"/> into <strong class="bold">Common Language Infrastructure</strong> (<strong class="bold">CLI</strong>) so that it runs on Windows platforms without us having to write machine code directly. CIL produces executables that can run on Windows and various Linux distributions such as <strong class="bold">Red Hat Enterprise Linux</strong> (<strong class="bold">RHEL</strong>), Ubuntu, Debian, Fedora, CentOS, Oracle, and SUSE. .NET is just one <a id="_idIndexMarker252"/>example. Other frameworks include ASP.NET, Java, Python, PHP, and JavaScript. They all run specific versions and developers must make sure that their code is running a supported version. Again, it's recommended to have the framework versions set out in a technology roadmap to keep track of the life cycles.    </li>
				<li><em class="italic">DevOps</em>: Finally, DevOps itself has various implementations, typically in combination with a specific way of agile working. In other words, it's not only the tool or toolsets that change, although it's important to keep track of the DevOps tool roadmaps. It's crucial for source control. For example, Azure DevOps – widely used to run DevOps projects in Azure – currently runs Azure DevOps Server 2020 as a version control system, allowing developers to work together on code and track changes. </li>
			</ul>
			<p>The key takeaway from this section is basically to never stop learning and never stop improving. IT is changing rapidly and so is DevOps. DevOps teams have a great responsibility in staying ahead so that the business really can benefit from new developments. It's<a id="_idIndexMarker253"/> the architect that has the responsibility of guiding the teams in this and making the right decisions. With that, the architect should focus on <em class="italic">quality</em>.  </p>
			<h1 id="_idParaDest-49"><a id="_idTextAnchor050"/>Summary</h1>
			<p>This chapter was all about quality. We learned how to identify quality measures and that this is more than just about fixing bugs. Quality is about meeting expectations, but DevOps teams need to be able to measure these expectations. That's why businesses, developers, and operators need to be clear on the acceptance criteria. In this chapter, we discussed the DoR as an entry point to working on a project and DoD for measuring whether a product is really complete. </p>
			<p>Measuring means that teams have to test. In a traditional way of working, testing is done as soon as the whole product is delivered. In DevOps, we work with continuous testing. In other words, all the team members are involved in testing and validating the quality of the product. In this chapter, we discussed different ways and types of testing that are common in DevOps. Lastly, we talked about continuous improvement using remediation. Cloud platforms, software development technology, and DevOps tools are constantly evolving, and DevOps teams need to adapt and adopt these changes in their projects to allow businesses to benefit. </p>
			<p>The role of the architect is crucial in that they need to guide in these developments and enable the team to make the right decisions.</p>
			<p>In the next chapter, we will discuss scaling DevOps. We start small, but in enterprises, we need to scale out if we want an entire business to start working agile and work in DevOps teams. On this note, what do we do with existing programs and projects? Let's find out!  </p>
			<h1 id="_idParaDest-50"><a id="_idTextAnchor051"/>Questions</h1>
			<ol>
				<li>In this chapter, we discussed different types of tests. One of them is unit tests. Give a short description of a unit test.</li>
				<li>In a data-oriented test, we enter the minimum and the maximum values. If we enter a value within these boundaries, the test result should be valid. What is this test method called?</li>
				<li>To decide if a product is complete, DevOps uses a certain technique. What is this technique called?</li>
				<li><em class="italic">True or False</em>: A fishbone diagram is a good practice for analyzing the root cause of a problem. </li>
			</ol>
			<h1 id="_idParaDest-51"><a id="_idTextAnchor052"/>Further reading</h1>
			<ul>
				<li><em class="italic">Quality for DevOps Teams</em>, by Rik Marselis, Berend van Veenendaal, Dennis Geurts and Wouter Ruigrok, Sogeti, 2020</li>
				<li><em class="italic">Test-Driven Development: By Example</em>, by Kent Beck, 2002</li>
			</ul>
		</div>
	</body></html>