<html><head></head><body>
		<div id="_idContainer037">
			<h1 id="_idParaDest-52"><em class="italic"><a id="_idTextAnchor053"/>Chapter 4</em>: Scaling DevOps</h1>
			<p>DevOps started—and is in some companies still done—with a lot of manual tasks, scripts, and ad hoc tests. A lot of enterprises focus on the applications and tend to forget about the platform itself—the infrastructure—but this is also crucial to the scaling. This chapter focuses on the scaling of DevOps, both from a technical and an organizational perspective. </p>
			<p>After completing this chapter, you will have learned how to handle scaling. First, we will learn about modern DevOps, which adopts cloud and cloud-native technology as target platforms to run applications. Before we can do that, we probably need to transform the applications; otherwise, we will develop new applications. In DevOps, we need a development method that fits to the way of working; therefore, we will discuss <strong class="bold">rapid- application development</strong> (<strong class="bold">RAD</strong>). Next, we will look at adopting DevOps throughout a whole enterprise, starting small and then expanding. Finally, we will have a look at mission-critical environments and how we can manage them in a DevOps mode.  </p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Understanding modern DevOps</li>
				<li>Working with RAD</li>
				<li>Scaling infrastructure with DevOps</li>
				<li>Scaling DevOps in enterprise environments</li>
				<li>Managing mission-critical environments with DevOps</li>
			</ul>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor054"/>Understanding modern DevOps </h1>
			<p>The concept of <a id="_idIndexMarker254"/>DevOps is not new. Basically, the idea was that teams could improve their work if developers and operators were really working together as one team. The reason for that was easy to find, as we've already seen in <a href="B17492_01_ePub_RK.xhtml#_idTextAnchor013"><em class="italic">Chapter 1</em></a>, <em class="italic">Defining the Reference Architecture for Enterprise DevOps</em>. In this section, we will learn how DevOps has evolved over the years and what the impact of modern DevOps has been on <a id="_idIndexMarker255"/>enterprise <strong class="bold">information technology</strong> (<strong class="bold">IT</strong>). We will also study how DevOps helps in transforming legacy applications by app modernization. </p>
			<p>A lot of enterprises decided in the 1990s that IT was not a core business and could be outsourced to suppliers. Typically, all management—operations—of commodity IT was outsourced. It created not only silos within enterprises, but also outside of them. Over time, IT got more complex, demands increased, and enterprises found themselves in a position of having to find ways to get back into the driving seat of IT, which had become core for the business. </p>
			<p>In 2009, the first <strong class="bold">DevOps Days</strong> conference was held in Belgium. The base idea: break down the silos, put <a id="_idIndexMarker256"/>developers and operations back in one team, and increase the quality and velocity of software development. These are still the goals of DevOps. That hasn't changed over the years. </p>
			<p>But it doesn't mean that DevOps hasn't changed at all. The main differentiators are cloud technology and automation. These are the <a id="_idIndexMarker257"/>two most important pillars of modern DevOps and are outlined as follows:</p>
			<ul>
				<li><strong class="bold">Cloud</strong>: One of the main issues in early DevOps was the availability of development and test systems. In modern cloud platform deployments, even temporary systems have become much easier.</li>
				<li><strong class="bold">Cloud native</strong>: Silos between developers and operations have been broken down, but the same applies for technical silos in different platforms. Interoperability between systems has become the standard in cloud native, with the <a id="_idIndexMarker258"/>entrance and emergence of <strong class="bold">Platform as a Service</strong> (<strong class="bold">PaaS</strong>), <strong class="bold">Software as a Service</strong> (<strong class="bold">SaaS</strong>), container <a id="_idIndexMarker259"/>technology, and serverless functions. The major two developments in IT for the near future are likely software to services and <strong class="bold">virtual machines</strong> (<strong class="bold">VMs</strong>) to <a id="_idIndexMarker260"/>containers, increasing portability across cloud platforms and even between on-premises systems and cloud systems.  </li>
				<li><strong class="bold">Automation</strong>: Automate as much as possible. This means that in modern DevOps, we should perceive everything as code—not only the application code, but infrastructure, configuration, and integration as well. In <a href="B17492_02_ePub_RK.xhtml#_idTextAnchor027"><em class="italic">Chapter 2</em></a>, <em class="italic">Ma</em><em class="italic">naging DevOps from Architecture</em>, we discussed pipelines for the deployment of applications and infrastructure, but in modern DevOps everything is built through pipelines. </li>
				<li><strong class="bold">All code is stored in a repository</strong>: Applications, infrastructure, tools, governance, and security are translated into code, and with everything as code, we can have everything in pipelines. So, besides a deployment pipeline for application code and a pipeline for infrastructure, we will also have pipelines for tool configurations, integrations, reports, and security. </li>
				<li><strong class="bold">Integrated security</strong>: For security, we <a id="_idIndexMarker261"/>will have DevSecOps, which starts with Security as Code. The security posture of enterprises is translated into code and managed from a single repository. The development of the security posture is handled in the same <a id="_idIndexMarker262"/>way as the development of applications and infrastructure, by continuous improvement and not solely by reacting to attacks, threats, or breaches. Code that has been developed will immediately be merged with the security code, integrating the security posture. Security is developed at the same speed as applications and infrastructure. <em class="italic">Section 3</em> of this book, <em class="italic">Bridging Security with DevSecOps</em>, is entirely about implementing DevSecOps, starting with <a href="B17492_12_ePub_RK.xhtml#_idTextAnchor145"><em class="italic">Chapter 12</em></a>, <em class="italic">Architecting for DevSecOps</em>.   </li>
				<li><strong class="bold">Enhanced technology</strong>: Modern DevOps is sometimes referred to as <em class="italic">accelerated</em> or intelligent DevOps. With <a id="_idIndexMarker263"/>enhanced technologies <a id="_idIndexMarker264"/>such as <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>), <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>), and <strong class="bold">robotic process automation</strong> (<strong class="bold">RPA</strong>), automation <a id="_idIndexMarker265"/>can really be leveraged. Examples are self-healing systems or code and pipelines that <em class="italic">learn</em> autonomously from previous deployments. With RPA, processes can be highly automated and, if combined with AI/ML, think about logical next steps in deployments—for instance, by learning from test results or system behavior. <strong class="bold">Artificial Intelligence IT Operations</strong> (<strong class="bold">AIOps)</strong> is a good example of this development. <a href="B17492_08_ePub_RK.xhtml#_idTextAnchor095"><em class="italic">Chapter 8</em></a>, <em class="italic">Architecting AIOps,</em> and <a href="B17492_09_ePub_RK.xhtml#_idTextAnchor111"><em class="italic">Chapter 9</em></a>, <em class="italic">Integrating AIOps in DevOps</em>, will provide deep dives into AIOps.     </li>
			</ul>
			<p>To summarize, modern DevOps is more about this:</p>
			<ul>
				<li>Involving all stakeholders—it's not only about developers and operations, but also about business managers, security specialists, quality and assurance managers, and procurement (think of licenses).</li>
				<li>Cloud and cloud-native adoption, including containers, functions, and automated services.</li>
				<li>Thinking in code, and therefore in pipelines. Keep in mind that with everything as code and deep automation, we also need to think about the principle of trust. We need to make sure that the code and assets we have in our pipelines are trusted. Next, who is mandated to state that assets are trusted and may be applied to the pipeline? Is that the security engineer, or can it be delegated to the developer? Or, can delegation even be automated if we have systems that adhere <a id="_idIndexMarker266"/>to the <strong class="bold">principle of least privilege</strong> (<strong class="bold">POLP</strong>)? Segregation of duties becomes very important—controls are required to protect code from unauthorized changes.    </li>
			</ul>
			<p>In this section, we <a id="_idIndexMarker267"/>discussed changes to DevOps over the years. The reason for enterprises adapting DevOps is to modernize IT as a whole. Enterprises have a long history (also in IT), and therefore typically have complex, large IT ecosystems with legacy applications. App modernization has become an important topic in modern DevOps, and the next section will talk about that. </p>
			<h2 id="_idParaDest-54"><a id="_idTextAnchor055"/>Introducing and understanding app modernization</h2>
			<p>DevOps, the cloud, automation, and code are all key principles of digital transformation. But many enterprises will <a id="_idIndexMarker268"/>have core applications that they <a id="_idIndexMarker269"/>have been running for a long time: legacy systems not fit to adopt DevOps or even ready to migrate to the cloud. In this section, we will discuss the process of application modernization: the process of transforming these applications to systems that we can run in the cloud, keeping up to date with modern technologies, and supporting the business by being able to adapt to new demands faster. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">App modernization is a huge market. A number of companies such as IBM and Fujitsu have massive programs to transform <a id="_idIndexMarker270"/>mainframe applications to cloud providers such as <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>), even <a id="_idIndexMarker271"/>running <strong class="bold">common business-oriented language</strong> (<strong class="bold">COBOL</strong>). The reason for enterprises <em class="italic">shifting</em> their old mainframe applications to the cloud is easy to understand. The original code is left intact as much as possible, but it's moved from expensive on-premises equipment to pay-as-you-go cloud environments, where risks are fairly low. The downside is that companies will still need to have resources with COBOL programming skills to maintain the app itself. In other words, the application itself is still legacy and will probably not be able to adopt and benefit from new cloud-native technology. The next step would be to also modernize the application by, for instance, rewriting the code or rebuilding the functionality in a completely new application. </p>
			<p>Enterprises can <a id="_idIndexMarker272"/>follow a number of strategies in <a id="_idIndexMarker273"/>app modernization, such as the following ones:</p>
			<ul>
				<li><strong class="bold">Rehosting</strong>: This is the lift and shift of existing systems <em class="italic">as they are</em>. The application is picked up and moved to another target platform. The application is not changed in any way whatsoever. However, moving an application from—for instance—an on-premises environment to AWS or Azure will imply some modifications, especially in connectivity. These modifications will be very minimal and will not impact the application itself. A common way of rehosting is exporting the VM, including the operating system and application code as a whole, to the new cloud environment. It's a fast way to migrate applications to the cloud, but by doing so, enterprises will not experience real benefits from cloud services. They simply run their machines in another data center—in this case, the cloud data centers of AWS, Azure, or any other public cloud provider.  </li>
				<li><strong class="bold">Replatforming</strong>: With replatforming, applications are optimized to run in the cloud. A very common example is replatforming databases to PaaS. Database instances are <a id="_idIndexMarker274"/>moved to AWS <strong class="bold">Relational Database Service</strong> (<strong class="bold">RDS</strong>) or Azure <strong class="bold">Structured Query Language</strong> (<strong class="bold">SQL</strong>), both <a id="_idIndexMarker275"/>native database services managed by the platforms. Developers will still be able to program databases the way they're used to, but they don't need to worry anymore about the database platform itself. That is taken care of by the provider.   </li>
				<li><strong class="bold">Refactoring</strong>: Sometimes referred to as rearchitecturing. In this case, the application code is modified to run in an optimized way in the cloud. Cloud-native services are applied. Application code might be rewritten to run in containers or with serverless functions. The functionality of the application remains as it is: only the underlying technology is changed. Take the COBOL example at the beginning of this section: COBOL could be rewritten to C# or Java. However, architects and engineers would first need to decouple the business logic from the code itself. If the business requires the business logic to be modified as well, then the strategy changes to rebuilding. </li>
				<li><strong class="bold">Rebuilding</strong>: In the case of a <a id="_idIndexMarker276"/>rebuild, architects start with revalidating the functionality of the application. What is the functionality that the business requires, which data will be used, and how does it translate into the usage of an application? Next, the application is rebuilt on the validated business and technical requirements. The functionality returns, the technology is completely revisited, and the application is rebuilt.  </li>
			</ul>
			<p>Now, rehosting will <a id="_idIndexMarker277"/>not bring real benefits in terms of costs. Cost savings might be achieved when applications are replatformed or refactored, since the use of cloud resources will be optimized. </p>
			<p>Rebuilding is a different story. This might lead to major projects that will inflict project costs. As soon as the application is ready to be pushed to production in the cloud, substantial savings might be achieved. However, enterprises need to take the total cost of ownership into account, thus including the project costs and possible risks in rebuilding an application. Enterprise architects play an important role in advising and supporting decisions. The following screenshot shows a very simple overview of cloud cost components:</p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B17492_04_001.jpg" alt="Figure 4.1 – Simple overview of cloud and DevOps costs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.1 – Simple overview of cloud and DevOps costs</p>
			<p>What are the <a id="_idIndexMarker278"/>steps an enterprise—and a responsible architect—should take to <a id="_idIndexMarker279"/>start with app modernization? Let's have a look at these here:</p>
			<ul>
				<li><strong class="bold">Importing</strong>: The architect gathers all relevant data about the applications. They can do so through analyzing information from the <strong class="bold">configuration management database</strong> (<strong class="bold">CMDB</strong>) by <a id="_idIndexMarker280"/>using tools to scan the applications, and through workshops with stakeholders such as business and application owners. </li>
				<li><strong class="bold">Assessing and architecting</strong>: The next step is assessing all the data. What does the architecture look like and how could it map to a modern—cloud—architecture? At this stage, the target architecture is defined as well as the <em class="italic">future mode of operations</em>, meaning the way the application is executed and managed. The DevOps mode of working and the use of <strong class="bold">continuous integration/continuous development</strong> (<strong class="bold">CI/CD</strong>) pipelines <a id="_idIndexMarker281"/>are included in the future architecture. This defines the method of transformation. In short: at this stage, the architect defines the <em class="italic">what</em> (what the application and the architecture will look like) and the <em class="italic">how</em> (how we transform the current application to a modern app). The <em class="italic">what</em> and <em class="italic">how </em>together form a solution. </li>
				<li><strong class="bold">Deciding</strong>: Stakeholders are informed on all relevant aspects: functionality of the application, technical realization, risks, and costs. The business case is validated and, based on this, a go/no-go decision is taken to proceed or not. </li>
				<li><strong class="bold">Executing</strong>: The project starts. Deliverables and technical roadmaps have been defined in features, product backlog items, and tasks. Components are refined and pulled into build sprints. Tests are executed, acceptance criteria are validated, and <strong class="bold">definitions of done</strong> (<strong class="bold">DoDs</strong>) are <a id="_idIndexMarker282"/>signed off as the project evolves.</li>
			</ul>
			<p>The following diagram shows the high-level process of app modernization:</p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B17492_04_002.jpg" alt="Figure 4.2 – High-level process of app modernization&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.2 – High-level process of app modernization</p>
			<p>In summary, app modernization is <a id="_idIndexMarker283"/>about <a id="_idIndexMarker284"/>the following:</p>
			<ul>
				<li>A compelling business case. Is it worthwhile to modernize an application? How <em class="italic">core</em> is the application to the business?</li>
				<li>A compelling strategy. Replatform, refactor, or rebuild? Or, is it wise to do a simple lift and shift to the cloud first and start the transformation on the new platform?</li>
				<li>A compelling plan. Have risks been identified? Does the team have the right skills and tools to mitigate these risks? Knowing the risks, is the plan feasible in a number of sprints?</li>
			</ul>
			<p>We've discussed legacy applications and what enterprises can do to modernize these applications, but enterprises will also develop new code and launch new or improved services. Since we are working in a DevOps mode, we have to look at a development methodology that keeps track with that. RAD is a solution. We will learn about RAD in the next section.  </p>
			<h1 id="_idParaDest-55"><a id="_idTextAnchor056"/>Working with RAD</h1>
			<p>So far, we discussed how DevOps breaks <a id="_idIndexMarker285"/>down silos between developers and operations and how it helps in speeding up the development of products, services, and systems. Implementing DevOps will increase the velocity of development, but DevOps in itself is merely a way of structuring planning of development. It helps in planning in iterations: starting with a <strong class="bold">minimal viable product</strong> (<strong class="bold">MVP</strong>) and then <a id="_idIndexMarker286"/>iterating improvements in next versions. DevOps is not about the development of code itself. We need a development methodology for writing the code, but that methodology should <em class="italic">fit</em> with DevOps. In this section, we will look at RAD.</p>
			<p>Why does RAD fit to DevOps and the agile way of working? The main reason is that RAD is agile in itself. RAD starts with prototyping (the MVP) and then focuses on iterations. The emphasis is on the fulfillment of requirements, rather than on planning. It allows developers to realize quick improvements and adjustments during the development cycle. </p>
			<p>Key principles in RAD are furthermore reuse of code and intensive collaboration between the stakeholders: business representatives, architects, developers, testers, engineers, and the end customer that will use the software. Code is constantly reviewed, tested, and validated against the requirements, which are implemented in small improvements. This way, risks that the end product is not meeting the specifications are less likely to occur. The team is in full control of every single small step.  </p>
			<p>To develop according to RAD, the team needs to follow the following five basic steps. These steps completely align with the principles of DevOps:</p>
			<ol>
				<li><strong class="bold">Define requirements</strong>: Gather the business requirements and set the scope, budget, timelines, and the acceptance criteria. Have all stakeholders sign off to ensure that everyone is in agreement of the deliverables and the final product.   </li>
				<li><strong class="bold">Build</strong>: The development starts with the MVP. Next, the MVP is improved in iterations up until the final product is delivered. Keep in mind that in DevOps, developers and operations need to be aligned on the product, so they will have to work closely together. Can operations manage the application or can it be improved? In <a href="B17492_05_ePub_RK.xhtml#_idTextAnchor066"><em class="italic">Chapter 5</em></a>, <em class="italic">Architecting Next-Level DevOps with SRE</em>, we will learn how operations can drive improvements such as automation in development.  </li>
				<li><strong class="bold">Collect feedback</strong>: We learned in the previous chapter that DevOps embraces continuous testing as a quality measurement. This means that feedback is constantly collected. This is technical feedback and feedback on the functionality. Developers use this feedback to improve the next iteration or version. This is also a matter of the DevOps culture: feedback should not be seen as criticism or even a verdict. Feedback is really an instrument to improve quality throughout the project.  </li>
				<li><strong class="bold">Test</strong>: In conjunction with collecting feedback, software is continuously tested. Does the code work properly and is it meeting the requirements? Testing is probably one of the most important things in DevOps projects. In <a href="B17492_03_ePub_RK.xhtml#_idTextAnchor040"><em class="italic">Chapter 3</em></a>, <em class="italic">Architecting for DevOps Quality</em>, we discussed testing strategies and different types of tests.  </li>
				<li><strong class="bold">Publish</strong>: If the product has <a id="_idIndexMarker287"/>reached its final state, it's ready for go-live so that it can be used. Two topics that need attention in a launch are the user training and the period of after-care. Users will need to learn how to use the product and the software, and be prepared that as soon as products go into production and are actually used, issues still might arise. In after-care mode, teams can still pick up these issues fast. <p>However, DevOps already takes care of this in itself. Issues create feedback that is looped back into the project, driving improvements. In practice, teams will create <em class="italic">fast lanes</em> to pick up issues in production with high priority. This might halt the further development of products and the development of new features. Exactly this is <a id="_idIndexMarker288"/>addressed in <strong class="bold">site reliability engineering</strong> (<strong class="bold">SRE</strong>), the main topic of the next chapter.   </p></li>
			</ol>
			<p>To summarize, the RAD process is shown in the following diagram:</p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B17492_04_003.jpg" alt="Figure 4.3 – RAD&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.3 – RAD</p>
			<p>In this section, we <a id="_idIndexMarker289"/>learned how to integrate software development in a DevOps project. Software needs infrastructure to run. In the next section, we will discuss scaling infrastructure.  </p>
			<h1 id="_idParaDest-56"><a id="_idTextAnchor057"/>Scaling infrastructure with DevOps</h1>
			<p>One of the key <a id="_idIndexMarker290"/>features in modern DevOps is the use of cloud technology. In this section, we will discuss why enterprises gain a lot of benefit by <a id="_idIndexMarker291"/>moving infrastructure in cloud platforms such as AWS and Azure. First, we will study the principles of scaling, since this is one of the major benefits of using cloud infrastructure. At the end of the section, we will also touch upon next-level scaling with containers, given the fact that in the coming years, there will be a big shift from VMs to containers.  </p>
			<p>In DevOps projects, developers use pipelines, as we have seen in the previous chapter. Code is pulled from a repository, changed, tested, and pushed to the next stage. Code follows a promotion path: from development to test, acceptance, and—eventually—production systems. Development and test systems might not always be needed; they simply have to be there whenever they are required in the process. If the work is done, then these systems might be suspended or even decommissioned. The benefit of the cloud is that enterprises don't pay for these systems if they're not in use, in contradiction with on-premises hardware that has been purchased as a one-off investment. So, the scaling up of development and test systems on demand is a huge advantage of cloud infrastructure.  </p>
			<p>Another important feature of modern DevOps is automation. A major benefit in using cloud infrastructure is the ability to have automatic scaling. However, architects and engineers might want to be a bit careful with automated scaling. It's true that enterprises pay for what they use in the cloud, whereas in the traditional way of working enterprises would need to buy physical machines whenever extra capacity was needed. The good side about that was that architects really needed to think about the required capacity. </p>
			<p>In the cloud, there <a id="_idIndexMarker292"/>might not be a driver anymore to worry <a id="_idIndexMarker293"/>about capacity. Nothing could be further from the truth, though. In cases of peak demand and automated scaling without setting limits, the cloud bill will turn out to be a surprise. Enterprises, especially financial officers, should therefore not completely rely on scaling. In other words, architects will still have a responsibility to plan capacity. </p>
			<p>Now, let's study the different varieties of scaling, as follows:</p>
			<ul>
				<li><strong class="bold">Vertical or scale-up</strong>: Let's take a <a id="_idIndexMarker294"/>server as an example to <a id="_idIndexMarker295"/>explain this. The server has one processor, 2 <strong class="bold">gigabytes</strong> (<strong class="bold">GB</strong>) of memory, and 100 GB of disk storage. If we scale up, we add processors, memory, or disk storage to that server. We are adding resources to the same machine and increasing its capacity. That can be done as long as there's room in the server to add resources. We can imagine that this is easier in a coded, virtual world than with a physical machine where engineers really need to take out their screwdrivers and mount, for instance, extra memory cards in that server. The following diagram shows the principle of vertical scaling:</li>
			</ul>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/B17492_04_004.jpg" alt="Figure 4.4 – Scale-up or vertical scaling&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.4 – Scale-up or vertical scaling</p>
			<ul>
				<li><strong class="bold">Horizontal or scale-out</strong>: Now, we're <a id="_idIndexMarker296"/>adding more servers to our environment, instead of increasing resources within the server. This is <a id="_idIndexMarker297"/>very common in the public cloud, especially when we're using load balancers to handle traffic and spreading the workloads among the available servers. With automatic scaling, servers or pools of servers can be added automatically whenever the load is increasing and existing servers can't handle it anymore without degrading the performance. As soon as the load decreases, the environment is scaled down again. Load balancers—an example is <strong class="bold">Elastic Load Balancing</strong> (<strong class="bold">ELB</strong>) in AWs—make <a id="_idIndexMarker298"/>sure that the load is evenly spread across available resources. <p>However, keep in mind that applications need to be <em class="italic">scale-aware</em>. Some applications can't handle scaling at all, while some can scale out but can't be scaled down without impacting the availability of the application. The following diagram shows the principle of horizontal scaling:</p></li>
			</ul>
			<div>
				<div id="_idContainer034" class="IMG---Figure">
					<img src="image/B17492_04_005.jpg" alt="Figure 4.5 – Scale-out or horizontal scaling&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.5 – Scale-out or horizontal scaling</p>
			<ul>
				<li><strong class="bold">Full or dynamic scaling</strong>: This is a <a id="_idIndexMarker299"/>combination of vertical and horizontal scaling. As soon as limits are reached in scaling up, environments <a id="_idIndexMarker300"/>can be scaled out. In most cases, the scaling out is done by a cloning server. In Azure, we can use Azure Automation to do this. In AWS, we can copy the image of the server and then spin up a new machine with that image in <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>), using <a id="_idIndexMarker301"/>AWS Systems Manager Automation. Off course, there are a lot of third-party tools too that can help in automating scaling.</li>
			</ul>
			<p>There are clear <a id="_idIndexMarker302"/>benefits of scaling in the cloud. We can have resources available on demand, scaling to the capacity that we need at a certain time. Since we're only <a id="_idIndexMarker303"/>paying for what we use, we could save money by scaling down resources if we don't need them anymore. For example, development and test systems might not be needed all the time and can be suspended when the work is done. Maybe teams can completely decommission these systems and simply spin up new ones as soon as the project requires it. </p>
			<p>The best part is that DevOps teams can control this completely by themselves—they are no longer dependent on purchase departments that need to order hardware or require engineers to install it in the data center. It's all code, including the scale sets, and it can be fully integrated in the pipelines, ready at their disposal.  </p>
			<h2 id="_idParaDest-57"><a id="_idTextAnchor058"/>Scaling with containers</h2>
			<p>A major forthcoming <a id="_idIndexMarker304"/>change in IT infrastructure is moving from VMs to containers. The driver behind this is interoperability of systems between different platforms. Containers <a id="_idIndexMarker305"/>seem to be a very good solution to have software interoperable across platforms, with ultimate scalability. There are, however, a few things that an architect needs to consider. To start with, they must understand that containers also need infrastructure to land on. Containers do not run by themselves.</p>
			<p>Containers are operated on compute clusters with a management layer that enables the sharing of resources and the scheduling of tasks to workloads that reside within the containers. Resources are compute clusters, a group of servers—commonly referred to as nodes—that host the containers. The management or orchestration layer makes sure that these nodes work as one unit to run containers and execute processes—the tasks—that are built inside the containers. </p>
			<p>The cluster management tracks the usage of resources in the cluster such as memory, processing power, and storage, and next assigns containers to these resources so that the cluster nodes are utilized in an optimized way and applications run well. </p>
			<p>In other words, scaling containers is not so much about the containers themselves, but more about scaling the underlying infrastructure. To make this a bit easier, Google invented the orchestration platform Kubernetes that takes care of cluster management. Kubernetes uses pods, enabling the sharing of data and application code among different containers, acting as one environment. Take the last sentence quite literally. Pods work <a id="_idIndexMarker306"/>with the <strong class="bold">share fate</strong> principle, meaning that if one container dies in the pod, all containers go with it. </p>
			<p>The workflow in the following screenshot shows the basics of Kubernetes:</p>
			<div>
				<div id="_idContainer035" class="IMG---Figure">
					<img src="image/B17492_04_006.jpg" alt="Figure 4.6 – High-level architecture of Kubernetes&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.6 – High-level architecture of Kubernetes</p>
			<p>The good news, though, is that pods can be replicated using replication controllers. Kubernetes polls whether the specified number of pods is running within the cluster nodes. If required, pods are replicated, making sure that the specified number of containers is running. </p>
			<p>Containers are a <a id="_idIndexMarker307"/>good solution, but there are still some shortcomings. The <a id="_idIndexMarker308"/>most important one is that containers and clusters might be interoperable, but typically, networks and storage layers are not. In order to scale container solutions, we also need networks and storage layers to be <em class="italic">integrated</em>. For example, Azure Blob is a different beast from AWS <strong class="bold">Simple Storage Service</strong> (<strong class="bold">S3</strong>), yet <a id="_idIndexMarker309"/>Kubernetes runs on both platforms <a id="_idIndexMarker310"/>using <strong class="bold">Azure Kubernetes Services</strong> (<strong class="bold">AKS</strong>) and <strong class="bold">Elastic Kubernetes Services</strong> (<strong class="bold">EKS</strong>) on <a id="_idIndexMarker311"/>AWS. There will be solutions to overcome this, but it's definitely something to take into account when planning container platforms. </p>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor059"/>Scaling DevOps in an enterprise environment</h1>
			<p>We've <a id="_idIndexMarker312"/>discussed the benefits of DevOps and what <a id="_idIndexMarker313"/>cloud adoption, automation, and an agile way of working could bring to an enterprise. The big question is: <em class="italic">How and where to start?</em> Opinions <a id="_idIndexMarker314"/>differ here, from a <strong class="bold">big-bang approach</strong> to step-by-step adoption. </p>
			<p>Enterprises that have a lot of their IT muscles outsourced to different IT suppliers and that have been working for decades in a certain way are not easily changed. For one, there will be a lot of pushback from staff—remember that DevOps is also about changing a mindset or a culture. In this section, we're taking the approach of step-by-step adoption, or evolution <a id="_idIndexMarker315"/>instead of <a id="_idIndexMarker316"/>revolution.</p>
			<p>Here are some recommendations:</p>
			<ul>
				<li><strong class="bold">Start small</strong>: Don't start by implementing DevOps on large projects. Organize a small team and a simple project to learn and—even more important—to identify possible bottlenecks in the processes. What is possibly hindering the DevOps way of working? Do resources have the right skills, and is the team composed of the right resources? Does the team have the required tools? Are the requirements clear, even if it's a simple build? Are processes aligned with DevOps? Learn from the bottlenecks and improve in each step. </li>
				<li><strong class="bold">Start with the end in mind</strong>: Know where you are going and what the end product will look like. Working in small iterations doesn't mean that the team will not need a clear picture of the end goal of the project. The same applies for implementing DevOps in an enterprise. From enterprise architecture, it must be clear what the strategy is for that enterprise: where will it be in 1, 3, or 5 years? Defining an enterprise roadmap can help in setting goals. An example is presented in the following diagram:</li>
			</ul>
			<div>
				<div id="_idContainer036" class="IMG---Figure">
					<img src="image/B17492_04_007.jpg" alt="Figure 4.7 – Enterprise roadmap for adopting DevOps&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.7 – Enterprise roadmap for adopting DevOps</p>
			<p>The preceding screenshot shows three basic stages, outlined as follows:</p>
			<p>- <strong class="bold">Foundation</strong>: The architect defines the target operating model, based on a reference architecture covering the applications, technology, security, services, and governance. At this stage, the cloud adoption is an important topic: the major cloud platforms, Azure, AWS, and Google Cloud, have <strong class="bold">Cloud Adoption Frameworks</strong> (<strong class="bold">CAFs</strong>) that <a id="_idIndexMarker317"/>will help in setting up the basics to operate systems in the cloud.</p>
			<p>- <strong class="bold">Adopt</strong>: This stage is about <a id="_idIndexMarker318"/>adopting the <a id="_idIndexMarker319"/>foundation and the target operating model. The cloud environments are set up and the first—small—projects are initiated in <a id="_idIndexMarker320"/>DevOps mode. Concepts such as <strong class="bold">Infrastructure as Code</strong> (<strong class="bold">IaC</strong>) and RAD can be introduced. A way to do <a id="_idIndexMarker321"/>this is by installing a <strong class="bold">Center of Excellence</strong> (<strong class="bold">CoE</strong>) with <strong class="bold">subject-matter experts</strong> (<strong class="bold">SMEs</strong>) that can guide in the <a id="_idIndexMarker322"/>adoption of the model, including the cloud technology, use of DevOps tooling, and agile coaches to help implement the agile way of working. In the next section, <em class="italic">Scaling using a CoE</em>, we will discuss the setup of the CoE. </p>
			<p>- <strong class="bold">Expand</strong>: We have referenced architecture, have defined a target operating model, and assigned a group of experts to take part in a CoE to help in adopting the new models and delivering the first projects. At this stage, the model can be expanded in the enterprise.</p>
			<ul>
				<li><strong class="bold">Make sure all steps are visible</strong>: Transparency is key in DevOps. It applies to the way of working within the teams and the delivery process of products. Tools must enable full visibility as to what happens in the development and release chain, the CI/CD pipelines. Ideally, teams have a single-pane-of-glass view on events in the release chain: tools that collect real-time data from the pipelines and the systems. But also, team members need to know exactly what other members are doing, since DevOps is in essence mainly about close cooperation. Team members need to be able to track activities, anticipate, and—if needed—correct steps. The end goal is a better product.    </li>
				<li><strong class="bold">Be ready for change—at all times</strong>: This one seems obvious, but in DevOps nothing is set in stone. If something can be improved, teams should be motivated to adopt the change that enables this improvement. It applies to DevOps teams and their <a id="_idIndexMarker323"/>projects, but also to the <a id="_idIndexMarker324"/>enterprise as a whole. Even the biggest enterprises in the world every now and then have to hit the refresh <a id="_idIndexMarker325"/>button, to quote the book of Microsoft's <strong class="bold">Chief Executive Officer</strong> (<strong class="bold">CEO</strong>) Satya Nadella.</li>
			</ul>
			<p>We've introduced the CoE. In the next section, we will elaborate on that. </p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor060"/>Scaling using a CoE</h2>
			<p>A starting point <a id="_idIndexMarker326"/>could be a CoE. Again, it sounds like a big thing, but it doesn't have to be. On the contrary—a CoE can be a good entry point to start <a id="_idIndexMarker327"/>transforming a business. The CoE is a team that leads or supports employees and organizations in the adoption, migration, and operations of new technology, or even a new way of working. In short, the CoE can be the starting point of the digital transformation of an enterprise. Instead of trying to change the enterprise as a whole at once, we assign a team to guide this. The main goal of a CoE is to define and help implement best practices for implementing architecture, transforming and optimizing operations, and implementing governance. </p>
			<p>The installation of a CoE should also be done in steps, starting with a CoE that defines the standards and policies. For that reason, the architect should be a member of the CoE. Next, the CoE defines the <em class="italic">guardrails</em>, ensuring the usage of best practices. Don't reinvent the wheel, but use what's out there and has been proven to work well in other enterprises. But there's a risk in that too. The risk is that the team is making it too big. </p>
			<p>A commonly used <a id="_idIndexMarker328"/>framework to enroll an agile way of working is <strong class="bold">SAFe</strong>, the <strong class="bold">Scaled Agile Framework</strong>. It might include the implementation of the Spotify model, with the instalment of tribes and squads. Those are huge changes for any company, even if it's done in just one team. It will impact the whole enterprise, especially when IT is outsourced and resources from suppliers need to be involved in newly formed teams such as squads. Does the contract between the enterprise and the supplier even cater for the new way of working? Before you know it, we are implementing a world-conquering plan.  </p>
			<p>It doesn't mean that we can't use principles of SAFe, but we need to make sure that it <em class="italic">fits</em> and that it is adopted. The CoE can help in defining and controlling the adoption toll gates and suggest improvements. This type of CoE—still a small team—is referred to as prescriptive. </p>
			<p>The next level of the <a id="_idIndexMarker329"/>CoE is the advisory level. At this stage, the <a id="_idIndexMarker330"/>CoE is formed as a (virtual) team of SMEs in different domains, actively helping DevOps teams in executing projects. The CoE guards the standards and policies, and controls and validates whether these are followed. From this point, the implementation of DevOps and agile is accelerated, breaking down the original organization silos. However, this is done step by step. </p>
			<p>Starting with simple projects in small teams, it doesn't sound like DevOps and agile are really suitable to develop and run mission-critical environments. That's not the case. An enterprise might want to start with mission-critical, but if DevOps is scaled right and there's a clear plan on app modernization, we can also start managing critical environments in a DevOps way. The final section, <em class="italic">Managing mission-critical environments with DevOps,</em> of this chapter will explain more on this.</p>
			<h1 id="_idParaDest-60"><a id="_idTextAnchor061"/>Managing mission-critical environments with DevOps</h1>
			<p>In this section, we <a id="_idIndexMarker331"/>will discuss DevOps for <a id="_idIndexMarker332"/>mission-critical environments and why it can be done to manage core applications. Let's first define <strong class="bold">mission-critical</strong>. </p>
			<p>A very straightforward definition would be: any software that an enterprise needs to remain in business. If a mission-critical system were to fail, the enterprise would potentially lose a lot of money, either due to direct missed transactions or through things that are less tangible, such as reputation damage. These systems are identified through the <a id="_idIndexMarker333"/>process of <strong class="bold">business impact analysis</strong> (<strong class="bold">BIA</strong>). </p>
			<p>When we start with DevOps projects, the first thing that an architect does is gather the business and technical requirements. That would include the outcomes of the BIA process, which is typically done in cooperation with internal auditors and business stakeholders. From the BIA, critical systems or system components are identified that need to be restored very quickly in case these systems fail. This is a very cumbersome process that will cause of lot of discussion. </p>
			<p>The enterprise architect will need to understand that stakeholders might have different views on what critical systems are. Financial systems in banks will be business-critical, but a car factory will not immediately lose business if the <strong class="bold">Chief Financial Officer</strong> (<strong class="bold">CFO</strong>) can't <a id="_idIndexMarker334"/>access financial reports for—let's say—an hour or so. Production at that factory, however, will stop immediately if the assembly robots fail. </p>
			<p>Enterprises are <a id="_idIndexMarker335"/>still reluctant to host critical systems in public clouds because they think that they will lose control over the systems if <a id="_idIndexMarker336"/>these are not sitting in a privately owned on-premises data center that engineers can immediately enter in the case of an emergency. Yet, the public cloud might be the best place to host these systems. Because of the vast capacity that these platforms have, it's easy to have a copy of critical systems in different regions and zones. If one cloud data center fails, there's a second data center that can take over. Using cloud technology, this can be done with a minimal loss of data. Cloud technology offers tools to build more resilient environments. </p>
			<p>Where does DevOps come in? In <a id="_idIndexMarker337"/>drafting the <strong class="bold">business continuity plan</strong> (<strong class="bold">BCP</strong>) for which the BIA is the input. There's no real technical reason why mission-critical systems can't be cloud-hosted and developed and managed through DevOps, but given the fact that these systems need to be highly resilient, there are a couple of things to consider—for instance, in planning and applying changes. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">There's a nuance to the statement that there's no real technical reason why mission-critical systems can't be hosted in the cloud. Latency can be an issue: the time that information needs to travel between systems. One other reason can be compliancy set by law and regulations. Some organizations are simply not allowed to host systems in a cloud data center that is not residing in the country or region where the organization itself is based. These are aspects that need to be taken into account too as part of the BIA. </p>
			<p>An ongoing theme within DevOps is CI. That comes with changes, and changes have impact, also on business continuity. With critical systems, we have to make sure that the release process is designed in such way that business continuity is safeguarded. Quality assurance is, therefore, crucial. </p>
			<p>First of all, test the code as soon as it's created. With critical systems, tests must be focused on ensuring that as code is pushed to production, the vital processes of the enterprise are not impacted or are only very limited, at an explicitly prior-accepted risk level. Next, be sure that there's a fallback, rollback, or restore mechanism. </p>
			<p>How can teams be <a id="_idIndexMarker338"/>sure that what they're <a id="_idIndexMarker339"/>planning to release is <em class="italic">safe to go</em>? The answer to that one is a go-live run. Here's where the promotion path that we discussed in <a href="B17492_03_ePub_RK.xhtml#_idTextAnchor040"><em class="italic">Chapter 3</em></a>, <em class="italic">Architecting for DevOps Quality,</em> plays a crucial role. The go-live run is a real practice with the tested code on an acceptance system. That system should have exactly the same specifications as the production systems. Better: acceptance systems are an exact copy of production; they are production-like. The go-live run is done from the CI/CD pipelines, using the code as it's processed and pushed to acceptance. But it's not only about the code. Processes, security, failover to different systems, and restore procedures must be tested as well. DevOps tools need to be able to support this, as part of the BCP or framework. </p>
			<p>This concludes the chapter. In the last section, we touched upon resilience and reliability. In <a href="B17492_05_ePub_RK.xhtml#_idTextAnchor066"><em class="italic">Chapter 5</em></a>, <em class="italic">Architecting Next-Level DevOps with SRE</em>, we go deeper into architecting for reliability with SRE.</p>
			<h1 id="_idParaDest-61"><a id="_idTextAnchor062"/>Summary</h1>
			<p>This chapter covered a lot of ground. It's not easy to start with DevOps in large, traditional enterprises, but it is possible. In this chapter, we learned that we can start small and then slowly expand. Starting small doesn't mean that an enterprise doesn't need to have an end goal in mind: the enterprise architect has a key role in defining the target operating model and the way the enterprise will develop and operate products in the future. A CoE with SMEs can guide in this transformation.</p>
			<p>There's a good chance that the company has legacy environments that will need to be transformed. We've discussed modern DevOps and using cloud and cloud-native technology. We also learned about different transformation strategies for applications and how we can develop new applications in DevOps mode using RAD.</p>
			<p>In the last section, we also learned that even mission-critical systems can be developed and managed in a DevOps way, if we focus on resilience and reliability of these systems. SRE is a method to cover this. We will learn about architecture in SRE in the next chapter.</p>
			<h1 id="_idParaDest-62"><a id="_idTextAnchor063"/>Questions</h1>
			<ol>
				<li value="1">We are migrating an application from an on-premises system to Azure. The SQL database is migrated to Azure SQL as a PaaS solution. What do we call this migration strategy?</li>
				<li>Name the Kubernetes services that Azure and AWS offer. </li>
				<li>To assess business-critical systems, we need to analyze the requirements of these systems. What is the methodology for this? </li>
			</ol>
			<h1 id="_idParaDest-63"><a id="_idTextAnchor064"/>Further reading</h1>
			<p><em class="italic">The Modern DevOps Manifesto</em> (<a href="https://medium.com/ibm-garage/the-modern-devops-manifesto-f06c82964722">https://medium.com/ibm-garage/the-modern-devops-manifesto-f06c82964722</a>) by Christopher Lazzaro and Andrea C. Crawford, 2020</p>
		</div>
	</body></html>