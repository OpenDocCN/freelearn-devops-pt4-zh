<html><head></head><body>
		<div id="_idContainer059">
			<h1 id="_idParaDest-84"><em class="italic"><a id="_idTextAnchor086"/>Chapter 7</em>: Understanding the Impact of AI on DevOps</h1>
			<p>In this chapter, we will introduce <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>) and what the impact of AI is on DevOps. We will discuss how this is driving a shift left in operations, by enabling the fast identification of issues already at the beginning of the DevOps cycle, using AI and <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>). Before we can implement systems such as AIOps, we need to get the enterprise ready for AIOps in the first place by creating visibility of all IT assets and workflows and mapping them to AI-driven processes. Next, we need an integrated toolset for both development and operations. Leading public cloud providers offer native toolsets, as we will see in this chapter.</p>
			<p>After completing this chapter, you will have a good understanding of the concept of AI in DevOps processes. You will also have learned how AI-driven systems can help in achieving shift left. Before we discuss the possible outcomes and benefits of AIOps, we need to create full visibility of all assets and processes in the enterprise's IT. In this chapter, we will also learn why that is important and how we can achieve full-stack visibility.    </p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Introducing AI and ML</li>
				<li>Understanding the shift-left movement in DevOps</li>
				<li>Defining the first step – DevOps as a service</li>
				<li>Creating the IT asset visibility map</li>
				<li>Measuring the business outcomes of AIOps</li>
			</ul>
			<h1 id="_idParaDest-85"><a id="_idTextAnchor087"/>Introducing AI and ML</h1>
			<p>In this section, we <a id="_idIndexMarker435"/>will briefly <a id="_idIndexMarker436"/>introduce the concepts of AI and ML. There have been complete bookstores worth of books written about AI and ML, but in this section, we will merely give a definition and describe how these concepts will change development and operations:</p>
			<ul>
				<li><strong class="bold">AI</strong>: The broadest <a id="_idIndexMarker437"/>definition of AI is a computer technology that simulates human behavior. In most cases, AI is used to express the fact that software is able to react to events in an autonomous, intelligent way by deducting and analyzing and, by doing that, reaching decisions without human interference.  </li>
				<li><strong class="bold">ML</strong>: After AI is machines that <a id="_idIndexMarker438"/>learn how to perform tasks and execute actions by analyzing earlier events, and then use this experience to improve autonomous decision making. To enable this, both AI and ML as technology need data and they need to understand how to interpret this data.  </li>
			</ul>
			<p>AI and ML are not magic. You will need to define the scope for these technologies, just as with any other concept. Next, you will need to prepare environments to be ready for AI and ML. For example, an enterprise will need to have a good understanding of automation to start with and a complete overview of all of their assets. Otherwise, even AI will be working <em class="italic">in the blind</em>, bringing no value. </p>
			<p>Introducing and implementing AIOps starts with a different mindset: improvements start with the early detection of possible failures and learning how to prevent them before they enter production, instead of detecting and correcting failures in production. This is the domain of shift-left thinking. We will learn more about that in the next section.  </p>
			<h1 id="_idParaDest-86"><a id="_idTextAnchor088"/>Understanding the shift-left movement in DevOps</h1>
			<p>Shift left has become a <a id="_idIndexMarker439"/>popular term over the past years. But what do we <a id="_idIndexMarker440"/>mean by this? It's about moving activities that were originally planned at a later stage up to the beginning of a process. This is typically the case with testing, which for a long time was executed as soon as the whole product was delivered to a test team. Shift-left testing has become an important paradigm in DevOps: executing tests as early as possible. By having tests already from the beginning of development, issues will be found much sooner and can be fixed in that early stage. It will improve the end product. The following figure shows the impact of shift-left testing: </p>
			<div>
				<div id="_idContainer055" class="IMG---Figure">
					<img src="image/B17492_07_001.jpg" alt="Figure 7.1 – Impact of shift-left testing&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.1 – Impact of shift-left testing</p>
			<p>The shift-left principle <a id="_idIndexMarker441"/>can be applied to more processes in DevOps. Think of the <a id="_idIndexMarker442"/>very first step in DevOps: design. IT teams, both software developers and cloud engineers working on the infrastructure, should have a good understanding of the business requirements before they start building a solution. One of the major pitfalls in IT is that IT is building something without completely understanding these business requirements. A strong collaboration between business and IT can solve this by adopting other design approaches. Design thinking fits in perfectly and is a good example of shift left. </p>
			<p>Design thinking starts with evaluating the perspectives of all parties involved in the development: in the methodology, this is referred to as <em class="italic">empathy</em>. The next step is to define the problem, brainstorming and generating ideas to solve the problem from every angle, then building and testing the prototype. Testing, however, is not the final stage. On the contrary: design thinking is an iterative process, just as DevOps. Products will get better with every cycle. The key is to involve IT already at the very beginning of the project, in the phase where business requirements are defined. The process is shown in the following figure:</p>
			<div>
				<div id="_idContainer056" class="IMG---Figure">
					<img src="image/B17492_07_002.jpg" alt="Figure 7.2 – Process of design thinking&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.2 – Process of design thinking</p>
			<p>Finally, shift left is also <a id="_idIndexMarker443"/>applicable to deployment and operations in DevOps. This is <a id="_idIndexMarker444"/>where automation, templating, and blueprinting play a major role. With automated templates, pre-approved patterns, and processes, we can shift deployment to an early stage. Using automation, we can achieve consistent deployment applications that will help operations in managing these environments. </p>
			<p>Pre-approved patterns <a id="_idIndexMarker445"/>also include <strong class="bold">test-driven development</strong> (<strong class="bold">TDD</strong>), shifting testing all the way to the beginning of the development and deployment process. In <a href="B17492_03_ePub_RK.xhtml#_idTextAnchor040"><em class="italic">Chapter 3</em></a>, <em class="italic">Architecting for DevOps Quality</em>, we discussed TDD, where the team writes the test cases first and then the code. The code is written to the specifications of the test case, proving that requirements have been fulfilled. </p>
			<p>In short, the shift-left principle is about reducing failures in an early stage, making end products more stable and resilient. Issues are often only discovered in production, typically caused by inconsistencies in the deployment of systems. Manual tasks or the use of a lot of different tools increase the risk of these inconsistencies. Developers using different tools than operations can result in issues that need to be fixed by manual tasks. In <strong class="bold">Site Reliability Engineering</strong> (<strong class="bold">SRE</strong>), this is <a id="_idIndexMarker446"/>referred to as toil, as we have seen in <a href="B17492_05_ePub_RK.xhtml#_idTextAnchor066"><em class="italic">Chapter 5</em></a>, <em class="italic">Architecting Next-Level DevOps with SRE</em>. Or, issues are caused by different procedures. Automation, templating, and TDD can avoid these issues occurring and reduce the failure rate. Templates, patterns, and blueprints are tested and improved continuously, leading to more stable operations. </p>
			<p>AI and ML can help in all of this. First of all, AI-driven monitoring will help in detecting issues and especially inconsistencies at an early stage. It will learn from these inconsistencies and suggest and even implement improvements in code and procedures using ML. But before we dive into that, we need to discuss automation a bit more as part of the shift-left paradigm, shifting as much as possible to cloud services using integrated toolsets, implementing DevOps as a service. That's the topic for the next section.  </p>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor089"/>Defining the first step – DevOps as a service</h1>
			<p>Consistency is the <a id="_idIndexMarker447"/>key to success. That applies to almost anything and it certainly applies to DevOps. Dev and ops need to collaborate in the same toolset: that is what DevOps as a service is about. DevOps as a service enables shifting left, but is also a good starting point for implementing overarching monitoring systems, including AIOps.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">AIOps is way <a id="_idIndexMarker448"/>more than just a monitoring tool, as we will find out in the following chapters. However, AIOps starts with the monitoring of complex environments. By gathering data from these systems and analyzing this, it will be able to track and remediate systems and processes, including the automation of repetitive tasks. AIOps is capable of discovering patterns for which it can define automated triggers. But it can't do this if it can't monitor the source systems. </p>
			<p>DevOps as a service will track every step in the development and delivery process, but the real value is that it provides feedback as soon as an issue in that process is detected. The value lies in the fact that this feedback is already collected before the software is pushed to production. From the start of the development cycle, an integrated toolset enables the tracking of bugs and errors and sends this back to the development team, way before operations is confronted with faulty software and unpredicted behavior from systems. This is a true shift left: shifting things that we typically do at a later stage to the beginning. </p>
			<p>DevOps as a service thus represents an integrated toolset that enables collaboration between developers and operations. The tools have to cover all steps in the DevOps process and basically work together as one tool. Cloud platforms provide these tools. In this section, we will discuss these <a id="_idIndexMarker449"/>tools in Azure, AWS, and <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>):    </p>
			<ul>
				<li><strong class="bold">AWS</strong>: AWS CodeBuild, AWS CodePipeline, and AWS CodeDeploy are the three main solutions to look at. CodeBuild is a <a id="_idIndexMarker450"/>managed service for building, compiling, and testing <a id="_idIndexMarker451"/>code through automated processes. CodeBuild <a id="_idIndexMarker452"/>also provides unique encryption keys for every artifact that is built and stored in the code repository. Deployment scenarios are defined in CodePipeline, up until production, where CodeDeploy <a id="_idIndexMarker453"/>enables the delivery to targeted infrastructure in production. CodeDeploy also takes care of patching, upgrades, and the synchronization of builds.    </li>
				<li><strong class="bold">Microsoft Azure</strong>: Azure DevOps is the integrated toolset in Azure for development and deployment. It's a sort of Swiss Army knife: it acts as one tool, but under the hood, it <a id="_idIndexMarker454"/>holds different solutions that <a id="_idIndexMarker455"/>work together. You can manage the code in Azure Repos, which provides support for Git repositories. Building, testing, and deploying code is done in Azure Pipelines. More extensive testing can be executed using Azure Test Plans. Next to this, Azure DevOps provides Azure Boards, which is used to track projects: it can be compared to Kanban boards. Finally, it provides Azure Artifacts, where developers can share NuGet, NPM, Python, and Maven packages from other sources into Azure DevOps.  </li>
				<li><strong class="bold">Google Cloud</strong>: Google Cloud offers the Operations Suite, formerly known as Stackdriver. The most <a id="_idIndexMarker456"/>interesting part for <a id="_idIndexMarker457"/>developers is likely Cloud Debugger, which <a id="_idIndexMarker458"/>allows analyzing code in a running state and finding bugs without stopping the applications. Code deployment is done through Deployment Manager. GCP also offers a powerful tool for fast and automatic issue detection and analysis with Cloud Trace—in fact, this is already very close to AIOps.</li>
			</ul>
			<p>Having integrated toolsets will help us in the shift-left movement and create a good starting point to implement AIOps. But we need to do one thing first and that's making sure that we have visibility of every asset in our IT environment. That's the topic of the next section. </p>
			<h1 id="_idParaDest-88"><a id="_idTextAnchor090"/>Creating the IT asset visibility map </h1>
			<p>There's a <a id="_idIndexMarker459"/>famous line in <em class="italic">Alice in Wonderland</em>: "If you don't know where you are going, any road will get you there." You can actually turn this around: if you want to go somewhere, you need to know where you're coming from. Let's put this into practice: if we want to transform the enterprise, we need to know what it is we are transforming. That's why every approach to digital transformation starts with assessments and discovery. An enterprise needs to have full visibility of all of its assets. The following figure shows the basic steps in a migration and transformation plan, starting with the assessment:</p>
			<div>
				<div id="_idContainer057" class="IMG---Figure">
					<img src="image/B17492_07_003.jpg" alt="Figure 7.3 – High-level plan for migration&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.3 – High-level plan for migration</p>
			<p>When all assets have been identified, we can start the planning of migrating and transforming these assets to a new target landing zone, typically a platform in the public cloud. Applications need to be validated so that the right strategy can be defined: rehost, replatform, rebuild. This is the domain of app modernization that we discussed in <a href="B17492_04_ePub_RK.xhtml#_idTextAnchor053"><em class="italic">Chapter 4</em></a>, <em class="italic">Scaling DevOps</em>. The final step is to plan the migrations and transformations in waves. A <em class="italic">big bang</em> can be a strategy, but in large enterprises, this is certainly not recommended.</p>
			<p>Getting back to the reasons why enterprises adopt Agile and DevOps: enterprises do this to speed up the delivery of products and become more flexible so they can respond faster to the changing demands of customers. To gain that speed, they need to rely on stable systems and operations, so time can be spent on development instead of fixing issues. IT needs to become more predictive and actually avoid issues occurring. Data coming from assets is crucial. That data needs to be collected and analyzed in real time. </p>
			<p>The first source of this <a id="_idIndexMarker460"/>data is the <strong class="bold">configuration management database</strong> (<strong class="bold">CMDB</strong>). The problem with a lot of CMDBs is that the information they hold is not accurate. The root cause for that is the <a id="_idIndexMarker461"/>fact that a lot of data is still entered manually by, for instance, importing spreadsheets; monitoring and asset collection is not done in real time; or data is scattered across multiple CMDBs that need to be synced. </p>
			<p>Next, CMDBs are not very often <em class="italic">cleaned</em>, so they contain noise. This typically is a result of not updating the CMDB after changes have been executed. The CMDB should be the single source of truth when it comes to capturing assets, but without real-time updated—automated—information, this becomes a challenge. The CMDB will not reflect the actual status of systems anymore.</p>
			<p>You will have noticed that we're using two different terms in this section: assets and configuration. These are different things, and they are equally important in understanding how the enterprise's IT is set up. Only when we have full visibility of assets and configurations can we start planning migrations and getting the tools in place that will help operations to become more predictable. Ops needs a system that does the following: </p>
			<ol>
				<li>Knows what systems are in the IT environment</li>
				<li>Knows how these systems relate to each other</li>
				<li>Tracks the status and configurations of these systems in real time </li>
			</ol>
			<p>We start with knowing what systems we have in our environment: the asset visibility map. This is asset management: basically a list of every physical and virtual system, including the software that is used and licenses so that we know when systems will need to be upgraded or replaced, for instance, because software gets to the end of support or licenses have expired. This is addressed by the life cycle management process. </p>
			<p>We also need to know how these systems are configured and what their relation is to other systems, including dependencies so that operators know what the impact is when a database is shut down. This is configuration management. </p>
			<p>So, full visibility involves not only all assets but also a comprehensible visualization of connections, dependencies, and processes. Without this information, operations will have to spend hours finding the root cause of a problem and learning how to solve it.   </p>
			<p>Working in the <a id="_idIndexMarker462"/>cloud makes real-time asset collection easier. As an example, with the <strong class="source-inline">Get</strong> command in Azure, you can create lists of assets in Azure subscriptions. Again, real time is crucial here. Since cloud systems tend to change fast, it becomes even more important to have instant, accurate asset data. How do we create this visibility? We define five layers, as shown in the following figure: </p>
			<div>
				<div id="_idContainer058" class="IMG---Figure">
					<img src="image/B17492_07_004.jpg" alt="Figure 7.4 – Layers of asset management &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.4 – Layers of asset management </p>
			<p>Let's explore these five <a id="_idIndexMarker463"/>layers in a bit more detail:</p>
			<ul>
				<li><strong class="bold">Infrastructure</strong>: This includes virtual machines and all network components. </li>
				<li><strong class="bold">Operating systems</strong>: Are all operating systems up to date? But also: how are they configured? For example, enterprises typically have security standards, applied to images of operating systems that are hardened with these standards. Are all systems implemented with that same image? Systems that have been set up with another image might be vulnerable. </li>
				<li><strong class="bold">Application</strong>: What application software has been installed and what version? Is software properly patched and licensed? </li>
				<li><strong class="bold">Data</strong>: Where is data stored and how is it stored? For example, is data encrypted and in what way? </li>
				<li><strong class="bold">Access</strong>: Who or what has <a id="_idIndexMarker464"/>access to the four other layers? <p class="callout-heading">Note </p><p class="callout">There are two vertical layers in the figure. Life cycle management is applicable to the entire stack. Are all components still compliant, properly licensed, and not running out of service? This is even valid for the access layer: think of accounts that are not used anymore and should be disabled. </p><p class="callout">Security is intrinsic to all layers. It's not something that we only have to take care of in the infrastructure or the data layer. Every layer needs to be compliant with the security policies. We will learn more about this in the third part of this book when we will talk about security in DevOps.    </p></li>
			</ul>
			<p>But enterprises <a id="_idIndexMarker465"/>will likely have more than only assets in a public cloud. Also, assets in the public cloud might have relations and dependencies with even non-cloud systems. So, we need an overarching system that collects all data and where this data is maintained: the single-pane-of-glass view or full-stack visibility. </p>
			<p>Azure, AWS, and GCP offer <a id="_idIndexMarker466"/>APIs to <strong class="bold">enterprise service management</strong> (<strong class="bold">ESM</strong>) systems such as ServiceNow and BMC. ESM goes way further than only IT: it correlates business processes to IT and provides one view of how IT supports these business processes. These systems allow predicting how changes in IT systems will impact the business processes. </p>
			<p>So far, we have only talked about the assets and configurations that reside within the enterprise. But in this fast-changing world, the enterprise will also have a massive amount of external sources that create data. Think of data coming from websites and social media platforms. These might be real assets to a company, but data from these sources are likely to have an impact on business processes. Therefore, enterprises will also have a need to analyze this data. </p>
			<p>For example, a campaign on social media might raise sales, requiring the extra capacity of the sales systems, including the company's websites. If this is not foreseen and systems crash because of traffic overload, it will definitely cause damage to the company that is not limited to loss of revenue, but also reputational damage.   </p>
			<p>Predicting the <a id="_idIndexMarker467"/>behavior of systems and measuring the impact on a business requires full visibility of the entire ecosystem of the enterprise's IT. AIOps will help and in the last section of this chapter, we will discuss how. </p>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor091"/>Measuring the business outcomes of AIOps</h1>
			<p>In the previous sections, we <a id="_idIndexMarker468"/>discussed shift left and saw how we can define DevOps as a service. Next, we learned how to create total visibility of all assets in the enterprise as a starting point to implement AI-driven processes that will help improve development, deployment, and operations and with that, accelerate a shift left in IT. How will AI help with that? </p>
			<ul>
				<li>AI is about analyzing data. AIOps is no different: it analyzes operational data and is able to give recommendations on improving systems in terms of performance and efficiency.</li>
				<li>To get valid data and recommendations, AIOps has to reduce noise. Noise is a very common problem in operations and specifically in monitoring systems and CMDBs, as we learned in the previous section. What is really an issue and what is a false alert? AIOps is capable of analyzing these alerts and, with the help of algorithms that group alerts, can identify and prioritize these. The outcome is that this saves a lot of time in operations: operators can now focus on alerts that really impact systems—and therefore business. </li>
				<li>A very strong capability of AIOps is that it can correlate alerts and events to identify the root cause of an issue. A prerequisite is the full-stack visibility that we discussed in the previous section. AIOps are learning systems: meaning that they will first need to capture all the assets and understand the relationships between them. </li>
				<li>One more time: AIOps are learning systems, so they will learn what the normal behavior of systems is. They will then recognize anomalies and correlate these proactively with the possible business impact. Take the example we used with the campaign leading to a spike in sales. AIOps systems will detect abnormally high traffic much faster than operations and trigger scaling more quickly. </li>
				<li>Triggering <a id="_idIndexMarker469"/>scaling implies that AIOps is highly automated. AIOps can be used to take care of routine tasks, such as executing backups.</li>
			</ul>
			<p>How can we measure the <a id="_idIndexMarker470"/>benefits of adding AI? The <a id="_idIndexMarker471"/>following <strong class="bold">key performance indicators</strong> (<strong class="bold">KPIs</strong>) can help:</p>
			<ul>
				<li><strong class="bold">Mean time to detect (MTTD)</strong>: How <a id="_idIndexMarker472"/>much time elapses before an issue is detected? AIOps will learn how to detect failures, analyzing patterns and the behavior of systems. AIOps will also know how <em class="italic">severe</em> an issue is by analyzing how it affects business processes. Since AIOps uses ML, it will learn how to detect issues faster, how to predict them, and eventually avoid them by proactive recommendations. </li>
				<li><strong class="bold">Mean time to acknowledge (MTTA)</strong>: This <a id="_idIndexMarker473"/>logically follows MTTD. MTTD is about detection, while MTTA is about how fast AIOps can route the issue to the right operators. This is covered by automation of the workflow process: AIOps will first recognize the issue, determine the impact, and then decide which operator it should be routed to for further investigation. This includes raising the incident to the highest level of criticality when, for instance, crucial business processes are impacted. AIOps may decide to flag the issue as critical, triggering the crisis workflow. Using these systems, a lot of time will be saved in comparison to manual intervention.</li>
				<li><strong class="bold">Mean time to resolve (MTTR)</strong>: Using AIOps, it <a id="_idIndexMarker474"/>can be quickly identified whether similar issues have occurred before and what solution was executed to mitigate them. In short, AIOps will help in finding and analyzing solutions fast, restoring the service as soon as possible. </li>
				<li><strong class="bold">Detection by monitoring</strong>: A useful KPI to measure the success rate of AIOps is how many issues have been detected by AIOps before users actually noticed a drop in performance or even the outage of systems. </li>
				<li><strong class="bold">Remediation by automation</strong>: This is sometimes referred to as <em class="italic">automate automation</em>. AIOps will learn what solutions are used to solve issues. Sophisticated systems will <a id="_idIndexMarker475"/>also learn how to automate these solutions, proactively taking measures to prevent the issue from happening again. A useful KPI to measure the effectiveness of AIOps is to track how many remediating actions are automated by AIOps and what the effect is on the availability of systems. </li>
			</ul>
			<p>Be aware that <a id="_idIndexMarker476"/>AIOps is still in its very early stages. Quite a number of tools that call themselves AIOps aren't able yet to, for instance, "automate automation," as described in the last bullet. However, AI and ML will absolutely evolve and get more mature in the coming years. It will be a first step in implementing AI and ML to DevOps and IT as a whole and changing the software development by doing the following:  </p>
			<ul>
				<li>Creating prototypes</li>
				<li>Automated detection and analysis</li>
				<li>Automated correction</li>
				<li>Automated code generation</li>
				<li>Automated testing</li>
			</ul>
			<p>This chapter introduced the concepts of AI and ML and how these technologies will impact the development, deployment, and management of IT systems. AI will help in creating more reliable systems and improve the development of software. AI will certainly not replace developers or operators, but their roles might change as they learn to work with AI-driven systems such as AIOps. First, we will discuss how we can integrate AIOps into our architecture, which is the main topic of <a href="B17492_08_ePub_RK.xhtml#_idTextAnchor095"><em class="italic">Chapter 8</em></a>, <em class="italic">Architecting AIOps</em>.</p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor092"/>Summary</h1>
			<p>After a short introduction to AI and ML, this chapter discussed how these technologies will help in making better software and more reliable systems. AI enables the shift-left movement: shifting things that were typically done in a later stage to the beginning of the development and deployment cycle. With AI, it's possible to detect issues in a very early stage and by means of automation, AI will also be able to trigger correcting actions. </p>
			<p>Since AI and ML are learning systems, they will learn how to predict and possibly prevent issues from happening. For this, AI needs real-time data coming from source systems, hence the first step is to get a total overview of all assets in our IT environments and make sure that these systems are monitored, providing real-time logs. We learned how to create this full visibility using five layers.</p>
			<p>In the last section, we discussed KPIs used to measure the outcomes of AI-driven systems. Although AIOps is still relatively new, the technology is very promising in getting better insights into the behavior of IT and predicting the impact of IT events on the business. In the next chapter, we will learn how to integrate AIOps into the enterprise architecture.   </p>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor093"/>Questions</h1>
			<ol>
				<li value="1">Design thinking is a method to create a shift-left movement. Design thinking starts with evaluating the perspectives of all parties involved in the development. What is the term that is used to describe this step in the methodology?</li>
				<li>AWS offers DevOps as a service using native tools. What are the three tools for building the code, planning the deployment scenarios, and the actual deployment to production instances? </li>
				<li>What does MTTA stand for?  </li>
			</ol>
			<h1 id="_idParaDest-92"><a id="_idTextAnchor094"/>Further reading</h1>
			<ul>
				<li><em class="italic">AI Crash Course</em>, by Hadelin de Ponteves, Packt Publishing, 2019</li>
				<li>Blog by Clive Longbottom: https://searchitoperations.techtarget.com/definition/DevOps-as-a-service-DaaS </li>
				<li><em class="italic">Azure DevOps Explained</em>, by Sjoukje Zaal, Stefano Demiliani, and Amit Malik, Packt Publishing, 2020</li>
			</ul>
		</div>
	</body></html>