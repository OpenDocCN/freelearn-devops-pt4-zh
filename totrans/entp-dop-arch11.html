<html><head></head><body>
		<div id="_idContainer073">
			<h1 id="_idParaDest-109"><em class="italic"><a id="_idTextAnchor111"/>Chapter 9</em>: Integrating AIOps in DevOps</h1>
			<p>So far, we've looked at automating development from a DevOps perspective and have automated operations. The next step is <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>)-enabled DevOps. DevOps engineers manage multiple libraries and various pipelines. To speed up digital transformation, it's crucial that issues are detected and remediated fast. AI can also be of great added value in these DevOps processes. In this chapter, you will learn how to implement AI-enabled DevOps and enable rapid innovation. </p>
			<p>After completing this chapter, you will have a good understanding of the various steps that need to be taken to implement and integrate AI-driven pipelines for development and deployment. You will be introduced to some major tools and will learn the requirements to implement these as part of the innovation of digitally transforming enterprises. </p>
			<p> In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Introducing AI-enabled DevOps</li>
				<li>Enabling rapid innovation for digital transformation</li>
				<li>Monitoring pipelines with AIOps</li>
				<li>Assessing the enterprise readiness of AI-enabled DevOps</li>
			</ul>
			<h1 id="_idParaDest-110"><a id="_idTextAnchor112"/>Introducing AI-enabled DevOps</h1>
			<p>In the previous chapter, we studied the AIOps platform, concluding that it will help operators in <a id="_idIndexMarker546"/>getting rid of tedious, repetitive tasks, detecting and solving issues faster, and enabling more stable systems. Stability and resilience are still the key aspects operators strive for with IT systems, yet new features and changes to the systems are being developed and launched at an increasing speed. If AI can help operations, it can also help development. This section will explain why AI-enabled DevOps will help in creating better systems at a higher velocity. </p>
			<p>AI can help developers monitor and detect issues in their builds faster than if this were done only manually or even in an automated process, without the power of AI. With AI, it's possible to continuously monitor code changes, compare these to other code building blocks, and swiftly detect issues. But AI will also enable predictive mitigations: it will learn how certain code changes may impact systems. Given the fact that new features and thus new code are developed at an ever-increasing pace in systems that become more complex, AI-enabled DevOps is a solution to ensure the stability of these systems. AI will help in managing various code libraries, keeping track of configurations and deployment scripts, and avoiding unexpected application behavior. </p>
			<p>How does it work? Well, in the same way as AIOps, which we discussed in <a href="B17492_08_ePub_RK.xhtml#_idTextAnchor095"><em class="italic">Chapter 8</em></a>, <em class="italic">Architecting AIOps.</em> AI-enabled DevOps will learn from patterns in the DevOps cycle. To do that, it needs data. It will use the code data that is stored in the code repository and the process data that is used to build the CI/CD pipeline, and then run the various test and deployment procedures. Additionally, it will learn from historical data; that is, issues and events <a id="_idIndexMarker547"/>that have occurred and the way these have been solved. Through analytics and machine learning, AI will learn how to optimize code builds, testing, and deployments. </p>
			<p>DevOps has certainly evolved over the last decade, but developers and operators still face some tedious tasks in coding, testing, and deploying new features to systems. A lot of the work is still very manual and requires several steps in testing and code reviews. Since code is becoming increasingly complex and systems are becoming more entangled in various platforms, issues may not always be detected in time or at all. To save time, code review is sometimes done through sampling: some code is randomly picked, and that specific piece of code is reviewed, leaving no guarantee that the rest of the code is OK. So, when is code OK? Often, the focus is on removing empty lines or obsolete spaces, but these things can easily be solved with formatting tools. Obviously, bugs need to be removed, but code also needs to be optimized to perform well. All this needs to be done while production is kept running and stable.</p>
			<p>AI, <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>), and deep <a id="_idIndexMarker548"/>learning can help overcome <a id="_idIndexMarker549"/>these issues. Then, there's AI-enabled DevOps. This requires the following components:</p>
			<ul>
				<li>Access and control over the source repository</li>
				<li>Data lake and data marts for modeling</li>
				<li>AI-integrated pipelines</li>
			</ul>
			<p>The basic process contains the steps shown in the following diagram:</p>
			<div>
				<div id="_idContainer067" class="IMG---Figure">
					<img src="image/B17492_09_001.jpg" alt="Figure 9.1 – Concepts of an AI-integrated pipeline&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.1 – Concepts of an AI-integrated pipeline</p>
			<p>We will elaborate on these steps in the <em class="italic">Monitoring pipelines with AIOps</em> section, where we will discuss various tools and technologies for monitoring processes in DevOps pipelines. </p>
			<p>AI is a new <a id="_idIndexMarker550"/>domain in DevOps. It's an innovation that can speed up the digital transformation of enterprises. Before we dive into the details of injecting AI into DevOps pipelines, it's good to get a better understanding of the innovation cycle and the rationale for including AI and ML. We will discuss this in the next section. </p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor113"/>Enabling rapid innovation in digital transformation</h1>
			<p>The majority of modern enterprises are well underway in transforming their business to make it <a id="_idIndexMarker551"/>more digital native. We talked about this extensively in the first two chapters of this book. Customers continuously demand new features, and they want these features to be delivered almost instantly. To control this process, enterprises need to develop an innovation strategy catering for rapid innovation. An innovation strategy can be depicted as a pyramid, where AI-driven innovation is at the very peak of this pyramid. </p>
			<p>This can be seen in the following diagram:</p>
			<div>
				<div id="_idContainer068" class="IMG---Figure">
					<img src="image/B17492_09_002.jpg" alt="Figure 9.2 – Pyramid of AI-enabled innovation&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.2 – Pyramid of AI-enabled innovation</p>
			<p>Enterprises do not get to the top of the pyramid in one go; they usually start at the bottom, where innovation is driven by cost savings. From there, they need to develop the next steps, resulting in rapid innovation using AI and ML. </p>
			<p>The first <a id="_idIndexMarker552"/>steps typically involve ways to find a budget, which they do by implementing technology that can lead to drastic cost savings, for instance, by moving to another platform. That choice of platform is crucial: enterprises will want to make sure that they make a sustainable choice for the future and have planned such innovations to drive digital transformation. Such a platform can be a public cloud, offering not just hosting services, but allowing us to use cloud-native technology and integrate that with DevOps, AI, and ML. </p>
			<p>An even more important step is to collect and leverage the use of data. AI and ML need data, and it needs to be aggregated for analytics purposes and for training data models. Data is likely the most valuable asset in any enterprise, so this step will take a lot of time. </p>
			<p>Aggregating data doesn't mean that every single piece of data needs to be in one data lake. There will be a need for different datasets, but architects will have to think of efficient ways to create these datasets without the usual silos in an enterprise. And then there's data security: who is authorized to see what data and for what reason? How do you prevent <a id="_idIndexMarker553"/>data from getting somewhere it shouldn't be? Data <strong class="bold">identity and access management</strong> (<strong class="bold">IAM</strong>) and <strong class="bold">data loss prevention</strong> (<strong class="bold">DLP</strong>) are important topics. For this, an enterprise will need to have a <a id="_idIndexMarker554"/>consistent system for data classification.</p>
			<p>Now, we can <a id="_idIndexMarker555"/>bring AI and ML to the table. Data models need to be trained, deployed, and integrated with the CI/CD pipelines to enhance coding and application development. The pipelines will have to be integrated with the data analytics models and AI services from the platform of choice. The end of this journey might be an AI-controlled CI/CD pipeline. That's the topic of the next section, where we will have a look at some AI-driven tools in the major public clouds; that is, Google Cloud Platform, AWS, and Azure. </p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor114"/>Monitoring pipelines with AIOps</h1>
			<p>In this section, we will study AI-driven technology that will help developers in monitoring and improving their CI/CD pipelines. Let's recap on the principle of a pipeline first. A pipeline <a id="_idIndexMarker556"/>should be seen as a workflow: it <a id="_idIndexMarker557"/>guides code through a process where it's tested and eventually deployed to a platform. Following this process, code will be pushed to different levels in the promotion path: development, testing, acceptance, and production. This process can be automated. </p>
			<p>At the start of this process, and thus the pipeline, there is a repository where the various components of systems are stored. Since everything is code, the repository will hold code for applications, infrastructure components, configuration templates, and scripts to launch APIs. While building a system through a pipeline, DevOps software will make sure that the appropriate components are pulled from the repository and compiled into packages that can be deployed. A common way to do this is by using containers, such as Docker images that have been orchestrated via Kubernetes. Containers are also very suitable for injecting AI and ML into pipelines. The following diagram shows the basic functionality of Kubernetes:</p>
			<div>
				<div id="_idContainer069" class="IMG---Figure">
					<img src="image/B17492_09_003.jpg" alt="Figure 9.3 – Functionality of Kubernetes&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.3 – Functionality of Kubernetes</p>
			<p>From the <a id="_idIndexMarker558"/>DevOps CI/CD pipeline, Kubernetes <a id="_idIndexMarker559"/>can be instructed on how components must be pushed to the target platform using containers. To enable this, we can use the Kubernetes <strong class="source-inline">kubectl</strong> command-line tool. It runs commands against Kubernetes clusters and tells these clusters how to deploy application code while monitoring the cluster's resources and hosts. </p>
			<h2 id="_idParaDest-113"><a id="_idTextAnchor115"/>Introducing Kubeflow by Google</h2>
			<p>According to their own documentation, Kubeflow is the ML toolkit for Kubernetes. It allows us to <a id="_idIndexMarker560"/>implement and monitor complex workflows and application development processes in pipelines that are running on Kubernetes and using ML on any cloud, such as AWS, Azure, and Google Cloud, just to name a few. </p>
			<p>In-depth monitoring and analytics for all the components in the pipelines are highly valued features of Kubeflow. Originally, TensorFlow and PyTorch were used to train the data models. In the words of Kubeflow itself, it takes care of all the <em class="italic">boring stuff</em> by using ML, so that developers can concentrate on the new features.  </p>
			<p>The high-level architecture of Kubeflow is shown in the following diagram:</p>
			<div>
				<div id="_idContainer070" class="IMG---Figure">
					<img src="image/B17492_09_004.jpg" alt="Figure 9.4 – Conceptual architecture of Kubeflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.4 – Conceptual architecture of Kubeflow</p>
			<p>ML is used to load vast amounts of data, verify that data, process it, and, by doing that, train models so that they learn from this data. However, developers want to be able to do this at scale. An example could be image recognition. You can train ML models to recognize images, a feature <a id="_idIndexMarker561"/>that is becoming increasingly popular in diagnostic imaging at hospitals. Using AI and ML clinical images from; for example, CT scans can already be valued, denoised, and have possible focus areas highlighted to support doctors in getting a more precise diagnosis faster. To run this type of model at scale, using containers is a viable option. This is what Kubeflow does. </p>
			<p class="callout-heading">Note </p>
			<p class="callout">On <a href="https://www.kubeflow.org/docs/examples/">https://www.kubeflow.org/docs/examples/</a>, you can find tutorials and examples of Kubeflow <a id="_idIndexMarker562"/>use cases, including a sample for image recognition and a tutorial on how to use a Jupyter Notebook on a Kubeflow cluster. </p>
			<p>The architecture of Kubeflow shows that AI-enabled DevOps requires a number of components and that different tools need to be integrated. Some of these tools are platform native, such as CodeGuru by AWS and MLOps in Azure. We will briefly evaluate these in the following sections.</p>
			<h2 id="_idParaDest-114"><a id="_idTextAnchor116"/>Introducing CodeGuru by AWS</h2>
			<p>There are more developments underway, proving that this is a growing market. As an example, AWS announced the introduction of ML in DevOps in May 2021, using CodeGuru.  </p>
			<p>CodeGuru Reviewer <a id="_idIndexMarker563"/>is a tool that uses ML to detect issues <a id="_idIndexMarker564"/>and bugs in code, but also vulnerabilities in security policies that have been applied to code. It also provides recommendations to improve the code, either by solving bugs or suggesting enhancements to be made to the code. </p>
			<p>A second component <a id="_idIndexMarker565"/>of CodeGuru is CodeGuru Profiler. Once the code review has been completed, Profiler validates the runtime of the code, identifying and removing inefficiencies in the code and, with that, improving the performance of the application. AWS claims that it also helps in decreasing compute costs, since Profiler also checks the code against the resources that it calls during the runtime process. By using ML, it can do this proactively, since it learns how code can be optimized, from comparing new code to existing code patterns. According to the AWS documentation, CodeGuru has already reviewed over 200 million lines of code since its launch.   </p>
			<p>The following diagram shows the architecture of CodeGuru using CodeGuru Reviewer and CodeGuru Profiler:</p>
			<div>
				<div id="_idContainer071" class="IMG---Figure">
					<img src="image/B17492_09_005.jpg" alt="Figure 9.5 – CodeGuru and CodeGuru Profiler by AWS&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.5 – CodeGuru and CodeGuru Profiler by AWS</p>
			<p>The next step in this domain is Amazon DevOps Guru. DevOps Guru works more on the infrastructure level of DevOps. It runs pre-trained ML models that analyze system logs and metrics against operational baselines to detect anomalies in infrastructure components. Because it uses deep learning, the model is trained and enhanced continuously.  </p>
			<h2 id="_idParaDest-115"><a id="_idTextAnchor117"/>Introducing MLOps in Azure</h2>
			<p>All major cloud providers have AI-driven solutions. The last one we will discuss briefly is MLOps in Azure. The <a id="_idIndexMarker566"/>basic principle is the same as with CodeGuru: MLOps <a id="_idIndexMarker567"/>will pull code from the repository, which is usually integrated with Azure DevOps. The following diagram shows the MLOps architecture:</p>
			<div>
				<div id="_idContainer072" class="IMG---Figure">
					<img src="image/B17492_09_006.jpg" alt="Figure 9.6 – Architecture of MLOps in Microsoft Azure&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.6 – Architecture of MLOps in Microsoft Azure</p>
			<p>MLOps performs various tests on the committed code. Although the outcomes will be comparable to other AI-enabled tools, MLOps works a bit differently, using an Azure ML pipeline where <a id="_idIndexMarker568"/>the models are trained. However, MLOps also works on the foundation of containerization with <strong class="bold">Azure Kubernetes Services</strong> (<strong class="bold">AKS</strong>) and <strong class="bold">Azure Container Instances</strong> (<strong class="bold">ACI</strong>). </p>
			<p>In summary, using AI-enabled <a id="_idIndexMarker569"/>DevOps will result in you being able to do the following:</p>
			<ul>
				<li>Identify missing code.</li>
				<li>Detect badly written code.</li>
				<li>Detect unnecessary code.</li>
				<li>Detect expected and/or required but missing dependencies.</li>
				<li>Perform configuration checks.</li>
				<li>Make recommendations for improvements.</li>
				<li>Trigger automated actions for improvements.</li>
			</ul>
			<p>AI-enabled DevOps is a fast-growing market, so besides the native services of major cloud providers such as CodeGuru and Kubeflow, which were launched by Google, there are a lot of emerging tools from startup companies that have been launched over the past few years. Examples include Pipeline.ai, Enterprise AI by DataRobot, Hydrosphere.io, and Xpanse AI. The first three focus more on ML-driven pipelines, while Xpanse AI is an <a id="_idIndexMarker570"/>environment for creating data models using AI.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">In this chapter, we're discussing DevOps pipelines that have been enhanced with AI and ML. To get started with data modeling and data analytics, you will also need tools to enable them. Popular tools in this field include Databricks, MapR, Cloudera, and RapidMiner. </p>
			<p>To conclude, it makes <a id="_idIndexMarker571"/>sense for enterprises to invest in AI-driven DevOps, enabling rapid innovation and speeding up digital transformation. So, the first question that needs to be answered is, when is the enterprise ready for this paradigm shift? We will briefly discuss this in the following section. </p>
			<h1 id="_idParaDest-116"><a id="_idTextAnchor118"/>Assessing the enterprise readiness of AI-enabled DevOps</h1>
			<p>So far, we've learned that digital transformation is a process. It doesn't come in one go; the enterprise <a id="_idIndexMarker572"/>needs to be prepared for this. It includes adopting cloud platforms and cloud-native technology. Enterprises will have legacy systems and likely a lot of data sitting in different silos, leaving the enterprise with the challenge that this data is used in an optimized way. It's a misperception to think that AI-enabled tools and data science can solve this issue from the beginning. </p>
			<p>The enterprise will need to have a complete overview of all its assets, but also its skills and capabilities. First, data specialists will need to assess the locations, formats, and usability of data sources. The data scientists then will have to design data models. They can't do this in isolation: they will have to collaborate with DevOps engineers and the application owners to agree on things such as version control, model training, and testing. </p>
			<p>The agreed-upon data models can then be integrated into DevOps pipelines. In the previous section, we learned that tools will have to be selected and integrated with the CI/CD tooling, for example, by using containers and container orchestration platforms such as Kubernetes. Engineers specialized in ML can help in implementing, tracking, and training these data models by leveraging the benefits of AI. </p>
			<p>That's not all. Processes – we called these engagement processes – such as incident, problem, and change management need to be aligned with the new development and deployment setup. Service managers will need to understand the new metrics that come with ML- and AI-enabled platforms. What needs to be done in the case of alerts or recommendations coming from the platforms? What is monitored and for what reason? Can tasks be automated even further, saving time and thus costs? </p>
			<p>However, the <a id="_idIndexMarker573"/>most important question is, what recommendations need to be actioned to improve development and speed up releases? AI can help, but it needs time to <em class="italic">learn</em> the enterprise. Trained and skilled staff are required to help AI become familiar with the enterprise. It isn't magic. </p>
			<p>In summary, the enterprise needs to have the following:</p>
			<ul>
				<li>Full visibility of all the assets</li>
				<li>Full visibility of all the data sources and how these are related to business processes</li>
				<li>Engagement processes that are implemented throughout the enterprise for consistency</li>
				<li>Trained and skilled staff, such as DevOps engineers, data scientists, and AI/ML engineers </li>
				<li>An innovation roadmap with realistic timelines</li>
			</ul>
			<p>The aforementioned roadmap may lead to a distant horizon where operations are completely automated by means of AI and ML and no manual intervention is required anymore. That's where NoOps comes in. In <a href="B17492_10_ePub_RK.xhtml#_idTextAnchor122"><em class="italic">Chapter 10</em></a>, <em class="italic">Making the Final Step to NoOps</em>, we will introduce this concept. </p>
			<h1 id="_idParaDest-117"><a id="_idTextAnchor119"/>Summary</h1>
			<p>In this chapter, we learned how to integrate AI and ML into our DevOps pipelines. We discussed the basic requirements and steps for implementing AI-enabled DevOps, starting with access to source repositories, creating data lakes, initiating and training data models, and follow-up recommendations and actions. We also learned that AI-enabled DevOps is a stage in digital transformation, but that enterprises need to set out a roadmap that eventually allows them to integrate AI and ML into their development and deployment processes. AI-driven development and operations are at the peak of innovation in digital transformation.</p>
			<p>Next, we introduced some tools that will help us in implementing AI-enabled DevOps. We learned that it's a fast-growing market where major cloud providers try to integrate their native DevOps tools with AI and ML. Examples include Kubeflow by Google, CodeGuru by AWS, and MLOps by Microsoft Azure. </p>
			<p>Finally, we discussed the readiness assessment for enterprises that want to implement AI-enabled DevOps. It's crucial to develop a comprehensive roadmap, including the different steps and a realistic timeline. The end of that roadmap might be a fully automated pipeline orchestration without any manual intervention: NoOps. This is the topic of the next chapter. </p>
			<h1 id="_idParaDest-118"><a id="_idTextAnchor120"/>Questions</h1>
			<ol>
				<li>We introduced the innovation pyramid for digital transformation. What is the base platform of this pyramid?</li>
				<li>Integrating AI into DevOps pipelines is typically done through containerization. We discussed a container orchestration tool that allows us to agnostically deploy containers to various platforms. What is this tool called?</li>
				<li>Name three possible outcomes/results of AI-enabled DevOps, specifically for improving code.</li>
			</ol>
			<h1 id="_idParaDest-119"><a id="_idTextAnchor121"/>Further reading</h1>
			<ul>
				<li><em class="italic">Pragmatic Enterprise Architecture</em>, by James V. Luisi, 2014</li>
				<li>Documentation on Kubeflow: <a href="https://www.kubeflow.org/">https://www.kubeflow.org/</a></li>
				<li>Blog about the introduction of CodeGuru, by AWS: <a href="https://www.allthingsdistributed.com/2021/05/devops-powered-by-machine-learning.html">https://www.allthingsdistributed.com/2021/05/devops-powered-by-machine-learning.html</a></li>
				<li>Blog on MLOps in Microsoft Azure, by Lee Stott: <a href="https://techcommunity.microsoft.com/t5/educator-developer-blog/machine-learning-devops-mlops-with-azure-ml/ba-p/742150">https://techcommunity.microsoft.com/t5/educator-developer-blog/machine-learning-devops-mlops-with-azure-ml/ba-p/742150</a></li>
			</ul>
		</div>
	</body></html>