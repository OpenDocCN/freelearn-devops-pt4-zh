<html><head></head><body>
		<div id="_idContainer090">
			<h1 id="_idParaDest-143"><em class="italic"><a id="_idTextAnchor145"/>Chapter 12</em>: Architecting for DevSecOps</h1>
			<p>As with everything in the enterprise IT domain, DevSecOps requires an architectural foundation. In this chapter, you will learn how to compose the reference architecture for DevSecOps practices and design the pipelines for DevSecOps. We will also discuss the best DevSecOps practices for the major public cloud providers; that is, AWS, Azure, and GCP. For that, we will elaborate on some of the leading tools in the market. In the last section, you will learn what steps the enterprise should take to implement DevSecOps. </p>
			<p>After completing this chapter, you will be able to name the different components in a DevSecOps architecture and how to include these in a DevSecOps pipeline. You will have also learned how to secure containers and what the best practices are in various public clouds. Most importantly, you will be able to explain why including security in DevOps is crucial for enterprises.</p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Understanding the DevSecOps ecosystem</li>
				<li>Creating the reference architecture</li>
				<li>Composing the DevSecOps pipeline</li>
				<li>Applying DevSecOps to AWS, Azure, and GCP</li>
				<li>Planning deployment</li>
			</ul>
			<h1 id="_idParaDest-144"><a id="_idTextAnchor146"/>Understanding the DevSecOps ecosystem</h1>
			<p>In the previous<a id="_idIndexMarker638"/> chapter, we discussed security principles and how this impacts the DevOps way of working. We concluded that security must be at the heart of every step in the development and deployment cycle, from the moment where code is pulled from a repository to the actual code commit and push to production. In this chapter, we will look at the foundation of <strong class="bold">DevSecOps</strong>, <strong class="bold">DevOps that has security embedded</strong>.</p>
			<p>DevSecOps<a id="_idIndexMarker639"/> consists of three layers:</p>
			<ul>
				<li><strong class="bold">Culture</strong>: This is not a technical layer, but it's often forgotten that DevOps is much more than just applying tools and creating CI/CD pipelines. Obviously, the same applies to DevSecOps. Within DevSecOps, every team member feels responsible for security and acts accordingly, taking ownership of it. This doesn't mean that security specialists have become obsolete, though. It's a good practice to have a security engineer or professional in the team, sometimes referred<a id="_idIndexMarker640"/> to as the security champion. This person must lead all processes in terms of applying security standards and policies, ensuring compliance. </li>
				<li><strong class="bold">Security by design</strong>: Security is embedded at every layer of the system. This typically means that an enterprise has a defined architecture that covers every aspect of security and enforcing security postures onto systems: authentication, authorization, confidentiality, data integrity, privacy, accountability, and availability, including remediation and corrective actions when systems are under attack. Software developers do not need to think of security every time they design and build new applications or features – the posture is applied as soon as development starts. The security architecture, frameworks, rules, and standards are centrally managed.  </li>
				<li><strong class="bold">Automation</strong>: In DevSecOps, we want to automate as much as we can, and this includes security. The rationale for automating security is that we can prevent human error, and also have automated tollgates where code is scanned for possible vulnerabilities or non-compliant components such as unlicensed code. The security lead also takes responsibility for automating security, but does so with the team. Automation also implies automated audits and collection of evidence in case of attacks or breaches. Next, the<a id="_idIndexMarker641"/> automation process makes sure that security metrics are collected and sent back for feedback in the DevSecOps practice. For example, if, when you scan, a vulnerability in the code is discovered or a license has been breached, evidence will be collected and sent for feedback.</li>
			</ul>
			<p>To manage these layers, DevSecOps<a id="_idIndexMarker642"/> relies on the following components:</p>
			<ul>
				<li>Harnessing repositories</li>
				<li>Application (code) security</li>
				<li>Cloud platform<a id="_idIndexMarker643"/> security</li>
				<li>Vulnerability assessments and testing </li>
			</ul>
			<p>DevSecOps should not be mixed up with <strong class="bold">security as a service</strong> (<strong class="bold">SECaaS</strong>). SECaaS can<a id="_idIndexMarker644"/> be a component of the DevSecOps practice, but the concept of SECaaS is mainly about shifting security as a responsibility to a service provider. It's a sourcing model that allows enterprises to get cybersecurity delivered from a service provider on a subscription base. There are good reasons for implementing SECaaS, and one of them is that a provider is responsible for all security updates, based on the latest insights. Enterprises can define service-level agreements for incident response times and the timely application of security practices. As we mentioned previously, it can be integrated into DevSecOps, but SECaaS also means that an enterprise has to rely upon a third party for implementing and managing the security baseline.  </p>
			<p>In the next section, we will discuss the DevSecOps components and define the reference architecture. </p>
			<h1 id="_idParaDest-145"><a id="_idTextAnchor147"/>Creating the reference architecture</h1>
			<p>Before we<a id="_idIndexMarker645"/> discuss the reference architecture of DevSecOps, we need to understand what the role of DevOps is and how security fits in. DevOps is about the software development life cycle. An important note that we have to make is the fact that developers increasingly use open source components. This makes sense since this provides great flexibility when developing new code. </p>
			<p>Open source is community-driven, so developers can contribute to each other's code and speed up the process. Projects can and are shared in open Git and GitHub repositories, but also internally in enterprises. InnerSource type projects are a good example of this. InnerSource uses open source best practices for software development, within the boundaries of an organization. Typically, InnerSource projects make use of shielded, access restricted repositories in GitHub or alike. </p>
			<p>Yet, there are some risks associated with open source that need to be addressed from a security perspective. Because of its open, community character – the strength of open source – there's an increased risk of introducing vulnerabilities to the code base. A second risk is license compliance. Licenses are not at the top of everyone's mind in open source, but be aware that even open source software and tools require licensing.  </p>
			<p>Let's look at the process first. The software development<a id="_idIndexMarker646"/> life cycle is a repetitive process. The developer pulls source code out of a repository and a build is triggered. After the code has been written, the code is packaged and enabled for deployment to the next stage in the promotion path; that is, test, acceptance, and eventually production. The whole process is facilitated through CI/CD pipelines and monitored. As we have concluded in the previous chapters, it's essential to test the code throughout the whole process. We also scan the code for security and compliance. This should be done at every single step in the process. </p>
			<p>In fact, we need security from the start of the DevOps process. In practice, this means that we start scanning for security issues from the moment the code is pulled from the repositories. The repositories are indeed part of the software development<a id="_idIndexMarker647"/> life cycle too, so these must be protected<a id="_idIndexMarker648"/> from unauthorized access. This calls for <strong class="bold">role-based access control</strong> (<strong class="bold">RBAC</strong>) and <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) on repositories. </p>
			<p>With that in mind, we can create the reference architecture for DevSecOps with the following components:</p>
			<ul>
				<li>Repository access with RBAC</li>
				<li><strong class="bold">Static Application Security Testing (SAST)</strong>: This will detect errors<a id="_idIndexMarker649"/> in the source code</li>
				<li><strong class="bold">Software Composition Analysis (SCA)</strong>: This will detect dependencies<a id="_idIndexMarker650"/> in code</li>
				<li><strong class="bold">Dynamic Application Security Testing (DAST)</strong>: This will dynamically scan<a id="_idIndexMarker651"/> the code</li>
			</ul>
			<p>These components are embedded in the DevSecOps pipeline, which we will discuss in the next section. </p>
			<h1 id="_idParaDest-146"><a id="_idTextAnchor148"/>Composing the DevSecOps pipeline</h1>
			<p>Let's look at a common DevOps<a id="_idIndexMarker652"/> pipeline first. The basic pipeline is shown in the following diagram:</p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="image/B17492_12_001.jpg" alt="Figure 12.1 – DevOps pipeline&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.1 – DevOps pipeline</p>
			<p>The basic steps<a id="_idIndexMarker653"/> in the pipeline are as follows:</p>
			<ul>
				<li>Pull code from the repository</li>
				<li>Build</li>
				<li>Test</li>
				<li>Deploy</li>
			</ul>
			<p>In DevSecOps, we are embedding security into the pipeline, making security standards and policies an integrated part of it. Security is a layer that is applied to every step in the pipeline, but it does include several steps. This is shown in the following diagram:</p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B17492_12_002.jpg" alt="Figure 12.2 – DevSecOps pipeline&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.2 – DevSecOps pipeline</p>
			<p>These steps are as follows:</p>
			<ol>
				<li><strong class="bold">Dependency check</strong>: First, any vulnerability that exposes the code to the risk of an exploit should be removed. This includes code that relies on other pieces of code to run. There are differences in code dependencies: developers can have controlled and uncontrolled dependencies. As a common practice, we don't want dependencies in our code. The risk is that if the code that the dependency relies on is breached or the function of that code is halted, the entire application <a id="_idIndexMarker654"/>might fail. Alternatively, malware that is injected in a certain piece of code, but has a dependency with other code, will infect the entire code stack. Therefore, the ground rule is to eliminate dependencies – this is one of the basic principles of zero trust, which we will discuss further in <a href="B17492_15_ePub_RK.xhtml#_idTextAnchor179"><em class="italic">Chapter 15</em></a>, <em class="italic">Implementing Zero Trust Architecture. </em><p>Package managers will check the code. Examples include <strong class="source-inline">pipenv</strong> for Python code and <strong class="source-inline">npm</strong> for Node.js. The commands that are used for the checks here are <strong class="source-inline">pipenv check</strong> and <strong class="source-inline">npm audit</strong>, respectively.</p><p class="callout-heading">Tip</p><p class="callout">Check the <strong class="source-inline">pipenv</strong> website<a id="_idIndexMarker655"/> for scripts and tutorials on <a href="https://pipenv.pypa.io/en/latest/">https://pipenv.pypa.io/en/latest/</a>. Take a look at <a href="https://docs.npmjs.com/cli/v6/commands/npm-audit">https://docs.npmjs.com/cli/v6/commands/npm-audit</a> for npm code<a id="_idIndexMarker656"/> checks. </p></li>
				<li><strong class="bold">Static analysis</strong>: This <a id="_idIndexMarker657"/>checks for bad coding practices, such as bad configurations. There are open source tools for almost every coding language. Some<a id="_idIndexMarker658"/> examples of tools are as follows:<p>- ArchUnitNet and Puma Scan for C#</p><p>- Go vet for Go</p><p>- Checkstyle and <strong class="bold">Open Web Application Security Project</strong> (<strong class="bold">OWASP</strong>) dependency checks for Java</p><p>- Flow for JavaScript</p><p>- Parse for PHP</p><p>- Bandit for Python</p><p class="callout-heading">Tip</p><p class="callout">This list is by no means exhaustive. On <a href="https://github.com/analysis-tools-dev/static-analysis">https://github.com/analysis-tools-dev/static-analysis</a>, you will find a list of the current, most used tools. </p></li>
				<li><strong class="bold">Scanning</strong>: Developers will likely use containers and thus container images to build and package their applications. These<a id="_idIndexMarker659"/> images need to be scanned for vulnerabilities in used binaries and libraries. This scanning is done with base lists of known vulnerabilities; these lists<a id="_idIndexMarker660"/> are provided by institutes such as the <strong class="bold">National Institute of Standards and Technology</strong> (<strong class="bold">NIST</strong>), but also software providers in the form of <strong class="bold">Common Vulnerability and Exposures</strong> (<strong class="bold">CVE</strong>) notifications. As soon as a new CVE is reported, the lists are updated, and the scanning<a id="_idIndexMarker661"/> tools are automatically updated and triggered to redo the scan. Clair (<a href="https://github.com/quay/clair">https://github.com/quay/clair</a>) is an open source tool that performs these scans, also for Docker images.  Scanning involves <strong class="bold">linting</strong>, which we will explain<a id="_idIndexMarker662"/> in more detail when we talk about hardening containers in the next section.  </li>
				<li><strong class="bold">Dynamic analysis</strong>: In the case of web applications, developers can run an automated web application scan to check for bad headers or missing tokens for <strong class="bold">cross-site request forgery</strong> (<strong class="bold">CSRF</strong> or <strong class="bold">XSRF</strong>). These tokens prevent<a id="_idIndexMarker663"/> exploits of unauthorized commands that come from a trusted user – this can also be a function on a different website. These automated dynamic scans can be integrated into the pipeline. The OWASP Zed Attack Proxy<a id="_idIndexMarker664"/> is a free web security tool (<a href="https://owasp.org/www-project-zap/">https://owasp.org/www-project-zap/</a>). </li>
			</ol>
			<p>Now, we have a security-embedded CI/CD pipeline that will automatically cover most commonly<a id="_idIndexMarker665"/> recognized vulnerabilities in code. There's one specific item that we didn't touch on in this section, though, and that's the use of containers and how we can secure these. We will study secured container builds in the next section.</p>
			<h2 id="_idParaDest-147"><a id="_idTextAnchor149"/>Using secured containers in the pipeline </h2>
			<p>Most<a id="_idIndexMarker666"/> developers will<a id="_idIndexMarker667"/> use containers to wrap and deploy their code, typically Docker containers. There are some best practices when it comes to using and securing containers. To keep containers consistent and secured, they should be scanned regularly, even when the application has reached a steady state and updates are done less frequently or active development has stopped. If the application still runs with its underlying containers hosting the different application components, these containers must be scanned since there's always a possibility that a dependency is creating a new vulnerability. </p>
			<p>Applications consisting of containers are defined by Dockerfiles. <strong class="bold">Linting</strong> – analyzing the code<a id="_idIndexMarker668"/> for errors or bad syntaxes used in the code – can be used to do <strong class="bold">Static Code Analyzer</strong> (<strong class="bold">SCA</strong>) of the Dockerfiles and make<a id="_idIndexMarker669"/> sure that these files remain secure. A popular<a id="_idIndexMarker670"/> linting tool to do this is <strong class="bold">Haskell Dockerfile Linter</strong> (<strong class="bold">Hadolint</strong>). It's available as a Docker image and can easily be executed through the following command:</p>
			<p class="source-code">docker run --rm -i hadolint/hadolint</p>
			<p>Hadolint will scan the code and if everything is all right, it will return an exit code of <strong class="source-inline">0</strong>.  When it discovers errors or bad<a id="_idIndexMarker671"/> practices, it will<a id="_idIndexMarker672"/> present a <strong class="bold">Hadolint error</strong> (<strong class="bold">DL</strong>) or <strong class="bold">SellCheck error</strong> (<strong class="bold">SC</strong>) key.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">An overview of common errors is collected at <a href="https://github.com/hadolint/hadolint#rules">https://github.com/hadolint/hadolint#rules</a>. </p>
			<p>Besides linting, Docker recommends some best practices for keeping containers secure. Docker already takes care of namespaces and network stacks to provide isolation so that containers can't obtain privileged access to other containers, unless specifically specified in the configuration. Next, there are some important things to consider:  </p>
			<ul>
				<li>Docker uses the Docker daemon. This daemon<a id="_idIndexMarker673"/> requires root access, which implies security risks. First, only trusted users should be allowed to set controls for the daemon. Next, you will need to take action and limit the attack surface of the daemon by setting access rights to the Docker host and the guest containers, especially when containers can be provisioned through an API from a web server.</li>
				<li>The use of Docker Content Trust Signature Verification is strongly recommended. It's a feature that is available from the <strong class="source-inline">dockerd</strong> binary and allows you to set the Docker engine to only run signed images. For the signing itself, you can use Notary.</li>
				<li>Use <a id="_idIndexMarker674"/>hardened <a id="_idIndexMarker675"/>templates for Linux hosting systems such as AppArmor and SELinux.  </li>
			</ul>
			<p>If we follow up on all the recommendations of Docker, we will have tested, immutable images that we can use to deploy containers on Kubernetes, for instance. Kubernetes will use the trusted image repository and takes care of provisioning, scaling, and load balancing the containers. One of the security features of Kubernetes is its support for rolling updates: if the image repository is updated with patches or enhancements, Kubernetes will deploy the new versions and destroy the previous ones. With this feature, developers will always be sure that only the latest, hardened versions of images are used. </p>
			<h2 id="_idParaDest-148"><a id="_idTextAnchor150"/>Applying secrets management</h2>
			<p>Database<a id="_idIndexMarker676"/> credentials, API keys, certificates, and access<a id="_idIndexMarker677"/> tokens must be stored in a safe place at all times. The use of CI/CD and containers doesn't change that. It's strongly recommended to use a vault outside the repositories that the pipelines access for CI/CD. The best practices<a id="_idIndexMarker678"/> for secret management are as follows:</p>
			<ul>
				<li>Encryption at rest and in transit. AES-256 encryption keys are recommended.</li>
				<li>Secrets, such as keys, must never be stored in Git/GitHub repositories.</li>
				<li>It's advised that secrets are injected into the application via a secure string as an environment variable.</li>
			</ul>
			<p>Hashicorp (Terraform) offers Vault as an open source solution for securely accessing secrets. The service allows us to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their life cycles. </p>
			<p>A more robust<a id="_idIndexMarker679"/> solution is provided by CyberArk. CyberArk Conjur is a platform-independent secrets management solution, specifically architected for<a id="_idIndexMarker680"/> securing containers and microservices. The solution is platform-agnostic, meaning that it can be deployed to any cloud or on-premises system. </p>
			<p>Both tools integrate with native environments for key management in, for example, Azure and AWS, which use Azure Key Vault and AWS Secrets Manager, respectively.</p>
			<h1 id="_idParaDest-149"><a id="_idTextAnchor151"/>Applying DevSecOps to AWS, Azure, and GCP</h1>
			<p>In the previous sections, we discussed the DevSecOps<a id="_idIndexMarker681"/> principles and how<a id="_idIndexMarker682"/> the pipeline<a id="_idIndexMarker683"/> is built with embedded<a id="_idIndexMarker684"/> security. In this section, we will<a id="_idIndexMarker685"/> look at the best<a id="_idIndexMarker686"/> practices of applying DevSecOps to the major public cloud platforms, that is, AWS, Azure, and <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>).</p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor152"/>Working with DevSecOps in AWS CodePipeline</h2>
			<p>Before we start exploring DevSecOps in AWS, we need to understand that deployments in AWS should be based<a id="_idIndexMarker687"/> on the principles of the <strong class="bold">Cloud Adoption Framework</strong> (<strong class="bold">CAF</strong>). That framework<a id="_idIndexMarker688"/> covers specific security tasks<a id="_idIndexMarker689"/> and responsibilities, grouped into the four categories or principles for enterprise security that we discussed in <a href="B17492_11_ePub_RK.xhtml#_idTextAnchor131"><em class="italic">Chapter 11</em></a>, <em class="italic">Understanding Security in DevOps</em>:</p>
			<ul>
				<li>Prevention</li>
				<li>Detection</li>
				<li>Correction</li>
				<li>Direction<p class="callout-heading"> Note</p><p class="callout">AWS refers to these principles with different terminology for correction and direction. In CAF, these are subsequently called detective and responsive. </p></li>
			</ul>
			<p>AWS offers native solutions to provide controls for managing security postures in CI/CD pipelines: Amazon CloudWatch Alarms, AWS CloudTrail, Amazon CloudWatch Events, AWS Lambda, and AWS Config. The following diagram shows the CI/CD pipeline for DevSecOps using these solutions:</p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="image/B17492_12_003.jpg" alt="Figure 12.3 – Using CodePipeline and security groups in AWS&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.3 – Using CodePipeline and security groups in AWS</p>
			<p>AWS CodePipeline<a id="_idIndexMarker690"/> is used to orchestrate<a id="_idIndexMarker691"/> the different steps in the pipeline. An important artifact is the security groups: these are the <em class="italic">bins</em> where the security posture of all the components that are developed and deployed in the pipeline is defined. It contains the templates, guardrails, and policies that have to be applied to these components. We can define<a id="_idIndexMarker692"/> three stages in the pipeline:</p>
			<ol>
				<li value="1"><strong class="bold">Source or commit</strong>: Static code analysis<a id="_idIndexMarker693"/> is performed on the code that is pulled from an S3 bucket. In the case of security group breaches, the build will be stopped. </li>
				<li><strong class="bold">Test</strong>: In this stage, CloudFormation is used<a id="_idIndexMarker694"/> to create<a id="_idIndexMarker695"/> a stack that contains a <strong class="bold">Virtual Private Cloud</strong> (<strong class="bold">VPC</strong>) in AWS to run the tests. Next, AWS Lambda is used to run the code in the stack and validate the build. AWS calls this stack validation: Lambda functions will validate the stack against the security groups. If a breach is detected, a Lambda function will delete the stack and send out an error message. This is to prevent the stack and the code from entering the next stage. </li>
				<li><strong class="bold">Production</strong>: After a successful<a id="_idIndexMarker696"/> stack validation, a Lambda function is triggered to prepare the stack for production using CloudFormation templates. This <em class="italic">change set</em> – translating the test stack into production with production templates – is then executed.<p class="callout-heading">Tip</p><p class="callout">AWS provides samples for CloudFormation templates and pipelines at <a href="https://github.com/awslabs/automating-governance-sample/tree/master/DevSecOps-Blog-Code">https://github.com/awslabs/automating-governance-sample/tree/master/DevSecOps-Blog-Code</a>.</p></li>
			</ol>
			<p>Examples of items that are checked against security groups can be validating user access and permissions, access controls to the S3 buckets, and the policies to create instances using, for example, EC2 <a id="_idIndexMarker697"/>compute resources. CloudWatch<a id="_idIndexMarker698"/> and CloudTrail are used to monitor the components, the access levels, and their usage, and will collect logs from events that are triggered during the execution of the various steps in the pipeline. </p>
			<h2 id="_idParaDest-151"><a id="_idTextAnchor153"/>Working with DevSecOps using GitHub and Azure services</h2>
			<p>Microsoft <a id="_idIndexMarker699"/>Azure <a id="_idIndexMarker700"/>uses a<a id="_idIndexMarker701"/> different approach to DevSecOps: it leverages the scan possibilities<a id="_idIndexMarker702"/> of GitHub and the features of <strong class="bold">Azure Kubernetes Services</strong> (<strong class="bold">AKS</strong>), next to Azure Pipelines, which is integrated into Azure DevOps and Azure Security Center for storing the security postures. The following diagram shows a high-level architecture for a security embedded CI/CD pipeline using GitHub and Azure services:</p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="image/B17492_12_004.jpg" alt="Figure 12.4 – DevSecOps with GitHub and Azure services&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.4 – DevSecOps with GitHub and Azure services</p>
			<p>The numbers in the preceding diagram represent the order in which steps are taken. As soon<a id="_idIndexMarker703"/> as the containers are pushed to <strong class="bold">Azure Container Registry</strong> (<strong class="bold">ACR</strong>), they are scanned against the policies that are stored in Azure<a id="_idIndexMarker704"/> Policies. Next, the appropriate security <a id="_idIndexMarker705"/>keys <a id="_idIndexMarker706"/>are fetched<a id="_idIndexMarker707"/> to authenticate the containers to <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>). Only when all the checks have passed will the code be pushed to the application gateway. </p>
			<p>Let's look at this in a bit more detail:</p>
			<ol>
				<li value="1"><strong class="bold">Source</strong>: The solution starts with code analysis in GitHub, which involves using CodeQL and Dependabot to detect vulnerabilities in the source code and dependencies, respectively.  </li>
				<li><strong class="bold">Test</strong>: Once the code has been validated, it's packaged in a Docker container and deployed to a test environment using Azure Dev Spaces. This orchestration is done through Azure Pipelines. Azure Dev Spaces will build an isolated test environment using AKS. This is comparable to how CloudFormation in AWS builds stacks.</li>
				<li><strong class="bold">Scan</strong>: Containers are stored in the ACR, where they are scanned against the security posture. For this, Azure uses Azure Security Center, which is a huge library that holds all security policies for environments that are enrolled in Azure.  </li>
				<li><strong class="bold">Production</strong>: Scanned containers are pushed to a Kubernetes cluster using AKS. Azure Policies are used to validate the compliance of provisioned clusters and containers.   </li>
			</ol>
			<p>Just like AWS, Azure uses several different solutions to provide an end-to-end solution that embeds security rules, policies, and postures throughout the whole CI/CD process. However, all <a id="_idIndexMarker708"/>these solutions <a id="_idIndexMarker709"/>start with a repository where <a id="_idIndexMarker710"/>these security guardrails and guidelines are stored and managed: security groups managed through AWS Security Hub or, in Azure, the Azure Security Center. </p>
			<h2 id="_idParaDest-152"><a id="_idTextAnchor154"/>Working with DevSecOps in Google Cloud using Anthos and JFrog</h2>
			<p>GCP <a id="_idIndexMarker711"/>offers<a id="_idIndexMarker712"/> an<a id="_idIndexMarker713"/> interesting <a id="_idIndexMarker714"/>best practice solution for implementing DevSecOps pipelines using Anthos and JFrog. With this, it doesn't only provide a cloud-native pipeline, but also a solution<a id="_idIndexMarker715"/> to develop and deploy<a id="_idIndexMarker716"/> for hybrid environments, using GCP and on-premises systems. </p>
			<p>This is interesting for enterprises since a lot of enterprises will not move their IT systems completely to public clouds. Most enterprises are expected to move more and more systems to the cloud, but some of their systems will remain on private stacks. CI/CD pipelines that cater for both cloud and on-premises solutions are favorable and with Kubernetes, they are relatively easy to set up.</p>
			<p>The architecture is shown in the following diagram:</p>
			<div>
				<div id="_idContainer088" class="IMG---Figure">
					<img src="image/B17492_12_005.jpg" alt="Figure 12.5 – High-level architecture of using JFrog Artifactory and Google Anthos&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.5 – High-level architecture of using JFrog Artifactory and Google Anthos</p>
			<p>GCP advocates the use of JFrog Artifcatory and JFrog Xray:</p>
			<ul>
				<li><strong class="bold">JFrog Artifactory</strong> takes care of storing<a id="_idIndexMarker717"/> artifacts that are used when building applications. In this chapter, we saw that a pipeline starts by <a id="_idIndexMarker718"/>pulling<a id="_idIndexMarker719"/> code from source repositories. Developers need<a id="_idIndexMarker720"/> to be <a id="_idIndexMarker721"/>able to <a id="_idIndexMarker722"/>rely <a id="_idIndexMarker723"/>on the tooling that stores and orders artifacts – code building blocks – comprehensively and safely so that software delivery to the pipelines can be automated.</li>
				<li><strong class="bold">JFrog XRay</strong> scans the artifacts – the code building<a id="_idIndexMarker724"/> blocks – through Artifactory against known vulnerabilities and license compliance. XRay advocates the shift-left mentality by already scanning the source artifacts. </li>
			</ul>
			<p>The solution is shown in the following diagram:</p>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="image/B17492_12_006.jpg" alt="Figure 12.6 – DevSecOps in Google Cloud using JFrog XRay&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.6 – DevSecOps in Google Cloud using JFrog XRay</p>
			<p>In this solution, JFrog XRay is the <a id="_idIndexMarker725"/>security solution<a id="_idIndexMarker726"/> that is embedded in <a id="_idIndexMarker727"/>the pipeline. Builds are <a id="_idIndexMarker728"/>then pushed to production, using Kubernetes in GCP, and on Anthos. Anthos, however, ensures a consistent layer for deploying <a id="_idIndexMarker729"/>and managing<a id="_idIndexMarker730"/> Kubernetes clusters across<a id="_idIndexMarker731"/> the native cloud with <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>) and on-premises. This solution is not only feasible with GCP, but it can be used on top of VMWare stacks on-premises, as well as on AWS.  </p>
			<h2 id="_idParaDest-153"><a id="_idTextAnchor155"/>Planning for deployment</h2>
			<p>So far, we've <a id="_idIndexMarker732"/>discussed the reference architecture for DevSecOps pipelines and the best practices for AWS, Azure, and GCP. If we have the architecture, the next step would be planning to deploy DevSecOps and the pipelines in our enterprise. That's the topic of this final section.</p>
			<p>There are three major steps that enterprises will need to follow to implement DevSecOps:</p>
			<ol>
				<li value="1"><strong class="bold">Assess the enterprise security</strong>: Enterprises will likely already have adopted security policies and taken measures to protect their systems. They will also need to adhere to security standards and frameworks, because of governmental or industry regulations. Security specialists will have conducted risk assessments and analyzed possible threats. These specialists understand and manage the security controls. This is, by default, the starting point of merging security into the DevOps practice. A very strong recommendation is that DevOps teams should not start without including security policies and standards for developing and deploying new code, not even in pilot projects or Proof of Concepts. Security must be a top priority from day 1. </li>
				<li><strong class="bold">Embed security into DevOps</strong>: Security policies and standards are integrated into the development process. The DevOps workflows are matched against the security guidelines and guardrails. This includes vulnerability testing and code scanning, which<a id="_idIndexMarker733"/> we discussed extensively in this chapter. Without processes and tools in place, DevOps teams can't start developing new code. The risk of increasing the attack surface of systems and, ultimately, causing immense damage to the enterprise is too big. Companies, both big and small, are under the constant threat of hackers and security threats. That brings us to step three.</li>
				<li><strong class="bold">Train, train, train</strong>: DevOps and DevSecOps aren't only about technology – it's a way of working and even thinking. Maybe even better formulated: it's a culture, and people need to be trained in adopting that culture. That training is not a one-off. Staff, developers, and operators need to be trained constantly and consistently. Developers, operators, and security engineers need to be fully committed to applying the security controls throughout their work, and that implies that they always need to be aware of the risks an enterprise is facing in terms of security breaches and hacks. </li>
			</ol>
			<p>Of course, proper tooling is essential. Enterprises<a id="_idIndexMarker734"/> are recommended to include the following tools as a minimum:</p>
			<ul>
				<li><strong class="bold">Testing</strong>: This is the crucial element in DevSecOps. The market provides a massive number of tools for performing tests. Examples are Chef Inspec, Haikiri, and Infer. </li>
				<li><strong class="bold">Alerting</strong>: When security<a id="_idIndexMarker735"/> threats are detected, alerts need to be raised and sent out. Elastalert is an example of an alerting tool.</li>
				<li><strong class="bold">Automated remediation</strong>: Tools such as StackStorm can help in providing remediation as soon as security issues are detected. </li>
				<li><strong class="bold">Visualization</strong>: Developers and operators need to be able to see what's going on in systems. Grafana and Kibana are popular tools that help in visualizing and sharing security information. </li>
			</ul>
			<p>This list is by no means<a id="_idIndexMarker736"/> intended to be exhaustive. The tools mentioned are third-party tools that integrate well with DevOps tooling and native tooling in AWS, Azure, and Google Cloud. Of course, the public cloud platforms themselves offer extensive security tooling. Examples are Sentinel and Azure Security Center in Azure, Security Hub in AWS, and the Security Command Center in GCP. </p>
			<p>The benefits of DevSecOps should be clear after reading this chapter, but we will summarize this with a conclusion: with DevSecOps enterprises, we can achieve better collaboration between developers, operators, and security engineers and with that, ensure that security threats and vulnerabilities are detected at an early stage of development so that risks for the enterprise are minimized. </p>
			<p>We will elaborate on implementing security in DevOps in <a href="B17492_14_ePub_RK.xhtml#_idTextAnchor168"><em class="italic">Chapter 14</em></a>, <em class="italic">Integrating DevSecOps with DevOps</em>, where we will also discuss DevSecOps governance. But first, we will learn how to work with and integrate industry security standards in DevOps in the next chapter. </p>
			<h1 id="_idParaDest-154"><a id="_idTextAnchor156"/>Summary</h1>
			<p>In this chapter, we studied the different components of DevSecOps. We learned that DevSecOps is not only about tooling and automation, but also very much about culture: DevOps teams have to collaborate with the security specialists in the enterprise and together, they must be fully committed to embracing and embedding security guidelines into developing and deploying new code. Tools can certainly help in achieving maximum security in DevOps. A larger part of this chapter was about architecting the DevSecOps practice. </p>
			<p>Then, we discussed the best practices for DevSecOps in the major public cloud providers; that is, AWS, Azure, and Google Cloud. These practices typically include the use of Docker containers and Kubernetes as container orchestration platforms. We also learned how to scan code and secure the containers before deploying them to a production platform. Important activities include static code analysis and dynamic scanning. </p>
			<p>In the last section of this chapter, we discussed the steps an enterprise must take to implement the DevSecOps practice and provided some recommendations for the necessary tools. </p>
			<p>Enterprises must typically adhere to governmental and industry security standards and frameworks. The next chapter is all about working with these standards in DevSecOps.   </p>
			<h1 id="_idParaDest-155"><a id="_idTextAnchor157"/>Questions</h1>
			<ol>
				<li value="1">What is the function of <strong class="bold">software composition analysis</strong> (<strong class="bold">SCA</strong>)?</li>
				<li>What technique is used to keep containers secure?</li>
				<li>What is the native tool in AWS that's used to create stacks?</li>
				<li>The AWS, Azure, and GCP public cloud providers offer their own Kubernetes services to run containers. Name their respective services. </li>
			</ol>
			<h1 id="_idParaDest-156"><a id="_idTextAnchor158"/>Further reading</h1>
			<ul>
				<li>Blog on using AWS CodePipeline in DevSecOps: <a href="https://aws.amazon.com/blogs/devops/implementing-devsecops-using-aws-codepipeline/#:~:text=%20Implementing%20DevSecOps%20Using%20AWS%20CodePipeline%20%201,%206%20Create%20change%20set%3A.%20%20More%20">https://aws.amazon.com/blogs/devops/implementing-devsecops-using-aws-codepipeline/#:~:text=%20Implementing%20DevSecOps%20Using%20AWS%20CodePipeline%20%201,%206%20Create%20change%20set%3A.%20%20More%20</a></li>
				<li>Documentation on applying DevSecOps practices in Azure: <a href="https://azure.microsoft.com/en-us/solutions/devsecops/">https://azure.microsoft.com/en-us/solutions/devsecops/</a></li>
				<li>Documentation on DevSecOps CI/CD using GCP, Anthos, and JFrog: https://cloud.google.com/architecture/partners/a-hybrid-cloud-native-devsecops-pipeline-with-jfrog-artifactory-and-gke-on-prem#best_practices </li>
				<li>Documentation on security in Docker: <a href="https://docs.docker.com/engine/security/trust/">https://docs.docker.com/engine/security/trust/</a></li>
			</ul>
		</div>
	</body></html>