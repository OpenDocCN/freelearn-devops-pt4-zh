- en: '*Chapter 8*: Understanding GKE Essentials to Deploy Containerized Applications'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes or K8s is an open source container orchestration system for automating
    the application deployment, scaling, and management of a cluster running containerized
    applications. The previous chapter introduced K8s fundamentals, including cluster
    anatomy, master plane components, Kubernetes objects (such as Pods and Services),
    workloads such as Deployments, StatefulSets, DaemonSets, and so on, and deep-dived
    into deployment strategies. However, setting up an open source Kubernetes cluster
    involves a lot of work at the infrastructure level and will also take a lot of
    time to set up. This also includes post-maintenance activities such as updating,
    upgrading, or repairing the cluster. GCP provides a compute offering that provides
    a managed Kubernetes or K8s environment called **Google Kubernetes Engine** (**GKE**).
  prefs: []
  type: TYPE_NORMAL
- en: 'The chapter introduces Google Kubernetes Engine as the managed Kubernetes option
    in GCP and uses the concepts introduced in [*Chapter 7*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154),
    *Understanding Kubernetes Essentials to Deploy Containerized Applications*, to
    create a managed GKE cluster, deploy a containerized application into the cluster,
    and expose the application to be accessible from external clients. The chapter
    later details key GKE features, including the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Google Kubernetes Engine (GKE) – introduction**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GKE – core features**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GKE Autopilot – hands-on lab**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are four main technical requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A valid **Google Cloud Platform** (**GCP**) account to go hands-on with GCP
    services: [https://cloud.google.com/free](https://cloud.google.com/free)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Install Google Cloud SDK: [https://cloud.google.com/sdk/docs/quickstart](https://cloud.google.com/sdk/docs/quickstart)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Install Git: [https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Install Docker: [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Kubernetes Engine (GKE) – introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GKE is managed K8s and abstracts away the need to manage the master plane components
    from a user's standpoint. Creating a GKE cluster is much easier than creating
    a K8s cluster. This is because GKE cluster creation removes the need to manually
    create nodes, configure nodes and certificates, and establish network communication
    between the nodes. GKE also offers options to autoscale and manage auto-upgrades
    of the cluster's node software.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the key features of a GKE cluster. These features differentiate
    GKE from open source Kubernetes or K8s:'
  prefs: []
  type: TYPE_NORMAL
- en: Fully managed and abstracts away the need for a user to provide underlying resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uses a container-optimized OS, an OS that is maintained by Google and is built
    to scale quickly with minimal resource requirements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports auto-upgrade and provides options to either get the latest available
    features or a more stable version without manual intervention.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provides the ability to auto-repair nodes by continuously monitoring the status
    of the nodes. If unhealthy, the nodes are gracefully drained and recreated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatically scales the cluster by adding more nodes as needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition to the preceding list, here are some additional key features that
    are available in K8s but need to be added and explicitly maintained as add-ons.
    These come as standard with GKE, thus making GKE a more viable and preferred option
    when compared to K8s:'
  prefs: []
  type: TYPE_NORMAL
- en: Load balancer – GKE provides a HTTP(S) load balancer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DNS – GKE implements service discovery and provides a managed DNS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging, monitoring, and dashboard – GKE provides these features built in due
    to its integration with Google Cloud operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Until recently, GKE offered only one mode of operation called **Standard** (also
    referred to as default). The Standard mode allows users to select the configurations
    needed to run workloads such as the node's machine type. This mode also allows
    you to select security configuration features, provides the ability to group nodes
    that run similar workloads, provides options to configure networking, and so on.
    Essentially, creating a cluster through GKE Standard mode is much easier than
    in open source K8s, but there is still a learning curve.
  prefs: []
  type: TYPE_NORMAL
- en: GKE recently introduced a new mode of operation called Autopilot. Autopilot
    has many of the configurations pre-selected and essentially creates a production-grade
    cluster that is hardened from a security standpoint. There are a few options to
    configure but, most importantly, the nodes are provisioned only when workloads
    are deployed. Autopilot mode will be discussed in detail later in this chapter
    through a hands-on lab.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The current chapter focuses on *Standard* mode unless explicitly specified.
    This will help you to understand the available options while creating a GKE cluster
    and provides insights into GKE features. Later in this chapter, the Autopilot
    mode will be elaborated on, calling out the key differences between the Standard
    and Autopilot modes, along with a hands-on lab.
  prefs: []
  type: TYPE_NORMAL
- en: GKE provides seamless integration with multiple service offerings from GCP.
    GKE provides options to automate deployment by building code stored in a source
    code repository using Cloud Build, which results in private container images that
    could be stored in Google's Container Registry. In addition, access to the cluster
    and the ability to configure GKE cluster options can be controlled via Google's
    **Identity and Access Management** (**IAM**). GKE integrates with GCP's network
    offerings as a GKE cluster is created as part of Google's Virtual Private Cloud
    or VPC. GCP provides insights into a GKE cluster and its resources as GKE integrates
    with Google's Cloud operations, a suite of tools from Google aimed at providing
    integrated services related to monitoring and logging.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by creating a GKE cluster through a step-by-step process. This
    will provide an insight into the possible configuration options. Once the cluster
    is created, the user will be able to deploy an application through the concept
    of a Deployment and expose the application through the concept of a Service. The
    application runs inside a container wrapped by a Pod. The Deployment specification
    will manage the Pod. The Pod is then exposed using the concept of a Service. The
    concepts of Pods, Deployments, and services are K8s fundamentals that were discussed
    in [*Chapter 7*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154), *Understanding
    Kubernetes Essentials to Deploy Containerized Applications*, and these concepts
    will be put into action on an actual GKE cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a GKE cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are multiple ways to create a GKE cluster – the Cloud Console, CLI, or
    REST. To create a cluster, the user or the service account should have one of
    the following pre-defined roles: Kubernetes Engine Admin or Kubernetes Engine
    Cluster Admin.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a step-by-step process to create a GKE cluster from the Google
    Cloud Console. The mode of operation will be **Standard** in this specific example:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the GCP Console and select the compute service – **Kubernetes Engine**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the option to create a cluster and choose the **Standard** mode.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the name for the cluster as `my-first-cluster`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Leave the default selections for the rest of the options. Refer to *Figure 8.1*:![Figure
    8.1 – Creating a GKE Cluster from the GCP Console
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_08_01.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.1 – Creating a GKE Cluster from the GCP Console
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select the option to **CREATE** the cluster. This will initiate the cluster
    creation process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The newly created cluster will be displayed on the cluster home page. Refer
    to *Figure 8.2*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.2 – The GKE cluster list page displays the newly created cluster'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 – The GKE cluster list page displays the newly created cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'The newly created cluster used the default options. Nothing really was changed
    during the cluster creation except for the cluster name. The following are some
    important points to know when a GKE cluster is created with default options. Each
    of the default options mentioned in the following list can be explicitly changed
    during cluster creation:'
  prefs: []
  type: TYPE_NORMAL
- en: The default **Location type** of the cluster is **Zonal**. **Location type**
    refers to the cluster based on availability requirements. The options are **Zonal**
    and **Regional**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The default `us-central1-c`. This indicates the zone where the control plane
    components are created.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The default `us-central1-c`. This indicates where the nodes are created. Multiple
    locations within a region can be selected to form a cluster where the location
    type is a multi-zonal cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The default **Control plane version** is **Release channel**. **Control plane
    version** provides options to signify the cluster version. The cluster version
    is indicative of the preferred feature set in terms of stability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `3`, indicating the number of worker nodes. The cluster, by default, only
    has 1 node pool. It's important to note that the cluster size doesn't include
    the master node count. Customers only pay for the worker nodes. The master node
    and the associated master plane components are entirely managed by GKE.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `default-pool`. A node pool is a collection of VMs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The default node pool consists of 3 nodes and the machine type for the node
    is `e2-medium` (2 vCPU, 4 GB memory).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The default **Maintenance Window** is **anytime**. This implies that GKE maintenance
    can run at any time on the cluster. This is not the preferred option when running
    production workloads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The default cluster type based on networking is **Public cluster** and the default
    **VPC network** is **default**. This indicates how clients can reach the control
    plane and how applications in the cluster communicate with each other and with
    the control plane.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced networking options such as **VPC-native traffic routing** and **HTTP
    Load Balancing** are *enabled* by default. These options are discussed in detail
    in the sub-section *Networking in GKE*, later in this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`110`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The security feature **Shielded GKE Node** is *enabled*. This feature provides
    strong cryptographic identity for nodes joining a cluster and is discussed in
    detail as part of [*Chapter 9*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201),
    *Securing the Cluster Using GKE Security Constructs*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud operations for GKE are enabled and are set to **System, workload logging
    and monitoring**. This feature aggregates logs, events, and metrics for both infrastructure
    and application-level workloads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A cluster can also be created from the **Command-Line Interface** (**CLI**).
    The following is the CLI command to create a cluster with default options. The
    default options used in the CLI are the same as the default options used while
    creating a cluster from the console as described previously. One significant difference,
    however, is that it is mandatory to explicitly specify a zone while executing
    through the CLI. However, the zone is auto-filled in the UI unless modified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This CLI command can be run from the terminal window of your local machine,
    which has Google Cloud SDK installed and configured. Alternatively, the CLI command
    can also be executed using Google Cloud Shell, activated through the Google Cloud
    Console.
  prefs: []
  type: TYPE_NORMAL
- en: Given that a GKE cluster is created, the next step is to deploy an application
    onto the GKE cluster and expose the application to an external client. This is
    discussed as the next topic.
  prefs: []
  type: TYPE_NORMAL
- en: GKE cluster – deploying and exposing an application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131), *Building
    code using Cloud Build, and Pushing to Container Registry*, we created a container
    image, and the container image was deployed using Cloud Run. In this chapter and
    in this sub-section, we will reuse this image and deploy it to the newly created
    GKE cluster by creating appropriate workloads. Once the application is deployed,
    the application will be exposed via a Service so that the application can be reached
    via an external client such as a web browser.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: For continuity from an example standpoint, we will be using the container image
    created in [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131), *Building
    code using Cloud Build, and Pushing to Container Registry* – `gcr.io/gcp-devops-2021/cloud-build-trigger`.
    It's recommended to use an appropriate container image of your choice that you
    have access to. For example, if you followed the step-by-step instructions in
    [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131), *Building code
    using Cloud Build, and Pushing to Container Registry*, and ended up creating a
    container image in your project, you can reuse the same image in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will deploy the application and expose the application in two different
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: GKE Console
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The CLI approach via Cloud Shell
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's important to note that a cluster is typically deployed in most cases through
    the command line. However, we will first explore the GKE Console approach as this
    will give us insights into the available configuration options. This is covered
    as the next topic.
  prefs: []
  type: TYPE_NORMAL
- en: GKE Console
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step is to deploy the application to the GKE cluster through the GKE
    Console.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying an application to the GKE cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following is the step-by-step process to deploy an application through
    the GKE Console:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the **Clusters** page in the **Kubernetes Engine** section of the
    GCP Console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the cluster that was previously created – `my-first-cluster`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the left-hand pane, select the section **Workloads**. From a GKE perspective,
    workloads refer to Deployments, StatefulSets, DaemonSets, Jobs, and CronJobs.
    There are no workloads at this moment and the current state will be as shown in
    *Figure 8.3*:![Figure 8.3 – The Workloads section of a newly created cluster
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_08_03.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.3 – The Workloads section of a newly created cluster
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a workload by selecting the **DEPLOY** option. This action allows you
    to create a Deployment object in a two-step process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first step to create a Deployment is to define the containers required for
    the Deployment. Select the container image created in [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131),
    *Building code using Cloud Build, and Pushing to Container Registry*. For this
    example, select the container image `gcr.io/gcp-devops-2021/cloud-build-trigger`.
    Refer to *Figure 8.4*. Optionally, add environment variables for the container
    and click on **Done**:![Figure 8.4 – Selecting container image while defining
    a container for Deployment
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_08_04.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.4 – Selecting container image while defining a container for Deployment
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Optionally, multiple containers can be added to the Pod by using the **ADD CONTAINER**
    option. Refer to *Figure 8.5*:![Figure 8.5 – The option to add multiple containers
    to a Deployment
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_08_05.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.5 – The option to add multiple containers to a Deployment
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The second step in creating a Deployment is to configure the Deployment. This
    includes specifying the application name, namespace, labels, and the cluster to
    which the application should be deployed. For this specific example, set `hello-world`,
    `default`, `app` and `hello-world`, and select the cluster called `my-first-cluster`.
    Refer to *Figure 8.6*:![Figure 8.6 – Configuring a Deployment by specifying the
    required attributes
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_08_06.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.6 – Configuring a Deployment by specifying the required attributes
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Before selecting the **DEPLOY** option, the configuration YAML can be viewed
    by selecting the **VIEW YAML** option as shown in *Figure 8.6*. By default, the
    number of replicas is defined as 3\. This can optionally be changed to the desired
    replica count.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initiate the deployment creation process by selecting the **DEPLOY** option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The newly created Deployment – `hello-world` – will be displayed as follows.
    This Deployment created three replicas with the same image. Refer to *Figure 8.7*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Details of the newly created Deployment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.7 – Details of the newly created Deployment
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to note that the newly created Deployment – `hello-world` –
    cannot be accessed from external clients (such as a web browser or through a `ping`
    command) as the Deployment is not exposed as a Service. However, the application
    can still be tested by using the `port-forward` option. The CLI commands required
    to execute this option are shown in the following snippet. These commands can
    be executed through Google Cloud Shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the preceding `port-forward` command is executed, traffic coming on `127.0.0.1:10080`
    will be forwarded to port `8080`. Port `8080` is the container port related to
    the `hello-world` Deployment. Refer to *Figure 8.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8 – Forwarding traffic to a container inside a Pod'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.8 – Forwarding traffic to a container inside a Pod
  prefs: []
  type: TYPE_NORMAL
- en: 'To test whether traffic is getting forwarded, open another Cloud Shell window
    and run the `curl` command as shown. This will do a REST call invocation against
    the application running inside the container of a Pod. Refer to *Figure 8.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9 – Result of accessing the application in a Pod through port-forwarding'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.9 – Result of accessing the application in a Pod through port-forwarding
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, you can also use the web preview option on port `10080` in Cloud
    Shell to view the application. Given that the application is now deployed and
    is working as expected, the next step is to expose the application as a Service.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing the application as a Service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following is a step-by-step process to expose the application as a Service
    through the GCP Console:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the **Clusters** page in the **Kubernetes Engine** section of the
    GCP Console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the cluster that was previously created – `my-first-cluster`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the Deployment that was previously created – `hello-world`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under the **Actions** menu on the deployment details page, select the **EXPOSE**
    option. This will open a pop-up window where **Port**, **Target port**, **Protocol**,
    and **Service type** need to be selected.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter `80` (this represents the port where the Service will be listening for
    incoming traffic), `8080` (this is the port the container will be listening on),
    `TCP`, and `Load balancer`. Select the **EXPOSE** option. Refer to *Figure 8.10*:![Figure
    8.10 – Specifying port mapping to expose a Pod as a Service of type Load balancer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_08_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.10 – Specifying port mapping to expose a Pod as a Service of type Load
    balancer
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once the Pod is exposed, a Service will be created as shown in the following
    screenshot. Given the Service is of type **LoadBalancer**, the Service will have
    an external endpoint. Refer to *Figure 8.11*:![Figure 8.11 – The LoadBalancer
    Service created by exposing the Pod
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_08_11.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.11 – The LoadBalancer Service created by exposing the Pod
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the external endpoint. This will open the application in the browser
    as shown in the following screenshot. This essentially is the output of deploying
    the application to the GKE cluster. The output is the same as the output in [*Chapter
    6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131), *Building code using Cloud
    Build, and Pushing to Container Registry*, when the same container image was deployed
    to Cloud Run. Refer to *Figure 8.12*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.12 – Output of accessing the application through the load balancer
    Service'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.12 – Output of accessing the application through the load balancer
    Service
  prefs: []
  type: TYPE_NORMAL
- en: This completes the topic on deploying an application to the GKE cluster and
    exposing the application via a load balancer Service through the GKE Console.
    The next sub-section essentially works on a similar example but provides insights
    on how the same thing can be done through Cloud Shell using the CLI approach.
  prefs: []
  type: TYPE_NORMAL
- en: The CLI approach via Cloud Shell
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this sub-section, we will deploy an application and expose the application
    as a load balancer Service through the CLI using Cloud Shell. We will use the
    same cluster as was previously created – `my-first-cluster`. It is also recommended
    to use the container image created as part of the exercise in [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131),
    *Building code using Cloud Build, and Pushing to Container Registry*. For this
    example, the container image `gcr.io/gcp-devops-2021/cloud-build-trigger` will
    be used.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying an application to the GKE cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following is the step-by-step process to deploy an application via Cloud
    Shell:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open Cloud Shell and connect to the cluster using the following CLI command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new file called `hello-world-cli.yaml` with contents as follows. This
    file essentially creates a Deployment that has the container and respective image
    to be deployed. The replica count is also specified and in this case, is 1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the Deployment by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the Deployment is created, the Deployment and its respective Pod can be
    queried as follows through the CLI. Please note that this Deployment will create
    only one Pod. Refer to *Figure 8.13*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.13 – Querying the Deployment through the CLI'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.13 – Querying the Deployment through the CLI
  prefs: []
  type: TYPE_NORMAL
- en: The deployed application cannot be accessed through an external client. However,
    the port-forward approach explained in the previous sub-section can be exactly
    applied in this context as well. Given that the application is now deployed, the
    next step is to expose the application as a Service.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing the application as a Service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following is the step-by-step process to expose the application as a Service
    through Cloud Shell:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new file called `hello-world-cli-service.yaml` with a definition as
    follows. This will create a load balancer Service that will expose a Pod with
    matching label selectors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the load balancer Service by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once the Service is created, a load balancer will be created with an external
    endpoint. As per the Service definition, the Service will listen to traffic on
    port `80` and will forward the traffic to the container on port `8080`. The external
    endpoint of the Service can be found out by querying the Service as follows. Refer
    to *Figure 8.14*:![Figure 8.14 – Query the load balancer Service to fetch the
    external endpoint
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_08_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.14 – Query the load balancer Service to fetch the external endpoint
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Access the external endpoint through a browser window. The output will be the
    same as the output from [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131),
    *Building code using Cloud Build, and Pushing to Container Registry*, or the output
    from the application deployed in GKE through the console. This is because we are
    using the same image. Refer to *Figure 8.15*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.15 – Viewing the output of the load balancer Service via an external
    endpoint'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.15 – Viewing the output of the load balancer Service via an external
    endpoint
  prefs: []
  type: TYPE_NORMAL
- en: This concludes this section, which introduced GKE and took a deep dive into
    the step-by-step process to create a GKE cluster, deploy an application to the
    cluster, and expose the deployed application as a Service to be accessed by external
    clients. Essentially, the output of this approach is the same as the output from
    the console approach. The goal is to understand the process of creating a cluster,
    deploying workloads, and exposing the workloads through a Service via the CLI.
  prefs: []
  type: TYPE_NORMAL
- en: The concepts used while creating the cluster or deploying the application are
    the same concepts that form the fundamentals of K8s (learned about in [*Chapter
    7*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154), *Understanding Kubernetes
    Essentials to Deploy Containerized Applications*). However, the cluster creation
    is much simpler in nature since the maintenance of the master plane components
    is completely abstracted and is not the responsibility of the user. The upcoming
    section focuses on core GKE features and possible cluster types, and provides
    an introduction to integration with networking and cloud operations in GKE.
  prefs: []
  type: TYPE_NORMAL
- en: GKE – core features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section covers the following topics. These topics will provide a considerable
    amount of information, which is required to build a good understanding and working
    knowledge of GKE. Most of these GKE concepts are an extension of topics learned
    about in the Kubernetes section. The topics that will be covered are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: GKE node pools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE cluster types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoscaling in GKE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Networking in GKE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud operations for GKE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first of the GKE constructs that will be detailed in the upcoming sub-section
    is GKE node pools.
  prefs: []
  type: TYPE_NORMAL
- en: GKE node pools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Nodes (that is, worker nodes) in a Kubernetes cluster deploy workloads. The
    nature of workloads deployed across all nodes might not be the same. Some workloads
    might be CPU-intensive, others might be memory-intensive, and some might need
    a minimum version of the CPU platform. Workloads can also be fault-tolerant batch
    jobs or might need a specific type of storage such as SSD.
  prefs: []
  type: TYPE_NORMAL
- en: A `nodeConfig` specification. All matching nodes that match the `nodeConfig`
    specification will be labeled using a node label where the key is `cloud.google.com/gke-nodepool`
    and the value is the name of the node pool.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a `nodeConfig` specification with a specific
    machine type, OAuth scopes, and a disk type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: A cluster is always created with a default node pool with a specific number
    of nodes and a specific machine type (along with other attributes). Additional
    custom node pools can be added based on their respective `nodeConfig` and workload
    requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some of the key characteristics of a node pool:'
  prefs: []
  type: TYPE_NORMAL
- en: A new node pool, by default, runs the latest stable Kubernetes version.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kubernetes version on existing node pools can either be configured for auto-upgrade
    or can be manually upgraded.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A node pool can be individually resized, upgraded, or deleted without impacting
    other node pools. Any change to the node pool impacts all nodes within the pool.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following are a few CLI commands that can perform actions on a node pool.
    These commands can be executed on the cluster that was previously created in this
    chapter – `my-first-cluster`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following CLI command creates a node pool with a specific machine type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The created node pool will be reflected on the GKE Console against the cluster
    (refer to *Figure 8.16*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.16 – New custom node pool – my-high-mem-pool created'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.16 – New custom node pool – my-high-mem-pool created
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are other CLI commands to resize a node pool, upgrade to a specific
    version, or delete a node pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Node pools in a regional or multi-zonal cluster are replicated to multiple zones.
    Additionally, the workload can be deployed to a specific node pool by explicitly
    specifying the node pool name using a `nodeSelector` or by finding a node pool
    that satisfies the resource requests as defined for the workload.
  prefs: []
  type: TYPE_NORMAL
- en: If the node pool name is explicitly specified using the `nodeSelector` attribute,
    then `kube-scheduler` will deploy workloads to the specified node. Otherwise,
    `kube-scheduler` will find the node pool that meets the intended resource request
    for the workload.
  prefs: []
  type: TYPE_NORMAL
- en: This completes the overview of GKE node pools. The next topic deep-dives into
    the various cluster configurations available in GKE.
  prefs: []
  type: TYPE_NORMAL
- en: GKE cluster configuration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GKE offers multiple cluster configuration choices based on cluster availability
    type, cluster version, network isolation, and Kubernetes features. Each of these
    configuration choices is discussed in the following sub-sections.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster availability type
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GKE allows you to create a cluster based on the availability requirements of
    the workloads. There are two types of cluster configuration based on availability
    types – zonal clusters (single-zone or multi-zonal) and regional clusters. These
    are discussed in the following sub-sections.
  prefs: []
  type: TYPE_NORMAL
- en: Zonal clusters
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A **zonal cluster** will have a single control plane running in a single zone.
    The nodes (that is, worker nodes) can run either in a single zone or run across
    multiple zones. If the nodes run in the same zone as the control plane, then it
    represents a **single-zone cluster**. However, if nodes run across multiple zones,
    then it represents a **multi-zonal cluster**. Note that GKE allows up to 50 clusters
    per zone.
  prefs: []
  type: TYPE_NORMAL
- en: A multi-zonal cluster will only have a single replica of the control plane.
    The choice between a single zone or multi-zonal cluster is based on the level
    of availability required for an application. Specific to a multi-zonal cluster
    and in the event of a cluster upgrade or a zone outage, the workloads running
    on the nodes will continue to run, but a new node or workload cannot be configured
    till the cluster control plane is available.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are CLI commands to create a zonal cluster (single zone and multi
    zonal):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The input parameter specific to the zone refers to the location of the control
    plane. The node locations refer to the locations of the worker node(s) and are
    not required for a single zone cluster as it will be the same as the master control
    plane.
  prefs: []
  type: TYPE_NORMAL
- en: This completes a brief overview of GKE zonal clusters. The next topic will provide
    an overview of GKE regional clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Regional clusters
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A regional cluster provides high availability both in terms of worker nodes
    as well as the control plane. A regional cluster has multiple replicas of the
    control plane running across multiple zones in a region. The worker nodes are
    also replicated across multiple zones and the worker nodes run in conjunction
    in the same zone as the control plane. A regional cluster cannot be converted
    into a zonal cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the CLI command to create a regional cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The input parameter specific to `region` refers to the location of the control
    plane. The node locations refer to the locations of the worker node. This is required
    for a multi-zone cluster as node locations could be in multiple zones.
  prefs: []
  type: TYPE_NORMAL
- en: This completes a brief overview of GKE cluster configuration based on cluster
    availability type. The next topic will provide an overview of GKE cluster configuration
    based on cluster version.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster versions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GKE allows you to choose the cluster version. The cluster version can be a very
    specific version, the current default version, or can be based on a release channel,
    which is a combination of features based on early availability and stability.
    These cluster version configurations are discussed in the following sub-sections.
  prefs: []
  type: TYPE_NORMAL
- en: Specific versions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A GKE cluster can be created by specifying a specific version. This information
    can be provided as part of the *Static Version* selection while creating the cluster
    from the console. The user will be provided with a choice of cluster versions
    and can select an available version.
  prefs: []
  type: TYPE_NORMAL
- en: Release channels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Open source Kubernetes or K8s has a constant stream of releases. These could
    be required for the following purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: To fix known issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To add new features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To address any security risks/concerns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes users who run applications on a Kubernetes cluster will prefer to
    exercise control in terms of how frequently the releases should be applied or
    the rate at which new features should be adopted. Google provides this choice
    to customers using the concept of a **release channel**.
  prefs: []
  type: TYPE_NORMAL
- en: Each of the release channels provides **generally available** (**GA**) features
    but the maturity of the features in terms of their original release date will
    vary from one channel to another. In addition, Google can also add the latest
    GKE-specific features depending on the type of release channel. This ensures that
    a specific feature or fix has potentially gone through the grind and is vetted
    in terms of its correctness and consistency over a period.
  prefs: []
  type: TYPE_NORMAL
- en: 'GKE provides three release channels:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rapid**: This release channel includes the latest Kubernetes and GKE features
    when compared to other release channels, but the features are still several weeks
    old after their respective open source GA release.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regular**: This is the default release channel, which includes Kubernetes
    and GKE-specific features that are reasonably new but are more stable in nature.
    The features are at least 2-3 months old after their release in the rapid channel
    and several months old from their open source GA release.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stable**: This is the most stable of the release channels since the features
    added to this channel are added at least 2-3 months after being added to the regular
    channel. Essentially, the features are thoroughly validated and tested to provide
    the utmost stability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is the CLI command to enroll a cluster in a release channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: To summarize, new Kubernetes versions and GKE features are promoted from the
    rapid to the regular to the stable channel, providing users with the choice to
    use newer features over stable features. GKE handles the availability of versions
    and the upgrade cadence once a cluster is added to the release channel. Each of
    the release channels continues to receive critical security updates.
  prefs: []
  type: TYPE_NORMAL
- en: The default version
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If a specific version or a release channel is not specified, then GKE creates
    a cluster with the current default version. GKE selects a default version based
    on usage and real-world performance. GKE is responsible for changing the default
    version on a regular basis. Historically, new versions of Kubernetes are released
    every 3 months.
  prefs: []
  type: TYPE_NORMAL
- en: This completes a brief overview of GKE cluster configuration based on cluster
    version. The next topic will provide an overview of GKE cluster configuration
    based on network isolation choices.
  prefs: []
  type: TYPE_NORMAL
- en: Network isolation choices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are two specific choices related to network isolation – a public cluster
    or a private cluster. A public cluster is the default configuration. However,
    this does not enforce network isolation and the cluster is accessible from any
    public endpoint. This makes the cluster vulnerable from a security standpoint.
    The drawbacks of configuring a public cluster can be handled through a private
    cluster, which is introduced in the following sub-sections.
  prefs: []
  type: TYPE_NORMAL
- en: Private clusters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GKE provides an option to create a private cluster where the nodes only have
    internal IP addresses. This means that the nodes and the pods running on the nodes
    are isolated from the internet and inherently will not have inbound or outbound
    connectivity to the public internet.
  prefs: []
  type: TYPE_NORMAL
- en: A private cluster will have a control plane that includes a private endpoint,
    in addition to a public endpoint. Access to the public endpoint can be controlled
    through multiple options. In addition, the control plane will run on a VM that
    is in a VPC network in a Google-owned project. The details surrounding private
    clusters will be discussed in depth as part of [*Chapter 9*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201),
    *Securing the Cluster Using GKE Security Constructs*.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes features – alpha clusters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: New features in Kubernetes are rolled out to GKE as part of the release channel
    in most cases. The release channel includes choices of rapid, regular, and stable.
    However, alpha features are only available in special GKE alpha clusters. This
    is discussed in the following sub-sections.
  prefs: []
  type: TYPE_NORMAL
- en: Alpha clusters
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Alpha clusters are a specific feature of GKE that is designed for adopting new
    features that are not production-ready or generally available as open source.
    GKE creates alpha clusters as short-lived clusters and they are automatically
    deleted after 30 days.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the CLI command to create an alpha cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: These clusters do not receive security updates, cannot be auto-upgraded or auto-repaired,
    and are not covered by any GKE-specific SLAs. Hence, alpha clusters are never
    recommended for production workloads.
  prefs: []
  type: TYPE_NORMAL
- en: This completes a brief overview of GKE cluster configuration based on network
    isolation choices. This also concludes the sub-section on GKE cluster configuration
    in general. The next topic details possible autoscaling options in GKE.
  prefs: []
  type: TYPE_NORMAL
- en: AutoScaling in GKE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are three potential options to perform autoscaling in GKE. Each of these
    options is suitable for specific needs and situations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cluster autoscaler**: A scaling option to resize a node pool in a GKE cluster'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Horizontal Pod Autoscaler** (**HPA**): An option that indicates when application
    instances should be autoscaled based on their current utilization'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Vertical Pod Autoscaler** (**VPA**): An option that suggests recommended
    resources for a Pod based on the current utilization'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The upcoming topics detail the preceding autoscaling mechanisms, starting with
    the cluster autoscaler.
  prefs: []
  type: TYPE_NORMAL
- en: The cluster autoscaler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **cluster autoscaler** is a scaling mechanism to automatically resize a
    node pool in a GKE cluster. The scaling is based on the demands of workloads deployed
    within the node pool. This allows you to implement the core concept of cloud computing,
    called elasticity, and removes the need to over-provision or under-provision nodes.
  prefs: []
  type: TYPE_NORMAL
- en: The cluster autoscaler works on a per-node pool basis and is based on resource
    requests (defined as part of the Pod specification) rather than the actual resource
    utilization. When a new Pod needs to be deployed, the Kubernetes scheduler works
    out of the Pod resource requests and attempts to find a node to deploy the Pod.
    If there is no node that matches the Pod resource requirement in terms of available
    capacity, then the Pod goes into a pending state until any of the existing pods
    are terminated or a new node is added.
  prefs: []
  type: TYPE_NORMAL
- en: The cluster autoscaler keeps track of the pods that are in the pending state
    and subsequently tries to scale up the number of nodes. Similarly, the cluster
    autoscaler also scales down the number of nodes if the nodes are under-utilized.
    A minimum or maximum number of nodes can be defined for the cluster autoscaler,
    which allows it to operate within the specified limits.
  prefs: []
  type: TYPE_NORMAL
- en: 'When a cluster is scaled down, there is a possibility that new workloads might
    have to wait till new nodes are added. This could cause a potential disruption.
    GKE profile types provide a choice of options to choose between balanced and aggressive
    scale-down:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Balanced**: The default profile option, which is not aggressive in nature.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimize-utilization**: Scaling down is more aggressive and removes underutilized
    nodes faster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following are some CLI commands related to the cluster autoscaler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The following are some limitations that need to be considered when using the
    cluster autoscaler:'
  prefs: []
  type: TYPE_NORMAL
- en: There is a graceful termination of 10 minutes for rescheduling pods on to a
    different node before forcibly terminating the original node.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The node pool scaling limits are determined by zone availability. If a cluster
    has 3 nodes (with `min_nodes` = `1` and `max_nodes` = `5`) across 4 zones, then
    if 1 of the zones fails, the size of the cluster can vary from 4-20 nodes per
    cluster to 3-15 nodes per cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This concludes the overview of the cluster autoscaler. The next topic focuses
    on the **Horizontal Pod Autoscaler** (**HPA**).
  prefs: []
  type: TYPE_NORMAL
- en: The Horizontal Pod Autoscaler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The HPA is a Kubernetes controller object that automatically scales the number
    of pods in a replication controller, Deployment, ReplicaSet, or StatefulSet based
    on the observed CPU or memory utilization. The HPA indicates the Deployment or
    StatefulSet against which scaling needs to happen. The HPA doesn't apply to DaemonSets.
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement the HPA, the following factors need to be considered:'
  prefs: []
  type: TYPE_NORMAL
- en: One HPA object needs to be defined per Deployment or StatefulSet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The attribute `--horizontal-pod-autoscaler-sync-period` allows you to implement
    the HPA as a control loop. The default value is 15 seconds per period.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-controller-manager` (on a per-period basis) obtains metrics from the
    resource manager API or the custom metrics API and compares them against the metrics
    specified in each HPA definition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following are few key parameters that can define the HPA configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--horizontal-pod-autoscaler-initial-readiness-delay`: A configurable window
    to ensure that a Pod is transitioned to the ready state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--horizontal-pod-autoscaler-cpu-initialization-period`: A configurable window
    to set the CPU initialization period, once the Pod is transitioned to the ready
    state. The default is 5 minutes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--horizontal-pod-autoscaler-downscale-stabilization`: A configurable window
    that autoscaler needs to wait before initiating a downscale operation after the
    current one is completed. The default is 5 minutes. This prevents thrashing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is the sample definition of an HPA object based on CPU utilization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, `kube-controller-manager` will scale up the Deployment
    based on the HPA object specification, to a maximum of 5 instances if the target
    CPU utilization exceeds 75%. This concludes the overview of the HPA. The next
    topic focuses on the **Vertical Pod Autoscaler** (**VPA**).
  prefs: []
  type: TYPE_NORMAL
- en: The Vertical Pod Autoscaler (VPA)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The cluster autoscaler functions based on the workload's CPU and memory request
    limits. If these limits are not defined appropriately, then there is always a
    chance of over-provisioning or under-provisioning as the reference values will
    not be accurate.
  prefs: []
  type: TYPE_NORMAL
- en: The VPA is a Kubernetes resource that recommends values for CPU and memory requests/limits.
    Additionally, the VPA can automatically update workloads if the `updateMode` attribute
    is set to *On* on the VPA. This will potentially evict the existing Pod as a change
    is required to the pod's resource requests and will result in a new Pod with the
    updated recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: This ensures that the cluster nodes are optimally utilized and potentially removes
    the need to run benchmark tests to determine the correct values for CPU and memory
    requests. VPA communicates with the cluster autoscaler to perform the appropriate
    operations on the nodes tied to the node pools.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a sample definition of a VPA object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The `kind` attribute in the preceding snippet indicates that the Kubernetes
    resource is a VPA object. The `updateMode` attribute indicates that the recommendations
    suggested by the VPA are automatically applied against the running workloads.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some CLI commands specific to the VPA:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If an HPA object is configured to evaluate metrics for CPU or memory, it's recommended
    that HPA should not be used with VPA.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-dimensional Pod autoscaling (MPA)
  prefs: []
  type: TYPE_NORMAL
- en: This is a new autoscaling option that is currently in pre-GA. As per this option,
    it is possible to configure autoscaling to horizontally scale based on CPU and
    vertically scale based on memory at the same time. MPA is supported for clusters
    that are 1.19.4-gke.1700 or later.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes the section on autoscaling in GKE where multiple mechanisms were
    detailed out. The next section focuses on networking constructs with respect to
    GKE. This will cover details about Pod networking, Service networking, and will
    deep dive into the usage of GKE load balancers to expose services for external
    consumption.
  prefs: []
  type: TYPE_NORMAL
- en: Networking in GKE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Applications are deployed in Kubernetes as containers. Pods run containers.
    The desired state of the pods is controlled by Deployments and the applications
    are exposed for both internal and external networking through Services. The deployed
    pods run in GKE on nodes. Nodes in GKE are represented by virtual machines or
    VMs. These nodes are deployed in a **Virtual Private Cloud** (**VPC**).
  prefs: []
  type: TYPE_NORMAL
- en: A VPC defines a virtual network topology that closely resembles a traditional
    network. It is a logically isolated network and provides connectivity between
    deployed resources. A VPC also provides complete control in terms of launching
    resources, selecting a range of RFC 1918 addressing, the creation of subnets,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: A VPC on GCP has a pre-allocated IP subnet, for every GCP region. When a GKE
    cluster is deployed within the VPC, a specific region or zone can be selected.
    Since GKE nodes are made up of Compute Engine VMs and these VMs need an IP address,
    the range of IP addresses is allocated from the IP subnet pre-allocated to the
    region. A VPC on GCP is considered a global resource since a single Google Cloud
    VPC can span multiple regions without communicating across the public internet.
    It is not required to have a connection in every region.
  prefs: []
  type: TYPE_NORMAL
- en: GCP provides the option of configuring alias IP ranges. This allows VMs to have
    an additional secondary IP address. As a result, a VM can have multiple services
    running with a separate IP address. These secondary IP addresses are routable
    within the VPC without the need to configure additional routes.
  prefs: []
  type: TYPE_NORMAL
- en: 'A GKE cluster might need to run cluster-wide services. GCP recommends deploying
    a GKE cluster as a **VPC-native cluster**. A VPC-native cluster uses three unique
    subnet IP address ranges:'
  prefs: []
  type: TYPE_NORMAL
- en: A primary IP address range of subnet for node IP addresses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A secondary IP address range for all Pod IP addresses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An additional secondary IP address range for all Service IP addresses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE provides flexibility where the number of nodes in a cluster and the maximum
    number of pods per node are configurable. The next topic details how pods are
    assigned IP addresses when pods are deployed in a GKE cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Pod networking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When a Pod is scheduled on a node, Kubernetes creates a network namespace for
    the Pod on the node's Linux kernel and connects the node's physical network interface
    to the Pod with a virtual network interface, thus allowing communication among
    pods within the same node.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes assigns an IP address (the Pod's IP) to the virtual network interface
    in the Pod's network namespace from a range of addresses reserved for Pods on
    the node. This address range is a subset of the IP address range assigned to the
    cluster for Pods, which can be configured when creating a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: GKE automatically configures VPC to recognize this range of IP addresses as
    an authorized secondary subnet of IP addresses. As a result, the pod's traffic
    is permitted to pass the anti-spoofing filters on the network. Also, because each
    node maintains a separate IP address base for its pods, the nodes don't need to
    perform network address translation on the pod's IP address. The next topic details
    Service networking, specifically, how services can effectively receive traffic
    from external sources via the use of GKE load balancers.
  prefs: []
  type: TYPE_NORMAL
- en: Service networking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A Service is a Kubernetes resource that creates a dynamic collection of IP addresses
    called endpoints. These IP addresses belong to the Pod that matches the Service
    label selector. Kubernetes creates a Service by assigning a static virtual IP
    address and this IP address is assigned from the pool of IP addresses reserved
    for services by the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Out of the available Service types, the `LoadBalancer` Service type is implemented
    in GKE using GCP's `LoadBalancer` is created within the GKE cluster. GCP will
    subsequently assign a static `LoadBalancer` IP address that is accessible from
    outside the cluster and the project.
  prefs: []
  type: TYPE_NORMAL
- en: 'For traffic sent to the GCP NLB, *Figure 8.17* depicts the interactions between
    the NLB and the nodes within the GKE cluster. These interactions are listed as
    follows in a step-by-step manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.17 – Interactions between the NLB and a GKE cluster within a VPC'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.17 – Interactions between the NLB and a GKE cluster within a VPC
  prefs: []
  type: TYPE_NORMAL
- en: '**Step-by-step interactions**:'
  prefs: []
  type: TYPE_NORMAL
- en: NLB will pick a random node in the cluster and forwards the traffic (say **Node
    2** as per *Figure 8.17*)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Service might be tied to multiple pods spread across the cluster nodes.
    The `kube-proxy` Service on the node receives the client request and will select
    a Pod matching the Service at random. The selected Pod can be on the same node
    or a different node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the selected Pod is on a different node (say **Pod 8**), then the client
    request will be sent to the other node (**Node 4**) from the original node (**Node
    2**). The response goes back to the original node (**Node 2**) that received the
    request and subsequently goes back to the client.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The preceding process provides a way to access services from an external client
    and maintains an even balance with respect to Pod usage. However, there is a possibility
    that within the Kubernetes cluster, a response might have to go through multiple
    nodes as the request was directed from one node to the other, resulting in a **double
    hop**.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid `externalTrafficPolicy`. If set to local, `kube-proxy` will pick a
    Pod on the local node (either **Pod 3** or **Pod 4**) and will not forward the
    client request to another node. However, this creates an imbalance and users must
    choose between better balance versus low-latency communication. GKE solves this
    by using the concept of container-native load balancing.
  prefs: []
  type: TYPE_NORMAL
- en: Container-native load balancing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The essence of container-native load balancing is that instead of directing
    traffic to nodes, traffic will be sent to pods directly, avoiding an additional
    hop. The connection is made directly between the load balancer and the pods. GKE
    accomplishes this by leveraging **GCP HTTP(S) Load Balancing** and the use of
    a data model called a **Network Endpoint Group** (**NEG**). GKE needs to run in
    VPC-native mode to use the container-native load balancing feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'A NEG is a set of network endpoints representing IP to port pairs. So instead
    of load balancing traffic using node IPs, the combination of Pod IPs and a port
    is used as a tuple. This information is maintained in the NEG. *Figure 8.18* depicts
    the interactions between GKE container-native load balancing and pods in GKE nodes
    through an NEG. As per *Figure 8.18*, a request to the container-native load balancer
    is forwarded to the NEG. The NEG then chooses the specific Pod based on the request,
    and directly forwards the traffic to the node associated with the Pod in a single
    hop, thus avoiding the *double hop*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.18 – Solving the double hop problem using container-native load
    balancing'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.18 – Solving the double hop problem using container-native load balancing
  prefs: []
  type: TYPE_NORMAL
- en: Apart from establishing a direct connection to the Pod, container-native load
    balancing allows direct visibility of Pods, leading to the possibility of accurate
    health checks. The source IP address is preserved thus giving insights into the
    roundtrip time between the client and the load balancer.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes a high-level overview of networking constructs specific to GKE.
    The next section summarizes the storage options available for containerized applications
    deployed in GKE.
  prefs: []
  type: TYPE_NORMAL
- en: Storage options for GKE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes offers storage abstractions in the form of Volumes and Persistent
    Volumes. These are used as storage options providing file system capacity that
    is directly accessible by applications running in a Kubernetes cluster. Persistent
    Volumes exist beyond the life of a container and can further be used as durable
    file storage or as a database backing store.
  prefs: []
  type: TYPE_NORMAL
- en: In GKE, Compute Engine persistent disks are used as persistent volumes. GKE
    also provides various managed backing stores such as Cloud SQL, Cloud Datastore,
    and so on, which removes the need to run a database as an application inside the
    GKE cluster, connecting applications in a GKE cluster to a managed datastore instead.
    For example, a frontend application in a GKE Cluster can be connected to Cloud
    SQL rather than the frontend application connecting to another application running
    a MySQL server. To be more specific, the frontend application can connect to Cloud
    SQL for database needs through a Cloud SQL proxy. This can be run inside the frontend
    application's Pod as a side-car container.
  prefs: []
  type: TYPE_NORMAL
- en: This abstracts away infrastructure requirements and reduces maintenance, allowing
    you to focus on the application. GCP offers managed services across relational,
    non-relational, and caching services that applications running in a GKE cluster
    can connect to.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to applications that might require a backend data store, there
    could be applications running in a GKE cluster that might need object storage.
    **Google Cloud Storage** (**GCS**) is an object storage Service. Object-based
    storage refers to the storage of an ordered group of bytes where the structure
    and semantics of those bytes are not important. It can be used for a variety of
    applications, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Serving images for a website
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streaming music, videos, and media hosting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constructing data lakes for analytics and machine learning workloads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications within the GKE cluster can access Cloud Storage using Cloud Storage
    APIs. This concludes the summary of the storage options available in GCP for applications
    deployed in GKE. The next section summarizes details on cloud operations from
    a GKE perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Operations for GKE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Google Kubernetes Engine** (**GKE**) provides native integration with **Google''s
    Cloud operations** – a suite of tools that allows you to monitor workloads, collect
    application logs, capture metrics and provide alerting or notification options
    on key metrics. Cloud operations and the respective suite of services are elaborated
    on in detail as part of [*Chapter 10*](B15587_10_Final_ASB_ePub.xhtml#_idTextAnchor218),
    *Exploring GCP Cloud Operations*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloud Operations for GKE is enabled by default at the time of cluster creation.
    However, it is possible to configure if the user chooses to disable Cloud Monitoring
    or Cloud Logging as part of the GKE cluster configuration. Cloud Operations for
    GKE monitors GKE clusters and provides a tailored, out-of-the-box dashboard that
    includes the following capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: Viewing cluster resources categorized by infrastructure, workloads, or services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inspecting namespaces, nodes, workloads, services, pods, and containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viewing application logs for pods and containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viewing key metrics related to clusters, such as CPU utilization, memory utilization,
    and so on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging and monitoring are two critical aspects of reliably running a Service
    or application in a GKE cluster. These will be covered as part of upcoming topics
    from the aspect of Cloud Operations for GKE.
  prefs: []
  type: TYPE_NORMAL
- en: Logging for GKE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GKE deploys applications and orchestrates multiple actions or events within
    a cluster. This results in a variety of logs such as application logs, system
    logs, event logs, and so on. Logging provides visibility of various actions that
    happen and is also considered a passive form of monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two options to view logs for a GKE cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Native Logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE Cloud Logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Native Logging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Kubernetes supports native logging to standard output and standard error. In
    Kubernetes, the *container engine* can be used to redirect stdin/out and standard
    error streams from the containers to a logging driver. This driver is configured
    to write these container logs in JSON format and store them in the `/var/log`
    directory at the node level. This includes logs from containers and logs from
    node control plane components such as `kubelet` and `kube-proxy`. These logs can
    be retrieved using the `kubectl logs` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `kubectl logs` command can be used to retrieve logs for a Pod or a specific
    container within a Pod. The command also provides options to retrieve logs for
    a specific period or you can retrieve a portion of logs using the `tail` option.
    A few of such examples are provided as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Kubernetes native logging can lead to node saturation as the log files continue
    to grow in the node's storage directory. GKE solves this to an extent by running
    the Linux log rotate utility to clean up the log files. Any log files older than
    a day or more than 100 MB will be automatically compressed and copied into an
    archive file.
  prefs: []
  type: TYPE_NORMAL
- en: GKE only stores the five most recently archived log files on the nodes and will
    delete the previous archived log files. Though this ensures that the node doesn't
    saturate in terms of disk space, it still poses a problem if older application
    logs need to be analyzed or researched.
  prefs: []
  type: TYPE_NORMAL
- en: By default, open source Kubernetes or K8s will delete logs related to a container
    either when a container is deleted or when a Pod tied to the container is deleted.
    GKE resolves problems related to node saturation and provides the ability to analyze
    logs related to deleted pods/containers by streaming the logs to Cloud Logging,
    as part of Cloud Operations. Application logs, system logs, and log events can
    be streamed to Cloud Logging, which will be discussed as part of upcoming topics.
  prefs: []
  type: TYPE_NORMAL
- en: GKE Cloud Logging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Open source Kubernetes or K8s doesn't provide a log storage solution for cluster-level
    logging. GKE handles this by streaming log events to Cloud Logging. **Cloud Logging**
    is a centralized log management utility and a fully managed Service. Cloud Logging
    can automatically scale and can ingest terabytes of log data per second.
  prefs: []
  type: TYPE_NORMAL
- en: GKE streams to Cloud Logging by using `FluentD` logging agents. A `FluentD`
    agent is implemented as a DaemonSet because it needs to run on every node in the
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Logging agents are pre-installed on each node as a DaemonSet and are pre-configured
    to push log data to Cloud Logging. `FluentD` collects container logs and system
    logs from the node. FluentD aggregates the logs, appends additional metadata,
    and pushes them to Cloud Logging.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8.19* illustrates the interactions of logs being sent from GKE to Cloud
    Logging using the `FluentD` DaemonSet Pod on each node in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.19 – FluentD agent capturing logs and sending to Cloud Logging'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.19 – FluentD agent capturing logs and sending to Cloud Logging
  prefs: []
  type: TYPE_NORMAL
- en: '**Event logs** are also streamed to Cloud Logging. Event logs refers to logs
    from operations that take place on the cluster such as the creation/deletion of
    a Pod, scaling of deployments, and so on. Events are stored as API objects on
    the Kubernetes master or control plane. GKE uses an event exporter in the cluster
    master to capture the events and automatically pushes them to Cloud Logging.'
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Logging provides the ability to capture metrics from streaming logs and
    create alerting policies as needed. Cluster actions such as autoscaling can be
    configured based on custom metrics. By default, GKE-specific logs related to a
    cluster are available in Cloud Logging for 30 days. For longer retention, Cloud
    Logging offers options to export logs to Cloud Storage or Big Query using the
    concept of log sinks. [*Chapter 10*](B15587_10_Final_ASB_ePub.xhtml#_idTextAnchor218),
    *Exploring GCP Cloud Operations*, elaborates on topics related to Cloud Logging
    in depth.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring for GKE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Monitoring provides insights into how an application or Service functions based
    on key internal metrics related to a GKE cluster. In addition, monitoring also
    provides insights from a user's perspective based on the user's interaction with
    the Service. The previous chapters on site reliability engineering ([*Chapter
    1*](B15587_01_Final_ASB_ePub.xhtml#_idTextAnchor014), *DevOps, SRE, and Google
    Cloud Services for CI/CD*, to [*Chapter 4*](B15587_04_Final_ASB_ePub.xhtml#_idTextAnchor087),
    *Building SRE Teams and Applying Cultural Practices*), clearly call out Service
    reliability as one of the key aspects. Monitoring is the fundamental input to
    ensure that a Service runs reliably.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring provides data that is critical to make decisions about applications.
    This data can be used further to resolve an ongoing incident and perform a blameless
    postmortem, and you can use it further to improve an existing test suite and provide
    inputs to the product and development team for any further improvements or fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: '**Cloud Monitoring** is Google''s managed solution that provides a solution
    to monitor the state of services using key parameters such as latency, throughput,
    and so on, and identify performance bottlenecks. From a GKE perspective, monitoring
    can be divided into two domains:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kube-apiserver`, `etcd`, and other infrastructure elements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pod-Level Monitoring**: This includes monitoring resources using container-specific
    metrics, tracking deployment-specific system metrics, tracking instances, monitoring
    uptime checks, and monitoring application-specific metrics designed by the application''s
    developer(s).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kubernetes uses the concept of labels to group or track resources. The same
    concept can be extended, and resources can be filtered in Cloud Monitoring using
    labels. Cloud Monitoring provides ways to track all relevant metrics and put them
    on a customized dashboard, thus giving visibility of a GKE cluster. *Figure 8.20*
    shows the built-in **GKE Dashboard** from Cloud Monitoring (with options displayed
    in collapsed mode). The GKE dashboard summarizes information about clusters, namespaces,
    nodes, workloads, Kubernetes services, Pods, and Containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.20 – Built-in GKE Dashboard from Cloud Monitoring'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.20 – Built-in GKE Dashboard from Cloud Monitoring
  prefs: []
  type: TYPE_NORMAL
- en: This completes the topic on Cloud Operations for GKE and concludes the section
    on GKE where many key concepts and core features were discussed in detail. The
    next section elaborates on the latest operation mode in GKE, called **Autopilot**.
  prefs: []
  type: TYPE_NORMAL
- en: GKE Autopilot – hands-on lab
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**GKE Autopilot or Autopilot** is one of the two modes of operation supported
    by GKE. The other mode being the standard mode (which was elaborated on at the
    start of this chapter). Autopilot removes the need to perform **do-it-yourself**
    (**DIY**) actions during cluster creation and instead creates a cluster with the
    industry-standard recommendations regarding networking and security. In addition,
    Autopilot removes the need to configure node pools or estimate the size of the
    cluster upfront. Nodes are automatically provisioned based on the types of deployed
    workloads and the user is essentially charged for the running workloads.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Autopilot is not only managed but is also a serverless K8s offering from GKE.
    Autopilot, however, does not offer all cluster configuration choices offered by
    the standard mode. The following table represents the configuration choices offered
    by Autopilot in comparison to the standard mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Table_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is a step-by-step guide to creating a GKE cluster in Autopilot
    mode:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the GCP Console and select the compute Service – **Kubernetes Engine**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the option to create a cluster and choose **Autopilot** mode. Refer to
    *Figure 8.21*:![Figure 8.21 – Select Autopilot mode during cluster creation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_08_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.21 – Select Autopilot mode during cluster creation
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Enter the name for the cluster as `my-autopilot-cluster`. Leave the default
    selections for the rest of the options and select the **CREATE** action. Refer
    to *Figure 8.22*:![Figure 8.22 – Creating a cluster in Autopilot mode
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_08_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.22 – Creating a cluster in Autopilot mode
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'This will initiate the cluster creation process but in Autopilot mode. Once
    the cluster is created, the cluster will be listed on the cluster list page as
    shown in *Figure 8.23*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.23 – New cluster created in Autopilot mode'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.23 – New cluster created in Autopilot mode
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some observations from the newly created Autopilot cluster. These
    observations differentiate the Autopilot cluster from a Standard mode cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: An autopilot cluster is created without pre-assigning any nodes upfront.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An autopilot cluster is always created as a regional cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The release channel for an autopilot cluster is the *Regular channel*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Node auto-provisioning and vertical Pod autoscaling are enabled by default.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced networking options such as intranode visibility, NodeLocal DNSCache,
    and HTTP load balancing are enabled by default.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security options such as Workload Identity and shielded GKE nodes are enabled
    by default. These security options are discussed in [*Chapter 9*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201),
    *Securing the Cluster Using GKE Security Constructs*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once a cluster is created in Autopilot mode, workloads can be deployed to the
    Autopilot cluster in the exact same way that workloads were previously deployed
    to a cluster in Standard mode. *Figure 8.24* refers to a Deployment created on
    the Autopilot cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.24 – Deployment details in an Autopilot cluster'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.24 – Deployment details in an Autopilot cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'The resources required to run the workloads are allocated to the Autopilot
    cluster. *Figure 8.25* displays the cluster list page with resources allocated
    to `my-autopilot-cluster`. In this specific case, 0.5 vCPUs and 2 GB memory are
    allocated to run a single Pod. So, the user is only charged for this workload:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.25 – Resource allocation for the Autopilot cluster after deploying
    a workload'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.25 – Resource allocation for the Autopilot cluster after deploying
    a workload
  prefs: []
  type: TYPE_NORMAL
- en: This completes the hands-on lab related to GKE Autopilot. This lab provides
    insights into the Autopilot configuration and how resources are allocated to the
    cluster after the deployment of workloads. This also brings us to the end of the
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given that open source Kubernetes or K8s involves a lot of setup and upkeep,
    we deep-dived into Google Kubernetes Engine or GKE, a GCP compute Service that
    runs containerized applications. The Kubernetes concepts learned in [*Chapter
    7*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154), *Understanding Kubernetes
    Essentials to Deploy Containerized Applications*, apply to GKE. We additionally
    explored GKE core features such as GKE node pools, GKE cluster configurations,
    autoscaling, and GKE's ability to integrate with other GCP services across networking
    and operations. The next chapter focuses on security-specific features related
    to the Google Kubernetes Engine, with the goal of hardening a cluster's security.
  prefs: []
  type: TYPE_NORMAL
- en: Points to remember
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are some important points to remember:'
  prefs: []
  type: TYPE_NORMAL
- en: GKE is fully managed, uses a container-optimized OS, and supports autoscaling,
    the auto-repair of nodes, and auto-upgrades.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE supports two modes of operations – Standard and Autopilot.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE Standard mode supports VPC-native traffic routing and HTTP load balancing
    as default options.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud operations for GKE are enabled as a default setting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A private Kubernetes engine cluster cannot be accessed publicly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A node pool represents a group of nodes with the same configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, a new node pool runs the latest Kubernetes version and can be configured
    for auto-upgrade or can be manually upgraded.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Node pools in a regional or multi-zonal cluster are replicated to multiple zones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A multi-zonal cluster will only have a single replica of the control plane.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A regional cluster has multiple replicas of the control plane running across
    multiple zones in a region.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A release channel is used to fix known issues or add new features or address
    any security risks or concerns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE creates a cluster with the default version if a specific version or release
    channel is not specified.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alpha features are only available in special GKE alpha clusters and are not
    available as part of release channels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Options to autoscale in GKE include the cluster autoscaler, HPA, VPA, and MPA
    (pre-GA).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cluster autoscaler automatically resizes a node pool in a GKE cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The HPA indicates when application instances should be scaled based on the current
    utilization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The HPA is not supported for DaemonSets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The VPA suggests recommended resources for a Pod based on the current utilization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The VPA can automatically update workloads if the `updateMode` attribute is
    set to *On*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MPA allows you to horizontally scale based on CPU and vertically scale based
    on memory at the same time. This is a pre-GA feature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Autoscaler provides two profile options to scale down: balanced and optimize-utilization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes' native option to avoid double hop is to set `externalTrafficPolicy`
    to `local`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE avoids double hop using GCP HTTP(S) Load Balancer and an NEG.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An NEG is a set of network endpoints representing IP to port pairs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE runs Linux's log rotate utility to clean up log files. Any log files older
    than a day or more than 100 MB will be automatically compressed and copied into
    an archive file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE only stores the five most recently archived log files on the nodes and will
    delete the previously archived log files.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE streams to Cloud Logging by using FluentD logging agents.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Event logs refers to logs from operations that take place on a cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Events are stored as API objects on the cluster master. GKE uses an event exporter
    to push events to Cloud Logging.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE cluster-specific logs are available in Cloud Logging for 30 days.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For longer retention, Cloud Logging can export logs using log sinks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE Autopilot mode supports cluster configurations where the availability type
    is *Regional*, the version is *Release Channel*, network isolation is *Private*
    or *Public*, and Kubernetes features are *Production*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information on GCP''s approach to DevOps, read the following articles:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Kubernetes**: [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Google Kubernetes Engine**: [https://cloud.google.com/kubernetes-engine](https://cloud.google.com/kubernetes-engine
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Practice test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: How do you create control plane components in GKE?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Create worker nodes and then create control plane components on the worker
    nodes.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) A GKE cluster does not mandate the creation of control plane components.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Create control plane components on a node group called `master` and the worker
    nodes are placed in a node group called `worker`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) The control plane components are automatically created and managed by GKE
    on behalf of the user.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Pod `p1` has three containers – `c1`, `c2`, and `c3`. The user wants to view
    the logs of container `c2`. Select the option that represents the appropriate
    CLI command to view the logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `kubectl logs -p p1 -c c2`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) `kubectl logs p1 -c c2`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) `kubectl logs pod=p1 container=c2`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) `kubectl logs p1 container=c2`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The company *Alpha* is about to launch a stateless web application to offer
    a new e-commerce Service. The web application will have steady traffic with occasional
    peaks, especially when special offers are announced for customers. Select the
    option that depicts an appropriate cluster design in this case:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Deploy a standard cluster and use a Deployment with the HPA.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Deploy a cluster with autoscaling and use a Deployment with the HPA.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Deploy a standard cluster and use a Deployment with the VPA.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Deploy a cluster with autoscaling and use a Deployment with the VPA.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Choose the cluster configuration that could withstand it if there was a loss
    of a GCP zone:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Create a regional cluster.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Create a Redis cluster that can cache the resource information of the zone
    where cluster resources are hosted.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Create two clusters in separate zones and create a load balancer between
    them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) None of the above.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select the Google Cloud Service where private GKE clusters can use Docker images
    from?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Cloud Source Repositories
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Container Registry
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Cloud Build
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) All of the above
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the allowed maximum clusters per zone:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Unlimited
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the command to get authentication credentials to interact with a cluster
    named `my-cluster`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `gcloud containers clusters get-credentials my-cluster`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) `gcloud container clusters get-credentials my-cluster`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) `gcloud container cluster get-credentials my-cluster`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) `gcloud containers cluster get-credentials my-cluster`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the command that can retrieve pods in a cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `gcloud get pods`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) `kubectl list pods`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) `gcloud list pods`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) `kubectl get pods`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The company *Real World* decides to use a third-party monitoring solution to
    monitor an application deployed in a GKE cluster. Select the best approach to
    deploy the third-party monitoring solution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) It is not possible to use a third-party monitoring solution in GKE.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Download the monitoring solution for Cloud Marketplace.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Deploy the monitoring solution in a Pod as a DaemonSet.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Deploy the monitoring solution in a Pod as a ReplicaSet.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A VPC on Google Cloud is a:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Zonal resource
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Global resource
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Regional resource
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Multi-Regional resource
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'An application called *my-app* in GKE needs access to a managed MySQL database.
    Select the most appropriate option:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Run MySQL as an application in the cluster. The *my-app* application will
    connect with the MySQL application through the ClusterIP Service.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Use Cloud SQL to run MySQL database. Run the Cloud SQL proxy as a side-car
    container insider the application's Pod.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Run MySQL as an application in the cluster. The *my-app* application will
    connect with the MySQL application through the `LoadBalancer` Service.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Use Cloud SQL for running MySQL Database. Run the Cloud SQL proxy as a ClusterIP
    Service.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Google Network Load Balancing distributes the following traffic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) TCP
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) UDP
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) TCP or UDP
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) None of the above
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'From an availability-type point of view, a cluster created in *Autopilot* mode
    is:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Zonal
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Multi-zonal
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Regional
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Zonal and regional
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the option that is not a supported release channel in GKE:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Regular
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Alpha
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Rapid
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Stable
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the possible cluster configurations based on network isolation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Standard and Private
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Standard and Public
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Standard and Default
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Private and Public
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: (d) – The control plane components such as the `kube-api` server, scheduler,
    and so on form the cluster master and are set up and managed by GKE.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) – `kubectl logs p1 -c c2`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) – Deploy a cluster with autoscaling and use Deployment with HPA.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (a) – Create a regional cluster as the workload is spread across multiple zones
    in one region.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) – Container Registry
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) – 50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) - `gcloud container clusters get-credentials my-cluster`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (d) - `kubectl get pods`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (c) - Deploy the monitoring solution in a Pod as a DaemonSet.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) – Global resource
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (c)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (c) – TCP or UDP
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (c) – Regional
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) – Alpha
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (d) – Private and Public
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
