- en: '*Chapter 8*: Understanding GKE Essentials to Deploy Containerized Applications'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第8章*：理解 GKE 基础知识以部署容器化应用'
- en: Kubernetes or K8s is an open source container orchestration system for automating
    the application deployment, scaling, and management of a cluster running containerized
    applications. The previous chapter introduced K8s fundamentals, including cluster
    anatomy, master plane components, Kubernetes objects (such as Pods and Services),
    workloads such as Deployments, StatefulSets, DaemonSets, and so on, and deep-dived
    into deployment strategies. However, setting up an open source Kubernetes cluster
    involves a lot of work at the infrastructure level and will also take a lot of
    time to set up. This also includes post-maintenance activities such as updating,
    upgrading, or repairing the cluster. GCP provides a compute offering that provides
    a managed Kubernetes or K8s environment called **Google Kubernetes Engine** (**GKE**).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 或 K8s 是一个开源的容器编排系统，用于自动化应用程序的部署、扩展和管理运行容器化应用程序的集群。前一章介绍了 K8s 的基础知识，包括集群结构、主平面组件、Kubernetes
    对象（如 Pods 和 Services）、工作负载（如 Deployments、StatefulSets、DaemonSets 等），并深入探讨了部署策略。然而，搭建一个开源的
    Kubernetes 集群涉及大量基础设施层面的工作，并且需要花费大量时间来设置。此外，还包括后期的维护活动，如更新、升级或修复集群。GCP 提供了一个计算服务，提供一个托管的
    Kubernetes 或 K8s 环境，称为 **Google Kubernetes Engine** (**GKE**)。
- en: 'The chapter introduces Google Kubernetes Engine as the managed Kubernetes option
    in GCP and uses the concepts introduced in [*Chapter 7*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154),
    *Understanding Kubernetes Essentials to Deploy Containerized Applications*, to
    create a managed GKE cluster, deploy a containerized application into the cluster,
    and expose the application to be accessible from external clients. The chapter
    later details key GKE features, including the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了作为 GCP 中托管 Kubernetes 选项的 Google Kubernetes Engine，并使用在 [*第7章*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154)
    中介绍的概念，*理解 Kubernetes 基础知识以部署容器化应用*，来创建一个托管的 GKE 集群，将容器化应用程序部署到集群中，并使该应用程序可供外部客户端访问。本章随后详细介绍了
    GKE 的关键特性，包括以下内容：
- en: '**Google Kubernetes Engine (GKE) – introduction**'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Kubernetes Engine (GKE) – 介绍**'
- en: '**GKE – core features**'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GKE – 核心特性**'
- en: '**GKE Autopilot – hands-on lab**'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GKE 自动驾驶模式 – 实操实验**'
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'There are four main technical requirements:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 有四个主要的技术要求：
- en: 'A valid **Google Cloud Platform** (**GCP**) account to go hands-on with GCP
    services: [https://cloud.google.com/free](https://cloud.google.com/free)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个有效的 **Google Cloud Platform** (**GCP**) 账户，以便使用 GCP 服务： [https://cloud.google.com/free](https://cloud.google.com/free)
- en: 'Install Google Cloud SDK: [https://cloud.google.com/sdk/docs/quickstart](https://cloud.google.com/sdk/docs/quickstart)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '安装 Google Cloud SDK: [https://cloud.google.com/sdk/docs/quickstart](https://cloud.google.com/sdk/docs/quickstart)'
- en: 'Install Git: [https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '安装 Git: [https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)'
- en: 'Install Docker: [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '安装 Docker: [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)'
- en: Google Kubernetes Engine (GKE) – introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Google Kubernetes Engine (GKE) – 介绍
- en: GKE is managed K8s and abstracts away the need to manage the master plane components
    from a user's standpoint. Creating a GKE cluster is much easier than creating
    a K8s cluster. This is because GKE cluster creation removes the need to manually
    create nodes, configure nodes and certificates, and establish network communication
    between the nodes. GKE also offers options to autoscale and manage auto-upgrades
    of the cluster's node software.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 是一个托管的 K8s，能够从用户的角度抽象出管理主平面组件的需求。创建 GKE 集群比创建 K8s 集群要简单得多。这是因为 GKE 集群创建过程中无需手动创建节点、配置节点和证书、以及建立节点间的网络通信。GKE
    还提供了自动扩展和管理集群节点软件自动升级的选项。
- en: 'The following are the key features of a GKE cluster. These features differentiate
    GKE from open source Kubernetes or K8s:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 GKE 集群的关键特性，这些特性使 GKE 与开源 Kubernetes 或 K8s 区别开来：
- en: Fully managed and abstracts away the need for a user to provide underlying resources.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全托管，抽象出用户无需提供底层资源的需求。
- en: Uses a container-optimized OS, an OS that is maintained by Google and is built
    to scale quickly with minimal resource requirements.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一种容器优化的操作系统，这是一种由 Google 维护的操作系统，专为快速扩展且资源需求最小化而设计。
- en: Supports auto-upgrade and provides options to either get the latest available
    features or a more stable version without manual intervention.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持自动升级，并提供选项，可以选择获取最新的功能，或是选择更稳定的版本，而无需手动干预。
- en: Provides the ability to auto-repair nodes by continuously monitoring the status
    of the nodes. If unhealthy, the nodes are gracefully drained and recreated.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供自动修复节点的功能，通过持续监控节点的状态。如果节点不健康，会优雅地将其排空并重新创建。
- en: Automatically scales the cluster by adding more nodes as needed.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据需要自动扩展集群，添加更多的节点。
- en: 'In addition to the preceding list, here are some additional key features that
    are available in K8s but need to be added and explicitly maintained as add-ons.
    These come as standard with GKE, thus making GKE a more viable and preferred option
    when compared to K8s:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除了前述功能，以下是一些 K8s 中可用的关键功能，这些功能需要作为附加组件添加并显式维护。而这些功能在 GKE 中是标准配置，使得 GKE 相比 K8s
    更加可行和优选：
- en: Load balancer – GKE provides a HTTP(S) load balancer.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负载均衡器——GKE 提供了一个 HTTP(S) 负载均衡器。
- en: DNS – GKE implements service discovery and provides a managed DNS.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DNS——GKE 实现了服务发现，并提供了托管 DNS。
- en: Logging, monitoring, and dashboard – GKE provides these features built in due
    to its integration with Google Cloud operations.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志、监控和仪表板——由于与 Google Cloud 操作的集成，GKE 提供了这些内置功能。
- en: Until recently, GKE offered only one mode of operation called **Standard** (also
    referred to as default). The Standard mode allows users to select the configurations
    needed to run workloads such as the node's machine type. This mode also allows
    you to select security configuration features, provides the ability to group nodes
    that run similar workloads, provides options to configure networking, and so on.
    Essentially, creating a cluster through GKE Standard mode is much easier than
    in open source K8s, but there is still a learning curve.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 直到最近，GKE 只提供了一种操作模式，称为 **标准** 模式（也称为默认模式）。标准模式允许用户选择运行工作负载所需的配置，例如节点的机器类型。此模式还允许选择安全配置功能，提供将运行相似工作负载的节点分组的能力，提供配置网络的选项等。总的来说，通过
    GKE 标准模式创建集群比在开源 K8s 中要容易，但仍然有学习曲线。
- en: GKE recently introduced a new mode of operation called Autopilot. Autopilot
    has many of the configurations pre-selected and essentially creates a production-grade
    cluster that is hardened from a security standpoint. There are a few options to
    configure but, most importantly, the nodes are provisioned only when workloads
    are deployed. Autopilot mode will be discussed in detail later in this chapter
    through a hands-on lab.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 最近引入了一种新的操作模式，称为 Autopilot。Autopilot 预先选择了许多配置，基本上创建了一个从安全角度强化的生产级集群。虽然有一些配置选项，但最重要的是，只有在工作负载部署时才会配置节点。Autopilot
    模式将在本章后面通过动手实验详细讨论。
- en: Important note
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The current chapter focuses on *Standard* mode unless explicitly specified.
    This will help you to understand the available options while creating a GKE cluster
    and provides insights into GKE features. Later in this chapter, the Autopilot
    mode will be elaborated on, calling out the key differences between the Standard
    and Autopilot modes, along with a hands-on lab.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当前章节重点讲解 *标准* 模式，除非明确说明。本章将帮助你了解在创建 GKE 集群时可用的选项，并提供 GKE 功能的洞见。后续章节会详细介绍 Autopilot
    模式，强调标准模式和 Autopilot 模式之间的主要区别，并附带一个动手实验。
- en: GKE provides seamless integration with multiple service offerings from GCP.
    GKE provides options to automate deployment by building code stored in a source
    code repository using Cloud Build, which results in private container images that
    could be stored in Google's Container Registry. In addition, access to the cluster
    and the ability to configure GKE cluster options can be controlled via Google's
    **Identity and Access Management** (**IAM**). GKE integrates with GCP's network
    offerings as a GKE cluster is created as part of Google's Virtual Private Cloud
    or VPC. GCP provides insights into a GKE cluster and its resources as GKE integrates
    with Google's Cloud operations, a suite of tools from Google aimed at providing
    integrated services related to monitoring and logging.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 与 GCP 的多项服务提供无缝集成。GKE 提供选项，通过使用 Cloud Build 构建存储在源代码仓库中的代码自动化部署，从而生成可以存储在
    Google 容器注册表中的私有容器镜像。此外，通过 Google 的**身份和访问管理**（**IAM**）可以控制访问集群的权限和配置 GKE 集群选项。GKE
    与 GCP 的网络服务集成，因为 GKE 集群作为 Google 的虚拟私有云（VPC）的一部分创建。GCP 提供对 GKE 集群及其资源的洞察，GKE 与
    Google 的 Cloud operations 集成，Cloud operations 是 Google 提供的一套旨在提供与监控和日志相关的集成服务的工具。
- en: We will start by creating a GKE cluster through a step-by-step process. This
    will provide an insight into the possible configuration options. Once the cluster
    is created, the user will be able to deploy an application through the concept
    of a Deployment and expose the application through the concept of a Service. The
    application runs inside a container wrapped by a Pod. The Deployment specification
    will manage the Pod. The Pod is then exposed using the concept of a Service. The
    concepts of Pods, Deployments, and services are K8s fundamentals that were discussed
    in [*Chapter 7*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154), *Understanding
    Kubernetes Essentials to Deploy Containerized Applications*, and these concepts
    will be put into action on an actual GKE cluster.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过逐步过程创建一个 GKE 集群，这将提供对可能配置选项的洞察。集群创建完成后，用户将能够通过 Deployment 的概念部署应用，并通过 Service
    的概念暴露应用。应用运行在由 Pod 包裹的容器中。Deployment 规格将管理 Pod。Pod 随后通过 Service 的概念进行暴露。Pod、Deployment
    和 Service 这些概念是 K8s 基础知识，已经在[*第 7 章*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154)《理解
    Kubernetes 基础知识以部署容器化应用》中讨论过，这些概念将在实际的 GKE 集群中付诸实践。
- en: Creating a GKE cluster
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 GKE 集群
- en: 'There are multiple ways to create a GKE cluster – the Cloud Console, CLI, or
    REST. To create a cluster, the user or the service account should have one of
    the following pre-defined roles: Kubernetes Engine Admin or Kubernetes Engine
    Cluster Admin.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 GKE 集群有多种方式——Cloud Console、CLI 或 REST。要创建集群，用户或服务帐户应具备以下预定义角色之一：Kubernetes
    引擎管理员或 Kubernetes 引擎集群管理员。
- en: 'The following is a step-by-step process to create a GKE cluster from the Google
    Cloud Console. The mode of operation will be **Standard** in this specific example:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过 Google Cloud Console 创建 GKE 集群的逐步过程。此示例中的操作模式为**标准**模式：
- en: Navigate to the GCP Console and select the compute service – **Kubernetes Engine**.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航至 GCP 控制台并选择计算服务 – **Kubernetes 引擎**。
- en: Select the option to create a cluster and choose the **Standard** mode.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择创建集群的选项并选择**标准**模式。
- en: Enter the name for the cluster as `my-first-cluster`.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入集群名称为 `my-first-cluster`。
- en: Leave the default selections for the rest of the options. Refer to *Figure 8.1*:![Figure
    8.1 – Creating a GKE Cluster from the GCP Console
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保留其余选项的默认选择。请参见 *图 8.1*：
- en: '](img/B15587_08_01.jpg)'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_01.jpg)'
- en: Figure 8.1 – Creating a GKE Cluster from the GCP Console
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.1 – 从 GCP 控制台创建 GKE 集群
- en: Select the option to **CREATE** the cluster. This will initiate the cluster
    creation process.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**创建**集群的选项。这将启动集群创建过程。
- en: 'The newly created cluster will be displayed on the cluster home page. Refer
    to *Figure 8.2*:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新创建的集群将在集群主页显示。请参见 *图 8.2*：
- en: '![Figure 8.2 – The GKE cluster list page displays the newly created cluster'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.2 – GKE 集群列表页面显示新创建的集群](img/B15587_08_02.jpg)'
- en: '](img/B15587_08_02.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_02.jpg)'
- en: Figure 8.2 – The GKE cluster list page displays the newly created cluster
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 – GKE 集群列表页面显示新创建的集群
- en: 'The newly created cluster used the default options. Nothing really was changed
    during the cluster creation except for the cluster name. The following are some
    important points to know when a GKE cluster is created with default options. Each
    of the default options mentioned in the following list can be explicitly changed
    during cluster creation:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 新创建的集群使用了默认选项。除集群名称外，集群创建过程中没有进行任何实际更改。以下是使用默认选项创建GKE集群时需要了解的一些重要事项。列表中提到的每个默认选项都可以在集群创建过程中显式更改：
- en: The default **Location type** of the cluster is **Zonal**. **Location type**
    refers to the cluster based on availability requirements. The options are **Zonal**
    and **Regional**.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群的默认**位置类型**为**区域性**。**位置类型**指的是基于可用性要求的集群类型。可选项有**区域性**和**区域级别**。
- en: The default `us-central1-c`. This indicates the zone where the control plane
    components are created.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认值为`us-central1-c`。这表示控制平面组件的创建区域。
- en: The default `us-central1-c`. This indicates where the nodes are created. Multiple
    locations within a region can be selected to form a cluster where the location
    type is a multi-zonal cluster.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认值为`us-central1-c`。这表示节点创建的位置。可以选择区域内的多个位置来形成一个集群，其中位置类型是多区域集群。
- en: The default **Control plane version** is **Release channel**. **Control plane
    version** provides options to signify the cluster version. The cluster version
    is indicative of the preferred feature set in terms of stability.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认**控制平面版本**为**发布通道**。**控制平面版本**提供了指示集群版本的选项。集群版本代表了在稳定性方面首选的功能集。
- en: The `3`, indicating the number of worker nodes. The cluster, by default, only
    has 1 node pool. It's important to note that the cluster size doesn't include
    the master node count. Customers only pay for the worker nodes. The master node
    and the associated master plane components are entirely managed by GKE.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`3`，表示工作节点的数量。集群默认只有1个节点池。需要注意的是，集群大小不包括主节点的数量。客户仅需为工作节点付费。主节点及其相关的主平面组件完全由GKE管理。'
- en: The `default-pool`. A node pool is a collection of VMs.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`default-pool`。节点池是虚拟机的集合。'
- en: The default node pool consists of 3 nodes and the machine type for the node
    is `e2-medium` (2 vCPU, 4 GB memory).
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认节点池由3个节点组成，节点的机器类型为`e2-medium`（2个vCPU，4 GB内存）。
- en: The default **Maintenance Window** is **anytime**. This implies that GKE maintenance
    can run at any time on the cluster. This is not the preferred option when running
    production workloads.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认**维护窗口**为**随时**。这意味着GKE维护可以在集群上的任何时间进行。这不是在运行生产工作负载时的首选选项。
- en: The default cluster type based on networking is **Public cluster** and the default
    **VPC network** is **default**. This indicates how clients can reach the control
    plane and how applications in the cluster communicate with each other and with
    the control plane.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于网络的默认集群类型为**公共集群**，默认**VPC网络**为**default**。这表示客户端如何访问控制平面，以及集群中的应用程序如何彼此之间以及与控制平面进行通信。
- en: Advanced networking options such as **VPC-native traffic routing** and **HTTP
    Load Balancing** are *enabled* by default. These options are discussed in detail
    in the sub-section *Networking in GKE*, later in this chapter
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级网络选项，如**VPC原生流量路由**和**HTTP负载均衡**，默认是*启用*的。这些选项将在本章稍后的子章节*GKE中的网络*中详细讨论。
- en: '`110`.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`110`。'
- en: The security feature **Shielded GKE Node** is *enabled*. This feature provides
    strong cryptographic identity for nodes joining a cluster and is discussed in
    detail as part of [*Chapter 9*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201),
    *Securing the Cluster Using GKE Security Constructs*.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全功能**Shielded GKE节点**已*启用*。该功能为加入集群的节点提供强加密身份，并将在[*第9章*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201)中详细讨论，章节标题为*使用GKE安全构件保护集群*。
- en: Cloud operations for GKE are enabled and are set to **System, workload logging
    and monitoring**. This feature aggregates logs, events, and metrics for both infrastructure
    and application-level workloads.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE的云操作已启用，并设置为**系统、工作负载日志记录和监控**。此功能会聚合基础设施和应用级工作负载的日志、事件和指标。
- en: 'A cluster can also be created from the **Command-Line Interface** (**CLI**).
    The following is the CLI command to create a cluster with default options. The
    default options used in the CLI are the same as the default options used while
    creating a cluster from the console as described previously. One significant difference,
    however, is that it is mandatory to explicitly specify a zone while executing
    through the CLI. However, the zone is auto-filled in the UI unless modified:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以通过**命令行界面**（**CLI**）创建集群。以下是使用默认选项创建集群的 CLI 命令。CLI 中使用的默认选项与之前从控制台创建集群时使用的默认选项相同。一个显著的区别是，在通过
    CLI 执行时，必须显式指定一个区域。然而，在 UI 中，区域会自动填充，除非进行了修改：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This CLI command can be run from the terminal window of your local machine,
    which has Google Cloud SDK installed and configured. Alternatively, the CLI command
    can also be executed using Google Cloud Shell, activated through the Google Cloud
    Console.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 该 CLI 命令可以从本地计算机的终端窗口运行，该计算机已经安装并配置了 Google Cloud SDK。或者，也可以通过 Google Cloud
    Console 激活 Google Cloud Shell 来执行该命令。
- en: Given that a GKE cluster is created, the next step is to deploy an application
    onto the GKE cluster and expose the application to an external client. This is
    discussed as the next topic.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GKE 集群创建后，下一步是将应用程序部署到 GKE 集群，并将其公开给外部客户端。接下来将讨论这一主题。
- en: GKE cluster – deploying and exposing an application
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE 集群 – 部署并公开应用程序
- en: In [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131), *Building
    code using Cloud Build, and Pushing to Container Registry*, we created a container
    image, and the container image was deployed using Cloud Run. In this chapter and
    in this sub-section, we will reuse this image and deploy it to the newly created
    GKE cluster by creating appropriate workloads. Once the application is deployed,
    the application will be exposed via a Service so that the application can be reached
    via an external client such as a web browser.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第 6 章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)中，*使用 Cloud Build
    构建代码并推送到容器注册表*，我们创建了一个容器镜像，并使用 Cloud Run 部署了该容器镜像。在本章及本小节中，我们将重用此镜像，并通过创建适当的工作负载将其部署到新创建的
    GKE 集群中。应用程序部署后，将通过服务公开，以便外部客户端（如网页浏览器）可以访问该应用程序。
- en: Important note
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: For continuity from an example standpoint, we will be using the container image
    created in [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131), *Building
    code using Cloud Build, and Pushing to Container Registry* – `gcr.io/gcp-devops-2021/cloud-build-trigger`.
    It's recommended to use an appropriate container image of your choice that you
    have access to. For example, if you followed the step-by-step instructions in
    [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131), *Building code
    using Cloud Build, and Pushing to Container Registry*, and ended up creating a
    container image in your project, you can reuse the same image in this chapter.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持示例的连续性，我们将使用在[*第 6 章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)中创建的容器镜像，*使用
    Cloud Build 构建代码并推送到容器注册表* – `gcr.io/gcp-devops-2021/cloud-build-trigger`。建议使用你有权限访问的适当容器镜像。例如，如果你按照[*第
    6 章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)中的逐步说明，*使用 Cloud Build 构建代码并推送到容器注册表*，并最终在你的项目中创建了一个容器镜像，你可以在本章中重用相同的镜像。
- en: 'We will deploy the application and expose the application in two different
    ways:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以两种不同的方式部署并公开应用程序：
- en: GKE Console
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE 控制台
- en: The CLI approach via Cloud Shell
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 Cloud Shell 的 CLI 方法
- en: It's important to note that a cluster is typically deployed in most cases through
    the command line. However, we will first explore the GKE Console approach as this
    will give us insights into the available configuration options. This is covered
    as the next topic.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，在大多数情况下，集群通常通过命令行部署。然而，我们将首先探索 GKE 控制台的方法，因为这将使我们深入了解可用的配置选项。接下来将讨论这一主题。
- en: GKE Console
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE 控制台
- en: The first step is to deploy the application to the GKE cluster through the GKE
    Console.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是通过 GKE 控制台将应用程序部署到 GKE 集群中。
- en: Deploying an application to the GKE cluster
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将应用程序部署到 GKE 集群
- en: 'The following is the step-by-step process to deploy an application through
    the GKE Console:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在 GKE 控制台中部署应用程序的逐步过程：
- en: Navigate to the **Clusters** page in the **Kubernetes Engine** section of the
    GCP Console.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 GCP 控制台的 **Kubernetes Engine** 部分，导航到 **Clusters** 页面。
- en: Select the cluster that was previously created – `my-first-cluster`.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择之前创建的集群 – `my-first-cluster`。
- en: On the left-hand pane, select the section **Workloads**. From a GKE perspective,
    workloads refer to Deployments, StatefulSets, DaemonSets, Jobs, and CronJobs.
    There are no workloads at this moment and the current state will be as shown in
    *Figure 8.3*:![Figure 8.3 – The Workloads section of a newly created cluster
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧面板中，选择**工作负载**部分。从 GKE 的角度来看，工作负载指的是 Deployments、StatefulSets、DaemonSets、Jobs
    和 CronJobs。目前没有工作负载，当前状态如下所示，参见*图 8.3*：![图 8.3 – 新创建集群的工作负载部分
- en: '](img/B15587_08_03.jpg)'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_03.jpg)'
- en: Figure 8.3 – The Workloads section of a newly created cluster
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.3 – 新创建集群的工作负载部分
- en: Create a workload by selecting the **DEPLOY** option. This action allows you
    to create a Deployment object in a two-step process.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过选择**部署**选项来创建工作负载。此操作允许您通过两步过程创建 Deployment 对象。
- en: The first step to create a Deployment is to define the containers required for
    the Deployment. Select the container image created in [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131),
    *Building code using Cloud Build, and Pushing to Container Registry*. For this
    example, select the container image `gcr.io/gcp-devops-2021/cloud-build-trigger`.
    Refer to *Figure 8.4*. Optionally, add environment variables for the container
    and click on **Done**:![Figure 8.4 – Selecting container image while defining
    a container for Deployment
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 Deployment 的第一步是定义 Deployment 所需的容器。选择在[*第 6 章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)中创建的容器镜像，*使用
    Cloud Build 构建代码并推送到容器注册表*。对于这个示例，选择容器镜像 `gcr.io/gcp-devops-2021/cloud-build-trigger`。参见*图
    8.4*。可选地，添加容器的环境变量，并点击**完成**：![图 8.4 – 在定义 Deployment 容器时选择容器镜像
- en: '](img/B15587_08_04.jpg)'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_04.jpg)'
- en: Figure 8.4 – Selecting container image while defining a container for Deployment
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.4 – 在定义 Deployment 容器时选择容器镜像
- en: Optionally, multiple containers can be added to the Pod by using the **ADD CONTAINER**
    option. Refer to *Figure 8.5*:![Figure 8.5 – The option to add multiple containers
    to a Deployment
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，可以通过使用**添加容器**选项将多个容器添加到 Pod 中。请参阅*图 8.5*：![图 8.5 – 向 Deployment 添加多个容器的选项
- en: '](img/B15587_08_05.jpg)'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_05.jpg)'
- en: Figure 8.5 – The option to add multiple containers to a Deployment
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.5 – 向 Deployment 添加多个容器的选项
- en: The second step in creating a Deployment is to configure the Deployment. This
    includes specifying the application name, namespace, labels, and the cluster to
    which the application should be deployed. For this specific example, set `hello-world`,
    `default`, `app` and `hello-world`, and select the cluster called `my-first-cluster`.
    Refer to *Figure 8.6*:![Figure 8.6 – Configuring a Deployment by specifying the
    required attributes
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 Deployment 的第二步是配置 Deployment。这包括指定应用程序名称、命名空间、标签以及应用程序应该部署到的集群。对于这个具体示例，设置
    `hello-world`、`default`、`app` 和 `hello-world`，并选择名为 `my-first-cluster` 的集群。参见*图
    8.6*：![图 8.6 – 通过指定所需属性来配置 Deployment
- en: '](img/B15587_08_06.jpg)'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_06.jpg)'
- en: Figure 8.6 – Configuring a Deployment by specifying the required attributes
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.6 – 通过指定所需属性来配置 Deployment
- en: Before selecting the **DEPLOY** option, the configuration YAML can be viewed
    by selecting the **VIEW YAML** option as shown in *Figure 8.6*. By default, the
    number of replicas is defined as 3\. This can optionally be changed to the desired
    replica count.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在选择**部署**选项之前，可以通过选择**查看 YAML**选项来查看配置的 YAML，如*图 8.6*所示。默认情况下，副本数定义为 3。这可以根据需要更改为所需的副本数量。
- en: Initiate the deployment creation process by selecting the **DEPLOY** option.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过选择**部署**选项来启动部署创建过程。
- en: 'The newly created Deployment – `hello-world` – will be displayed as follows.
    This Deployment created three replicas with the same image. Refer to *Figure 8.7*:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新创建的 Deployment – `hello-world` – 将如下所示显示。此 Deployment 创建了三个副本，使用相同的镜像。请参阅*图
    8.7*：
- en: '![Figure 8.7 – Details of the newly created Deployment'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.7 – 新创建的 Deployment 的详细信息'
- en: '](img/B15587_08_07.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_07.jpg)'
- en: Figure 8.7 – Details of the newly created Deployment
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 – 新创建的 Deployment 的详细信息
- en: 'It is important to note that the newly created Deployment – `hello-world` –
    cannot be accessed from external clients (such as a web browser or through a `ping`
    command) as the Deployment is not exposed as a Service. However, the application
    can still be tested by using the `port-forward` option. The CLI commands required
    to execute this option are shown in the following snippet. These commands can
    be executed through Google Cloud Shell:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，新创建的部署 – `hello-world` – 不能被外部客户端（如 Web 浏览器或通过 `ping` 命令）访问，因为该部署没有被暴露为
    Service。然而，仍然可以通过使用 `port-forward` 选项进行测试。执行此选项所需的 CLI 命令如下所示。这些命令可以通过 Google
    Cloud Shell 执行：
- en: '[PRE1]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once the preceding `port-forward` command is executed, traffic coming on `127.0.0.1:10080`
    will be forwarded to port `8080`. Port `8080` is the container port related to
    the `hello-world` Deployment. Refer to *Figure 8.8*:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦执行上述 `port-forward` 命令，来自 `127.0.0.1:10080` 的流量将被转发到端口 `8080`。端口 `8080` 是与
    `hello-world` 部署相关的容器端口。参见 *图 8.8*：
- en: '![Figure 8.8 – Forwarding traffic to a container inside a Pod'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.8 – 将流量转发到 Pod 内部的容器'
- en: '](img/B15587_08_08.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_08.jpg)'
- en: Figure 8.8 – Forwarding traffic to a container inside a Pod
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 – 将流量转发到 Pod 内部的容器
- en: 'To test whether traffic is getting forwarded, open another Cloud Shell window
    and run the `curl` command as shown. This will do a REST call invocation against
    the application running inside the container of a Pod. Refer to *Figure 8.9*:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试流量是否被转发，打开另一个 Cloud Shell 窗口并运行如下 `curl` 命令。这将对在 Pod 容器内运行的应用进行 REST 调用。参见
    *图 8.9*：
- en: '![Figure 8.9 – Result of accessing the application in a Pod through port-forwarding'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.9 – 通过端口转发访问 Pod 中应用的结果'
- en: '](img/B15587_08_09.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_09.jpg)'
- en: Figure 8.9 – Result of accessing the application in a Pod through port-forwarding
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9 – 通过端口转发访问 Pod 中应用的结果
- en: Alternatively, you can also use the web preview option on port `10080` in Cloud
    Shell to view the application. Given that the application is now deployed and
    is working as expected, the next step is to expose the application as a Service.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你也可以在 Cloud Shell 中使用 `10080` 端口的 Web 预览选项来查看应用。由于应用已经部署并按预期工作，下一步是将该应用暴露为
    Service。
- en: Exposing the application as a Service
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将应用暴露为 Service
- en: 'The following is a step-by-step process to expose the application as a Service
    through the GCP Console:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过 GCP 控制台将应用暴露为 Service 的逐步过程：
- en: Navigate to the **Clusters** page in the **Kubernetes Engine** section of the
    GCP Console.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 GCP 控制台中 **Kubernetes Engine** 部分的 **Clusters** 页面。
- en: Select the cluster that was previously created – `my-first-cluster`.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择之前创建的集群 – `my-first-cluster`。
- en: Select the Deployment that was previously created – `hello-world`.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择之前创建的部署 – `hello-world`。
- en: Under the **Actions** menu on the deployment details page, select the **EXPOSE**
    option. This will open a pop-up window where **Port**, **Target port**, **Protocol**,
    and **Service type** need to be selected.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在部署详情页面的 **Actions** 菜单下，选择 **EXPOSE** 选项。这将打开一个弹出窗口，需要选择 **端口**、**目标端口**、**协议**
    和 **Service 类型**。
- en: Enter `80` (this represents the port where the Service will be listening for
    incoming traffic), `8080` (this is the port the container will be listening on),
    `TCP`, and `Load balancer`. Select the **EXPOSE** option. Refer to *Figure 8.10*:![Figure
    8.10 – Specifying port mapping to expose a Pod as a Service of type Load balancer
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入 `80`（表示 Service 监听传入流量的端口）、`8080`（表示容器监听的端口）、`TCP` 和 `负载均衡器`。选择 **EXPOSE**
    选项。参见 *图 8.10*：![图 8.10 – 指定端口映射，将 Pod 暴露为负载均衡器类型的 Service
- en: '](img/B15587_08_10.jpg)'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_10.jpg)'
- en: Figure 8.10 – Specifying port mapping to expose a Pod as a Service of type Load
    balancer
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.10 – 指定端口映射，将 Pod 暴露为负载均衡器类型的 Service
- en: Once the Pod is exposed, a Service will be created as shown in the following
    screenshot. Given the Service is of type **LoadBalancer**, the Service will have
    an external endpoint. Refer to *Figure 8.11*:![Figure 8.11 – The LoadBalancer
    Service created by exposing the Pod
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦 Pod 被暴露，就会创建一个 Service，如下图所示。由于该 Service 是 **LoadBalancer** 类型，Service 将具有一个外部端点。参见
    *图 8.11*：![图 8.11 – 通过暴露 Pod 创建的 LoadBalancer Service
- en: '](img/B15587_08_11.jpg)'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_11.jpg)'
- en: Figure 8.11 – The LoadBalancer Service created by exposing the Pod
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.11 – 通过暴露 Pod 创建的 LoadBalancer Service
- en: 'Select the external endpoint. This will open the application in the browser
    as shown in the following screenshot. This essentially is the output of deploying
    the application to the GKE cluster. The output is the same as the output in [*Chapter
    6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131), *Building code using Cloud
    Build, and Pushing to Container Registry*, when the same container image was deployed
    to Cloud Run. Refer to *Figure 8.12*:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择外部端点。这将在浏览器中打开应用程序，如下图所示。这基本上是将应用程序部署到 GKE 集群后的输出。输出与在 [*第 6 章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)，*使用
    Cloud Build 构建代码并推送到容器注册表* 中，使用相同的容器镜像部署到 Cloud Run 时的输出相同。参见 *图 8.12*：
- en: '![Figure 8.12 – Output of accessing the application through the load balancer
    Service'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.12 – 通过负载均衡器服务访问应用程序的输出'
- en: '](img/B15587_08_12.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_12.jpg)'
- en: Figure 8.12 – Output of accessing the application through the load balancer
    Service
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.12 – 通过负载均衡器服务访问应用程序的输出
- en: This completes the topic on deploying an application to the GKE cluster and
    exposing the application via a load balancer Service through the GKE Console.
    The next sub-section essentially works on a similar example but provides insights
    on how the same thing can be done through Cloud Shell using the CLI approach.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了将应用程序部署到 GKE 集群并通过 GKE 控制台将应用程序暴露为负载均衡器服务的主题。下一个子章节基本上是一个类似的示例，但提供了如何通过
    Cloud Shell 使用 CLI 方法完成相同任务的见解。
- en: The CLI approach via Cloud Shell
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过 Cloud Shell 使用 CLI 方法
- en: In this sub-section, we will deploy an application and expose the application
    as a load balancer Service through the CLI using Cloud Shell. We will use the
    same cluster as was previously created – `my-first-cluster`. It is also recommended
    to use the container image created as part of the exercise in [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131),
    *Building code using Cloud Build, and Pushing to Container Registry*. For this
    example, the container image `gcr.io/gcp-devops-2021/cloud-build-trigger` will
    be used.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个子章节中，我们将通过 CLI 使用 Cloud Shell 部署应用程序并将其暴露为负载均衡器服务。我们将使用之前创建的相同集群 — `my-first-cluster`。同时，建议使用作为练习一部分创建的容器镜像，位于
    [*第 6 章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)，*使用 Cloud Build 构建代码并推送到容器注册表*。在本示例中，将使用容器镜像
    `gcr.io/gcp-devops-2021/cloud-build-trigger`。
- en: Deploying an application to the GKE cluster
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将应用程序部署到 GKE 集群
- en: 'The following is the step-by-step process to deploy an application via Cloud
    Shell:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过 Cloud Shell 部署应用程序的逐步过程：
- en: 'Open Cloud Shell and connect to the cluster using the following CLI command:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Cloud Shell 并使用以下 CLI 命令连接到集群：
- en: '[PRE2]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create a new file called `hello-world-cli.yaml` with contents as follows. This
    file essentially creates a Deployment that has the container and respective image
    to be deployed. The replica count is also specified and in this case, is 1:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `hello-world-cli.yaml` 的新文件，内容如下。这个文件本质上创建了一个包含容器及其对应镜像的部署。还指定了副本数，在本例中为
    1：
- en: '[PRE3]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create the Deployment by running the following command:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令创建部署：
- en: '[PRE4]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once the Deployment is created, the Deployment and its respective Pod can be
    queried as follows through the CLI. Please note that this Deployment will create
    only one Pod. Refer to *Figure 8.13*:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦部署创建完成，可以通过 CLI 查询该部署及其相应的 Pod。请注意，此部署将只创建一个 Pod。参见 *图 8.13*：
- en: '![Figure 8.13 – Querying the Deployment through the CLI'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.13 – 通过 CLI 查询部署情况'
- en: '](img/B15587_08_13.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_13.jpg)'
- en: Figure 8.13 – Querying the Deployment through the CLI
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.13 – 通过 CLI 查询部署情况
- en: The deployed application cannot be accessed through an external client. However,
    the port-forward approach explained in the previous sub-section can be exactly
    applied in this context as well. Given that the application is now deployed, the
    next step is to expose the application as a Service.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 部署的应用程序无法通过外部客户端访问。然而，在前一个子章节中解释的端口转发方法也可以在此上下文中完全适用。鉴于应用程序已经部署，下一步是将应用程序暴露为服务。
- en: Exposing the application as a Service
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将应用程序暴露为服务
- en: 'The following is the step-by-step process to expose the application as a Service
    through Cloud Shell:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过 Cloud Shell 将应用程序暴露为服务的逐步过程：
- en: 'Create a new file called `hello-world-cli-service.yaml` with a definition as
    follows. This will create a load balancer Service that will expose a Pod with
    matching label selectors:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `hello-world-cli-service.yaml` 的新文件，定义如下。这将创建一个负载均衡器服务，将暴露带有匹配标签选择器的
    Pod：
- en: '[PRE5]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Create the load balancer Service by running the following command:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令创建负载均衡器服务：
- en: '[PRE6]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Once the Service is created, a load balancer will be created with an external
    endpoint. As per the Service definition, the Service will listen to traffic on
    port `80` and will forward the traffic to the container on port `8080`. The external
    endpoint of the Service can be found out by querying the Service as follows. Refer
    to *Figure 8.14*:![Figure 8.14 – Query the load balancer Service to fetch the
    external endpoint
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦创建了服务，负载均衡器将被创建并分配一个外部端点。根据服务定义，该服务将在`80`端口监听流量，并将流量转发到`8080`端口的容器。可以通过如下方式查询服务来获取服务的外部端点。请参见*图
    8.14*：![图 8.14 – 查询负载均衡器服务以获取外部端点
- en: '](img/B15587_08_14.jpg)'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15587_08_14.jpg)'
- en: Figure 8.14 – Query the load balancer Service to fetch the external endpoint
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.14 – 查询负载均衡器服务以获取外部端点
- en: 'Access the external endpoint through a browser window. The output will be the
    same as the output from [*Chapter 6*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131),
    *Building code using Cloud Build, and Pushing to Container Registry*, or the output
    from the application deployed in GKE through the console. This is because we are
    using the same image. Refer to *Figure 8.15*:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过浏览器窗口访问外部端点。输出将与[*第6章*](B15587_06_Final_ASB_ePub.xhtml#_idTextAnchor131)《使用Cloud
    Build构建代码并推送到容器注册表》中的输出或通过控制台在GKE中部署的应用程序的输出相同。这是因为我们使用的是相同的镜像。请参见*图 8.15*：
- en: '![Figure 8.15 – Viewing the output of the load balancer Service via an external
    endpoint'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.15 – 通过外部端点查看负载均衡器服务的输出'
- en: '](img/B15587_08_15.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_15.jpg)'
- en: Figure 8.15 – Viewing the output of the load balancer Service via an external
    endpoint
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.15 – 通过外部端点查看负载均衡器服务的输出
- en: This concludes this section, which introduced GKE and took a deep dive into
    the step-by-step process to create a GKE cluster, deploy an application to the
    cluster, and expose the deployed application as a Service to be accessed by external
    clients. Essentially, the output of this approach is the same as the output from
    the console approach. The goal is to understand the process of creating a cluster,
    deploying workloads, and exposing the workloads through a Service via the CLI.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 本节结束，介绍了GKE并深入探讨了创建GKE集群、将应用程序部署到集群并将已部署的应用程序公开为外部客户端可访问的服务的步骤。实际上，这种方法的输出与控制台方法的输出相同。目标是理解通过CLI创建集群、部署工作负载并通过服务暴露工作负载的过程。
- en: The concepts used while creating the cluster or deploying the application are
    the same concepts that form the fundamentals of K8s (learned about in [*Chapter
    7*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154), *Understanding Kubernetes
    Essentials to Deploy Containerized Applications*). However, the cluster creation
    is much simpler in nature since the maintenance of the master plane components
    is completely abstracted and is not the responsibility of the user. The upcoming
    section focuses on core GKE features and possible cluster types, and provides
    an introduction to integration with networking and cloud operations in GKE.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建集群或部署应用程序时使用的概念与构成K8s基础的概念相同（在[*第7章*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154)《理解Kubernetes基础以部署容器化应用》中已学习）。然而，集群创建的性质更加简单，因为主控平面组件的维护已完全抽象化，不再是用户的责任。接下来的部分将重点介绍GKE的核心功能和可能的集群类型，并介绍GKE中与网络和云操作的集成。
- en: GKE – core features
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GKE – 核心功能
- en: 'This section covers the following topics. These topics will provide a considerable
    amount of information, which is required to build a good understanding and working
    knowledge of GKE. Most of these GKE concepts are an extension of topics learned
    about in the Kubernetes section. The topics that will be covered are as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖以下主题。这些主题将提供大量信息，帮助您构建对GKE的良好理解和操作知识。这些GKE概念大多是Kubernetes部分学习的主题的扩展。将要覆盖的主题如下：
- en: GKE node pools
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE节点池
- en: GKE cluster types
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE集群类型
- en: Autoscaling in GKE
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE中的自动扩展
- en: Networking in GKE
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE中的网络
- en: Cloud operations for GKE
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GKE的云操作
- en: The first of the GKE constructs that will be detailed in the upcoming sub-section
    is GKE node pools.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来小节将详细介绍的第一个GKE构建块是GKE节点池。
- en: GKE node pools
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE节点池
- en: Nodes (that is, worker nodes) in a Kubernetes cluster deploy workloads. The
    nature of workloads deployed across all nodes might not be the same. Some workloads
    might be CPU-intensive, others might be memory-intensive, and some might need
    a minimum version of the CPU platform. Workloads can also be fault-tolerant batch
    jobs or might need a specific type of storage such as SSD.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群中的节点（即工作节点）部署工作负载。分布在所有节点上的工作负载性质可能不同。有些工作负载可能是 CPU 密集型的，有些可能是内存密集型的，还有些可能需要特定版本的
    CPU 平台。工作负载还可能是容错的批处理任务，或者需要特定类型的存储，如 SSD。
- en: A `nodeConfig` specification. All matching nodes that match the `nodeConfig`
    specification will be labeled using a node label where the key is `cloud.google.com/gke-nodepool`
    and the value is the name of the node pool.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`nodeConfig` 规范。所有符合 `nodeConfig` 规范的节点将使用节点标签标记，其中键为 `cloud.google.com/gke-nodepool`，值为节点池的名称。'
- en: 'The following is an example of a `nodeConfig` specification with a specific
    machine type, OAuth scopes, and a disk type:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个包含特定机器类型、OAuth 范围和磁盘类型的 `nodeConfig` 规范示例：
- en: '[PRE7]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: A cluster is always created with a default node pool with a specific number
    of nodes and a specific machine type (along with other attributes). Additional
    custom node pools can be added based on their respective `nodeConfig` and workload
    requirements.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 集群总是与默认节点池一起创建，默认节点池具有特定数量的节点和特定的机器类型（以及其他属性）。可以根据各自的 `nodeConfig` 和工作负载需求添加额外的自定义节点池。
- en: 'The following are some of the key characteristics of a node pool:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是节点池的一些关键特性：
- en: A new node pool, by default, runs the latest stable Kubernetes version.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新创建的节点池默认运行最新的稳定 Kubernetes 版本。
- en: The Kubernetes version on existing node pools can either be configured for auto-upgrade
    or can be manually upgraded.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现有节点池上的 Kubernetes 版本可以配置为自动升级，也可以手动升级。
- en: A node pool can be individually resized, upgraded, or deleted without impacting
    other node pools. Any change to the node pool impacts all nodes within the pool.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以单独调整节点池的大小、升级或删除，而不影响其他节点池。对节点池的任何更改都会影响池中的所有节点。
- en: The following are a few CLI commands that can perform actions on a node pool.
    These commands can be executed on the cluster that was previously created in this
    chapter – `my-first-cluster`.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些 CLI 命令，可以对节点池执行操作。这些命令可以在本章之前创建的集群 `my-first-cluster` 上执行。
- en: 'The following CLI command creates a node pool with a specific machine type:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 CLI 命令会创建一个特定机器类型的节点池：
- en: '[PRE8]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The created node pool will be reflected on the GKE Console against the cluster
    (refer to *Figure 8.16*):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 创建的节点池将在 GKE 控制台中反映出来，显示在集群对应位置（参见*图 8.16*）：
- en: '![Figure 8.16 – New custom node pool – my-high-mem-pool created'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.16 – 新建自定义节点池 – 创建了 my-high-mem-pool'
- en: '](img/B15587_08_16.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_08_16.jpg)'
- en: Figure 8.16 – New custom node pool – my-high-mem-pool created
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.16 – 新建自定义节点池 – 创建了 my-high-mem-pool
- en: 'The following are other CLI commands to resize a node pool, upgrade to a specific
    version, or delete a node pool:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是其他 CLI 命令，用于调整节点池大小、升级到特定版本或删除节点池：
- en: '[PRE9]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Node pools in a regional or multi-zonal cluster are replicated to multiple zones.
    Additionally, the workload can be deployed to a specific node pool by explicitly
    specifying the node pool name using a `nodeSelector` or by finding a node pool
    that satisfies the resource requests as defined for the workload.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在区域性或多区域集群中的节点池会被复制到多个区域。此外，可以通过明确指定节点池名称使用 `nodeSelector`，或者找到满足工作负载资源请求的节点池，来将工作负载部署到特定节点池中。
- en: If the node pool name is explicitly specified using the `nodeSelector` attribute,
    then `kube-scheduler` will deploy workloads to the specified node. Otherwise,
    `kube-scheduler` will find the node pool that meets the intended resource request
    for the workload.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如果节点池名称通过 `nodeSelector` 属性明确指定，则 `kube-scheduler` 会将工作负载部署到指定的节点。否则，`kube-scheduler`
    会找到符合工作负载资源请求的节点池。
- en: This completes the overview of GKE node pools. The next topic deep-dives into
    the various cluster configurations available in GKE.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了 GKE 节点池的概述。接下来的主题将深入探讨 GKE 中的各种集群配置。
- en: GKE cluster configuration
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE 集群配置
- en: GKE offers multiple cluster configuration choices based on cluster availability
    type, cluster version, network isolation, and Kubernetes features. Each of these
    configuration choices is discussed in the following sub-sections.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 提供多种集群配置选择，基于集群可用性类型、集群版本、网络隔离和 Kubernetes 特性。以下子章节将详细讨论这些配置选项。
- en: Cluster availability type
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集群可用性类型
- en: GKE allows you to create a cluster based on the availability requirements of
    the workloads. There are two types of cluster configuration based on availability
    types – zonal clusters (single-zone or multi-zonal) and regional clusters. These
    are discussed in the following sub-sections.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 允许你根据工作负载的可用性要求创建集群。根据可用性类型，有两种集群配置——区域集群（单区域或多区域）和区域集群。这些将在以下子章节中讨论。
- en: Zonal clusters
  id: totrans-187
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 区域集群
- en: A **zonal cluster** will have a single control plane running in a single zone.
    The nodes (that is, worker nodes) can run either in a single zone or run across
    multiple zones. If the nodes run in the same zone as the control plane, then it
    represents a **single-zone cluster**. However, if nodes run across multiple zones,
    then it represents a **multi-zonal cluster**. Note that GKE allows up to 50 clusters
    per zone.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**区域集群**将拥有一个在单一区域运行的控制平面副本。节点（即工作节点）可以运行在单一区域，也可以跨多个区域运行。如果节点与控制平面运行在同一区域，则表示为**单区域集群**。然而，如果节点跨多个区域运行，则表示为**多区域集群**。请注意，GKE
    允许每个区域最多创建 50 个集群。'
- en: A multi-zonal cluster will only have a single replica of the control plane.
    The choice between a single zone or multi-zonal cluster is based on the level
    of availability required for an application. Specific to a multi-zonal cluster
    and in the event of a cluster upgrade or a zone outage, the workloads running
    on the nodes will continue to run, but a new node or workload cannot be configured
    till the cluster control plane is available.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 多区域集群将仅有一个控制平面的副本。选择单区域集群还是多区域集群取决于应用程序所需的可用性级别。对于多区域集群，如果发生集群升级或区域故障，节点上运行的工作负载将继续运行，但直到集群控制平面可用之前，无法配置新的节点或工作负载。
- en: 'The following are CLI commands to create a zonal cluster (single zone and multi
    zonal):'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是创建区域集群（单区域和多区域）的 CLI 命令：
- en: '[PRE10]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The input parameter specific to the zone refers to the location of the control
    plane. The node locations refer to the locations of the worker node(s) and are
    not required for a single zone cluster as it will be the same as the master control
    plane.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 与区域相关的输入参数是指控制平面的位置。节点位置指的是工作节点的所在位置，对于单区域集群来说并不需要指定，因为它与主控制平面的位置相同。
- en: This completes a brief overview of GKE zonal clusters. The next topic will provide
    an overview of GKE regional clusters.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 GKE 区域集群的简要概述。下一个主题将概述 GKE 区域集群。
- en: Regional clusters
  id: totrans-194
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 区域集群
- en: A regional cluster provides high availability both in terms of worker nodes
    as well as the control plane. A regional cluster has multiple replicas of the
    control plane running across multiple zones in a region. The worker nodes are
    also replicated across multiple zones and the worker nodes run in conjunction
    in the same zone as the control plane. A regional cluster cannot be converted
    into a zonal cluster.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 区域集群提供了在工作节点和控制平面方面的高可用性。区域集群在多个区域内运行多个控制平面副本。工作节点也跨多个区域进行复制，并且工作节点与控制平面在同一区域内共同运行。区域集群不能转换为区域集群。
- en: 'The following is the CLI command to create a regional cluster:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是创建区域集群的 CLI 命令：
- en: '[PRE11]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The input parameter specific to `region` refers to the location of the control
    plane. The node locations refer to the locations of the worker node. This is required
    for a multi-zone cluster as node locations could be in multiple zones.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `region` 相关的输入参数是指控制平面的位置。节点位置指的是工作节点的位置。对于多区域集群，这是必需的，因为节点位置可能分布在多个区域。
- en: This completes a brief overview of GKE cluster configuration based on cluster
    availability type. The next topic will provide an overview of GKE cluster configuration
    based on cluster version.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是基于集群可用性类型的 GKE 集群配置的简要概述。下一个主题将概述基于集群版本的 GKE 集群配置。
- en: Cluster versions
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集群版本
- en: GKE allows you to choose the cluster version. The cluster version can be a very
    specific version, the current default version, or can be based on a release channel,
    which is a combination of features based on early availability and stability.
    These cluster version configurations are discussed in the following sub-sections.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 允许你选择集群版本。集群版本可以是非常特定的版本、当前默认版本，或者基于发布渠道，发布渠道是基于早期可用性和稳定性的功能组合。这些集群版本配置将在以下子章节中讨论。
- en: Specific versions
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特定版本
- en: A GKE cluster can be created by specifying a specific version. This information
    can be provided as part of the *Static Version* selection while creating the cluster
    from the console. The user will be provided with a choice of cluster versions
    and can select an available version.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过指定特定版本来创建 GKE 集群。在从控制台创建集群时，这些信息可以作为*静态版本*选择的一部分提供给用户。用户将获得集群版本的选择，并可以选择一个可用的版本。
- en: Release channels
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发布渠道
- en: 'Open source Kubernetes or K8s has a constant stream of releases. These could
    be required for the following purpose:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 开源 Kubernetes 或 K8s 持续发布新版本。这些版本可能出于以下目的而需要：
- en: To fix known issues
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修复已知问题
- en: To add new features
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加新功能
- en: To address any security risks/concerns
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决任何安全风险/问题
- en: Kubernetes users who run applications on a Kubernetes cluster will prefer to
    exercise control in terms of how frequently the releases should be applied or
    the rate at which new features should be adopted. Google provides this choice
    to customers using the concept of a **release channel**.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 Kubernetes 集群上应用程序的 Kubernetes 用户，更倾向于控制发布的频率或采用新功能的速度。Google 通过**发布渠道**的概念为客户提供这一选择。
- en: Each of the release channels provides **generally available** (**GA**) features
    but the maturity of the features in terms of their original release date will
    vary from one channel to another. In addition, Google can also add the latest
    GKE-specific features depending on the type of release channel. This ensures that
    a specific feature or fix has potentially gone through the grind and is vetted
    in terms of its correctness and consistency over a period.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 每个发布渠道都提供**普遍可用**（**GA**）功能，但功能的成熟度会根据其最初发布的日期在不同渠道之间有所不同。此外，Google 还可以根据发布渠道的类型添加最新的
    GKE 特定功能。这确保了某个特性或修复程序在一段时间内经过了验证，并确保其正确性和一致性。
- en: 'GKE provides three release channels:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 提供三个发布渠道：
- en: '**Rapid**: This release channel includes the latest Kubernetes and GKE features
    when compared to other release channels, but the features are still several weeks
    old after their respective open source GA release.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速**：与其他发布渠道相比，这个发布渠道包括最新的 Kubernetes 和 GKE 特性，但这些特性距离它们各自的开源 GA 版本发布仍有几周的时间。'
- en: '**Regular**: This is the default release channel, which includes Kubernetes
    and GKE-specific features that are reasonably new but are more stable in nature.
    The features are at least 2-3 months old after their release in the rapid channel
    and several months old from their open source GA release.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**常规**：这是默认的发布渠道，包括 Kubernetes 和 GKE 特定的功能，这些功能相对较新，但稳定性较好。这些功能在快速发布渠道发布后至少已有
    2-3 个月的历史，且距离开源 GA 版本发布已经有几个月。'
- en: '**Stable**: This is the most stable of the release channels since the features
    added to this channel are added at least 2-3 months after being added to the regular
    channel. Essentially, the features are thoroughly validated and tested to provide
    the utmost stability.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稳定**：这是最稳定的发布渠道，因为添加到此渠道的功能是在加入常规渠道后至少 2-3 个月添加的。实际上，这些功能经过充分验证和测试，以提供极致的稳定性。'
- en: 'The following is the CLI command to enroll a cluster in a release channel:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将集群注册到发布渠道的 CLI 命令：
- en: '[PRE12]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To summarize, new Kubernetes versions and GKE features are promoted from the
    rapid to the regular to the stable channel, providing users with the choice to
    use newer features over stable features. GKE handles the availability of versions
    and the upgrade cadence once a cluster is added to the release channel. Each of
    the release channels continues to receive critical security updates.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，新版本的 Kubernetes 和 GKE 特性会从快速发布渠道、常规发布渠道到稳定发布渠道依次推广，提供用户在使用新特性和稳定特性之间的选择。一旦集群被加入到发布渠道，GKE
    会处理版本的可用性和升级节奏。每个发布渠道都会继续接收关键的安全更新。
- en: The default version
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 默认版本
- en: If a specific version or a release channel is not specified, then GKE creates
    a cluster with the current default version. GKE selects a default version based
    on usage and real-world performance. GKE is responsible for changing the default
    version on a regular basis. Historically, new versions of Kubernetes are released
    every 3 months.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有指定特定的版本或发布渠道，则 GKE 会创建一个使用当前默认版本的集群。GKE 会根据使用情况和实际性能选择默认版本，并定期更改默认版本。历史上，Kubernetes
    的新版本每三个月发布一次。
- en: This completes a brief overview of GKE cluster configuration based on cluster
    version. The next topic will provide an overview of GKE cluster configuration
    based on network isolation choices.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了基于集群版本的 GKE 集群配置的简要概述。下一个主题将提供基于网络隔离选择的 GKE 集群配置概述。
- en: Network isolation choices
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络隔离选择
- en: There are two specific choices related to network isolation – a public cluster
    or a private cluster. A public cluster is the default configuration. However,
    this does not enforce network isolation and the cluster is accessible from any
    public endpoint. This makes the cluster vulnerable from a security standpoint.
    The drawbacks of configuring a public cluster can be handled through a private
    cluster, which is introduced in the following sub-sections.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个与网络隔离相关的特定选择——公有集群或私有集群。公有集群是默认配置。然而，这并不强制执行网络隔离，集群可以从任何公共端点访问。这使得集群在安全性方面存在漏洞。配置公有集群的缺点可以通过私有集群来解决，私有集群将在以下小节中介绍。
- en: Private clusters
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 私有集群
- en: GKE provides an option to create a private cluster where the nodes only have
    internal IP addresses. This means that the nodes and the pods running on the nodes
    are isolated from the internet and inherently will not have inbound or outbound
    connectivity to the public internet.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 提供了创建私有集群的选项，在该集群中，节点只有内部 IP 地址。这意味着节点和运行在节点上的 Pods 与互联网隔离，因此天然不会与公共互联网进行进出连接。
- en: A private cluster will have a control plane that includes a private endpoint,
    in addition to a public endpoint. Access to the public endpoint can be controlled
    through multiple options. In addition, the control plane will run on a VM that
    is in a VPC network in a Google-owned project. The details surrounding private
    clusters will be discussed in depth as part of [*Chapter 9*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201),
    *Securing the Cluster Using GKE Security Constructs*.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 私有集群将拥有一个包含私有端点的控制平面，此外还有一个公共端点。可以通过多种选项来控制对公共端点的访问。此外，控制平面将在 Google 拥有的项目中的
    VPC 网络中的虚拟机上运行。有关私有集群的详细信息将在 [*第 9 章*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201)，*使用
    GKE 安全构件保护集群* 中进行深入讨论。
- en: Kubernetes features – alpha clusters
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes 功能——alpha 集群
- en: New features in Kubernetes are rolled out to GKE as part of the release channel
    in most cases. The release channel includes choices of rapid, regular, and stable.
    However, alpha features are only available in special GKE alpha clusters. This
    is discussed in the following sub-sections.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 中的新功能通常通过发布渠道推广到 GKE。发布渠道包括快速、常规和稳定的选择。然而，alpha 功能仅在特殊的 GKE alpha
    集群中提供。以下小节将讨论这一点。
- en: Alpha clusters
  id: totrans-228
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Alpha 集群
- en: Alpha clusters are a specific feature of GKE that is designed for adopting new
    features that are not production-ready or generally available as open source.
    GKE creates alpha clusters as short-lived clusters and they are automatically
    deleted after 30 days.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Alpha 集群是 GKE 的一个特定功能，旨在用于采用那些尚未准备好投入生产或尚未普遍开放源代码的新功能。GKE 创建的 alpha 集群是短期存在的集群，并将在
    30 天后自动删除。
- en: 'The following is the CLI command to create an alpha cluster:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是创建 alpha 集群的 CLI 命令：
- en: '[PRE13]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: These clusters do not receive security updates, cannot be auto-upgraded or auto-repaired,
    and are not covered by any GKE-specific SLAs. Hence, alpha clusters are never
    recommended for production workloads.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这些集群不会接收安全更新，不能自动升级或自动修复，且不受任何 GKE 特定的 SLA 保障。因此，永远不建议将 alpha 集群用于生产工作负载。
- en: This completes a brief overview of GKE cluster configuration based on network
    isolation choices. This also concludes the sub-section on GKE cluster configuration
    in general. The next topic details possible autoscaling options in GKE.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了基于网络隔离选择的 GKE 集群配置的简要概述。这也结束了关于 GKE 集群配置的一般小节。下一个主题将详细介绍 GKE 中可能的自动扩展选项。
- en: AutoScaling in GKE
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GKE 中的自动扩展
- en: 'There are three potential options to perform autoscaling in GKE. Each of these
    options is suitable for specific needs and situations:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GKE 中有三种潜在的自动扩展选项。这些选项适用于特定的需求和场景：
- en: '**Cluster autoscaler**: A scaling option to resize a node pool in a GKE cluster'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群自动扩展器**：用于调整 GKE 集群中节点池大小的扩展选项'
- en: '**Horizontal Pod Autoscaler** (**HPA**): An option that indicates when application
    instances should be autoscaled based on their current utilization'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**水平 Pod 自动扩展器**（**HPA**）：一个选项，用于根据当前利用率指示何时应自动扩展应用实例'
- en: '**Vertical Pod Autoscaler** (**VPA**): An option that suggests recommended
    resources for a Pod based on the current utilization'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**垂直 Pod 自动缩放器** (**VPA**): 一种选项，根据当前利用率为 Pod 建议推荐资源。'
- en: The upcoming topics detail the preceding autoscaling mechanisms, starting with
    the cluster autoscaler.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的话题详细说明了先前的自动缩放机制，从集群自动缩放器开始。
- en: The cluster autoscaler
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集群自动缩放器
- en: The **cluster autoscaler** is a scaling mechanism to automatically resize a
    node pool in a GKE cluster. The scaling is based on the demands of workloads deployed
    within the node pool. This allows you to implement the core concept of cloud computing,
    called elasticity, and removes the need to over-provision or under-provision nodes.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '**集群自动缩放器**是自动调整 GKE 集群中节点池大小的机制。缩放基于节点池内部署的工作负载的需求。这允许您实现云计算的核心概念，称为弹性，从而消除了过度或不足提供节点的需要。'
- en: The cluster autoscaler works on a per-node pool basis and is based on resource
    requests (defined as part of the Pod specification) rather than the actual resource
    utilization. When a new Pod needs to be deployed, the Kubernetes scheduler works
    out of the Pod resource requests and attempts to find a node to deploy the Pod.
    If there is no node that matches the Pod resource requirement in terms of available
    capacity, then the Pod goes into a pending state until any of the existing pods
    are terminated or a new node is added.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 集群自动缩放器基于节点池的基础工作，并基于资源请求（作为 Pod 规范的一部分定义）而非实际资源利用率。当需要部署新的 Pod 时，Kubernetes
    调度器根据 Pod 的资源请求来寻找节点进行部署。如果没有节点满足 Pod 的资源需求以及可用容量，那么 Pod 将处于挂起状态，直到现有的 Pod 终止或者添加新节点。
- en: The cluster autoscaler keeps track of the pods that are in the pending state
    and subsequently tries to scale up the number of nodes. Similarly, the cluster
    autoscaler also scales down the number of nodes if the nodes are under-utilized.
    A minimum or maximum number of nodes can be defined for the cluster autoscaler,
    which allows it to operate within the specified limits.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 集群自动缩放器会跟踪处于挂起状态的 Pod，并随后尝试增加节点的数量。同样，如果节点未充分利用，集群自动缩放器也会减少节点的数量。可以为集群自动缩放器定义最小或最大节点数，以使其在指定的限制内运行。
- en: 'When a cluster is scaled down, there is a possibility that new workloads might
    have to wait till new nodes are added. This could cause a potential disruption.
    GKE profile types provide a choice of options to choose between balanced and aggressive
    scale-down:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '当集群缩小规模时，可能需要新的工作负载等待新节点的添加。这可能导致潜在的中断。GKE 配置文件类型提供了在平衡和激进缩小规模之间进行选择的选项:'
- en: '**Balanced**: The default profile option, which is not aggressive in nature.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平衡**: 默认的配置选项，性质不激进。'
- en: '**Optimize-utilization**: Scaling down is more aggressive and removes underutilized
    nodes faster.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优化利用率**: 缩小比较激进，更快地移除未充分利用的节点。'
- en: 'The following are some CLI commands related to the cluster autoscaler:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '以下是一些与集群自动缩放器相关的 CLI 命令:'
- en: '[PRE14]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following are some limitations that need to be considered when using the
    cluster autoscaler:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '在使用集群自动缩放器时需要考虑的一些限制如下:'
- en: There is a graceful termination of 10 minutes for rescheduling pods on to a
    different node before forcibly terminating the original node.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在将 Pod 重新调度到不同节点之前，对原始节点进行强制终止之前会进行 10 分钟的优雅终止。
- en: The node pool scaling limits are determined by zone availability. If a cluster
    has 3 nodes (with `min_nodes` = `1` and `max_nodes` = `5`) across 4 zones, then
    if 1 of the zones fails, the size of the cluster can vary from 4-20 nodes per
    cluster to 3-15 nodes per cluster.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点池缩放限制由区域可用性决定。如果集群跨越 4 个区域拥有 3 个节点（`min_nodes` = `1` 和 `max_nodes` = `5`），那么如果其中
    1 个区域失败，集群的大小可以从每个集群的 4-20 个节点变为 3-15 个节点。
- en: This concludes the overview of the cluster autoscaler. The next topic focuses
    on the **Horizontal Pod Autoscaler** (**HPA**).
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这里结束了对集群自动缩放器的概述。下一个主题关注**水平 Pod 自动缩放器** (**HPA**)。
- en: The Horizontal Pod Autoscaler
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 水平 Pod 自动缩放器
- en: The HPA is a Kubernetes controller object that automatically scales the number
    of pods in a replication controller, Deployment, ReplicaSet, or StatefulSet based
    on the observed CPU or memory utilization. The HPA indicates the Deployment or
    StatefulSet against which scaling needs to happen. The HPA doesn't apply to DaemonSets.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: HPA 是一个 Kubernetes 控制器对象，根据观察到的 CPU 或内存利用率自动调整复制控制器、Deployment、ReplicaSet 或
    StatefulSet 中 Pod 的数量。HPA 指示需要对其进行缩放的 Deployment 或 StatefulSet。HPA 不适用于 DaemonSets。
- en: 'To implement the HPA, the following factors need to be considered:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: One HPA object needs to be defined per Deployment or StatefulSet.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The attribute `--horizontal-pod-autoscaler-sync-period` allows you to implement
    the HPA as a control loop. The default value is 15 seconds per period.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-controller-manager` (on a per-period basis) obtains metrics from the
    resource manager API or the custom metrics API and compares them against the metrics
    specified in each HPA definition.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following are few key parameters that can define the HPA configuration:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '`--horizontal-pod-autoscaler-initial-readiness-delay`: A configurable window
    to ensure that a Pod is transitioned to the ready state.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--horizontal-pod-autoscaler-cpu-initialization-period`: A configurable window
    to set the CPU initialization period, once the Pod is transitioned to the ready
    state. The default is 5 minutes.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--horizontal-pod-autoscaler-downscale-stabilization`: A configurable window
    that autoscaler needs to wait before initiating a downscale operation after the
    current one is completed. The default is 5 minutes. This prevents thrashing.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is the sample definition of an HPA object based on CPU utilization:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In the preceding example, `kube-controller-manager` will scale up the Deployment
    based on the HPA object specification, to a maximum of 5 instances if the target
    CPU utilization exceeds 75%. This concludes the overview of the HPA. The next
    topic focuses on the **Vertical Pod Autoscaler** (**VPA**).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: The Vertical Pod Autoscaler (VPA)
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The cluster autoscaler functions based on the workload's CPU and memory request
    limits. If these limits are not defined appropriately, then there is always a
    chance of over-provisioning or under-provisioning as the reference values will
    not be accurate.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: The VPA is a Kubernetes resource that recommends values for CPU and memory requests/limits.
    Additionally, the VPA can automatically update workloads if the `updateMode` attribute
    is set to *On* on the VPA. This will potentially evict the existing Pod as a change
    is required to the pod's resource requests and will result in a new Pod with the
    updated recommendations.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: This ensures that the cluster nodes are optimally utilized and potentially removes
    the need to run benchmark tests to determine the correct values for CPU and memory
    requests. VPA communicates with the cluster autoscaler to perform the appropriate
    operations on the nodes tied to the node pools.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a sample definition of a VPA object:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `kind` attribute in the preceding snippet indicates that the Kubernetes
    resource is a VPA object. The `updateMode` attribute indicates that the recommendations
    suggested by the VPA are automatically applied against the running workloads.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some CLI commands specific to the VPA:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: If an HPA object is configured to evaluate metrics for CPU or memory, it's recommended
    that HPA should not be used with VPA.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: Multi-dimensional Pod autoscaling (MPA)
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: This is a new autoscaling option that is currently in pre-GA. As per this option,
    it is possible to configure autoscaling to horizontally scale based on CPU and
    vertically scale based on memory at the same time. MPA is supported for clusters
    that are 1.19.4-gke.1700 or later.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: This concludes the section on autoscaling in GKE where multiple mechanisms were
    detailed out. The next section focuses on networking constructs with respect to
    GKE. This will cover details about Pod networking, Service networking, and will
    deep dive into the usage of GKE load balancers to expose services for external
    consumption.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Networking in GKE
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Applications are deployed in Kubernetes as containers. Pods run containers.
    The desired state of the pods is controlled by Deployments and the applications
    are exposed for both internal and external networking through Services. The deployed
    pods run in GKE on nodes. Nodes in GKE are represented by virtual machines or
    VMs. These nodes are deployed in a **Virtual Private Cloud** (**VPC**).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: A VPC defines a virtual network topology that closely resembles a traditional
    network. It is a logically isolated network and provides connectivity between
    deployed resources. A VPC also provides complete control in terms of launching
    resources, selecting a range of RFC 1918 addressing, the creation of subnets,
    and so on.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: A VPC on GCP has a pre-allocated IP subnet, for every GCP region. When a GKE
    cluster is deployed within the VPC, a specific region or zone can be selected.
    Since GKE nodes are made up of Compute Engine VMs and these VMs need an IP address,
    the range of IP addresses is allocated from the IP subnet pre-allocated to the
    region. A VPC on GCP is considered a global resource since a single Google Cloud
    VPC can span multiple regions without communicating across the public internet.
    It is not required to have a connection in every region.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: GCP provides the option of configuring alias IP ranges. This allows VMs to have
    an additional secondary IP address. As a result, a VM can have multiple services
    running with a separate IP address. These secondary IP addresses are routable
    within the VPC without the need to configure additional routes.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: 'A GKE cluster might need to run cluster-wide services. GCP recommends deploying
    a GKE cluster as a **VPC-native cluster**. A VPC-native cluster uses three unique
    subnet IP address ranges:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: A primary IP address range of subnet for node IP addresses
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A secondary IP address range for all Pod IP addresses
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An additional secondary IP address range for all Service IP addresses
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE provides flexibility where the number of nodes in a cluster and the maximum
    number of pods per node are configurable. The next topic details how pods are
    assigned IP addresses when pods are deployed in a GKE cluster.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Pod networking
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When a Pod is scheduled on a node, Kubernetes creates a network namespace for
    the Pod on the node's Linux kernel and connects the node's physical network interface
    to the Pod with a virtual network interface, thus allowing communication among
    pods within the same node.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes assigns an IP address (the Pod's IP) to the virtual network interface
    in the Pod's network namespace from a range of addresses reserved for Pods on
    the node. This address range is a subset of the IP address range assigned to the
    cluster for Pods, which can be configured when creating a cluster.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: GKE automatically configures VPC to recognize this range of IP addresses as
    an authorized secondary subnet of IP addresses. As a result, the pod's traffic
    is permitted to pass the anti-spoofing filters on the network. Also, because each
    node maintains a separate IP address base for its pods, the nodes don't need to
    perform network address translation on the pod's IP address. The next topic details
    Service networking, specifically, how services can effectively receive traffic
    from external sources via the use of GKE load balancers.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: Service networking
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A Service is a Kubernetes resource that creates a dynamic collection of IP addresses
    called endpoints. These IP addresses belong to the Pod that matches the Service
    label selector. Kubernetes creates a Service by assigning a static virtual IP
    address and this IP address is assigned from the pool of IP addresses reserved
    for services by the cluster.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Out of the available Service types, the `LoadBalancer` Service type is implemented
    in GKE using GCP's `LoadBalancer` is created within the GKE cluster. GCP will
    subsequently assign a static `LoadBalancer` IP address that is accessible from
    outside the cluster and the project.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: 'For traffic sent to the GCP NLB, *Figure 8.17* depicts the interactions between
    the NLB and the nodes within the GKE cluster. These interactions are listed as
    follows in a step-by-step manner:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.17 – Interactions between the NLB and a GKE cluster within a VPC'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_17.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.17 – Interactions between the NLB and a GKE cluster within a VPC
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '**Step-by-step interactions**:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: NLB will pick a random node in the cluster and forwards the traffic (say **Node
    2** as per *Figure 8.17*)
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Service might be tied to multiple pods spread across the cluster nodes.
    The `kube-proxy` Service on the node receives the client request and will select
    a Pod matching the Service at random. The selected Pod can be on the same node
    or a different node.
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the selected Pod is on a different node (say **Pod 8**), then the client
    request will be sent to the other node (**Node 4**) from the original node (**Node
    2**). The response goes back to the original node (**Node 2**) that received the
    request and subsequently goes back to the client.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The preceding process provides a way to access services from an external client
    and maintains an even balance with respect to Pod usage. However, there is a possibility
    that within the Kubernetes cluster, a response might have to go through multiple
    nodes as the request was directed from one node to the other, resulting in a **double
    hop**.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: To avoid `externalTrafficPolicy`. If set to local, `kube-proxy` will pick a
    Pod on the local node (either **Pod 3** or **Pod 4**) and will not forward the
    client request to another node. However, this creates an imbalance and users must
    choose between better balance versus low-latency communication. GKE solves this
    by using the concept of container-native load balancing.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: Container-native load balancing
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The essence of container-native load balancing is that instead of directing
    traffic to nodes, traffic will be sent to pods directly, avoiding an additional
    hop. The connection is made directly between the load balancer and the pods. GKE
    accomplishes this by leveraging **GCP HTTP(S) Load Balancing** and the use of
    a data model called a **Network Endpoint Group** (**NEG**). GKE needs to run in
    VPC-native mode to use the container-native load balancing feature.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: 'A NEG is a set of network endpoints representing IP to port pairs. So instead
    of load balancing traffic using node IPs, the combination of Pod IPs and a port
    is used as a tuple. This information is maintained in the NEG. *Figure 8.18* depicts
    the interactions between GKE container-native load balancing and pods in GKE nodes
    through an NEG. As per *Figure 8.18*, a request to the container-native load balancer
    is forwarded to the NEG. The NEG then chooses the specific Pod based on the request,
    and directly forwards the traffic to the node associated with the Pod in a single
    hop, thus avoiding the *double hop*:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.18 – Solving the double hop problem using container-native load
    balancing'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_18.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.18 – Solving the double hop problem using container-native load balancing
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Apart from establishing a direct connection to the Pod, container-native load
    balancing allows direct visibility of Pods, leading to the possibility of accurate
    health checks. The source IP address is preserved thus giving insights into the
    roundtrip time between the client and the load balancer.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: This concludes a high-level overview of networking constructs specific to GKE.
    The next section summarizes the storage options available for containerized applications
    deployed in GKE.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Storage options for GKE
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes offers storage abstractions in the form of Volumes and Persistent
    Volumes. These are used as storage options providing file system capacity that
    is directly accessible by applications running in a Kubernetes cluster. Persistent
    Volumes exist beyond the life of a container and can further be used as durable
    file storage or as a database backing store.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: In GKE, Compute Engine persistent disks are used as persistent volumes. GKE
    also provides various managed backing stores such as Cloud SQL, Cloud Datastore,
    and so on, which removes the need to run a database as an application inside the
    GKE cluster, connecting applications in a GKE cluster to a managed datastore instead.
    For example, a frontend application in a GKE Cluster can be connected to Cloud
    SQL rather than the frontend application connecting to another application running
    a MySQL server. To be more specific, the frontend application can connect to Cloud
    SQL for database needs through a Cloud SQL proxy. This can be run inside the frontend
    application's Pod as a side-car container.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: This abstracts away infrastructure requirements and reduces maintenance, allowing
    you to focus on the application. GCP offers managed services across relational,
    non-relational, and caching services that applications running in a GKE cluster
    can connect to.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to applications that might require a backend data store, there
    could be applications running in a GKE cluster that might need object storage.
    **Google Cloud Storage** (**GCS**) is an object storage Service. Object-based
    storage refers to the storage of an ordered group of bytes where the structure
    and semantics of those bytes are not important. It can be used for a variety of
    applications, such as the following:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Serving images for a website
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streaming music, videos, and media hosting
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constructing data lakes for analytics and machine learning workloads
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications within the GKE cluster can access Cloud Storage using Cloud Storage
    APIs. This concludes the summary of the storage options available in GCP for applications
    deployed in GKE. The next section summarizes details on cloud operations from
    a GKE perspective.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Operations for GKE
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Google Kubernetes Engine** (**GKE**) provides native integration with **Google''s
    Cloud operations** – a suite of tools that allows you to monitor workloads, collect
    application logs, capture metrics and provide alerting or notification options
    on key metrics. Cloud operations and the respective suite of services are elaborated
    on in detail as part of [*Chapter 10*](B15587_10_Final_ASB_ePub.xhtml#_idTextAnchor218),
    *Exploring GCP Cloud Operations*.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloud Operations for GKE is enabled by default at the time of cluster creation.
    However, it is possible to configure if the user chooses to disable Cloud Monitoring
    or Cloud Logging as part of the GKE cluster configuration. Cloud Operations for
    GKE monitors GKE clusters and provides a tailored, out-of-the-box dashboard that
    includes the following capabilities:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: Viewing cluster resources categorized by infrastructure, workloads, or services
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inspecting namespaces, nodes, workloads, services, pods, and containers
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viewing application logs for pods and containers
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viewing key metrics related to clusters, such as CPU utilization, memory utilization,
    and so on
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging and monitoring are two critical aspects of reliably running a Service
    or application in a GKE cluster. These will be covered as part of upcoming topics
    from the aspect of Cloud Operations for GKE.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: Logging for GKE
  id: totrans-331
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GKE deploys applications and orchestrates multiple actions or events within
    a cluster. This results in a variety of logs such as application logs, system
    logs, event logs, and so on. Logging provides visibility of various actions that
    happen and is also considered a passive form of monitoring.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two options to view logs for a GKE cluster:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Native Logging
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE Cloud Logging
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Native Logging
  id: totrans-336
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Kubernetes supports native logging to standard output and standard error. In
    Kubernetes, the *container engine* can be used to redirect stdin/out and standard
    error streams from the containers to a logging driver. This driver is configured
    to write these container logs in JSON format and store them in the `/var/log`
    directory at the node level. This includes logs from containers and logs from
    node control plane components such as `kubelet` and `kube-proxy`. These logs can
    be retrieved using the `kubectl logs` command.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: 'The `kubectl logs` command can be used to retrieve logs for a Pod or a specific
    container within a Pod. The command also provides options to retrieve logs for
    a specific period or you can retrieve a portion of logs using the `tail` option.
    A few of such examples are provided as follows:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Kubernetes native logging can lead to node saturation as the log files continue
    to grow in the node's storage directory. GKE solves this to an extent by running
    the Linux log rotate utility to clean up the log files. Any log files older than
    a day or more than 100 MB will be automatically compressed and copied into an
    archive file.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: GKE only stores the five most recently archived log files on the nodes and will
    delete the previous archived log files. Though this ensures that the node doesn't
    saturate in terms of disk space, it still poses a problem if older application
    logs need to be analyzed or researched.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: By default, open source Kubernetes or K8s will delete logs related to a container
    either when a container is deleted or when a Pod tied to the container is deleted.
    GKE resolves problems related to node saturation and provides the ability to analyze
    logs related to deleted pods/containers by streaming the logs to Cloud Logging,
    as part of Cloud Operations. Application logs, system logs, and log events can
    be streamed to Cloud Logging, which will be discussed as part of upcoming topics.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: GKE Cloud Logging
  id: totrans-343
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Open source Kubernetes or K8s doesn't provide a log storage solution for cluster-level
    logging. GKE handles this by streaming log events to Cloud Logging. **Cloud Logging**
    is a centralized log management utility and a fully managed Service. Cloud Logging
    can automatically scale and can ingest terabytes of log data per second.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: GKE streams to Cloud Logging by using `FluentD` logging agents. A `FluentD`
    agent is implemented as a DaemonSet because it needs to run on every node in the
    cluster.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: Logging agents are pre-installed on each node as a DaemonSet and are pre-configured
    to push log data to Cloud Logging. `FluentD` collects container logs and system
    logs from the node. FluentD aggregates the logs, appends additional metadata,
    and pushes them to Cloud Logging.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8.19* illustrates the interactions of logs being sent from GKE to Cloud
    Logging using the `FluentD` DaemonSet Pod on each node in the cluster:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.19 – FluentD agent capturing logs and sending to Cloud Logging'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_19.jpg)'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.19 – FluentD agent capturing logs and sending to Cloud Logging
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '**Event logs** are also streamed to Cloud Logging. Event logs refers to logs
    from operations that take place on the cluster such as the creation/deletion of
    a Pod, scaling of deployments, and so on. Events are stored as API objects on
    the Kubernetes master or control plane. GKE uses an event exporter in the cluster
    master to capture the events and automatically pushes them to Cloud Logging.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Logging provides the ability to capture metrics from streaming logs and
    create alerting policies as needed. Cluster actions such as autoscaling can be
    configured based on custom metrics. By default, GKE-specific logs related to a
    cluster are available in Cloud Logging for 30 days. For longer retention, Cloud
    Logging offers options to export logs to Cloud Storage or Big Query using the
    concept of log sinks. [*Chapter 10*](B15587_10_Final_ASB_ePub.xhtml#_idTextAnchor218),
    *Exploring GCP Cloud Operations*, elaborates on topics related to Cloud Logging
    in depth.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring for GKE
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Monitoring provides insights into how an application or Service functions based
    on key internal metrics related to a GKE cluster. In addition, monitoring also
    provides insights from a user's perspective based on the user's interaction with
    the Service. The previous chapters on site reliability engineering ([*Chapter
    1*](B15587_01_Final_ASB_ePub.xhtml#_idTextAnchor014), *DevOps, SRE, and Google
    Cloud Services for CI/CD*, to [*Chapter 4*](B15587_04_Final_ASB_ePub.xhtml#_idTextAnchor087),
    *Building SRE Teams and Applying Cultural Practices*), clearly call out Service
    reliability as one of the key aspects. Monitoring is the fundamental input to
    ensure that a Service runs reliably.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring provides data that is critical to make decisions about applications.
    This data can be used further to resolve an ongoing incident and perform a blameless
    postmortem, and you can use it further to improve an existing test suite and provide
    inputs to the product and development team for any further improvements or fine-tuning.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: '**Cloud Monitoring** is Google''s managed solution that provides a solution
    to monitor the state of services using key parameters such as latency, throughput,
    and so on, and identify performance bottlenecks. From a GKE perspective, monitoring
    can be divided into two domains:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: '`kube-apiserver`, `etcd`, and other infrastructure elements.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pod-Level Monitoring**: This includes monitoring resources using container-specific
    metrics, tracking deployment-specific system metrics, tracking instances, monitoring
    uptime checks, and monitoring application-specific metrics designed by the application''s
    developer(s).'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kubernetes uses the concept of labels to group or track resources. The same
    concept can be extended, and resources can be filtered in Cloud Monitoring using
    labels. Cloud Monitoring provides ways to track all relevant metrics and put them
    on a customized dashboard, thus giving visibility of a GKE cluster. *Figure 8.20*
    shows the built-in **GKE Dashboard** from Cloud Monitoring (with options displayed
    in collapsed mode). The GKE dashboard summarizes information about clusters, namespaces,
    nodes, workloads, Kubernetes services, Pods, and Containers:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.20 – Built-in GKE Dashboard from Cloud Monitoring'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_20.jpg)'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.20 – Built-in GKE Dashboard from Cloud Monitoring
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: This completes the topic on Cloud Operations for GKE and concludes the section
    on GKE where many key concepts and core features were discussed in detail. The
    next section elaborates on the latest operation mode in GKE, called **Autopilot**.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: GKE Autopilot – hands-on lab
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**GKE Autopilot or Autopilot** is one of the two modes of operation supported
    by GKE. The other mode being the standard mode (which was elaborated on at the
    start of this chapter). Autopilot removes the need to perform **do-it-yourself**
    (**DIY**) actions during cluster creation and instead creates a cluster with the
    industry-standard recommendations regarding networking and security. In addition,
    Autopilot removes the need to configure node pools or estimate the size of the
    cluster upfront. Nodes are automatically provisioned based on the types of deployed
    workloads and the user is essentially charged for the running workloads.'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: 'Autopilot is not only managed but is also a serverless K8s offering from GKE.
    Autopilot, however, does not offer all cluster configuration choices offered by
    the standard mode. The following table represents the configuration choices offered
    by Autopilot in comparison to the standard mode:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Table_01.jpg)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
- en: 'The following is a step-by-step guide to creating a GKE cluster in Autopilot
    mode:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the GCP Console and select the compute Service – **Kubernetes Engine**.
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the option to create a cluster and choose **Autopilot** mode. Refer to
    *Figure 8.21*:![Figure 8.21 – Select Autopilot mode during cluster creation
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_08_21.jpg)'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.21 – Select Autopilot mode during cluster creation
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Enter the name for the cluster as `my-autopilot-cluster`. Leave the default
    selections for the rest of the options and select the **CREATE** action. Refer
    to *Figure 8.22*:![Figure 8.22 – Creating a cluster in Autopilot mode
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_08_22.jpg)'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.22 – Creating a cluster in Autopilot mode
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'This will initiate the cluster creation process but in Autopilot mode. Once
    the cluster is created, the cluster will be listed on the cluster list page as
    shown in *Figure 8.23*:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.23 – New cluster created in Autopilot mode'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_23.jpg)'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.23 – New cluster created in Autopilot mode
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some observations from the newly created Autopilot cluster. These
    observations differentiate the Autopilot cluster from a Standard mode cluster:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: An autopilot cluster is created without pre-assigning any nodes upfront.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An autopilot cluster is always created as a regional cluster.
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The release channel for an autopilot cluster is the *Regular channel*.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Node auto-provisioning and vertical Pod autoscaling are enabled by default.
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced networking options such as intranode visibility, NodeLocal DNSCache,
    and HTTP load balancing are enabled by default.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security options such as Workload Identity and shielded GKE nodes are enabled
    by default. These security options are discussed in [*Chapter 9*](B15587_09_Final_ASB_ePub.xhtml#_idTextAnchor201),
    *Securing the Cluster Using GKE Security Constructs*.
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once a cluster is created in Autopilot mode, workloads can be deployed to the
    Autopilot cluster in the exact same way that workloads were previously deployed
    to a cluster in Standard mode. *Figure 8.24* refers to a Deployment created on
    the Autopilot cluster:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.24 – Deployment details in an Autopilot cluster'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_24.jpg)'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.24 – Deployment details in an Autopilot cluster
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: 'The resources required to run the workloads are allocated to the Autopilot
    cluster. *Figure 8.25* displays the cluster list page with resources allocated
    to `my-autopilot-cluster`. In this specific case, 0.5 vCPUs and 2 GB memory are
    allocated to run a single Pod. So, the user is only charged for this workload:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.25 – Resource allocation for the Autopilot cluster after deploying
    a workload'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_08_25.jpg)'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.25 – Resource allocation for the Autopilot cluster after deploying
    a workload
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: This completes the hands-on lab related to GKE Autopilot. This lab provides
    insights into the Autopilot configuration and how resources are allocated to the
    cluster after the deployment of workloads. This also brings us to the end of the
    chapter.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-396
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given that open source Kubernetes or K8s involves a lot of setup and upkeep,
    we deep-dived into Google Kubernetes Engine or GKE, a GCP compute Service that
    runs containerized applications. The Kubernetes concepts learned in [*Chapter
    7*](B15587_07_Final_ASB_ePub.xhtml#_idTextAnchor154), *Understanding Kubernetes
    Essentials to Deploy Containerized Applications*, apply to GKE. We additionally
    explored GKE core features such as GKE node pools, GKE cluster configurations,
    autoscaling, and GKE's ability to integrate with other GCP services across networking
    and operations. The next chapter focuses on security-specific features related
    to the Google Kubernetes Engine, with the goal of hardening a cluster's security.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: Points to remember
  id: totrans-398
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are some important points to remember:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: GKE is fully managed, uses a container-optimized OS, and supports autoscaling,
    the auto-repair of nodes, and auto-upgrades.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE supports two modes of operations – Standard and Autopilot.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE Standard mode supports VPC-native traffic routing and HTTP load balancing
    as default options.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud operations for GKE are enabled as a default setting.
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A private Kubernetes engine cluster cannot be accessed publicly.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A node pool represents a group of nodes with the same configuration.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, a new node pool runs the latest Kubernetes version and can be configured
    for auto-upgrade or can be manually upgraded.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Node pools in a regional or multi-zonal cluster are replicated to multiple zones.
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A multi-zonal cluster will only have a single replica of the control plane.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A regional cluster has multiple replicas of the control plane running across
    multiple zones in a region.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A release channel is used to fix known issues or add new features or address
    any security risks or concerns.
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE creates a cluster with the default version if a specific version or release
    channel is not specified.
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alpha features are only available in special GKE alpha clusters and are not
    available as part of release channels.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Options to autoscale in GKE include the cluster autoscaler, HPA, VPA, and MPA
    (pre-GA).
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cluster autoscaler automatically resizes a node pool in a GKE cluster.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The HPA indicates when application instances should be scaled based on the current
    utilization.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The HPA is not supported for DaemonSets.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The VPA suggests recommended resources for a Pod based on the current utilization.
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The VPA can automatically update workloads if the `updateMode` attribute is
    set to *On*.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MPA allows you to horizontally scale based on CPU and vertically scale based
    on memory at the same time. This is a pre-GA feature.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Autoscaler provides two profile options to scale down: balanced and optimize-utilization.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes' native option to avoid double hop is to set `externalTrafficPolicy`
    to `local`.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE avoids double hop using GCP HTTP(S) Load Balancer and an NEG.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An NEG is a set of network endpoints representing IP to port pairs.
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE runs Linux's log rotate utility to clean up log files. Any log files older
    than a day or more than 100 MB will be automatically compressed and copied into
    an archive file.
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE only stores the five most recently archived log files on the nodes and will
    delete the previously archived log files.
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE streams to Cloud Logging by using FluentD logging agents.
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Event logs refers to logs from operations that take place on a cluster.
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Events are stored as API objects on the cluster master. GKE uses an event exporter
    to push events to Cloud Logging.
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE cluster-specific logs are available in Cloud Logging for 30 days.
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For longer retention, Cloud Logging can export logs using log sinks.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE Autopilot mode supports cluster configurations where the availability type
    is *Regional*, the version is *Release Channel*, network isolation is *Private*
    or *Public*, and Kubernetes features are *Production*.
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-432
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information on GCP''s approach to DevOps, read the following articles:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '**Kubernetes**: [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/
    )'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Google Kubernetes Engine**: [https://cloud.google.com/kubernetes-engine](https://cloud.google.com/kubernetes-engine
    )'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Practice test
  id: totrans-436
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Answer the following questions:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: How do you create control plane components in GKE?
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Create worker nodes and then create control plane components on the worker
    nodes.
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) A GKE cluster does not mandate the creation of control plane components.
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Create control plane components on a node group called `master` and the worker
    nodes are placed in a node group called `worker`.
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) The control plane components are automatically created and managed by GKE
    on behalf of the user.
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Pod `p1` has three containers – `c1`, `c2`, and `c3`. The user wants to view
    the logs of container `c2`. Select the option that represents the appropriate
    CLI command to view the logs:'
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `kubectl logs -p p1 -c c2`
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) `kubectl logs p1 -c c2`
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) `kubectl logs pod=p1 container=c2`
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) `kubectl logs p1 container=c2`
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The company *Alpha* is about to launch a stateless web application to offer
    a new e-commerce Service. The web application will have steady traffic with occasional
    peaks, especially when special offers are announced for customers. Select the
    option that depicts an appropriate cluster design in this case:'
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Deploy a standard cluster and use a Deployment with the HPA.
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Deploy a cluster with autoscaling and use a Deployment with the HPA.
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Deploy a standard cluster and use a Deployment with the VPA.
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Deploy a cluster with autoscaling and use a Deployment with the VPA.
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Choose the cluster configuration that could withstand it if there was a loss
    of a GCP zone:'
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Create a regional cluster.
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Create a Redis cluster that can cache the resource information of the zone
    where cluster resources are hosted.
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Create two clusters in separate zones and create a load balancer between
    them.
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) None of the above.
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select the Google Cloud Service where private GKE clusters can use Docker images
    from?
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Cloud Source Repositories
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Container Registry
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Cloud Build
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) All of the above
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the allowed maximum clusters per zone:'
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 25
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 50
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 100
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Unlimited
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the command to get authentication credentials to interact with a cluster
    named `my-cluster`:'
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `gcloud containers clusters get-credentials my-cluster`
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) `gcloud container clusters get-credentials my-cluster`
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) `gcloud container cluster get-credentials my-cluster`
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) `gcloud containers cluster get-credentials my-cluster`
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the command that can retrieve pods in a cluster:'
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `gcloud get pods`
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) `kubectl list pods`
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) `gcloud list pods`
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) `kubectl get pods`
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The company *Real World* decides to use a third-party monitoring solution to
    monitor an application deployed in a GKE cluster. Select the best approach to
    deploy the third-party monitoring solution:'
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) It is not possible to use a third-party monitoring solution in GKE.
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Download the monitoring solution for Cloud Marketplace.
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Deploy the monitoring solution in a Pod as a DaemonSet.
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Deploy the monitoring solution in a Pod as a ReplicaSet.
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A VPC on Google Cloud is a:'
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Zonal resource
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Global resource
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Regional resource
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Multi-Regional resource
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'An application called *my-app* in GKE needs access to a managed MySQL database.
    Select the most appropriate option:'
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Run MySQL as an application in the cluster. The *my-app* application will
    connect with the MySQL application through the ClusterIP Service.
  id: totrans-489
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Use Cloud SQL to run MySQL database. Run the Cloud SQL proxy as a side-car
    container insider the application's Pod.
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Run MySQL as an application in the cluster. The *my-app* application will
    connect with the MySQL application through the `LoadBalancer` Service.
  id: totrans-491
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Use Cloud SQL for running MySQL Database. Run the Cloud SQL proxy as a ClusterIP
    Service.
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Google Network Load Balancing distributes the following traffic:'
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) TCP
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) UDP
  id: totrans-495
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) TCP or UDP
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) None of the above
  id: totrans-497
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'From an availability-type point of view, a cluster created in *Autopilot* mode
    is:'
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Zonal
  id: totrans-499
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Multi-zonal
  id: totrans-500
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Regional
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Zonal and regional
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the option that is not a supported release channel in GKE:'
  id: totrans-503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Regular
  id: totrans-504
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Alpha
  id: totrans-505
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Rapid
  id: totrans-506
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Stable
  id: totrans-507
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the possible cluster configurations based on network isolation:'
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Standard and Private
  id: totrans-509
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Standard and Public
  id: totrans-510
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Standard and Default
  id: totrans-511
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Private and Public
  id: totrans-512
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answers
  id: totrans-513
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: (d) – The control plane components such as the `kube-api` server, scheduler,
    and so on form the cluster master and are set up and managed by GKE.
  id: totrans-514
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) – `kubectl logs p1 -c c2`
  id: totrans-515
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) – Deploy a cluster with autoscaling and use Deployment with HPA.
  id: totrans-516
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (a) – Create a regional cluster as the workload is spread across multiple zones
    in one region.
  id: totrans-517
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) – Container Registry
  id: totrans-518
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) – 50
  id: totrans-519
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) - `gcloud container clusters get-credentials my-cluster`
  id: totrans-520
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (d) - `kubectl get pods`
  id: totrans-521
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (c) - Deploy the monitoring solution in a Pod as a DaemonSet.
  id: totrans-522
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) – Global resource
  id: totrans-523
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (c)
  id: totrans-524
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (c) – TCP or UDP
  id: totrans-525
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (c) – Regional
  id: totrans-526
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) – Alpha
  id: totrans-527
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (d) – Private and Public
  id: totrans-528
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
