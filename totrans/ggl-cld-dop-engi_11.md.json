["```\n# Create kubernetes service account\nkubectl create serviceaccount jenkins \n```", "```\n# Get the definition of the service account\nkubectl get serviceaccounts jenkins -o yaml\n```", "```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  # ...\nsecrets:\n- name: jenkins-token-78abcd\n```", "```\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: viewer\n  namespace: production\nrules:\napiGroups: [\"\"]\n   resources: [\"pods\"]\n   verbs: [\"get\", \"list\"]\n```", "```\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: viewer\n  namespace: production\nrules:\napiGroups: [\"\"]\n   resources: [\"pods\"]\n   verbs: [\"get\", \"list\"]\napiGroups: [\"\"]\nresources: [\"ConfigMap\"]\nresourceNames: [\"prodEnvironmentVariables\"]\nverbs: [\"get\", \"list\"]\n```", "```\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: node-administrator\nrules:\napiGroups: [\"\"]\n   resources: [\"nodes\"]\n   verbs: [\"get\", \"list\", \"create\", \"delete\"]\n```", "```\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: viewer-rolebinding\n  namespace: production\nsubjects:\n- kind: User\n  name: joe@organization.com\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: viewer\n  apiGroup: rbac.authorization.k8s.io\n```", "```\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: node-administrator-clusterrolebinding\nsubjects:\n- kind: User\n  name: theadmin@organization.com\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: node-administrator\n  apiGroup: rbac.authorization.k8s.io\n```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  securityContext:\n    runAsUser: 3000\n  containers:\n  - name: nginx\n    image: nginx\n    securityContext:\n      runAsUser: 1000\n      allowPrivilegeEscalation: false\n  - name: hello\n    image: hello-world\n```", "```\n    . . .\n    spec:\n      containers:\n      - name: security-context-example\n        image: gcr.io/demo/security-context-example\n        securityContext:\n          capabilities:\n            add: [\"NET_ADMIN\", \"SYS_TIME\"]\n    ```", "```\n    PodSecurityPolicy resource using the following CLI command:\n\n    ```", "```\n\n    ```", "```\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: ClusterRole\n    metadata:\n      name: my-cluster-role\n    rules:\n    - apiGroups:\n      - policy\n      resources:\n      - podsecuritypolicies\n      verbs:\n      - use\n      resourceNames:\n      - my-pod-security-policy\n    ```", "```\n    # Create ClusterRole\n    kubectl apply -f my-cluster-role.yaml\n    ```", "```\n    # Bind the ClusterRole to the desired set of service accounts\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: RoleBinding\n    metadata:\n      name: my-role-binding\n      namespace: my-namespace\n    roleRef:\n      apiGroup: rbac.authorization.k8s.io\n      kind: ClusterRole\n      name: my-cluster-role\n    subjects:\n      - kind: ServiceAccount\n        name: sa@example.com\n        namespace: my-namespace\n    ```", "```\n    # Create RoleBinding\n    kubectl apply -f my-role-binding.yaml\n    ```", "```\n    # To enable at the time of cluster creation\n    gcloud beta container clusters create <cluster-name> --enable-pod-security-policy\n    # To enable on an existing cluster\n    gcloud beta container clusters update <cluster-name> --enable-pod-security-policy\n    ```", "```\n    To disable PodSecurityPolicy controller\n    gcloud beta container clusters update <cluster-name> --no-enable-pod-security-policy\n    ```", "```\n# For Standard Clusters\ngcloud container clusters create my-private-cluster \\\n    --create-subnetwork name=my-subnet \\\n    --enable-master-authorized-networks \\\n    --enable-ip-alias \\\n    --enable-private-nodes \\\n    --enable-private-endpoint \\\n    --master-ipv4-cidr 172.20.4.32/28\n```", "```\n# For Standard Clusters\ngcloud container clusters create my-private-cluster-1 \\\n    --create-subnetwork name=my-subnet-1 \\\n    --enable-master-authorized-networks \\\n    --enable-ip-alias \\\n    --enable-private-nodes \\\n    --master-ipv4-cidr 172.20.8.0/28\n```", "```\n# For Standard Clusters\ngcloud container clusters create my-private-cluster-2 \\\n    --create-subnetwork name=my-subnet-2 \\\n    --no-enable-master-authorized-networks \\\n    --enable-ip-alias \\\n    --enable-private-nodes \\\n    --master-ipv4-cidr 172.20.10.32/28\n```", "```\n# Enable Shielded GKE nodes on new cluster\ngcloud container clusters create <cluster-name> --enable-shielded-nodes\n# Enable Shielded GKE nodes on existing cluster\ngcloud container clusters update <cluster-name> --enable-shielded-nodes\n# Verify that Shielded GKE nodes are enabled (check for enabled under shieldedNodes as true)\ngcloud container clusters describe <cluster-name>\n# Disable Shielded GKE nodes (This will recreate the control plane and nodes thus leading to downtime)\ngcloud container clusters update <cluster-name> --no-enable-shielded-nodes\n```", "```\n# Enforce network policy for a new GKE cluster\ngcloud container clusters create <cluster-name> --enable-network-policy\n```", "```\n# Enable add-on to enforce network policy on existing cluster\ngcloud container clusters update <cluster-name> --update-addons=NetworkPolicy=ENABLED\n# Enforce network policy after enabling add-on for existing cluster. This will recreate the cluster node pools\ngcloud container clusters update <cluster-name> --enable-network-policy\n```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: my-break-glass-pod\n  annotations:\n    alpha.image-policy.k8s.io/break-glass: \"true\"\n```", "```\nserviceAccount:PROJECT_ID.svc.id.goog[K8S_NAMESPACE/KSA_NAME]\n# PROJECT_ID.svc.id.good - workload identity pool on the cluster\n# KSA_NAME Kubernetes - service account making the request\n# K8S_NAMESPACE Kubernetes - namespace with Kube SA is defined\n```", "```\n    # Create cluster with workload identity enabled\n    gcloud container clusters create <CLUSTER_NAME> \\\n      --workload-pool=<PROJECT_ID>.svc.id.goog\n    ```", "```\n    # Update existing cluster with workload identity enabled\n    gcloud container clusters update <CLUSTER_NAME> \\\n     --workload-pool=<PROJECT_ID>.svc.id.goog\n    ```"]