- en: '*Chapter 10*: Exploring GCP Cloud Operations'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Reliability** is the most critical feature of a service or a system. **Site
    Reliability Engineering** (**SRE**) prescribes specific technical tools or practices
    that help in measuring characteristics that define and track reliability, such
    as **SLAs**, **SLOs**, **SLIs**, and **error budgets**.'
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 2*](B15587_02_Final_ASB_ePub.xhtml#_idTextAnchor038), *SRE Technical
    Practices – Deep Dive*, we discussed the key constructs of SLAs in detail, the
    need for SLOs to achieve SLAs, the guidelines for setting SLOs, and the need for
    SLIs to achieve SLOs. In addition, we learned about the different types of SLIs
    based on user journey categorization, different sources to measure SLIs, the importance
    of error budgets, and the ways to set error budgets to make a service reliable.
  prefs: []
  type: TYPE_NORMAL
- en: 'This raises a series of fundamental questions:'
  prefs: []
  type: TYPE_NORMAL
- en: How can we observe SLIs for a service so that the SLOs are not violated?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we track whether our error budgets are getting exhausted?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we maintain harmony between the key SRE technical tools?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SRE''s answer to the preceding questions is observability. Observability on
    **Google Cloud Platform** (**GCP**) is established through operations. From Google''s
    point of view, Cloud Operations is about monitoring, troubleshooting, and improving
    application performance in the Google Cloud environment. The key objectives of
    Cloud Operations are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Gather logs, metrics, and traces from any source.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Query the captured metrics and analyze traces.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualize information on built-in or customizable dashboards.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish performance and reliability indicators.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trigger alerts and report errors in situations where reliability indicators
    are not met, or issues are encountered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google achieves key objectives of operations through a collection of services
    called Cloud Operations. Cloud Operations is a suite of GCP services that includes
    Cloud Monitoring, Cloud Logging, Error Reporting, and **Application Performance
    Management** (**APM**). Furthermore, APM includes Cloud Debugger, Cloud Trace,
    and Cloud Profiler. This chapter will explore services tied to Cloud Operations.
    Post that, we will focus on a specific feature that was introduced in Google Cloud
    to track the reliability of services through Service Monitoring. This specific
    feature/option links the SRE technical practices (SLIs, SLOs, and Error Budget)
    to features available in Google Cloud Operations that monitor the service and
    tell us about its reliability.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cloud Monitoring**: Workspaces, dashboards, Metrics explorer, uptime checks,
    and alerting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Logging**: Audit Logs, Logs Ingestion, Logs Explorer, and Logs-Based
    Metrics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Debugger**: Setting up, Usage, Debug Logpoints, and Debug Snapshots.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Trace**: Trace Overview, Trace List, and Analysis Reports.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Profiler**: Profile Types.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Binding SRE and Cloud Operations**: We will measure service reliability using
    Cloud Operations by linking them to SRE technical practices via a hands-on lab.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Cloud Monitoring** is a GCP service that collects metrics, events, and metadata
    from multi-cloud and hybrid infrastructures in real time. Cloud Monitoring helps
    us understand how well our resources are performing and if there is something
    wrong that requires immediate attention. Cloud Monitoring is a medium through
    which SRE best practices can be implemented and to ensure that applications are
    meeting their set SLAs. Cloud Monitoring consists of out-of-the-box dashboards.
    These can be used to visualize insights into key factors that impact SLIs and
    SLOs such as latency, throughput, and more. Cloud Monitoring is also critical
    for incident management as alerts can be generated from key metrics, and these
    alerts can be sent as notifications to configured notification channels.'
  prefs: []
  type: TYPE_NORMAL
- en: This section on Cloud Monitoring deep dives into several key areas/properties,
    such as workspaces, dashboards, Metrics explorer, uptime checks, alerting, access
    controls, and the Monitoring agent. We will start with workspaces.
  prefs: []
  type: TYPE_NORMAL
- en: Workspaces
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Google Workspace** is a centralized hub that''s used to organize and display
    monitoring information about GCP and AWS resources. Workspace provides a centralized
    view and acts as a single point of entry to resource dashboards, uptime checks,
    groups, incidents, events, and charts. Google describes this centralized view
    as a *single pane of glass* (please refer to the following screenshot). The actions
    that can be performed against a workspace include the ability to view content,
    which is controlled by **Identity and Access Management** (**IAM**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Overview of a Cloud Monitoring workspace'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.1 – Overview of a Cloud Monitoring workspace
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is some key terminology we need to know about before we elaborate
    on the relationship between workspaces and projects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Host project**: This refers to the project where Workspace is created.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitored project**: This refers to the GCP projects or AWS accounts that
    the workspace can monitor.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AWS connector project**: This refers to the GCP project that connects the
    monitored AWS account to the workspace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The upcoming subsection provides insights into the relationship between Workspace
    and Project.
  prefs: []
  type: TYPE_NORMAL
- en: Workspace/project relationship
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following are some key pointers with respect to a workspace/project relationship:'
  prefs: []
  type: TYPE_NORMAL
- en: A workspace is always created inside a project. This is known as the host project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A workspace is part of a single host project and is named after the host project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A workspace can monitor resources from multiple monitored projects simultaneously.
    This could include about 200 GCP projects/AWS accounts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A workspace can access other monitored projects' metric data, but the actual
    data lives in monitored projects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A monitored project can only be associated with a single workspace, and a monitored
    project can be moved from one workspace to another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple workspaces can be merged into a single workspace.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no charge associated with creating a workspace. However, charges with
    respect to logging and ingesting metric data is charged to the billing account
    associated with the *monitored projects*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip – how to connect an AWS account to a workspace
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A GCP connector project is required. This can be an existing project, or an
    empty project (preferred) created for this purpose. GCP connector project needs
    to be under the same parent organization as the workspace. A billing account should
    be tied to the connector project and this account will be charged to monitor the
    resources under the AWS account.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The following section discusses potential strategies for creating a workspace.
  prefs: []
  type: TYPE_NORMAL
- en: Workspace creation – strategies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In a real-time scenario, it is possible to have multiple projects where the
    projects are either differentiated by customers or differentiated by environment
    types such as development, test, staging, and production. Given that a workspace
    can monitor resources from multiple projects, the strategy/approach that's taken
    to create the workspace becomes critical. There are multiple strategies we can
    follow to create a workspace, as detailed in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: A single workspace for all monitored projects
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Information about all monitored project resources is available from within a
    single workspace. The following diagram represents a single workspace that monitors
    an application, `app`, that's been deployed across multiple projects, such as
    `app-dev`, `app-test`, and `app-prod`. These have been categorized by environment
    type. This approach has its own pros and cons.
  prefs: []
  type: TYPE_NORMAL
- en: 'The pro is that the workspace provides a single pane of glass for all the resources
    tied to the application across multiple projects representing multiple environment
    types. The con is that a non-production user can access resources from a production
    project, and this might not be acceptable in most cases. This approach is not
    suitable for organizations that have strict isolation between production and non-production
    environments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – A single workspace for all related projects'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.2 – A single workspace for all related projects
  prefs: []
  type: TYPE_NORMAL
- en: Workspace per group of monitored projects
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A workspace will monitor a specific group of projects. There could be more
    than one workspace monitoring the available projects. The following diagram is
    an alternative workspace creation strategy compared to the one shown in the preceding
    diagram. Specifically, the following diagram represents two workspaces where one
    workspace monitors the non-production projects and the second workspace monitors
    the production project. Access controls to that specific group can be controlled
    by the host project of the individual workspace. This allows us to differentiate
    between users across environment types, such as production versus non-production
    or even across customers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Workspace per group of monitored projects'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.3 – Workspace per group of monitored projects
  prefs: []
  type: TYPE_NORMAL
- en: Single workspace per monitored project
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Essentially, every project that needs to be monitored is hosted by a workspace
    within the same project. This can be seen in the following diagram. This means
    that the source and the host project will be the same. This approach provides
    the most granular control in terms of providing monitoring access to the project
    resources. However, this might also only provide a slice of information if an
    application is spread across multiple projects:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Single workspace per monitored project'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.4 – Single workspace per monitored project
  prefs: []
  type: TYPE_NORMAL
- en: Important note – Workspace management
  prefs: []
  type: TYPE_NORMAL
- en: One or more GCP project(s) or AWS account(s) can either be added or removed
    from the workspace. In addition, all projects within a selected workspace can
    be merged into the current workspace, but the configuration will be deleted in
    the selected workspace. These actions are performed through the settings page
    of Cloud Monitoring. A workspace can only be deleted if the workspace host project
    is deleted.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes this subsection on workspace creation strategies. The preferred
    strategy depends on the organizational need. Workspace basic operations include
    creating a workspace, adding project(s) to a workspace, moving projects between
    workspaces, and merging workspaces. Detailed instructions on how to create a workspace
    can be found at [https://cloud.google.com/monitoring/workspaces/create](https://cloud.google.com/monitoring/workspaces/create).
    The upcoming subsection discusses IAM roles, which are used to determine who has
    access to monitor the resources inside the monitoring workspace.
  prefs: []
  type: TYPE_NORMAL
- en: Workspace IAM roles
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following are the IAM roles that can be applied to a workspace project
    so that we can view monitoring data or perform actions on the workspace:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Monitoring Viewer**: Read-only access to view metrics inside a workspace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring Editor**: Monitoring Viewer, plus the ability to edit a workspace,
    create alerts, and have write access to Monitoring Console and Monitoring API.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring Admin**: Monitoring Editor, plus the ability to manage IAM roles
    for the workspace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring Metric Writer**: A service account role that''s given to applications
    instead of humans. This allows an application to write data to a workspace but
    does not provide read access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This concludes our quick insight into workspaces and their concepts, such as
    workspace creation strategies. Next, we will look at dashboards.
  prefs: []
  type: TYPE_NORMAL
- en: Dashboards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Dashboards** provide a graphical representation of key signal data, called
    metrics, in a manner that is suitable for end users or the operations team. It''s
    recommended that a single dashboard displays metrics depicting a specific viewpoint
    (for example, serverless resources with a specific label) or for a specific resource
    (for example, persistent disks, snapshots, and so on). There are two types of
    dashboards: predefined dashboards and custom dashboards.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot is of the **Dashboards Overview** page in Cloud Monitoring.
    This page displays the list of available dashboards, categorized by dashboard
    types, and provides quick links to the most recently used dashboards:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Cloud Monitoring – Dashboards Overview'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.5 – Cloud Monitoring – Dashboards Overview
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Monitoring supports both predefined dashboards and custom dashboards.
    The upcoming subsection provides an overview of the different types of dashboards
    and steps for how to create a custom dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Predefined dashboards
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cloud Monitoring provides a set of predefined dashboards that are grouped by
    a specific GCP resource such as firewalls or GKE Clusters. These dashboards are
    categorized by **Type**. This is set to **Google Cloud Platform**, which is maintained
    by Google Cloud. They do not require any explicit setup or effort to configure.
  prefs: []
  type: TYPE_NORMAL
- en: However, predefined dashboards are not customizable. These dashboards are organized
    in a specific manner with a set of predefined filters from the context of the
    dashboard. Users cannot change the contents of the view or add a new filter criterion.
    Users can only use the predefined filters to control the data being displayed.
  prefs: []
  type: TYPE_NORMAL
- en: Custom dashboards
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Users or operation teams can create a **custom dashboard** that displays specific
    content of interest. These dashboards are categorized by **Type** set to **Custom**.
    Content is added by configuring one or more widgets. There are multiple types
    of widgets. Dashboards can either be created from Google Cloud Console or via
    the Cloud Monitoring API. In addition, the Cloud Monitoring API allows you to
    import a dashboard configuration from GitHub and modify it as needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Custom dashboards represent information about a metric using a chart. This
    chart displays raw signal information from a metric that''s aligned across a configurable
    time window. Each chart is of a specific widget type. Cloud Monitoring supports
    multiple widget types such as Line, Stacked area, Stacked bar, Heatmap, Gauge,
    Scorecard, and Textboxes. Let''s take a brief look at the different types of widgets:'
  prefs: []
  type: TYPE_NORMAL
- en: Line charts, stacked area charts, and stacked bar charts are best utilized to
    display time series data. Each of these widget types can be configured so that
    they're displayed in Color/X-Ray/Stats/Outlier mode, along with an optional legend,
    using the display view options.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heatmap charts are used to represent metrics with a distribution value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gauges display the most recent measurement in terms of a number. This is represented
    by a thick line around the gauge. This is visually categorized across good, warning,
    and danger zones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scorecards are similar to gauges as they display the recent measurement in terms
    of a number, but they can be visually depicted using a different view other than
    a gauge, such as a spark line, spark bar, icon, or value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Textboxes allow us to add any custom information, such as quick notes or links,
    concerning the relevant resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The upcoming subsection will show you how to create a custom dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a custom dashboard
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Follow these steps to create a custom dashboard from the GCP console:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to `VM Instance – Mean CPU Utilization`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select a chart type or widget. This will open **Metrics explorer** on the left-hand
    pane and will add the chart to the dashboard.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the options to choose a resource type, metric type, and grouping criteria.
    Then, **Save** the dashboard to add the chart type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Redo the preceding steps to add multiple charts to the same dashboard.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following screenshot shows a custom dashboard depicting the mean CPU utilization
    for all the VM instances, along with seven possible widget types:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6 – Custom dashboard with seven possible widget types'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.6 – Custom dashboard with seven possible widget types
  prefs: []
  type: TYPE_NORMAL
- en: This concludes this section on Cloud Monitoring dashboards. The next section
    focuses on using *Metrics explorer* as an option to explore predefined and user-created
    metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics explorer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Metrics** is one of the critical sources for monitoring data. Metrics represents
    numerical measurements of resource usage or behavior that can be observed and
    collected across the system over many data points at regular time intervals. There
    are about 1,000 pre-created metrics in GCP. This includes CPU utilization, network
    traffic, and more. However, some granular metrics such as memory usage can be
    collected using an optional Monitoring agent. Additionally, custom metrics can
    be created either through the built-in Monitoring API or through OpenCensus –
    an open source library used to create metrics. It is always recommended to check
    if a default or pre-created metric exists before creating a custom metric.'
  prefs: []
  type: TYPE_NORMAL
- en: Metrics explorer provides options for exploring existing metrics (either predefined
    or user-created), using metrics to build charts, adding charts to an existing
    or new dashboard, sharing charts via a URL, or retrieving chart configuration
    data in JSON format. Metrics explorer is an interface that provides a DIY approach
    to building charts as you can select a metric of your choice.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the **Metrics explorer** section, which charts
    the **CPU Utilization** metric for a **VM Instance**, grouped by system state.
    The left-hand side displays the configuration region, while the right-hand side
    depicts the chart for the selected metric. The configuration region has two tabs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Metric**: This tab is used to select the metric and explore it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**View Options**: This tab is used to change the chart''s display characteristics:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.7 – Cloud Monitoring – Metrics explorer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.7 – Cloud Monitoring – Metrics explorer
  prefs: []
  type: TYPE_NORMAL
- en: The following section discusses the available options for configuring a metric
    using Metrics explorer.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding metric configuration via Metrics explorer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To configure a metric for a monitored resource, we can use the following options.
  prefs: []
  type: TYPE_NORMAL
- en: '**Resource type** and **Metric** option can be selected in either of the following
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Standard Mode**: Select a specific metric type or browse the available metric
    types based on a specific GCP resource.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Direct Filter Mode**: Manually enter a metric type and resource type in a
    text box.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The **Filter** option can be used to filter out the results based on the filter
    criterion. The filter criterion can be defined using the available operators or
    regular expressions. There are two possible filter types:'
  prefs: []
  type: TYPE_NORMAL
- en: '`project_id`, `instance_id`, and `zone` as the available filter options).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**By Metric Label**: Refers to project-wide user-created labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Group By** option can be used to group time series data by resource type
    and metric label. This creates new time series data based on the combination of
    group by values.
  prefs: []
  type: TYPE_NORMAL
- en: The **Aggregator** option can be used to describe how to aggregate data points
    across multiple time series. Common options include min, max, sum, count, and
    standard deviation. By default, the aggregation results in a single line by applying
    the aggregator across all the time series. If **Group By** labels are selected,
    the aggregation results in a time series for each combination of matching labels.
  prefs: []
  type: TYPE_NORMAL
- en: The **Period** option can be used to determine the time interval for which aggregation
    takes place. The default selection is 1 minute.
  prefs: []
  type: TYPE_NORMAL
- en: The **Aligner** option can be used to bring the data points in each individual
    time series into equal periods of time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additional options include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Secondary Aggregator**: Used in charts with multiple metrics'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Legend Template**: For better readability'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Multiple **View Options** can be used to plot metrics, and these are distinguished
    by the available chart modes, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Color mode**: This is the default mode where graph lines are shown in color.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**X-Ray mode**: Shows graph lines in a translucent gray color but with brightness
    in the case of overlapping bands.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stats mode**: Shows common statistical values such as the 5th percentile,
    95th percentile, average, median, and more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outlier mode**: Allows you to choose a number of time series to display,
    along with the option to rank time series by ordering them from the top or bottom.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, each chart mode supports the ability to specify a specific threshold
    and allows you to compare past time series data. In addition, it is possible to
    apply a log scale to the *y* axis for better separation between larger values
    in datasets where some values are much larger than the others.
  prefs: []
  type: TYPE_NORMAL
- en: Tip – Monitoring Query Language (MQL) – Advanced option to create charts
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Monitoring supports **MQL**, an advanced option for creating a chart with
    a text-based interface and an expressive query language that can execute complex
    queries against time series data. Potential use cases include the ability to select
    a random sample of time series or compute the ratio of requests, resulting in
    a particular class of response codes.
  prefs: []
  type: TYPE_NORMAL
- en: This completes this section on Metrics explorer, which allows users to explore
    predefined and custom metrics. These can potentially be used to create charts.
    The options related to configuring a metric were also discussed in detail. The
    upcoming section focuses on uptime checks – an option for validating whether a
    service is functioning.
  prefs: []
  type: TYPE_NORMAL
- en: Uptime checks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Uptime check** is a Cloud Monitoring feature where periodic requests are
    sent to monitor a resource to check if the resource is indeed up. Uptime checks
    can check the uptime of GCP VMs, App Engine services, website URLs, and AWS Load
    Balancer. Uptime checks are also a way to track the Error Budget of services.
    Uptime checks essentially test the availability of an external facing service
    within a specific timeout interval and ensure that the Error Budget of the service
    is not burnt unnecessarily. It is possible to initiate these tests from one or
    more GCP geographic regions, and a minimum of three active locations must be selected
    as geographic regions. Alternatively, selecting the **Global** option will initiate
    tests from all available locations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The frequency at which uptime checks are performed can be configured and defaults
    to 1 minute. Uptime checks support multiple protocol options, such as HTTP, HTTPS,
    and TCP, and can be defined for the following resource types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**URL**: Required to specify a hostname and path.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**App Engine Service**: Required to specify a service and path.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Instance**: Required to specify a path for a single instance (GCP or EC2)
    or a predefined group. This group needs to be explicitly configured.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Elastic Load Balancer**: Required to specify a path for AWS ELB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The configuration to create an uptime check includes options to perform response
    validation. These options include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Provide response timeout**: This is the time it takes for the request to
    complete. Must be between 1 and 60 seconds. The default is 10 seconds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enable response content**: This option allows you to select a response content
    match type with specific operators that contain or do not contain specific text
    or matches on regex.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Log Check Failures**: This option will save all the logs related to uptime
    checks failing to Cloud Logging.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition, alerts and notifications can be configured in situations when
    the uptime check fails for the selected duration. It is mandatory that the alert
    policy already exists and that the notification channel has been pre-created.
    The following screenshot shows the summary configuration of an uptime check where
    the target resource type is a URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.8 – Uptime checking a URL as the target resource type'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.8 – Uptime checking a URL as the target resource type
  prefs: []
  type: TYPE_NORMAL
- en: The URL being used in the preceding screenshot is the URL of the LoadBalancer
    service, `hello-world-service`, that was created as part of [*Chapter 8*](B15587_08_Final_ASB_TD_ePub.xhtml#_idTextAnchor182),
    *Understanding GKE Essentials to Deploy Containerized Applications*. A configured
    uptime check can result in a failure. The upcoming subsection lists the potential
    reasons for uptime check failures.
  prefs: []
  type: TYPE_NORMAL
- en: Potential reasons for uptime check failures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following are some potential reasons for uptime checks failing:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Connection errors**: The hostname/service not found or responding, or the
    specified port is not open or valid.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`403` (Forbidden Service), `404` (Incorrect Path), and `408` (port number is
    incorrect or service is not running).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GoogleStackdriverMonitoring-UptimeChecks`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This concludes our detailed overview of uptime checks. The next topic deep dives
    into alerting – a Cloud Monitoring option that's key for Incident Management.
    Alerting provides options for reporting on monitored metrics and providing notifications
    appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: Alerting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Alerting** is the process of processing the alerting rules, which track the
    SLOs and notify or perform certain actions when the rules are violated. [*Chapter
    3*](B15587_03_Final_ASB_ePub.xhtml#_idTextAnchor064), *Understanding Monitoring
    and Alerting to Target Reliability*, deep dived into alerting, described how alerting
    allows us to convert SLOs into actionable alerts, discussed key alerting attributes,
    and elaborated on alerting strategies. The alerting UI in Cloud Monitoring hosts
    information with respect to incidents currently being fired, incidents being acknowledged,
    active alerting policies that have been configured, details of open and closed
    incidents, and all the incidents tied to the events. In addition, alerting allows
    us to create an alert policy and configure notification channels.'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring an alert policy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The steps involved in configuring an alert policy are very similar to the ones
    for creating a chart using Metrics explorer. Essentially, an alert needs to be
    created against a metric. Configuring an alert includes adding a metric condition
    through Metrics explorer and setting a metric threshold condition.
  prefs: []
  type: TYPE_NORMAL
- en: A metric threshold condition will define the specific value. If the specific
    metric value falls above or below the threshold value (based on how the policy
    is defined), an alert will be triggered, and we will be notified through the configured
    notification channels. If the policy is defined through the console, then the
    policy trigger field is used, while if the policy is defined through the API,
    then the combiner field is used.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, to define an alert policy based on a metric threshold condition,
    you can define an alert policy based on a metric absence condition. A metric absence
    condition is defined as a condition where time series data doesn't exist for a
    metric for a specific duration of time.
  prefs: []
  type: TYPE_NORMAL
- en: Important note – The alignment period is a lookback interval
  prefs: []
  type: TYPE_NORMAL
- en: The alignment period is a lookback interval from a particular point in time.
    For example, if the alignment period is 5 minutes, then at 1:00 P.M., the alignment
    period contains the samples received between 12:55 P.M. and 1:00 P.M. At 1:01
    P.M., the alignment period slides 1 minute and contains the samples received between
    12:56 P.M. and 1:01 P.M.
  prefs: []
  type: TYPE_NORMAL
- en: The next section describes the available notification channels that are used
    to send information that's specific to firing alerts.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring notification channels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If an alerting policy violates the specified condition, then an incident gets
    created with an Open status. Information about the incident can be sent to one
    or more notification channels. On receipt of the notification, the operations
    team can acknowledge the incident through the console. This changes the status
    of the incident to Acknowledged. This is an indication that the event is being
    inspected. The incident eventually goes to Closed status if either the conditions
    are no longer being violated, or no data is received for the specific incident
    over the course of the next 7 days.
  prefs: []
  type: TYPE_NORMAL
- en: 'The supported notification channels are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mobile Devices**: Mobile devices should be registered via the incidents section
    of the Cloud Console Mobile App.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PagerDuty Services**: Requires a service key to authenticate and authorize.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pagerduty.com` and the respective API key to authenticate and authorize.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Slack**: Prompts the user to authenticate and authorize to a Slack channel
    through a custom URL, and then prompts the user to provide the Slack channel''s
    name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Webhooks**: Requires the endpoint URL, along with optional usage of HTTP
    Basic Auth.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Email**: Requires an email address to receive notifications when a new incident
    is created.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SMS**: Requires a phone number to receive notifications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`service-[PROJECT_NUMBER]@gcp-sa-monitoring-notification.iam.gserviceaccount.com`.
    The `pubsub.publisher` role should be added to the preceding service account to
    configure alert notifications via Cloud Pub/Sub.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This concludes this section on alerting, where we looked at configuring an alerting
    policy and notification channels. The next section introduces the Cloud Monitoring
    agent.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cloud Monitoring provides a lot of metrics out of the box, without any additional
    configuration, such as CPU utilization, network traffic, and more. However, more
    granular metrics such as memory usage, network traffic, and so on can be collected
    from unmanaged VMs or from third-party applications using an optional `collectd`
    daemon (daemon refers to a program that runs in the background) to collect system
    statistics from various sources, including operating systems, applications, logs,
    and external devices.
  prefs: []
  type: TYPE_NORMAL
- en: The Monitoring agent can be installed on unmanaged GCE VMs or AWS EC2 VMs. Other
    Google compute services, such as App Engine, Cloud Run, and Cloud Functions, have
    built-in support for monitoring and do not require you to explicitly install the
    Monitoring agent. GKE also has built-in support for monitoring and can be enabled
    for new or existing clusters via *Cloud Operations for GKE*, an integrated monitoring
    and logging solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conceptually, you must follow this process to install/configure a Monitoring
    agent on unmanaged VMs:'
  prefs: []
  type: TYPE_NORMAL
- en: Add the agent's package repository via a provided script that detects the Linux
    distribution being run on the VM and configures the repository accordingly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Install the Monitoring agent using the `stackdriver-agent` agent for the latest
    version or by using `stackdriver-agent-version-number` for a very specific version.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restart the agent for the installed agent to come into effect.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The step-by-step process of installing a Logging agent on a single VM/GCE VM/AWS
    EC2 instance can be found at [https://cloud.google.com/monitoring/agent/installation](https://cloud.google.com/monitoring/agent/installation).
    This completes our brief overview of the Monitoring agent. The next subsection
    mentions the possible access controls with respect to Cloud Monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Monitoring access controls
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following table summarizes the critical IAM roles required to access or
    perform actions on Cloud Monitoring:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Groups – A collection of resources that is defined as a Monitoring Group'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_Table_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Groups – A collection of resources that is defined as a Monitoring Group
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Monitoring allows you to create a monitoring group. This is a convenient
    way to view the list of GCP resources, events, incidents, and visualizations as
    key metrics from a centralized place. A monitoring group is created by defining
    one or more criteria either against the name, resource type, tag, security group,
    cloud project, or region. If multiple criteria are specified, then an OR/AND operator
    can be specified.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our deep dive into Cloud Monitoring and its respective constructs,
    such as Workspace, dashboards, Metrics explorer, uptime checks, alerting policies,
    and access controls. The next section elaborates on another GCP construct that's
    part of Cloud Operations and focuses on logging; that is, Cloud Logging.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A log is defined as a record of a status or event. Logging essentially describes
    what happened and provides data so that we can investigate an issue. It is critical
    to be able to read and parse logs across a distributed infrastructure involving
    multiple services and products. **Cloud Logging** is a GCP service that allows
    you to store, search, analyze, monitor, and alert others about logging data and
    events from Google Cloud and AWS, third-party applications, or custom application
    code. The information in the log entry is structured as a payload. This payload
    consists of information related to a timestamp, a resource that the log entry
    applies to, and a log name. The maximum size of a log entry is 256 KB. Each log
    entry indicates the source of the resource, labels, namespaces, and status codes.
    Cloud Logging is also the source of input for other Cloud Operations services,
    such as Cloud Debug and Cloud Error Reporting.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the key features of Cloud Logging:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Audit Logs**: Logs are captured and categorized as Admin Activity, Data Access,
    System Event, and Access Transparency Logs, with each category having a default
    retention period.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logs Ingestion**: Logs can be ingested from many sources, including GCP services
    and on-premises or external cloud providers, by using the Cloud Logging API or
    through logging agents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logs Explorer**: Logs can be searched for and analyzed through a guided filter
    configuration or flexible query language, resulting in effective visualization.
    Results can also be saved in JSON format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logs-based Metrics**: Metrics can be created from log data and can be added
    to charts/dashboards using the Metrics explorer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logs Alerting**: Alerts can be created based on the occurrence of log events
    and based on the created logs-based metrics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logs Retention**: Logs can be retained for a custom retention period based
    on user-defined criteria.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logs Export**: Logs can be exported to Cloud Storage for archival, BigQuery
    for advanced analytics, Pub/Sub for event-based processing using GCP services,
    user-defined cloud logging sinks, or to initiate external third-party integrations
    so that you can export using services such as Splunk.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Logging features will be discussed in detailed in the upcoming subsections,
    starting with Audit Logs.
  prefs: []
  type: TYPE_NORMAL
- en: Audit Logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Cloud Audit Logs** is a fundamental source for finding out about certain
    parts of a project (*who did what, where, and when?*). Cloud Audit Logs maintains
    logs for each project (including folder- and organization-level information).
    Cloud Audit Logs can be categorized into various categories. Let''s take a look.'
  prefs: []
  type: TYPE_NORMAL
- en: Admin activity logs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Admin activity logs** are specific to any administrative actions that modify
    the configuration or metadata of resources. Examples for admin activity logs include,
    but not are limited to, the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting or changing permissions of a cloud storage bucket
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assigning /unassigning IAM roles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing any properties of a resource, such as tags/labels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating/deleting resources for GCE, GKE, or Cloud Storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following screenshot shows the admin activity logs for when a GCE VM or
    bucket was created. The easiest way to access these activity logs is from the
    **Activity** tab on the GCP console home page. This pulls a live feed of the admin
    activity logs but does not include data access logs by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.9 – Admin activity logs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.9 – Admin activity logs
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection provides an overview of an audit log category specific to
    *data access*.
  prefs: []
  type: TYPE_NORMAL
- en: Data access logs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Data access logs** are useful for reading the configuration or metadata of
    resources. This also includes user-level API calls, which read or write resource
    data. Data access audit logs need to be enabled explicitly (except for Big Query),
    and this can be controlled by specifying the services whose audit logs should
    be captured. In addition, data access logs tied to actions performed by a specific
    set of users or groups can be exempted, thus providing granular control. Data
    access logs can be further classified into three subtypes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Admin read**: Read attempts on service metadata or configuration data. An
    example of this is listing the available buckets or listing the nodes within a
    cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data read**: Read attempts of data within a service. An example of this includes
    listing the objects within a bucket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data write**: Write attempts of data to a service. An example of this includes
    creating an object within a bucket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is a screenshot of granular data access being configured for
    an individual GCP service from IAM – the **Audit Logs** UI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.10 – Configuring IAM Audit Logs for a service'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.10 – Configuring IAM Audit Logs for a service
  prefs: []
  type: TYPE_NORMAL
- en: The preceding screenshot also shows the option to configure **Exempted Users**.
    This option allows you to exempt audit logs from being generated for certain users,
    as configured. Data access logs can be viewed either through the **Activity**
    tab of the GCP home page, where **Activity Type** is **Data Access**, or through
    the **Logs Explorer** UI (discussed later). The next subsection provides an overview
    of an audit log category specific to system events.
  prefs: []
  type: TYPE_NORMAL
- en: System event logs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**System event logs** are used when changes have been made to resources by
    Google systems or services. They are not specific to user actions on the resources.
    Examples of system event logs include, but are not limited to, the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Automatically restarting or resetting Compute Engine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: System maintenance operations, such as migration events, which are performed
    by Compute Engine to migrate applications to a different host
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next subsection provides an overview on an audit log category specific to
    access transparency.
  prefs: []
  type: TYPE_NORMAL
- en: Access transparency logs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Access transparency logs** are used by Google personnel when they''re accessing
    a user''s/customer''s content. This situation typically arises when Google''s
    support team is working on a customer issue (such as a specific service not working
    as expected or an outage) and, as a result, needs to access the customer''s project.
    This category of logs is critical if you wish to follow legal and regulatory obligations.
    In addition, you can trace events to look back on the actions that have been performed
    by Google support personnel. Access transparency logs can be enabled by contacting
    Google support and are available for customer support levels, excluding individual
    accounts. An example of access transparency logs could be the logs that are accessed
    by the support personnel while trying to resolve a support issue for a VM instance.'
  prefs: []
  type: TYPE_NORMAL
- en: Policy denied logs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Policy denied logs** are logs that are captured when access is denied by
    a Google Cloud service to either a user or service account. Policy denied logs
    can be excluded from ingestion into Cloud Logging through Logs Exclusions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This completes this section on audit logs, where we provided an overview of
    the various subcategories. Before proceeding to the next section, take a look
    at the following table, which lists the IAM roles specific to accessing logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15587_10_Table_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The next section will explain how logs are ingested into Cloud Logging from
    multiple sources.
  prefs: []
  type: TYPE_NORMAL
- en: Logs ingestion, routing, and exporting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cloud Logging supports logs ingestion from multiple sources, such as audit logs,
    service logs, application logs, syslogs, and platform logs. These logs are sent
    to the **Cloud Logging API**. The Cloud Logging API forwards the incoming log
    entries to a component called **Logs Router**. Logs Router is fundamentally responsible
    for routing logs to their respective destinations.
  prefs: []
  type: TYPE_NORMAL
- en: These destinations can be grouped into four possible categories. Logs Router
    will check the incoming logs against existing rules to determine whether to ingest
    (store), export, or exclude them, and will route the logs to one of the four destination
    categories.
  prefs: []
  type: TYPE_NORMAL
- en: 'These destination categories are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**_Required log bucket**: This is the primary destination for admin activity,
    system event, and access transparency logs. There are no charges associated with
    these logs and this bucket cannot be modified or deleted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`_Default` log sink can be disabled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`_Required` log bucket and the `_Default` log bucket. The process of writing
    logs to user-managed log sinks can also be characterized as **Log Exports** (if
    the intent is to export for external processing) or **Log Retention** (if the
    intent is to export to retain logs for a longer period from a compliance perspective).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`_Default` log bucket. In other words, logs that qualify for the `_Required`
    log bucket can never be excluded. If any of the log exclusion filters match with
    entries that qualify for the `_Default` log bucket, then the entries will be excluded
    and never be saved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip – What are log buckets?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Log buckets are a form of object storage in Google Cloud projects that are
    used by Cloud Logging to store and organize logs data. All logs generated in the
    project are stored in these logs'' buckets. Cloud Logging automatically creates
    two buckets in each project: `_Required` and `_Default`. `_Required` represents
    an audit bucket, which has a 400-day retention period, while `_Default` represents
    the *everything else* bucket, which has a 30-day retention period. In addition,
    a user can create custom logging buckets, also known as user-managed log sinks.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The log bucket per project can be viewed via the **Logs Storage UI** in Cloud
    Logging. Additional actions such as creating a user-defined log bucket and a usage
    alert can also be initiated from the Logs Storage UI.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following diagram illustrates how logs are ingested from multiple sources
    via the Cloud Logging API and, subsequently, routed by Logs Router to possible
    destinations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.11 – Illustrating logs ingesting and logs routing'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.11 – Illustrating logs ingesting and logs routing
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three steps we must follow to export logs:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a sink.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a filter that represents the criteria to identify logs to export.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a destination – Cloud Storage Bucket, BigQuery, or Pub/Sub topics.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: IAM roles to Create/Modify/View a Sink
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The Owner or Logging/Logs Configuration Writer role is required to create or
    modify a sink. The Viewer or Logging/Logs Viewer role is required to view existing
    sinks. The Project Editor role does not have access to create/edit sinks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To summarize, logs can originate from multiple sources, such as on-premises,
    Google Cloud, or a third-party cloud service. These logs are injected into Cloud
    Logging through the Cloud Logging API, which are then sent to Logs Router. Logs
    Router, which is based on configured filters, will route the logs to logged sinks
    (the `_Required` or `_Default` log bucket). Additionally, a copy of the logs can
    be sent to user-managed sinks based on the configured filter criteria, where the
    destination can either be Cloud Storage, BigQuery, or Pub/Sub. Log export can
    be used for multiple purposes, such as long-term retention for compliance reasons
    (using Cloud Storage), Big Data analysis (using BigQuery), or to stream to other
    applications (using Pub/Sub). If these logs are sent to the Pub/Sub messaging
    service, then they can be exported outside Google Cloud to third-party tools such
    as Splunk, Elastic Stack, or SumoLogic. It is important to note that configured
    log sinks for export will only capture new logs, since the export was created
    but does not capture the previous logs or backfill.
  prefs: []
  type: TYPE_NORMAL
- en: How to export logs across folders/organizations
  prefs: []
  type: TYPE_NORMAL
- en: Logs can be exported from all projects inside a specific folder or organization.
    This can currently only be done through the command line using the gcloud logging
    sink's `create` command. Apart from the sink's name, destination, and log filter,
    the command should include the `--include-children` flag and either the `--folder`
    or `--organization` attribute, along with its respective values.
  prefs: []
  type: TYPE_NORMAL
- en: This completes this subsection on logs ingestion, routing, and exporting. The
    following subsection summarizes log characteristics across log buckets in the
    form of a table for ease of understanding.
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing log characteristics across log buckets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Each log type is destined to a specific Cloud Logging bucket. In addition,
    every log type has specific characteristics in terms of the minimum IAM roles
    required to access the logs, the default retention period, and the ability to
    configure a custom retention period. The following table details the respective
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15587_10_Table_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: All other logs
  prefs: []
  type: TYPE_NORMAL
- en: This refers to either user logs generated by applications through a Logging
    agent or platform logs generated by GCP services or VPC Flow Logs or Firewall
    Logs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the preceding table, it is important to note the following:'
  prefs: []
  type: TYPE_NORMAL
- en: System event logs are system initiated, whereas admin activity, data access,
    and access transparency logs are user initiated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Admin activity and system event logs record the changes in the configuration
    of resources, whereas data access logs record the changes that were made inside
    the record.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Admin activity, system event, and access transparency logs are always enabled.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This completes our overview on logs ingestion. The next topic focuses on the
    **Logs Explorer** UI, through which users can explore ingested logs.
  prefs: []
  type: TYPE_NORMAL
- en: Logs Explorer UI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Logs Explorer UI** is the centralized way to view logs that have been ingested
    into Cloud Logging via the Cloud Logging API, and ultimately routed via Cloud
    Router to either Cloud Logging buckets or user-managed sinks. The UI allows us
    to filter logs by writing advanced search queries, visualize the time series data
    by configuring time windows, and perform critical actions to create log-based
    metrics or create users. The UI consists of multiple options and sections, as
    shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.12 – Logs Explorer UI'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.12 – Logs Explorer UI
  prefs: []
  type: TYPE_NORMAL
- en: 'To filter Cloud Audit Logs through the Logs Explorer UI, select the following
    options for the **Log Name** field:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cloudaudit.googleapis.com%2Factivity`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cloudaudit.googleapis.com%2Fdata_access`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cloudaudit.googleapis.com%2Fsystem_event`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a look at some key important information with respect to navigating
    the options in the Logs Explorer UI.
  prefs: []
  type: TYPE_NORMAL
- en: Query builder
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This section constructs queries to filter logs. Queries can be expressed in
    query builder language by choosing an appropriate combination of field and value,
    as shown in the following screenshot. The user can provide input in two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: By choosing options from the available drop-down menus with respect to **Resource**,
    **Log Name**, and **Severity**. This is the basic query interface.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By choosing fields from the **Log Fields** section, starting by either selecting
    the **Resource** type or the **Severity** type. This is the advanced query interface:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.13 – Query builder section under Logs Explorer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.13 – Query builder section under Logs Explorer
  prefs: []
  type: TYPE_NORMAL
- en: Query results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This section displays the results that match the filter criteria defined within
    query builder. If there is a match, the results are displayed in one or more rows.
    Each row represents a log entry, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.14 – Query results section'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.14 – Query results section
  prefs: []
  type: TYPE_NORMAL
- en: Log entries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Each query result that''s returned is a log entry that''s displayed with a
    timestamp and summary text information. When expanded, the log entry displays
    further details in a JSON payload format. The JSON payload has multiple fields
    and can be elaborated on using the **Expand nested fields** option. Additionally,
    the user can copy the payload to a clipboard or share the specific payload by
    copying the shareable link, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.15 – Viewing the JSON payload for a log entry'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.15 – Viewing the JSON payload for a log entry
  prefs: []
  type: TYPE_NORMAL
- en: Payload-specific actions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are multiple options that perform actions on a specific payload on a
    specific field, as shown in the following screenshot. These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Show matching entries**: Adds the selected key-value pair from the JSON payload
    to the existing filter criteria and shows matching entries within the configured
    time window.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hide matching entries**: Adds the selected key-value pair from the JSON payload
    to the existing filter criteria in a negation form and removes the matching entries
    from user display, within the configured time window.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Add field to summary line**: Adds the selected key to the summary section:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.16 – Possible payload-specific actions for a specific field'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.16 – Possible payload-specific actions for a specific field
  prefs: []
  type: TYPE_NORMAL
- en: Page layout
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This option allows users to configure the page layout and optionally include
    **Log Fields** and/or a **Histogram**. **Query builder** and **Query results**
    are mandatory sections and cannot be excluded:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.17 – Options under the PAGE LAYOUT section'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.17 – Options under the PAGE LAYOUT section
  prefs: []
  type: TYPE_NORMAL
- en: Actions (to perform on a query filter)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Actions allows user to operate on the potential results from the query filter
    definition. This includes **Create Metrics**, **Download Logs**, and **Create
    Sinks**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.18 – Possible actions you can perform on a query filter'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.18 – Possible actions you can perform on a query filter
  prefs: []
  type: TYPE_NORMAL
- en: This completes this section on Logs Explorer and all the possible UI options
    for filtering and analyzing logs. The next section provides an overview of *logs-based
    metrics*.
  prefs: []
  type: TYPE_NORMAL
- en: Logs-based metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Logs-based metrics** are Cloud Monitoring metrics that are created based
    on the content of the log entries. They can be extracted from both included and
    excluded logs. As matching log entries are found, the information that''s tied
    to the metrics is built over time. This forms the required time series data that
    is critical to metrics. Logs-based metrics are used in creating Cloud Monitoring
    charts and can also be added to Cloud Monitoring dashboards.'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: To use logs-based metrics, a Google Cloud project is required with billing enabled.
    In addition, logs-based metrics are recorded for matching log entries, once the
    metric has been created. Metrics are not backfilled for log entries that are already
    in Cloud Logging.
  prefs: []
  type: TYPE_NORMAL
- en: 'Logs-based metrics can be classified as either of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: System (logs-based) metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-defined (logs-based) metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these logs-based metrics will be covered in the upcoming subsections.
  prefs: []
  type: TYPE_NORMAL
- en: System (logs-based) metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**System (logs-based) metrics** are out-of-the-box, predefined metrics from
    Google and are very specific to the current project. These metrics record the
    number of events that occur within a specific period. A list of available system
    (logs-based) metrics can be found under the **Logs-based Metrics** UI in the **Logging**
    section of Cloud Operations. Examples include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**byte_count**: Represents the total number of received bytes in log entries'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**excluded_byte_count**: Represents the total number of excluded bytes from
    log entries'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The user can create an alert from a predefined metric or view the details of
    the metric, along with its current values, in Metrics explorer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.19 – System (logs-based) metrics and their qualifying actions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.19 – System (logs-based) metrics and their qualifying actions
  prefs: []
  type: TYPE_NORMAL
- en: The next section provides an overview of user-defined metrics.
  prefs: []
  type: TYPE_NORMAL
- en: User-defined (logs-based) metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**User-defined (logs-based) metrics**, as the name suggests, are defined by
    the user and are specific to the project where the user configures these metrics.
    These metrics can either of the **Counter** or **Distribution** type:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Counter**: Counts the number of log entries that match on a query'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distribution**: Accumulates numeric data from log entries that match on a
    query'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Users can create a user-defined metric either from **Logs-based Metrics UI**
    via the **Create Metric** action or the **Logs Explorer UI** via the actions menu
    above the query results. Once the user initiates these actions, they get to choose
    the type of metric in the Metric Editor panel; that is, **Counter** or **Distribution**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, the user will have to configure fields such as the metric''s name,
    description, and any optional labels and units. For a `s`, `ms`, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.20 – Creating a logs-based metric'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.20 – Creating a logs-based metric
  prefs: []
  type: TYPE_NORMAL
- en: More details on creating a distribution metric can be found at [https://cloud.google.com/logging/docs/logs-based-metrics/distribution-metrics](https://cloud.google.com/logging/docs/logs-based-metrics/distribution-metrics).
  prefs: []
  type: TYPE_NORMAL
- en: Access control for logs-based metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following table displays the critical IAM roles required, along with their
    minimal permissions (in accordance with the principle of least privilege), to
    access or perform actions related to logs-based metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15587_10_Table_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The following section will conclude this section on Cloud Logging by exploring
    the available network-based log types on Google Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Network-based log types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two network-based log types that primarily capture logs related to
    network interactions. These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: VPC Flow Logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Firewall logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's look at them in detail.
  prefs: []
  type: TYPE_NORMAL
- en: VPC Flow Logs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**VPC Flow Logs** capture real-time network activity (incoming/outgoing) against
    VPC resources on an enabled subnet. Flow logs capture activity specific to the
    TCP/UDP protocols and are enabled at a VPC subnet level. Flow logs generate a
    large amount of chargeable log files, but they don''t capture 100% of traffic;
    instead, traffic is sampled at 1 out of 10 packets and cannot be adjusted. Flow
    logs are used for Network Monitoring – to understand traffic growth from a forecasting
    capacity and for forensics – to evaluate network traffic (in/out) in terms of
    traffic source. Flow logs can be exported for analysis using BigQuery. In the
    case of a Shared VPC – where multiple service projects connect to a common VPC
    – flow logs flow into the host project, not the service projects.'
  prefs: []
  type: TYPE_NORMAL
- en: Firewall logs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Firewall logs** capture the effects of a specific firewall rule in terms
    of the traffic that''s allowed or denied by that firewall rule. Similar to VPC
    Flow Logs, firewall logs capture TCP/UDP traffic only and are used for auditing,
    verifying, and analyzing the effect of the configured rules. Firewall logs can
    be configured for an individual firewall rule. Firewall rules are applied for
    the entire VPC and cannot be applied at a specific subnet level like flow logs.
    Firewall logs attempt to capture every firewall connection attempt on a best effort
    basis. Firewall logs can also be exported to BigQuery for further analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Every VPC has a set of hidden implied pre-configured rules, with the lowest
    priority being `65535`. Firewall rules can have a priority between `0` and `65535`
    (`0` implies highest, while `65535` implies lowest). These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`deny all ingress`: By default, this denies all incoming traffic to the VPC.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`allow all egress`: By default, this allows all outgoing traffic from the VPC.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, firewall logs cannot be enabled for the hidden rules. So, to capture
    the incoming traffic that is being denied or the outgoing traffic that is being
    allowed, it is recommended to explicitly configure a firewall rule for the denied/allowed
    traffic with an appropriate priority and enable firewall logs on that rule.
  prefs: []
  type: TYPE_NORMAL
- en: This completes this subsection on network-based log types, where we introduced
    VPC Flow Logs and firewall logs.
  prefs: []
  type: TYPE_NORMAL
- en: Logging agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `fluentd` – an open source log or data collector. The Logging agent can
    be installed on unmanaged GCE VMs or AWS EC2 VMs. Other Google Compute services
    such as App Engine, Cloud Run, and Cloud Functions have built-in support for logging
    and do not require you to explicitly install the Logging agent. GKE also has built-in
    support for logging and can be enabled for new or existing clusters by *Cloud
    Operations for GKE*, an integrated monitoring and logging solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'To configure the Logging agent, you must configure an additional configuration
    file, but a single configuration file acts as a catch all for capturing multiple
    types of logs, including OS logs and third-party application logs such as Apache,
    MySQL, Nginx, RabbitMQ, and so on. However, there are scenarios where the configuration
    file of the agent needs to be modified so that we can modify the logs. These are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: When reformatting log fields, either the order or combine multiple fields into
    one
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When removing any **Personally Identifiable Information** (**PII**) or sensitive
    data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When modifying records with `fluentd` plugins such as `filter_record_transformer`,
    a plugin for adding/modifying/deleting fields from logs before they're sent to
    Cloud Logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Conceptually, the following is the process of installing/configuring an agent
    on a GCE VM:'
  prefs: []
  type: TYPE_NORMAL
- en: Add the agent's package repository via a provided script that detects the Linux
    distribution being run on the VM and configures the repository accordingly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install the Logging agent and install the `google-fluentd-catch-all-config`
    agent for unstructured logging and the `google-fluentd-catch-all-config-structured`
    agent for structured logging.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Restart the agent for the installed agents to come into effect.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The step-by-step process of installing a Logging agent on a single VM/GCE VM/AWS
    EC2 instance can be found at [https://cloud.google.com/logging/docs/agent/installation](https://cloud.google.com/logging/docs/agent/installation).
  prefs: []
  type: TYPE_NORMAL
- en: This completes our high-level overview of logging agents. Subsequently, this
    also completes the section on Cloud Logging, where we looked at features such
    as audit log types, logs ingestion, the Logs Explorer UI, logs-based metrics,
    and access controls. The next section deep dives into *Cloud Debugger*, a GCP
    construct from Cloud Operations that can potentially inspect a production application
    by taking a snapshot of it, without stopping or slowing down.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Debugger
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Cloud Debugger** allows us to inspect the state of a running application
    in real time. Cloud Debugger doesn''t require the application to be stopped during
    this process and doesn''t slow it down, either. Users can capture the call stack
    and variables at any location in the source code. This essentially allows the
    user to analyze the application state, especially in complex situations, without
    adding any additional log statements.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition, Cloud Debugger can be used for production environments and is not
    limited to development or test environments. When Cloud Debugger captures the
    application state, it adds request latency that is less than 10 ms, which, practically,
    is not noticeable by users.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Debugger is supported on applications running in GCP such as App Engine,
    Compute Engineer, GKE, Cloud Run, and so on, as well as those written in a number
    of languages, including Java, Python, Go, Node.js, Ruby, PHP, and .NET. Cloud
    Debugger needs access to the application code and supports reading the code from
    App Engine, Google Cloud source repositories, or third-party repositories such
    as GitHub, Bitbucket, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Cloud Debugger
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Enabling/setting up Cloud Debugger involves the following fundamental steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Enable the Cloud Debugger API as a one-time setup per project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide appropriate access so that the GCP service where Cloud Debugger will
    run has permission to upload telemetry data or call Cloud Debugger.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: App Engine and Cloud Run must already be configured for Cloud Debugger.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A service account with the Cloud Debugger Agent role is required for applications
    running in Compute Engine, GKW, or external systems.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If the application is running inside a Compute Engine VM or cluster nodes with
    a default service account, then the following access scopes should be added to
    the VMs or cluster nodes: [https://www.googleapis.com/auth/cloud-platform](https://www.googleapis.com/auth/cloud-platform)
    and [https://www.googleapis.com/auth/cloud_debugger](https://www.googleapis.com/auth/cloud_debugger).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the source code location. If there is no access to the source code, a
    debug snapshot can be taken that captures the call stack and local variables.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If there is access to the source code, then App Engine standard will select
    the source code automatically. App Engine flex, GCE, GKE, and Cloud Run can automatically
    select the source code based on the configuration file in the application root
    folder; that is, `source-context.json`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Alternatively, select a source code location from the possible options, including
    local files, Cloud Source Repositories, GitHub, Bitbucket, and GitLab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To enable Cloud Debugger from application code, you must follow a set of instructions
    that are specific to the language that the application has been written in. The
    following is an example snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we've set up Cloud Debugger, let's learn how to use it.
  prefs: []
  type: TYPE_NORMAL
- en: Using Cloud Debugger
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using Cloud Debugger involves learning about the functionality of debug snapshots,
    debug logpoints, and accessing the logs panel.
  prefs: []
  type: TYPE_NORMAL
- en: Debug snapshots
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Snapshots** capture local variables and the call stack at a specific location
    in the application''s source code. The fundamental step prior to taking a snapshot
    is to set up a breakpoint. It takes about 40 seconds for a breakpoint to come
    into effect. Cloud Debugger breakpoints do not stop code execution. A non-intrusive
    snapshot is taken when the flow of execution passes the debug point. Additional
    conditions can be added so that a snapshot is only taken if a data condition passes.
    The captured snapshot will contain details of the local variables and the state
    of the call stack.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, the breakpoint was set to line 39 against a specific
    file. The breakpoint has a qualifying condition, and a snapshot is taken if its
    condition is met. The details of the variables are displayed in the **Variables**
    section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.21 – Taking a debug snapshot in Cloud Debugger'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.21 – Taking a debug snapshot in Cloud Debugger
  prefs: []
  type: TYPE_NORMAL
- en: Optionally, expressions can also be included while configuring a snapshot. Expressions
    can be used as special variables to evaluate values when a snapshot is taken.
    These are especially useful in scenarios where the values being captured by the
    expressions are not usually captured by local variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, we can see that multiple expressions are defined
    while configuring a snapshot and are captured while taking a snapshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.22 – Defining expressions while configuring a snapshot'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.22 – Defining expressions while configuring a snapshot
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some key pointers related to snapshots:'
  prefs: []
  type: TYPE_NORMAL
- en: A snapshot is taken only once. To capture another snapshot of the application
    data for the same location in the code, the user needs to manually retake the
    snapshot through the camera icon in the snapshot panel.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A snapshot location can be manually removed by clicking the **x** icon on the
    breakpoint.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Debugger generates a new URL for every snapshot that's been taken. It
    is valid for 30 days from the time it was taken. This URL can be shared with other
    members of the project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next subsection provides an overview of debug logpoints and how they can
    be injected into a running application.
  prefs: []
  type: TYPE_NORMAL
- en: Debug logpoints
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It's a common practice to add log messages when you're trying to solve complex
    problems. In such scenarios, developers often provide code changes to production
    that essentially include additional log statements that help with analysis. If
    the problem is complex, this process needs to be repeated multiple times, which
    means the production code needs to go through multiple changes to include log
    statements. Cloud Debugger steps away from the traditional approach to debugging
    an application and instead provides a dynamic way to add log messages using **debug
    logpoints**.
  prefs: []
  type: TYPE_NORMAL
- en: Debug logpoints can inject logs into a running application without stopping,
    editing, or restarting. A logpoint is added at a location of choice, as per the
    developer's wishes. When that particular portion of code is executed, Cloud Debugger
    logs a message, and the log message is sent to the appropriate service that is
    hosting the application. So, if the application is hosted in App Engine, then
    the log message can be found in the logs tied to App Engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, a logpoint has been added with a condition, with
    the message log level set to **Info**. The concept of specifying a condition along
    with a logpoint is called a *logpoint condition*. This is an expression in the
    application language that must evaluate to true for the logpoint to be logged.
    Logpoint conditions are evaluated each time that specific line is executed, if
    the logpoint is valid:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.23 – Adding a debug logpoint via Cloud Debugger'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.23 – Adding a debug logpoint via Cloud Debugger
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some key pointers related to logpoints:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A logpoint can be created even if direct access to the source code is not available.
    A logpoint can be created by specifying the name of the file, the line number
    to create the logpoint, the log level, an optional condition, and an appropriate
    message, as shown here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.24 – Configuring a logpoint without access to the source code'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.24 – Configuring a logpoint without access to the source code
  prefs: []
  type: TYPE_NORMAL
- en: Logpoints becomes inactive after 24 hours and post that, messages with respect
    to those logpoints will not be evaluated or logged.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logpoints are automatically deleted after 30 days from the time of creation.
    Optionally, users can manually delete logpoints at will.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next subsection illustrates the usage and options available in the *Logs
    panel*.
  prefs: []
  type: TYPE_NORMAL
- en: Logs panel
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Cloud Debugger includes an in-page Logs panel that displays the running logs
    of the current application being inspected. This allows the developer to view
    logs next to the respective code. Users can use the logs panel to perform search
    variations, including text-based search, and can filter by either log level, request,
    or file. The results are highlighted in the context or are shown in the logs viewer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.25 – Logs panel for viewing logs while debugging in Cloud Debugger'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.25 – Logs panel for viewing logs while debugging in Cloud Debugger
  prefs: []
  type: TYPE_NORMAL
- en: The upcoming subsection provides an overview of the access control that's required
    for Cloud Debugger.
  prefs: []
  type: TYPE_NORMAL
- en: Access control for Cloud Debugger
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following table displays the critical IAM roles required, along with their
    minimal permissions (in accordance with the principle of least privilege), to
    access or perform actions related to Cloud Debugger:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15587_10_Table_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Tip – How to hide sensitive data while using debugging
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Debugger has a feature in Pre-GA where sensitive data can be hidden through
    a configuration file. This configuration file consists of a list of rules that
    are either expressed as `blacklist` or `blacklist_exception` (to specify an inverse
    pattern). If the criteria match, then data is hidden and is reported by the debugger
    as `blocked by admin`. This feature is currently only supported for applications
    written in Java.
  prefs: []
  type: TYPE_NORMAL
- en: This completes this section on Cloud Debugger, where we learned how to set up
    Cloud Debugger, utilize debug logpoints to add log messages, and create snapshots
    to capture the call stack and its local values. We looked at the options that
    are available in the Logs panel and looked at the required access controls we
    can use to perform actions related to Cloud Debugger. In the next section, we
    will look at *Cloud Trace*, another GCP service that is part of Cloud Operations.
    Cloud Trace represents a distributed tracing system that collects latency data
    from applications to identify bottlenecks.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Trace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **trace** is a collection of spans. A **span** is an object that wraps latency-specific
    metrics and other contextual information around a unit of work in an application.
    **Cloud Trace** is a distributed tracing system that captures latency data from
    an application, tracks the request's propagation, retrieves real-time performance
    insights, and displays the results in Google Cloud Console. This latency information
    can be either for a single request or can be aggregated for the entire application.
    This information helps us identify performance bottlenecks.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, Cloud Trace can automatically analyze application traces that
    might reflect recent changes to the application's performance, identify degradations
    from latency reports, capture traces from containers, and create alerts as needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloud Trace''s language-specific SDKs are available for Java, Node.js, Ruby,
    and Go. These SDKs can analyze projects running on VMs. It is not necessary for
    these VMs to only be running on Google Cloud. Apart from the SDK, the Trace API can
    be used to submit and retrieve trace data from any source. A Zipkin collector is
    available, which allows Zipkin tracers to submit data to Cloud Trace. Additionally,
    Cloud Trace can generate trace information using OpenCensus or OpenTelemetry instrumentation.
    Cloud Trace consists of three main sections: Trace Overview, Trace List, and Analysis
    Reports. Let''s look at them in detail.'
  prefs: []
  type: TYPE_NORMAL
- en: Trace Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The **Trace Overview** page provides a summary of latency data that''s spread
    across various informational panes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Insights**: Displays a list of performance insights, if applicable'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recent Traces**: Highlights the most recent traces for a project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frequent URIs**: Displays a list of URIs along with their average latency
    for the most frequent requests to the application in the last 7 days'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frequent RPCs**: Displays a list of RPCs along with their average latency
    for the most frequent RPC calls made in the last 7 days'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chargeable trace spans**: Summarizes the number of trace spans that have
    been created and received by Cloud Trace for the current and previous months:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.26 –Chargeable trace spans from the Trace Overview page'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_26.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.26 –Chargeable trace spans from the Trace Overview page
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection provides an overview of the **Trace List** window, which
    can be used to examine traces in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Trace List
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The **Trace List** window allows users to find, filter, and examine individual
    traces in detail. These traces are displayed in a heatmap, and a specific section
    of the heatmap can be selected if you wish to view these traces within that specific
    slice of the window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.27 – List of all the traces filtered by the POST method in the
    last 30 days'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_27.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.27 – List of all the traces filtered by the POST method in the last
    30 days
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on the individual trace (represented by a circle) provides details
    about the trace. It is represented by a waterfall graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.28 – Waterfall graph of an individual trace'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_28.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.28 – Waterfall graph of an individual trace
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection provides an overview of trace analysis reports with respect
    to request latency.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis Reports
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Analysis Reports shows an overall view of the latency for all the requests or
    a subset of requests with respect to the application. These reports are categorized
    either as daily reports or custom analysis reports.
  prefs: []
  type: TYPE_NORMAL
- en: Daily reports
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cloud Trace creates a daily report automatically for the top three endpoints.
    Cloud Trace compares the previous days' performance with the performance from
    the same day of the previous week. The content of the report cannot be controlled
    by the user.
  prefs: []
  type: TYPE_NORMAL
- en: Custom analysis reports
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The user can create a custom analysis report, where the content of the report
    can be controlled from the aspect of which traces can be included. The report
    can include latency data either in histogram format or table format, with links
    to sample traces. The report can optionally include a bottleneck pane that lists
    **Remote Procedure Calls** (**RPCs**), which are significant contributors to latency.
  prefs: []
  type: TYPE_NORMAL
- en: Condition to auto-generate or manually create a trace report
  prefs: []
  type: TYPE_NORMAL
- en: For the daily report to auto-generate or for a user to create a custom report
    within a specific time range, it is mandatory that at least 100 traces are available
    in that time period. Otherwise, a trace report will not be generated.
  prefs: []
  type: TYPE_NORMAL
- en: This completes this section on Cloud Trace, a GCP construct for representing
    a distributed tracing system, collecting latency data from applications, and identifying
    performance bottlenecks. The next section focuses on Cloud Profiler, a service
    that is part of Cloud Operations. Cloud Profiler is a low-impact production profiling
    system that presents call hierarchy and resource consumption through an interactive
    flame graph.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Profiler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud Profiler provides low-impact continuous profiling to help users understand
    the performance of a production system. It provides insights into information
    such as CPU usage, memory consumption, and so on. Cloud Profiler allows developers
    to analyze applications running either in Google Cloud, other cloud providers,
    or on-premises.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Profiler uses statistical techniques and extremely low-impact instrumentation
    to provide a complete picture of an application's performance, without slowing
    it down. Cloud Profiler runs across all production application instances, presents
    a call hierarchy, and explains the resource consumption of the relevant function
    in an interactive flame graph. This information is critical for developers to
    understand which paths consume the most resources and illustrates the different
    ways in which the code is actually called. The supported programming languages
    include Java, Go, Node.js, and Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloud Profiler supports the following types of profiles:'
  prefs: []
  type: TYPE_NORMAL
- en: '**CPU time**: The time the CPU spent executing a block of code. This doesn''t
    include the time the CPU was waiting or processing instructions for something
    else.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heap**: Heap or heap usage is the amount of memory that''s allocated to the
    program''s heap when the profile is collected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Allocated heap**: Allocated heap or heap allocation is the total amount of
    memory that was allocated in the program''s heap, including memory that has been
    freed and is no longer in use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Contention**: Contention provides information about the threads that are
    stuck and the ones waiting for other threads. Understanding contention behavior
    is critical to designing code and provides information for performance tuning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Threads**: Information related to threads gives insights into the threads
    that are created but never actually used. This forms the basis for identifying
    leaked threads, where the number of threads keeps increasing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Wall time**: Wall time is the time it takes to run a block of code, including
    its wait time. The wall time for a block of code can never be less than the CPU
    time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following screenshot summarizes the supported profile types by language:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.29 – Supported profile types by language'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_29.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.29 – Supported profile types by language
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the Profiler interface, which depicts a sample
    interactive flame graph for the **CPU time** profile type. The profile data is
    retained for 30 days and the profile information can be downloaded for long-term
    storage:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.30 – Interactive flame graph with the profile type set to CPU time'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_30.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.30 – Interactive flame graph with the profile type set to CPU time
  prefs: []
  type: TYPE_NORMAL
- en: The upcoming subsection explains the access controls that are required to perform
    actions with respect to Cloud Profiler.
  prefs: []
  type: TYPE_NORMAL
- en: Access control for Cloud Profiler
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following table displays the critical IAM roles required, along with their
    minimal permissions (in accordance with the principle of least privilege), to
    access or perform actions related to Cloud Profiler:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15587_10_Table_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This completes this section on Cloud Profiler, where we looked at the supported
    profile types and learned how to use an interactive flame graph.
  prefs: []
  type: TYPE_NORMAL
- en: Binding SRE and Cloud Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B15587_02_Final_ASB_ePub.xhtml#_idTextAnchor038), *SRE Technical
    Practices – Deep Dive*, introduced SRE technical practices such as SLAs, SLOs,
    SLIs, and Error Budgets. To summarize, this chapter established a relationship
    between these practices and tied them directly to the reliability of the service.
    To ensure that a service meets its SLAs, the service needs to be reliable. SRE
    recommends using SLOs to measure the reliability of the service. SLOs require
    SLIs to evaluate the service''s reliability. If these SLIs are not met, then the
    SLOs will miss their targets. This will eventually burn the Error Budget, which
    is a measure that calculates the acceptable level of unavailability or unreliability.
    [*Chapter 3*](B15587_03_Final_ASB_ePub.xhtml#_idTextAnchor064), *Understanding
    Monitoring and Alerting to Target Reliability*, introduced concepts related to
    monitoring, alerting, logging, and tracing and established how these are critical
    to tracking the reliability of the service. However, both these chapters were
    conceptual in nature.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter''s focus is Cloud Operations. So far, we''ve described how Google
    Cloud captures monitoring metrics, logging information, and traces and allows
    us to debug applications or services. Additionally, Cloud Operations has an option
    called SLO monitoring. This option allows you to define and track the SLO of a
    service. This option currently supports three service types for auto-ingestion:
    Anthos Service Mesh, Istio on GKE, and App Engine. However, this option also supports
    user-defined microservices. The next subsection deep dives into SLO monitoring.'
  prefs: []
  type: TYPE_NORMAL
- en: SLO monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Given that SLOs are measured using SLIs and SLOs are defined as quantifiable
    measures of service reliability that are measured over time, there are three specific
    steps in defining an SLO via SLO monitoring. These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting a **SLI**
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Defining SLI details
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Setting a **SLO**
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's look at these steps in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Setting an SLI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is the first step and has two specific goals: choosing a metric as an
    SLI and selecting a method of evaluation for measuring the chosen metric.'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a metric
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SLO monitoring allows you to choose either **Availability** or **Latency** as
    an out-of-the-box SLI for a service that's been configured via Anthos Service
    Mesh, Istio on GKE, and App Engine. These options are not available for microservices
    on GKE that haven't been configured through the preceding options. These are also
    known as custom services. However, irrespective of how the service is configured,
    you have the option to choose **Other**. Here, the user can pick the metric of
    choice to track as the SLI.
  prefs: []
  type: TYPE_NORMAL
- en: Request-based or windows-based
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are two methods of evaluation to choose from that will affect how compliance
    against SLIs is measured. These are request-based and windows-based. The request-based
    option counts individual events and evaluates how a service performs over the
    compliance period, irrespective of how load is distributed. The windows-based
    option, on the other hand, measures performance in terms of time (good minutes
    versus bad minutes), irrespective of how load is distributed.
  prefs: []
  type: TYPE_NORMAL
- en: Defining SLI details
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is the second step and provides options for the user to choose a performance
    metric. The user can either use the predefined metrics in Cloud Monitoring or
    any user-defined metrics that can be created from logs (through logs-based metrics).
    Once a metric has been chosen, the performance criteria for the metric need to
    be defined. The performance criteria for metrics related to services on Anthos
    Service Mesh, Istio on GKE, and App Engine are predefined. However, for custom
    services, this needs to be manually defined by the user by using two of the three
    filter options – **Good**, **Bad**, and **Total**.
  prefs: []
  type: TYPE_NORMAL
- en: Setting an SLO
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is the third and final step and has two specific goals: setting the compliance
    period and setting the performance goal.'
  prefs: []
  type: TYPE_NORMAL
- en: Compliance period
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The compliance period option allows you to set a time period to evaluate the
    SLO. There are two possible choices:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Calendar**: Performance is measured from the start of the period, with a
    hard reset at the start of every new period. The available options for period
    length are Calendar day, Calendar week, Calendar fortnight, and Calendar month.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rolling**: Performance is measured for a fixed time period; say, the last
    10 days. The user can specify the fixed time period in days.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let's look at setting the performance goal.
  prefs: []
  type: TYPE_NORMAL
- en: Performance goal
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The performance goal indicates the goal that's been set as a ratio of *good
    service* to *demanded service* over the compliance period. This goal can be refined
    as more information is known about the system's behavior.
  prefs: []
  type: TYPE_NORMAL
- en: This completes our overview of SLO monitoring, which we can use to define an
    SLO to measure the reliability of a service. The next subsection provides a hands-on
    demonstration of how SLO monitoring can be configured against a GKE service (that
    we previously created in [*Chapter 8*](B15587_08_Final_ASB_TD_ePub.xhtml#_idTextAnchor182),
    *Understanding GKE Essentials to Deploy Containerized Applications*).
  prefs: []
  type: TYPE_NORMAL
- en: Hands-on lab – tracking service reliability using SLO monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SLO monitoring allows us to link the SRE technical practices with the practical
    options available in Google Cloud. These help us monitor the reliability of the
    service and alert the on-call engineer if the service misses the reliability threshold.
  prefs: []
  type: TYPE_NORMAL
- en: 'This subsection is a hands-on lab that will show you how to use the SLO monitoring
    option from Cloud Monitoring. The SLO monitoring option tracks service reliability
    by defining an SLO. In this lab, we will use `hello-world-service` from the `my-first-cluster`
    GKE cluster, which was created as part of [*Chapter 8*](B15587_08_Final_ASB_TD_ePub.xhtml#_idTextAnchor182),
    *Understanding GKE Essentials to Deploy Containerized Applications*. This lab
    has three main goals:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining an SLO for a service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating an SLO burn rate alert policy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verifying SLO monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a look at these goals in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Defining a SLO for a service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Follow these steps to define a SLO for `hello-world-service`:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the `hello-world-service` section from the `my-first-cluster` cluster,
    as shown in the following screenshot. Set the display name to `hello-world-service`.
    The system will create the service to be monitored and will navigate the user
    to the service overview dashboard:![Figure 10.31 – Defining a custom service by
    selecting one
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_31.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.31 – Defining a custom service by selecting one
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select the **Create SLO** action to define an SLO. This action will open a pop-up
    window, as shown in the following screenshot. Note that, as discussed in [*Chapter
    2*](B15587_02_Final_ASB_ePub.xhtml#_idTextAnchor038), *SRE Technical Practices
    – Deep Dive*, an SLO requires an SLI. So, to define an SLO, we must first choose
    the SLI metric and then define it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Given that the service being used for this lab is not part of Anthos Service
    Mesh, Istio on GKE, or App Engine, the only option available is to choose **Other**.
    Here, the user can configure a metric of choice to measure the performance of
    the service. In addition, set the method of evaluation to **Request-based**:![Figure
    10.32 – Setting an SLI as part of SLO monitoring
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_32.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.32 – Setting an SLI as part of SLO monitoring
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To define the SLI's details, select a performance metric. In this case, we will
    select the `kubernetes.io/container/restart_count` metric. Set the filters to
    **Total** and **Bad**, as shown here:![Figure 10.33 – Defining SLI details as
    part of SLO monitoring
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_33.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.33 – Defining SLI details as part of SLO monitoring
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select a compliance period; that is, either `90`%, as shown here:![Figure 10.34
    – Setting an SLO as part of SLO monitoring
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_34.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.34 – Setting an SLO as part of SLO monitoring
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Review the configuration and save it by providing an appropriate display name,
    such as `90% - Restart Count - Calendar Day`, as shown here:![Figure 10.35 – Reviewing
    and saving the SLO as part of SLO monitoring
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_35.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.35 – Reviewing and saving the SLO as part of SLO monitoring
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once saved, the SLO – `90% - Restart Count - Calendar Day` – will be created
    under the `hello-world-service` service, as shown in the following screenshot.
    At the moment, the error budget is **100%** since none of the containers were
    restarted:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.36 – SLO created for a service as part of SLO monitoring'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_36.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.36 – SLO created for a service as part of SLO monitoring
  prefs: []
  type: TYPE_NORMAL
- en: With this, we've learned the steps we need to take to define an SLO for a service.
    In the next topic, we'll explore the steps we need to create an SLO burn rate
    alert policy.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a SLO burn rate alert policy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The concept of alerting and notification channels from Cloud Monitoring (discussed
    earlier in this chapter) is used to create an alert. Before we look at the steps
    for this, let''s recap on the critical jargon that was discussed in [*Chapter
    3*](B15587_03_Final_ASB_ePub.xhtml#_idTextAnchor064), *Understanding Monitoring
    and Alerting to Target Reliability*. We must configure these elements while defining
    an alert through Cloud Monitoring:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lookback duration** refers to how far you must go back in time to retrieve
    monitoring data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fast-burn alert** refers to using shorter lookback durations that help with
    quickly detecting problems. However, this will lead to more frequent alerting
    and, potentially, false alarms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Slow-burn alert** refers to using a longer lookback duration to ensure that
    a problem exists for a longer duration and avoids false alarms. However, the downside
    is that the alert is fired after a longer duration, even though the problem has
    a current negative impact on the service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Follow these steps to set up an alert for when the error budget for the SLO
    drops beyond a certain burn rate within a specified period of time:'
  prefs: []
  type: TYPE_NORMAL
- en: Click the `1` minute(s) and `10` minute(s). The following is our configuration
    for a fast-burn alert:![Figure 10.37 – Setting an SLO alert condition
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_37.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.37 – Setting an SLO alert condition
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select a notification channel of choice (that has already been pre-configured).
    In this case, select an email notification channel, as shown here:![Figure 10.38
    – Selecting a notification channel to send an alert
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_38.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.38 – Selecting a notification channel to send an alert
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, create the SLO burn rate alert policy. Optionally, add documentation that
    references the alert in terms of what the on-job SRE engineer should check or
    do.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once the alert has been configured, the SLO status will look as follows, where
    **Error Budget** is currently at 100% and none of the alerts are firing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.39 – Showing the complete setup for SLO monitoring with its alert
    and initial error budget'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_39.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.39 – Showing the complete setup for SLO monitoring with its alert
    and initial error budget
  prefs: []
  type: TYPE_NORMAL
- en: With that, we've created an SLO burn rate alert policy. Now, let's verify SLO
    monitoring by performing a test.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying SLO monitoring
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the previous two subsections of this hands-on lab on SLO monitoring, we
    created an SLO for a service (that was previously created in [*Chapter 8*](B15587_08_Final_ASB_TD_ePub.xhtml#_idTextAnchor182),
    *Understanding GKE Essentials to Deploy Containerized Applications*) and then
    created an SLO burn rate alert policy. This section will show you how to test
    the configuration and verify if our SLO monitoring option verifies the health
    of our service; that is, `hello-world-service`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that we previously selected the performance metric while defining our
    SLO as `kubernetes.io/container/restart_count`, let''s restart the container and
    see if the error budget changes and, subsequently, if the alert gets fired. Use
    the following command to restart the container after connecting to the cluster.
    Replace `pod-name` and `container-name` accordingly. `pod-name` can be found via
    the service, while `container-name` can be found via `pod-name`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once the command has been executed, the container inside the pod, with respect
    to `hello-world-service`, will restart. This means that the SLI that's been defined
    will not be met and, subsequently, the SLO will not be met. As a result, the error
    budget will be consumed. If the error budget is consumed by more than the burn
    rate that's been defined – which was 10 under 1 minute – then an alert will also
    be fired. The following screenshot shows the updated status of the SLO for `hello-world-service`.
    The status of the SLO has now been updated to **Unhealthy**:![Figure 10.40 – Displaying
    the service as Unhealthy, alerts firing, and the reduced error budget
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_40.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.40 – Displaying the service as Unhealthy, alerts firing, and the reduced
    error budget
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The alert triggers a notification that will be sent to the configured email,
    as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.41 – Alert notification set to the configured email address'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_41.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.41 – Alert notification set to the configured email address
  prefs: []
  type: TYPE_NORMAL
- en: This completes our detailed hands-on lab related to SLO monitoring, where we
    linked the SRE technical practices to options available in Google Cloud Operations
    to monitor and alert users about the reliability of the service. This also completes
    this chapter on Cloud Operations.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the suite of tools that are part of Cloud Operations.
    Cloud Operations is critical for forming the feedback loop of the CI/CD process
    and is fundamental to establishing observability on GCP. Observability is key
    to ensuring that an SRE's technical practices – specifically, SLIs, SLOs, SLAs,
    and Error Budgets – are not violated. This is achieved by gathering logs, metrics,
    and traces from multiple sources and by visualizing this information on dashboards.
    This information is used to establish performance and reliability indicators.
    These indicators can then be tracked with configurable alerts. These alerts trigger
    when there is a potential violation, and the alerts will be notified on the configurable
    notification channels. Cloud Operations also offers services that allow us to
    debug the application, without slowing down, and capture trace information. The
    end goal is to ensure that the service is reliable. We concluded this chapter
    by providing a hands-on lab on SLO monitoring, a feature from Google Cloud that
    tracks the reliability of the service by bringing together Cloud Operations and
    SRE technical practices.
  prefs: []
  type: TYPE_NORMAL
- en: This was the last chapter of this book. The next section provides insights into
    preparing to become a Professional Cloud DevOps Engineer, along with a summary
    on a few topics that might show up in the exam but were not covered in the last
    10 chapters. We have also provided a mock exam, which will be useful as a preparation
    resource.
  prefs: []
  type: TYPE_NORMAL
- en: Points to remember
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are some important points to remember:'
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Monitoring is a GCP service that collects metrics, events, and metadata
    from multi-cloud and hybrid infrastructures in real time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A workspace provides a *single pane of glass* related to GCP resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A workspace can monitor resources from multiple monitored projects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A monitored project, however, can only be associated with a single workspace.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dashboards provide a graphical representation of key signal data, called metrics,
    in a manner that is suitable for end users or the operations team.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics represent numerical measurements of resource usage that can be observed
    and collected across the system at regular time intervals.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MQL can be used to create a chart with a text-based interface and uses an expressive
    query language to execute complex queries against time series data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uptime checks test the availability of an external facing service within a specific
    timeout interval.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connection errors, 40x client errors, and not configuring firewall rules are
    potential reasons for uptime check failures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alerting is the process of processing the alerting rules that track the SLOs
    and notify or perform certain actions when the rules are violated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The alignment period is a lookback interval from a particular point in time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Monitoring agent is based on the `collectd` daemon and is used to collect
    system statistics from various sources, including OSes, applications, logs, and
    external devices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Logging is a GCP service that allows you to store, search, analyze, monitor,
    and alert users about logging data and events from applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Policy denied logs are specific to logs that are captured when access is denied
    by a Google Cloud service to either a user or service account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logs-based metrics are metrics that are created based on the content of the
    log entries and can be extracted from both included and excluded logs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VPC Flow Logs capture real-time network activity (incoming/outgoing) against
    VPC resources on an enabled subnet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Firewall logs capture the effects of a specific firewall rule in terms of the
    traffic that's allowed or denied by that firewall rule.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Logging agent is based on `fluentd` and captures additional VM logs such
    as operating system (OS) logs and logs from third-party applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Monitoring and Logging agents can both be installed on unmanaged GCE VMs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE has built-in support for logging and can be enabled for new or existing
    clusters via *Cloud Operations for GKE*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Debugger inspects the state of a running application in real time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snapshots capture local variables and the call stack at a specific location
    in the application's source code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A snapshot is only taken once, and the user needs to manually retake it if needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debug logpoints can inject a log into a running application without stopping,
    editing, or restarting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logpoints can be created even if direct access to the source code is not available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logpoints become inactive after 24 hours and are automatically deleted after
    30 days.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Trace is a collection of spans. A span is an object that wraps latency-specific
    metrics. Cloud Trace is a distributed tracing system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Trace's language-specific SDKs are available for Java, Node.js, Ruby,
    and Go.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Profiler provides low-impact continuous profiling to help us understand
    the performance of a production system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The programming languages that are supported by Cloud Profiler include Java,
    Go, Node.js, and Python. Profile data is retained for 30 days by default.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information on GCP''s approach toward DevOps, please read the following
    articles:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cloud Operations**: [https://cloud.google.com/products/operations](https://cloud.google.com/products/operations)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Monitoring**: [https://cloud.google.com/monitoring](https://cloud.google.com/monitoring)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Logging**: [https://cloud.google.com/logging](https://cloud.google.com/logging)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Debugger**: [https://cloud.google.com/debugger](https://cloud.google.com/debugger)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Trace**: [https://cloud.google.com/trace](https://cloud.google.com/trace)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Profiler**: [https://cloud.google.com/profiler](https://cloud.google.com/profiler)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Practice test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: A user has performed administrative actions that modify the configuration or
    metadata of resources. Which of the following is the most appropriate option to
    quickly get to the logs related to administrative actions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Go to Error Reporting and view the administrative activity logs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Go to Cloud Logging and view the administrative activity logs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Go to Cloud Monitoring and view the administrative activity logs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Go to the Activity tab on the Cloud Console and view the administrative activity
    logs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The default retention period for data access audit logs is ___________.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 7 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 30 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 400 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Unlimited
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select the most appropriate option for monitoring multiple GCP projects with
    resources through a single workspace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Cannot monitor multiple GCP projects through a single workspace.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Configure a separate project as a `host` project for a Cloud Monitoring workspace.
    Configure metrics and logs from each project to the host project via Pub/Sub.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Configure a separate project as a `host` project for a Cloud Monitoring workspace.
    Use this host project to manage all other projects.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Configure a separate project as a `host` project for a Cloud Monitoring workspace.
    Configure the metrics and logs from each project for the host project via Cloud
    Storage.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ____________ logs record operations of instances that have been reset for Google
    Compute Engine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Admin activity
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) System event
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Data access
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Access transparency
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The maximum size of a log entry is __________.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 64 KB
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 128 KB
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 256 KB
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) 512 KB
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The default retention period for access transparency logs is ___________.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 7 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 30 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 400 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Unlimited
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ___________ logs are specific to actions that are performed by Google personnel
    when accessing user's/customer's content.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Admin activity
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) System event
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Data access
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Access transparency
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The SRE team supports multiple production workloads in GCP. The SRE team wants
    to manage issues better by sending error reports and stack traces to a centralized
    service. Which of the following is best suited for accomplishing this goal?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Cloud Error Logging
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Cloud Error Reporting
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Cloud Tracing
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Cloud Profiling
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ___________ logs record the operations that are performed when assigning/unassigning
    IAM roles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Admin activity
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) System event
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Data access
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Access transparency
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: _________ logs analyze the network logs of an application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) VPC flow
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Firewall
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Audit
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Activity
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the option that represents the right characteristics for log entry from
    Cloud Logging:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Timestamp
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Log name
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Resource tied to the log entry
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) All of the above
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select two actions where the user will want to send a subset of logs for big
    data analysis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Create a sink in Cloud Logging that identifies the subset of logs to send.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Export logs to Cloud Storage.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Export logs to BigQuery.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Export logs to Pub/Sub.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The default retention period for admin activity logs is ___________.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 7 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 30 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 400 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Unlimited
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which of the following represents the right sequence of steps to export logs?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Choose destination, create sink, create filter
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Create sink, create filter, choose destination
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Create sink, choose destination, create filter
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Choose destination, create filter, create Sink
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '___________ logs will record how resources are created for Google Compute Engine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Admin activity
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) System event
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Data access
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Access transparency
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the option that governs access to logs from Cloud Logging for a given
    user:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Service accounts
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Cloud IAM roles
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Both (a) and (b)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) None of the above
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the role that allows us to manage IAM roles for a Monitoring workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Monitoring Viewer
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Monitoring Editor
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Monitoring Admin
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Monitoring Metric Writer
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the Cloud Monitoring widget that represents metrics with a distribution
    value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Line charts
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Heatmap charts
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Gauges
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Scorecards
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To perform uptime checks, what is the minimum number of active locations that
    need to be selected as geographic regions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Two
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Three
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Four
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Five
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The Monitoring agent is based on _________, while the Logging agent is based
    on __________.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `fluentd`, `collectd`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) `google-collectd`, `google-fluentd`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) `collectd`, `fluentd`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) `google-fluentd`, `google-collectd`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which of the following is not a valid classification type for data access logs?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Admin read
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Admin write
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Data read
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Data write
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the role that allows us to view data access and access transparency
    logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Logs Viewer
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Private Logs Viewer
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Project Viewer
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Project Editor
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The default retention period for firewall logs is ___________.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 7 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 30 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 400 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Unlimited
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Every VPC has a set of hidden, implied, pre-configured rules with the lowest
    priority. Select two valid pre-configured rules:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `allow all ingress`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) `deny all ingress`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) `allow all egress`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) `deny all egress`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The default retention period for system event audit logs is ___________.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 7 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 30 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 400 days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Unlimited
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '(d): Go to the Activity tab on the Cloud Console and view the administrative
    activity logs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): 30 days.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): Configure a separate project as a `host` project for a Cloud Monitoring
    workspace. Use this host project to manage all other projects.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): System event.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): 256 KB.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): 400 days.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(d): Access transparency.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Cloud Error Reporting.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(a): Admin activity.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(a): VPC flow.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(d): All of the above.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (a) and (c).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): 400 days.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Create sink, create filter, choose destination.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(a): Admin activity.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Cloud IAM roles.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): Monitoring Admin.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Heatmap chart.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Three.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): `collectd`, `fluentd`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Admin write; this is not a valid classification for data access logs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Private Logs Viewer.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): 30 days.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b) and (c): `deny all ingress` and `allow all egress`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): 400 days.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
