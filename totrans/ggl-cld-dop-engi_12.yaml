- en: '*Chapter 10*: Exploring GCP Cloud Operations'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第10章*：探索GCP Cloud Operations'
- en: '**Reliability** is the most critical feature of a service or a system. **Site
    Reliability Engineering** (**SRE**) prescribes specific technical tools or practices
    that help in measuring characteristics that define and track reliability, such
    as **SLAs**, **SLOs**, **SLIs**, and **error budgets**.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**可靠性**是服务或系统最关键的特性。**站点可靠性工程**（**SRE**）规定了一些特定的技术工具或实践，帮助衡量定义并跟踪可靠性的特征，如**SLAs**、**SLOs**、**SLIs**和**错误预算**。'
- en: In [*Chapter 2*](B15587_02_Final_ASB_ePub.xhtml#_idTextAnchor038), *SRE Technical
    Practices – Deep Dive*, we discussed the key constructs of SLAs in detail, the
    need for SLOs to achieve SLAs, the guidelines for setting SLOs, and the need for
    SLIs to achieve SLOs. In addition, we learned about the different types of SLIs
    based on user journey categorization, different sources to measure SLIs, the importance
    of error budgets, and the ways to set error budgets to make a service reliable.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第二章*](B15587_02_Final_ASB_ePub.xhtml#_idTextAnchor038)中，*SRE技术实践深度剖析*，我们详细讨论了SLAs的关键构成、实现SLA所需的SLOs、设置SLOs的指南，以及实现SLOs所需的SLIs。此外，我们了解了基于用户旅程分类的不同类型的SLIs、用于衡量SLIs的不同来源、错误预算的重要性，以及如何设置错误预算以确保服务的可靠性。
- en: 'This raises a series of fundamental questions:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了一个系列的基础性问题：
- en: How can we observe SLIs for a service so that the SLOs are not violated?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何观察服务的SLIs，以确保不违反SLOs？
- en: How can we track whether our error budgets are getting exhausted?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何跟踪我们的错误预算是否被消耗完了？
- en: How can we maintain harmony between the key SRE technical tools?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何保持关键SRE技术工具之间的和谐？
- en: 'SRE''s answer to the preceding questions is observability. Observability on
    **Google Cloud Platform** (**GCP**) is established through operations. From Google''s
    point of view, Cloud Operations is about monitoring, troubleshooting, and improving
    application performance in the Google Cloud environment. The key objectives of
    Cloud Operations are as follows:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: SRE对上述问题的回答是可观测性。在**Google Cloud Platform**（**GCP**）上，可观测性是通过运营来建立的。从Google的角度看，Cloud
    Operations是关于在Google Cloud环境中监控、故障排除和提升应用性能。Cloud Operations的关键目标如下：
- en: Gather logs, metrics, and traces from any source.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从任何来源收集日志、指标和追踪。
- en: Query the captured metrics and analyze traces.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询捕获的指标并分析追踪。
- en: Visualize information on built-in or customizable dashboards.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在内置或可定制的仪表板上可视化信息。
- en: Establish performance and reliability indicators.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立性能和可靠性指标。
- en: Trigger alerts and report errors in situations where reliability indicators
    are not met, or issues are encountered.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在可靠性指标未达到或遇到问题的情况下触发警报并报告错误。
- en: Google achieves key objectives of operations through a collection of services
    called Cloud Operations. Cloud Operations is a suite of GCP services that includes
    Cloud Monitoring, Cloud Logging, Error Reporting, and **Application Performance
    Management** (**APM**). Furthermore, APM includes Cloud Debugger, Cloud Trace,
    and Cloud Profiler. This chapter will explore services tied to Cloud Operations.
    Post that, we will focus on a specific feature that was introduced in Google Cloud
    to track the reliability of services through Service Monitoring. This specific
    feature/option links the SRE technical practices (SLIs, SLOs, and Error Budget)
    to features available in Google Cloud Operations that monitor the service and
    tell us about its reliability.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Google通过一组名为Cloud Operations的服务实现运营的关键目标。Cloud Operations是一套GCP服务，包括Cloud Monitoring、Cloud
    Logging、Error Reporting和**应用性能管理**（**APM**）。此外，APM包括Cloud Debugger、Cloud Trace和Cloud
    Profiler。本章将探讨与Cloud Operations相关的服务。之后，我们将重点关注Google Cloud中引入的一项特性，用于通过服务监控来追踪服务的可靠性。这个特性/选项将SRE技术实践（SLIs、SLOs和错误预算）与Google
    Cloud Operations中可用的监控服务功能相连接，从而告诉我们服务的可靠性。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将覆盖以下主要主题：
- en: '**Cloud Monitoring**: Workspaces, dashboards, Metrics explorer, uptime checks,
    and alerting.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cloud Monitoring**：工作区、仪表板、指标探查器、正常运行时间检查和告警。'
- en: '**Cloud Logging**: Audit Logs, Logs Ingestion, Logs Explorer, and Logs-Based
    Metrics.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cloud Logging**：审计日志、日志摄取、日志探查器和基于日志的指标。'
- en: '**Cloud Debugger**: Setting up, Usage, Debug Logpoints, and Debug Snapshots.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cloud Debugger**：设置、使用、调试日志点和调试快照。'
- en: '**Cloud Trace**: Trace Overview, Trace List, and Analysis Reports.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cloud Trace**：追踪概述、追踪列表和分析报告。'
- en: '**Cloud Profiler**: Profile Types.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cloud Profiler**：配置文件类型。'
- en: '**Binding SRE and Cloud Operations**: We will measure service reliability using
    Cloud Operations by linking them to SRE technical practices via a hands-on lab.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**绑定 SRE 和云操作**：我们将通过实践实验室将 SRE 技术实践与 Cloud Operations 结合，以衡量服务的可靠性。'
- en: Cloud Monitoring
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云监控
- en: '**Cloud Monitoring** is a GCP service that collects metrics, events, and metadata
    from multi-cloud and hybrid infrastructures in real time. Cloud Monitoring helps
    us understand how well our resources are performing and if there is something
    wrong that requires immediate attention. Cloud Monitoring is a medium through
    which SRE best practices can be implemented and to ensure that applications are
    meeting their set SLAs. Cloud Monitoring consists of out-of-the-box dashboards.
    These can be used to visualize insights into key factors that impact SLIs and
    SLOs such as latency, throughput, and more. Cloud Monitoring is also critical
    for incident management as alerts can be generated from key metrics, and these
    alerts can be sent as notifications to configured notification channels.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**云监控**是一个 GCP 服务，能够实时收集来自多云和混合基础设施的度量、事件和元数据。云监控帮助我们了解资源的性能以及是否存在需要立即关注的问题。云监控是实施
    SRE 最佳实践的途径，并确保应用程序达到其设定的 SLA。云监控包括开箱即用的仪表盘，这些仪表盘可用于可视化对影响 SLI 和 SLO 的关键因素的洞察，如延迟、吞吐量等。云监控对事件管理也至关重要，因为可以从关键指标中生成警报，并将这些警报作为通知发送到配置的通知通道。'
- en: This section on Cloud Monitoring deep dives into several key areas/properties,
    such as workspaces, dashboards, Metrics explorer, uptime checks, alerting, access
    controls, and the Monitoring agent. We will start with workspaces.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本节深入探讨了云监控的几个关键领域/属性，如工作区、仪表盘、指标资源探索器、正常运行时间检查、警报、访问控制和监控代理。我们将从工作区开始。
- en: Workspaces
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作区
- en: '**Google Workspace** is a centralized hub that''s used to organize and display
    monitoring information about GCP and AWS resources. Workspace provides a centralized
    view and acts as a single point of entry to resource dashboards, uptime checks,
    groups, incidents, events, and charts. Google describes this centralized view
    as a *single pane of glass* (please refer to the following screenshot). The actions
    that can be performed against a workspace include the ability to view content,
    which is controlled by **Identity and Access Management** (**IAM**):'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**Google 工作区**是一个集中式的中心，用于组织和展示有关 GCP 和 AWS 资源的监控信息。工作区提供集中视图，并作为访问资源仪表盘、正常运行时间检查、组、事件、警报和图表的单一入口点。Google
    将这种集中视图称为*单一窗口*（请参阅以下截图）。可以对工作区执行的操作包括查看内容，这些内容由**身份与访问管理**（**IAM**）控制：'
- en: '![Figure 10.1 – Overview of a Cloud Monitoring workspace'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.1 – 云监控工作区概述'
- en: '](img/B15587_10_01.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_10_01.jpg)'
- en: Figure 10.1 – Overview of a Cloud Monitoring workspace
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – 云监控工作区概述
- en: 'The following is some key terminology we need to know about before we elaborate
    on the relationship between workspaces and projects:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在详细说明工作区与项目之间的关系之前，以下是我们需要了解的一些关键术语：
- en: '**Host project**: This refers to the project where Workspace is created.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主机项目**：指的是创建工作区的项目。'
- en: '**Monitored project**: This refers to the GCP projects or AWS accounts that
    the workspace can monitor.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控项目**：指的是工作区可以监控的 GCP 项目或 AWS 账户。'
- en: '**AWS connector project**: This refers to the GCP project that connects the
    monitored AWS account to the workspace.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS 连接器项目**：指的是将监控的 AWS 账户与工作区连接的 GCP 项目。'
- en: The upcoming subsection provides insights into the relationship between Workspace
    and Project.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的子章节将深入探讨工作区与项目之间的关系。
- en: Workspace/project relationship
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工作区/项目关系
- en: 'The following are some key pointers with respect to a workspace/project relationship:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是关于工作区/项目关系的一些关键要点：
- en: A workspace is always created inside a project. This is known as the host project.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个工作区始终是在一个项目内创建的，这个项目被称为主机项目。
- en: A workspace is part of a single host project and is named after the host project.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个工作区是单个主机项目的一部分，并以主机项目命名。
- en: A workspace can monitor resources from multiple monitored projects simultaneously.
    This could include about 200 GCP projects/AWS accounts.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个工作区可以同时监控来自多个监控项目的资源。这可以包括大约 200 个 GCP 项目/AWS 账户。
- en: A workspace can access other monitored projects' metric data, but the actual
    data lives in monitored projects.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个工作区可以访问其他监控项目的度量数据，但实际数据存储在监控项目中。
- en: A monitored project can only be associated with a single workspace, and a monitored
    project can be moved from one workspace to another.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个被监控项目只能与一个工作区关联，并且一个被监控项目可以从一个工作区移动到另一个工作区。
- en: Multiple workspaces can be merged into a single workspace.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多个工作区可以合并为一个工作区。
- en: There is no charge associated with creating a workspace. However, charges with
    respect to logging and ingesting metric data is charged to the billing account
    associated with the *monitored projects*.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建工作区本身没有费用。然而，与日志记录和指标数据获取相关的费用将由与*被监控项目*关联的账单账户承担。
- en: Tip – how to connect an AWS account to a workspace
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示 – 如何将AWS账户连接到工作区
- en: A GCP connector project is required. This can be an existing project, or an
    empty project (preferred) created for this purpose. GCP connector project needs
    to be under the same parent organization as the workspace. A billing account should
    be tied to the connector project and this account will be charged to monitor the
    resources under the AWS account.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 需要一个GCP连接器项目。这个项目可以是一个现有的项目，或者是一个为此目的创建的空项目（优选）。GCP连接器项目需要与工作区处于相同的父组织下。一个账单账户应该与连接器项目绑定，并且此账户将被用来监控AWS账户下的资源。
- en: The following section discusses potential strategies for creating a workspace.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分讨论了创建工作区的潜在策略。
- en: Workspace creation – strategies
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工作区创建 – 策略
- en: In a real-time scenario, it is possible to have multiple projects where the
    projects are either differentiated by customers or differentiated by environment
    types such as development, test, staging, and production. Given that a workspace
    can monitor resources from multiple projects, the strategy/approach that's taken
    to create the workspace becomes critical. There are multiple strategies we can
    follow to create a workspace, as detailed in the following sections.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在实时场景中，可能会有多个项目，这些项目要么按客户区分，要么按环境类型（如开发、测试、预发布和生产）区分。由于一个工作区可以监控来自多个项目的资源，因此创建工作区时采用的策略/方法变得至关重要。我们可以遵循多种策略来创建工作区，具体策略将在以下部分详细介绍。
- en: A single workspace for all monitored projects
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 所有被监控项目的单一工作区
- en: Information about all monitored project resources is available from within a
    single workspace. The following diagram represents a single workspace that monitors
    an application, `app`, that's been deployed across multiple projects, such as
    `app-dev`, `app-test`, and `app-prod`. These have been categorized by environment
    type. This approach has its own pros and cons.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 所有被监控项目资源的信息都可以从单一工作区中获取。下图展示了一个工作区，监控了一个应用程序`app`，该应用程序已部署到多个项目中，如`app-dev`、`app-test`和`app-prod`。这些项目按环境类型进行了分类。这种方法有其优缺点。
- en: 'The pro is that the workspace provides a single pane of glass for all the resources
    tied to the application across multiple projects representing multiple environment
    types. The con is that a non-production user can access resources from a production
    project, and this might not be acceptable in most cases. This approach is not
    suitable for organizations that have strict isolation between production and non-production
    environments:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 优点是，工作区为所有与应用程序相关的资源提供了一个统一视图，这些资源来自多个项目，代表了不同的环境类型。缺点是，非生产用户可以访问生产项目中的资源，这在大多数情况下可能是不可接受的。这种方法不适合那些在生产和非生产环境之间有严格隔离的组织：
- en: '![Figure 10.2 – A single workspace for all related projects'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.2 – 所有相关项目的单一工作区'
- en: '](img/B15587_10_02.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_10_02.jpg)'
- en: Figure 10.2 – A single workspace for all related projects
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – 所有相关项目的单一工作区
- en: Workspace per group of monitored projects
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 每组被监控项目的工作区
- en: 'A workspace will monitor a specific group of projects. There could be more
    than one workspace monitoring the available projects. The following diagram is
    an alternative workspace creation strategy compared to the one shown in the preceding
    diagram. Specifically, the following diagram represents two workspaces where one
    workspace monitors the non-production projects and the second workspace monitors
    the production project. Access controls to that specific group can be controlled
    by the host project of the individual workspace. This allows us to differentiate
    between users across environment types, such as production versus non-production
    or even across customers:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一个工作空间将监控一组特定的项目。可以有多个工作空间监控可用的项目。以下图表是与前面的图表所示的工作空间创建策略相比的另一种选择。具体来说，以下图表代表两个工作空间，其中一个工作空间监控非生产项目，而第二个工作空间监控生产项目。通过单个工作空间的主机项目控制对该特定组的访问控制，这允许我们区分跨环境类型（例如生产与非生产）或甚至跨客户的用户：
- en: '![Figure 10.3 – Workspace per group of monitored projects'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.3 – 每组受监控项目一个工作空间'
- en: '](img/B15587_10_03.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_10_03.jpg)'
- en: Figure 10.3 – Workspace per group of monitored projects
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 – 每组受监控项目一个工作空间
- en: Single workspace per monitored project
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 每个受监控项目一个单一工作空间
- en: 'Essentially, every project that needs to be monitored is hosted by a workspace
    within the same project. This can be seen in the following diagram. This means
    that the source and the host project will be the same. This approach provides
    the most granular control in terms of providing monitoring access to the project
    resources. However, this might also only provide a slice of information if an
    application is spread across multiple projects:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，需要进行监控的每个项目都由同一项目中的一个工作空间托管。这可以在以下图表中看到。这意味着源和托管项目将是相同的。这种方法在提供对项目资源进行监控访问方面提供了最精细的控制。但是，如果应用程序跨多个项目分布，这也可能仅提供信息的一部分：
- en: '![Figure 10.4 – Single workspace per monitored project'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.4 – 每个受监控项目一个单一工作空间'
- en: '](img/B15587_10_04.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_10_04.jpg)'
- en: Figure 10.4 – Single workspace per monitored project
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4 – 每个受监控项目一个单一工作空间
- en: Important note – Workspace management
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示 – 工作空间管理
- en: One or more GCP project(s) or AWS account(s) can either be added or removed
    from the workspace. In addition, all projects within a selected workspace can
    be merged into the current workspace, but the configuration will be deleted in
    the selected workspace. These actions are performed through the settings page
    of Cloud Monitoring. A workspace can only be deleted if the workspace host project
    is deleted.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 可以向工作空间添加或删除一个或多个 GCP 项目或 AWS 账户。此外，可以将所选工作空间中的所有项目合并到当前工作空间中，但所选工作空间中的配置将被删除。这些操作是通过
    Cloud Monitoring 的设置页面执行的。只有当工作空间托管项目被删除时，才能删除工作空间。
- en: This concludes this subsection on workspace creation strategies. The preferred
    strategy depends on the organizational need. Workspace basic operations include
    creating a workspace, adding project(s) to a workspace, moving projects between
    workspaces, and merging workspaces. Detailed instructions on how to create a workspace
    can be found at [https://cloud.google.com/monitoring/workspaces/create](https://cloud.google.com/monitoring/workspaces/create).
    The upcoming subsection discusses IAM roles, which are used to determine who has
    access to monitor the resources inside the monitoring workspace.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了关于工作空间创建策略的子节。首选策略取决于组织需求。工作空间的基本操作包括创建工作空间、将项目添加到工作空间、在工作空间之间移动项目以及合并工作空间。有关如何创建工作空间的详细说明，请参阅
    [https://cloud.google.com/monitoring/workspaces/create](https://cloud.google.com/monitoring/workspaces/create)。接下来的子节将讨论
    IAM 角色，这些角色用于确定谁有权限监控监控工作空间内的资源。
- en: Workspace IAM roles
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工作空间 IAM 角色
- en: 'The following are the IAM roles that can be applied to a workspace project
    so that we can view monitoring data or perform actions on the workspace:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是可以应用于工作空间项目的 IAM 角色，以便我们可以查看监控数据或在工作空间上执行操作：
- en: '**Monitoring Viewer**: Read-only access to view metrics inside a workspace.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控查看者**：仅具有查看工作空间内指标的只读访问权限。'
- en: '**Monitoring Editor**: Monitoring Viewer, plus the ability to edit a workspace,
    create alerts, and have write access to Monitoring Console and Monitoring API.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控编辑者**：监控查看者，以及编辑工作空间、创建警报、以及对监控控制台和监控 API 具有写访问权限的能力。'
- en: '**Monitoring Admin**: Monitoring Editor, plus the ability to manage IAM roles
    for the workspace.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控管理员**：监控编辑者，以及管理工作空间的 IAM 角色的能力。'
- en: '**Monitoring Metric Writer**: A service account role that''s given to applications
    instead of humans. This allows an application to write data to a workspace but
    does not provide read access.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控指标写入者**：一种授予应用程序而非用户的服务帐户角色。这样，应用程序可以将数据写入工作区，但不提供读取权限。'
- en: This concludes our quick insight into workspaces and their concepts, such as
    workspace creation strategies. Next, we will look at dashboards.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们对工作区及其概念（如工作区创建策略）的简要了解。接下来，我们将关注仪表板。
- en: Dashboards
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 仪表板
- en: '**Dashboards** provide a graphical representation of key signal data, called
    metrics, in a manner that is suitable for end users or the operations team. It''s
    recommended that a single dashboard displays metrics depicting a specific viewpoint
    (for example, serverless resources with a specific label) or for a specific resource
    (for example, persistent disks, snapshots, and so on). There are two types of
    dashboards: predefined dashboards and custom dashboards.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**仪表板**提供了关键信号数据（称为指标）的图形化表示方式，适合最终用户或运维团队使用。建议单个仪表板展示特定视角下的指标（例如，带有特定标签的无服务器资源）或特定资源（例如，持久磁盘、快照等）。仪表板有两种类型：预定义仪表板和自定义仪表板。'
- en: 'The following screenshot is of the **Dashboards Overview** page in Cloud Monitoring.
    This page displays the list of available dashboards, categorized by dashboard
    types, and provides quick links to the most recently used dashboards:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是 Cloud Monitoring 中的 **仪表板概览** 页面。该页面展示了可用仪表板的列表，按仪表板类型分类，并提供快速链接到最近使用的仪表板：
- en: '![Figure 10.5 – Cloud Monitoring – Dashboards Overview'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.5 – Cloud Monitoring – 仪表板概览'
- en: '](img/B15587_10_05.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_10_05.jpg)'
- en: Figure 10.5 – Cloud Monitoring – Dashboards Overview
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5 – Cloud Monitoring – 仪表板概览
- en: Cloud Monitoring supports both predefined dashboards and custom dashboards.
    The upcoming subsection provides an overview of the different types of dashboards
    and steps for how to create a custom dashboard.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Cloud Monitoring 同时支持预定义仪表板和自定义仪表板。接下来的小节将提供不同类型仪表板的概述，并介绍如何创建自定义仪表板的步骤。
- en: Predefined dashboards
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预定义仪表板
- en: Cloud Monitoring provides a set of predefined dashboards that are grouped by
    a specific GCP resource such as firewalls or GKE Clusters. These dashboards are
    categorized by **Type**. This is set to **Google Cloud Platform**, which is maintained
    by Google Cloud. They do not require any explicit setup or effort to configure.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Cloud Monitoring 提供了一组预定义的仪表板，这些仪表板按特定的 GCP 资源（例如防火墙或 GKE 集群）进行分组。这些仪表板按 **类型**
    分类。该设置为 **Google Cloud Platform**，由 Google Cloud 维护。它们不需要任何显式的设置或配置工作。
- en: However, predefined dashboards are not customizable. These dashboards are organized
    in a specific manner with a set of predefined filters from the context of the
    dashboard. Users cannot change the contents of the view or add a new filter criterion.
    Users can only use the predefined filters to control the data being displayed.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，预定义仪表板是不可自定义的。这些仪表板以特定方式组织，并且具有一组预定义的过滤器，基于仪表板的上下文，用户不能更改视图内容或添加新的过滤条件。用户只能使用预定义的过滤器来控制显示的数据。
- en: Custom dashboards
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自定义仪表板
- en: Users or operation teams can create a **custom dashboard** that displays specific
    content of interest. These dashboards are categorized by **Type** set to **Custom**.
    Content is added by configuring one or more widgets. There are multiple types
    of widgets. Dashboards can either be created from Google Cloud Console or via
    the Cloud Monitoring API. In addition, the Cloud Monitoring API allows you to
    import a dashboard configuration from GitHub and modify it as needed.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 用户或运维团队可以创建 **自定义仪表板**，以展示特定的内容。这些仪表板按 **类型** 分类，设置为 **自定义**。通过配置一个或多个小部件来添加内容。小部件有多种类型。仪表板可以通过
    Google Cloud Console 或 Cloud Monitoring API 创建。此外，Cloud Monitoring API 允许你从 GitHub
    导入仪表板配置并根据需要进行修改。
- en: 'Custom dashboards represent information about a metric using a chart. This
    chart displays raw signal information from a metric that''s aligned across a configurable
    time window. Each chart is of a specific widget type. Cloud Monitoring supports
    multiple widget types such as Line, Stacked area, Stacked bar, Heatmap, Gauge,
    Scorecard, and Textboxes. Let''s take a brief look at the different types of widgets:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义仪表板通过图表展示关于某个指标的信息。这个图表显示了来自一个在可配置时间窗口内对齐的指标的原始信号信息。每个图表都是特定的小部件类型。Cloud
    Monitoring 支持多种小部件类型，例如线形图、堆叠区域图、堆叠条形图、热图、仪表盘、记分卡和文本框。让我们简要了解一下不同类型的小部件：
- en: Line charts, stacked area charts, and stacked bar charts are best utilized to
    display time series data. Each of these widget types can be configured so that
    they're displayed in Color/X-Ray/Stats/Outlier mode, along with an optional legend,
    using the display view options.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 折线图、堆叠区域图和堆叠条形图最适合用来显示时间序列数据。每种小部件类型都可以配置，以便在颜色/透视/统计/异常模式下显示，并且可以选择是否显示图例。
- en: Heatmap charts are used to represent metrics with a distribution value.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 热力图图表用于表示具有分布值的指标。
- en: Gauges display the most recent measurement in terms of a number. This is represented
    by a thick line around the gauge. This is visually categorized across good, warning,
    and danger zones.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仪表盘以数字形式显示最新的测量值。这通过仪表周围的粗线条表示。视觉上，这些数值被分类为良好区、警告区和危险区。
- en: Scorecards are similar to gauges as they display the recent measurement in terms
    of a number, but they can be visually depicted using a different view other than
    a gauge, such as a spark line, spark bar, icon, or value.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 积分卡与仪表盘类似，也以数字形式显示最新的测量值，但它们可以使用不同的视图展示，而不仅限于仪表盘，例如火花线、火花条、图标或数值。
- en: Textboxes allow us to add any custom information, such as quick notes or links,
    concerning the relevant resources.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本框允许我们添加任何自定义信息，如快速笔记或链接，关于相关资源。
- en: The upcoming subsection will show you how to create a custom dashboard.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的子节将展示如何创建自定义仪表盘。
- en: Creating a custom dashboard
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建自定义仪表盘
- en: 'Follow these steps to create a custom dashboard from the GCP console:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤从 GCP 控制台创建自定义仪表盘：
- en: Navigate to `VM Instance – Mean CPU Utilization`.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到`VM Instance – Mean CPU Utilization`。
- en: Select a chart type or widget. This will open **Metrics explorer** on the left-hand
    pane and will add the chart to the dashboard.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择图表类型或小部件。这将打开左侧窗格中的**Metrics explorer**，并将图表添加到仪表盘。
- en: Select the options to choose a resource type, metric type, and grouping criteria.
    Then, **Save** the dashboard to add the chart type.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择选项以选择资源类型、指标类型和分组标准。然后，**保存**仪表盘以添加图表类型。
- en: Redo the preceding steps to add multiple charts to the same dashboard.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复上述步骤，将多个图表添加到同一仪表盘。
- en: 'The following screenshot shows a custom dashboard depicting the mean CPU utilization
    for all the VM instances, along with seven possible widget types:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了一个自定义仪表盘，显示了所有虚拟机实例的平均 CPU 使用率，并包含七种可能的小部件类型：
- en: '![Figure 10.6 – Custom dashboard with seven possible widget types'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.6 – 自定义仪表盘，包含七种可能的小部件类型'
- en: '](img/B15587_10_06.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_10_06.jpg)'
- en: Figure 10.6 – Custom dashboard with seven possible widget types
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6 – 自定义仪表盘，包含七种可能的小部件类型
- en: This concludes this section on Cloud Monitoring dashboards. The next section
    focuses on using *Metrics explorer* as an option to explore predefined and user-created
    metrics.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 本节结束后，我们将进入下一节，重点介绍如何使用*Metrics explorer*作为探索预定义和用户创建的指标的选项。
- en: Metrics explorer
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指标资源浏览器
- en: '**Metrics** is one of the critical sources for monitoring data. Metrics represents
    numerical measurements of resource usage or behavior that can be observed and
    collected across the system over many data points at regular time intervals. There
    are about 1,000 pre-created metrics in GCP. This includes CPU utilization, network
    traffic, and more. However, some granular metrics such as memory usage can be
    collected using an optional Monitoring agent. Additionally, custom metrics can
    be created either through the built-in Monitoring API or through OpenCensus –
    an open source library used to create metrics. It is always recommended to check
    if a default or pre-created metric exists before creating a custom metric.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**指标**是监控数据的关键来源之一。指标代表了资源使用或行为的数值测量，可以在系统中跨多个数据点以定期的时间间隔收集和观察。GCP 中大约有 1,000
    个预创建的指标，包括 CPU 使用率、网络流量等。然而，一些更为精细的指标，如内存使用率，可以通过可选的监控代理进行收集。此外，用户可以通过内置的监控 API
    或通过 OpenCensus（一种开源库）创建自定义指标。在创建自定义指标之前，始终建议先检查是否已存在默认或预创建的指标。'
- en: Metrics explorer provides options for exploring existing metrics (either predefined
    or user-created), using metrics to build charts, adding charts to an existing
    or new dashboard, sharing charts via a URL, or retrieving chart configuration
    data in JSON format. Metrics explorer is an interface that provides a DIY approach
    to building charts as you can select a metric of your choice.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 度量资源浏览器提供了探索现有度量的选项（包括预定义的或用户创建的），使用度量构建图表，向现有或新建的仪表盘添加图表，通过 URL 分享图表，或以 JSON
    格式获取图表配置数据。度量资源浏览器是一个提供 DIY 方法的接口，您可以选择自己选择的度量来构建图表。
- en: 'The following screenshot shows the **Metrics explorer** section, which charts
    the **CPU Utilization** metric for a **VM Instance**, grouped by system state.
    The left-hand side displays the configuration region, while the right-hand side
    depicts the chart for the selected metric. The configuration region has two tabs:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了**度量资源浏览器**部分，其中为**虚拟机实例**绘制了**CPU 利用率**度量，并按系统状态进行了分组。左侧显示配置区域，右侧显示所选度量的图表。配置区域有两个选项卡：
- en: '**Metric**: This tab is used to select the metric and explore it.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**度量**：此选项卡用于选择度量并进行探索。'
- en: '**View Options**: This tab is used to change the chart''s display characteristics:'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查看选项**：此选项卡用于更改图表的显示特性：'
- en: '![Figure 10.7 – Cloud Monitoring – Metrics explorer'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.7 – 云监控 – 度量资源浏览器'
- en: '](img/B15587_10_07.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_10_07.jpg)'
- en: Figure 10.7 – Cloud Monitoring – Metrics explorer
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7 – 云监控 – 度量资源浏览器
- en: The following section discusses the available options for configuring a metric
    using Metrics explorer.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分讨论了使用度量资源浏览器配置度量的可用选项。
- en: Understanding metric configuration via Metrics explorer
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过度量资源浏览器了解度量配置。
- en: To configure a metric for a monitored resource, we can use the following options.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 要为监控资源配置度量，我们可以使用以下选项。
- en: '**Resource type** and **Metric** option can be selected in either of the following
    ways:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源类型**和**度量**选项可以通过以下任一方式选择：'
- en: '**Standard Mode**: Select a specific metric type or browse the available metric
    types based on a specific GCP resource.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准模式**：选择特定的度量类型，或根据特定的 GCP 资源浏览可用的度量类型。'
- en: '**Direct Filter Mode**: Manually enter a metric type and resource type in a
    text box.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直接筛选模式**：手动在文本框中输入度量类型和资源类型。'
- en: 'The **Filter** option can be used to filter out the results based on the filter
    criterion. The filter criterion can be defined using the available operators or
    regular expressions. There are two possible filter types:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**筛选器**选项可用于根据筛选标准过滤结果。筛选标准可以使用可用操作符或正则表达式进行定义。筛选器有两种可能的类型：'
- en: '`project_id`, `instance_id`, and `zone` as the available filter options).'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`project_id`、`instance_id` 和 `zone` 可作为可用的筛选选项。'
- en: '**By Metric Label**: Refers to project-wide user-created labels.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**按度量标签**：指的是跨项目的用户创建标签。'
- en: The **Group By** option can be used to group time series data by resource type
    and metric label. This creates new time series data based on the combination of
    group by values.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**按组**选项可用于按资源类型和度量标签对时间序列数据进行分组。这将基于按组值的组合创建新的时间序列数据。'
- en: The **Aggregator** option can be used to describe how to aggregate data points
    across multiple time series. Common options include min, max, sum, count, and
    standard deviation. By default, the aggregation results in a single line by applying
    the aggregator across all the time series. If **Group By** labels are selected,
    the aggregation results in a time series for each combination of matching labels.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚合器**选项可用于描述如何对多个时间序列中的数据点进行聚合。常见的选项包括最小值、最大值、总和、计数和标准差。默认情况下，聚合结果会应用于所有时间序列，从而得到一条单一的线。如果选择了**按组**标签，聚合结果将为每个匹配标签组合生成一个时间序列。'
- en: The **Period** option can be used to determine the time interval for which aggregation
    takes place. The default selection is 1 minute.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**周期**选项可用于确定聚合发生的时间间隔。默认选择是1分钟。'
- en: The **Aligner** option can be used to bring the data points in each individual
    time series into equal periods of time.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**对齐器**选项可用于将每个单独时间序列中的数据点按相等的时间段对齐。'
- en: 'Additional options include the following:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 其他选项包括以下内容：
- en: '**Secondary Aggregator**: Used in charts with multiple metrics'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二级聚合器**：用于包含多个度量的图表。'
- en: '**Legend Template**: For better readability'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图例模板**：为更好地阅读性。'
- en: 'Multiple **View Options** can be used to plot metrics, and these are distinguished
    by the available chart modes, which are as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用多个**查看选项**来绘制度量图表，这些选项通过可用的图表模式进行区分，具体如下：
- en: '**Color mode**: This is the default mode where graph lines are shown in color.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**颜色模式**：这是默认模式，其中图形线条以颜色显示。'
- en: '**X-Ray mode**: Shows graph lines in a translucent gray color but with brightness
    in the case of overlapping bands.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**X-Ray 模式**：以半透明灰色显示图形线条，并在重叠区域中显示亮度。'
- en: '**Stats mode**: Shows common statistical values such as the 5th percentile,
    95th percentile, average, median, and more.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统计模式**：显示常见的统计值，如第 5 百分位数、第 95 百分位数、平均值、中位数等。'
- en: '**Outlier mode**: Allows you to choose a number of time series to display,
    along with the option to rank time series by ordering them from the top or bottom.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常值模式**：允许选择多个时间序列进行显示，并提供按升序或降序排列时间序列的选项。'
- en: Additionally, each chart mode supports the ability to specify a specific threshold
    and allows you to compare past time series data. In addition, it is possible to
    apply a log scale to the *y* axis for better separation between larger values
    in datasets where some values are much larger than the others.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，每种图表模式都支持指定特定的阈值，并允许比较过去的时间序列数据。此外，对于数据集中某些值远大于其他值的情况，可以将*y*轴应用对数刻度，以更好地区分较大的数值。
- en: Tip – Monitoring Query Language (MQL) – Advanced option to create charts
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 提示 - 监控查询语言（MQL）- 创建图表的高级选项
- en: Cloud Monitoring supports **MQL**, an advanced option for creating a chart with
    a text-based interface and an expressive query language that can execute complex
    queries against time series data. Potential use cases include the ability to select
    a random sample of time series or compute the ratio of requests, resulting in
    a particular class of response codes.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 云监控支持**MQL**，这是一种使用基于文本的界面和表达性查询语言创建图表的高级选项，可以对时间序列数据执行复杂查询。潜在的用例包括选择时间序列的随机样本或计算请求比率，从而得出特定类别的响应代码。
- en: This completes this section on Metrics explorer, which allows users to explore
    predefined and custom metrics. These can potentially be used to create charts.
    The options related to configuring a metric were also discussed in detail. The
    upcoming section focuses on uptime checks – an option for validating whether a
    service is functioning.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了指标浏览器，允许用户探索预定义和自定义指标。这些指标可以用于创建图表。与配置指标相关的选项也已详细讨论。接下来的部分将重点介绍在线检查——一种验证服务是否正常运行的选项。
- en: Uptime checks
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线检查
- en: '**Uptime check** is a Cloud Monitoring feature where periodic requests are
    sent to monitor a resource to check if the resource is indeed up. Uptime checks
    can check the uptime of GCP VMs, App Engine services, website URLs, and AWS Load
    Balancer. Uptime checks are also a way to track the Error Budget of services.
    Uptime checks essentially test the availability of an external facing service
    within a specific timeout interval and ensure that the Error Budget of the service
    is not burnt unnecessarily. It is possible to initiate these tests from one or
    more GCP geographic regions, and a minimum of three active locations must be selected
    as geographic regions. Alternatively, selecting the **Global** option will initiate
    tests from all available locations.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**在线检查**是一个云监控功能，通过定期请求监控资源，检查资源是否真正可用。在线检查可以检查 GCP 虚拟机、App Engine 服务、网站 URL
    和 AWS 负载均衡器的可用性。在线检查也是跟踪服务错误预算的一种方式。在线检查本质上是在特定的超时区间内测试外部服务的可用性，确保服务的错误预算不会不必要地被耗尽。可以从一个或多个
    GCP 地理区域发起这些测试，必须选择至少三个活跃的地理位置作为测试区域。或者，选择**全球**选项将从所有可用位置发起测试。'
- en: 'The frequency at which uptime checks are performed can be configured and defaults
    to 1 minute. Uptime checks support multiple protocol options, such as HTTP, HTTPS,
    and TCP, and can be defined for the following resource types:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 可以配置在线检查的执行频率，默认间隔为 1 分钟。在线检查支持多种协议选项，如 HTTP、HTTPS 和 TCP，并可针对以下资源类型进行定义：
- en: '**URL**: Required to specify a hostname and path.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**URL**：需要指定主机名和路径。'
- en: '**App Engine Service**: Required to specify a service and path.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**App Engine 服务**：需要指定服务和路径。'
- en: '**Instance**: Required to specify a path for a single instance (GCP or EC2)
    or a predefined group. This group needs to be explicitly configured.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实例**：需要指定单个实例（GCP 或 EC2）或预定义组的路径。此组需要明确配置。'
- en: '**Elastic Load Balancer**: Required to specify a path for AWS ELB.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**弹性负载均衡器**：需要指定 AWS ELB 的路径。'
- en: 'The configuration to create an uptime check includes options to perform response
    validation. These options include the following:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '**Provide response timeout**: This is the time it takes for the request to
    complete. Must be between 1 and 60 seconds. The default is 10 seconds.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enable response content**: This option allows you to select a response content
    match type with specific operators that contain or do not contain specific text
    or matches on regex.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Log Check Failures**: This option will save all the logs related to uptime
    checks failing to Cloud Logging.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition, alerts and notifications can be configured in situations when
    the uptime check fails for the selected duration. It is mandatory that the alert
    policy already exists and that the notification channel has been pre-created.
    The following screenshot shows the summary configuration of an uptime check where
    the target resource type is a URL:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.8 – Uptime checking a URL as the target resource type'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_08.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.8 – Uptime checking a URL as the target resource type
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: The URL being used in the preceding screenshot is the URL of the LoadBalancer
    service, `hello-world-service`, that was created as part of [*Chapter 8*](B15587_08_Final_ASB_TD_ePub.xhtml#_idTextAnchor182),
    *Understanding GKE Essentials to Deploy Containerized Applications*. A configured
    uptime check can result in a failure. The upcoming subsection lists the potential
    reasons for uptime check failures.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Potential reasons for uptime check failures
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following are some potential reasons for uptime checks failing:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '**Connection errors**: The hostname/service not found or responding, or the
    specified port is not open or valid.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`403` (Forbidden Service), `404` (Incorrect Path), and `408` (port number is
    incorrect or service is not running).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GoogleStackdriverMonitoring-UptimeChecks`.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This concludes our detailed overview of uptime checks. The next topic deep dives
    into alerting – a Cloud Monitoring option that's key for Incident Management.
    Alerting provides options for reporting on monitored metrics and providing notifications
    appropriately.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Alerting
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Alerting** is the process of processing the alerting rules, which track the
    SLOs and notify or perform certain actions when the rules are violated. [*Chapter
    3*](B15587_03_Final_ASB_ePub.xhtml#_idTextAnchor064), *Understanding Monitoring
    and Alerting to Target Reliability*, deep dived into alerting, described how alerting
    allows us to convert SLOs into actionable alerts, discussed key alerting attributes,
    and elaborated on alerting strategies. The alerting UI in Cloud Monitoring hosts
    information with respect to incidents currently being fired, incidents being acknowledged,
    active alerting policies that have been configured, details of open and closed
    incidents, and all the incidents tied to the events. In addition, alerting allows
    us to create an alert policy and configure notification channels.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Configuring an alert policy
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The steps involved in configuring an alert policy are very similar to the ones
    for creating a chart using Metrics explorer. Essentially, an alert needs to be
    created against a metric. Configuring an alert includes adding a metric condition
    through Metrics explorer and setting a metric threshold condition.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 配置警报策略的步骤与使用 Metrics Explorer 创建图表的步骤非常相似。本质上，警报需要针对某个指标创建。配置警报包括通过 Metrics
    Explorer 添加指标条件并设置指标阈值条件。
- en: A metric threshold condition will define the specific value. If the specific
    metric value falls above or below the threshold value (based on how the policy
    is defined), an alert will be triggered, and we will be notified through the configured
    notification channels. If the policy is defined through the console, then the
    policy trigger field is used, while if the policy is defined through the API,
    then the combiner field is used.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 指标阈值条件将定义具体的值。如果特定的指标值超过或低于阈值（根据策略定义的方式），则会触发警报，并通过配置的通知渠道通知我们。如果策略是通过控制台定义的，则使用策略触发字段；如果策略是通过
    API 定义的，则使用组合器字段。
- en: Alternatively, to define an alert policy based on a metric threshold condition,
    you can define an alert policy based on a metric absence condition. A metric absence
    condition is defined as a condition where time series data doesn't exist for a
    metric for a specific duration of time.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，要基于指标阈值条件定义警报策略，也可以基于指标缺失条件来定义警报策略。指标缺失条件定义为某个特定时间段内某个指标的时间序列数据不存在的条件。
- en: Important note – The alignment period is a lookback interval
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明 – 对齐周期是一个回顾间隔。
- en: The alignment period is a lookback interval from a particular point in time.
    For example, if the alignment period is 5 minutes, then at 1:00 P.M., the alignment
    period contains the samples received between 12:55 P.M. and 1:00 P.M. At 1:01
    P.M., the alignment period slides 1 minute and contains the samples received between
    12:56 P.M. and 1:01 P.M.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 对齐周期是从某个特定时间点回顾的间隔。例如，如果对齐周期是 5 分钟，那么在下午 1:00 时，对齐周期包含了下午 12:55 到 1:00 之间接收到的样本。在下午
    1:01 时，对齐周期滑动 1 分钟，并包含下午 12:56 到 1:01 之间接收到的样本。
- en: The next section describes the available notification channels that are used
    to send information that's specific to firing alerts.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将描述用于发送与触发警报相关的特定信息的可用通知渠道。
- en: Configuring notification channels
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置通知渠道。
- en: If an alerting policy violates the specified condition, then an incident gets
    created with an Open status. Information about the incident can be sent to one
    or more notification channels. On receipt of the notification, the operations
    team can acknowledge the incident through the console. This changes the status
    of the incident to Acknowledged. This is an indication that the event is being
    inspected. The incident eventually goes to Closed status if either the conditions
    are no longer being violated, or no data is received for the specific incident
    over the course of the next 7 days.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如果警报策略违反了指定的条件，则会创建一个状态为“打开”的事件。关于该事件的信息可以发送到一个或多个通知渠道。收到通知后，操作团队可以通过控制台确认该事件。这将把事件的状态更改为“已确认”。这表示事件正在被检查。如果在接下来的
    7 天内条件不再被违反，或者该事件没有收到数据，则该事件最终将变为“已关闭”状态。
- en: 'The supported notification channels are as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 支持的通知渠道如下：
- en: '**Mobile Devices**: Mobile devices should be registered via the incidents section
    of the Cloud Console Mobile App.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**移动设备**：应通过 Cloud Console 移动应用的事件部分注册移动设备。'
- en: '**PagerDuty Services**: Requires a service key to authenticate and authorize.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PagerDuty 服务**：需要一个服务密钥来进行身份验证和授权。'
- en: '`pagerduty.com` and the respective API key to authenticate and authorize.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pagerduty.com` 及相应的 API 密钥用于身份验证和授权。'
- en: '**Slack**: Prompts the user to authenticate and authorize to a Slack channel
    through a custom URL, and then prompts the user to provide the Slack channel''s
    name.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Slack**：提示用户通过自定义 URL 进行身份验证和授权到 Slack 渠道，然后提示用户提供 Slack 渠道的名称。'
- en: '**Webhooks**: Requires the endpoint URL, along with optional usage of HTTP
    Basic Auth.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Webhooks**：需要端点 URL，并可选择使用 HTTP Basic Auth。'
- en: '**Email**: Requires an email address to receive notifications when a new incident
    is created.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电子邮件**：需要一个电子邮件地址，以便在创建新事件时接收通知。'
- en: '**SMS**: Requires a phone number to receive notifications.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**短信**：需要一个电话号码来接收通知。'
- en: '`service-[PROJECT_NUMBER]@gcp-sa-monitoring-notification.iam.gserviceaccount.com`.
    The `pubsub.publisher` role should be added to the preceding service account to
    configure alert notifications via Cloud Pub/Sub.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`service-[PROJECT_NUMBER]@gcp-sa-monitoring-notification.iam.gserviceaccount.com`。应将
    `pubsub.publisher` 角色添加到上述服务帐户，以通过 Cloud Pub/Sub 配置警报通知。'
- en: This concludes this section on alerting, where we looked at configuring an alerting
    policy and notification channels. The next section introduces the Cloud Monitoring
    agent.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 本节关于警报的内容到此结束，我们查看了如何配置警报策略和通知渠道。下一节介绍云监控代理。
- en: Monitoring agent
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控代理
- en: Cloud Monitoring provides a lot of metrics out of the box, without any additional
    configuration, such as CPU utilization, network traffic, and more. However, more
    granular metrics such as memory usage, network traffic, and so on can be collected
    from unmanaged VMs or from third-party applications using an optional `collectd`
    daemon (daemon refers to a program that runs in the background) to collect system
    statistics from various sources, including operating systems, applications, logs,
    and external devices.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 云监控提供许多默认指标，无需任何额外配置，例如 CPU 利用率、网络流量等。然而，更多细粒度的指标，如内存使用、网络流量等，可以通过可选的 `collectd`
    守护进程（守护进程是指在后台运行的程序）从未管理的虚拟机或第三方应用程序收集，来收集来自操作系统、应用程序、日志和外部设备的系统统计信息。
- en: The Monitoring agent can be installed on unmanaged GCE VMs or AWS EC2 VMs. Other
    Google compute services, such as App Engine, Cloud Run, and Cloud Functions, have
    built-in support for monitoring and do not require you to explicitly install the
    Monitoring agent. GKE also has built-in support for monitoring and can be enabled
    for new or existing clusters via *Cloud Operations for GKE*, an integrated monitoring
    and logging solution.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 监控代理可以安装在未管理的 GCE 虚拟机或 AWS EC2 虚拟机上。其他 Google 计算服务，如 App Engine、Cloud Run 和
    Cloud Functions，内置支持监控，无需显式安装监控代理。GKE 也内置支持监控，并可以通过 *Cloud Operations for GKE*
    启用，后者是一个集成的监控和日志记录解决方案，可以在新建或现有集群中启用。
- en: 'Conceptually, you must follow this process to install/configure a Monitoring
    agent on unmanaged VMs:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，您必须遵循此过程，在未管理的虚拟机上安装/配置监控代理：
- en: Add the agent's package repository via a provided script that detects the Linux
    distribution being run on the VM and configures the repository accordingly.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供的脚本添加代理的包存储库，该脚本检测虚拟机上运行的 Linux 发行版并相应地配置存储库。
- en: Install the Monitoring agent using the `stackdriver-agent` agent for the latest
    version or by using `stackdriver-agent-version-number` for a very specific version.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `stackdriver-agent` 代理安装监控代理以获取最新版本，或者使用 `stackdriver-agent-version-number`
    安装特定版本。
- en: Restart the agent for the installed agent to come into effect.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重启代理以使已安装的代理生效。
- en: The step-by-step process of installing a Logging agent on a single VM/GCE VM/AWS
    EC2 instance can be found at [https://cloud.google.com/monitoring/agent/installation](https://cloud.google.com/monitoring/agent/installation).
    This completes our brief overview of the Monitoring agent. The next subsection
    mentions the possible access controls with respect to Cloud Monitoring.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个虚拟机/GCE 虚拟机/AWS EC2 实例上安装日志代理的逐步过程可以在 [https://cloud.google.com/monitoring/agent/installation](https://cloud.google.com/monitoring/agent/installation)
    中找到。至此，我们简要介绍了监控代理。下一小节提到了与云监控相关的可能访问控制。
- en: Cloud Monitoring access controls
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云监控访问控制
- en: 'The following table summarizes the critical IAM roles required to access or
    perform actions on Cloud Monitoring:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格总结了访问或执行云监控操作所需的关键 IAM 角色：
- en: '![Groups – A collection of resources that is defined as a Monitoring Group'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '![组 – 定义为监控组的资源集合'
- en: '](img/B15587_10_Table_01.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_10_Table_01.jpg)'
- en: Groups – A collection of resources that is defined as a Monitoring Group
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 组 – 定义为监控组的资源集合
- en: Note
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Cloud Monitoring allows you to create a monitoring group. This is a convenient
    way to view the list of GCP resources, events, incidents, and visualizations as
    key metrics from a centralized place. A monitoring group is created by defining
    one or more criteria either against the name, resource type, tag, security group,
    cloud project, or region. If multiple criteria are specified, then an OR/AND operator
    can be specified.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 云监控允许您创建监控组。这是查看 GCP 资源、事件、事故和可视化的关键指标的便捷方式，所有信息集中展示。监控组是通过定义一个或多个标准来创建的，这些标准可以是名称、资源类型、标签、安全组、云项目或区域。如果指定多个标准，则可以使用
    OR/AND 运算符。
- en: This concludes our deep dive into Cloud Monitoring and its respective constructs,
    such as Workspace, dashboards, Metrics explorer, uptime checks, alerting policies,
    and access controls. The next section elaborates on another GCP construct that's
    part of Cloud Operations and focuses on logging; that is, Cloud Logging.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分内容总结了我们对云监控及其相关构件的深入探讨，如工作区、仪表板、指标探查器、正常运行时间检查、告警策略和访问控制。接下来的部分将详细介绍另一个属于云操作的GCP构件，专注于日志记录；即，云日志。
- en: Cloud Logging
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云日志
- en: A log is defined as a record of a status or event. Logging essentially describes
    what happened and provides data so that we can investigate an issue. It is critical
    to be able to read and parse logs across a distributed infrastructure involving
    multiple services and products. **Cloud Logging** is a GCP service that allows
    you to store, search, analyze, monitor, and alert others about logging data and
    events from Google Cloud and AWS, third-party applications, or custom application
    code. The information in the log entry is structured as a payload. This payload
    consists of information related to a timestamp, a resource that the log entry
    applies to, and a log name. The maximum size of a log entry is 256 KB. Each log
    entry indicates the source of the resource, labels, namespaces, and status codes.
    Cloud Logging is also the source of input for other Cloud Operations services,
    such as Cloud Debug and Cloud Error Reporting.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 日志被定义为状态或事件的记录。日志记录本质上描述了发生了什么，并提供了数据，以便我们可以调查问题。在涉及多个服务和产品的分布式基础设施中，能够读取和解析日志至关重要。**云日志**是一个GCP服务，允许你存储、搜索、分析、监控以及针对来自Google
    Cloud和AWS、第三方应用程序或自定义应用程序代码的日志数据和事件发送告警。日志条目中的信息以负载的形式结构化。该负载包含与时间戳、日志条目适用的资源以及日志名称相关的信息。日志条目的最大大小为256
    KB。每个日志条目都会指示资源的来源、标签、命名空间和状态码。云日志还是其他云操作服务（如云调试和云错误报告）的输入来源。
- en: 'The following are the key features of Cloud Logging:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是云日志的主要特性：
- en: '**Audit Logs**: Logs are captured and categorized as Admin Activity, Data Access,
    System Event, and Access Transparency Logs, with each category having a default
    retention period.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**审计日志**：日志被捕获并分类为管理员活动、数据访问、系统事件和访问透明度日志，每个类别都有默认的保留期。'
- en: '**Logs Ingestion**: Logs can be ingested from many sources, including GCP services
    and on-premises or external cloud providers, by using the Cloud Logging API or
    through logging agents.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志摄取**：可以通过使用云日志API或通过日志代理从许多来源摄取日志，包括GCP服务、内部部署或外部云提供商。'
- en: '**Logs Explorer**: Logs can be searched for and analyzed through a guided filter
    configuration or flexible query language, resulting in effective visualization.
    Results can also be saved in JSON format.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志探查器**：可以通过引导式过滤配置或灵活的查询语言搜索和分析日志，从而实现有效的可视化。结果还可以以JSON格式保存。'
- en: '**Logs-based Metrics**: Metrics can be created from log data and can be added
    to charts/dashboards using the Metrics explorer.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于日志的度量**：可以从日志数据中创建度量，并通过指标探查器将其添加到图表/仪表板中。'
- en: '**Logs Alerting**: Alerts can be created based on the occurrence of log events
    and based on the created logs-based metrics.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志告警**：可以根据日志事件的发生以及基于日志创建的度量指标来创建告警。'
- en: '**Logs Retention**: Logs can be retained for a custom retention period based
    on user-defined criteria.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志保留**：日志可以根据用户定义的标准保留自定义的保留期。'
- en: '**Logs Export**: Logs can be exported to Cloud Storage for archival, BigQuery
    for advanced analytics, Pub/Sub for event-based processing using GCP services,
    user-defined cloud logging sinks, or to initiate external third-party integrations
    so that you can export using services such as Splunk.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志导出**：可以将日志导出到云存储进行归档，导入到BigQuery进行高级分析，通过Pub/Sub进行基于事件的处理，使用GCP服务进行用户定义的云日志接收器，或启动外部第三方集成，以便通过Splunk等服务导出。'
- en: Cloud Logging features will be discussed in detailed in the upcoming subsections,
    starting with Audit Logs.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 云日志的功能将在接下来的子章节中详细讨论，从审计日志开始。
- en: Audit Logs
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 审计日志
- en: '**Cloud Audit Logs** is a fundamental source for finding out about certain
    parts of a project (*who did what, where, and when?*). Cloud Audit Logs maintains
    logs for each project (including folder- and organization-level information).
    Cloud Audit Logs can be categorized into various categories. Let''s take a look.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**云审计日志**是了解项目中某些部分的基础来源（*谁做了什么，在哪里，何时做的？*）。云审计日志为每个项目（包括文件夹和组织级别的信息）维护日志。云审计日志可以分为不同的类别。让我们来看一下。'
- en: Admin activity logs
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理活动日志
- en: '**Admin activity logs** are specific to any administrative actions that modify
    the configuration or metadata of resources. Examples for admin activity logs include,
    but not are limited to, the following:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '**管理员活动日志**特指任何修改资源配置或元数据的管理操作。管理员活动日志的示例包括但不限于以下内容：'
- en: Setting or changing permissions of a cloud storage bucket
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置或更改云存储存储桶的权限
- en: Assigning /unassigning IAM roles
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配/取消分配 IAM 角色
- en: Changing any properties of a resource, such as tags/labels
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改资源的任何属性，如标签/标签
- en: Creating/deleting resources for GCE, GKE, or Cloud Storage
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建/删除 GCE、GKE 或 Cloud Storage 资源
- en: 'The following screenshot shows the admin activity logs for when a GCE VM or
    bucket was created. The easiest way to access these activity logs is from the
    **Activity** tab on the GCP console home page. This pulls a live feed of the admin
    activity logs but does not include data access logs by default:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了创建 GCE VM 或存储桶时的管理员活动日志。访问这些活动日志的最简单方法是从 GCP 控制台首页的**活动**选项卡查看。这会拉取管理员活动日志的实时流，但默认不包括数据访问日志：
- en: '![Figure 10.9 – Admin activity logs'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.9 – 管理员活动日志'
- en: '](img/B15587_10_09.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_10_09.jpg)'
- en: Figure 10.9 – Admin activity logs
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9 – 管理员活动日志
- en: The next subsection provides an overview of an audit log category specific to
    *data access*.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 下一小节提供了与*数据访问*相关的审计日志类别概述。
- en: Data access logs
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据访问日志
- en: '**Data access logs** are useful for reading the configuration or metadata of
    resources. This also includes user-level API calls, which read or write resource
    data. Data access audit logs need to be enabled explicitly (except for Big Query),
    and this can be controlled by specifying the services whose audit logs should
    be captured. In addition, data access logs tied to actions performed by a specific
    set of users or groups can be exempted, thus providing granular control. Data
    access logs can be further classified into three subtypes:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据访问日志**对于读取资源的配置或元数据非常有用。它还包括用户级别的 API 调用，这些调用会读取或写入资源数据。数据访问审计日志需要显式启用（Big
    Query 除外），并可以通过指定应捕获审计日志的服务来进行控制。此外，数据访问日志还可以针对由特定用户或用户组执行的操作进行豁免，从而提供细粒度的控制。数据访问日志可以进一步细分为三种子类型：'
- en: '**Admin read**: Read attempts on service metadata or configuration data. An
    example of this is listing the available buckets or listing the nodes within a
    cluster.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理员读取**：对服务元数据或配置数据的读取尝试。例如，列出可用的存储桶或列出集群中的节点。'
- en: '**Data read**: Read attempts of data within a service. An example of this includes
    listing the objects within a bucket.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据读取**：在服务内的数据读取尝试。例如，列出存储桶中的对象。'
- en: '**Data write**: Write attempts of data to a service. An example of this includes
    creating an object within a bucket.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据写入**：向服务写入数据的尝试。例如，在存储桶中创建一个对象。'
- en: 'The following is a screenshot of granular data access being configured for
    an individual GCP service from IAM – the **Audit Logs** UI:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过 IAM 配置单个 GCP 服务的详细数据访问的截图 —— **审计日志** UI：
- en: '![Figure 10.10 – Configuring IAM Audit Logs for a service'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.10 – 配置服务的 IAM 审计日志'
- en: '](img/B15587_10_10.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_10_10.jpg)'
- en: Figure 10.10 – Configuring IAM Audit Logs for a service
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.10 – 配置服务的 IAM 审计日志
- en: The preceding screenshot also shows the option to configure **Exempted Users**.
    This option allows you to exempt audit logs from being generated for certain users,
    as configured. Data access logs can be viewed either through the **Activity**
    tab of the GCP home page, where **Activity Type** is **Data Access**, or through
    the **Logs Explorer** UI (discussed later). The next subsection provides an overview
    of an audit log category specific to system events.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 上述截图还显示了配置**豁免用户**的选项。此选项允许您豁免某些用户的审计日志生成，具体取决于配置。数据访问日志可以通过 GCP 首页的**活动**选项卡查看，其中**活动类型**为**数据访问**，或者通过**日志浏览器**UI查看（稍后会讨论）。下一小节提供了与系统事件相关的审计日志类别概述。
- en: System event logs
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 系统事件日志
- en: '**System event logs** are used when changes have been made to resources by
    Google systems or services. They are not specific to user actions on the resources.
    Examples of system event logs include, but are not limited to, the following:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '**系统事件日志**在 Google 系统或服务对资源进行更改时使用。它们不是特定于用户对资源的操作。系统事件日志的示例包括但不限于以下内容：'
- en: Automatically restarting or resetting Compute Engine
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动重启或重置计算引擎
- en: System maintenance operations, such as migration events, which are performed
    by Compute Engine to migrate applications to a different host
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统维护操作，例如迁移事件，由计算引擎执行，以将应用迁移到不同的主机。
- en: The next subsection provides an overview on an audit log category specific to
    access transparency.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 下一小节提供了一个关于访问透明度的审计日志类别概述。
- en: Access transparency logs
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 访问透明度日志
- en: '**Access transparency logs** are used by Google personnel when they''re accessing
    a user''s/customer''s content. This situation typically arises when Google''s
    support team is working on a customer issue (such as a specific service not working
    as expected or an outage) and, as a result, needs to access the customer''s project.
    This category of logs is critical if you wish to follow legal and regulatory obligations.
    In addition, you can trace events to look back on the actions that have been performed
    by Google support personnel. Access transparency logs can be enabled by contacting
    Google support and are available for customer support levels, excluding individual
    accounts. An example of access transparency logs could be the logs that are accessed
    by the support personnel while trying to resolve a support issue for a VM instance.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '**访问透明度日志**是Google人员在访问用户/客户内容时使用的日志。通常这种情况发生在Google的支持团队在处理客户问题（例如某个服务未按预期工作或发生故障）时，因而需要访问客户的项目。如果你希望遵循法律和监管义务，这类日志至关重要。此外，你还可以追踪事件，回溯Google支持人员执行的操作。通过联系Google支持，你可以启用访问透明度日志，并且它们适用于客户支持级别，个人账户除外。一个例子是，支持人员在尝试解决VM实例的支持问题时访问的日志。'
- en: Policy denied logs
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 策略拒绝日志
- en: '**Policy denied logs** are logs that are captured when access is denied by
    a Google Cloud service to either a user or service account. Policy denied logs
    can be excluded from ingestion into Cloud Logging through Logs Exclusions.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '**策略拒绝日志**是指当Google Cloud服务拒绝对某个用户或服务账户的访问时所捕获的日志。可以通过日志排除功能排除这些日志的摄取。'
- en: 'This completes this section on audit logs, where we provided an overview of
    the various subcategories. Before proceeding to the next section, take a look
    at the following table, which lists the IAM roles specific to accessing logs:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分关于审计日志的内容已完成，我们提供了各种子类别的概述。在进入下一部分之前，先看一下下面的表格，表格列出了特定于访问日志的IAM角色：
- en: '![](img/B15587_10_Table_02.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15587_10_Table_02.jpg)'
- en: The next section will explain how logs are ingested into Cloud Logging from
    multiple sources.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 下一部分将解释如何从多个源将日志摄取到Cloud Logging中。
- en: Logs ingestion, routing, and exporting
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 日志摄取、路由和导出
- en: Cloud Logging supports logs ingestion from multiple sources, such as audit logs,
    service logs, application logs, syslogs, and platform logs. These logs are sent
    to the **Cloud Logging API**. The Cloud Logging API forwards the incoming log
    entries to a component called **Logs Router**. Logs Router is fundamentally responsible
    for routing logs to their respective destinations.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: Cloud Logging支持从多个源摄取日志，例如审计日志、服务日志、应用日志、系统日志和平台日志。这些日志被发送到**Cloud Logging API**。Cloud
    Logging API将传入的日志条目转发给一个名为**日志路由器**的组件。日志路由器的基本职能是将日志路由到其相应的目标。
- en: These destinations can be grouped into four possible categories. Logs Router
    will check the incoming logs against existing rules to determine whether to ingest
    (store), export, or exclude them, and will route the logs to one of the four destination
    categories.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这些目标可以分为四个可能的类别。日志路由器将检查传入的日志与现有规则，决定是否摄取（存储）、导出或排除这些日志，并将日志路由到四个目标类别中的一个。
- en: 'These destination categories are as follows:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这些目标类别如下：
- en: '**_Required log bucket**: This is the primary destination for admin activity,
    system event, and access transparency logs. There are no charges associated with
    these logs and this bucket cannot be modified or deleted.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**_必需的日志存储桶_**：这是管理活动、系统事件和访问透明度日志的主要存储目标。这些日志不收费，并且该存储桶不能被修改或删除。'
- en: '`_Default` log sink can be disabled.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_默认`日志接收器可以被禁用。'
- en: '`_Required` log bucket and the `_Default` log bucket. The process of writing
    logs to user-managed log sinks can also be characterized as **Log Exports** (if
    the intent is to export for external processing) or **Log Retention** (if the
    intent is to export to retain logs for a longer period from a compliance perspective).'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_Required` 日志桶和 `_Default` 日志桶。将日志写入用户管理的日志汇聚点的过程也可以被描述为 **日志导出**（如果目的是导出进行外部处理）或
    **日志保留**（如果目的是从合规性角度导出以长期保留日志）。'
- en: '`_Default` log bucket. In other words, logs that qualify for the `_Required`
    log bucket can never be excluded. If any of the log exclusion filters match with
    entries that qualify for the `_Default` log bucket, then the entries will be excluded
    and never be saved.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_Default` 日志桶。换句话说，符合 `_Required` 日志桶条件的日志永远不能被排除。如果任何日志排除过滤器与符合 `_Default`
    日志桶条件的条目匹配，则这些条目将被排除并且永远不会被保存。'
- en: Tip – What are log buckets?
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示 – 什么是日志桶？
- en: 'Log buckets are a form of object storage in Google Cloud projects that are
    used by Cloud Logging to store and organize logs data. All logs generated in the
    project are stored in these logs'' buckets. Cloud Logging automatically creates
    two buckets in each project: `_Required` and `_Default`. `_Required` represents
    an audit bucket, which has a 400-day retention period, while `_Default` represents
    the *everything else* bucket, which has a 30-day retention period. In addition,
    a user can create custom logging buckets, also known as user-managed log sinks.'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 日志桶是 Google Cloud 项目中一种对象存储形式，用于通过 Cloud Logging 存储和组织日志数据。项目中生成的所有日志都存储在这些日志桶中。Cloud
    Logging 会在每个项目中自动创建两个桶：`_Required` 和 `_Default`。`_Required` 代表审核桶，其保留期为 400 天，而
    `_Default` 代表*其他所有*桶，其保留期为 30 天。此外，用户还可以创建自定义日志桶，也称为用户管理的日志汇聚点。
- en: The log bucket per project can be viewed via the **Logs Storage UI** in Cloud
    Logging. Additional actions such as creating a user-defined log bucket and a usage
    alert can also be initiated from the Logs Storage UI.
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每个项目的日志桶可以通过 **Logs Storage UI** 在 Cloud Logging 中查看。也可以从 Logs Storage UI 发起其他操作，例如创建用户定义的日志桶和使用警报。
- en: 'The following diagram illustrates how logs are ingested from multiple sources
    via the Cloud Logging API and, subsequently, routed by Logs Router to possible
    destinations:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了如何通过 Cloud Logging API 从多个来源接收日志，并随后由日志路由器将其路由到可能的目标：
- en: '![Figure 10.11 – Illustrating logs ingesting and logs routing'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.11 – 描述日志接收和日志路由'
- en: '](img/B15587_10_11.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15587_10_11.jpg)'
- en: Figure 10.11 – Illustrating logs ingesting and logs routing
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.11 – 描述日志接收和日志路由
- en: 'There are three steps we must follow to export logs:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 导出日志需要遵循三个步骤：
- en: Create a sink.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个汇聚点。
- en: Create a filter that represents the criteria to identify logs to export.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个表示导出日志筛选标准的过滤器。
- en: Create a destination – Cloud Storage Bucket, BigQuery, or Pub/Sub topics.
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建目标 – Cloud Storage 桶、BigQuery 或 Pub/Sub 主题。
- en: IAM roles to Create/Modify/View a Sink
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创建/修改/查看汇聚点的 IAM 角色
- en: The Owner or Logging/Logs Configuration Writer role is required to create or
    modify a sink. The Viewer or Logging/Logs Viewer role is required to view existing
    sinks. The Project Editor role does not have access to create/edit sinks.
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创建或修改汇聚点需要拥有 Owner 或 Logging/Logs Configuration Writer 角色。查看现有汇聚点需要拥有 Viewer
    或 Logging/Logs Viewer 角色。Project Editor 角色无法创建或编辑汇聚点。
- en: To summarize, logs can originate from multiple sources, such as on-premises,
    Google Cloud, or a third-party cloud service. These logs are injected into Cloud
    Logging through the Cloud Logging API, which are then sent to Logs Router. Logs
    Router, which is based on configured filters, will route the logs to logged sinks
    (the `_Required` or `_Default` log bucket). Additionally, a copy of the logs can
    be sent to user-managed sinks based on the configured filter criteria, where the
    destination can either be Cloud Storage, BigQuery, or Pub/Sub. Log export can
    be used for multiple purposes, such as long-term retention for compliance reasons
    (using Cloud Storage), Big Data analysis (using BigQuery), or to stream to other
    applications (using Pub/Sub). If these logs are sent to the Pub/Sub messaging
    service, then they can be exported outside Google Cloud to third-party tools such
    as Splunk, Elastic Stack, or SumoLogic. It is important to note that configured
    log sinks for export will only capture new logs, since the export was created
    but does not capture the previous logs or backfill.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: How to export logs across folders/organizations
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: Logs can be exported from all projects inside a specific folder or organization.
    This can currently only be done through the command line using the gcloud logging
    sink's `create` command. Apart from the sink's name, destination, and log filter,
    the command should include the `--include-children` flag and either the `--folder`
    or `--organization` attribute, along with its respective values.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: This completes this subsection on logs ingestion, routing, and exporting. The
    following subsection summarizes log characteristics across log buckets in the
    form of a table for ease of understanding.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing log characteristics across log buckets
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Each log type is destined to a specific Cloud Logging bucket. In addition,
    every log type has specific characteristics in terms of the minimum IAM roles
    required to access the logs, the default retention period, and the ability to
    configure a custom retention period. The following table details the respective
    information:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15587_10_Table_03.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
- en: All other logs
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: This refers to either user logs generated by applications through a Logging
    agent or platform logs generated by GCP services or VPC Flow Logs or Firewall
    Logs.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the preceding table, it is important to note the following:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: System event logs are system initiated, whereas admin activity, data access,
    and access transparency logs are user initiated.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Admin activity and system event logs record the changes in the configuration
    of resources, whereas data access logs record the changes that were made inside
    the record.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Admin activity, system event, and access transparency logs are always enabled.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This completes our overview on logs ingestion. The next topic focuses on the
    **Logs Explorer** UI, through which users can explore ingested logs.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: Logs Explorer UI
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Logs Explorer UI** is the centralized way to view logs that have been ingested
    into Cloud Logging via the Cloud Logging API, and ultimately routed via Cloud
    Router to either Cloud Logging buckets or user-managed sinks. The UI allows us
    to filter logs by writing advanced search queries, visualize the time series data
    by configuring time windows, and perform critical actions to create log-based
    metrics or create users. The UI consists of multiple options and sections, as
    shown in the following screenshot:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.12 – Logs Explorer UI'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_12.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.12 – Logs Explorer UI
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: 'To filter Cloud Audit Logs through the Logs Explorer UI, select the following
    options for the **Log Name** field:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '`cloudaudit.googleapis.com%2Factivity`'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cloudaudit.googleapis.com%2Fdata_access`'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cloudaudit.googleapis.com%2Fsystem_event`'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a look at some key important information with respect to navigating
    the options in the Logs Explorer UI.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Query builder
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This section constructs queries to filter logs. Queries can be expressed in
    query builder language by choosing an appropriate combination of field and value,
    as shown in the following screenshot. The user can provide input in two ways:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: By choosing options from the available drop-down menus with respect to **Resource**,
    **Log Name**, and **Severity**. This is the basic query interface.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By choosing fields from the **Log Fields** section, starting by either selecting
    the **Resource** type or the **Severity** type. This is the advanced query interface:'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.13 – Query builder section under Logs Explorer'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_13.jpg)'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.13 – Query builder section under Logs Explorer
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Query results
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This section displays the results that match the filter criteria defined within
    query builder. If there is a match, the results are displayed in one or more rows.
    Each row represents a log entry, as shown here:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.14 – Query results section'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_14.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.14 – Query results section
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Log entries
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Each query result that''s returned is a log entry that''s displayed with a
    timestamp and summary text information. When expanded, the log entry displays
    further details in a JSON payload format. The JSON payload has multiple fields
    and can be elaborated on using the **Expand nested fields** option. Additionally,
    the user can copy the payload to a clipboard or share the specific payload by
    copying the shareable link, as shown here:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.15 – Viewing the JSON payload for a log entry'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_15.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.15 – Viewing the JSON payload for a log entry
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: Payload-specific actions
  id: totrans-305
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are multiple options that perform actions on a specific payload on a
    specific field, as shown in the following screenshot. These are as follows:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '**Show matching entries**: Adds the selected key-value pair from the JSON payload
    to the existing filter criteria and shows matching entries within the configured
    time window.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hide matching entries**: Adds the selected key-value pair from the JSON payload
    to the existing filter criteria in a negation form and removes the matching entries
    from user display, within the configured time window.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Add field to summary line**: Adds the selected key to the summary section:'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.16 – Possible payload-specific actions for a specific field'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_16.jpg)'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.16 – Possible payload-specific actions for a specific field
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Page layout
  id: totrans-313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This option allows users to configure the page layout and optionally include
    **Log Fields** and/or a **Histogram**. **Query builder** and **Query results**
    are mandatory sections and cannot be excluded:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.17 – Options under the PAGE LAYOUT section'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_17.jpg)'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.17 – Options under the PAGE LAYOUT section
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: Actions (to perform on a query filter)
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Actions allows user to operate on the potential results from the query filter
    definition. This includes **Create Metrics**, **Download Logs**, and **Create
    Sinks**:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.18 – Possible actions you can perform on a query filter'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_18.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.18 – Possible actions you can perform on a query filter
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: This completes this section on Logs Explorer and all the possible UI options
    for filtering and analyzing logs. The next section provides an overview of *logs-based
    metrics*.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: Logs-based metrics
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Logs-based metrics** are Cloud Monitoring metrics that are created based
    on the content of the log entries. They can be extracted from both included and
    excluded logs. As matching log entries are found, the information that''s tied
    to the metrics is built over time. This forms the required time series data that
    is critical to metrics. Logs-based metrics are used in creating Cloud Monitoring
    charts and can also be added to Cloud Monitoring dashboards.'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: To use logs-based metrics, a Google Cloud project is required with billing enabled.
    In addition, logs-based metrics are recorded for matching log entries, once the
    metric has been created. Metrics are not backfilled for log entries that are already
    in Cloud Logging.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: 'Logs-based metrics can be classified as either of the following:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: System (logs-based) metrics
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-defined (logs-based) metrics
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these logs-based metrics will be covered in the upcoming subsections.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: System (logs-based) metrics
  id: totrans-332
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**System (logs-based) metrics** are out-of-the-box, predefined metrics from
    Google and are very specific to the current project. These metrics record the
    number of events that occur within a specific period. A list of available system
    (logs-based) metrics can be found under the **Logs-based Metrics** UI in the **Logging**
    section of Cloud Operations. Examples include the following:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: '**byte_count**: Represents the total number of received bytes in log entries'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**excluded_byte_count**: Represents the total number of excluded bytes from
    log entries'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The user can create an alert from a predefined metric or view the details of
    the metric, along with its current values, in Metrics explorer:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.19 – System (logs-based) metrics and their qualifying actions'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_19.jpg)'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.19 – System (logs-based) metrics and their qualifying actions
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: The next section provides an overview of user-defined metrics.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: User-defined (logs-based) metrics
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**User-defined (logs-based) metrics**, as the name suggests, are defined by
    the user and are specific to the project where the user configures these metrics.
    These metrics can either of the **Counter** or **Distribution** type:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: '**Counter**: Counts the number of log entries that match on a query'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distribution**: Accumulates numeric data from log entries that match on a
    query'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Users can create a user-defined metric either from **Logs-based Metrics UI**
    via the **Create Metric** action or the **Logs Explorer UI** via the actions menu
    above the query results. Once the user initiates these actions, they get to choose
    the type of metric in the Metric Editor panel; that is, **Counter** or **Distribution**.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, the user will have to configure fields such as the metric''s name,
    description, and any optional labels and units. For a `s`, `ms`, and so on:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.20 – Creating a logs-based metric'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_20.jpg)'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.20 – Creating a logs-based metric
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: More details on creating a distribution metric can be found at [https://cloud.google.com/logging/docs/logs-based-metrics/distribution-metrics](https://cloud.google.com/logging/docs/logs-based-metrics/distribution-metrics).
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: Access control for logs-based metrics
  id: totrans-351
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following table displays the critical IAM roles required, along with their
    minimal permissions (in accordance with the principle of least privilege), to
    access or perform actions related to logs-based metrics:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15587_10_Table_04.jpg)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
- en: The following section will conclude this section on Cloud Logging by exploring
    the available network-based log types on Google Cloud.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: Network-based log types
  id: totrans-355
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two network-based log types that primarily capture logs related to
    network interactions. These are as follows:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: VPC Flow Logs
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Firewall logs
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's look at them in detail.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: VPC Flow Logs
  id: totrans-360
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**VPC Flow Logs** capture real-time network activity (incoming/outgoing) against
    VPC resources on an enabled subnet. Flow logs capture activity specific to the
    TCP/UDP protocols and are enabled at a VPC subnet level. Flow logs generate a
    large amount of chargeable log files, but they don''t capture 100% of traffic;
    instead, traffic is sampled at 1 out of 10 packets and cannot be adjusted. Flow
    logs are used for Network Monitoring – to understand traffic growth from a forecasting
    capacity and for forensics – to evaluate network traffic (in/out) in terms of
    traffic source. Flow logs can be exported for analysis using BigQuery. In the
    case of a Shared VPC – where multiple service projects connect to a common VPC
    – flow logs flow into the host project, not the service projects.'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: Firewall logs
  id: totrans-362
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Firewall logs** capture the effects of a specific firewall rule in terms
    of the traffic that''s allowed or denied by that firewall rule. Similar to VPC
    Flow Logs, firewall logs capture TCP/UDP traffic only and are used for auditing,
    verifying, and analyzing the effect of the configured rules. Firewall logs can
    be configured for an individual firewall rule. Firewall rules are applied for
    the entire VPC and cannot be applied at a specific subnet level like flow logs.
    Firewall logs attempt to capture every firewall connection attempt on a best effort
    basis. Firewall logs can also be exported to BigQuery for further analysis.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: 'Every VPC has a set of hidden implied pre-configured rules, with the lowest
    priority being `65535`. Firewall rules can have a priority between `0` and `65535`
    (`0` implies highest, while `65535` implies lowest). These are as follows:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: '`deny all ingress`: By default, this denies all incoming traffic to the VPC.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`allow all egress`: By default, this allows all outgoing traffic from the VPC.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, firewall logs cannot be enabled for the hidden rules. So, to capture
    the incoming traffic that is being denied or the outgoing traffic that is being
    allowed, it is recommended to explicitly configure a firewall rule for the denied/allowed
    traffic with an appropriate priority and enable firewall logs on that rule.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: This completes this subsection on network-based log types, where we introduced
    VPC Flow Logs and firewall logs.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: Logging agent
  id: totrans-369
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `fluentd` – an open source log or data collector. The Logging agent can
    be installed on unmanaged GCE VMs or AWS EC2 VMs. Other Google Compute services
    such as App Engine, Cloud Run, and Cloud Functions have built-in support for logging
    and do not require you to explicitly install the Logging agent. GKE also has built-in
    support for logging and can be enabled for new or existing clusters by *Cloud
    Operations for GKE*, an integrated monitoring and logging solution.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: 'To configure the Logging agent, you must configure an additional configuration
    file, but a single configuration file acts as a catch all for capturing multiple
    types of logs, including OS logs and third-party application logs such as Apache,
    MySQL, Nginx, RabbitMQ, and so on. However, there are scenarios where the configuration
    file of the agent needs to be modified so that we can modify the logs. These are
    as follows:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: When reformatting log fields, either the order or combine multiple fields into
    one
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When removing any **Personally Identifiable Information** (**PII**) or sensitive
    data
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When modifying records with `fluentd` plugins such as `filter_record_transformer`,
    a plugin for adding/modifying/deleting fields from logs before they're sent to
    Cloud Logging
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Conceptually, the following is the process of installing/configuring an agent
    on a GCE VM:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: Add the agent's package repository via a provided script that detects the Linux
    distribution being run on the VM and configures the repository accordingly.
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install the Logging agent and install the `google-fluentd-catch-all-config`
    agent for unstructured logging and the `google-fluentd-catch-all-config-structured`
    agent for structured logging.
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Restart the agent for the installed agents to come into effect.
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The step-by-step process of installing a Logging agent on a single VM/GCE VM/AWS
    EC2 instance can be found at [https://cloud.google.com/logging/docs/agent/installation](https://cloud.google.com/logging/docs/agent/installation).
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: This completes our high-level overview of logging agents. Subsequently, this
    also completes the section on Cloud Logging, where we looked at features such
    as audit log types, logs ingestion, the Logs Explorer UI, logs-based metrics,
    and access controls. The next section deep dives into *Cloud Debugger*, a GCP
    construct from Cloud Operations that can potentially inspect a production application
    by taking a snapshot of it, without stopping or slowing down.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Debugger
  id: totrans-381
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Cloud Debugger** allows us to inspect the state of a running application
    in real time. Cloud Debugger doesn''t require the application to be stopped during
    this process and doesn''t slow it down, either. Users can capture the call stack
    and variables at any location in the source code. This essentially allows the
    user to analyze the application state, especially in complex situations, without
    adding any additional log statements.'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: In addition, Cloud Debugger can be used for production environments and is not
    limited to development or test environments. When Cloud Debugger captures the
    application state, it adds request latency that is less than 10 ms, which, practically,
    is not noticeable by users.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Debugger is supported on applications running in GCP such as App Engine,
    Compute Engineer, GKE, Cloud Run, and so on, as well as those written in a number
    of languages, including Java, Python, Go, Node.js, Ruby, PHP, and .NET. Cloud
    Debugger needs access to the application code and supports reading the code from
    App Engine, Google Cloud source repositories, or third-party repositories such
    as GitHub, Bitbucket, and so on.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Cloud Debugger
  id: totrans-385
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Enabling/setting up Cloud Debugger involves the following fundamental steps:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: Enable the Cloud Debugger API as a one-time setup per project.
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide appropriate access so that the GCP service where Cloud Debugger will
    run has permission to upload telemetry data or call Cloud Debugger.
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: App Engine and Cloud Run must already be configured for Cloud Debugger.
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A service account with the Cloud Debugger Agent role is required for applications
    running in Compute Engine, GKW, or external systems.
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If the application is running inside a Compute Engine VM or cluster nodes with
    a default service account, then the following access scopes should be added to
    the VMs or cluster nodes: [https://www.googleapis.com/auth/cloud-platform](https://www.googleapis.com/auth/cloud-platform)
    and [https://www.googleapis.com/auth/cloud_debugger](https://www.googleapis.com/auth/cloud_debugger).'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the source code location. If there is no access to the source code, a
    debug snapshot can be taken that captures the call stack and local variables.
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If there is access to the source code, then App Engine standard will select
    the source code automatically. App Engine flex, GCE, GKE, and Cloud Run can automatically
    select the source code based on the configuration file in the application root
    folder; that is, `source-context.json`.
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Alternatively, select a source code location from the possible options, including
    local files, Cloud Source Repositories, GitHub, Bitbucket, and GitLab.
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To enable Cloud Debugger from application code, you must follow a set of instructions
    that are specific to the language that the application has been written in. The
    following is an example snippet:'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now that we've set up Cloud Debugger, let's learn how to use it.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: Using Cloud Debugger
  id: totrans-398
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using Cloud Debugger involves learning about the functionality of debug snapshots,
    debug logpoints, and accessing the logs panel.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: Debug snapshots
  id: totrans-400
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Snapshots** capture local variables and the call stack at a specific location
    in the application''s source code. The fundamental step prior to taking a snapshot
    is to set up a breakpoint. It takes about 40 seconds for a breakpoint to come
    into effect. Cloud Debugger breakpoints do not stop code execution. A non-intrusive
    snapshot is taken when the flow of execution passes the debug point. Additional
    conditions can be added so that a snapshot is only taken if a data condition passes.
    The captured snapshot will contain details of the local variables and the state
    of the call stack.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, the breakpoint was set to line 39 against a specific
    file. The breakpoint has a qualifying condition, and a snapshot is taken if its
    condition is met. The details of the variables are displayed in the **Variables**
    section:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.21 – Taking a debug snapshot in Cloud Debugger'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_21.jpg)'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.21 – Taking a debug snapshot in Cloud Debugger
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: Optionally, expressions can also be included while configuring a snapshot. Expressions
    can be used as special variables to evaluate values when a snapshot is taken.
    These are especially useful in scenarios where the values being captured by the
    expressions are not usually captured by local variables.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, we can see that multiple expressions are defined
    while configuring a snapshot and are captured while taking a snapshot:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.22 – Defining expressions while configuring a snapshot'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_22.jpg)'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.22 – Defining expressions while configuring a snapshot
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some key pointers related to snapshots:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: A snapshot is taken only once. To capture another snapshot of the application
    data for the same location in the code, the user needs to manually retake the
    snapshot through the camera icon in the snapshot panel.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A snapshot location can be manually removed by clicking the **x** icon on the
    breakpoint.
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Debugger generates a new URL for every snapshot that's been taken. It
    is valid for 30 days from the time it was taken. This URL can be shared with other
    members of the project.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next subsection provides an overview of debug logpoints and how they can
    be injected into a running application.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: Debug logpoints
  id: totrans-416
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It's a common practice to add log messages when you're trying to solve complex
    problems. In such scenarios, developers often provide code changes to production
    that essentially include additional log statements that help with analysis. If
    the problem is complex, this process needs to be repeated multiple times, which
    means the production code needs to go through multiple changes to include log
    statements. Cloud Debugger steps away from the traditional approach to debugging
    an application and instead provides a dynamic way to add log messages using **debug
    logpoints**.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: Debug logpoints can inject logs into a running application without stopping,
    editing, or restarting. A logpoint is added at a location of choice, as per the
    developer's wishes. When that particular portion of code is executed, Cloud Debugger
    logs a message, and the log message is sent to the appropriate service that is
    hosting the application. So, if the application is hosted in App Engine, then
    the log message can be found in the logs tied to App Engine.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, a logpoint has been added with a condition, with
    the message log level set to **Info**. The concept of specifying a condition along
    with a logpoint is called a *logpoint condition*. This is an expression in the
    application language that must evaluate to true for the logpoint to be logged.
    Logpoint conditions are evaluated each time that specific line is executed, if
    the logpoint is valid:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.23 – Adding a debug logpoint via Cloud Debugger'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_23.jpg)'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.23 – Adding a debug logpoint via Cloud Debugger
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some key pointers related to logpoints:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: 'A logpoint can be created even if direct access to the source code is not available.
    A logpoint can be created by specifying the name of the file, the line number
    to create the logpoint, the log level, an optional condition, and an appropriate
    message, as shown here:'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.24 – Configuring a logpoint without access to the source code'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_24.jpg)'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.24 – Configuring a logpoint without access to the source code
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: Logpoints becomes inactive after 24 hours and post that, messages with respect
    to those logpoints will not be evaluated or logged.
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logpoints are automatically deleted after 30 days from the time of creation.
    Optionally, users can manually delete logpoints at will.
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next subsection illustrates the usage and options available in the *Logs
    panel*.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: Logs panel
  id: totrans-431
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Cloud Debugger includes an in-page Logs panel that displays the running logs
    of the current application being inspected. This allows the developer to view
    logs next to the respective code. Users can use the logs panel to perform search
    variations, including text-based search, and can filter by either log level, request,
    or file. The results are highlighted in the context or are shown in the logs viewer:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.25 – Logs panel for viewing logs while debugging in Cloud Debugger'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_25.jpg)'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.25 – Logs panel for viewing logs while debugging in Cloud Debugger
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: The upcoming subsection provides an overview of the access control that's required
    for Cloud Debugger.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: Access control for Cloud Debugger
  id: totrans-437
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following table displays the critical IAM roles required, along with their
    minimal permissions (in accordance with the principle of least privilege), to
    access or perform actions related to Cloud Debugger:'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15587_10_Table_05.jpg)'
  id: totrans-439
  prefs: []
  type: TYPE_IMG
- en: Tip – How to hide sensitive data while using debugging
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Debugger has a feature in Pre-GA where sensitive data can be hidden through
    a configuration file. This configuration file consists of a list of rules that
    are either expressed as `blacklist` or `blacklist_exception` (to specify an inverse
    pattern). If the criteria match, then data is hidden and is reported by the debugger
    as `blocked by admin`. This feature is currently only supported for applications
    written in Java.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: This completes this section on Cloud Debugger, where we learned how to set up
    Cloud Debugger, utilize debug logpoints to add log messages, and create snapshots
    to capture the call stack and its local values. We looked at the options that
    are available in the Logs panel and looked at the required access controls we
    can use to perform actions related to Cloud Debugger. In the next section, we
    will look at *Cloud Trace*, another GCP service that is part of Cloud Operations.
    Cloud Trace represents a distributed tracing system that collects latency data
    from applications to identify bottlenecks.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Trace
  id: totrans-443
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **trace** is a collection of spans. A **span** is an object that wraps latency-specific
    metrics and other contextual information around a unit of work in an application.
    **Cloud Trace** is a distributed tracing system that captures latency data from
    an application, tracks the request's propagation, retrieves real-time performance
    insights, and displays the results in Google Cloud Console. This latency information
    can be either for a single request or can be aggregated for the entire application.
    This information helps us identify performance bottlenecks.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, Cloud Trace can automatically analyze application traces that
    might reflect recent changes to the application's performance, identify degradations
    from latency reports, capture traces from containers, and create alerts as needed.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloud Trace''s language-specific SDKs are available for Java, Node.js, Ruby,
    and Go. These SDKs can analyze projects running on VMs. It is not necessary for
    these VMs to only be running on Google Cloud. Apart from the SDK, the Trace API can
    be used to submit and retrieve trace data from any source. A Zipkin collector is
    available, which allows Zipkin tracers to submit data to Cloud Trace. Additionally,
    Cloud Trace can generate trace information using OpenCensus or OpenTelemetry instrumentation.
    Cloud Trace consists of three main sections: Trace Overview, Trace List, and Analysis
    Reports. Let''s look at them in detail.'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: Trace Overview
  id: totrans-447
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The **Trace Overview** page provides a summary of latency data that''s spread
    across various informational panes:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: '**Insights**: Displays a list of performance insights, if applicable'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recent Traces**: Highlights the most recent traces for a project'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frequent URIs**: Displays a list of URIs along with their average latency
    for the most frequent requests to the application in the last 7 days'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frequent RPCs**: Displays a list of RPCs along with their average latency
    for the most frequent RPC calls made in the last 7 days'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chargeable trace spans**: Summarizes the number of trace spans that have
    been created and received by Cloud Trace for the current and previous months:'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.26 –Chargeable trace spans from the Trace Overview page'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_26.jpg)'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.26 –Chargeable trace spans from the Trace Overview page
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection provides an overview of the **Trace List** window, which
    can be used to examine traces in detail.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: Trace List
  id: totrans-458
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The **Trace List** window allows users to find, filter, and examine individual
    traces in detail. These traces are displayed in a heatmap, and a specific section
    of the heatmap can be selected if you wish to view these traces within that specific
    slice of the window:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.27 – List of all the traces filtered by the POST method in the
    last 30 days'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_27.jpg)'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.27 – List of all the traces filtered by the POST method in the last
    30 days
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on the individual trace (represented by a circle) provides details
    about the trace. It is represented by a waterfall graph:'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.28 – Waterfall graph of an individual trace'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_28.jpg)'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.28 – Waterfall graph of an individual trace
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection provides an overview of trace analysis reports with respect
    to request latency.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: Analysis Reports
  id: totrans-468
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Analysis Reports shows an overall view of the latency for all the requests or
    a subset of requests with respect to the application. These reports are categorized
    either as daily reports or custom analysis reports.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: Daily reports
  id: totrans-470
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cloud Trace creates a daily report automatically for the top three endpoints.
    Cloud Trace compares the previous days' performance with the performance from
    the same day of the previous week. The content of the report cannot be controlled
    by the user.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: Custom analysis reports
  id: totrans-472
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The user can create a custom analysis report, where the content of the report
    can be controlled from the aspect of which traces can be included. The report
    can include latency data either in histogram format or table format, with links
    to sample traces. The report can optionally include a bottleneck pane that lists
    **Remote Procedure Calls** (**RPCs**), which are significant contributors to latency.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: Condition to auto-generate or manually create a trace report
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
- en: For the daily report to auto-generate or for a user to create a custom report
    within a specific time range, it is mandatory that at least 100 traces are available
    in that time period. Otherwise, a trace report will not be generated.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: This completes this section on Cloud Trace, a GCP construct for representing
    a distributed tracing system, collecting latency data from applications, and identifying
    performance bottlenecks. The next section focuses on Cloud Profiler, a service
    that is part of Cloud Operations. Cloud Profiler is a low-impact production profiling
    system that presents call hierarchy and resource consumption through an interactive
    flame graph.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Profiler
  id: totrans-477
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud Profiler provides low-impact continuous profiling to help users understand
    the performance of a production system. It provides insights into information
    such as CPU usage, memory consumption, and so on. Cloud Profiler allows developers
    to analyze applications running either in Google Cloud, other cloud providers,
    or on-premises.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Profiler uses statistical techniques and extremely low-impact instrumentation
    to provide a complete picture of an application's performance, without slowing
    it down. Cloud Profiler runs across all production application instances, presents
    a call hierarchy, and explains the resource consumption of the relevant function
    in an interactive flame graph. This information is critical for developers to
    understand which paths consume the most resources and illustrates the different
    ways in which the code is actually called. The supported programming languages
    include Java, Go, Node.js, and Python.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloud Profiler supports the following types of profiles:'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: '**CPU time**: The time the CPU spent executing a block of code. This doesn''t
    include the time the CPU was waiting or processing instructions for something
    else.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heap**: Heap or heap usage is the amount of memory that''s allocated to the
    program''s heap when the profile is collected.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Allocated heap**: Allocated heap or heap allocation is the total amount of
    memory that was allocated in the program''s heap, including memory that has been
    freed and is no longer in use.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Contention**: Contention provides information about the threads that are
    stuck and the ones waiting for other threads. Understanding contention behavior
    is critical to designing code and provides information for performance tuning.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Threads**: Information related to threads gives insights into the threads
    that are created but never actually used. This forms the basis for identifying
    leaked threads, where the number of threads keeps increasing.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Wall time**: Wall time is the time it takes to run a block of code, including
    its wait time. The wall time for a block of code can never be less than the CPU
    time.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following screenshot summarizes the supported profile types by language:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.29 – Supported profile types by language'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_29.jpg)'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.29 – Supported profile types by language
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the Profiler interface, which depicts a sample
    interactive flame graph for the **CPU time** profile type. The profile data is
    retained for 30 days and the profile information can be downloaded for long-term
    storage:'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.30 – Interactive flame graph with the profile type set to CPU time'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_30.jpg)'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.30 – Interactive flame graph with the profile type set to CPU time
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: The upcoming subsection explains the access controls that are required to perform
    actions with respect to Cloud Profiler.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: Access control for Cloud Profiler
  id: totrans-496
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following table displays the critical IAM roles required, along with their
    minimal permissions (in accordance with the principle of least privilege), to
    access or perform actions related to Cloud Profiler:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15587_10_Table_06.jpg)'
  id: totrans-498
  prefs: []
  type: TYPE_IMG
- en: This completes this section on Cloud Profiler, where we looked at the supported
    profile types and learned how to use an interactive flame graph.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: Binding SRE and Cloud Operations
  id: totrans-500
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B15587_02_Final_ASB_ePub.xhtml#_idTextAnchor038), *SRE Technical
    Practices – Deep Dive*, introduced SRE technical practices such as SLAs, SLOs,
    SLIs, and Error Budgets. To summarize, this chapter established a relationship
    between these practices and tied them directly to the reliability of the service.
    To ensure that a service meets its SLAs, the service needs to be reliable. SRE
    recommends using SLOs to measure the reliability of the service. SLOs require
    SLIs to evaluate the service''s reliability. If these SLIs are not met, then the
    SLOs will miss their targets. This will eventually burn the Error Budget, which
    is a measure that calculates the acceptable level of unavailability or unreliability.
    [*Chapter 3*](B15587_03_Final_ASB_ePub.xhtml#_idTextAnchor064), *Understanding
    Monitoring and Alerting to Target Reliability*, introduced concepts related to
    monitoring, alerting, logging, and tracing and established how these are critical
    to tracking the reliability of the service. However, both these chapters were
    conceptual in nature.'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter''s focus is Cloud Operations. So far, we''ve described how Google
    Cloud captures monitoring metrics, logging information, and traces and allows
    us to debug applications or services. Additionally, Cloud Operations has an option
    called SLO monitoring. This option allows you to define and track the SLO of a
    service. This option currently supports three service types for auto-ingestion:
    Anthos Service Mesh, Istio on GKE, and App Engine. However, this option also supports
    user-defined microservices. The next subsection deep dives into SLO monitoring.'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: SLO monitoring
  id: totrans-503
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Given that SLOs are measured using SLIs and SLOs are defined as quantifiable
    measures of service reliability that are measured over time, there are three specific
    steps in defining an SLO via SLO monitoring. These are as follows:'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: Setting a **SLI**
  id: totrans-505
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Defining SLI details
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Setting a **SLO**
  id: totrans-507
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's look at these steps in more detail.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
- en: Setting an SLI
  id: totrans-509
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is the first step and has two specific goals: choosing a metric as an
    SLI and selecting a method of evaluation for measuring the chosen metric.'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a metric
  id: totrans-511
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SLO monitoring allows you to choose either **Availability** or **Latency** as
    an out-of-the-box SLI for a service that's been configured via Anthos Service
    Mesh, Istio on GKE, and App Engine. These options are not available for microservices
    on GKE that haven't been configured through the preceding options. These are also
    known as custom services. However, irrespective of how the service is configured,
    you have the option to choose **Other**. Here, the user can pick the metric of
    choice to track as the SLI.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
- en: Request-based or windows-based
  id: totrans-513
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are two methods of evaluation to choose from that will affect how compliance
    against SLIs is measured. These are request-based and windows-based. The request-based
    option counts individual events and evaluates how a service performs over the
    compliance period, irrespective of how load is distributed. The windows-based
    option, on the other hand, measures performance in terms of time (good minutes
    versus bad minutes), irrespective of how load is distributed.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
- en: Defining SLI details
  id: totrans-515
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is the second step and provides options for the user to choose a performance
    metric. The user can either use the predefined metrics in Cloud Monitoring or
    any user-defined metrics that can be created from logs (through logs-based metrics).
    Once a metric has been chosen, the performance criteria for the metric need to
    be defined. The performance criteria for metrics related to services on Anthos
    Service Mesh, Istio on GKE, and App Engine are predefined. However, for custom
    services, this needs to be manually defined by the user by using two of the three
    filter options – **Good**, **Bad**, and **Total**.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
- en: Setting an SLO
  id: totrans-517
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is the third and final step and has two specific goals: setting the compliance
    period and setting the performance goal.'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
- en: Compliance period
  id: totrans-519
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The compliance period option allows you to set a time period to evaluate the
    SLO. There are two possible choices:'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
- en: '**Calendar**: Performance is measured from the start of the period, with a
    hard reset at the start of every new period. The available options for period
    length are Calendar day, Calendar week, Calendar fortnight, and Calendar month.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rolling**: Performance is measured for a fixed time period; say, the last
    10 days. The user can specify the fixed time period in days.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let's look at setting the performance goal.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
- en: Performance goal
  id: totrans-524
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The performance goal indicates the goal that's been set as a ratio of *good
    service* to *demanded service* over the compliance period. This goal can be refined
    as more information is known about the system's behavior.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
- en: This completes our overview of SLO monitoring, which we can use to define an
    SLO to measure the reliability of a service. The next subsection provides a hands-on
    demonstration of how SLO monitoring can be configured against a GKE service (that
    we previously created in [*Chapter 8*](B15587_08_Final_ASB_TD_ePub.xhtml#_idTextAnchor182),
    *Understanding GKE Essentials to Deploy Containerized Applications*).
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
- en: Hands-on lab – tracking service reliability using SLO monitoring
  id: totrans-527
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SLO monitoring allows us to link the SRE technical practices with the practical
    options available in Google Cloud. These help us monitor the reliability of the
    service and alert the on-call engineer if the service misses the reliability threshold.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
- en: 'This subsection is a hands-on lab that will show you how to use the SLO monitoring
    option from Cloud Monitoring. The SLO monitoring option tracks service reliability
    by defining an SLO. In this lab, we will use `hello-world-service` from the `my-first-cluster`
    GKE cluster, which was created as part of [*Chapter 8*](B15587_08_Final_ASB_TD_ePub.xhtml#_idTextAnchor182),
    *Understanding GKE Essentials to Deploy Containerized Applications*. This lab
    has three main goals:'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
- en: Defining an SLO for a service
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating an SLO burn rate alert policy
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verifying SLO monitoring
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a look at these goals in more detail.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
- en: Defining a SLO for a service
  id: totrans-534
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Follow these steps to define a SLO for `hello-world-service`:'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the `hello-world-service` section from the `my-first-cluster` cluster,
    as shown in the following screenshot. Set the display name to `hello-world-service`.
    The system will create the service to be monitored and will navigate the user
    to the service overview dashboard:![Figure 10.31 – Defining a custom service by
    selecting one
  id: totrans-536
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_31.jpg)'
  id: totrans-537
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.31 – Defining a custom service by selecting one
  id: totrans-538
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select the **Create SLO** action to define an SLO. This action will open a pop-up
    window, as shown in the following screenshot. Note that, as discussed in [*Chapter
    2*](B15587_02_Final_ASB_ePub.xhtml#_idTextAnchor038), *SRE Technical Practices
    – Deep Dive*, an SLO requires an SLI. So, to define an SLO, we must first choose
    the SLI metric and then define it.
  id: totrans-539
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Given that the service being used for this lab is not part of Anthos Service
    Mesh, Istio on GKE, or App Engine, the only option available is to choose **Other**.
    Here, the user can configure a metric of choice to measure the performance of
    the service. In addition, set the method of evaluation to **Request-based**:![Figure
    10.32 – Setting an SLI as part of SLO monitoring
  id: totrans-540
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_32.jpg)'
  id: totrans-541
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.32 – Setting an SLI as part of SLO monitoring
  id: totrans-542
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To define the SLI's details, select a performance metric. In this case, we will
    select the `kubernetes.io/container/restart_count` metric. Set the filters to
    **Total** and **Bad**, as shown here:![Figure 10.33 – Defining SLI details as
    part of SLO monitoring
  id: totrans-543
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_33.jpg)'
  id: totrans-544
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.33 – Defining SLI details as part of SLO monitoring
  id: totrans-545
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select a compliance period; that is, either `90`%, as shown here:![Figure 10.34
    – Setting an SLO as part of SLO monitoring
  id: totrans-546
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_34.jpg)'
  id: totrans-547
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.34 – Setting an SLO as part of SLO monitoring
  id: totrans-548
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Review the configuration and save it by providing an appropriate display name,
    such as `90% - Restart Count - Calendar Day`, as shown here:![Figure 10.35 – Reviewing
    and saving the SLO as part of SLO monitoring
  id: totrans-549
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_35.jpg)'
  id: totrans-550
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.35 – Reviewing and saving the SLO as part of SLO monitoring
  id: totrans-551
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once saved, the SLO – `90% - Restart Count - Calendar Day` – will be created
    under the `hello-world-service` service, as shown in the following screenshot.
    At the moment, the error budget is **100%** since none of the containers were
    restarted:'
  id: totrans-552
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.36 – SLO created for a service as part of SLO monitoring'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_36.jpg)'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.36 – SLO created for a service as part of SLO monitoring
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
- en: With this, we've learned the steps we need to take to define an SLO for a service.
    In the next topic, we'll explore the steps we need to create an SLO burn rate
    alert policy.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
- en: Creating a SLO burn rate alert policy
  id: totrans-557
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The concept of alerting and notification channels from Cloud Monitoring (discussed
    earlier in this chapter) is used to create an alert. Before we look at the steps
    for this, let''s recap on the critical jargon that was discussed in [*Chapter
    3*](B15587_03_Final_ASB_ePub.xhtml#_idTextAnchor064), *Understanding Monitoring
    and Alerting to Target Reliability*. We must configure these elements while defining
    an alert through Cloud Monitoring:'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
- en: '**Lookback duration** refers to how far you must go back in time to retrieve
    monitoring data.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fast-burn alert** refers to using shorter lookback durations that help with
    quickly detecting problems. However, this will lead to more frequent alerting
    and, potentially, false alarms.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Slow-burn alert** refers to using a longer lookback duration to ensure that
    a problem exists for a longer duration and avoids false alarms. However, the downside
    is that the alert is fired after a longer duration, even though the problem has
    a current negative impact on the service.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Follow these steps to set up an alert for when the error budget for the SLO
    drops beyond a certain burn rate within a specified period of time:'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
- en: Click the `1` minute(s) and `10` minute(s). The following is our configuration
    for a fast-burn alert:![Figure 10.37 – Setting an SLO alert condition
  id: totrans-563
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_37.jpg)'
  id: totrans-564
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.37 – Setting an SLO alert condition
  id: totrans-565
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select a notification channel of choice (that has already been pre-configured).
    In this case, select an email notification channel, as shown here:![Figure 10.38
    – Selecting a notification channel to send an alert
  id: totrans-566
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_38.jpg)'
  id: totrans-567
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.38 – Selecting a notification channel to send an alert
  id: totrans-568
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, create the SLO burn rate alert policy. Optionally, add documentation that
    references the alert in terms of what the on-job SRE engineer should check or
    do.
  id: totrans-569
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once the alert has been configured, the SLO status will look as follows, where
    **Error Budget** is currently at 100% and none of the alerts are firing:'
  id: totrans-570
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.39 – Showing the complete setup for SLO monitoring with its alert
    and initial error budget'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_39.jpg)'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.39 – Showing the complete setup for SLO monitoring with its alert
    and initial error budget
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
- en: With that, we've created an SLO burn rate alert policy. Now, let's verify SLO
    monitoring by performing a test.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
- en: Verifying SLO monitoring
  id: totrans-575
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the previous two subsections of this hands-on lab on SLO monitoring, we
    created an SLO for a service (that was previously created in [*Chapter 8*](B15587_08_Final_ASB_TD_ePub.xhtml#_idTextAnchor182),
    *Understanding GKE Essentials to Deploy Containerized Applications*) and then
    created an SLO burn rate alert policy. This section will show you how to test
    the configuration and verify if our SLO monitoring option verifies the health
    of our service; that is, `hello-world-service`:'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that we previously selected the performance metric while defining our
    SLO as `kubernetes.io/container/restart_count`, let''s restart the container and
    see if the error budget changes and, subsequently, if the alert gets fired. Use
    the following command to restart the container after connecting to the cluster.
    Replace `pod-name` and `container-name` accordingly. `pod-name` can be found via
    the service, while `container-name` can be found via `pod-name`:'
  id: totrans-577
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-578
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Once the command has been executed, the container inside the pod, with respect
    to `hello-world-service`, will restart. This means that the SLI that's been defined
    will not be met and, subsequently, the SLO will not be met. As a result, the error
    budget will be consumed. If the error budget is consumed by more than the burn
    rate that's been defined – which was 10 under 1 minute – then an alert will also
    be fired. The following screenshot shows the updated status of the SLO for `hello-world-service`.
    The status of the SLO has now been updated to **Unhealthy**:![Figure 10.40 – Displaying
    the service as Unhealthy, alerts firing, and the reduced error budget
  id: totrans-579
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15587_10_40.jpg)'
  id: totrans-580
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.40 – Displaying the service as Unhealthy, alerts firing, and the reduced
    error budget
  id: totrans-581
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The alert triggers a notification that will be sent to the configured email,
    as shown in the following screenshot:'
  id: totrans-582
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.41 – Alert notification set to the configured email address'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15587_10_41.jpg)'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.41 – Alert notification set to the configured email address
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
- en: This completes our detailed hands-on lab related to SLO monitoring, where we
    linked the SRE technical practices to options available in Google Cloud Operations
    to monitor and alert users about the reliability of the service. This also completes
    this chapter on Cloud Operations.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-587
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the suite of tools that are part of Cloud Operations.
    Cloud Operations is critical for forming the feedback loop of the CI/CD process
    and is fundamental to establishing observability on GCP. Observability is key
    to ensuring that an SRE's technical practices – specifically, SLIs, SLOs, SLAs,
    and Error Budgets – are not violated. This is achieved by gathering logs, metrics,
    and traces from multiple sources and by visualizing this information on dashboards.
    This information is used to establish performance and reliability indicators.
    These indicators can then be tracked with configurable alerts. These alerts trigger
    when there is a potential violation, and the alerts will be notified on the configurable
    notification channels. Cloud Operations also offers services that allow us to
    debug the application, without slowing down, and capture trace information. The
    end goal is to ensure that the service is reliable. We concluded this chapter
    by providing a hands-on lab on SLO monitoring, a feature from Google Cloud that
    tracks the reliability of the service by bringing together Cloud Operations and
    SRE technical practices.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
- en: This was the last chapter of this book. The next section provides insights into
    preparing to become a Professional Cloud DevOps Engineer, along with a summary
    on a few topics that might show up in the exam but were not covered in the last
    10 chapters. We have also provided a mock exam, which will be useful as a preparation
    resource.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
- en: Points to remember
  id: totrans-590
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are some important points to remember:'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Monitoring is a GCP service that collects metrics, events, and metadata
    from multi-cloud and hybrid infrastructures in real time.
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A workspace provides a *single pane of glass* related to GCP resources.
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A workspace can monitor resources from multiple monitored projects.
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A monitored project, however, can only be associated with a single workspace.
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dashboards provide a graphical representation of key signal data, called metrics,
    in a manner that is suitable for end users or the operations team.
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics represent numerical measurements of resource usage that can be observed
    and collected across the system at regular time intervals.
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MQL can be used to create a chart with a text-based interface and uses an expressive
    query language to execute complex queries against time series data.
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uptime checks test the availability of an external facing service within a specific
    timeout interval.
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connection errors, 40x client errors, and not configuring firewall rules are
    potential reasons for uptime check failures.
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alerting is the process of processing the alerting rules that track the SLOs
    and notify or perform certain actions when the rules are violated.
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The alignment period is a lookback interval from a particular point in time.
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Monitoring agent is based on the `collectd` daemon and is used to collect
    system statistics from various sources, including OSes, applications, logs, and
    external devices.
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Logging is a GCP service that allows you to store, search, analyze, monitor,
    and alert users about logging data and events from applications.
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Policy denied logs are specific to logs that are captured when access is denied
    by a Google Cloud service to either a user or service account.
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logs-based metrics are metrics that are created based on the content of the
    log entries and can be extracted from both included and excluded logs.
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VPC Flow Logs capture real-time network activity (incoming/outgoing) against
    VPC resources on an enabled subnet.
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Firewall logs capture the effects of a specific firewall rule in terms of the
    traffic that's allowed or denied by that firewall rule.
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Logging agent is based on `fluentd` and captures additional VM logs such
    as operating system (OS) logs and logs from third-party applications.
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Monitoring and Logging agents can both be installed on unmanaged GCE VMs.
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE has built-in support for logging and can be enabled for new or existing
    clusters via *Cloud Operations for GKE*.
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Debugger inspects the state of a running application in real time.
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snapshots capture local variables and the call stack at a specific location
    in the application's source code.
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A snapshot is only taken once, and the user needs to manually retake it if needed.
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debug logpoints can inject a log into a running application without stopping,
    editing, or restarting.
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logpoints can be created even if direct access to the source code is not available.
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logpoints become inactive after 24 hours and are automatically deleted after
    30 days.
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Trace is a collection of spans. A span is an object that wraps latency-specific
    metrics. Cloud Trace is a distributed tracing system.
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Trace's language-specific SDKs are available for Java, Node.js, Ruby,
    and Go.
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Profiler provides low-impact continuous profiling to help us understand
    the performance of a production system.
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The programming languages that are supported by Cloud Profiler include Java,
    Go, Node.js, and Python. Profile data is retained for 30 days by default.
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-622
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information on GCP''s approach toward DevOps, please read the following
    articles:'
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
- en: '**Cloud Operations**: [https://cloud.google.com/products/operations](https://cloud.google.com/products/operations)'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Monitoring**: [https://cloud.google.com/monitoring](https://cloud.google.com/monitoring)'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Logging**: [https://cloud.google.com/logging](https://cloud.google.com/logging)'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Debugger**: [https://cloud.google.com/debugger](https://cloud.google.com/debugger)'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Trace**: [https://cloud.google.com/trace](https://cloud.google.com/trace)'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Profiler**: [https://cloud.google.com/profiler](https://cloud.google.com/profiler)'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Practice test
  id: totrans-630
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Answer the following questions:'
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
- en: A user has performed administrative actions that modify the configuration or
    metadata of resources. Which of the following is the most appropriate option to
    quickly get to the logs related to administrative actions?
  id: totrans-632
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Go to Error Reporting and view the administrative activity logs.
  id: totrans-633
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Go to Cloud Logging and view the administrative activity logs.
  id: totrans-634
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Go to Cloud Monitoring and view the administrative activity logs.
  id: totrans-635
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Go to the Activity tab on the Cloud Console and view the administrative activity
    logs.
  id: totrans-636
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The default retention period for data access audit logs is ___________.
  id: totrans-637
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 7 days
  id: totrans-638
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 30 days
  id: totrans-639
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 400 days
  id: totrans-640
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Unlimited
  id: totrans-641
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select the most appropriate option for monitoring multiple GCP projects with
    resources through a single workspace.
  id: totrans-642
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Cannot monitor multiple GCP projects through a single workspace.
  id: totrans-643
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Configure a separate project as a `host` project for a Cloud Monitoring workspace.
    Configure metrics and logs from each project to the host project via Pub/Sub.
  id: totrans-644
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Configure a separate project as a `host` project for a Cloud Monitoring workspace.
    Use this host project to manage all other projects.
  id: totrans-645
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Configure a separate project as a `host` project for a Cloud Monitoring workspace.
    Configure the metrics and logs from each project for the host project via Cloud
    Storage.
  id: totrans-646
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ____________ logs record operations of instances that have been reset for Google
    Compute Engine.
  id: totrans-647
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Admin activity
  id: totrans-648
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) System event
  id: totrans-649
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Data access
  id: totrans-650
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Access transparency
  id: totrans-651
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The maximum size of a log entry is __________.
  id: totrans-652
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 64 KB
  id: totrans-653
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 128 KB
  id: totrans-654
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 256 KB
  id: totrans-655
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) 512 KB
  id: totrans-656
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The default retention period for access transparency logs is ___________.
  id: totrans-657
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 7 days
  id: totrans-658
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 30 days
  id: totrans-659
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 400 days
  id: totrans-660
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Unlimited
  id: totrans-661
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ___________ logs are specific to actions that are performed by Google personnel
    when accessing user's/customer's content.
  id: totrans-662
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Admin activity
  id: totrans-663
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) System event
  id: totrans-664
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Data access
  id: totrans-665
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Access transparency
  id: totrans-666
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The SRE team supports multiple production workloads in GCP. The SRE team wants
    to manage issues better by sending error reports and stack traces to a centralized
    service. Which of the following is best suited for accomplishing this goal?
  id: totrans-667
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Cloud Error Logging
  id: totrans-668
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Cloud Error Reporting
  id: totrans-669
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Cloud Tracing
  id: totrans-670
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Cloud Profiling
  id: totrans-671
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ___________ logs record the operations that are performed when assigning/unassigning
    IAM roles.
  id: totrans-672
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Admin activity
  id: totrans-673
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) System event
  id: totrans-674
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Data access
  id: totrans-675
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Access transparency
  id: totrans-676
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: _________ logs analyze the network logs of an application.
  id: totrans-677
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) VPC flow
  id: totrans-678
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Firewall
  id: totrans-679
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Audit
  id: totrans-680
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Activity
  id: totrans-681
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the option that represents the right characteristics for log entry from
    Cloud Logging:'
  id: totrans-682
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Timestamp
  id: totrans-683
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Log name
  id: totrans-684
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Resource tied to the log entry
  id: totrans-685
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) All of the above
  id: totrans-686
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select two actions where the user will want to send a subset of logs for big
    data analysis:'
  id: totrans-687
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Create a sink in Cloud Logging that identifies the subset of logs to send.
  id: totrans-688
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Export logs to Cloud Storage.
  id: totrans-689
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Export logs to BigQuery.
  id: totrans-690
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Export logs to Pub/Sub.
  id: totrans-691
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The default retention period for admin activity logs is ___________.
  id: totrans-692
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 7 days
  id: totrans-693
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 30 days
  id: totrans-694
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 400 days
  id: totrans-695
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Unlimited
  id: totrans-696
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which of the following represents the right sequence of steps to export logs?
  id: totrans-697
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Choose destination, create sink, create filter
  id: totrans-698
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Create sink, create filter, choose destination
  id: totrans-699
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Create sink, choose destination, create filter
  id: totrans-700
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Choose destination, create filter, create Sink
  id: totrans-701
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '___________ logs will record how resources are created for Google Compute Engine:'
  id: totrans-702
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Admin activity
  id: totrans-703
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) System event
  id: totrans-704
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Data access
  id: totrans-705
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Access transparency
  id: totrans-706
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the option that governs access to logs from Cloud Logging for a given
    user:'
  id: totrans-707
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Service accounts
  id: totrans-708
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Cloud IAM roles
  id: totrans-709
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Both (a) and (b)
  id: totrans-710
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) None of the above
  id: totrans-711
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the role that allows us to manage IAM roles for a Monitoring workspace:'
  id: totrans-712
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Monitoring Viewer
  id: totrans-713
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Monitoring Editor
  id: totrans-714
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Monitoring Admin
  id: totrans-715
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Monitoring Metric Writer
  id: totrans-716
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the Cloud Monitoring widget that represents metrics with a distribution
    value:'
  id: totrans-717
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Line charts
  id: totrans-718
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Heatmap charts
  id: totrans-719
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Gauges
  id: totrans-720
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Scorecards
  id: totrans-721
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To perform uptime checks, what is the minimum number of active locations that
    need to be selected as geographic regions?
  id: totrans-722
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Two
  id: totrans-723
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Three
  id: totrans-724
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Four
  id: totrans-725
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Five
  id: totrans-726
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The Monitoring agent is based on _________, while the Logging agent is based
    on __________.
  id: totrans-727
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `fluentd`, `collectd`
  id: totrans-728
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) `google-collectd`, `google-fluentd`
  id: totrans-729
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) `collectd`, `fluentd`
  id: totrans-730
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) `google-fluentd`, `google-collectd`
  id: totrans-731
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which of the following is not a valid classification type for data access logs?
  id: totrans-732
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Admin read
  id: totrans-733
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Admin write
  id: totrans-734
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Data read
  id: totrans-735
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Data write
  id: totrans-736
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the role that allows us to view data access and access transparency
    logs:'
  id: totrans-737
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Logs Viewer
  id: totrans-738
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Private Logs Viewer
  id: totrans-739
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Project Viewer
  id: totrans-740
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Project Editor
  id: totrans-741
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The default retention period for firewall logs is ___________.
  id: totrans-742
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 7 days
  id: totrans-743
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 30 days
  id: totrans-744
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 400 days
  id: totrans-745
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Unlimited
  id: totrans-746
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Every VPC has a set of hidden, implied, pre-configured rules with the lowest
    priority. Select two valid pre-configured rules:'
  id: totrans-747
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `allow all ingress`
  id: totrans-748
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) `deny all ingress`
  id: totrans-749
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) `allow all egress`
  id: totrans-750
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) `deny all egress`
  id: totrans-751
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The default retention period for system event audit logs is ___________.
  id: totrans-752
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) 7 days
  id: totrans-753
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) 30 days
  id: totrans-754
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) 400 days
  id: totrans-755
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Unlimited
  id: totrans-756
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answers
  id: totrans-757
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '(d): Go to the Activity tab on the Cloud Console and view the administrative
    activity logs.'
  id: totrans-758
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): 30 days.'
  id: totrans-759
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): Configure a separate project as a `host` project for a Cloud Monitoring
    workspace. Use this host project to manage all other projects.'
  id: totrans-760
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): System event.'
  id: totrans-761
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): 256 KB.'
  id: totrans-762
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): 400 days.'
  id: totrans-763
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(d): Access transparency.'
  id: totrans-764
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Cloud Error Reporting.'
  id: totrans-765
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(a): Admin activity.'
  id: totrans-766
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(a): VPC flow.'
  id: totrans-767
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(d): All of the above.'
  id: totrans-768
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (a) and (c).
  id: totrans-769
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): 400 days.'
  id: totrans-770
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Create sink, create filter, choose destination.'
  id: totrans-771
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(a): Admin activity.'
  id: totrans-772
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Cloud IAM roles.'
  id: totrans-773
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): Monitoring Admin.'
  id: totrans-774
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Heatmap chart.'
  id: totrans-775
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Three.'
  id: totrans-776
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): `collectd`, `fluentd`.'
  id: totrans-777
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Admin write; this is not a valid classification for data access logs.'
  id: totrans-778
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): Private Logs Viewer.'
  id: totrans-779
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b): 30 days.'
  id: totrans-780
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(b) and (c): `deny all ingress` and `allow all egress`.'
  id: totrans-781
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(c): 400 days.'
  id: totrans-782
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
