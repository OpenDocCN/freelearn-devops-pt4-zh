- en: Running a Prometheus Server
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行 Prometheus 服务器
- en: It's time to get our hands on some Prometheus configurations. This chapter will
    explore the core component of the stack, you will be introduced to common patterns
    of usage and full setup process scenarios under virtual machines and containers.
    This will allow you to truly validate the knowledge you've gathered so far and
    provide you with real examples to test your knowledge.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候动手配置一些 Prometheus 配置了。本章将探索这一堆栈的核心组件，你将了解常见的使用模式和在虚拟机及容器下的完整设置过程。这将帮助你真正验证你迄今为止所学的知识，并为你提供实际的示例来测试你的知识。
- en: 'In brief, the following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 简要来说，本章将涵盖以下主题：
- en: Deep dive into the Prometheus configuration
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入探索 Prometheus 配置
- en: Managing Prometheus in a standalone server
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在独立服务器上管理 Prometheus
- en: Managing Prometheus in Kubernetes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中管理 Prometheus
- en: Deep dive into the Prometheus configuration
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探索 Prometheus 配置
- en: One of the key features of Prometheus is, owing to incredibly sane default configurations,
    that it can scale from a quick test running on a local computer to a production-grade
    instance, handling millions of samples per second without having to touch almost
    any of its many knobs and dials. Having said that, it is very useful to know what
    configuration options are available to be able to get the most value out of Prometheus.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 的一个关键特性是，得益于其极为合理的默认配置，它可以从本地计算机上运行的快速测试，扩展到生产级实例，处理每秒数百万个样本，而几乎不需要触动它的任何一个设置选项。话虽如此，了解有哪些配置选项可用，能够帮助你充分利用
    Prometheus 的功能，这一点非常有用。
- en: There are two main types of configuration on a Prometheus server—command-line
    flags and operating logic that provided through configuration files. Command-line
    flags control the parameters that cannot be changed at runtime, such as the storage
    path or which TCP port to bind to, and need a full server restart to apply any
    change done at this level. The configuration files control runtime configuration,
    such as scrape job definitions, rules files locations, or remote storage setup.
    In the following sections, we're going to explore both of these types of configurations
    in depth.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 服务器有两种主要的配置类型——命令行标志和通过配置文件提供的操作逻辑。命令行标志控制那些无法在运行时更改的参数，例如存储路径或绑定的
    TCP 端口，并且需要完全重启服务器才能应用此级别所做的任何更改。配置文件控制运行时配置，例如抓取作业定义、规则文件位置或远程存储设置。在接下来的章节中，我们将深入探讨这两种配置类型。
- en: Prometheus startup configuration
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Prometheus 启动配置
- en: While running a Prometheus server with no startup configuration can be good
    enough for local instances, it is advisable to configure a couple of basic command-line
    flags for any serious deployment.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在没有启动配置的情况下运行 Prometheus 服务器对于本地实例可能足够，但对于任何严肃的部署，建议配置一些基本的命令行标志。
- en: 'At the time of writing, Prometheus has almost 30 command-line flags for tweaking
    several aspects of its operational configuration, grouped by the following namespaces:
    `config`, `web`, `storage`, `rules`, `alertmanager`, `query`, and `log`. The `--help`
    flag does a good job of describing most options, but it can be a bit terse in
    a few places, so we''re going to highlight the ones that are either important
    for any deployment or whose function is not readily apparent.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Prometheus 大约有 30 个命令行标志，用于调整其操作配置的多个方面，这些标志按以下命名空间分组：`config`、`web`、`storage`、`rules`、`alertmanager`、`query`
    和 `log`。`--help` 标志在描述大部分选项时做得很好，但有些地方可能简短一些，因此我们将重点介绍那些对于任何部署都很重要或其功能不太显而易见的选项。
- en: The config section
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置部分
- en: The first thing that is usually important to set is the Prometheus configuration
    file path, through the `--config.file` flag. By default, Prometheus will look
    for a file named `prometheus.yml` in the current working directory. While this
    is great for local tests, production deployments usually place server binaries
    and configuration files in their own paths, and so this flag is commonly needed.
    As a side note, this and a storage directory are the only hard requirements for
    starting a Prometheus server; without a configuration file, Prometheus refuses
    to start.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通常首先需要设置的重要内容是 Prometheus 配置文件的路径，可以通过 `--config.file` 标志来指定。默认情况下，Prometheus
    会在当前工作目录中查找名为 `prometheus.yml` 的文件。虽然这对于本地测试很方便，但生产环境的部署通常会将服务器二进制文件和配置文件放置在各自的路径中，因此通常需要使用这个标志。顺便提一下，配置文件和存储目录是启动
    Prometheus 服务器的唯一硬性要求；如果没有配置文件，Prometheus 会拒绝启动。
- en: The storage section
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 存储部分
- en: Following the same logic from the previous section, the `--storage.tsdb.path` flag
    should be set to configure the base path to the data storage location. This defaults
    to `data/` on the current working directory, and so it is advisable to point this
    to a more appropriate path—possibly to a different drive/volume, where data can
    be safely persisted and I/O contention can be mitigated. To note that NFS (AWS
    EFS included) is not supported, as it doesn't support the POSIX locking primitives
    needed for safe database files management. Placing the Prometheus data storage
    directory in a network share is also ill-advised as transient network failures
    would impact the monitoring system's ability to keep functioning - just when you'd
    need it the most.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 按照上一部分相同的逻辑，`--storage.tsdb.path` 标志应该被设置来配置数据存储位置的基础路径。默认情况下，它指向当前工作目录中的 `data/`，因此建议将其指向更合适的路径——可能是不同的驱动器/卷，在那里数据可以安全地持久化并且减少
    I/O 竞争。需要注意的是，不支持 NFS（包括 AWS EFS），因为它不支持进行安全数据库文件管理所需的 POSIX 锁定原语。将 Prometheus
    数据存储目录放在网络共享上也是不推荐的，因为暂时的网络故障会影响监控系统的正常运行——尤其是在你最需要它的时候。
- en: The Prometheus local storage can only be written to by a single Prometheus instance
    at a time. To make sure this is the case, it uses a lock file in the data directory.
    On startup, it tries to lock this file using OS-specific system calls, and will
    refuse to start if the file is already locked by another process.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 本地存储一次只能由一个 Prometheus 实例进行写入。为了确保这一点，它在数据目录中使用锁文件。在启动时，它会尝试使用操作系统特定的系统调用来锁定此文件，如果文件已被另一个进程锁定，则会拒绝启动。
- en: There can be an edge case to this behavior; when using persistent volumes to
    store the data directory, there is a chance that, when relaunching Prometheus
    as another container instance using the same volume, the previous instance might
    not have unlocked the database. This problem would make a setup of this kind susceptible
    to race conditions. Luckily, there is the `--storage.tsdb.no-lockfile` flag, which
    can be used in exactly this type of situation. Be warned though that, in general
    (and namely, in most Prometheus deployments), it is a bad idea to disable the
    lock file, as doing so makes unintended data corruption easier.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这种行为可能存在一个边缘情况；当使用持久化卷存储数据目录时，如果通过相同的卷重新启动 Prometheus 实例作为另一个容器实例，可能会出现前一个实例没有解锁数据库的情况。这种问题会使这种配置容易受到竞争条件的影响。幸运的是，存在
    `--storage.tsdb.no-lockfile` 标志，可以在这种情况下使用。不过需要警告的是，一般来说（特别是在大多数 Prometheus 部署中），禁用锁文件是个坏主意，因为这样会更容易导致意外的数据损坏。
- en: The web section
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Web 部分
- en: The next step is to configure what address users are going to utilize to get
    to the Prometheus server. The `--web.external-url` flag sets this base URL so
    that weblinks generated both in the web user interface and in outgoing alerts
    link back to the Prometheus server or servers correctly. This might be the DNS
    name for a load balancer/reverse proxy, a Kubernetes service, or, in the simplest
    deployments, the publicly accessible, fully qualified domain name of the host
    running the server. For completeness, and as stated in the official documentation,
    a URL path can also be supplied here when Prometheus is behind some layer seven
    reverse proxy with content switching (also referred to as location-based switching
    or URL prefix routing).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是配置用户将使用什么地址来访问 Prometheus 服务器。`--web.external-url` 标志设置此基础 URL，以便在 web 用户界面和外发警报中生成的
    web 链接能够正确地指向 Prometheus 服务器或多个服务器。这可能是负载均衡器/反向代理的 DNS 名称，一个 Kubernetes 服务，或者在最简单的部署中，运行服务器的主机的公共可访问完全合格域名。为了完整性，并且如官方文档中所述，当
    Prometheus 位于某个具有内容切换的七层反向代理后面时（也称为基于位置的切换或 URL 前缀路由），也可以在此提供一个 URL 路径。
- en: The Prometheus server behaves as a conventional `*nix` daemon by reloading its
    configuration file (along with rules files) when it receives a `SIGHUP`. However,
    there are situations where sending this signal isn't convenient (for example,
    when running in a container orchestration system such as Kubernetes or using custom-built
    automation) or even impossible (when running Prometheus on Windows). In these
    situations, the `--web.enable-lifecycle` flag can be used to enable the `/-/reload`
    and `/-/quit` HTTP endpoints, which can be used to control, reload, and shut down,
    respectively. To prevent accidental triggering of these endpoints, and because
    a `GET` wouldn't be semantically correct,  a `POST` request is needed. This flag
    is turned off by default as unfettered access to these endpoints pose a security
    concern.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus服务器像传统的`*nix`守护进程一样，当收到`SIGHUP`信号时，会重新加载其配置文件（以及规则文件）。然而，有些情况下发送此信号并不方便（例如，在Kubernetes等容器编排系统中运行，或者使用自定义构建的自动化工具），甚至可能不可能（例如，在Windows上运行Prometheus时）。在这些情况下，可以使用`--web.enable-lifecycle`标志来启用`/-/reload`和`/-/quit`这两个HTTP端点，用于控制、重新加载和关闭Prometheus。为了防止意外触发这些端点，并且因为`GET`请求在语义上不合适，必须使用`POST`请求。此标志默认关闭，因为对这些端点的无限制访问可能带来安全隐患。
- en: Similarly, the `--web.enable-admin-api` flag is also turned off by default for
    the same reason. This flag enables HTTP endpoints that provide some advanced administration
    actions, such as creating snapshots of data, deleting time series, and cleaning
    tombstones.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，`--web.enable-admin-api`标志默认也是关闭的，原因相同。此标志启用提供一些高级管理操作的HTTP端点，例如创建数据快照、删除时间序列和清理墓碑数据。
- en: As you may have noticed in [Chapter 3](8f575e82-4713-45c7-8eb3-0af3e0e61ed3.xhtml),
    *Setting Up a Test Environment*, the official Prometheus tarballs also bring two
    additional directories, `consoles` and `console_libraries`. These are needed to
    enable the native dashboarding capabilities of Prometheus, which are often overlooked.
    These directories contain some preconfigured dashboards (referred to as consoles)
    and support template libraries, written in the Go templating language. Prometheus
    can be configured to load these by using the `--web.console.templates` and `--web.console.libraries`
    flags. After that, those dashboards will be available at the `/consoles` endpoint
    (a link will be available in the main web UI if an index.html file exists).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[第3章](8f575e82-4713-45c7-8eb3-0af3e0e61ed3.xhtml)《设置测试环境》中可能已经注意到，官方的Prometheus
    tarball还带有两个额外的目录，`consoles`和`console_libraries`。这些是启用Prometheus本地仪表盘功能所需的，然而这一点常常被忽视。这些目录包含一些预配置的仪表盘（称为控制台）和支持模板库，这些都是用Go模板语言编写的。可以通过使用`--web.console.templates`和`--web.console.libraries`标志来配置Prometheus加载这些内容。之后，这些仪表盘将可在`/consoles`端点访问（如果存在index.html文件，主Web界面中将提供一个链接）。
- en: The query section
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查询部分
- en: This section is all about tuning the inner workings of the query engine. Some
    are fairly straightforward to understand, such as how long a given query can run
    before being aborted (`--query.timeout`), or how many queries can run simultaneously
    (`--query.max-concurrency`).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本节内容主要讲解如何调整查询引擎的内部工作机制。某些调整比较简单易懂，例如指定查询在被终止之前能够运行多长时间（`--query.timeout`），或者能够同时运行多少个查询（`--query.max-concurrency`）。
- en: However, two of them set limits that can have non-obvious consequences. The
    first is `--query.max-samples`, which was introduced in Prometheus 2.5.0, that
    sets the maximum number of samples that can be loaded onto memory. This was done
    as a way of capping the maximum memory the query subsystem can use (by using it
    together with `--query.max-concurrency`) to try and prevent the dreaded *query-of-death*—a
    query that loaded so much data to memory that it made Prometheus hit a memory
    limit and then killing the process. The behavior post 2.5.0 is that if any query
    hits the limit set by this flag (which defaults to 50,000,000 samples), the query
    simply fails.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有两个参数设置的限制可能会产生不明显的后果。第一个是`--query.max-samples`，它在Prometheus 2.5.0版本中引入，用于设置可以加载到内存中的最大样本数量。这个设置是为了限制查询子系统能够使用的最大内存（与`--query.max-concurrency`一起使用），以避免出现*致命查询*——一个将大量数据加载到内存中，导致Prometheus达到内存限制并终止进程的查询。2.5.0版本之后的行为是，如果某个查询触及了该标志所设置的限制（默认是50,000,000个样本），查询会直接失败。
- en: The second one is `--query.lookback-delta`. Without going into too much detail
    regarding how PromQL works internally, this flag sets the limit of how far back
    Prometheus will look for time series data points before considering them stale.
    This implicitly means that if you collect data at a greater interval than what's
    set here (the default being five minutes), you will get inconsistent results in
    alerts and graphs, and as such, two minutes is the maximum sane value to allow
    for failures.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个配置项是`--query.lookback-delta`。在不详细解释PromQL内部工作原理的前提下，这个标志设置了Prometheus在考虑数据点过时之前，回溯查询时间序列数据的时间限制。这意味着，如果你的数据收集间隔比此处设置的更长（默认值为五分钟），你将在警报和图表中得到不一致的结果，因此，允许失败的最大合理值为两分钟。
- en: Prometheus configuration file walkthrough
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Prometheus配置文件解析
- en: The configuration file we mentioned in the previous section declares the runtime
    configuration for the Prometheus instance. As we will see, everything related
    to scrape jobs, rule evaluation, and remote read/write configuration is all defined
    here. As we mentioned previously, these configurations can be reloaded without
    shutting down the Prometheus server by either sending a `SIGHUP` to the process,
    or by sending an HTTP POST request to the `/-/reload` endpoint (when `--web.enable-lifecycle`
    is used at startup).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前一节中提到的配置文件声明了Prometheus实例的运行时配置。如我们所见，所有与抓取任务、规则评估以及远程读写配置相关的内容都在此定义。正如前面提到的，这些配置可以在不关闭Prometheus服务器的情况下重新加载，可以通过向进程发送`SIGHUP`信号，或者向`/-/reload`端点发送HTTP
    POST请求来实现（当启动时使用了`--web.enable-lifecycle`）。
- en: 'At a high level, we can split the configuration file into the following sections:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次看，我们可以将配置文件划分为以下几个部分：
- en: '`global`'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`global`'
- en: '`scrape_configs`'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scrape_configs`'
- en: '`alerting`'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alerting`'
- en: '`rule_files`'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rule_files`'
- en: '`remote_read`'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`remote_read`'
- en: '`remote_write`'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`remote_write`'
- en: Once again, the official Prometheus documentation includes the schema for this
    file, which is written in YAML format. In this chapter, we will introduce an example
    configuration for us to analyze, but only go into detail on the `global` and `scrape_configs`
    sections. The alerting and `rule_files` are covered in [Chapter 9](9aa1e3da-13cf-4051-845d-1d1c924ef47b.xhtml)*,
    Defining Alerting and Recording Rules*, while `remote_read` and `remote_write`
    are explained in [Chapter 14](1fb2aaff-5fe3-44ed-9df8-1cd27f383906.xhtml), *Integrating
    Long-Term Storage with Prometheus*.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，官方的Prometheus文档包括了该文件的架构，该文件采用YAML格式。在本章中，我们将介绍一个示例配置供大家分析，但只详细讲解`global`和`scrape_configs`部分。警报和`rule_files`在[第9章](9aa1e3da-13cf-4051-845d-1d1c924ef47b.xhtml)《定义警报和记录规则》中有详细讨论，而`remote_read`和`remote_write`则在[第14章](1fb2aaff-5fe3-44ed-9df8-1cd27f383906.xhtml)《将长期存储与Prometheus集成》中有解释。
- en: A configuration file with the most comprehensive list of options available can
    be found in the Prometheus project GitHub repository, located in the following
    address: [https://github.com/prometheus/prometheus/blob/v2.9.2/config/testdata/conf.good.yml](https://github.com/prometheus/prometheus/blob/v2.9.2/config/testdata/conf.good.yml).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包含最全配置选项的配置文件可以在Prometheus项目的GitHub仓库中找到，地址为：[https://github.com/prometheus/prometheus/blob/v2.9.2/config/testdata/conf.good.yml](https://github.com/prometheus/prometheus/blob/v2.9.2/config/testdata/conf.good.yml)。
- en: 'Our example configuration looks as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例配置如下所示：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: At first glance, it may seem a bit dense, but for clarity's sake, we're making
    some configurations whose defaults values don't usually need to be touched explicit.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 初看之下，它可能显得有些复杂，但为了清晰起见，我们正在进行一些配置，这些配置的默认值通常不需要修改。
- en: Let's examine each section in detail.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐个详细查看每个部分。
- en: Global configuration
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全局配置
- en: 'The `global` configuration defines the default parameters for every other configuration
    section, as well as outlining what labels should be added to metrics going to
    external systems, as shown in the following code block:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`global`配置定义了每个其他配置部分的默认参数，同时概述了应该添加到外部系统度量值的标签，如下所示的代码块所示：'
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Duration can only be integer values and can only have one unit. This means that
    trying to use 0.5 minutes instead of 30 seconds or one minute 30 seconds instead
    of 90 seconds will be considered a configuration error.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 持续时间只能是整数值，并且只能有一个单位。这意味着，如果试图使用0.5分钟而不是30秒，或用一分钟30秒而不是90秒，将被视为配置错误。
- en: '`scrape_interval` sets the default frequency targets that should be scraped.
    This is usually between 10 seconds and one minute, and the default `1m` is a good
    conservative value to start. Longer intervals are not advisable as the lost granularity
    (especially in gauges) starts to impact the ability to properly alert on issues
    and makes querying finicky as you need to be aware that some shorter intervals
    might not return data. Additionally, considering the default loopback delta of
    five minutes (mentioned in the command-line flags), any `scrape_interval` longer
    than 150 seconds (2 minutes 30 seconds) will mean every time series for a given
    target will be considered stale if a single scrape fails.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`scrape_interval` 设置目标被抓取的默认频率。通常在 10 秒到 1 分钟之间，默认的 `1m` 是一个很好的保守值。较长的间隔不建议使用，因为丧失的粒度（尤其是在仪表类指标中）开始影响正确告警的能力，并且查询会变得麻烦，因为你需要意识到某些较短的间隔可能不会返回数据。此外，考虑到默认的
    5 分钟回环差值（在命令行标志中提到），任何大于 150 秒（2 分钟 30 秒）的 `scrape_interval` 都意味着如果一次抓取失败，那么给定目标的每个时间序列都会被视为过期。'
- en: '`scrape_timeout` defines how long Prometheus should wait by default for a response
    from a target before closing the connection and marking the scrape as failed (10
    seconds if not declared). Bear in mind that even though it is expected that targets
    respond to scrapes fairly quickly, the guidelines for metrics exposition mandate
    that collection should happen at scrape time and not cached, which means there
    can be some exporters that take a bit longer to respond.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`scrape_timeout` 定义了 Prometheus 默认等待目标响应的时间，超过该时间则关闭连接并将抓取标记为失败（如果未声明，则默认为
    10 秒）。请记住，尽管预期目标能快速响应抓取请求，但关于指标暴露的指导原则要求在抓取时进行数据收集，而非使用缓存，这意味着某些导出程序可能需要稍长时间来响应。'
- en: 'Similar to `scrape_interval`, `evaluation_interval` sets the default frequency
    recording and alerting rules are evaluated. For sanity, both should have the same.
    This is going to be discussed in more detail in [Chapter 9](9aa1e3da-13cf-4051-845d-1d1c924ef47b.xhtml),
    *Defining Alerting and Recording Rules*:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 `scrape_interval`，`evaluation_interval` 设置记录和告警规则评估的默认频率。为了确保一致性，两者应当相同。关于这一点将在[第
    9 章](9aa1e3da-13cf-4051-845d-1d1c924ef47b.xhtml)《定义告警和记录规则》中详细讨论：
- en: '![](img/5423912c-df8a-4cab-9a10-8e20e264621d.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5423912c-df8a-4cab-9a10-8e20e264621d.png)'
- en: 'Figure 5.1: Representation of scrape intervals and evaluation intervals inside
    Prometheus'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1：Prometheus 中抓取间隔和评估间隔的表示
- en: Lastly, `external_labels` allows you to set label name/value pairs that are
    added to time series or alerts going to external systems, such as Alertmanager,
    remote read and write infrastructure, or even other Prometheis through federation.
    This functionality is usually employed to uniquely identify the source of a given
    alert or time series; therefore, it is common to identify the region, datacenter,
    shard, or even the instance identifier of a Prometheus server.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`external_labels` 允许你设置标签名/值对，这些标签会添加到发送到外部系统的时间序列或警报中，例如 Alertmanager、远程读写基础设施，甚至是通过联合（federation）连接的其他
    Prometheus 实例。此功能通常用于唯一标识给定警报或时间序列的来源；因此，通常会标识区域、数据中心、分片，甚至是 Prometheus 服务器的实例标识符。
- en: 'As per the official documentation, the plural form of *Prometheus* is *Prometheis*:
    [https://prometheus.io/docs/introduction/faq/#what-is-the-plural-of-prometheus](https://prometheus.io/docs/introduction/faq/#what-is-the-plural-of-prometheus).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 根据官方文档，*Prometheus* 的复数形式是 *Prometheis*：[https://prometheus.io/docs/introduction/faq/#what-is-the-plural-of-prometheus](https://prometheus.io/docs/introduction/faq/#what-is-the-plural-of-prometheus)。
- en: Scrape configuration
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 抓取配置
- en: Even though Prometheus accepts an empty file as a valid configuration file,
    the absolute minimum useful configuration needs a `scrape_configs` section. This
    is where we define the targets for metrics collection, and if some post-scrape
    processing is needed before actual ingestion.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Prometheus 将空文件视为有效的配置文件，但最基本的有效配置需要一个 `scrape_configs` 部分。在这里，我们定义用于指标收集的目标，以及在实际数据摄取之前是否需要进行一些抓取后处理。
- en: 'In the configuration example we introduced previously, we defined two scrape
    jobs: `prometheus` and `blackbox`. In Prometheus terms, a scrape is the action
    of collecting metrics through an HTTP request from a targeted instance, parsing
    the response, and ingesting the collected samples to storage. The default HTTP
    endpoint used in the Prometheus ecosystem for metrics collection is aptly named
    `/metrics`.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前介绍的配置示例中，我们定义了两个抓取任务：`prometheus` 和 `blackbox`。在 Prometheus 的术语中，抓取是指通过 HTTP
    请求从目标实例收集指标，解析响应，并将收集的样本存入存储。Prometheus 生态系统中用于指标收集的默认 HTTP 端点恰当地命名为 `/metrics`。
- en: 'A collection of such instances is called a **job**. The instances in a job
    are usually all running copies of the same service, and so there is usually a
    job definition for each kind of monitored software, though this can be a bit different
    when using service discovery, as we''ll see in [Chapter 12](5360e790-3884-4eeb-aaa1-8aad21dc6c1e.xhtml),
    *Choosing the Right Service Discovery*. The combination of instance and job identify
    the source of the collected samples, and so these are automatically added as labels
    to the ingested data, as shown in the following code block:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的实例集合被称为**任务**。任务中的实例通常是相同服务的多个运行副本，因此通常会为每种被监控的软件定义一个任务，即使在使用服务发现时也可能有所不同，正如我们在[第12章](5360e790-3884-4eeb-aaa1-8aad21dc6c1e.xhtml)《选择正确的服务发现》中将看到的那样。实例和任务的组合标识了收集样本的来源，因此这些会自动作为标签添加到摄取的数据中，如下代码块所示：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'A scrape job definition needs at least a `job_name` and a set of targets. In
    this example, `static_configs` was used to declare the list of targets for both
    scrape jobs. While Prometheus supports a lot of ways to dynamically define this
    list, `static_configs` is the simplest and most straightforward method:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一个抓取任务定义至少需要一个 `job_name` 和一组目标。在此示例中，`static_configs` 被用来声明两个抓取任务的目标列表。虽然 Prometheus
    支持多种动态定义该列表的方法，但 `static_configs` 是最简单和直接的方法：
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Analyzing the `prometheus` scrape job in detail, we can see that both `scrape_interval`
    and `scrape_timeout` can be redeclared at the job level, thus overriding the global
    values. As stated before, having varying intervals is discouraged, so only use
    this when absolutely necessary.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 详细分析 `prometheus` 抓取任务后，我们可以看到 `scrape_interval` 和 `scrape_timeout` 都可以在任务级别重新声明，从而覆盖全局值。如前所述，不推荐使用不同的抓取间隔，因此仅在绝对必要时使用此功能。
- en: By setting `sample_limit`, Prometheus will ensure that whatever value was set,
    it will be collected per scrape by not ingesting those samples when their number
    goes over the limit and marking the scrape as failed. This is a great safety net
    for preventing a cardinality explosion from a target outside of your control impacting
    the monitoring system.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通过设置 `sample_limit`，Prometheus 将确保不论设置了什么值，它都会在每次抓取时检查，如果样本数量超过限制，则不摄取这些样本，并将该次抓取标记为失败。这是一个很好的安全机制，可以防止来自不可控目标的基数爆炸影响监控系统。
- en: 'The last relevant configuration here is `metric_relabel_configs`. This is a
    powerful rewrite engine that allows a collected metrics'' identity to be transformed,
    or even dropped, before being saved to storage. The most common use cases for
    this feature is to blacklist a set of misbehaving metrics, dropping labels without
    compromising a metric''s identity, or changing labels to better match Prometheus
    semantics. Ideally, `metric_relabel_configs` should be used as a stopgap while
    the problems aren''t fixed at the source and so using it often can be a red flag.
    The preceding example is using `metric_relabel_configs` to drop every metric that
    starts with `expensive_metric_`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这里最后一个相关的配置是 `metric_relabel_configs`。这是一个强大的重写引擎，允许在保存到存储之前转换或丢弃收集到的指标的身份。此功能最常见的使用场景是将一组表现不佳的指标列入黑名单，丢弃标签而不影响指标的身份，或者更改标签以更好地符合
    Prometheus 的语义。理想情况下，`metric_relabel_configs` 应该作为在源头问题未解决之前的临时解决方法，因此频繁使用它可能是一个警示信号。前面的示例使用
    `metric_relabel_configs` 来丢弃每个以 `expensive_metric_` 开头的指标：
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'While we are going to explore blackbox exporter in depth in the next chapter,
    its configuration is used here to help explain the following important configurations:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们将在下一章深入探讨 blackbox exporter，但这里的配置用于帮助解释以下重要配置：
- en: '`metrics_path` is used to change which endpoint Prometheus should scrape'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metrics_path` 用于更改 Prometheus 应该抓取的端点'
- en: '`scheme` defines whether HTTP or HTTPS is going to be used when connecting
    to targets'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scheme` 定义了连接目标时是使用 HTTP 还是 HTTPS'
- en: '`params` allows you to define a set of optional HTTP parameters'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`params` 允许你定义一组可选的 HTTP 参数'
- en: 'However, the most important and most useful configuration is `relabel_configs`.
    It provides the same powerful semantics as `metric_relabel_configs`, but it has
    a very different function; `relabel_configs` is used to manipulate the scrape
    job''s list of targets. The relabel actions are performed in sequence, and so
    it is possible to create or modify labels and then use those in the next action.
    By default, a target will have a couple of labels that have been generated automatically
    and that will be available for relabeling: the `job` label will be set to the
    `job_name` configuration,  `__address__` label will be created with the target''s
    host and port, `__scheme__` and `__metrics_path__` labels will be set to their
    respective configurations (`scheme` and `metrics_path`), and a `__param_<name>` label
    will be created for each of the parameters defined in the `params` configuration.
    Additionally, `__meta_` labels will be available when using a service discovery
    mechanism, as we''ll see in [Chapter 12](5360e790-3884-4eeb-aaa1-8aad21dc6c1e.xhtml),
    *Choosing the Right Service Discovery*. If the `instance` label is not set by
    the end of the relabeling phase, `__address__` will be used to set it. Labels
    that start with two underscores (`__`) will be removed when the relabeling phase
    ends. As a final note, if you need temporary labels during the relabeling process,
    always use the `__tmp` prefix, as it is guaranteed to not overlap with Prometheus
    internal labels.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，最重要且最有用的配置是 `relabel_configs`。它提供与 `metric_relabel_configs` 相同的强大语义，但功能完全不同；`relabel_configs`
    用于操作抓取任务的目标列表。重新标记操作是按顺序执行的，因此可以创建或修改标签，然后在下一个操作中使用这些标签。默认情况下，目标将具有几个自动生成的标签，这些标签将可供重新标记使用：`job`
    标签将设置为 `job_name` 配置，`__address__` 标签将使用目标的主机和端口生成，`__scheme__` 和 `__metrics_path__`
    标签将设置为各自的配置（`scheme` 和 `metrics_path`），并且会为 `params` 配置中定义的每个参数创建一个 `__param_<name>`
    标签。此外，当使用服务发现机制时，`__meta_` 标签将可用，正如我们在[第12章](5360e790-3884-4eeb-aaa1-8aad21dc6c1e.xhtml)
    *选择合适的服务发现*中看到的那样。如果在重新标记阶段结束时 `instance` 标签未设置，则将使用 `__address__` 来设置它。以两个下划线开头的标签（`__`）将在重新标记阶段结束时被删除。最后，如果在重新标记过程中需要临时标签，始终使用
    `__tmp` 前缀，因为它保证不会与 Prometheus 内部标签重叠。
- en: 'In the case of the blackbox exporter, this functionality is very useful as
    we need to send the probe requests to the exporter, which will then use the `target`
    `GET` parameter to perform its job. So, going through the example, for each target
    specified in `static_configs`, this configuration does the following:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于黑盒导出器，这个功能非常有用，因为我们需要将探测请求发送到导出器，导出器将使用 `target` 的 `GET` 参数来执行其工作。因此，通过这个示例，对于
    `static_configs` 中指定的每个目标，此配置执行以下操作：
- en: Copies the target's address into a `__param_target` label, which will be used
    to set the `target` `GET` parameter in the scrape
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将目标的地址复制到 `__param_target` 标签中，该标签将用于设置抓取中的 `target` `GET` 参数。
- en: Copies the content of this newly created label into the `instance` label so
    that it is explicitly set, bypassing the automatic generation based on the `__address__`
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将新创建的标签的内容复制到 `instance` 标签中，以便明确设置它，绕过基于 `__address__` 的自动生成。
- en: Replaces the `__address__` label with the address of the blackbox exporter so
    that scrapes are done to the exporter and not directly to the target we specified
    in `` `static_configs` ``
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用黑盒导出器的地址替换 `__address__` 标签，以便抓取任务被定向到导出器，而不是直接定向到我们在 `` `static_configs` ``
    中指定的目标。
- en: While `relabel_configs` is used to rewrite the target list (it runs before the
    scrape is performed), `metric_relabel_configs` is used to rewrite labels or drop
    samples (it runs after the scrape is performed).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`relabel_configs` 用于重写目标列表（它在抓取之前运行），而 `metric_relabel_configs` 用于重写标签或删除样本（它在抓取之后运行）。'
- en: The example configuration used in this section is for demonstration purposes
    only. For example, there should be no need to set `sample_limit` on Prometheus
    itself, or to drop metrics without a concrete reason.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中使用的示例配置仅用于演示目的。例如，通常不需要在 Prometheus 本身上设置 `sample_limit`，或者在没有明确理由的情况下删除度量指标。
- en: A very useful metric that must be introduced is the `up` metric. This metric
    exposes the status of a scrape job. It includes, at least, a label with the correspondent
    job name and another with the targeted instance. In its sample, we can have the
    value `1` for a successful scrape or `0` for a failed one.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常有用的度量是 `up` 度量。这个度量暴露了抓取任务的状态。它至少包括一个与相应任务名称的标签和另一个与目标实例的标签。在其样本中，成功抓取时我们可以看到值
    `1`，而抓取失败时则为 `0`。
- en: Next, we're going to start managing Prometheus in different deployment environments.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将开始在不同的部署环境中管理 Prometheus。
- en: Managing Prometheus in a standalone server
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在独立服务器上管理 Prometheus
- en: As we previously went through several configuration definitions, we're now ready
    to put them to practice by managing a standalone instance of Prometheus. In these
    examples, we'll be exposing several configurations while providing an environment
    to validate them.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们之前讨论了多个配置定义，现在我们准备通过管理 Prometheus 的独立实例来将它们付诸实践。在这些示例中，我们将展示多个配置，同时提供一个环境来验证它们。
- en: Server deploy
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务器部署
- en: 'To create a new instance of Prometheus, move into the correct repository path,
    as shown here:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个新的 Prometheus 实例，请移动到正确的仓库路径，如下所示：
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Ensure that no other test environments are running and spin up this chapter''s
    environment, like so:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 确保没有其他测试环境正在运行，然后启动本章的环境，如下所示：
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: After a few moments, the new instance will be available for inspection, and
    the Prometheus web interface will be accessible at `http://192.168.42.10:9090`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 几秒钟后，新的实例将可供检查，并且 Prometheus Web 界面可以通过`http://192.168.42.10:9090`访问。
- en: Configuration inspection
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置检查
- en: 'With the newly created instance running, it''s time to log in using the following
    command:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 创建新的实例并运行后，使用以下命令登录：
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can validate the startup configuration in use by looking into its `systemd`
    unit file by using the following command:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下命令查看`systemd`单元文件来验证当前使用的启动配置：
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following excerpt shows the flags that are currently in place:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 以下摘录显示了当前的标志设置：
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The configuration file for Prometheus itself, as defined by the `--config.file` flag,
    can be reviewed as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 本身的配置文件，如`--config.file`标志所定义，可以按如下方式查看：
- en: '[PRE10]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As we can see, the configuration in use is similar to the one that was presented
    previously, in the Prometheus configuration file walkthrough. We can now validate
    a couple of concepts we mentioned previously.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，当前使用的配置与之前在 Prometheus 配置文件演示中展示的配置类似。我们现在可以验证之前提到的一些概念。
- en: 'Due to `metric_relabel_configs` in the `prometheus` job, we can use two of
    Prometheus'' per-scrape metrics to determine the number of samples being dropped
    by our configuration as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`prometheus`任务中的`metric_relabel_configs`，我们可以使用 Prometheus 的两个按抓取的指标来确定我们的配置丢弃的样本数量，如下所示：
- en: '`scrape_samples_scraped`: This metric provides the total of samples collected'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scrape_samples_scraped`：此指标提供已收集样本的总数'
- en: '`scrape_samples_post_metric_relabeling`: This metric provides the total of
    samples available after the metric relabeling takes place'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scrape_samples_post_metric_relabeling`：此指标提供在指标重标记发生后可用的样本总数'
- en: 'If we subtract these two metrics, we obtain the number of dropped samples (in
    our example, this is all of the metric names starting with `go_`):'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们减去这两个指标，我们就可以得到丢弃的样本数量（在我们的示例中，这些是所有以`go_`开头的指标名称）：
- en: '![](img/b5186397-edfd-4ac5-a0b5-e7ee7282c009.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b5186397-edfd-4ac5-a0b5-e7ee7282c009.png)'
- en: Figure 5.2: Number of metrics being dropped
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2：丢弃的指标数量
- en: 'We can confirm the outcome of the configuration relabeling, which in our example,
    generates the instance labels under the `blackbox` job:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以确认配置重标记的结果，在我们的示例中，它生成了`blackbox`任务下的实例标签：
- en: '![](img/81d9eaa7-bc18-414f-b81d-3a879252e4bd.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/81d9eaa7-bc18-414f-b81d-3a879252e4bd.png)'
- en: Figure 5.3: Instance labels generated by *relabel_configs*
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3：由*relabel_configs*生成的实例标签
- en: You can validate the Prometheus configuration by using a provided utility called
    `promtool`, which will be thoroughly dissected on [Chapter 8](19357d8c-dfcf-4497-ae80-4761f6633d14.xhtml),* Troubleshooting
    and Validation*. When reloading Prometheus with a new configuration, you also
    have the option to look at the `prometheus_config_last_reload_successful` metric
    to assess whether the configuration was successfully parsed and applied.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过使用提供的工具`promtool`来验证 Prometheus 配置，它将在[第 8 章](19357d8c-dfcf-4497-ae80-4761f6633d14.xhtml)中详细分析，*故障排除与验证*。当使用新配置重新加载
    Prometheus 时，您还可以查看`prometheus_config_last_reload_successful`指标，评估配置是否已成功解析并应用。
- en: Cleanup
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清理
- en: 'When you''ve finish testing, just make sure you''re inside the `chapter05/` path
    and execute the following:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 完成测试后，只需确保您位于`chapter05/`路径下并执行以下命令：
- en: '[PRE11]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Don't worry too much – you can easily spin up the environment again if you so
    require.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 不必过于担心——如果需要，您可以轻松重新启动环境。
- en: Managing Prometheus in Kubernetes
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中管理 Prometheus
- en: Kubernetes is the first project to graduate from the CNCF and is currently the
    de facto standard for container orchestration. Early on, Heapster was widely used
    as a monitoring solution that came out-of-the-box with Kubernetes. It started
    out as a tool to send monitoring data to external systems but then grew to become
    a monitoring system itself. However, it didn't take long for Prometheus to become
    the de facto standard monitoring system for Kubernetes clusters. Nowadays, most
    of the components that make up a Kubernetes cluster have native Prometheus instrumentation.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是首个从CNCF毕业的项目，目前是容器编排的事实标准。早期，Heapster被广泛用作与Kubernetes一起开箱即用的监控解决方案。最初，它是一个将监控数据发送到外部系统的工具，但后来它发展成了一个监控系统。然而，Prometheus很快成为Kubernetes集群的事实标准监控系统。如今，构成Kubernetes集群的大多数组件都内置了Prometheus监控功能。
- en: In the following sections, we'll go into how to integrate Prometheus in a Kubernetes
    environment by, employing examples based on the Kubernetes project and the Prometheus
    Operator project.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将探讨如何通过基于Kubernetes项目和Prometheus Operator项目的示例，将Prometheus集成到Kubernetes环境中。
- en: 'You can find the complete source code of the Kubernetes project and the Prometheus
    Operator at the following addresses, respectively:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以分别在以下地址找到Kubernetes项目和Prometheus Operator的完整源代码：
- en: '[https://github.com/kubernetes/kubernetes](https://github.com/kubernetes/kubernetes)
    and [https://github.com/coreos/prometheus-operator](https://github.com/coreos/prometheus-operator).'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/kubernetes/kubernetes](https://github.com/kubernetes/kubernetes)
    和 [https://github.com/coreos/prometheus-operator](https://github.com/coreos/prometheus-operator)。'
- en: 'Ensure that you have all the software requirements that were defined in [Chapter
    3](8f575e82-4713-45c7-8eb3-0af3e0e61ed3.xhtml), *Setting Up a Test Environment*,
    available in their specific versions, particularly the following:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已经具备[第3章](8f575e82-4713-45c7-8eb3-0af3e0e61ed3.xhtml)中定义的所有软件要求，*设置测试环境*，并确保它们是特定版本，特别是以下内容：
- en: Minikube
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Minikube
- en: kubectl
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kubectl
- en: Static configuration
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 静态配置
- en: Although this approach is quite far from being advised, it provides the foundations
    to better understand and troubleshoot a Prometheus server running in Kubernetes.
    In this example, we'll create a Prometheus deployment using a ConfigMap to define
    the server configuration.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种方法远非推荐，但它为更好地理解和排除Kubernetes中运行的Prometheus服务器的故障提供了基础。在此示例中，我们将创建一个Prometheus部署，使用ConfigMap定义服务器配置。
- en: Kubernetes environment
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes环境
- en: 'Ensure that there''s no instance of `minikube` running the following commands:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 确保没有`minikube`实例在运行以下命令：
- en: '[PRE12]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`minikube delete` is a destructive instruction, so be sure you save your work
    before proceeding.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`minikube delete`是一个破坏性指令，所以在继续之前，请确保保存你的工作。'
- en: 'Start a new `minikube` instance with the following specifications:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下规格启动一个新的`minikube`实例：
- en: '[PRE13]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'When the previous command finishes, a new Kubernetes environment should be
    ready to be used. You may access its dashboard by using the following command,
    which will open the Kubernetes dashboard address in your default browser:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当上一个命令完成后，一个新的Kubernetes环境应该已经准备好使用。你可以通过以下命令访问其仪表盘，该命令将在默认浏览器中打开Kubernetes仪表盘地址：
- en: '[PRE14]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To proceed with our example, ensure that you move into the correct repository
    path, like so:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要继续我们的示例，请确保进入正确的仓库路径，如下所示：
- en: '[PRE15]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'For the sake of organization, we''ll be creating a new namespace called `monitoring`
    using the following manifest with the help of `kubectl`:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 为了组织结构，我们将使用`kubectl`帮助创建一个新的命名空间，命名为`monitoring`，并使用以下清单：
- en: '[PRE16]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Apply the previous manifest using the following command:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用上面的清单：
- en: '[PRE17]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We can validate the successful namespace creation on the Kubernetes dashboard:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在Kubernetes仪表盘上验证命名空间的成功创建：
- en: '![](img/29f1589b-449a-4300-9623-28fcd8d16f23.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/29f1589b-449a-4300-9623-28fcd8d16f23.png)'
- en: Figure 5.4: Kubernetes dashboard - monitoring namespace
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4：Kubernetes仪表盘 - 监控命名空间
- en: Prometheus server deployment
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Prometheus服务器部署
- en: 'With our new namespace available, it''s time to create a very simple Prometheus
    configuration and save it on a ConfigMap using the following manifest:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的新命名空间可用之后，是时候创建一个非常简单的Prometheus配置，并使用以下清单将其保存到ConfigMap中：
- en: '[PRE18]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Apply the previous manifest using the following command:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用上面的清单：
- en: '[PRE19]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, it''s time to start a new deployment of Prometheus, making sure we mount
    the previously configured ConfigMap into the pod we are deploying. The Deployment
    object is configured with the following metadata:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候启动 Prometheus 的新部署了，确保我们将之前配置的 ConfigMap 挂载到我们正在部署的 pod 中。Deployment 对象配置如下元数据：
- en: '[PRE20]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The Prometheus container will be started with its configuration file and data
    directory coming from volume mounts, shown as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 容器将根据其配置文件和来自卷挂载的数据目录启动，如下所示：
- en: '[PRE21]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The `config-volume` volume is created from a ConfigMap, while the `prometheus-data`
    volume is created with an empty directory. This can be seen in the following snippet:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`config-volume` 卷是从 ConfigMap 创建的，而 `prometheus-data` 卷是通过空目录创建的。这可以从以下代码片段中看到：'
- en: '[PRE22]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Apply the previous manifest using the following command:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用之前的清单：
- en: '[PRE23]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can follow the deployment status using this snippet:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个代码片段跟踪部署状态：
- en: '[PRE24]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We should look at the logs of our Prometheus instance using the following command:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该使用以下命令查看 Prometheus 实例的日志：
- en: '[PRE25]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'After a successful deployment, we''re ready to assign a new service to our
    instance, choosing `NodePort` so we can access it without requiring port-forwarding,
    like so:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 部署成功后，我们准备好为我们的实例分配一个新服务，选择 `NodePort`，这样我们就可以无需端口转发直接访问它，如下所示：
- en: '[PRE26]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Apply the previous manifest using the following:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用之前的清单：
- en: '[PRE27]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'And you''re ready to check your new Prometheus service using the following
    code snippet:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以使用以下代码片段检查你的新 Prometheus 服务：
- en: '[PRE28]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This will open your browser on the Prometheus service endpoint. You can now
    check the running configuration and targets using the Prometheus web interface:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打开浏览器并指向 Prometheus 服务端点。你现在可以通过 Prometheus 的 web 界面查看正在运行的配置和目标：
- en: '![](img/9d66fcb0-d114-413a-924c-5b1b5a193991.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9d66fcb0-d114-413a-924c-5b1b5a193991.png)'
- en: Figure 5.5: Prometheus initial configuration
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5： Prometheus 初始配置
- en: Now that we have Prometheus running in Kubernetes, we can start adding targets
    for it to scrape. In the next section, we will have a look at how you can achieve
    this.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经在 Kubernetes 中运行了 Prometheus，可以开始为其添加目标进行抓取。在接下来的章节中，我们将看看如何实现这一目标。
- en: Adding targets to Prometheus
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将目标添加到 Prometheus
- en: For the sake of this example, we'll deploy yet another service and add it to
    our Prometheus server, going step by step on how to do it. We'll use a small *Hello
    World* type of application called *Hey* for our setup.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 为了举例说明，我们将部署另一个服务，并逐步演示如何将其添加到我们的 Prometheus 服务器中。我们将使用一个小型的 *Hello World* 类型应用程序，名为
    *Hey*，来进行设置。
- en: The code for the *Hey* application can be inspected at [https://github.com/kintoandar/hey](https://github.com/kintoandar/hey).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '*Hey* 应用程序的代码可以在 [https://github.com/kintoandar/hey](https://github.com/kintoandar/hey)
    上查看。'
- en: 'These steps are quite similar to the deployment of the Prometheus server. Start
    by creating a new deployment for *Hey* using the following manifest:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤与 Prometheus 服务器的部署非常相似。首先使用以下清单创建一个新的 *Hey* 部署：
- en: '[PRE29]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Apply the previous manifest using the following command:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用之前的清单：
- en: '[PRE30]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can follow the deployment status using this code snippet:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个代码片段跟踪部署状态：
- en: '[PRE31]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can validate the logs of our *Hey* instance using the following command:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令验证 *Hey* 实例的日志：
- en: '[PRE32]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'After a successful deployment, we''re ready to assign a new service to our
    instance choosing `NodePort` so that we can access it without requiring port-forwarding,
    like so:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 部署成功后，我们准备好为我们的实例分配一个新服务，选择 `NodePort`，这样我们就可以无需端口转发直接访问它，如下所示：
- en: '[PRE33]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Apply the previous manifest using the following command:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用之前的清单：
- en: '[PRE34]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, you''re ready to check your new *Hey* service like so:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以这样检查你的新 *Hey* 服务：
- en: '[PRE35]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Since Prometheus is statically managed in our example, we need to add the new
    *Hey* target for metric collection. This means that we need to change the Prometheus
    ConfigMap to reflect the newly added service, like so:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在我们的示例中 Prometheus 是静态管理的，我们需要为新的 *Hey* 目标添加指标收集。这意味着我们需要更改 Prometheus 的 ConfigMap
    以反映新增的服务，如下所示：
- en: '[PRE36]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Apply the previous manifest using the following command:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用之前的清单：
- en: '[PRE37]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'If you check the running Prometheus configuration, nothing has changed; this
    is because a new deployment wasn''t triggered. For that to happen, something needs
    to change on the deployment definition, so we just change the version annotation
    and apply the new manifest like so:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你检查正在运行的 Prometheus 配置，你会发现没有变化；这是因为没有触发新的部署。为了使部署生效，需要更改部署定义，因此我们只需更改版本注释并应用新的清单，如下所示：
- en: '[PRE38]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We can follow the deployment status using the following command:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令跟踪部署状态：
- en: '[PRE39]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'After a moment, a new deployment will take place, changing the Prometheus configuration
    and a new target will present itself, which you can validate in the Prometheus
    web user interface:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 片刻后，将会进行一次新的部署，改变 Prometheus 配置并出现一个新的目标，你可以在 Prometheus 的 Web 用户界面中验证这一点：
- en: '![](img/06658f18-12d1-47fd-90e4-f35e00f2c945.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/06658f18-12d1-47fd-90e4-f35e00f2c945.png)'
- en: Figure 5.6: Prometheus targeting the Hey application
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6：Prometheus 定位到 Hey 应用
- en: You may have noticed that no **role-based access control** (**RBAC**) configuration
    was required in this example. This is because all pods run in the same namespace
    and Prometheus didn't require access to the Kubernetes API yet. We strongly believe
    RBAC is fundamental in a secure Kubernetes setup.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，在这个示例中并未要求配置 **基于角色的访问控制** (**RBAC**)。这是因为所有 pod 都运行在同一个命名空间，且 Prometheus
    尚未需要访问 Kubernetes API。我们坚信，RBAC 是安全的 Kubernetes 设置中的基础。
- en: Dynamic configuration – the Prometheus Operator
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态配置 – Prometheus Operator
- en: CoreOS was the pioneer in building a pattern called Operator, which abstracts
    the complexity of packaging, deployment, and the management of Kubernetes applications.
    The Operator synthesizes the knowledge required for the operation of an application
    (such as configuration and deploy logic) into Kubernetes custom resources and
    custom controllers.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 是构建名为 Operator 的模式的先驱，Operator 抽象了 Kubernetes 应用的打包、部署和管理的复杂性。Operator
    将应用所需的操作知识（如配置和部署逻辑）合成到 Kubernetes 自定义资源和自定义控制器中。
- en: A custom resource is an object that extends the Kubernetes API, allowing custom
    API definitions. Custom controller strives to achieve the user's required state
    for a resource, continuously working on maintaining such a state.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义资源是扩展 Kubernetes API 的对象，允许自定义 API 定义。自定义控制器旨在实现资源的用户所需状态，持续保持该状态。
- en: The combination of both a Kubernetes custom resource and custom controller into
    a pattern is what brings the Operator definition to life.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Kubernetes 自定义资源和自定义控制器结合成模式，就是让 Operator 定义得以实现的关键。
- en: When implementing this type of pattern, instead of defining per example, the
    persistent storage for an application, as well as the specific configuration for
    their environment, the user would rather just request an instance of that application,
    and the Operator would abstract all the required dependencies and provide the
    final result automatically.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现这种模式时，用户不需要为每个示例定义持久化存储和特定环境配置，而是直接请求该应用程序的一个实例，Operator 会抽象出所有所需的依赖项，并自动提供最终结果。
- en: 'In our case, besides managing the deployment, including the number of pods
    and persistent volumes of the Prometheus server, the Prometheus Operator will
    also update the configuration dynamically using the concept of ServiceMonitor,
    which targets services with matching rules against the labels of running containers:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，除了管理部署，包括 Prometheus 服务器的 pod 数量和持久化卷外，Prometheus Operator 还将使用 ServiceMonitor
    的概念动态更新配置，ServiceMonitor 会针对运行容器的标签匹配规则来定位服务：
- en: '![](img/ed29b32a-94a0-4d12-b694-1265ce526576.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed29b32a-94a0-4d12-b694-1265ce526576.png)'
- en: Figure 5.7: Prometheus Operator logic diagram
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7：Prometheus Operator 逻辑图
- en: Empowered with this knowledge, we'll provide an example on how to deploy and
    configure Prometheus using the Prometheus Operator, including collecting metrics
    from an application, this time running on a different namespace.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握这些知识后，我们将提供一个示例，展示如何使用 Prometheus Operator 部署和配置 Prometheus，包括从应用程序收集指标，这次我们将在不同的命名空间中运行应用。
- en: Kubernetes environment
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 环境
- en: 'Ensure that there''s no instance of `minikube` running, like so:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 确保没有 `minikube` 实例在运行，如下所示：
- en: '[PRE40]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Start a new `minikube` instance with the following specifications:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下规格启动一个新的 `minikube` 实例：
- en: '[PRE41]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'When the previous command finishes, a new Kubernetes environment should be
    ready to be used. You may access its dashboard by using the following command,
    which will open the Kubernetes dashboard address in your default browser:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 当前一个命令完成后，一个新的 Kubernetes 环境应该准备好使用。你可以使用以下命令访问其仪表盘，命令会在默认浏览器中打开 Kubernetes
    仪表盘地址：
- en: '[PRE42]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'To proceed with the deployment of our example, ensure that you move into the
    correct repository path, as shown here:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 要继续部署我们的示例，请确保进入正确的仓库路径，如下所示：
- en: '[PRE43]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Like the previous example, we''ll be creating a new namespace called `monitoring`
    with the help of `kubectl`, like so:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 像之前的例子一样，我们将使用`kubectl`创建一个新的命名空间，命名为`monitoring`，如下所示：
- en: '[PRE44]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Prometheus Operator deployment
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Prometheus Operator部署
- en: 'With the new namespace available, it''s time to ensure that all access permissions
    are in place for the Prometheus Operator, as shown in the next few configuration
    snippets. The first one defines the `ClusterRole`:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 创建好新的命名空间后，接下来需要确保Prometheus Operator的所有访问权限已经到位，如接下来的几个配置片段所示。第一个片段定义了`ClusterRole`：
- en: '[PRE45]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Then, we apply the `ClusterRole` to a `ClusterRoleBinding`:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将`ClusterRole`应用到`ClusterRoleBinding`：
- en: '[PRE46]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Finally, we create a `ServiceAccount` for the `ClusterRoleBinding`:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们为`ClusterRoleBinding`创建一个`ServiceAccount`：
- en: '[PRE47]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Apply the manifest containing the previous snippets using the following command:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用包含前面片段的清单：
- en: '[PRE48]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Having the new service account configured, we''re ready to deploy the Operator
    itself, like so:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 配置好新的服务账户后，我们准备好部署Operator本身，如下所示：
- en: '[PRE49]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Apply the previous manifest using the following command:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用前面的清单：
- en: '[PRE50]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We can follow the deployment status using the following code snippet:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码片段跟踪部署状态：
- en: '[PRE51]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: With the Operator deployed, we can now use it to deploy and manage Prometheus
    instances.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: Operator部署完成后，我们现在可以使用它来部署和管理Prometheus实例。
- en: Prometheus server deployment
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Prometheus服务器部署
- en: 'Before proceeding with the setup of Prometheus, we''ll need to grant its instances
    with the right access control permissions.  The following snippets from the Prometheus
    RBAC manifest do just that. First we need to create a `ClusterRole` that allows
    Prometheus access to `/metrics` through GET requests:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续设置Prometheus之前，我们需要为其实例授予正确的访问控制权限。以下是Prometheus RBAC清单中的片段，完成了这一任务。首先，我们需要创建一个`ClusterRole`，允许Prometheus通过GET请求访问`/metrics`：
- en: '[PRE52]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Next, we create a `ClusterRoleBinding` to grant the permissions from the aforementioned
    `ClusterRole` to a user, which in our case will be a `ServiceAccount`:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个`ClusterRoleBinding`，将前面提到的`ClusterRole`权限授予用户，在我们的例子中是`ServiceAccount`：
- en: '[PRE53]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Finally, we create a `ServiceAccount` for Prometheus:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们为Prometheus创建一个`ServiceAccount`：
- en: '[PRE54]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Apply the manifest containing the previous snippets using the following command:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用包含前面片段的清单：
- en: '[PRE55]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Having the service account ready, we can now use the Prometheus Operator to
    deploy our Prometheus servers using the following manifest:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 配置好服务账户后，我们可以使用Prometheus Operator通过以下清单部署Prometheus服务器：
- en: '[PRE56]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Apply the previous manifest using the following command:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用前面的清单：
- en: '[PRE57]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We can follow the deployment progress using the following command:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令跟踪部署进度：
- en: '[PRE58]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'When the deployment is finished, we''ll be ready to create a new service for
    our Prometheus servers and launch the web interface to validate the current settings,
    like so:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 部署完成后，我们将准备好为Prometheus服务器创建一个新的服务，并启动Web界面来验证当前设置，如下所示：
- en: '[PRE59]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Following is the Prometheus default configuration created by the Prometheus
    Operator:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是Prometheus Operator创建的Prometheus默认配置：
- en: '![](img/378fe1fa-94fd-43c0-93af-072535466a0e.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](img/378fe1fa-94fd-43c0-93af-072535466a0e.png)'
- en: Figure 5.8: Prometheus default configuration created by the Prometheus Operator
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8：Prometheus Operator创建的Prometheus默认配置
- en: Adding targets to Prometheus
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向Prometheus添加目标
- en: So far, we've deployed the Operator and used it to deploy Prometheus itself.
    Now, we're ready to add targets and go over the logic of how to generate them.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经部署了Operator并使用它部署了Prometheus。现在，我们准备添加目标并探讨生成目标的逻辑。
- en: 'Before proceeding, we''ll also deploy an application to increase the number
    of available targets. For this, we''ll be using the *Hey* application once again,
    this time using the default namespace:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，我们还将部署一个应用程序，以增加可用目标的数量。为此，我们将再次使用*Hey*应用程序，这次使用默认命名空间：
- en: '[PRE60]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Pay close attention to the labels and the port name, as shown in the following
    code block; they''ll be used by the service monitor:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 请特别注意标签和端口名称，如以下代码块所示；它们将被服务监视器使用：
- en: '[PRE61]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Apply the manifest containing the previous snippets using the following command:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用包含前面片段的清单：
- en: '[PRE62]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'We can follow the status of the deployment using the following command:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令跟踪部署状态：
- en: '[PRE63]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'After the deployment finishes, we''ll create a new service, as shown in the
    following code block. Pay close attention to the labels that will be used by the
    service monitor to target this service:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 部署完成后，我们将创建一个新的服务，如以下代码块所示。请特别注意服务监视器将用于定位此服务的标签：
- en: '[PRE64]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Apply the previous manifest using the following command:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用之前的清单：
- en: '[PRE65]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Finally, we are going to create service monitors for both the Prometheus instances
    and the *Hey* application, which will instruct the Operator to configure Prometheus,
    adding the required targets. Pay close attention to the selector configuration –
    it will be used to match the services we created previously.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将为 Prometheus 实例和 *Hey* 应用程序创建服务监视器，指示 Operator 配置 Prometheus，并添加所需的目标。请注意选择器配置——它将用于匹配我们之前创建的服务。
- en: 'The following is the service monitor for Prometheus:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Prometheus 的服务监视器：
- en: '[PRE66]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The service monitor for the *Hey* application is as follows:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '*Hey* 应用程序的服务监视器如下：'
- en: '[PRE67]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Apply the previous manifests using the following command:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用之前的清单：
- en: '[PRE68]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'You can validate the successful deployment of the service monitors using the
    following command:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令验证服务监视器的成功部署：
- en: '[PRE69]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'After the Operator reconfigures Prometheus, which might take a few seconds,
    the added targets should be available on your Prometheus web interface:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Operator 重新配置 Prometheus 后，可能需要几秒钟，新增的目标应该会出现在 Prometheus 的网页界面上：
- en: '![](img/4cc495c2-9f2d-437c-9666-316902f42895.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4cc495c2-9f2d-437c-9666-316902f42895.png)'
- en: Figure 5.9: Prometheus targets after the service monitors' configuration
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9：服务监视器配置后的 Prometheus 目标
- en: ServiceMonitors are the main building block when using the Prometheus Operator.
    You can configure anything that goes into a scrape job, such as scrape and timeout
    intervals, metrics endpoint to scrape, HTTP query parameters, and so on. You can
    find the documentation for these configurations at [https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint](https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint).
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ServiceMonitors 是使用 Prometheus Operator 时的核心构件。你可以配置任何进入抓取作业的内容，如抓取和超时间隔、抓取的指标端点、HTTP
    查询参数等。你可以在 [https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint](https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint)
    找到这些配置的文档。
- en: Summary
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we were introduced to some of the most important configuration
    concepts for setting up a Prometheus server. This knowledge is fundamental for
    tailoring Prometheus for your specific scenario. From startup flags to the configuration
    file, we also spun up an instance to experiment and validate the knowledge we
    obtained.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了设置 Prometheus 服务器的一些重要配置概念。这些知识对定制 Prometheus 以适应特定场景至关重要。从启动标志到配置文件，我们还启动了一个实例来实验并验证我们获得的知识。
- en: As more and more workloads are transitioning to containers, and specifically
    to Kubernetes, we dived into how to set up and manage Prometheus on such an environment.
    We began experimenting with static configurations as a stepping stone to understand
    a more robust approach, the Prometheus Operator.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 随着越来越多的工作负载过渡到容器，特别是 Kubernetes 环境，我们探讨了如何在这种环境中设置和管理 Prometheus。我们开始通过静态配置进行实验，作为理解更强大方法——Prometheus
    Operator 的基础。
- en: In the next chapter, we'll go into the most common exporters and build upon
    what we've learned so that we can successfully collect data from various different
    sources on Prometheus.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入探讨最常见的导出器，并在此基础上进行构建，以便我们能够成功地从 Prometheus 收集来自不同来源的数据。
- en: Questions
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What happens if `scrape_timeout` is not declared explicitly?
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有显式声明 `scrape_timeout` 会发生什么？
- en: How can Prometheus be made to reload its configuration file?
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何让 Prometheus 重新加载其配置文件？
- en: How far back does Prometheus look for data before considering a time series
    stale?
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Prometheus 会回溯多长时间来判断一个时间序列是否过时？
- en: What is the difference between `relabel_configs` and `metric_relabel_configs`?
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`relabel_configs` 和 `metric_relabel_configs` 有什么区别？'
- en: On the static deployment example, we added a Kubernetes service for the Hey
    application as a target in Prometheus. What problems will arise if we increase
    the number of *Hey* pods?
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在静态部署示例中，我们将 Hey 应用程序的 Kubernetes 服务作为目标添加到 Prometheus。如果我们增加 *Hey* pod 的数量，会出现什么问题？
- en: Does static Prometheus static configuration make sense on a Kubernetes environment?
    Why?
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 环境中，静态 Prometheus 配置是否合理？为什么？
- en: In which Kubernetes facilities does the Prometheus Operator rely upon to achieve
    its goals?
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Prometheus Operator 依赖哪些 Kubernetes 组件来实现其目标？
- en: Further reading
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '**Prometheus configuration**: [https://prometheus.io/docs/prometheus/latest/configuration/configuration/](https://prometheus.io/docs/prometheus/latest/configuration/configuration/)'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus 配置**: [https://prometheus.io/docs/prometheus/latest/configuration/configuration/](https://prometheus.io/docs/prometheus/latest/configuration/configuration/)'
- en: '**Prometheus TSDB APIs**: [https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis](https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis)'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus TSDB APIs**: [https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis](https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis)'
- en: '**Prometheus security**: [https://prometheus.io/docs/operating/security/](https://prometheus.io/docs/operating/security/)'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus 安全性**: [https://prometheus.io/docs/operating/security/](https://prometheus.io/docs/operating/security/)'
- en: '**Kubernetes custom controllers**: [https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#custom-controllers](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#custom-controllers)'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubernetes 自定义控制器**: [https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#custom-controllers](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#custom-controllers)'
- en: '**Kubernetes custom resources**: [https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#customresourcedefinitions](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#customresourcedefinitions)'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubernetes 自定义资源**: [https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#customresourcedefinitions](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#customresourcedefinitions)'
- en: '**Prometheus Operator**: [https://github.com/coreos/prometheus-operator/blob/master/Documentation/design.md](https://github.com/coreos/prometheus-operator/blob/master/Documentation/design.md)'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus Operator**: [https://github.com/coreos/prometheus-operator/blob/master/Documentation/design.md](https://github.com/coreos/prometheus-operator/blob/master/Documentation/design.md)'
