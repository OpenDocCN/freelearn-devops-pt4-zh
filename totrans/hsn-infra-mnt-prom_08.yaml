- en: Exporters and Integrations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even though first-party exporters cover the basics pretty well, the Prometheus
    ecosystem provides a wide variety of third-party exporters that cover everything
    else. In this chapter, we will be introduced to some of the most useful exporters
    available—from **operating system** (**OS**) metrics and **Internet Control Message
    Protocol** (**ICMP**) probing to generating metrics from logs, or how to collect
    information from short-lived processes, such as batch jobs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In brief, the following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Test environments for this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operating system exporter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container exporter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From logs to metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blackbox monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pushing metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More exporters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test environments for this chapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll be using two test environments: one based on **virtual
    machines** (**VMs**) that mimic traditional static infrastructure and one based
    on Kubernetes for modern workflows. The following topics will guide you through
    the automated setup procedure for both of them, but will gloss over the details
    from each exporter—these will be explained in depth in their own sections.'
  prefs: []
  type: TYPE_NORMAL
- en: Static infrastructure test environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This method will abstract all the deployment and configuration details, allowing
    you to have a fully provisioned test environment with a couple of commands. You'll
    still be able to connect to each of the guest instances and tinker with the example
    configurations.
  prefs: []
  type: TYPE_NORMAL
- en: 'To launch a new test environment, move into this chapter path, relative to
    the repository root:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Ensure no other test environments are running and spin up this chapter’s environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You can validate the successful deploy of the test environment using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Which will output the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The end result will be an environment like the one depicted in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0c7250b5-02ab-47dd-97c8-78102e3f0217.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.1: Diagram of the static infrastructure test environment'
  prefs: []
  type: TYPE_NORMAL
- en: 'To connect to the `target01` instance, just run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To connect to the Prometheus instance, use the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'When you''re finished with this environment, move into this chapter path, relative
    to the repository root as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'And execute the following instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Kubernetes test environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To start the Kubernetes test environment, we first must ensure there''s no
    instance of `minikube` running as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Start a new `minikube` instance with the following specifications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: When the previous command finishes, a new Kubernetes environment should be ready
    to be used.
  prefs: []
  type: TYPE_NORMAL
- en: For our Kubernetes test environment, we'll be building upon the lessons learned
    in [Chapter 5](12e775c2-bee9-4ebe-ad73-2f9313eeeeee.xhtml), *Running a Prometheus
    Server*, and using Prometheus Operator in our workflow. Since we already covered
    the Prometheus Operator setup, we'll deploy all the required components without
    going over each one of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step into the following chapter number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Deploy the Prometheus Operator and validate the successful deploy as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the Prometheus Operator to deploy Prometheus and ensure the deploy was
    successful like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Add ServiceMonitors as shown in the following code, which will configure Prometheus
    jobs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'After a moment, you should have Prometheus available and ready; the following
    instruction will provide its web interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'You can validate the Kubernetes StatefulSet for Prometheus using the following
    instruction, which will open the Kubernetes dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: More information regarding the Kubernetes objects, including the StatefulSet
    controller, is available at [https://kubernetes.io/docs/concepts/](https://kubernetes.io/docs/concepts/).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot illustrates the correct deployment of the Prometheus
    StatefulSet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8a6e82f8-87c5-48ef-8a16-cde67a650f61.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 - Kubernetes dashboard depicting Prometheus StatefulSet
  prefs: []
  type: TYPE_NORMAL
- en: Operating system exporter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When monitoring infrastructure, the most common place to start looking is at
    the OS level. Metrics for resources such as CPU, memory, and storage devices,
    as well as kernel operating counters and statistics provide valuable insight to
    assess a system's performance characteristics. For a Prometheus server to collect
    these types of metrics, an OS-level exporter is needed on the target hosts to
    expose them in an HTTP endpoint. The Prometheus project provides such an exporter
    that supports Unix-like systems called the Node Exporter, and the community also
    maintains an equivalent exporter for Microsoft Windows systems called the WMI
    exporter.
  prefs: []
  type: TYPE_NORMAL
- en: The Node Exporter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Node Exporter is the most well-known Prometheus exporter, for good reason.
    It provides over 40 collectors for different areas of the OS, as well as a way
    of exposing local metrics for cron jobs and static information about the host.
    Like the rest of the Prometheus ecosystem, the Node Exporter comes with a sane
    default configuration and some smarts to identify what can be collected, so it's
    perfectly reasonable to run it without much tweaking.
  prefs: []
  type: TYPE_NORMAL
- en: In this context, *node* refers to a computer node or host and is not related
    to Node.js in any way.
  prefs: []
  type: TYPE_NORMAL
- en: Although this exporter was designed to be run as a non-privileged user, it does
    need to access kernel and process statistics, which aren't normally available
    when running inside a container. This is not to say that it doesn't work in containers—every
    Prometheus component can be run in containers—but that additional configuration
    is required for it to work. It is, therefore, recommended that the Node Exporter
    be run as a system daemon directly on the host whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: Node Exporter collectors might gather different metrics depending on the system
    being run, as OS kernels vary in the way they expose internal state and what details
    they make available. As an example, metrics exposed by `node_exporter` on macOS
    will be substantially different from the ones on Linux. This means that, even
    though the Node Exporter supports Linux, Darwin (macOS), FreeBSD, OpenBSD, NetBSD,
    DragonFly BSD, and Solaris, each collector within the Node Exporter will have
    their own compatibility matrix, with Linux being the kernel with the most support.
  prefs: []
  type: TYPE_NORMAL
- en: Metric names exposed by the Node Exporter changed in version 0.16.0 due to a
    standardization effort across the Prometheus project. This was a breaking change,
    which means that dashboards and tutorials made for earlier versions of this exporter
    won't work out of the box. An upgrade guide ([https://github.com/prometheus/node_exporter/blob/v0.17.0/docs/V0_16_UPGRADE_GUIDE.md](https://github.com/prometheus/node_exporter/blob/v0.17.0/docs/V0_16_UPGRADE_GUIDE.md))
    can be found in the Node Exporter's repository.
  prefs: []
  type: TYPE_NORMAL
- en: The source code and installation files for the Node Exporter are available at
    [https://github.com/prometheus/node_exporter](https://github.com/prometheus/node_exporter).
  prefs: []
  type: TYPE_NORMAL
- en: By design, this exporter only produces aggregated metrics about processes (such
    as how many are running, and so on) and not individual metrics per process. In
    the Prometheus model, each process of relevance needs to expose its own metrics,
    or have a companion exporter to do that job for it. This is one of the reasons
    why it is ill-advised in most cases to run a generic process exporter without
    an explicit whitelist.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exporters in the Prometheus ecosystem usually collect a specific set of metrics
    from a given process. The Node Exporter differs from most other exporters as machine-level
    metrics span a wide range of subsystems, and so it is architected to provide individual
    collectors, which can be turned on and off, depending on the instrumentation needs.
    Enabling collectors that are turned off by default can be done with the `--collector.<name>`
    set of flags; enabled collectors can be disabled by using the `--no-collector.<name>`
    flag variant.
  prefs: []
  type: TYPE_NORMAL
- en: 'From all the collectors enabled by default, one needs to be singled out due
    to its usefulness as well as its need of configuration to properly work. The `textfile`
    collector enables the exposition of custom metrics by watching a directory for
    files with the `.prom` extension that contain metrics in the Prometheus exposition
    format. The `--collector.textfile.directory` flag is empty by default and so needs
    to be set to a directory path for the collector to do its job. It is expected
    that only instance-specific metrics be exported through this method, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: Local cron jobs can report their exit status through a metric (finish timestamp
    is not useful to record, as the metrics file modification timestamp is already
    exported as a metric)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Informational metrics (that only exist for the labels they provide), such as
    VM flavor, size, or assigned role
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many package upgrades are pending, if a restart is required
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anything else not covered by the built-in collectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The test environment for static infrastructure for this chapter should already
    have `node_exporter` up and running through the automatic provisioning. Nevertheless,
    we can inspect it by connecting, for example, to the `target01` VM as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Then check the configuration of the provided `systemd` unit file like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'In this snippet, we can see the `textfile` collector directory being set so
    that custom metrics can be exported:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s try creating a custom metric. To do that, we only need to write the
    metric to a file inside the `textfile` collector directory with a `.prom` extension
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In a real-world scenario, you would need to make sure the file was written atomically
    so that `node_exporter` wouldn't see a half-written (thus corrupted) file. You
    could either write it out to a temporary file and then `mv` it into place (taking
    care to not cross mount point boundaries), or use the `sponge` utility, which
    is usually found in the `moreutils` package.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then request the `/metrics` endpoint and search for our test metric
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This exporter produces a large number of metrics, depending on which collectors
    are enabled. Some of the more interesting metrics available from `node_exporter`
    are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`node_cpu_seconds_total`, which provides the number of seconds cumulatively
    used per core for all the available CPU modes, is very useful for understanding
    the CPU utilization'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`node_memory_MemTotal_bytes` and `node_memory_MemAvailable_bytes`, which allow
    calculating the ratio of memory available'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`node_filesystem_size_bytes` and `node_filesystem_avail_bytes`, which enable
    the calculation of filesystem utilization'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`node_textfile_scrape_error`, which tells you if the textfile collector couldn''t
    parse any of the metrics files in the textfile directory (when this collector
    is enabled)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container exporter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the constant pursuit for workload isolation and resource optimization, we
    witnessed the move from physical to virtualized machines using hypervisors. Using
    virtualization implies a certain degree of resource usage inefficiency, as the
    storage, CPU, and memory need to be allocated to each running VM whether it uses
    them or not. A lot of work has been done in this area to mitigate such inefficiencies
    but, in the end, fully taking advantage of system resources is still a difficult
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the rise of operating-system-level virtualization on Linux (that is, the
    use of containers), the mindset changed. We no longer want a full copy of an OS
    for each workload, but instead, only properly isolated processes to do the desired
    work. To achieve this, and focusing specifically on Linux containers, a set of
    kernel features responsible for isolating hardware resources (named cgroups or
    control groups) and kernel resources (named namespaces) were made available. Resources
    managed by cgroups are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: CPU
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disk I/O
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These kernel features allow the user to have fine control over what resources
    a given workload has available, thus optimizing resource usage. Cgroups metrics
    are invaluable to any modern monitoring system.
  prefs: []
  type: TYPE_NORMAL
- en: cAdvisor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Container Advisor** (**cAdvisor**) is a project developed by Google that
    collects, aggregates, analyzes, and exposes data from running containers. The
    data available covers pretty much anything you might require, from memory limits
    to GPU metrics, all available and segregated by container and/or host.'
  prefs: []
  type: TYPE_NORMAL
- en: cAdvisor isn't tied to Docker containers but it's usually deployed as one. Data
    is collected from the container daemon and Linux cgroups, making the discovery
    of containers transparent and completely automatic. It also exposes process limits
    and throttling events whenever these limits are reached, which is important information
    to keep an eye on to maximize infrastructure resource usage without negatively
    impacting workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Besides exposing metrics in the Prometheus format, cAdvisor also ships with
    a useful web interface, allowing the instant visualization of the status of hosts
    and their containers.
  prefs: []
  type: TYPE_NORMAL
- en: The source code and installation files for cAdvisor are available at [https://github.com/google/cadvisor](https://github.com/google/cadvisor).
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When launching cAdvisor as a container, some host paths are required to be available
    in read-only mode. This will allow, for example, the collection of kernels, processes,
    and container data.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are quite a few runtime flags, so we''ll feature some of the most relevant
    for our test case in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Flag** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `--docker` | Docker endpoint, defaults to `unix:///var/run/docker.sock` |'
  prefs: []
  type: TYPE_TB
- en: '| `--docker_only` | Only report containers in addition to root stats |'
  prefs: []
  type: TYPE_TB
- en: '| `--listen_ip` | IP to bind on, default to `0.0.0.0` |'
  prefs: []
  type: TYPE_TB
- en: '| `--port` | Port to listen on, defaults to `8080` |'
  prefs: []
  type: TYPE_TB
- en: '| `--storage_duration` | How long to store data, defaults to `2m0s` |'
  prefs: []
  type: TYPE_TB
- en: 'You can inspect the available runtime configurations using the following address:
    [https://github.com/google/cadvisor/blob/release-v0.33/docs/runtime_options.md](https://github.com/google/cadvisor/blob/release-v0.33/docs/runtime_options.md).'
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although historically the cAdvisor code was embedded in the Kubelet binary,
    it is currently scheduled to be deprecated there. Therefore, we'll be launching
    cAdvisor as a DaemonSet to future proof this example and to expose its configurations,
    while also enabling its web interface, as a Kubernetes service, to be explored.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ensure you move into the correct repository path as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we must create a DaemonSet, because we want cAdvisor running in every
    single node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice all the volume mounts allowing the collection of data from the Docker
    daemon and various Linux resources as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the previous manifest using the following instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We can follow the deployment status using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'When the deployment finishes, it''s time to add a new service. Notice the port
    name that will be used in the ServiceMonitor. Here''s the manifest we''ll be using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The manifest can be applied using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now connect to the cAdvisor web interface using the following instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This will open a browser window with an interface similar to the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/21261d68-ce9a-41af-a132-ea1ae8e77535.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.3: cAdvisor web interface'
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s time to add cAdvisor exporters as new targets for Prometheus. For that,
    we''ll be using the next `ServiceMonitor` manifest as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The previous manifest can be applied using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'After a few moments, you can inspect the newly added targets in the Prometheus
    web interface, using the following instruction to open its web interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The following figure illustrates the Prometheus `/targets` endpoint showing
    cAdvisor target:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f901508a-146e-4557-bc0a-b73f384cc5b7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.4: Prometheus */targets* endpoint showing cAdvisor target'
  prefs: []
  type: TYPE_NORMAL
- en: With this, we now have container-level metrics. Do note that cAdvisor exports
    a large amount of samples per container, which can easily balloon exported metrics
    to multiple thousands of samples per scrape, possibly causing cardinality-related
    issues on the scraping Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: You can find every metric exposed by cAdvisor at their Prometheus documentation: [https://github.com/google/cadvisor/blob/release-v0.33/docs/storage/prometheus.md](https://github.com/google/cadvisor/blob/release-v0.33/docs/storage/prometheus.md).
  prefs: []
  type: TYPE_NORMAL
- en: 'From the thousands of metrics exported by cAdvisor, these are generally useful
    for keeping an eye out for problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '`container_last_seen`,  which keeps track of the timestamp the container was
    last seen as running'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`container_cpu_usage_seconds_total`, which gives you a counter of the number
    of CPU seconds per core each container has used'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`container_memory_usage_bytes` and `container_memory_working_set_bytes`, which
    keep track of container memory usage (including cache and buffers) and just container
    active memory, respectively'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`container_network_receive_bytes_total` and `container_network_transmit_bytes_total`,
    which let you know how much traffic in the container receiving and transmitting,
    respectively'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When running on Kubernetes, cAdvisor doesn''t provide you with insight into
    how the cluster is running—application-level metrics from Kubernetes itself. For
    this, we need another exporter: kube-state-metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: kube-state-metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'kube-state-metrics does not export container-level data, as that''s not its
    function. It operates at a higher level, exposing the Kubernetes state, providing
    metrics regarding the API internal objects such as pods, services, or deployments.
    The object metric groups currently available when using this exporter are the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: CronJob metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DaemonSet metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Job metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LimitRange metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Node metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PersistentVolume metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PersistentVolumeClaim metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pod metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pod Disruption Budget metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ReplicaSet metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ReplicationController metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resource quota metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: StatefulSet metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Namespace metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Horizontal Pod Autoscaler metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Endpoint metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secret metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ConfigMap metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are two endpoints exposed by kube-state-metrics: one provides the API
    objects metrics and the other presents the internal metrics from the exporter
    itself.'
  prefs: []
  type: TYPE_NORMAL
- en: The source code and installation files for kube-state-metrics are available
    at [https://github.com/kubernetes/kube-state-metrics](https://github.com/kubernetes/kube-state-metrics).
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When configuring kube-state-metrics, other than all the required RBAC permissions,
    there are also several runtime flags to be aware of. We will provide an overview
    of the more relevant ones for our test case in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Flag** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `--host` | IP to bind and expose Kubernetes metrics on, defaults to `0.0.0.0`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `--port` | Port to expose Kubernetes metrics, defaults to `80` |'
  prefs: []
  type: TYPE_TB
- en: '| `--telemetry-host` | IP to expose internal metrics, defaults to `0.0.0.0`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `--telemetry-port` | Port to expose internal metrics, defaults to `80` |'
  prefs: []
  type: TYPE_TB
- en: '| `--collectors` | Comma-separated list of metrics groups to enable, defaults
    to ConfigMap, CronJobs, DaemonSets, Deployments, endpoints, horizontalpodautoscalers,
    Jobs, LimitRanges, namespaces, Nodes, PersistentVolumeClaims, PersistentVolumes,
    PodDisruptionBudgets, pods, ReplicaSets, ReplicationControllers, resource quotas,
    Secrets, services, StatefulSets |'
  prefs: []
  type: TYPE_TB
- en: '| `--metric-blacklist` | Comma-separated list of metrics to disable, mutually
    exclusive with the whitelist |'
  prefs: []
  type: TYPE_TB
- en: '| `--metric-whitelist` | Comma-separated list of metrics to enable, mutually
    exclusive with the blacklist |'
  prefs: []
  type: TYPE_TB
- en: Due to the unpredictable amount of objects required to be exported, which are
    directly proportional to the size of the cluster, a common pattern when deploying
    kube-state-metrics is to use a special container called **addon-resizer**, which
    can vertically resize the exporter pod dynamically. Information regarding *addon-resizer*
    can be found at [https://github.com/kubernetes/autoscaler/tree/addon-resizer-release-1.8](https://github.com/kubernetes/autoscaler/tree/addon-resizer-release-1.8).
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ll be building upon the Kubernetes test environment started previously.
    To begin the deployment, ensure you move into the correct repository path, relative
    to the repository root as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: As access to the Kubernetes API is required, the **role-based access control**
    (**RBAC**) configuration for this deploy is quite extensive, which includes a
    Role, a RoleBinding, a ClusterRole, a ClusterRoleBinding, and a ServiceAccount.
    This manifest is available at `./kube-state-metrics/kube-state-metrics-rbac.yaml`.
  prefs: []
  type: TYPE_NORMAL
- en: 'It should be applied using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll be creating a deployment for kube-state-metrics with just one instance,
    as, in this case, no clustering or special deployment requirements are necessary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This deployment will run an instance of the `kube-state-metrics` exporter,
    along with `addon-resizer` to scale the exporter dynamically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This can be applied using the following instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We can follow the deployment status using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'After a successful deployment, we''ll be creating a service for this exporter,
    this time with two ports: one for the Kubernetes API object metrics and another
    for the exporter''s internal metrics themselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The previous manifest can be applied as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'With the service in place, we are able to validate both metrics endpoints using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'This will open two different browser tabs, one for each metrics endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/41899a12-c246-4f9c-99ad-f2b051013453.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5: The kube-state-metrics web interface
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, it is time to configure Prometheus to scrape both endpoints using
    the `ServiceMonitor` manifest as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'And it can now be applied using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now validate the correct configuration of scrape targets in Prometheus,
    using the following instruction to open its web interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/cb45ae0f-8e9f-481e-b075-ab635a27c1cf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.6: Prometheus /targets endpoint showing kube-state-metrics targets
    for metrics and telemetry'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some interesting metrics from kube-state-metrics that can be used to keep an
    eye on your Kubernetes clusters are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kube_pod_container_status_restarts_total`, which can tell you if a given pod
    is restarting on a loop;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube_pod_status_phase`, which can be used to alert on pods that are in a non-ready
    state for a long time;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparing `kube_<object>_status_observed_generation` with `kube_<object>_metadata_generation`
    can give you a sense when a given object has failed but hasn't been rolled back
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From logs to metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a perfect world, all applications and services would have been properly
    instrumented and we would only be required to collect metrics to gain visibility.
    External exporters are a stop-gap approach that simplifies our work, but not every
    service exposes its internal state through a neat API. Older daemon software,
    such as Postfix or ntpd, makes use of logging to relay their inner workings. For
    these cases, we''re left with two options: either instrument the service ourselves
    (which isn''t possible for closed source software) or rely on logs to gather the
    metrics we require. The next topics go over the available options for extracting
    metrics from logs.'
  prefs: []
  type: TYPE_NORMAL
- en: mtail
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Developed by Google, mtail is a very light log processor that is capable of
    running programs with pattern matching logic, allowing the extraction of metrics
    from said logs. It supports multiple export formats, such as Prometheus, StatsD,
    Graphite, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides the `/metrics` endpoint, the `/` endpoint for the mtail service exposes
    valuable debug information. This endpoint is available in the static infrastructure
    test environment at `http://192.168.42.11:9197`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/80ad4e51-8be9-4473-8202-3ed0462d3b6f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.7: mtail web interface'
  prefs: []
  type: TYPE_NORMAL
- en: The source code and installation files for mtail are available at [https://github.com/google/mtail](https://github.com/google/mtail).
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To configure mtail, we require a program with the pattern matching logic. Let''s
    look at a very straightforward example available in the official repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: This program defines the `line_count` metric of the `counter` type, an RE2-compatible
    expression `/$/` matching the end of a line, and finally, an action between `{
    }`, which, in this case, increments the `line_count` counter.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run this program, we are only required to start mtail with command line
    flags to point it to our program and to the log we want to monitor. Here are some
    of the most useful flags for our test case:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `-address` | Host or IP to bind |'
  prefs: []
  type: TYPE_TB
- en: '| `-port` | Listener port, defaults to `3903` |'
  prefs: []
  type: TYPE_TB
- en: '| `-progs` | Path to the programs |'
  prefs: []
  type: TYPE_TB
- en: '| `-logs` | Comma-separated list of files to monitor (this flag can be set
    multiple times) |'
  prefs: []
  type: TYPE_TB
- en: You can find the mtail programming guide at [https://github.com/google/mtail/blob/master/docs/Programming-Guide.md](https://github.com/google/mtail/blob/master/docs/Programming-Guide.md)
    and the RE2 syntax at [https://github.com/google/re2/wiki/Syntax](https://github.com/google/re2/wiki/Syntax).
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our static infrastructure test environment, we can validate the configuration
    of mtail by connecting to the `target01` instance as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Then checking the configuration of the provided `systemd` unit file as shown
    in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'As in this example, `mtail` is counting the lines of the `syslog` file so it
    needs to have proper permissions to access system logs, and thus, we run the `mtail`
    daemon with `Group=adm` to make this work. We can see all the required arguments
    for the `mtail` service in the following snippet from the unit file, including
    the path to the line count program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'On the Prometheus instance, we added the following job:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: In a real-world scenario, you would name the scrape job as the daemon whose
    logs mtail is monitoring, such as ntpd or Postfix.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the Prometheus expression browser, available at `http://192.168.42.10:9090`,
    we can validate, not only that the scrapes are being successful through the `up`
    metric, but also that our metric is available:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2f3bbc09-a32c-4f34-aa3a-609d72f408e1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.8: mtail line_count metric'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some interesting metrics from mtail that can be used to keep an eye on this
    exporter are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`mtail_log_watcher_error_count` , which counts the number of errors received
    from `fsnotify` (kernel-based notification system for filesystem events)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mtail_vm_line_processing_duration_milliseconds_bucket`, a histogram which
    provides the line processing duration distribution in milliseconds per mtail program'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grok exporter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Similarly to `mtail`, `grok_exporter` parses unstructured log data and generates
    metrics from it. However, as the name suggests, the main difference is the domain-specific
    language for this exporter being modeled after the Logstash pattern language (Grok),
    which enables the reuse of patterns you might already have built.
  prefs: []
  type: TYPE_NORMAL
- en: The source code and installation files for `grok_exporter` are available at
    [https://github.com/fstab/grok_exporter](https://github.com/fstab/grok_exporter).
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This exporter requires a configuration file for its setup. There are five main
    sections in the configuration, which we can dissect in the following snippets
    from the exporter''s configuration file deployed in our static infrastructure
    test environment. The `global` section sets the configuration format version.  Version
    2 is currently the standard configuration version, and so we set it here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The input section defines the location of the logs to be parsed. If `readall`
    is set to `true`, the file will be completely parsed before waiting for new lines;
    as we can see, we''re not doing that in our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The `grok` section loads the patterns to use for parsing. These are configured
    in a separate location, as can be seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The `metrics` section is where the magic happens. It defines what metrics to
    extract from the parsed logs. Every Prometheus metric type is natively supported
    in this exporter. The configuration for each `type` can be slightly different,
    so you should check its documentation. However, we''re going to provide an overview
    of the configuration that is common among them:'
  prefs: []
  type: TYPE_NORMAL
- en: The `match` configuration  defines the regular expression for data extraction;
    in our example, `LOGLEVEL` is a predefined pattern to match log levels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `labels` configuration is able to use Go''s templating syntax to output
    whatever was extracted from the match definition; in this case, we used `level`
    as our variable in the match pattern and so it is available as `.level` in the
    template:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: The full configuration documentation is available at [https://github.com/fstab/grok_exporter/blob/v0.2.7/CONFIG.md](https://github.com/fstab/grok_exporter/blob/v0.2.7/CONFIG.md)
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the `server` section is where the bind address and port for the exporter
    are defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have a better understanding of what goes into the configuration
    file, it is time for us to try this exporter out in our test environment.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our static infrastructure test environment, we can validate the configuration
    of `grok_exporter` by connecting to the `target01` instance as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Outputting the configuration of the provided `systemd` unit file is shown in
    the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Just as with the `mtail` exporter, we need to run `grok_exporter` with `Group=adm`
    so that it has access to `syslog` without requiring being run as a privileged
    user. We can see all the required arguments for the `grok_exporter` service in
    the following snippet from the unit file, including the path to the configuration
    file mentioned before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'On the Prometheus instance, we added the following job:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the Prometheus expression browser, available at `http://192.168.42.10:9090`,
    we can validate not only whether the scrapes are successful but also that our
    metric is available:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e2f553af-8c1b-4021-9dec-dfeb67e9a58d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.9: *grok_exporter* example metric'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some interesting metrics from `grok_exporter` that can be used to keep an eye
    on this exporter are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`grok_exporter_line_buffer_peak_load`, a summary which provides the number
    of lines that are read from the log file and waiting to be processed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`grok_exporter_line_processing_errors_total`, which exposes the total number
    of processing errors for each defined metric'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blackbox monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introspection is invaluable to gather data about a system, but sometimes we're
    required to measure from the point of view of a user of that system. In such cases,
    probing is a good option to simulate user interaction. As probing is made from
    the outside and without knowledge regarding the inner workings of the system,
    this is classified as blackbox monitoring, as discussed in [Chapter 1](4214ddff-8289-4dc6-b0ef-240510a22192.xhtml),
    *Monitoring Fundamentals*.
  prefs: []
  type: TYPE_NORMAL
- en: Blackbox exporter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`blackbox_exporter` is one of the most peculiar of all the currently available
    exporters in the Prometheus ecosystem. Its usage pattern is ingenious and usually,
    newcomers are puzzled by it. We''ll be going to dive into this exporter with the
    hope of making its use as straightforward as possible.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `blackbox_exporter` service exposes two main endpoints:'
  prefs: []
  type: TYPE_NORMAL
- en: '`/metrics`: Where its own metrics are exposed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/probe`: It is the query endpoint that enables blackbox probes, returning
    their results in Prometheus exposition format'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Besides the two previous endpoints, the `/` of the service also provides valuable
    information, including logs for the probes performed. This endpoint is available
    in the static infrastructure test environment at `http://192.168.42.11:9115`.
  prefs: []
  type: TYPE_NORMAL
- en: The blackbox exporter supports probing endpoints through a wide variety of protocols
    natively, such as TCP, ICMP, DNS, HTTP (versions 1 and 2), as well as TLS on most
    probes. Additionally, it also supports scripting text-based protocols such as
    IRC, IMAP, or SMTP by connecting through TCP and configuring what messages should
    be sent and what responses are expected; even plain HTTP would be possible to
    script but, as HTTP probing is such a common use case, it's already built in.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having said that, this exporter doesn''t cover all the blackbox-style monitoring
    needs. For those cases, writing your own exporter might be needed. As an example,
    you can''t use `blackbox_exporter` to test a Kafka topic end to end, so you might
    need to look for an exporter able to produce a message to Kafka and then consume
    it back:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/93515ee5-4572-42e6-984b-a8520d7d16e8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.10: blackbox_exporter web interface'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `/probe` endpoint, when hit with an HTTP GET request with the parameters
    module and target, it executes the specified `prober` module against the defined
    target, and the result is then exposed as Prometheus metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/487c05fd-69a4-41c3-9272-f917c67ea8fe.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.11: blackbox_exporter high-level workflow
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, a request such as `http://192.168.42.11:9115/probe?module=http_2xx&target=example.com`
    will return something like the following snippet (a couple of metrics were discarded
    for briefness):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: When debugging probes, you can append `&debug=true` to the HTTP GET URL to enable
    debug information.
  prefs: []
  type: TYPE_NORMAL
- en: The source code and installation files for `blackbox_exporter` are available
    at [https://github.com/prometheus/blackbox_exporter](https://github.com/prometheus/blackbox_exporter).
  prefs: []
  type: TYPE_NORMAL
- en: A quirk to be aware of when using `blackbox_exporter` is that the `up` metric
    does not reflect the status of the probe, but merely that Prometheus can reach
    the exporter. As can be seen in the previous metrics output, there is a `probe_success`
    metric that represents the status of the probe itself. This means that it is common
    for the `up` metric to appear healthy, but the probe might be failing, which is
    a common source for confusion.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The scrape job configuration for blackbox probes is unusual, in the sense that
    both the `prober` module and the list of targets, whether static or discovered,
    need to be relayed to the exporter as HTTP GET parameters to the `/probe` endpoint.
    To make this work, a bit of `relabel_configs` magic is required, as seen in [Chapter
    5](12e775c2-bee9-4ebe-ad73-2f9313eeeeee.xhtml), *Running a Prometheus Server*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the following Prometheus configuration snippet as an example, we''re
    setting up an ICMP probe against the Prometheus instance, while `blackbox_exporter`
    is running on `target01`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Due to the nature of the ICMP probe, it requires elevated privileges to be run.
    In our environment, we're setting the capability to use raw sockets (`setcap cap_net_raw+ep
    /usr/bin/blackbox_exporter`) to guarantee such privileges.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal is to replace the address of the target with the address of `blackbox_exporter`,
    ensuring the internal `__param_target` keeps the address of the target. Focusing
    on how the `relabel_configs` is processed, the following happens:'
  prefs: []
  type: TYPE_NORMAL
- en: The `__address__` value (which contains the address of the target) is stored
    into `__param_target`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__param_target` value is then stored into the instance label.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `blackbox_exporter` host is then applied to `__address__`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This enables to Prometheus to query `blackbox_exporter` (using `__address__`),
    keep the instance label with the target definition, and pass the parameters module
    and target (using the internal `__param_target`) to the `/probe` endpoint, which
    returns the metrics data.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our static infrastructure test environment, we can validate the configuration
    of `blackbox_exporter` by connecting to the `target01` instance as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Then checking the configuration of the provided `systemd` unit file as shown
    in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: The configuration can be reloaded in runtime by sending an HTTP POST to the
    `/-/reload` endpoint or a `SIGHUP` to the `blackbox_exporter` process. If there
    are configuration errors, it will not be applied.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see all the required arguments for the `blackbox_exporter` service in
    the following snippet from the unit file, including the path to the configuration
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The configuration we tailored for our example can be found in the following
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice `preferred_ip_protocol: ip4` is used, as `blackbox_exporter` prefers
    `ipv6`, but we''re forcing `ipv4` in our probes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the Prometheus instance, we added the following jobs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the Prometheus web interface, available at `http://192.168.42.10:9090/targets`,
    we can validate whether the scrapes are successful (independently of the return
    status of the probes):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d2c5b2de-f1a8-4d04-a4e1-172c2cd6276d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.12: Prometheus /targets endpoint showing the blackbox_exporter targets'
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned before, the `/targets` page doesn''t tell you whether a probe
    was successful or not. This needs to be validated in the expression browser by
    querying the `probe_success` metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/67800f60-c4c3-47dd-a5de-04f90153a2ac.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.13: Prometheus expression browser showing the probe_success query results
  prefs: []
  type: TYPE_NORMAL
- en: 'Some interesting metrics that can be collected from `blackbox_exporter` (both
    about the exporter itself and from probes) are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`blackbox_exporter_config_last_reload_successful`, which exposes if the exporter''s
    configuration file was reloaded successfully after a `SIGHUP`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`probe_http_status_code`, which allows you to understand what HTTP status code
    is being returned when using the HTTP `prober` module'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`probe_ssl_earliest_cert_expiry`, which returns the timestamp for when the
    certificate chain from a SSL probe becomes invalid due to one of the certificates
    in the chain expiring'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pushing metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Despite the intense debate regarding push versus pull and the deliberate decision
    of using pull in the Prometheus server design, there are some legitimate situations
    where push is more appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: One of those situations is batch jobs, though, for this statement to truly make
    sense, we need to clearly define what is considered a batch job. In this scope,
    a service-level batch job is a processing workload not tied to a particular instance,
    executed infrequently or on a schedule, and as such is not always running. This
    kind of job makes it very hard to generate successful scrapes if instrumented,
    which, as discussed previously in [Chapter 5](12e775c2-bee9-4ebe-ad73-2f9313eeeeee.xhtml),
    *Running a Prometheus Server*, results in metric staleness, even if running for
    long enough to be scraped occasionally.
  prefs: []
  type: TYPE_NORMAL
- en: There are alternatives to relying on pushing metrics; for example, by using
    the textfile collector from `node_exporter` as described previously. Nevertheless,
    this option does not come without downsides. If the workload is not specific to
    a particular instance, you'll end up with multiple time series plus the cleanup
    logic of the textfile collector files, unless the lifetime of the metric matches
    the lifetime of the instance, which can then work out well in practice.
  prefs: []
  type: TYPE_NORMAL
- en: As a last resort, you have Pushgateway, which we'll be covering next.
  prefs: []
  type: TYPE_NORMAL
- en: Pushgateway
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This exporter should only be employed in very specific use cases, as stated
    previously, and we should be aware of some common pitfalls. One possible problem
    is the lack of high availability, making it a single point of failure. This also
    impacts scalability as the only way to accommodate more metrics/clients is to
    either scale the instance vertically (adding more resources) or sharding (having
    different Pushgateway instances for different logical groups). By using Pushgateway,
    Prometheus does not scrape an application instance directly, which prevents having
    the `up` metric as a proxy for health monitoring. Additionally, and similarly
    to the textfile collector from `node_exporter`, metrics need to be manually deleted
    from Pushgateway via its API, or they will forever be exposed to Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: 'To push a metric, you need to send an HTTP POST request to the Pushgateway
    endpoint, using the following URL path definition. This will be demonstrated in
    the following deployment section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Here, `<job_name>` will become the value of the label job for the metrics pushed
    and the `<label_name>/<label_value>` pairs will become additional label/value
    pairs. Keep in mind that metrics will be available until manually deleted, or
    in the case of a restart, when persistence is not configured.
  prefs: []
  type: TYPE_NORMAL
- en: The source code and installation files for Pushgateway are available at [https://github.com/prometheus/pushgateway](https://github.com/prometheus/pushgateway).
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As Pushgateway is a centralized point where instances push their metrics, when
    a scrape is performed by Prometheus, the label instance will be automatically
    set to the Pushgateway server address/port for every single metric it exposes,
    and the label job to whatever name was set in the Prometheus scrape job definition.
    On label collision, Prometheus renames the original labels to `exported_instance`
    and `exported_job`, respectively. To avoid this behavior, `honor_labels: true`
    should be used in the scrape job definition to guarantee the labels that prevail
    are the ones coming from Pushgateway.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The noteworthy runtime configuration for our test case is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Flag** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `--web.listen-address` | Bind address, defaults to `0.0.0.0:9091` |'
  prefs: []
  type: TYPE_TB
- en: '| `--persistence.file` | Persistence file location, if empty metrics are only
    kept in memory |'
  prefs: []
  type: TYPE_TB
- en: '| `--persistence.interval` | Interval to write to the persistence file, defaults
    to 5m |'
  prefs: []
  type: TYPE_TB
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll be building upon the Kubernetes test environment started previously. In
    this particular scenario, we'll deploy an instance of Pushgateway and we'll be
    adding it as a target in Prometheus. To validate the correctness of our setup,
    we'll create a Kubernetes CronJob to emulate a batch job style of workload, and
    push its metrics to the Pushgateway service to ensure Prometheus collects our
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin the deployment, ensure you move into the correct repository path,
    relative to the code repository root:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'To deploy an instance of Pushgateway, you can use the following manifest. Keep
    in mind that this service does not support high availability or clustering:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the manifest by executing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'And follow the deployment using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'After a successful deployment, it''s time to provide a `Service` to our new
    instance, using the following manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The following instruction applies to the previous manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'You may now validate the web interface for Pushgateway using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'This will open a new browser tab pointing to the newly created Pushgateway
    instance web interface, which should look like the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/034cb26b-a5b7-4f17-9887-3fa1d16a51a1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.14: Pushgateway web interface without any metric being pushed'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to instruct Prometheus to scrape Pushgateway. This can be accomplished
    via a new `ServiceMonitor` manifest as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'To apply this ServiceMonitor, we just type the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have our monitoring infrastructure in place, we need to simulate
    a batch job to validate our setup.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can rely on the following manifest, which pushes a dummy `batchjob_example`
    metric with several labels to the Pushgateway service endpoint using a handcrafted
    `curl` payload:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'To apply the previous manifest, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'After a minute, the web interface for Pushgateway will look similar to this
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/535397ed-e81b-4f4c-b4bb-4c660cfe4ce7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.15: Pushgateway web interface presenting the batchjob_example metric'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now use the Prometheus expression browser to validate the metric is
    being scraped from Pushgateway:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/614c64be-455d-4140-af56-45b359c91112.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.16: Prometheus expression browser showing the batchjob_example metric'
  prefs: []
  type: TYPE_NORMAL
- en: As Pushgateway's job is to proxy metrics from other sources, it provides very
    little metrics of its own - just the standard Go runtime metrics, process metrics,
    HTTP handler metrics and build info. However, there is one application metric
    to note, which is `push_time_seconds`. This will tell you the last time a specific
    group (combination of labels used in the HTTP API when pushing) was seen. This
    can be used to detect missing or delayed jobs.
  prefs: []
  type: TYPE_NORMAL
- en: More exporters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Prometheus community has produced a great number of exporters for just about
    anything you might need. However, making an intentional choice to deploy a new
    piece of software in your infrastructure has an indirect price to pay upfront.
    That price translates into the deployment automation code to be written, the packaging,
    the metrics to be collected and alerting to be created, the logging configuration,
    the security concerns, the upgrades, and other things we sometimes take for granted.
    When choosing an open source exporter, or any other open source project for that
    matter, there are a few indicators to keep in mind.
  prefs: []
  type: TYPE_NORMAL
- en: We should validate the community behind the project, the general health of contributions,
    if issues are being addressed, pull requests are being timely managed, and whether
    the maintainers are open to discuss and interact with the community. Technically,
    we should also check whether the official Prometheus client libraries are being
    used by the particular project. With that said, we'll be covering a few noteworthy
    exporters.
  prefs: []
  type: TYPE_NORMAL
- en: JMX exporter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Java Virtual Machine** (**JVM**) is a popular choice for core infrastructure
    services, such as Kafka, ZooKeeper, and Cassandra, among others. These services,
    like many others, do not natively offer metrics in the Prometheus exposition format
    and instrumenting such applications is far from being a trivial task. In these
    scenarios, we can rely on the **Java Management Extensions** (**JMX**) to expose
    the application's internal state through the **Managed Beans** (**MBeans**). The
    JMX exporter extracts numeric data from the exposed MBeans and converts it into
    Prometheus metrics, exposing them on an HTTP endpoint for ingestion.
  prefs: []
  type: TYPE_NORMAL
- en: 'The exporter is available in the following two forms:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Java agent**: In this mode, the exporter is loaded inside the local JVM where
    the target application is running and exposes a new HTTP endpoint.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standalone HTTP server**: In this mode, a separate JVM instance is used to
    run the exporter that connects via JMX to the target JVM and exposes collected
    metrics on its own HTTP server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The documentation strongly advises deploying the exporter using the Java agent,
    for good reason; the agent produces richer sets of metrics as compared with the
    standalone exporter, as it has access to the full JVM being instrumented. However,
    both have trade-offs that are important to be aware of so that the right tool
    for the job is chosen.
  prefs: []
  type: TYPE_NORMAL
- en: Although the standalone server does not have access to the JVM specific metrics,
    such as garbage collector statistics or process memory/CPU usage, it easier to
    deploy and manage on static infrastructure when Java applications already have
    JMX enabled and are long-running processes that might not be convenient to touch.
    Adding to that, the exporter upgrade cycle becomes decoupled with the application
    life cycle, even though new releases are infrequent.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the Java agent provides the full range of available metrics
    in the JVM, but needs to be loaded into the target application at startup. This
    might be simpler to do on regularly deployed applications or when those applications
    run in containers.
  prefs: []
  type: TYPE_NORMAL
- en: Another benefit of running the agent is that the target JVM is also responsible
    to serve its own metrics, so the `up` metric from the scrape job can represent
    the process status without ambiguity.
  prefs: []
  type: TYPE_NORMAL
- en: Both options require a configuration file that can whitelist, blacklist, and/or
    relabel metrics from MBeans into the Prometheus format. An important performance
    consideration is the use of whitelists whenever possible. Some applications expose
    a very large amount of MBeans (such as Kafka or Cassandra) and frequent scrapes
    do have a significant performance impact.
  prefs: []
  type: TYPE_NORMAL
- en: You can find useful examples of configuration files for the most used applications
    at [https://github.com/prometheus/jmx_exporter/tree/master/example_configs](https://github.com/prometheus/jmx_exporter/tree/master/example_configs).
  prefs: []
  type: TYPE_NORMAL
- en: The source code for `jmx_exporter` is available at [https://github.com/prometheus/jmx_exporter](https://github.com/prometheus/jmx_exporter).
  prefs: []
  type: TYPE_NORMAL
- en: HAProxy exporter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HAProxy, a well-known load balancing solution, at the time of writing does not
    expose Prometheus metrics natively. Fortunately, it has an exporter, made by the
    Prometheus maintainers, to ensure its metrics can be collected, which is the `haproxy_exporter`.
    HAProxy natively exposes its metrics in **comma-separated value** (**CSV**) format
    via a configurable HTTP endpoint by using the `stats enable` configuration. The
    `haproxy_exporter`, which runs as a separate daemon, is able to connect to the
    HAProxy stats endpoint, consume the CSV, and convert its contents to the Prometheus
    metric format, exposing it in a synchronous manner when triggered by a scrape.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumenting the load-balancer layer can be quite useful when the applications
    in the backend pools aren't properly instrumented and thus don't expose access
    metrics. For example, dashboards and alerts can be created for HTTP error rates
    or backend availability without any development effort from the application side.
    This is not meant to be a long-term solution, but can help in transitioning from
    legacy monitoring systems to Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the source code and installation files for the `haproxy_exporter`
    at [https://github.com/prometheus/haproxy_exporter](https://github.com/prometheus/haproxy_exporter)
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we had the opportunity to discover some of the most used Prometheus
    exporters available. Using test environments, we were able to interact with operating-system-level
    exporters running on VMs and container-specific exporters running on Kubernetes.
    We found that sometimes we need to rely on logs to obtain metrics and went through
    the current best options to achieve this. Then, we explored blackbox probing with
    the help of `blackbox_exporter` and validated its unique workflow. We also experimented
    with pushing metrics instead of using the standard pull approach from Prometheus,
    while making clear why sometimes this method does indeed make sense.
  prefs: []
  type: TYPE_NORMAL
- en: All these exporters enable you to gain visibility without having to natively
    instrument code, which sometimes is much more costly than relying on community-driven
    exporters.
  prefs: []
  type: TYPE_NORMAL
- en: With so many sources of metrics, now is the time to understand how to extract
    useful information from their data. In the next chapter, we'll go over PromQL
    and how best to leverage it.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How would you collect custom metrics with the Node Exporter?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What resources does cAdvisor consult to generate metrics?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: kube-state-metrics expose numerous API objects. Is there a way to restrict that
    number?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How could you debug a `blackbox_exporter` probe?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If an application does not expose metrics, in Prometheus format or otherwise,
    what could an option to monitor it be?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the downsides of using Pushgateway?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If a particular batch job is host specific, is there any alternative to the
    use of Pushgateway?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Prometheus exporters**: [https://prometheus.io/docs/instrumenting/exporters/](https://prometheus.io/docs/instrumenting/exporters/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prometheus port allocations**: [https://github.com/prometheus/prometheus/wiki/Default-port-allocations](https://github.com/prometheus/prometheus/wiki/Default-port-allocations)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manpages cgroups**: [http://man7.org/linux/man-pages/man7/cgroups.7.html](http://man7.org/linux/man-pages/man7/cgroups.7.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manpages namespaces**: [http://man7.org/linux/man-pages/man7/namespaces.7.html](http://man7.org/linux/man-pages/man7/namespaces.7.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kubernetes resource usage monitoring**: [https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/](https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
