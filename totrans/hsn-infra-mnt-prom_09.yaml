- en: Prometheus Query Language - PromQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prometheus offers a powerful and flexible query language in order to leverage
    its multi-dimensional data model that allows ad hoc aggregation and a combination
    of time series data. In this chapter, we'll introduce PromQL, its syntax, and
    semantics. Armed with the knowledge and features of this language, we'll be able
    to unlock the true potential of Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: 'In brief, the following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The test environment for this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting to know the basics of PromQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common patterns and pitfalls
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moving on to more complex queries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The test environment for this chapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will be using a Kubernetes-based environment to generate
    all the metrics we need to test the PromQL examples that are covered in this chapter.
    Using the Prometheus Operator, the setup of this environment is quite simple;
    go through the following steps to get yourself up and running:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To start the Kubernetes test environment, we first must ensure there''s no
    instance of `minikube` running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Start a new `minikube` instance with the following specifications:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: When the previous command finishes, a new Kubernetes environment should be ready
    to be used.
  prefs: []
  type: TYPE_NORMAL
- en: For our Kubernetes test environment, we'll be building upon the lessons we learned
    about in [Chapter 5](12e775c2-bee9-4ebe-ad73-2f9313eeeeee.xhtml), *Running a Prometheus
    Server*, and will employ the Prometheus Operator in our workflow. Since we've
    already covered the Prometheus Operator setup, we'll deploy all the required components
    without dwelling on each one of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step into this chapter number, relative to the code repository root path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Deploy the Prometheus Operator and validate the successful deploy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait a few seconds for the Prometheus Operator to be able to execute requests
    and deploy the Prometheus server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'So that we have a few metric providers, we''ll be deploying some of the exporters
    we covered in [Chapter 6](51ddca07-f381-40f6-ae45-8b089ed918cd.xhtml), *Exporters
    and Integrations*, specifically the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Node Exporter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: cAdvisor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: kube-state-metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll also be deploying a type of *Hello World* application, *Hey*, that we
    introduced in [Chapter 5](12e775c2-bee9-4ebe-ad73-2f9313eeeeee.xhtml), *Running
    a Prometheus Server*, so that Prometheus gathers web application metrics as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'To ease the effort required to deploy all of the components and configurations,
    the following command abstracts all the steps needed, which we also went through
    in previous chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After a moment, you should have Prometheus and all the services ready and available.
    The following instruction should open the Prometheus web interface in your default
    web browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If you browse the `/targets` endpoint, you''ll be presented with something
    similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7a882111-8d07-43a0-a237-d9404a1b740c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.1: Prometheus /targets endpoint showing all the configured targets'
  prefs: []
  type: TYPE_NORMAL
- en: You can now follow along with the examples in this chapter using this newly
    created test environment.
  prefs: []
  type: TYPE_NORMAL
- en: Getting to know the basics of PromQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding the Prometheus Query Language is essential to be able to perform
    insightful dashboarding, capacity planning, and alerting. But for that, we need
    to begin by learning the basics. The following topics will cover the components
    that available to construct queries and look into how they behave together.
  prefs: []
  type: TYPE_NORMAL
- en: Selectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Prometheus is designed to handle hundreds of thousands of time series. Each
    metric name can have several different time series, depending on the combination
    of labels; querying the right data can look difficult, or even downright perplexing,
    when similarly-named metrics from different jobs are mixed together. In Prometheus,
    a selector refers to a set of label matchers. The metric name is also included
    in this definition as, technically, its internal representation is also a label,
    albeit a special one: `__name__`. Each label name/value pair in a selector is
    called a label matcher, and multiple matchers can be used to further filter down
    the time series matched by the selector. Label matchers are enclosed in curly
    brackets. If no matcher is needed, the curly brackets can be omitted. Selectors
    can return instant or range vectors. Here''s an example selector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This selector is equivalent to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Let's now see how to label matchers work.
  prefs: []
  type: TYPE_NORMAL
- en: Label matchers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Matchers are employed to restrict a query search to a specific set of label
    values. We''ll be using the `node_cpu_seconds_total` metric to exemplify the four
    available label matcher operators: `=`, `!=`, `=~`, and `!~`. Without any matching
    specification, this metric alone returns an instant vector with all the available
    time series containing the metric name,  as well as all combinations of the CPU
    core numbers (`cpu=”0”`, `cpu=”1”`) and CPU modes (`mode="idle"`, `mode="iowait"`,
    `mode="irq"`, `mode="nice"`, `mode="softirq"`, `mode="steal"`, `mode="user"`,
    `mode="system"`), which makes a grand total of 16 time series, as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf556780-70a2-419b-a597-67aa44511f97.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.2: node_cpu_seconds_total query resulting in 16 time series being
    returned'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's use each of the four available label matchers (`=`, `!=`, `=~`, and `!~`)
    to restrict the query differently and analyze the produced results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using `=`, we can perform an exact match on the label value. For instance,
    if we only match CPU core `0`, it will return an instant vector with half of the
    time series from the previous query:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/90f43aa4-f2ca-4c0e-904e-474d4f3ed1d7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.3: Query node_cpu_seconds_total only on CPU core 0'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also negate a match to obtain all the remaining time series using the
    `!=` matcher. Once applied to our example, it will return the remaining eight
    time series only, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/21529ddd-f465-45fe-bac8-9f4e177d97f0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.4: Query node_cpu_seconds*_total* for all time series except core
    0'
  prefs: []
  type: TYPE_NORMAL
- en: When selecting time series, instead of relying solely on exact matches, it is
    also important to be able to apply regular expressions. Hence, `=~` and `!~` are
    PromQL matchers for this operation and they both accept RE2 type regex syntax.
    Keep in mind that the regular expressions are anchored when using these matchers.
    This means they need to match the full label value. You can unanchor an expression
    by adding `.*` at the beginning and end of the regex.
  prefs: []
  type: TYPE_NORMAL
- en: The regular expression syntax that's accepted by RE2 can be found at: [https://github.com/google/re2/wiki/Syntax](https://github.com/google/re2/wiki/Syntax).
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at our example, if we were only interested in two CPU modes, `mode="user"`
    and `mode="system"`, we could easily perform a query like the following, effectively
    selecting only the modes we require:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b428a929-dcaf-43eb-a8d1-040690da14c2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.5: Query node_cpu_seconds_total only for mode="user" and mode="system"'
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering that RE2 does not support negative lookahead, and similar to the
    negate matcher, Prometheus provides a way to negate the regex matcher, by using
    `!~`. This matcher excludes results that match the expression and allows all the
    remaining time series. Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4f35318a-d701-4cc9-ae3c-e1676169b106.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.6: Query node_cpu_seconds_total for all time series except mode="user"
    and mode="system"'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a good understanding on how label matchers work, let's have
    a look at instant vectors.
  prefs: []
  type: TYPE_NORMAL
- en: Instant vectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Instant vector selectors are named as such because they return a list of samples,
    relative to the query evaluation time, for the time series that match them. This
    list is called an **instant vector**, as it's a result at a given instant. A sample
    is a data point of a time series, composed of a value and a timestamp. This timestamp,
    in most cases, reflects the time when the scrape occurred and that value was ingested,
    with the exception of metrics pushed to the Pushgateway, which, due to their nature,
    will never have timestamps. However, if functions are applied or operations are
    performed on the time series, the timestamp for the instant vector samples will
    reflect the query time and not the ingested time.
  prefs: []
  type: TYPE_NORMAL
- en: The way instant vectors operate – by only returning the most recent samples
    relative to query time that match the selector - means that Prometheus will not
    return time series that are considered stale (as we mentioned in [Chapter 5](12e775c2-bee9-4ebe-ad73-2f9313eeeeee.xhtml),
    *Running a Prometheus Server*). A stale marker (a special kind of sample that
    marks that time series as stale) is inserted when either the originating target
    disappears from the discovery mechanism, or if they are not present in the scrape
    after the last successful one where they existed. A time series with a stale marker
    as its last sample will not be returned when using instant vector selectors.
  prefs: []
  type: TYPE_NORMAL
- en: Every example in the *Label Matchers*section was an instant vector selector,
    and so every result was an instant vector.
  prefs: []
  type: TYPE_NORMAL
- en: Range vectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A range vector selector is similar to an instant vector selector, but it returns
    a set of samples for a given time range, for each time series that matches it.
    Keep in mind that a timestamp of a given value might not be completely aligned
    with the scrape time for different targets since Prometheus spreads the scrapes
    across their defined intervals, reducing overlapping scrapes in the same instant.
  prefs: []
  type: TYPE_NORMAL
- en: To define a range vector selector query, you have to set an instant vector selector
    and append a range using square brackets `[ ]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table details the available time units for defining a range:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Abbreviation** | **Unit** |'
  prefs: []
  type: TYPE_TB
- en: '| `s` | Seconds |'
  prefs: []
  type: TYPE_TB
- en: '| `m` | Minutes |'
  prefs: []
  type: TYPE_TB
- en: '| `h` | Hours |'
  prefs: []
  type: TYPE_TB
- en: '| `d` | Days |'
  prefs: []
  type: TYPE_TB
- en: '| `w` | Weeks |'
  prefs: []
  type: TYPE_TB
- en: '| `y` | Years |'
  prefs: []
  type: TYPE_TB
- en: 'Like durations, as explained in [Chapter 5](12e775c2-bee9-4ebe-ad73-2f9313eeeeee.xhtml)*,
    Running a Prometheus Server*, a time range is always an integer value with a single
    unit. For example, 1.5d and 1d12h are considered errors and should be represented
    as 36h. Durations ignore leap seconds and leap days: a week is always is always
    exactly 7 days long, and a year 365 days.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s put this into practice. Using the *Hey* application as our case example,
    we''re going to inspect the samples that were collected in the last two minutes
    for HTTP code `200`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Following is the output for the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8199bca8-6b57-4898-b6f4-58a7788d1404.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.7: Two minutes of samples of the http_requests_total metric for the
    HTTP code 200'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in the preceding screenshot, there are four samples available
    (defined by the 30s scrape interval) for each instance of the *Hey* application
    that are returned by our range vector selector.
  prefs: []
  type: TYPE_NORMAL
- en: The offset modifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `offset` modifier allows you to query data in the past. This means that
    we can offset the query time of an instant or range vector selector relative to
    the current time. It is applied on a per-selector basis, which means that offsetting
    one selector but not another effectively unlocks the ability to compare current
    behavior with past behavior for each of the matched time series. To use this modifier,
    we need to specify it right after the selector and add the offset time; for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/05dbe816-b363-4134-8daa-655d9bedde7c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.8: Two minutes of samples of the http_requests_total metric of the
    past hour for the HTTP code 200'
  prefs: []
  type: TYPE_NORMAL
- en: Despite not being directly related to PromQL, it's important to be aware of
    the moment feature of the Prometheus expression browser. This feature changes
    the query moment as if we went back to a specific date and time. The main difference
    between the moment picker and using offset is that the former is absolute while
    the latter is relative time shifting.
  prefs: []
  type: TYPE_NORMAL
- en: Subqueries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before the introduction of the subquery selector in Prometheus 2.7.0, there
    wasn't a direct way to feed the output of functions that returned instant vectors
    to range vector functions. In order to do that, you would have recorded the expression
    that produced the desired instant vector as a new time series, also called a recording
    rule – which we'll go into in depth in [Chapter 9](9aa1e3da-13cf-4051-845d-1d1c924ef47b.xhtml),
    *Defining Alerting and Recording Rules – *waited for it to have enough data, and
    then used the appropriate range vector selector to feed the recorded series into
    the range vector function. The subquery selector simplifies this process by allowing
    the evaluation of functions that return instant vectors over time and return the
    result as a range vector, without needing to wait for recording rules to capture
    sufficient data. Subquery syntax is similar to range vectors, with the added detail
    of being able to specify the frequency in which samples should be captured, as
    we'll see soon.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll be using the following query example to explain its syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Splitting the query into its components, we can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Component** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `rate(http_requests_total{handler="/health", instance="172.17.0.9:8000"}[5m])`
    | The inner query to be run, which in this case is aggregating five minutes''
    worth of data into an instant vector. |'
  prefs: []
  type: TYPE_TB
- en: '| `[1h` | Just like a range vector selector, this defines the size of the range
    relative to the query evaluation time. |'
  prefs: []
  type: TYPE_TB
- en: '| `:1m]` | The resolution step to use. If not defined, it defaults to the global
    evaluation interval. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_over_time` | The subquery returns a range vector, which is now able
    to become the argument of this aggregation operation over time. |'
  prefs: []
  type: TYPE_TB
- en: This is a common use case, as it is good practice to expose counters wherever
    possible (with the obvious exception of things that are gauges by nature, such
    as current memory occupation) and then rate them to be resilient to failed scrapes,
    but most interesting functions take ranges of gauges.
  prefs: []
  type: TYPE_NORMAL
- en: Subqueries are fairly expensive to evaluate, so it is strongly discouraged to
    use them for dashboarding, as recording rules would produce the same result given
    enough time. Similarly, they should not be used in recording rules for the same
    reason. Subqueries are best suited for exploratory querying, where it is not known
    in advance which aggregations are needed to be looked at over time.
  prefs: []
  type: TYPE_NORMAL
- en: Operators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PromQL allows the use of binary, vector matching, and aggregation operators.
    In the following sections, we'll go over each one, providing examples on how and
    when to use them.
  prefs: []
  type: TYPE_NORMAL
- en: Binary operators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apart from instant and range vectors, Prometheus also supports values of the
    scalar type, which consist of single numbers without any dimensionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following subsections, we will explore each of the binary operators:
    the arithmetic and the comparison operators.'
  prefs: []
  type: TYPE_NORMAL
- en: Arithmetic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The arithmetic operators provide basic math between two operands.
  prefs: []
  type: TYPE_NORMAL
- en: There are three available combinations of operands. The simplest is between
    two scalars, which will return a scalar after applying the chosen arithmetic operator.
    We can also combine an instant vector and a scalar, which will apply the chosen
    arithmetic operator between the scalar and each sample of the instant vector,
    effectively returning the same instant vector with updated samples. The last combination
    we can have is between two instant vectors. In this case, the arithmetic operator
    is applied between the vector from the left-hand side and the matching element
    from the right-hand side vector, while the metric name is dropped. If no match
    is present, those samples will not be part of the result. This case will be explained
    further in the *Vector matching* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'For reference, the available arithmetic operators are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Operator** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `+` | Addition |'
  prefs: []
  type: TYPE_TB
- en: '| `-` | Subtraction |'
  prefs: []
  type: TYPE_TB
- en: '| `*` | Multiplication |'
  prefs: []
  type: TYPE_TB
- en: '| `/` | Division |'
  prefs: []
  type: TYPE_TB
- en: '| `%` | Modulo |'
  prefs: []
  type: TYPE_TB
- en: '| `^` | Power |'
  prefs: []
  type: TYPE_TB
- en: Comparison
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The comparison operators, as shown in the following table, are useful for filtering
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Operator** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `==` | Equal |'
  prefs: []
  type: TYPE_TB
- en: '| `!=` | Not equal |'
  prefs: []
  type: TYPE_TB
- en: '| `>` | Greater than |'
  prefs: []
  type: TYPE_TB
- en: '| `<` | Less than |'
  prefs: []
  type: TYPE_TB
- en: '| `>=` | Greater or equal |'
  prefs: []
  type: TYPE_TB
- en: '| `<=` | Less or equal |'
  prefs: []
  type: TYPE_TB
- en: 'Say, for example, we have the following instant vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'To that, we apply a comparison operator such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The result will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This operation shows that we have effectively filtered the results of the instant
    vector, which is fundamental for alerting, as we'll discuss later, in [Chapter
    9](9aa1e3da-13cf-4051-845d-1d1c924ef47b.xhtml), *Defining Alerting and Recording
    Rules*.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, we can use the `bool` modifier to not only return all matched time
    series but also modify each returned sample to become 1 or 0, depending on whether
    the sample would be kept or dropped by the comparison operator.
  prefs: []
  type: TYPE_NORMAL
- en: Using the bool modifier is the only way to compare scalars; for example, `42
    == bool 42`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we can apply the same query with the `bool` modifier to our previous
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This would return the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Vector matching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vector matching, as the name implies, is an operation only available between
    vectors. So far, we have learned that when we have a scalar and an instant vector,
    the scalar gets applied to each sample of the instant vector. However, when we
    have two instant vectors, how can we match their samples? We'll be tackling this
    question in the following sub-sections.
  prefs: []
  type: TYPE_NORMAL
- en: One-to-one
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since binary operators require two operands, as we described previously, when
    vectors of the same size and label set are located on each side of one operator,
    that is, one-to-one, samples with the exact same label/value pairs are matched
    together, while the metric name and all non-matching elements are dropped.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider an example. We''ll start by using the following instant vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll then apply the following operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return the resulting instant vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: It might be useful to aggregate vectors with mismatching labels. In those situations,
    you can apply the `ignoring` keyword right after the binary operator to ignore
    the specified labels. Additionally, it is also possible to restrict which labels
    from both sides should be used in matching by using the `on` keyword after the
    binary operator.
  prefs: []
  type: TYPE_NORMAL
- en: Many-to-one and one-to-many
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Occasionally, you are required to perform operations where the element of one
    side is matched with several elements on the other side of the operation. When
    this happens, you are required to provide Prometheus with the means to interpret
    such operations. If the higher cardinality is on the left-hand side of the operation,
    you can use the `group_left` modifier after either `on` or `ignoring`; if it's
    on the right-hand side, then `group_right` should be applied. The `group_left`
    operation is commonly used for its ability to copy labels over from the right
    side of the expression, as will be seen on some practical examples later in this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Logical operators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Logical operators are most easily understood as their set theory counterparts,
    as shown in the following table. These operators are the only ones in PromQL that
    work many-to-many. There are three logical operators that can be used between
    expressions:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Operator** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `and` | Intersection |'
  prefs: []
  type: TYPE_TB
- en: '| `or` | Union |'
  prefs: []
  type: TYPE_TB
- en: '| `unless` | Complement |'
  prefs: []
  type: TYPE_TB
- en: 'The `and` logical operator works by only returning the matches from the left-hand
    side if the expression on the right-hand side has results with matching label
    key/value pairs. All other time series from the left-hand side that do not have
    a match on the right-hand side are dropped. The resulting time series will keep
    the name from the left operand. This is why it is also called the **intersection**
    operator. The `and` operator is often used like an `if` statement: by using the
    expression on the right as the condition to return the one on the left.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the following instant vector as an example, we''ll validate the previous
    statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll be applying the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The union logical operator, `or`, works by returning the elements from the left-hand
    side, except if there are no matches, it will return the elements from the right-hand
    side. Again, both sides need to have matching label names/values.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can reuse the previous data sample and apply the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The result will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Finally, the `unless` logical operator will return the elements from the first
    expression that do not match the label name/value pairs from the second. In set
    theory, this is called a complement. Practically speaking, this operator works
    in the opposite way to `and`, which means it can also be used as an `if not` statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once again, we''ll be using the same sample data that we used previously while
    applying the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This, in turn, provides us with the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Aggregation operators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By employing aggregation operators, we can take an instant vector and aggregate
    its elements, resulting in a new instant vector, usually with fewer elements.
    Every aggregation of an instant vector such as this works in the ways that we
    described in the *Vertical aggregation* section of [Chapter 4](d571ee63-1941-40e0-a314-70030efe76ea.xhtml)*,
    Prometheus Metrics Fundamentals*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The available aggregation operators are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Operator** | **Description** | **Requirements** |'
  prefs: []
  type: TYPE_TB
- en: '| `sum` | Sums the elements |  |'
  prefs: []
  type: TYPE_TB
- en: '| `min` | Selects the minimum element |  |'
  prefs: []
  type: TYPE_TB
- en: '| `max` | Selects the maximum element |  |'
  prefs: []
  type: TYPE_TB
- en: '| `avg` | Calculates the average of the elements |  |'
  prefs: []
  type: TYPE_TB
- en: '| `stddev` | Calculates the standard deviation of the elements |  |'
  prefs: []
  type: TYPE_TB
- en: '| `stdvar` | Calculates the standard variance of the elements |  |'
  prefs: []
  type: TYPE_TB
- en: '| `count` | Counts the number of elements |  |'
  prefs: []
  type: TYPE_TB
- en: '| `count_values` | Counts the number of elements with the same value |  |'
  prefs: []
  type: TYPE_TB
- en: '| `bottomk` | The lower `k` elements by sample | Requires the number of elements
    (`k`) as a scalar |'
  prefs: []
  type: TYPE_TB
- en: '| `topq` | The higher `k` elements by sample value | Requires the number of
    elements (`k`) as a scalar |'
  prefs: []
  type: TYPE_TB
- en: '| `quantile` | Calculates the quantile of the elements | Requires the quantile
    (0 ≤ φ ≤ 1) definition as a scalar |'
  prefs: []
  type: TYPE_TB
- en: 'The operators that require a parameter (such as `count_values`, `bottomk`,
    `topk`, and `quantile`) need to specify it before the vector expression. There
    are two available modifiers to use in conjunction with aggregation operators that
    take a list of label names: `without` allows you to define which labels to aggregate
    away, effectively dropping those labels from the resulting vector, while `by`
    does exactly the opposite; that is, it allows you to specify which labels to keep
    from being aggregated. Only a single modifier can be used per aggregation operator.
    These modifiers will influence which dimensions will be aggregated by the operators.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let''s say that we use some sample data from the following query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This would generate something like the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to know the aggregate of all requests, we can apply the following
    expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if we add the `by` operator, we can aggregate by the handler endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This would, in turn, return the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: This simple example demonstrates how you can easily aggregate data.
  prefs: []
  type: TYPE_NORMAL
- en: Binary operator precedence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When a PromQL query is evaluated, the order in which binary operators are applied
    is dictated by the operator precedence. The following table shows the precedence
    order, from higher to lower:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Precedence** | **Operator** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | `^` | Evaluated right to left, for example, 1 ^ 2 ^ 3 is evaluated as
    1 ^ (2 ^ 3) |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | `*`, `/`, `%` | Evaluated left to right, for example, 1 / 2 * 3 is evaluated
    as (1 / 2) * 3 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | `+`, `-` | Evaluated left to right |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | `==`, `!=`, `<=`, `<`, `>=`, `>` | Evaluated left to right |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | `and`, `unless` | Evaluated left to right |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | `or` | Evaluated left to right |'
  prefs: []
  type: TYPE_TB
- en: Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PromQL has almost 50 different functions for a variety of use cases, such as
    math; sorting; counter, gauge and histogram manipulation; label transformations;
    aggregations over time; type conversions; and finally, date and time functions.
    In the following sections, we'll cover some of the most commonly used ones and
    provide examples on why they are so relevant.
  prefs: []
  type: TYPE_NORMAL
- en: A comprehensive overview of all functions is available at [https://prometheus.io/docs/prometheus/latest/querying/functions/](https://prometheus.io/docs/prometheus/latest/querying/functions/).
  prefs: []
  type: TYPE_NORMAL
- en: absent()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `absent()` function takes an instant vector as an argument and returns
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An empty vector if the argument has results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1-element vector with the sample value equal to 1, containing the labels from
    the specified argument in the case of non-conflicting equality matchers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This function is quite useful for alerting on, as the name suggests, absent
    time series.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, say that the instant vector exists and we execute the following
    expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s say we use an expression with a label matcher using a nonexistent label
    value, like in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This will produce an instant vector with the nonexistent label value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s apply `absent` to a nonexistent metric, as shown in this snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This will translate into the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let''s say we use `absent` on a nonexistent metric and a nonexistent
    label/value pair, as shown in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The result can be seen in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: label_join() and label_replace()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These functions are used to manipulate labels—they allow you to join labels
    to other ones, extract parts of label values, and even drop labels (though that
    particular operation is easier and more ergonomic to do with standard aggregation
    operators). In both functions, if the defined target label is a new one, it will
    get added to the label set; if it's an existing label, it will get replaced.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using `label_join`, you''re required to provide an instant vector, define
    a resulting label, identify the separator of the resulting concatenation, and
    establish the labels to join, as exemplified in the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, say that we use the following sample data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We then apply the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We end up with the following instant vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'When you need to arbitrarily manipulate labels, `label_replace` is the function
    to use. The way it works is by applying a regular expression to the value of a
    chosen source label and storing the matched capture groups on the destination
    label. Both source and destination can be the same label, effectively replacing
    its value. This sounds complex, but it really isn''t; let''s have a look at the
    syntax of `label_replace`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Say that we take the preceding sample data and apply the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The result will then be the matching elements with the new label, called **port**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: When using `label_replace`, if the regular expression doesn't match the label
    value, the originating time series will be returned unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: predict_linear()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This function receives a range vector and a scalar time value as arguments.
    It extrapolates the value of each matched time series from the query evaluation
    time to the specified number of seconds in the future, given the trend in the
    data from the range vector. It uses linear regression to achieve such a prediction,
    which means there is no complex algorithmic forecasting happening in the background.
    It should only be used with gauges.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll apply the following expression, which employs `predict_linear` using
    a range of one hour of data, and extrapolate the sample value four hours in the
    future (60 (seconds) * 60 (minutes) * 4):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: rate() and irate()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These two functions allow you to calculate the rate of increase of the given
    counters. Both automatically adjust for counter resets and take a range vector
    as an argument.
  prefs: []
  type: TYPE_NORMAL
- en: While the `rate()` function provides the per second *average rate of change*
    over the specified interval by using the first and last values in the range scaled
    to fit the range window, the `irate()` function uses the last two values in the
    range for the calculation, which produces the instant rate of change.
  prefs: []
  type: TYPE_NORMAL
- en: It's important to understand in what scenarios the usage of one is more suitable
    than the other. For example, when creating visualizations such as dashboards,
    we might want to increase the awareness of possible spikes; `irate` fits this
    criteria. Note that as `irate()` uses the last two values in a range, it is sensible
    to step downsampling, and so it can only be used when fully zoomed in. When building
    alerting expressions, we are more interested in obtaining smoother trends, so
    that spurious spikes don't reset the `for` timer (as we'll see in [Chapter 9](9aa1e3da-13cf-4051-845d-1d1c924ef47b.xhtml),
    *Defining Alerting and Recording Rules*); in this case, `rate` is the more appropriate
    function to apply. Always ensure there are at least four samples in the range
    vector so that `rate()` can work reliably.
  prefs: []
  type: TYPE_NORMAL
- en: 'To show the differences between these two functions, the following screenshot
    illustrate the same metric, at the same timeframe, one using `rate()` and the
    other using `irate()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3599e048-112a-4092-8ced-a4cdeed41835.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.9: rate() of node_network_receive_bytes_total with 1m range'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/29508fe3-2742-40b8-bc04-1dd2544b8c26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.10: irate() of node_network_receive_bytes_total with 1m range'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, `irate` is a lot more sensitive to variations in the underlying
    counters, while `rate` generally produces more smoothed-out values.
  prefs: []
  type: TYPE_NORMAL
- en: histogram_quantile()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This function takes a float, which defines the required quantile (0 ≤ φ ≤ 1),
    and an instant vector of the gauge type as arguments. Each time series must have
    a `le` label (which means less than or equal to) to represent the upper bound
    of a bucket. This function also expects one of the selected time series to have
    a bucket named such as `+Inf`, which works as the catch-all, the last bucket of
    the cumulative histogram. Since histograms that are generated by Prometheus client
    libraries use counters for each bucket, `rate()` needs to be applied to convert
    them into gauges for this function to do its work. The time that's range selected
    for the range vector will then correspond to the window for the quantile calculation.
    Although rare, some histograms produced by third-party software might not use
    counters for their buckets, so they can be used directly in `histogram_quantile` as
    long as they fulfil the label requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, lets execute the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll be presented with a result similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: This provides an example of the output of an internal Prometheus histogram.
  prefs: []
  type: TYPE_NORMAL
- en: sort() and sort_desc()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As their names suggest, `sort` receives a vector and sorts it in ascending order
    by the sample values, while `sort_desc` does the same function but in descending
    order.
  prefs: []
  type: TYPE_NORMAL
- en: The `topk` and `bottomk` aggregation operators sort their results by default.
  prefs: []
  type: TYPE_NORMAL
- en: vector()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `vector()` function receives a scalar value as a parameter and returns a
    vector with no labels with the value of the specified scalar argument.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, query the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'It will return the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'This is normally used as a way of ensuring an expression always has at least
    one result, by combining a vector expression with it, like in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Since the `or` operator returns both sides, a sample with the value 0 will always
    be present.
  prefs: []
  type: TYPE_NORMAL
- en: Aggregation operations over time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The aggregation operations we discussed earlier are always applied to instant
    vectors. When we need to perform those aggregations on range vectors, PromQL provides
    the `*_over_time` family of functions, which work as described in the *Horizontal
    aggregation* section of [Chapter 4](d571ee63-1941-40e0-a314-70030efe76ea.xhtml),
    *Prometheus Metrics Fundamentals*. All of them take a range vector and output
    an instant vector. Following is the description of the operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Operation** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `avg_over_time()` | Average value of all samples in the range. |'
  prefs: []
  type: TYPE_TB
- en: '| `count_over_time()` | Count of all samples in the range. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_over_time()` | Maximum value of all samples in the range. |'
  prefs: []
  type: TYPE_TB
- en: '| `min_over_time()` | Minimum value of all samples in the range. |'
  prefs: []
  type: TYPE_TB
- en: '| `quantile_over_time()` | The quantile of all samples in the range. It requires
    two arguments, the definition of the desired quantile, φ, as a scalar, where 0
    ≤ φ ≤ 1, as a first argument and then a range-vector. |'
  prefs: []
  type: TYPE_TB
- en: '| `stddev_over_time()` | The standard deviation of the sample''s value in the
    range. |'
  prefs: []
  type: TYPE_TB
- en: '| `stdvar_over_time()` | The standard variance of the sample''s value in the
    range. |'
  prefs: []
  type: TYPE_TB
- en: '| `sum_over_time()` | The sum of all sample values in the range. |'
  prefs: []
  type: TYPE_TB
- en: Time functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prometheus supplies a number of functions to help manipulating time data. These
    are useful for a couple of scenarios, such as checking how long ago was a process
    or batch job last seen, only triggering alerts at certain times, or not triggering
    them at all on certain days. Every time function in Prometheus assumes Universal
    Coordinated Time (UTC).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `time` function returns an instant vector with the current time in the
    UNIX epoch format (commonly known as a UNIX timestamp): the number of seconds
    that have elapsed since January 1st, 1970 UTC.'
  prefs: []
  type: TYPE_NORMAL
- en: The `timestamp` function returns an instant vector with the UNIX timestamps
    of the samples returned by the supplied selector.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `minute`, `hour`, `month` and `year` functions all work the same way: they
    receive an instant vector with one or more timestamps, and return an instant vector
    with the corresponding time component they represent. These functions'' default
    input is the `time` function so, if they''re used without an argument, they will
    return the current minute, hour, month or year, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: The `days_in_month` function receives an instant vector with timestamps as argument
    and returns the number of days in the month for each of those timestamps. As with
    the previous functions, the default input argument is the `time` function. The
    result will obviously range from 28 to 31.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, and similarly to the previous function, the `day_of_week` and `day_of_month`
    functions expect an instant vector with timestamps as input and returns the corresponding
    day of the week (Sunday as 0, Monday as 1, and so on) and day of the month (from
    1 to 31), respectively. The default input is the `time` function.
  prefs: []
  type: TYPE_NORMAL
- en: Info and enum
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two metric types yet to be mentioned, info and enum. They are quite
    recent, but the convenience they bring is very much appreciated. Metrics of the
    type info have their names end with `_info` and are regular gauges with one possible
    value, 1\. This special kind of metric was designed to be a place where labels
    whose values might change over time are stored, such as versions (for example,
    exporter version, language version, and kernel version), assigned roles, or VM
    metadata information; if those labels were to be exported in every time series,
    were they to change, a break in continuity would happen as the metric identity
    (the combination of the metric name and label set) would also change. This would
    also pollute the labels of all the time series that were affected, since these
    new labels would be present in every metric. To use this type of metric, we need
    to combine it with the metrics we wish to augment by using the multiplication
    operator—since the info metric value is `1`, the multiplication won't change the
    value of the other metric—and the `group_left`/`group_right` modifiers allow us
    to enrich of the resulting vector with the labels we might require.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of a query using an info metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the previous query result in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The enum metric type is also a gauge, just like info. Its objective is to provide
    a way to expose anything that might need state tracking, such as the current state
    of a state machine. The most common use case for this type of metric is exposing
    the state of daemons (start, starting, stop, stopping, failed, and so on). This
    tracking is done by maintaining state information on a label, appropriately named
    state, and setting the metric value to `1` for the current state and 0 otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of an instant vector selector query using an enum metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The previous query results in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Now that we know the basics of PromQL, let's dive into some common patterns
    and avoidable pitfalls when writing expressions.
  prefs: []
  type: TYPE_NORMAL
- en: Common patterns and pitfalls
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With such a powerful language at your disposal, it's easy to become overwhelmed
    with so many options. In the following sections, we'll provide some common patterns
    and pitfalls to ensure the intended use of PromQL for each situation described,
    and in this way, further enforcing the knowledge that we have provided you with
    so far.
  prefs: []
  type: TYPE_NORMAL
- en: Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the power and flexibility of PromQL allows for a world of possibilities
    in terms of information extraction, there are a few query patterns that make a
    set of common problems much easier to understand and help increase the level of
    insight into the monitored services. In the following topics, we'll be covering
    a few of our favorites, in the hope they become as useful for you as they currently
    are for us.
  prefs: []
  type: TYPE_NORMAL
- en: Service-level indicators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 1](4214ddff-8289-4dc6-b0ef-240510a22192.xhtml), *Monitoring Fundamentals*,
    we introduced the notion of *What to measure*, discussing *Google's Four Golden
    Signals*, as well as the USE and RED methodologies. Building upon that knowledge,
    we can start to define **service-level indicators** (**SLIs**), which reflect
    a given service's performance and availability. Constructing queries to generate
    SLIs is a common pattern of PromQL usage and one of the most useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example of an SLI: the typical definition of one is the number
    of good events over the number of valid events; in this case, we want to understand
    whether the percentage of requests being served by Prometheus is at or below 100
    ms, which makes it a latency SLI. First we need to gather information about how
    many requests are being served under that threshold; thankfully, we can rely on
    an already available histogram-typed metric called `prometheus_http_request_duration_seconds_bucket`.
    As we already know, this type of metric has buckets represented by the `le` label
    (less or equal), so we just match the elements under 100 ms (0.1 s), like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'While ratios are typically the base unit in these type of calculations, for
    this example, we want a percentage, and so we must divide the matched elements
    by the total number of requests made (`prometheus_http_request_duration_seconds_count`)
    and multiply that result by 100\. These two instant vectors can''t to be divided
    directly due to the mismatch of the `le` label, so we must ignore it, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us an instant vector with information per endpoint and per instance,
    setting the sample value to the percentage of requests answered below 100 ms since
    the service started on each instance (remember that `_bucket` is a counter). That''s
    a good start, but not quite what we''re after, as we want the SLI for the service
    as a whole, not for each instance or for each endpoint. It''s also more useful
    to calculate it on a rolling window instead of averaging an indeterminate amount
    of data; as more data is collected, the average becomes smoother and harder to
    move. So, to fix these issues, we need to rate the counters over a time window
    to get a fixed rolling average, and then aggregate away instances and endpoints
    using `sum()`. This way, we don''t need to ignore the `le` label either, as it
    is also discarded during aggregation. Let''s put it all together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Building a **service-level objective** (**SLO**) for our service now becomes
    trivial as we are just required to specify the percentage we're aiming to achieve
    using a comparison operator. This makes for an excellent condition to be defined
    as an alert.
  prefs: []
  type: TYPE_NORMAL
- en: Percentiles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We just learned how to extract the percentage of requests being served under
    a given latency, but what if we need to understand the latency of a given percentile
    of requests?
  prefs: []
  type: TYPE_NORMAL
- en: 'To obtain, for example, the 95th percentile, we can use the `histogram_quantile`
    function by defining the quantile (in this case, `0.95`), and then feed it the
    query expression that represents the set of data we''re interested in—the average
    rate of increase for each of the buckets in the request duration histogram during
    a rolling time window. If we want the global latency of the service, instead of
    per instance/pod/handler, we need to apply the `sum()` aggregation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: This expression will produce a value that represents that 95% of requests will
    be at or under said value.
  prefs: []
  type: TYPE_NORMAL
- en: The health of scrape jobs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For each defined scrape job, Prometheus will produce an automatic metric named
    `up`, which reflects the health of the job in question – 1 for a successful scrape
    and 0 for a failed one. We can use this metric to quickly visualize the current
    health state of the entire infrastructure of exporters and/or applications being
    scraped.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s get an overview of all the successful jobs being scraped:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Pitfalls
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The power and flexibility of PromQL can enable some impressive slicing and dicing
    of time series data, but can also be a source of frustration, unexpected results,
    and even severe performance issues. While recent releases of Prometheus have been
    steadily introducing features to address some of these pitfalls, understanding
    these issues can help you get the most out of PromQL, while saving you time and
    computing resources.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the right functions for the data type
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The most common pitfall when starting out with PromQL is not choosing the right
    function for the data type (such as counters, gauges, or histograms) or vector
    type. Even though this information is pointed out in the Prometheus documentation,
    there can still be some confusion as there are conceptually similar named functions
    and aggregators: `rate` and `deriv`, `increase`; `delta`, `quantile`; `histogram_quantile`,
    `sum` and `sum_over_time`, among others. Fortunately, in cases where there is
    a mismatch of vector types, the expression evaluation will fail and let you know
    what is wrong; for a mismatch in data types, such as providing a counter to a
    function that expects a gauge, the expression might evaluate successfully but
    return incorrect or deceptive results.'
  prefs: []
  type: TYPE_NORMAL
- en: Sum-of-rates versus rate-of-sums
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The previous point might seem obvious, but when the complexity of the queries
    built starts to increase, it''s easy to make mistakes. A common example of this
    is trying to rate a sum of counters instead of summing rates. The `rate` function
    expects a counter, but a sum of counters is actually a gauge, as it can go down
    when one of the counters resets; this would translate into seemingly random spikes
    when graphed, because `rate` would consider any decrease a counter reset, but
    the total sum of the other counters would be considered a huge delta between zero
    and the current value. In the following diagram, we can see this in action: two
    counters (**G1**, **G2**), one of which had a reset (**G2**); **G3** shows the
    expected aggregate result that''s produced by summing the rate of each counter;
    **G4** shows what the sum of counters 1 and 2 looks like; **G5** represents how
    the rate function would interpret **G4** as a counter (the sudden increase being
    the difference between 0 and the point where the decrease happened); and finally,
    **G6** shows what rating the sum of counters would look like, with the erroneous
    spike appearing where **G2**''s counter reset happened:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9a1a2ab8-d685-4ab1-8c23-f87a6af1a15d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.11: Approximation of what rate of sums and sum of rates look like'
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of how to properly do this in PromQL might be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Making this mistake was a bit harder in past versions of Prometheus, because
    to give `rate` a range vector of sums, we would either need a recording rule or
    a manual sum of range vectors. Unfortunately, as of Prometheus 2.7.0, it is now
    possible to ask for the sum of counters over a time window, effectively creating
    a range vector from that result. This is an error and should not be done. So,
    in short, always apply aggregations after taking rates, never the other way around.
  prefs: []
  type: TYPE_NORMAL
- en: Having enough data to work with
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The rate group of functions (`rate`, `irate`, `increase`, `deriv`, `delta`,
    and `idelta`) need at least two samples in the supplied range vector to work properly.
    This means that time ranges that are close to `scrape_interval` might fail to
    produce the desired results as a single failed scrape or window alignment issues
    (scrapes don''t happen at exact intervals and might be delayed) will make the
    range contain only one sample. It is therefore recommended to use 4 (or more)
    times the `scrape_interval` to make sure that enough samples are returned for
    the calculation to work. Following diagram shows failed scrape changing the trend
    of samples for a given range:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0920208d-3f3a-4d42-b37d-60e62297884e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.12: A failed scrape changing the trend of samples for a given range'
  prefs: []
  type: TYPE_NORMAL
- en: Unexpected results when using increase
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On a related subject, a common point of confusion is why functions such as `increase`
    and `delta` produce non-integer results. This point is briefly explained in the
    documentation, but is worth expanding upon. Since Prometheus collects data on
    a regular basis (defined in the `scrape_interval` configuration), when a query
    asks for a range of samples, the window limits for that range usually don't neatly
    align with the timestamps of the returned data. These functions extrapolate what
    the result would be like if the data points matched the time window. They do this
    by calculating the precise result with the samples provided, and then multiplying
    that result by the ratio of the time window over the interval between the first
    and last data point, effectively scaling the result to the requested range.
  prefs: []
  type: TYPE_NORMAL
- en: Not using enough matchers to select a time series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another common pitfall when writing PromQL expressions, whether for dashboarding
    or alerting, is not using enough matchers to make sure that the returned samples
    are from the expected time series. It is considered an anti-pattern in the Prometheus
    community to namespace metric names to applications when the metric in question
    is not specific to that particular software, and even if it is, there might be
    cases where naming collisions occur; this is why it is good practice to scope
    selectors so that `job` is always explicitly selected when trying to extract information
    about a particular software. As an example, we can look at the `go_goroutines` metric,
    which is collected by the first-party Prometheus Go client library: as a sizeable
    chunk of the Prometheus ecosystem is written in Go and uses this client library
    for instrumentation, it is usual for this metric to be present in many scrape
    jobs. This means that, if we were to investigate the aggregate go-routine behavior
    of a particular software, we would get incorrect results if the selectors that
    were used weren''t sufficiently narrow for the instances we were interested in.'
  prefs: []
  type: TYPE_NORMAL
- en: Losing statistical significance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A mistake not specifically related to PromQL, but easy to make due to the flexibility
    of the language, is to apply transformations to aggregate values, thus losing
    their statistical significance. As an example, you might be tempted to average
    pre-computed quantiles in summaries from a group of instances to get a feel for
    the cluster, but they can't be further manipulated from a statistical standpoint
    – the result from that operation would not resemble the corresponding quantiles
    of the cluster as a whole. This, however, can be done with histograms, since buckets
    from each instance can be summed cluster-wide before calculating the approximate
    quantile. Another common example of this is averaging averages.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing what to expect when constructing complex queries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An interesting detail to be mindful of when using PromQL is that, when using
    comparison operators between vectors, the returned result will be from the left-hand
    side of the comparison. This means that, when doing comparisons between a current
    value and a threshold, you should do them in that order (for example,  `current_value
    < threshold`) as you probably want the returned value to be the current value
    and not the threshold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Furthermore, when chaining different comparisons using `and`, the result will
    still be the left-hand side from the first comparison. The following example returns
    the percentage of space left in a filesystem, which is under 20%, and is predicted
    to be full within 4 hours given the fill rate of the last 6 hours. Note that it''s
    not in read-only mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Switching the first comparison with the second would produce the same number
    of results, but would also present the predicted bytes available 4 hours from
    now. This result would be less useful as knowing exactly the amount of negative
    bytes predicted just conveys the fact that they will be 0 in reality. Both expressions
    would be viable for alerting, though, as the resulting value of the expression
    is not sent in the alert notification.
  prefs: []
  type: TYPE_NORMAL
- en: The query of death
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lastly, care should be taken when crafting queries with overly broad selectors
    and memory-intensive aggregations. While Prometheus has default checks and bounds
    implemented to avoid unlimited memory usage (as discussed in [Chapter 5](12e775c2-bee9-4ebe-ad73-2f9313eeeeee.xhtml),
    *Running a Prometheus Server*), it is still possible to run up against a memory
    limit that is not large enough—either a container limit or even the actual system
    RAM, which would make the OS unceremoniously terminate the Prometheus server.
    Compounding the problem, pinpointing which queries are using the most resources
    is hard, especially in environments where you have little control over what queries
    are sent to the server; there is no slow query log functionality built in as making
    it work would involve some trade-offs that would impact performance and manageability.
    In practice, though, constant improvements to capping resource utilization (especially
    on the memory front) have made it much harder for this particular issue to happen
    in well-dimensioned environments.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on to more complex queries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the information that's provided so far, we can move on to more complex
    queries, understand how they are built, and what to expect from them. In the following
    sections, we'll go over some intricate scenarios that demand the use of PromQL
    to explore and solidify the concepts we've covered so far.
  prefs: []
  type: TYPE_NORMAL
- en: In which node is Node Exporter running?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This scenario is designed to assist your understanding of concepts such as `info`
    metrics and the `group_left` modifier.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario rationale
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When running on Kubernetes, you might need to troubleshoot a Node Exporter pod,
    and for that you're required to know on which host it's running. Node Exporter
    metrics see the pod and not the host, so you don't have the hostname available
    in the metrics that produced. In this scenario, we are required to add the missing
    information to metrics that didn't have that label originally. Another alternative
    to this scenario would be to make the required information available in the instance
    labels via relabeling.
  prefs: []
  type: TYPE_NORMAL
- en: PromQL approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following query allows us to augment the `node_exporter_build_info` metric
    with yet another label, called `nodename`, which has information regarding the
    hostname running your Node Exporter pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we have the following instant vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'We also have `node_uname_info`, which has the `nodename` label:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'This translates into the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'With the help of an info metric, as we described previously, we''ll use the
    following expression to add the `nodename` label from the `node_uname_info` info
    type metric to the `node_exporter_build_info` metric using `group_left`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'The result can be inspected in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Comparing CPU usage across different versions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This scenario is similar to the previous one, but takes it a step further by
    combining metrics from different sources and making them all work together.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario rationale
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You might want to observe how different software versions behave in terms of
    throughput or resource usage. This might be easier to analyze by graphing the
    patterns before and after the upgrade in clear terms. In this specific example,
    we are going to look at container CPU usage for `node_exporter` before and after
    an upgrade.
  prefs: []
  type: TYPE_NORMAL
- en: 'Keep in mind a couple of considerations: for the sake of this example, `node_exporter`
    is running as a container, which is ill-advised in a real-world scenario. Furthermore,
    we’ll be using `container_cpu_usage_seconds_total` from cAdvisor instead of `process_cpu_seconds_total`,
    which is collected directly from natively instrumented applications, so that this
    method can be applied to any kind of containerized process, consolidating the
    use of cAdvisor metrics along the way.'
  prefs: []
  type: TYPE_NORMAL
- en: PromQL approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `container_cpu_usage_seconds_total` metric gives us the amount of CPU seconds
    spent running each container, and comes from the `cadvisor` exporter. The `node_exporter`
    version can be found in the `node_exporter_build_info` metric. To make things
    a bit harder, since the container metrics come from `cadvisor`, the container
    and pod registered in those metrics are the `cadvisor` ones and not from the target
    pods; however, we can find the original container names and pod names in the `container_label_io_kubernetes_container_name`
    and `container_label_io_kubernetes_pod_name` labels, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we need to do is get the average number of CPU seconds per
    second each pod is using on a rolling window of one minute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to create a new label in `node_exporter_build_info` so that matching
    works as intended. For this use case, we can use either `label_join` or `label_replace`,
    as we''re just reading one label and writing its contents verbatim in another:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we just need to match both metrics through their common label, `container_label_io_kubernetes_pod_name`,
    by using `on()` and then ask for the version label to be joined to the CPU expression''s
    label set by using `group_left()`. Let''s put that all together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/f0716997-1497-4298-a144-62225620c708.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.13: Node exporter version upgrade impact on CPU usage'
  prefs: []
  type: TYPE_NORMAL
- en: All of this might seem complex at first but after you try out these concepts
    for yourself they quickly become much easier to understand, apply and to reason
    about.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the basics of PromQL, from selectors to functions,
    covering concepts such as binary operators, vector matching, and aggregations.
    Going through the common patterns and pitfalls, we were introduced to how this
    language allows much more than simple querying and how it has become an essential
    infrastructure tool, helping with the design and management of SLIs and SLOs.
    We also demonstrated several scenarios where PromQL shines, and how seemingly
    complex queries are not that complex after all.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, [Chapter 8](19357d8c-dfcf-4497-ae80-4761f6633d14.xhtml), *Troubleshooting
    and Validation*, we'll delve into how to validate a healthy Prometheus setup and
    learn how to troubleshoot issues quickly, ensuring the stability of the monitoring
    stack.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are the six available comparison operators in PromQL?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When should a `group_right` modifier be used instead of a `group_left` one?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why shouldn't you use the `sort()` function when applying the `topk` aggregation
    operator?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the major difference between `rate()` and `irate()`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which type of metric has an `_info` suffix and what is its purpose?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Should you sum and then rate or rate and then sum?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can you get the average CPU usage for the last five minutes in a percentage?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Querying Prometheus**: [https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SRE Book - Service Level Objectives**: [https://landing.google.com/sre/sre-book/chapters/service-level-objectives/](https://landing.google.com/sre/sre-book/chapters/service-level-objectives/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
