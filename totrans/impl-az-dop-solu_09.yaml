- en: Dealing with Databases in DevOps Scenarios
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapters, you have learned about the continuous integration
    and continuous deployment of your software. You also learned how the same principles
    can be applied to the delivery of configuration in infrastructure. Once you have
    adopted these principles and start increasing the flow of value delivery, you
    might run into another challenge: managing your database schema changes.'
  prefs: []
  type: TYPE_NORMAL
- en: Applying DevOps to databases can feel like trying to change the tires on a running
    car. You must find some way of coordinating changes between database schema and
    application code without taking the system down for maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will learn about different approaches for doing just that:
    managing these schema changes while avoiding downtime. With proper planning and
    a disciplined approach, this can be achieved in a way that manages risks well.
    You will see how you can treat your database schema as code, and you will learn
    about the different approaches that are available to do so. You will also see
    another approach that avoids database schemas altogether, namely, going schema-less.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Managing a database schema as code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying database schema changes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Going schema-less
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other approaches and concerns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to practice the ideas that are laid out in this chapter, you will
    need to have the following tools installed:'
  prefs: []
  type: TYPE_NORMAL
- en: An application with the Entity Framework Core NuGet package installed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visual Studio with SQL Server Data Tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to Azure Pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Azure subscription, for accessing Cosmos DB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing a database schema as code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For those of you who are familiar with working with relational databases from
    application code, it is very likely they have been working with an **object-relational
    mapper** (**ORM**). ORMs were introduced to fill the impedance mismatch between
    object-oriented programming languages and the relational database schema, which
    works with tables. Well-known examples are Entity Framework and NHibernate.
  prefs: []
  type: TYPE_NORMAL
- en: ORMs provide a layer of abstraction that allows for the storage and retrieval
    of objects from a database, without worrying about the underlying table structure
    when doing so. To perform automated mapping of objects to tables, or the other
    way around, ORMs often have built-in capabilities for describing a database schema,
    the corresponding object model, and the mappings between them in a markup language.
    Most of the time, neither of these have to be written by hand. Often, they can
    be generated from an object model or an existing database, and the mappings between
    them are often, by convention, generated or drawn in a visual editor.
  prefs: []
  type: TYPE_NORMAL
- en: While all this allows for the current database schema to be defined as code,
    this alone does not help with coping with schema changes, yet. For handling schema
    changes as code, two common approaches are available. The first one describes
    every change in code; the other one describes only the latest version of the schema
    in code. These approaches are known as migration-based and state-based approaches.
    Both can rely on third-party tooling to use these for applying the changes to
    the database.
  prefs: []
  type: TYPE_NORMAL
- en: Migrations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first approach is based on keeping an ordered set of changes that have to
    be applied to the database. These changes are often called *migrations*, and they
    can be generated by tools such as Microsoft Entity Framework, or Redgate SQL Change
    Automation, or they can be written by hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tools can automatically generate the migration scripts based on a comparison
    of the current schema of the database and the new schema definition in source
    control. This is called **scaffolding**. The scripts generated by tools are not
    always perfect, and they can be improved by applying the domain knowledge that
    the programmer has, but the tool does not. Once one or more new migrations are
    scaffolded or written, they can be applied to a database using the chosen tool.
    A diagram showing how that works is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f7b921f8-9d80-4f1c-a2f4-18aabca2489b.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we see how an ever-growing series of migrations, labeled m1 to m4, are
    generated to describe incremental changes to the database. To update the database
    to the latest version, the latest applied migration is determined and all migrations
    after that are added one after the other.
  prefs: []
  type: TYPE_NORMAL
- en: 'When editing migration scripts by hand, the following has to be kept in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: The migration scripts should be ordered. Migrations describe the SQL statements
    that need to be executed in order to move the database from a version *x* to version
    *x+1*. Only once this is complete can the next migration be started.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A migration script should migrate not only the schema, but also the data. This
    can mean that in-between steps are needed. For example, moving two columns to
    another table often implies that the new columns are first created, then filled
    with the data from the old columns, and that only then are the old columns removed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is advisable to include all database objects in the migration scripts. Extra
    indexes and constraints should not be applied to the production database only,
    but also to test environments. With migrations, there is already a mechanism for
    delivering those from source control. Having these in the same migration scripts
    also ensures that indexes and constraints are applied in the same order, and cannot
    unexpectedly block migrations by existing only in production.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If possible, migration scripts should be made idempotent. If there is ever an
    issue or the suspicion of an issue, being able to just rerun the last migration
    is a great way to ensure that it is fully applied.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One disadvantage of this approach is the strict ordering requirement that is
    imposed on generating and applying the generated migrations. This makes it hard
    to integrate this approach into a development workflow that relies heavily on
    the use of branches. Migrations created in different branches that are merged
    together only later might break the ordering of migrations or, even worse, merge
    a split in the migration path. For example, imagine the case where two migrations, *b*
    and *c*, in two different branches, have been created after an existing migration,
    *a*. How are these going to be merged? Neither order—*a, b, c* or *a, c, b—*is
    correct, since both *b* and *c* are created to be executed directly after *a.*
    The only way such an error can be fixed is by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Remove all migrations apart from the first new one, for example, *c* in this
    case.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply all other migrations to a database that has none of the new migrations
    applied; in this case, only *b* if *a* was already applied, or both *a* and *b*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a new migration for the other migrations; in this case, a replacement
    for *c.*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An advantage of this approach is that every individual schema change will be
    deployed against the database in the same fashion. Irrespective of whether one—or
    more than one—migration is applied to the production database at the same time,
    they will still run one by one in a predictable order and in the same way in which
    they ran against the test environment, even if they were applied there one by
    one.
  prefs: []
  type: TYPE_NORMAL
- en: End state
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A different approach to managing schema changes is to not keep track of the
    individual changes (or migrations), but only store the latest version of the schema
    in source control. External tools are then used to compare the current schema
    in source control with the actual schema of the database, generate migration scripts,
    and apply these when running. The migration scripts are not stored, and are single-use
    only.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike writing migrations, it is not feasible to execute a task like this by
    hand. While tracking the newest version of the schema by hand in source control
    can be managed, the same is not feasible for an end-state approach. Generating
    a migration script while comparing the existing schema and the new schema and
    applying this migration script can only be done using a tool. Examples of these
    tools are Redgate SQL Source Control and SQL Server Data Tools. How these tools
    work, is shown in the here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9bdb8efd-8b7a-43a1-9754-eeaa31b91458.png)'
  prefs: []
  type: TYPE_IMG
- en: Here we see how the current actual database schema and the description of the
    desired database schema are compared to generate an upgrade and directly apply
    a script for making the changes needed to make the actual schema the same as the
    desired schema.
  prefs: []
  type: TYPE_NORMAL
- en: One advantage of this approach is that there is no series of scripts generated
    that have to be executed in a specific order. Therefore, this approach combines
    easily with extensive branching schemas, where changes are integrated more slowly
    over time. It also removes the need to write migrations by hand for simple scenarios,
    such as adding or deleting a column, table, or index.
  prefs: []
  type: TYPE_NORMAL
- en: The disadvantage of this approach is that it makes it harder to handle changes
    that need data operations as well. Again, imagine a scenario of moving two columns
    to another table. Since the tooling only enforces the new schema, this will lead
    to data loss if there is no further intervention.
  prefs: []
  type: TYPE_NORMAL
- en: One possible form of intervention to circumvent this is the addition of pre-
    and post-deployment scripts to the schema package. In the pre-deployment script,
    the current data is staged in a temporary table. Then, after applying the new
    schema, the data is copied from the temporary table to the new location in the
    post-deployment script.
  prefs: []
  type: TYPE_NORMAL
- en: This section was about managing database schema changes in a format that can
    be stored in source control. The next section discusses how these changes can
    be picked up at deploy time and then applied to a database.
  prefs: []
  type: TYPE_NORMAL
- en: Applying database schema changes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the database schema, and optionally, a series of migrations defined in
    source control, it is time to start thinking about when to apply changes to the
    database schema. There are two methods to do so. Database schema changes can be
    applied prior to deployment of the new application version, or by the application
    code itself.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading as part of the release
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first approach to applying databases changes is as part of the release pipeline.
    When this is the case, the tool that is responsible for reading and executing
    the migration scripts is invoked using a step in the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: This invocation can be done using a custom script in PowerShell or another scripting
    language. However, this is error-prone, and with every change of tool, there is
    a risk that the scripts need to be updated. Luckily, for most of the migration-based
    tools, there are Azure Pipelines tasks that are readily available for starting
    the migration from the release.
  prefs: []
  type: TYPE_NORMAL
- en: For example, there is an Azure Pipelines extension available for applying Entity
    Framework Core migrations to a database directly from the `dll` file where they
    are defined. This task can be added to the release pipeline for updating the database,
    before the new application code is deployed.
  prefs: []
  type: TYPE_NORMAL
- en: Another variation is a split between the build and the release phase of an application.
    In this case, the migration scripts are exported as a separate build artifact,
    either directly from source code—if written in SQL—or after executing a tool that
    generates the necessary SQL scripts as output. This artifact is then downloaded
    again in the release phase, where it is applied to the database using an Azure
    Pipelines task for executing SQL.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading by the application code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Instead of applying schema changes from the release pipeline, they can also
    be applied by the application itself. Some of the ORMs, with migration support
    built in, have the capability to automatically detect whether the database schema
    matches the latest migration. If not, they can automatically migrate the schema
    to that latest version on the spot.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of an ORM that supports this is Entity Framework. The core version
    of Entity Framework does not have support for automatic migrations built in. In
    Entity Framework Core, a single line of application code can be used to initiate
    an upgrade at a time that is convenient from the perspective of the application.
    The code for doing so is shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The advantage of this approach is that it is very simple to enable. Just a Boolean
    switch in the configuration of, for example, Entity Framework can enable this
    workflow. However, the disadvantage is that most ORMs that support this will enforce
    a global lock on the database—stopping all database transactions while the migrations
    are running. For any migration or set of migrations that take more than a few
    seconds, this approach might be impractical.
  prefs: []
  type: TYPE_NORMAL
- en: This approach is normally only used for migration-based approaches. Approaches
    that use an end-state approach require an external third-party tool that is used
    to generate the necessary migration scripts and apply them. This is normally done
    from the release pipeline and is not wrapped in the application itself.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As the previous section illustrated, it is important to think about how and
    when changes to the database schema or the application (or applications!) that
    use that schema are applied. But no matter how the deployment of schema changes
    and code deployment are scheduled, there will always be a period at which one
    of the following is true:'
  prefs: []
  type: TYPE_NORMAL
- en: The new application code is already running while the schema changes are not
    applied yet or are in the process of being applied.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The old application code is still running while the schema changes are already
    applied or are in the process of being applied.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The application code is not running while the schema changes are being applied.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third situation is highly undesirable. This is true in general, but especially
    when practicing DevOps. If changes are shipped often and during working hours,
    it is unacceptable to take the application down for every schema change.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prevent having to take the application down while schema changes are being
    applied, one of the following conditions has to be met:'
  prefs: []
  type: TYPE_NORMAL
- en: The schema changes are backward-compatible in such a way that the old version
    of the application code can run without errors against a database where the schema
    changes have already been applied, or are being applied.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new application code is backward-compatible in such a way that it can run
    against both the old and the new versions of the schema.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meeting the first of these conditions ensures that the old application code
    can continue to run while the schema changes are being applied. Meeting the second
    of these conditions ensures that the new version of the application code can be
    deployed first, and once that is completed, the database can be upgraded while
    this code is running. While either will work, it is often desirable to aim for
    the first condition. The reason is that schema changes often support application
    code changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that the following is a safe process for deploying schema changes
    without downtime:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new database.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the database changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify that the changes have been applied properly, or abort the deployment
    pipeline.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the new application code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is important to realize that this process assumes failing forward. This means
    that if there ever is an issue with the deployment of schema changes, they should
    be resolved before going forward with the code changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, meeting the condition of backward combability for schema changes can
    sometimes be impossible to fulfill for a schema change. If this is the case, the
    change can often be split into two partial changes that together have the same
    end result, while they both meet the condition of backward combability. For example,
    renaming a property, or changing the unit in which it stores a distance from feet
    to meters, can be executed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a migration that adds a new column to a database table, storing the
    distance in meters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add an application code that reads from the old column, but writes to both columns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy these changes to production.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a new migration that migrates data from the old column to the new column
    for all cases where the new column is not yet filled, but the old column is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the application code to read and write only the new column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy these changes to production.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a new migration that removes the old column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the correct tools and a proper process, it is possible to execute effective
    and safe deployments of schema changes. In the next section, another approach,
    using schema-less databases, is introduced.
  prefs: []
  type: TYPE_NORMAL
- en: Going schema-less
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections, the focus was on relational databases, where strict
    schemas are applied to every table. A completely different approach to database
    schema management is to let go of having a database schema altogether. This can
    be done by using schema-less or document databases. A well-known example of a
    schema-less database is Azure Cosmos DB. These databases can store documents of
    different forms into the same table. Table is quoted here, since these types of
    databases often do not use the term "table", but call this a database, a container,
    or a collection.
  prefs: []
  type: TYPE_NORMAL
- en: Since these databases can store documents with a different schema in the same
    collection, schema changes no longer exist from a database's point of view. But
    of course, there will be changes to the structure of the corresponding objects
    in the application code over time. To see how to handle this, it is best to differentiate
    between storing objects in the database and reading them back.
  prefs: []
  type: TYPE_NORMAL
- en: Writing objects to the database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The documents that are stored in a schema-less database are often serializations
    of objects in application code. When working with a relational database, these
    objects are often stored using an **object-relational mapper** (**ORM**), such
    as Entity Framework, Dapper, or NHibernate. When working with a document database,
    these objects are often serialized and stored in the database. This means that
    a change in the definition of that code object will also result in a different
    document structure when saving the object. Due to the nature of document databases,
    this will work fine.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, take the following C# class and its JSON representation after
    serializing it to a document database:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'After this code has been running in a production environment for a while, and
    thousands of persons have been saved, a new requirement comes in. Next to the
    name of the person, the city where they live must also be recorded. For this reason,
    the `Person` class is extended to include another property. After performing this
    change and deploying the new code, whenever a person is saved, the following code
    is used, resulting in the JSON shown next to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: While the definition of the `Person` class has changed—and the corresponding
    JSON has as well—both document forms can be saved into the same collection.
  prefs: []
  type: TYPE_NORMAL
- en: This shows that from the viewpoint of writing information to the database, the
    schema-less approach is very convenient, since developers do not have to think
    about schema change management at all.
  prefs: []
  type: TYPE_NORMAL
- en: Reading objects from the database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While schema-less databases make it extremely easy to write documents of different
    forms to the same collection, this can pose problems when reading documents back
    from that same collection and deserializing them. In reality, the problem of schema
    management is not removed, but deferred to a later point in time.
  prefs: []
  type: TYPE_NORMAL
- en: Continuing the example from the previous section, deserializing the first person
    that was saved on the new C# `Person` class definition will result in a null value
    for the city property. This can be unexpected, since the C# code guarantees that
    a person without a city can never be constructed. This is a clear example of the
    challenges that schema-less databases pose.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, the issue can be circumvented by updating the `Person` class
    to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next to this scenario, where a property was added, there are many other scenarios
    that will require the C# class to be adapted in order to handle deserialization
    scenarios. Some examples are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Adding a property of a primitive type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding a complex property, another object, or an array
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Renaming a property
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replacing a property of a primitive type with a complex property
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making nullable properties non-nullable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Adding code to objects to handle these situations increases the size and complexity
    of the code base, and pollutes the primary code base with the capabilities for
    coping with past situations. Especially when this happens often, this can lead
    to unwanted complications in a code base. To prevent this, a possible solution
    is to go through the following process whenever the schema of an object changes:'
  prefs: []
  type: TYPE_NORMAL
- en: Change the schema of the object, ensuring that there are only properties added.
    Even when the goal is to remove a property, at this stage, only a property with
    the new name is added.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement logic on the object to cope with the deserialization of old versions
    of the object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the new version of the object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start a background process that loads all objects of the type from the database
    one by one, and saves them back to the database.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the background process has processed all existing entities, remove the
    code that is responsible for coping with the schema change during deserialization
    from the code base, along with any properties that are no longer used.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using this approach, all changes are propagated to all stored versions of the
    object over a period of time. The downside to this approach is that the change
    to the object's structure is spread over two changes that must be deployed separately.
    Also, deployment of the second change must wait until all objects in the database
    have been converted.
  prefs: []
  type: TYPE_NORMAL
- en: Other approaches and concerns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Besides the more common approaches that were discussed previously, the following
    tips and approaches might help with reducing the amount of work in dealing with
    databases, or help reduce the risk associated with making database changes.
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing the influence of databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A first step in dealing with databases can be to reduce the chance that a database
    change has to be made. In many databases, it is possible to write stored procedures—or
    some other code or script—that executes within the database engine. While stored
    procedures come with some benefits, changing them can also count as a database
    schema change, or at the least result in changes that can be difficult to test.
  prefs: []
  type: TYPE_NORMAL
- en: One simple approach for this is to just replace stored procedures with application
    code that allows for easier side-by-side changes using feature toggles.
  prefs: []
  type: TYPE_NORMAL
- en: Full side-by-side deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When working in a high-risk environment, or with a fragile database, there
    is also another approach to database schema changes that can be taken. This approach
    is based on applying feature toggles and the blue–green deployment pattern, and
    goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Change the application code in such a way that it writes any update to not just
    one, but to two databases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the production environment, create a complete, full copy of the existing
    database and configure the application code to write all changes to both databases.
    These databases will be called *old* and *new*, from now on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Introduce the required changes to the new database schema and the application
    code *only* in the path that writes to the new database.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Introduce the necessary changes in all code paths that read data in such a way
    that all queries run against both databases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the application code to detect differences in the query results between
    the new and the old databases, and log an error when it finds any discrepancy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the changes run without any issues, remove the old database, and the old
    read and write access paths, from the application code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the changes run with errors, fix the issue. Next, restart by restoring the
    backup of the intended new database, and resume at step five.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The advantage of this approach is that it is very lightweight. The downside
    is that it is very involved, takes a lot of work, and is more expensive. Also,
    the extra database costs and duration of backup and restore operations should
    be taken into account.
  prefs: []
  type: TYPE_NORMAL
- en: Testing database changes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just as with application code, insights into the quality of database schema
    changes can be gathered through testing. Links to performing tests on database
    schemas can be found at the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, in order to fully cover the risks introduced by database changes,
    system tests are needed that execute against a fully deployed stack of the application.
    This type of test can cover most of the risks that come from faulty schemas, invalid
    stored procedures, and database and application code mismatches.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have learned how to manage your database schema and schema
    changes using source control. You know about both the migration-based and end
    state based storing of changes, and how to apply them to your production database
    in a safe manner.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, you have learned how schema-less databases can remove the burden
    of traditional schema management. However, this comes at the price of having to
    cope with schema differences when reading older versions of an object back from
    the database.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn about continuous testing. You will not only
    learn about testing techniques, but also about which to apply at what point, and
    how testing is a crucial part of DevOps and a critical enabler of a continuous
    flow of value to end users.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we conclude, here is a list of questions for you to test your knowledge
    regarding this chapter''s material. You will find the answers in the *Assessments*
    section of the Appendix:'
  prefs: []
  type: TYPE_NORMAL
- en: 'True or false: When working with Entity Framework, schema management is  built
    in using migrations-based support.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True or false: When working with a migrations-based approach for schema management,
    you do not need extra tracking tables in your database schema.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True or false: When working with an end state-based approach for schema management,
    you do not need extra tracking tables in your database schema.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'What are the benefits of a full side-by-side approach to database schema changes?
    (Choose multiple answers):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The risks are reduced to almost zero.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You can measure the actual performance impact of changes in a production-like
    environment.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Side-by-side migrations reduce cycle time.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True or false: Schema-less databases remove the need for thinking about schema
    changes completely.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a possible technology choice that you can make to limit the impact of
    changes on your database schema?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: More information about Entity Framework and Entity Framework Migrations can
    be found at [https://docs.microsoft.com/nl-nl/ef/](https://docs.microsoft.com/nl-nl/ef/)
    and [https://docs.microsoft.com/en-us/ef/ef6/modeling/code-first/migrations/](https://docs.microsoft.com/en-us/ef/ef6/modeling/code-first/migrations/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More information about Redgate and its database tooling can be found at [https://www.red-gate.com/](https://www.red-gate.com/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More information on SQL Server Data Tools can be found at [https://docs.microsoft.com/en-us/sql/ssdt/sql-server-data-tools?view=sql-server-2017](https://docs.microsoft.com/en-us/sql/ssdt/sql-server-data-tools?view=sql-server-2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Azure Pipelines extension for deploying Entity Framework Core migrations
    from a DLL can be found at [https://marketplace.visualstudio.com/items?itemName=bendayconsulting.build-task](https://marketplace.visualstudio.com/items?itemName=bendayconsulting.build-task).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
