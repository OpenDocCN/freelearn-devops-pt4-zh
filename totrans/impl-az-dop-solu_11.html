<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Security and Compliance</h1>
                </header>
            
            <article>
                
<p>As important as it is to ensure that your application performs the functions it needs to, you also need to ensure it doesn't do things that it shouldn't. In the previous chapter, you learned about quality and testing in order to continuously measure whether your application is doing what it is supposed to do. In this chapter, you will learn how to prevent any unwanted behavior. This is the subject of security and compliance. While increasing the flow of value to your end users<span>—</span>by deploying faster and shortening delivery cycles<span>—</span>you will still want to make sure that you are delivering secure and compliant software. In this chapter, you will learn how to address these concerns in your DevOps processes.</p>
<p>To do this, this chapter will start by discussing the perceived trade-off between speed and security, and it will explain how security is not decreased but might even be increased when embracing DevOps. Next, a specific dimension of security is addressed: how to handle secrets such as keys and passwords that your pipeline and application need securely. Following this, code scanning tools for automatically identifying possible security risks in your application code and in your dependencies are discussed. The chapter concludes by discussing how to keep your infrastructure and configuration deployments compliant, and how to detect runtime security risks and threats using Azure Policy and Security Center.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Applying DevOps principles to security and compliance</li>
<li>Working with secrets</li>
<li>Detecting application code vulnerabilities</li>
<li>Working with dependencies</li>
<li>Ensuring infrastructure compliance</li>
<li>Monitoring and detecting runtime security risks and threats</li>
<li>Other tools you can use</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>To experiment with the techniques described in this chapter, you will need one or more of the following:</p>
<ul>
<li>An Azure DevOps project with access to build and release pipelines and the right to install extensions</li>
<li>An Azure subscription. (To sign up for Azure, you can go to <a href="https://portal.azure.com">https://portal.azure.com</a> and follow the guide there if you do not have an account yet)</li>
<li>PowerShell with the PowerShell Azure module installed. (Instructions on how to install the PowerShell Azure module can be found at <a href="https://docs.microsoft.com/en-us/powershell/azure/install-az-ps?view=azps-4.1.0">https://docs.microsoft.com/en-us/powershell/azure/install-az-ps?view=azps-4.1.0</a>)</li>
<li>Optionally, subscriptions for WhiteSource Bolt, SonarCloud, or similar products</li>
</ul>
<p>The preceding are all available, for free or as a trial, for learning or evaluation purposes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applying DevOps principles to security and compliance</h1>
                </header>
            
            <article>
                
<p>Concerns about security and compliance can be a reason for companies to be reluctant to accept a full DevOps mindset, in order to ship software often and quickly. In the past, they used to have fewer releases that were all handed off for a security or pen test before being deployed to production. This gave them the confidence that they were not shipping software that contained security vulnerabilities.</p>
<p>This practice of fewer releases and having a big final security test before the final release conflicts with a DevOps mindset, and this is where some companies struggle. They are looking for ways to ensure that they are shipping business value to their users but are not willing to compromise on security to do so. The question is whether this is a fair trade-off. Wouldn't it be possible to have both speed and security? Might it not actually be the case that releasing faster and more often, in combination with rigorous automation, can help to increase the level of security in software development? To answer this question, it is good to first explore how security is often practiced in non-DevOps environments and how this needs to be changed when adopting DevOps.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Bringing developers and security engineers together</h1>
                </header>
            
            <article>
                
<p>In many companies, security engineers are part of a different department compared to developers. The thought behind this separation is that it is beneficial to have some distance between those who are writing the code (that is, the developers) and those who are checking it.</p>
<p>In the past, the same separation often existed between software developers and software testers. However, recent insights have shown that putting developers and testers closer together does not result in unwanted behaviors such as group thinking, only testing what is already known to be working, or trying to cheat the tests by developing only for known test cases. Both experience and research show that the opposite is true. Putting developers and testers together results in products of higher quality. It is for this reason that movements such as Agile recommend development teams to incorporate, among other things, the discipline of testing.</p>
<p>It is by this same reasoning that the call for integrating security engineering into DevOps development teams is becoming louder. This movement is often called "DevSecOps" or "rugged DevOps." Both movements advocate that using DevOps principles such as shifting left and automating as much as possible can help to increase security. They advocate that pen tests or vulnerability reviews of applications are no longer done manually, but that they are fully automated as part of the delivery pipeline. This enables automation, faster feedback loops, and continuous delivery and deployment practices.</p>
<p>It is also advocated that shipping software more often can also help to increase security further, for the following reasons:</p>
<ul>
<li>When a reliable mechanism for shipping software automatically is available, any change that addresses a security risk can be deployed within minutes or days. Being able to react quickly to a new finding is a great security improvement.</li>
<li>Speed itself can be a security measure. If the working of a system changes multiple times a day, it is significantly harder to figure out what its inner workings are at any given time and to misuse them.</li>
<li>Applying the principle of immutable deployments and using infrastructure as code ensures that the infrastructure that is running an application is refreshed pretty often. This is a good mitigation of advanced persistent threats<em>.</em></li>
</ul>
<p>One of the things this chapter will explore is how to configure delivery pipelines to add security scanning. Please note that running these tools from a pipeline is a different discipline, which ensures that these tools are properly configured and apply the correct policies and requirements. For these activities, a security background and a close collaboration with security engineers are still essential. This is just another area where close collaboration can make a difference. Particularly on the subject of security, collaboration with other disciplines will be necessary; not to introduce manual checks, but to automate them together.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Security concerns</h1>
                </header>
            
            <article>
                
<p>The rest of this chapter will introduce a number of security concerns, but it is helpful to realize that some of the previous chapters have also introduced security concerns already. As you already know from software development, security is not just something that you add in one place. Security should be applied everywhere. The following diagram shows different activities surrounding the creation and delivery of software. Next to each activity, the applicable security concerns are shown:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-951 image-border" src="assets/53bc936d-33ad-485a-9d82-684d8268b6d2.png" style="width:35.50em;height:11.67em;"/></p>
<p>Let's walk through a quick recap of the security concerns at each of these stages:</p>
<ul>
<li><strong>Branch-master merge</strong>: At this stage, the four-eyes principle is applied using pull requests. Pull requests allow another engineer to review the changes before they are merged into the master branch. Branch policies are used to make the use of pull requests mandatory, to ensure that the code compiles and that the unit tests run. This was discussed in <a href="2be30fb3-5e71-4180-9830-f119e5a6cd76.xhtml">Chapter 2</a>, <em>Everything Starts with Source Control</em>, and <a href="7dcfa6ee-1460-4c49-a156-58073b263c90.xhtml">Chapter 3</a>, <em>Moving to Continuous Integration</em>.<em><br/></em></li>
<li><strong>Build</strong>: <span>During this stage, a security scan of all source code and third-party dependencies is executed by adding additional tasks to the build pipeline. This prevents security risks from propagating unchecked. We discuss how to do this in this chapter, in the <em>Working with secrets</em> section.</span></li>
</ul>
<ul>
<li><span><strong>Release</strong></span>: During the release, a<span>pprovers can be configured. An approver is a user who has to give their approval before the deployment to a specific stage can continue. Additionally, automated release gates are used to</span> ensure (and further enforce) that certain <span>criteria are met before a release can continue. We discuss how to do this in</span> <a href="8ab4597a-becd-4855-9b45-89045982c14a.xhtml">Chapter 4</a>, <span><em>Continuous Deployment.</em></span></li>
<li><strong>Deployment environment </strong>(<strong>target systems</strong>): All applications will run on a target environment. This can be on-premises; however, in this book, the focus is on Azure. For runtime security and compliance concerns, this chapter will introduce Azure Policy and Azure Security Center.</li>
<li><strong>Cross-cutting</strong>: All of the preceding points are only useful if there is sufficient access control within the Azure DevOps environment. While this is not in the scope of this book, it is an important angle to cover. Users should have enough rights to do their work, but they should not be able to make unauthorized changes to policies, builds, and deployment processes. Additionally, proper secret management is needed to keep secrets such as certificates, keys, and passwords secure during all phases of the delivery process. How we can do this is also covered in this chapter.</li>
</ul>
<p>Now, with an understanding of how software and security engineers can come together to work on an application, it is time to address the different aspects of this work in the following sections. The next section will discuss how to handle secrets.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Working with secrets</h1>
                </header>
            
            <article>
                
<p>An important security element is the handling of secrets. When deploying an application, there are always secrets involved. Especially when deploying to the cloud, that is, over the internet, handling these access keys in a secure way is very important. Besides the secrets that are necessary for deployment, there are also secrets that need to be inserted into the runtime configuration of an application. A common example is for accessing the database.</p>
<p>In <a href="d981a2b6-8bf4-4fb7-8a2e-ceff84691588.xhtml">Chapter 6</a>, <em>Infrastructure and Configuration as Code</em>, multiple mechanisms for delivering application configurations were discussed, including <span><strong>Azure Resource Manager</strong> (</span><strong>ARM</strong>) templates. However, templates require the input of external secrets, since they cannot be stored in parameter files in source control.</p>
<div class="packt_infobox">Secrets should not be stored in source control.</div>
<p>If secrets cannot be stored in source control, then where should they be stored instead? Common options include storing secrets in service connections or in variable groups.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Storing secrets in service connections</h1>
                </header>
            
            <article>
                
<p>The first group of secrets that are needed for the deployment of any application is those secrets that are required for connecting to the target system. No individual person should have access to these secrets as they are only used during deployments. This is why Azure Pipelines allows you to store them securely in service connections.</p>
<p>A service connection is the abstraction of another system that can be connected to from Azure DevOps. Service connections have a specific type, that is, to specify the family of systems they can be used to connect to. There are out of the service connection types for connecting to Azure, GitHub, Jira, NPM, NuGet, and over a dozen more systems. New service connection types can also be added through the Azure DevOps extension mechanism.</p>
<p>Service connections can contain a reference to the location of another system<span>—</span>often, a URL. Next to the location, they can contain an authorization token, a username, and/or a password, depending on the type of service connection. Secrets that are stored inside a service connection can never be retrieved again, not even by administrators. Also, whenever any details of the service connection are changed, the secret must be re-entered as well. This is to prevent a previously entered secret from being misused to access another location. These details indicate how service connections are designed to provide a secure location for storing connection credentials.</p>
<p>Service connections can be managed in a central location for each Azure DevOps project. You can create new connections, edit existing ones, alter user permissions, and much more. Practice this by following these steps:</p>
<ol>
<li>To open this view, navigate to <span class="packt_screen">Project Settings</span>. A vertical list of various setting options will open.</li>
<li>From the list, click on <span class="packt_screen">Service connections</span>. You will be able to view the various connections, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1070 image-border" src="assets/9bcde9c0-1f2a-4bcf-a868-3b5df785685a.png" style="width:36.75em;height:24.67em;"/></p>
<ol start="3">
<li>Now, click on the <span class="packt_screen">New service connection</span> button in the top-right of the screen if you wish to create new service connections.</li>
<li>To modify an existing entry, simply click on it. This will take you to a screen that is similar to the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1071 image-border" src="assets/f0a3719a-b771-4afd-b453-648effe9d6f4.png" style="width:39.75em;height:21.08em;"/></p>
<p>From this view, you can now carry out these actions:</p>
<ol>
<li>Edit the service connection details.</li>
<li>Alter user permissions.</li>
<li>Restrict permissions.</li>
<li>Add more users or groups, and specify, for each, whether they can use or administer the endpoint.</li>
<li>Specify which pipelines can use this service connection.</li>
</ol>
<p>In the current view, every pipeline in the project can use the service connection. This is not recommended and can be secured using the <span class="packt_screen">Restrict permissions</span> button (<em>3</em>). After securing the pipeline, each pipeline that wants to use the service connection must be authorized by a service connection administrator first.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Storing secrets in variable groups</h1>
                </header>
            
            <article>
                
<p>There are more secrets involved in application development than those that are required to connect to other systems. Examples include license keys, which are required during application compilation, or database usernames and passwords, which need to be passed on to the application after deployment or as part of an ARM template deployment.</p>
<p>These secrets can be stored in pipeline variables or variable groups, which we covered in <a href="7dcfa6ee-1460-4c49-a156-58073b263c90.xhtml">Chapter 3</a>, in the <em>Creating a build definition in Azure DevOps</em> section. Microsoft will store all variables that are marked as secrets securely and make them non-retrievable through the user interface.</p>
<p>However, there might be reasons for not wanting to store secrets in Azure DevOps but in a specialized key store such as Azure Key Vault instead. Doing so will provide the extra guarantees that come with Key Vault and the ability to further control access policies using <strong>Azure</strong> <strong>role-based access control</strong> (<strong>Azure </strong><strong>RBAC</strong>) and Key Vault access policies.</p>
<p>When storing secrets in an Azure key vault, they can still be used as a variable group as well, by connecting an empty variable group to the key vault through a service connection, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1073 image-border" src="assets/0c867831-d8e7-4f80-9ad1-bbebbf60e887.png" style="width:43.42em;height:34.42em;"/></p>
<p>To use a key vault as the storage for a variable group, perform the following actions:</p>
<ol>
<li>Enable the second slider to load the secrets from the key vault.</li>
<li>Select an already existing ARM service connection from the drop-down menu, or create a service connection with a new managed identity for Azure on the fly by selecting an Azure subscription from the list.</li>
<li>Type in the name of the key vault that the secrets should be loaded into. You can also select one from the drop-down menu. In that case, only key vaults that are accessible by the selected service connection are shown.</li>
<li>It is recommended that you disable the slider that allows access to all pipelines. In general, open authorizations are considered a risk, but, in particular, variable groups that hold secrets should only be available to explicitly authorized users.</li>
<li>Access for specific users can be configured using the <span class="packt_screen">Security</span> tab.</li>
</ol>
<p>The proper authorizations for the service connection to Azure and the key vault can also be automatically created. Please note that both operations will make changes to the Azure security setup, so ensure that these are (still) correct.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Detecting unsecured secrets</h1>
                </header>
            
            <article>
                
<p>As mentioned previously, secrets should not be stored in source control, which is why the capabilities discussed earlier are available. Still, a developer can, by accident or for local testing, write down secrets in the application source code.</p>
<p>To ensure that these secrets do not end up in source control, a local plugin can be used to detect secrets and emit a warning to alert the developer to this risk. One tool that can do this for Visual Studio is the <strong>Continuous Delivery Tools for Visual Studio</strong> extension. This extension scans any open file for secrets and emits a compiler warning when it detects a possible secret. A link to this extension is added to the references at the end of this chapter. After running the installer, any secret it detects in Visual Studio will result in a compiler warning. Unfortunately, at the time of writing, the extension does not yet support Visual Studio 2019.</p>
<p>In addition to this, it is advised that you run a similar tool as part of the delivery pipelines to identify any secrets that have accidentally been checked in. Even though it will be too late to keep the secret secure, it does provide a clear signal that the secret is compromised and needs to be changed. One tool that can do this is <strong>CredScan</strong>. CredScan is a build task that is part of the <strong>Microsoft Security Code Analysis Extension</strong> build task.</p>
<div class="packt_tip">The Microsoft Security Code Analysis Extension comes with more capabilities than just CredScan. It also includes other security tools offered by Microsoft.</div>
<p>A link to the details of this extension is available at the end of this chapter; it also includes all of the installation details. Please note that the extension is only available under certain conditions and is not free.</p>
<p>Once the extension has been installed, CredScan can be added to your pipeline, as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1074 image-border" src="assets/2d4bc1d8-351f-4bbd-83e5-e088d8eb42c2.png" style="width:48.08em;height:32.00em;"/></p>
<p class="CDPAlignLeft CDPAlign"><span>Perform these steps while referring to the annotations in the screenshot:</span></p>
<ol>
<li>Add the <em><span class="packt_screen">R</span></em><span class="packt_screen">un Credential Scanner</span> task to the pipeline.</li>
<li>Update the <span class="packt_screen">Tool Major Version</span> to V2. For all of the other options, the default settings are good enough for a first scan.</li>
<li>If there have been previous scans that result in one or more false positives, they can be removed from the results by pointing to a suppressions file.</li>
<li>Add the <span class="packt_screen">Create Security Analysis Repor</span><em><span class="packt_screen">t</span></em> task to the pipeline.</li>
<li>Add the <span class="packt_screen">Publish Security Analysis Logs</span> task to the pipeline.</li>
<li>Add the <span class="packt_screen">Post Analysis</span> task to the pipeline.</li>
<li>Save and queue the build definition.</li>
</ol>
<p>While some tasks fail and cancel the build when an error is detected, the CredScan task does not. It will always complete successfully, even if passwords are detected. Only the <em><span class="packt_screen">Post Analysis</span></em> task at the end of the build will act on discovered problems and fail the build if there are any issues found. The advantage of this is that all issues are identified, not only the first one. It also allows any other tasks you want to run to be completed.</p>
<p>The security analysis reporting task (<em>step 4</em>) is used to gather the logs of the different scanning tools that are part of the suite and combine the output into CSV and HTML files. The publishing task (<em>step 5</em>) publishes all of the generated files as a build artifact. If a possible password is detected, the following HTML will be generated and published as a build artifact:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/8b12d7d2-a489-41af-ab81-fc5697587528.png"/></p>
<p>This concludes our discussion of secrets and how to keep them secure in a DevOps pipeline. The next section covers the detection of application vulnerabilities.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Detecting application code vulnerabilities</h1>
                </header>
            
            <article>
                
<p>The secur<span>ity assessments that are often conducted at regular intervals in the pre-DevOps era cannot be just left out when moving to a DevOps culture. This means that, instead of leaving them out, they must be conducted in some other way. There are two approaches for doing this.</span></p>
<p>The first approach is to keep doing pen tests, security reviews, and other security inspections at regular intervals just as before. However, instead of waiting for an OK from the tests before moving to production, the code is deployed to production separate from the security assessment(s). This implies that there is an accepted risk that there might be vulnerabilities shipped to production that are found only during the next security scan and will be addressed in the next release. Using this approach, it is possible to achieve speed, but then it also needs to be accepted that some vulnerabilities might exist for a while.</p>
<p>The second approach relies on making application security scanning part of the regular workflow for committing code to the source code repository. For example, security code reviews do not have to be done per increment or every two months. They can also be done per pull request<span>—</span>before the code gets merged. Now, all of a sudden, you are no longer detecting vulnerabilities but are instead preventing them. The same can be done with security vulnerability scans. They can become part of the delivery pipeline, or a full nightly QA build that reports back on the quality of development every morning.</p>
<p class="mce-root"/>
<p>Of course, it is often not as black and white, and many companies use a combination of these approaches. They use automated feedback mechanisms to detect whatever they can, make security code reviews part of the pull request workflow, and then combine this with manual pen testing at regular intervals. In this way, the speed of delivery is increased, while there is no increase or even a decrease in security risks, the last being the consequence of the speed at which vulnerabilities can be mitigated.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">OWASP Top 10</h1>
                </header>
            
            <article>
                
<p>When it comes to the security of web applications, there are several types of security issues that are both common and responsible for the vast majority of all security issues. These types of issues are known as the OWASP Top 10. This is a list of the 10 most common types of security issues, published by the <strong>Open Web Application Security Platform</strong> (<strong>OWASP</strong>). The list is reviewed every few years but has remained quite stable over the last couple of years.</p>
<p>Most of the errors in the OWASP Top 10 can be prevented by implementing automated security tests; either by using static code analysis for security vulnerabilities or with dynamic testing using the <strong>OWASP Zed Attack Proxy</strong> <span>(</span><span><strong>OWASP</strong> </span><strong>ZAP</strong><span>)</span>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing automated vulnerability scanning</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, in which continuous testing was discussed, SonarCloud was already introduced as a code scanner for technical debt and code quality. Besides assessing the quality of application code, SonarCloud can also be used to scan for security vulnerabilities. In <a href="d86e8d08-7a5c-40da-978c-6dd7cb61c140.xhtml">Chapter 8</a>, <em>Continuous Testing</em>, you learned how to add a SonarCloud scan to your pipeline. There are other, more specialized tools available as well, which we will discuss in the last section of this chapter.</p>
<p>These tools assess the application based on static tests. They scan the code to identify any risky code. This is called a white-box approach because they can see, inspect, and scan all of the code. In other words, everything is visible. This is the opposite of a black-box approach, where the running is application is treated as a closed whole and is only tested by invoking it and observing the responses. One tool that can do this is the <span>OWASP </span>ZAP.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">OWASP Zed Attack Proxy</h1>
                </header>
            
            <article>
                
<p>The OWASP ZAP is a tool that can perform the automated pen test of an application. This tool can run in two modes:</p>
<ul>
<li><strong>A baseline scan</strong>: <span>The baseline scan takes only a few minutes, and it is optimized to iterate over as many security risks as possible within those few minutes. This makes the baseline scan quick enough to be run early on in the deployment pipeline. It is even possible to run the security scan after every deployment to the first test environment, resulting in fast feedback to developers.</span></li>
<li><strong>A full active scan</strong>: <span>The full active scan takes more time. In this type of scan, the proxy will examine every response from the application to identify other URLs that are part of the application, scanning them as well. In this way, the full application is discovered on the fly, using a spidering approach. This type of scan is more complete, but it also takes more time. For this reason, full scans are often run at intervals, for example, every night.</span></li>
</ul>
<p>The OWASP ZAP proxy tries to identify any possible security risks. Some of the most notable risks are SQL injections, JavaScript reflections, and path traversals.</p>
<p>The OWASP ZAP is an application that can be installed on any virtual machine. The disadvantage of this is that the virtual machine is always running, even when there is no scan running. This is more costly, and, of course, the virtual machine itself needs to be patched and secured too. More recently, a containerized version of the proxy was also made available. This container can be run in Azure Container Instances, spinning up the proxy only when needed and tearing it down right after execution.</p>
<p>This completes our introduction to code scanning tools and their implementation. With the help of these tools, you can detect vulnerabilities in your application and prevent any security issues. The next section will examine how you can scan application dependencies.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Working with dependencies</h1>
                </header>
            
            <article>
                
<p>Next to the security risks that the application code developed in-house pose, there is also a risk associated with components that are reused. Between 50% and 80% of modern application code is not developed in-house, but is taken from other parties in the form of packages or dependencies. Some of these might be open source, but this is not necessarily the case. There can also be components that are bought from other development companies or binaries taken from galleries such as NuGet.</p>
<p>Dependencies not only pose security risks, but also licensing risks. What happens if a team starts using a component that is published under the GPL license for a closed source component? If anyone ever finds out, they can be forced to open source their product, or at least suffer public shame for not using the work of others according to the license.</p>
<p>To mitigate these risks, a number of tools can be used to detect and scan all of the dependencies that are used when building an application. One of the tools available to do this is WhiteSource Bolt, which is available as an extension from the Azure DevOps marketplace.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Working with WhiteSource Bolt</h1>
                </header>
            
            <article>
                
<p>To start executing scans with WhiteSource Bolt, perform the following actions:</p>
<ol>
<li>Install the WhiteSource Bolt extension from the Azure DevOps marketplace.</li>
<li>Navigate to the <span class="packt_screen">WhiteSource Bolt</span> menu under <span class="packt_screen">Pipelines</span>.</li>
<li>Sign up and accept the license terms.</li>
<li>Add the <span class="packt_screen">WhiteSource Bolt</span> scanning task to build or release definitions, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1075 image-border" src="assets/1b58e509-8bac-44d0-b335-0112b65dc334.png" style="width:60.58em;height:28.00em;"/></p>
<ol start="5">
<li>Once a pipeline with the WhiteSource Bolt task installed has run, the page with the build results will contain an extra tab called <span class="packt_screen">WhiteSource Bolt Build Report</span> that shows the results, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1225 image-border" src="assets/b2988506-f292-417e-8e0f-846debbe08d8.png" style="width:152.58em;height:89.00em;"/></p>
<p>This report provides a number of insights about the overall security and licensing risks of the scanned application build:</p>
<ul>
<li>The top row, with four widgets, provides an overview of the vulnerability score and three different breakdowns into how that score was calculated.</li>
<li>Below this, all of the vulnerable packages are listed by name, with a reference to the dependency and a recommended mitigation.</li>
<li>The  section at the bottom provides a list of all licenses used by the dependencies. This list is sorted from high risk to low risk.</li>
<li>Below this overview, WhiteSource Bolt also generates a list of dependencies for which a newer version is available (this is not visible in the preceding screenshot).</li>
</ul>
<p>The results shown in this report can also be accessed from the <span class="packt_screen">WhiteSource Bolt</span> menu, under the <span class="packt_screen">Pipelines</span> menu. In this view, all of the reports for all of the builds can be accessed. This view is great for those who are responsible for accessing security or licensing standards across a project or organization.</p>
<p>This completes our discussion on dependency scanning. As mentioned earlier, you can use these <span>tools to your advantage to detect and scan all the dependencies that are used when building an application. </span>In the next section, infrastructure compliance is introduced.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ensuring infrastructure compliance</h1>
                </header>
            
            <article>
                
<p>Another important topic is that of compliance. In many countries or markets, there are sets of rules and policies that must be implemented or adhered to when creating software. A fair share of these policies relates to the infrastructure that the applications are running on. If this infrastructure is deployed and managed on the Azure platform, Azure Policy can be a powerful tool for ensuring that the infrastructure complies with regulations.</p>
<p>In <a href="d981a2b6-8bf4-4fb7-8a2e-ceff84691588.xhtml">Chapter 6</a>, <em>Infrastructure and Configuration as Code</em>, the topic of ARM templates was discussed. ARM templates can be viewed as a technique for describing a complete Azure environment as a JSON array with many objects, each describing one resource in an application's infrastructure.</p>
<p>Azure Policy allows you to write policies that query this document and the changes that are being made through any of the APIs or ARM templates. Whenever a resource is found that matches the query, it is prevented from being created or the match can be added to a list of audit results.</p>
<p>Next to writing custom policies, there are many policies readily available for all Azure users. These policies can be used to audit resources that do not comply with best practices or general advice. There are also groups of policies available, called initiatives, that describe the applicable parts of market standards.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Assigning an Azure Policy or initiative</h1>
                </header>
            
            <article>
                
<p>Policies can be assigned at different levels within Azure, either at the resource group level, subscription level, or management group level. This can be done through the portal, ARM templates or blueprints, or PowerShell.</p>
<p>To use PowerShell, the following series of commands can be used:</p>
<ol>
<li>To retrieve a reference to the resource group and policy, use the following command:</li>
</ol>
<pre style="padding-left: 90px"><strong>$rg = Get-AzResourceGroup -Name myResourceGroupName</strong><br/><strong>$definition = Get-AzPolicyDefinition | Where-Object { $_.Properties.DisplayName -eq 'Audit VMs that do not use managed disks' }</strong></pre>
<p style="padding-left: 60px">The policy that is chosen here is a built-in policy that will audit all virtual machines that do not use managed disks but have custom disks in storage accounts. This policy definition will be used in the command in the following assignment.</p>
<ol start="2">
<li>To assign the policy to the resource group<span>, use the following command</span>:</li>
</ol>
<pre style="padding-left: 90px"><strong>New-AzPolicyAssignment -Name 'audit-vm-manageddisks' -DisplayName 'Audit VMs without managed disks Assignment' -Scope $rg.ResourceId -PolicyDefinition $definition</strong></pre>
<p>Within 30 minutes of this assignment, the new policy will become active. At this point, a policy evaluation cycle is started, and all of the resources within the assignment scope will be evaluated against the policy. At the time of writing, there is no <span>published </span>SLA regarding how long such an evaluation cycle can take. Experience shows that this can be anything between 15 minutes and multiple hours—depending on the size of the assignment scope.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Writing an Azure Policy</h1>
                </header>
            
            <article>
                
<p>While there are many built-in policies available, there are many use cases in which the creation of custom policies is needed. Just like any other Azure resource, a policy is written as a JSON document. The appropriate ARM resource type is called <kbd>policyDefinitions</kbd> and has the following structure:</p>
<pre>{<br/>   "name": "string",<br/>   "type": "Microsoft.Authorization/policyDefinitions",<br/>   "apiVersion": "2019-01-01",<br/>    "properties": {<br/>      "parameters": {<br/>        “location”: { …}<br/>      },<br/>        "displayName": "…",<br/>        "description": "…",<br/>        "policyRule": {<br/>            "if": {<br/>              “field”: “location”,<br/>              “equals”: “[parameters(‘location’)]”,<br/>            },<br/>            "then": {<br/>                "effect": "&lt;audit|deny &gt;"<br/>            }<br/>        }<br/>    }<br/>}</pre>
<p>The <kbd>parameters</kbd> object can be used to specify one or more parameters that need to be specified when assigning the policy later on. These parameters follow the same syntax and work the same as the parameters of an ARM template.</p>
<p>The <kbd>displayName</kbd> and <kbd>description</kbd> properties can be used to give the policy definition a meaningful name and description for later reference.</p>
<p>The body of the definition contains two elements, as follows:</p>
<ul>
<li><strong>The</strong> <kbd>if</kbd> <strong>statement</strong> is used to specify a query that selects the Azure resources that this policy should apply to. There is a specific syntax for writing complex queries in JSON that is detailed in the ARM template reference that is linked at the end of this chapter.</li>
<li><strong>The</strong> <kbd>then</kbd> <strong>statement</strong> is used to describe the action that needs to be taken for any resource that matches the condition. This can be <em>deny,</em> that is, to automatically deny the creation of any non-compliant resource. Another approach is not to deny non-compliant deployments but rather to audit them. While denying non-compliant deployments is very straightforward in theory, there is good cause for temporarily allowing non-compliant deployments. In such cases, an audit policy can help to keep tabs on these resources. All non-compliant deployments get audit records in their Azure Activity log and can be viewed in the Azure portal, under <span class="packt_screen">Azure Policy</span> in the <span class="packt_screen">Compliance</span> tab. This is as follows:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1077 image-border" src="assets/3b4745f2-1655-481e-8fcb-d4f7faf0e76c.png" style="width:194.58em;height:51.00em;"/></p>
<p class="mce-root"/>
<p>After writing the policy definition, we need to create it within an Azure subscription for it to be usable. This can either be done through an ARM template or manually within the portal. From a DevOps perspective, writing policies in source control and delivering them through a pipeline as part of an ARM template is the recommended approach. In this way, Azure policies are written in the same way as the application and can be reviewed and automatically deployed to Azure as part of a DevOps pipeline.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Initiatives</h1>
                </header>
            
            <article>
                
<p>When working with Azure Policy, many companies find that they need to create many policies to define all the rules that they want their software developers to adhere to. For this reason, it might be beneficial to group policies. Such a grouping is called an "initiative" and these are defined in JSON as well:</p>
<pre>{<br/>  "name": "string",<br/>  "type": "Microsoft.Authorization/policySetDefinitions",<br/>  "apiVersion": "2019-01-01",<br/>  "properties": {<br/>    "displayName": "string",<br/>    "description": "string",<br/>    "parameters": { … },<br/>    "policyDefinitions": [<br/>      {<br/>        "policyDefinitionId": "string",<br/>        "parameters": {}<br/>      }<br/>    ]<br/>  }<br/>}</pre>
<p>The body of an initiative is an array of objects. Each object must contain a <kbd>policyDefinitionId</kbd> property and, optionally, an object with <kbd>parameters</kbd> for the policy. The <kbd>policyDefinitionId</kbd> property must reference a valid <kbd>policyDefintions</kbd> through its Azure resource ID. The <kbd>parameters</kbd> array should specify all of the parameters that the policy requires. Often, this is implemented by having the initiative specify the combined set of all parameters of all policies as an initiative parameter. The parameters for the individual policies are then specified with a reference to the initiative parameters.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fetching audit results</h1>
                </header>
            
            <article>
                
<p>After assigning a policy with the audit effect, the policy will automatically evaluate all of the resources within the scope of the assignment once it is active. There is no guarantee of how long this can take. For new resources, the results of policy evaluation are visible within 15 minutes, but, often, this is faster. </p>
<p>Once the results are in, the compliance status for each policy or initiative can be viewed in the portal, resulting in an overview, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1078 image-border" src="assets/8fe2da7d-64e7-42a8-bc52-f6ff76e8a880.png" style="width:58.67em;height:29.92em;"/></p>
<p>The difference between this report and other reports, which are the result of a manual audit, is that this overview is constantly updated to reflect the actual, current state of compliance—it is not a snapshot of compliance at a specific point in time.</p>
<p>An important benefit of this type of compliance is that the rules or policies are applied continuously to all the existing resources and any incoming change. This means that it is possible to ensure that the application environment is always compliant and always adheres to any rules and policies that apply.</p>
<p>Contrast this with the often-used approach of having security and compliance audits only every so many months. Often, this results in environments that are only compliant just before the audit and with its compliancy slowly decaying afterward. That is, until it is time for another audit, of course, at which point it rises close to 100% again. At many companies, this results in a compliance graph as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-534 image-border" src="assets/73896784-11f4-4e25-84f2-6cba850381ea.png" style="width:29.33em;height:22.33em;"/></p>
<p>With this, we've discussed another example of how DevOps practices can help increase security and compliance—by ensuring infrastructure compliance. In the next section, several alternative tools for those mentioned in this chapter will be discussed.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring and detecting runtime security risks and threats</h1>
                </header>
            
            <article>
                
<p>All of the security tools that have been discussed up to this point have focused on preventing shipping vulnerable code to production environments. However, the complete, deployed software solution, including all its support infrastructure is made out of so much more than just the code. On top of that, there are many interactions with a solution that may be unexpected or unplanned. Monitoring all of this continuously in production is necessary, not just to prevent security concerns but to also detect any security concerns coming up. In Azure, one of the tools available for doing just that is Azure Security Center. Azure Security Center is offered via the Azure portal and can be selected as any other service using the menu on the left or by searching for it in the top bar.</p>
<p>After opening Security Center, something similar to the following screenshot will open:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1079 image-border" src="assets/3e3f0a00-e201-42f8-8636-ba95b0082c09.png" style="width:111.67em;height:62.50em;"/></p>
<p>This dashboard delivers insight into three main categories:</p>
<ul>
<li><span class="packt_screen">Policy and compliance</span>: This part gives an overview of how compliant all of the selected Azure subscriptions are with regard to the security policies you have configured.</li>
<li><span class="packt_screen">Resource security hygiene</span>: Azure has many security controls that can be turned on or off, along with many security configuration settings. Just as anywhere else, it is up to the user to balance cost and security with risk and ease of use. This dashboard will show recommendations for turning the security up for your resources. Users can decide for each recommendation whether they want to follow it.</li>
</ul>
<ul>
<li><span class="packt_screen">Threat protection</span>: This section shows how many threats or attacks have been automatically detected and reported:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1080 image-border" src="assets/ac28bd46-d684-4cb4-9a4f-0207bee64198.png" style="width:106.75em;height:60.25em;"/></p>
<p>All of these overviews and categories can be drilled down further. The preceding example shows the results of opening the <span class="packt_screen">THREAT PROTECTION</span> overview. Here, it lists all of the possible security threats it has identified. In this case, it lists different access attempts to virtual machines that are hosted within the subscription.</p>
<p>There are many more capabilities within Azure Security Center and more are being added on an ongoing basis. When deploying in Azure, this is the place to identify and manage security risks.</p>
<p>This concludes our discussion of the various techniques for monitoring runtime environments for security risks. The next section looks at several alternative tools for performing some of the scanning tasks that were mentioned in earlier sections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Other tools you can use</h1>
                </header>
            
            <article>
                
<p>There are many tools available on the market for performing security scans of application code and dependencies. Some examples include WhiteSource, Black Duck, Veracode, and Checkmarx.</p>
<p><strong>WhiteSource</strong> is the paid version of WhiteSource Bolt. It offers the same services and more. For example, it doesn't only report risks at the time of the dependency scan; it also gives you alerts when new risks become available for dependencies that were present in the last scan of an application.</p>
<p><strong>Black Duck</strong> is a product that helps teams to manage the risks associated with using open source software. The services it offers are comparable to WhiteSource.</p>
<p><strong>Veracode</strong> and <strong>Checkmarx</strong> are code scanning tools that are used to identify vulnerable code. Whereas SonarQube checks both the code quality and security risks, these two products focus solely on security risks. In general, they are better at security scanning, with the downside being that they are more expensive.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, you have learned that DevOps and security are not two conflicting goals, but that DevOps practices can help you to reinforce security. First, you learned how to handle passwords and other secrets when working with continuous deployment pipelines. Next, you learned how to enhance your pipelines with code and dependency scanning tools, applying the shift-left principle to security as well. Finally, you learned how to use Azure Policy to define constraints and rules for your infrastructure and how you can have these automatically applied or have non-compliant deployments audited or automatically denied.</p>
<p>With the knowledge you have gained, you are now able to have a conversation within your company about how to address security concerns within your DevOps teams. You can cooperate with security engineers to configure the tools you work with and receive automated feedback on the security implications of your work.</p>
<p>In the next chapter, you will learn about application monitoring. Additionally, you will learn how to monitor whether your application is running smoothly and how to gather runtime metrics.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<p>Here is a list of questions for you to test your knowledge regarding this chapter's material. You will find the answers in the <em>Assessments</em> section of the <em>Appendix</em>:</p>
<ol>
<li>True or False: Securing the delivery of software is just a single step in a deployment pipeline.</li>
<li>Which tool can be used for security testing, where a proxy is used to identify valid application URLs and then perform different attacks, such as injections on an application?</li>
<li>True or False: In most modern applications, over 50% of the code base comes from open source libraries.</li>
<li>What are the secure locations for storing the secrets needed during deployment or for running an application? (You can choose more than one answer.)
<ol>
<li>Azure Pipelines variables that are marked as secret</li>
<li>Azure Key Vault</li>
<li>Azure DevOps Key Vault</li>
<li>Azure Variable Groups</li>
<li>Azure DevOps Secure Variables</li>
<li>Azure DevOps Service Connection</li>
</ol>
</li>
<li>Which two Azure offerings can be used to detect security risks at runtime?</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<ul>
<li>The OWASP Top 10 and the details of every type of risk can be found at <a href="https://www.owasp.org/index.php/Top_10-2017_Top_10">https://www.owasp.org/index.php/Top_10-2017_Top_10</a>.</li>
<li>WhiteSource Bolt can be found on the Azure DevOps marketplace at <a href="https://marketplace.visualstudio.com/items?itemName=whitesource.ws-bolt">https://marketplace.visualstudio.com/items?itemName=whitesource.ws-bolt</a>.</li>
<li>A detailed walk-through on using the OWASP ZAP can be found at <a href="https://devblogs.microsoft.com/premier-developer/azure-devops-pipelines-leveraging-owasp-zap-in-the-release-pipeline/">https://devblogs.microsoft.com/premier-developer/azure-devops-pipelines-leveraging-owasp-zap-in-the-release-pipeline/</a>.</li>
</ul>
<ul>
<li>More information about the Azure Policy resource types and JSON specifications can be found as part of the ARM reference at <a href="https://docs.microsoft.com/en-us/azure/templates/microsoft.authorization/allversions">https://docs.microsoft.com/en-us/azure/templates/microsoft.authorization/allversions</a>.</li>
<li>More information about the continuous delivery tools for Visual Studio can be found at <a href="https://marketplace.visualstudio.com/items?itemName=VSIDEDevOpsMSFT.ContinuousDeliveryToolsforVisualStudio">https://marketplace.visualstudio.com/items?itemName=VSIDEDevOpsMSFT.ContinuousDeliveryToolsforVisualStudio</a>.</li>
<li>More information about the Microsoft Security Code Analysis Extension can be found at <a href="https://secdevtools.azurewebsites.net/helpcredscan.html">https://secdevtools.azurewebsites.net/helpcredscan.html</a>.</li>
<li>More information about WhiteSource Bolt and WhiteSource can be found at <a href="https://bolt.whitesourcesoftware.com/">https://bolt.whitesourcesoftware.com/</a> and <a href="https://www.whitesourcesoftware.com/">https://www.whitesourcesoftware.com/</a>.</li>
<li>More information about Black Duck can be found at <a href="https://www.blackducksoftware.com/">https://www.blackducksoftware.com/</a>.</li>
<li>More information about Veracode can be found at <a href="https://www.veracode.com/">https://www.veracode.com/</a>.</li>
<li>More information about Checkmarx can be found at <a href="https://info.checkmarx.com">https://info.checkmarx.com</a>.</li>
</ul>


            </article>

            
        </section>
    </body></html>