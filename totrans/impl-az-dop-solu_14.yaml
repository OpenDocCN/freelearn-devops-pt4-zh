- en: Gathering User Feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you learned how to measure how your applications are
    performing in production. You learned how to gather crash reports and logs and
    how to instrument an application. However, the purpose of software is not just
    to deliver perfectly running applications, but to create business value. Gathering
    user feedback is necessary to determine whether your application is also achieving
    this higher goal. In this chapter, you will learn techniques to measure whether
    your users are satisfied, which features they are using and which they are not,
    and how you can use this information to steer future developments.
  prefs: []
  type: TYPE_NORMAL
- en: To do this, this chapter starts by introducing the concept of continuous feedback.
    Next, it moves on to introduce different approaches to asking users for feedback
    and recording their responses. This can be both in-application or via other channels.
    Besides gathering feedback directly, you can also tap into other, indirect channels.
    Examples are reactions to your software on Twitter and the usage of features in
    your application. Finally, this chapter will introduce hypothesis-driven development,
    an approach to software development practiced by Microsoft.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding continuous feedback
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asking for feedback
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gathering indirect feedback
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing hypothesis-driven development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are no technical requirements for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding continuous feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As explained in [Chapter 1](889f9224-f1b6-414d-bc80-16563f66e1e7.xhtml), *Introduction
    to DevOps*, DevOps is a cultural movement that tries to bring developers and operators
    closer together, to help them to deliver business value faster and more reliable.
    Feedback loops are an important element in doing this. In the previous chapter,
    we saw numerous feedback loops:'
  prefs: []
  type: TYPE_NORMAL
- en: Developers can run unit tests on their local machine to verify that their changes
    did not break existing behaviors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After source code check in, all unit tests are run again and a pipeline with
    more tests starts running.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Besides functional tests, security tests and dependency scans can be run.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After releasing, logs and metrics are gathered to determine whether the application
    is running smoothly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of this provides feedback on the technical quality of the work and now it
    is time to add one more feedback loop—a loop intended to verify whether the application
    actually fulfills the needs of its users.
  prefs: []
  type: TYPE_NORMAL
- en: As obvious as this may sound, it is more often forgotten than most developers
    would care to admit. In many companies, there is faith in product owners or business
    analysts and they are trusted to be able to predict which features users need
    and to sort them in order of priority.
  prefs: []
  type: TYPE_NORMAL
- en: This is while we know that developing software is a complex activity where the
    results of a change often cannot be predicted in advance. In such situations,
    it is important to continuously look for feedback from the user to identify whether
    features are delivering the value they should.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuously looking for feedback will help to make decisions such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Removing features that are not being used by most of the users; this removes
    the need for maintenance on them, therefore reducing cost and freeing up development
    time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Expanding features that are most used by users, making them more prominent in
    the interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increasing or decreasing testing efforts, based on the perceived quality of
    the application by users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Going further along this line of reasoning, we might conclude that it is impossible
    to predict whether a feature will actually deliver enough business value to justify
    its existence or not. Companies that do this often adopt the practice of hypothesis-driven
    development, which will be discussed later.
  prefs: []
  type: TYPE_NORMAL
- en: First, the next section will introduce different approaches for asking application
    users for feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Asking for direct feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One very straightforward way to collect user feedback is by just asking for
    it. Over the last few years, more and more applications have been enriched with
    feedback mechanisms built into the application. Other approaches that are commonly
    used are publishing a public roadmap and engaging with customers directly.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of in-product feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Collecting feedback in-product is a good way to get started with direct user
    feedback. Examples of in-product feedback are grading a specific view or action,
    giving a thumbs up or down, or sending a happy or sad smiley face.
  prefs: []
  type: TYPE_NORMAL
- en: 'Collecting in-product feedback has the following advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: It is one of the easiest ways for customers to give feedback, taking virtually
    none of their time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Due to the non-intrusiveness of this approach, a larger group of users might
    choose to respond.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recorded feedback can be context-aware.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When recording a grade, smiley face, or thumbs up or down for feedback, an application
    can also record the current state and most recent user activities and send all
    of that along with the user feedback. This makes a single click by the user much
    more valuable than it seems at first sight. It allows quick insights into the
    most loved and most hated parts of an application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, allowing in-product feedback makes the user feel heard and listened
    to.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, recording data about users and how they use an application requires
    their consent. It needs to be fully transparent what you intend do with the information
    gathered about users. Also, an opt-in for explicit content is often required as
    well as an option to revoke a previously given consent. The precise requirements
    vary from country to country and are a legal consideration.
  prefs: []
  type: TYPE_NORMAL
- en: 'The disadvantage of this type of feedback is that it can be too much to analyze
    in detail. Also, since the results are often anonymized, it is not possible to
    follow up on feedback. This makes it hard to understand *why* a user was satisfied
    or dissatisfied with a screen. Sometimes this is countered by adding a checkbox
    under the feedback box stating something like: "I give one-time permission to
    be contacted about this subject".'
  prefs: []
  type: TYPE_NORMAL
- en: For understanding the reasons for a user's feedback, other feedback mechanisms
    such as interviews or focus groups might be more appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: Having a public roadmap
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another approach for gathering user feedback is by publicly sharing what is
    currently in the backlog and what isn't. One team that publicly shares which features
    they are working on is the Azure DevOps team. Naturally, this list does not contain
    all features the product group is planning. The reasons for this might be to keep
    a competitive edge or to keep some new feature secret until a big announcement.
    However, their backlog provides a good insight into what is currently brewing.
  prefs: []
  type: TYPE_NORMAL
- en: Adopting this practice allows the users of a product to reach out and comment
    on this public list. It allows them to request features to be moved up or down
    the list of priorities and they can share which features they are missing.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can bring the following advantage to a company: When users engage with
    feedback on the list of features, they are encouraged to specify why they make
    a certain request. This might provide new insights into customer demand and may
    lead to a shift in priorities.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also downsides to this approach:'
  prefs: []
  type: TYPE_NORMAL
- en: Not all users will engage in and provide feedback on a public backlog. This
    might result in a bias toward more vocal or more demanding customers in the group
    that provides feedback. While not necessarily an issue, it is good to keep this
    in mind.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Engaging with users over feature requests or features that they want to be moved
    up or down the list can be very time-consuming. Especially when comparing with
    in-product feedback, this approach takes more time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As well as having a public feature roadmap, there are also other ways to give
    users an insight into what a company is currently working on and what they are
    planning. Some examples include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**UserVoice**: UserVoice is a platform that allows users to propose new features
    and vote on features proposed by others. It allows gathering user ideas, without
    opening the actual backlog to users.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bugtrackers**: If customers are very vocal about reporting bugs and errors
    in an application, it can help to open up a bugtracker. This allows users to see
    which issues are already known and if and when they might be fixed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Public backlogs and UserVoice-like platforms are more common than open backlogs.
    Open lists of bugs or issues are more often seen in open source development.
  prefs: []
  type: TYPE_NORMAL
- en: Using interviews or focus groups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Other forms of requesting user feedback are one-on-one interviews and focus
    groups. While these are even more time-intensive then open backlogs and public
    discussions, they also have the benefit of allowing more balanced user selection.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if an application is clearly targeting four different market segments,
    it can be beneficial to have five focus groups—one for each market segment and
    an additional one with a mix of those. The first four will allow focusing on the
    specific needs of each group, while the fifth will incite a lot of discussion
    and allows getting insight into how different wishes from different groups compare.
  prefs: []
  type: TYPE_NORMAL
- en: Interviews and focus groups are also more suitable for not only getting the
    feedback but for understanding the reasoning of users. Sitting face to face with
    users allows exploring their way of reasoning and how they perceive an application.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes the discussion of direct user feedback. In the next section,
    indirect user feedback is discussed.
  prefs: []
  type: TYPE_NORMAL
- en: Gathering indirect feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A well known saying in software development is that *users do not know what
    they want*. While this may sound harsh, there are a few reasons why direct user
    feedback from discussions, interviews, and focus groups does not necessarily lead
    to good product feedback:'
  prefs: []
  type: TYPE_NORMAL
- en: One reason for this is that everyone wants to be liked. When conducting an interview,
    or talking to a group of users, there is a chance that they will only say what
    they believe the interviewer wants to hear.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has a high turn-around time. Scheduling interviews and focus groups takes
    time and finding a time that everyone can attend can easily take days or even
    weeks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is hard to keep asking the same group of users for feedback every few weeks.
    This is especially important when trying to determine whether the quality of a
    feature is improving with the newest updates or not.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For these reasons, it can be worthwhile to cut back on asking for feedback,
    but instead, measure how users are interacting with an application on a functional
    level and whether they are satisfied with the value they receive from an application.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to do this is by measuring user behavior in an application and emitting
    metrics based on that. In [Chapter 10](bbccbc83-55fc-4fcf-b6a4-1721cdfea791.xhtml),
    *Application Monitoring*, Application Insights was introduced for gathering application-level
    metrics. While metrics are traditionally used for emitting metrics regarding application
    performance, metrics can also be used to emit metrics regarding application usage.
    Some examples are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: How frequently is every page visited?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many times are specific operations performed?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How long it takes to complete a certain view?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many users open a specific form, only to never complete it?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gathering these metrics can deliver important insights into how users are interacting
    with an application and which parts they use or do not use.
  prefs: []
  type: TYPE_NORMAL
- en: Besides usage, another indicator of user satisfaction can be Twitter sentiment
    or the number of support requests.
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Besides gathering metrics in-product, there are also metrics that can be gathered
    outside of the product. One example source of information is Twitter. Using the
    Azure cloud and machine learning algorithms, it is now possible to continuously
    analyze all of the tweets that are directed to a Twitter handle or a hashtag and
    automatically detect sudden changes.
  prefs: []
  type: TYPE_NORMAL
- en: This even goes so far as that there is an Azure Pipelines extension that allows
    continuously measuring Twitter sentiment and canceling the progress of a release
    to the next stage if sentiment turns too negative. This extension is implemented
    as a pipeline gate and is available in the Azure DevOps Marketplace.
  prefs: []
  type: TYPE_NORMAL
- en: Support requests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just like the Twitter sentiment, there might be other indicators of user satisfaction
    that can be gathered automatically. Continuously collecting the number of support
    calls or emails per minute and detecting a certain spike can be a clear indicator
    of a user issue. Using machine learning and system integrations this can be harnessed
    for automated responses or signaling a user to the results.
  prefs: []
  type: TYPE_NORMAL
- en: Adopting practices like this can save minutes or hours detecting production
    issues. Taking user feedback and making decisions based on that sentiment can
    go even further. This is called hypothesis-driven development, which is discussed
    next.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing hypothesis-driven development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A risk in software development is that teams are so busy creating more and more
    features that they forget to reflect upon their business value while everyone
    knows that not every feature is a success. Some features may not be used at all
    or may even be disliked by users. As an industry, we have come to learn that product
    owners have a hard time predicting which features will be really liked by users
    and which will not. Even when using all of the feedback mechanisms discussed previously,
    predicting what users want is difficult.
  prefs: []
  type: TYPE_NORMAL
- en: Another important thing to recognize is that every feature in the product also
    brings a future cost. Every feature requires documentation, support, and maintenance.
    This means that unnecessary features are driving costs up as well. From this stance,
    it makes sense to not only leave non-value features but to even remove them from
    the product as soon as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis-driven development is a practice that starts with acknowledging that
    it is impossible to predict whether a feature will add value, add no value, or,
    even worse, decrease business value. Next, it recommends transforming features
    in the backlog into quick, lightweight experiments that are run in the product
    to determine whether a new feature adds value or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Such an experiment can be written in a similar shape as a user story, for example,
    like this: *We believe that users want a new one-field popup to quickly create
    an appointment, instead of the full dialog. We are convinced that this is the
    case when we see that over 25% of appointments are created using this new dialog
    and that the average approval rate of appointments goes up by 2 points or more.*
    The first part is called the hypothesis, and the second is the threshold for confirmation
    of that hypothesis.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once this is written down, a minimal implementation of such a one-field popup
    is created and its usage and the usage of the original form are monitored using
    metrics. Depending on the measurements, one of the following can occur:'
  prefs: []
  type: TYPE_NORMAL
- en: The belief stated in the hypothesis is confirmed to be true and the new feature
    adds value. More stories surrounding this feature can be added to the backlog
    to increase the business value the product brings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The belief stated in the hypothesis is not confirmed and further experimentation
    is not expected to yield different results. The feature is dropped from the backlog
    and the current, minimal implementation might even be removed from the product.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The belief stated in the hypothesis is not confirmed but experimentation continues.
    This can happen when there are numerous user complaints about a certain feature
    that the team is set on fixing. If one approach does not work, they might try
    another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the approach outlined before, teams can increase the impact they make
    on business value by minimizing the time they spend on features that, after experimentation,
    do not add value and even remove them from the product again.
  prefs: []
  type: TYPE_NORMAL
- en: Often, hypothesis-driven development is combined with phased roll-out mechanisms
    such as feature flags or deployment rings. The experiment is then run on only
    a small percentage of the users, which makes it easier to pull the feature if
    it does not add enough value.
  prefs: []
  type: TYPE_NORMAL
- en: This completes the discussion of the means for gathering and using user feedback
    on applications and how user feedback ties into the DevOps goal of delivering
    business value to end users.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to measure the business outcomes of software
    development activities. First, you learned about the importance of feedback and
    how this helps to understand customer needs and whether those needs are actually
    being met. Then, numerous approaches to asking for feedback were introduced, both
    direct and indirect. Finally, you learned about hypothesis-driven development
    and how a mindset of experimentation can help to cut down waste.
  prefs: []
  type: TYPE_NORMAL
- en: With this knowledge, you can now choose and implement feedback mechanisms that
    allow you to learn what the user sentiment regarding your application is. You
    are now able to implement an experiment-based approach to creating software, focusing
    on value-adding features and ignoring or even removing features that do not add
    value.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn all about containers. Containers are rapidly
    changing the way software is delivered and are often used for applying DevOps
    principles to both existing and new applications.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we conclude, here is a list of questions for you to test your knowledge
    regarding this chapter''s material. You will find the answers in the *Assessments*
    section of the Appendix:'
  prefs: []
  type: TYPE_NORMAL
- en: 'True or false: There are no downsides to publicly sharing a roadmap.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is an important concern to keep in mind when evaluating user feedback on
    a public roadmap?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are two indirect indicators of user satisfaction that are relatively easy
    to capture?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is not part of a hypothesis, as used in hypothesis-driven
    development?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A hypothesis
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A confirmation threshold
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A conclusion
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What are two benefits of interviews or focus groups over other means of gathering
    feedback?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The list of features planned for Azure DevOps can be found at [https://docs.microsoft.com/en-us/azure/devops/release-notes/features-timeline](https://docs.microsoft.com/en-us/azure/devops/release-notes/features-timeline).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Twitter Sentiment extension can be found on the Azure DevOps Marketplace
    at [https://marketplace.visualstudio.com/items?itemName=ms-devlabs.vss-services-twittersentimentanalysis](https://marketplace.visualstudio.com/items?itemName=ms-devlabs.vss-services-twittersentimentanalysis).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
