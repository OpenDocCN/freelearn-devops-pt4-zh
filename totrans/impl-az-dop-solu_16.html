<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Containers</h1>
                </header>
            
            <article>
                
<p>Over the last couple of years, containers have become a hot topic. They allow you to package any application, any tool, written in any language, and deploy it on a basic host or cluster. When implementing DevOps, containers can be of tremendous value. That is why DevOps and containers are often mentioned in the same breath. However, they are not the same thing. While DevOps is more of a cultural thing, containers are a type of technology, an alternative way of hosting your applications.</p>
<p>In this chapter, you will learn more about containers and how they work. This is achieved by exercises wherein custom container images are created and run on different hosting platforms, such as Azure Container Instances and Kubernetes.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>An introduction to containers</li>
<li>Building a container image</li>
<li>Building images in Azure DevOps and running them in Azure</li>
<li>An introduction to Kubernetes</li>
<li>Kubernetes in action</li>
<li>Upgrading containers</li>
<li>Scaling containers and Kubernetes</li>
<li>Deploying to Kubernetes with Azure DevOps</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>To experiment with the techniques described in this chapter, you need one or more of the following:</p>
<ul>
<li>Docker Desktop</li>
<li>Visual Studio 2019</li>
<li>An Azure subscription</li>
<li>The Azure CLI</li>
</ul>
<p>All these are available for free or can be obtained for a limited period for free for evaluation purposes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">An introduction to containers  </h1>
                </header>
            
            <article>
                
<p>Containers are the evolution of virtualization. With virtualization, the resources of physical machines are shared among several virtual machines. Sharing those resources also means that all virtual machines have their own operating system. This is different when using containers. With containers, not only <span>are </span><span>the resources shared, but also the operating system kernel, making it very small in comparison with a virtual machine image.</span></p>
<p>Since the operating system kernel is shared, containers are also very portable. Images can be deployed on any type of host environment that supports running containers. This works because all the application's binaries and configurations are stored inside the container. As a result, environment variables outside the container do not impact the application. Naturally, there are a number of caveats, however: a container shares the operating system kernel; Linux containers can only run on a Linux operating system, and the same applies to Windows containers.</p>
<p>Containers provide the ability to virtualize an operating system in order to run multiple workloads on a single operating system. This is visualized in the following diagram, where you can see the difference between regular hosting, virtual machine hosting, and containers:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1087 image-border" src="assets/d858e1dc-2312-4de8-b626-dffa43717c02.png" style="width:193.67em;height:69.58em;"/></p>
<p>If you have ever heard of containers, you almost certainly have also heard of Docker. This is because Docker is one of the most well-known container engines that can be used for running containers. The next section will delve into DevOps and containers, while the remainder of the chapter will go into more technical detail regarding containers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">DevOps and containers</h1>
                </header>
            
            <article>
                
<p>As mentioned in the introduction, DevOps and containers are not the same thing. Containers are the technology that makes DevOps easier. This is because containers have benefits that make them <em>the</em> perfect tool for DevOps:</p>
<ul>
<li><strong>Consistent</strong>: Because you build the container images, the <span>hurdle </span>of "<q>it works on my machine</q>" is eliminated.</li>
<li><strong>Separation of concerns</strong>: When using containers, your application will be distributed between separate containers, <span>which </span>makes it easier to maintain and separate the processes.</li>
<li><strong>Platform</strong>: The solution can be run on different platforms. It does not matter whether this is in Azure, on Amazon Web Services, or in an on-premises environment.</li>
</ul>
<p>That aside, DevOps is more cultural than technical and, as mentioned in <a href="889f9224-f1b6-414d-bc80-16563f66e1e7.xhtml">Chapter 1</a>, <em>Introduction to DevOps</em>, technical components are used to support DevOps. In the remainder of this chapter, we will focus on the technical side of things.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hosting options</h1>
                </header>
            
            <article>
                
<p>As mentioned previously, one of the benefits of containers is that they are extremely portable. This also means that containers can be hosted on numerous platforms and technologies.</p>
<p>To run the containers, there are a lot of options that will vary according to your use case. Some of these options are as follows:</p>
<ul>
<li>Azure App Services</li>
<li>Azure Service Fabric</li>
<li>Docker Swarm</li>
<li>Docker Desktop</li>
<li>Kubernetes</li>
</ul>
<p>Depending on the demands of the application/container, it could run on all the options mentioned in the preceding list.</p>
<p>The images used to run containers (container images) also need to be hosted. These images are hosted in a so-called container registry. In a container registry, they are published privately or publicly. The two most well-know registries are the Docker Registry and the Azure Container Registry within the Azure platform.</p>
<p>Now that we have gone through some of the background information regarding containers, we are ready to go more deeply into the techniques behind containers and find out what is needed to create a custom container image.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a container image</h1>
                </header>
            
            <article>
                
<p>This section will take you through the process of building a container image and executing it on your local system. To do this, we will first have to create an application and then add Docker support to it before we create an image and finally test it. So let's begin!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating an application</h1>
                </header>
            
            <article>
                
<p>To be able to test and check what is running on the container, an application is required. For this, a new application can be created or you can use an existing application.</p>
<p>When creating a new application, the easiest option is to use the default ASP.NET Core website template within Visual Studio 2019. Container support can be added in a few clicks. This is simply done by checking the <span class="packt_screen">Enable Docker Support</span> <span>box </span>when creating the project:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1088 image-border" src="assets/8f581ba6-9178-4957-9d4c-5c5d729a39a6.png" style="width:80.67em;height:53.42em;"/></p>
<p>Keep the new application open or open your existing application. In the next section, we will investigate how Docker support can be added to an existing application.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding Docker support to an existing application</h1>
                </header>
            
            <article>
                
<p>Adding Docker support to an existing application requires a couple of simple steps:</p>
<ol>
<li>Open the project/solution in Visual Studio 2019 and right-click on the project.</li>
<li>Choose <span class="packt_screen">Add</span> and select <span class="packt_screen">Docker Support</span>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1089 image-border" src="assets/0d2ac44e-3785-4c6a-a0a1-f8ea4fee799f.png" style="width:62.50em;height:56.50em;"/></p>
<p>Depending on your client tools and Visual Studio configuration, there may also be a <span class="packt_screen">Container Orchestrator Support</span> option. With this option, the cloud orchestrator of your choice can be chosen. In this sample, we used Docker because this format is supported by the major container orchestrators. Other cloud orchestrator options do exist, however:</p>
<ul>
<li>Docker Swarm</li>
<li>Kubernetes</li>
<li>Mesos Marathon</li>
</ul>
<p>Depending on the cloud orchestrator used, a file is added to the project in the specific format for that orchestrator.</p>
<p>By adding Docker support, a new file is added to the project named <kbd>Docker</kbd>. The Dockerfile is the specification of a container image. This file can be read by Docker, which sees it as instructions. The file is a text document that contains separate commands that can also be called within a command-line tool to assemble an image:</p>
<pre>FROM mcr.microsoft.com/dotnet/core/aspnet:3.0-buster-slim AS base<br/>WORKDIR /app<br/>EXPOSE 80<br/>EXPOSE 443<br/>EXPOSE 555<br/>FROM mcr.microsoft.com/dotnet/core/sdk:3.0-buster AS build<br/>WORKDIR /src<br/>COPY ["ExistingDevOpsProject/ExistingDevOpsProject.csproj",<br/>"ExistingDevOpsProject/"]<br/>RUN dotnet restore "ExistingDevOpsProject/ExistingDevOpsProject.csproj"<br/>COPY . .<br/>WORKDIR "/src/ExistingDevOpsProject"<br/>RUN dotnet build "ExistingDevOpsProject.csproj" -c Release -o<br/>/app/build<br/>FROM build AS publish<br/>RUN dotnet publish "ExistingDevOpsProject.csproj" -c Release -o<br/>/app/publish<br/>FROM base AS final<br/>WORKDIR /app<br/>COPY --from=publish /app/publish .<br/>ENTRYPOINT ["dotnet", "ExistingDevOpsProject.dll"]</pre>
<p><span>The example uses a technique called a multi-stage build file. This is because the file uses multiple <kbd>FROM</kbd> statements where there is a reference to a specific image.</span></p>
<p>Prior to multi-stage build, it wasn't possible to use multiple <kbd>FROM</kbd> statements. During this time, it was hard to build efficient container images. Each statement in the file represented an additional layer on the image that resulted in it becoming larger and larger. </p>
<p>During this build process, it was also necessary to remove any components that were required during this process. For this reason, it was very common to have separate Dockerfiles for development and production.</p>
<p>As mentioned, the Dockerfile comprises instructions and the most commonly used instructions are as follows:</p>
<ul>
<li><strong>FROM</strong>: The <kbd>FROM</kbd> command is used to specify on which operating system or base image the image will be based. In the example, the <kbd>mcr.microsoft.com/dotnet/core/aspnet:3.0-buster-slim</kbd><span> image is used for the production version of the application, and the</span> <kbd>mcr.microsoft.com/dotnet/core/sdk:3.0-buster</kbd><span> image is used to build the image.</span></li>
<li><strong>RUN</strong>: The <kbd>RUN</kbd> command is used to install components or perform operations during the build process of the container image.</li>
<li><strong>ENTRYPOINT</strong>: The <kbd>ENTRYPOINT</kbd> command specifies what the entry point for a container image needs to be. In the example, the entry point is specified as a <kbd>.NET</kbd> application that references the library that was built during the compilation process.</li>
</ul>
<p>So far, we've created our application and added Docker support. Next, we'll see how to create an image with the application.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating an image with the application</h1>
                </header>
            
            <article>
                
<p>To be able to create a Docker image, Docker Desktop needs to be installed, as Visual Studio uses this to construct the image. With a complete Dockerfile, the image can be built using the following steps:</p>
<ol>
<li>Right-click the Dockerfile in Visual Studio and select <span class="packt_screen">Build Docker Image</span>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1090 image-border" src="assets/0ce5d270-2179-4c01-ac0a-762951e38fb0.png" style="width:47.50em;height:41.00em;"/></p>
<ol start="2">
<li>During the compilation and building of the image, take a look at the output window. Looking at it will provide more insights into the layered approach of container images. This layered approach is visible via the steps shown in the output window:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1091 image-border" src="assets/29d6b0f6-569c-4a6d-ae76-57c9b95a4097.png" style="width:54.75em;height:36.58em;"/></p>
<ol start="3">
<li>Docker Desktop also makes it possible to run and store images locally. After building the image, open a Terminal and run the following command:</li>
</ol>
<pre style="padding-left: 90px"><strong><span>docker images</span></strong></pre>
<p>The command displays all images currently on the machine. In this list, the base images that are downloaded during the creation of images are also listed.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the container image</h1>
                </header>
            
            <article>
                
<p>The container image can be started locally by running it within Docker. As we now have a container image, a container can be created:</p>
<ol>
<li>Run the following <kbd>docker container run</kbd> command:</li>
</ol>
<pre style="padding-left: 90px"><strong><span>docker container run --publish 8123:80 --detach --name [container name] [image name]</span></strong></pre>
<p style="padding-left: 60px">The preceding command will start the container image specified at the end of the command. In addition, different arguments are specified:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li><strong>Publish</strong>: The <kbd>publish</kbd> argument opens a port from the host to the container. As mentioned in the example, this will open port <kbd>8123</kbd> and will route traffic to port <kbd>80</kbd> within the container.</li>
<li><strong>Detach</strong>: The <kbd>detach</kbd> argument will run the container in the background and print out its specific ID.</li>
<li><strong>Name</strong>: The name for the container within Docker.</li>
</ul>
</li>
</ul>
<ol start="2">
<li>To list all running containers, use the <kbd>docker ps</kbd> <span>command </span>within the Terminal.</li>
<li>With the container running, open a browser and navigate to <kbd>http://localhost:8123</kbd>. If everything works fine, this should show a default ASP.NET Core web page:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1092 image-border" src="assets/d0e39e85-3964-47f4-a1e4-4d2ffc71ad49.png" style="width:44.08em;height:15.75em;"/></p>
<p>Since building stuff locally and running it on your machine is not really the DevOps way of thinking, we will move to a different hosting platform in the upcoming sections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building images in Azure DevOps and running them in Azure</h1>
                </header>
            
            <article>
                
<p>To support continuous integration and continuous delivery, the source files need to be shared in a repository. So, let's share the resources in Azure Repos and try to build our container by using Azure Pipelines. After building the container image, a place to store the images and run the container are also required. Within the Azure platform, there are two perfect services for this scenario:</p>
<ul>
<li><strong>Azure Container Registry</strong>: This service is a managed private Docker registry based on the open source Docker Registry. Here, you can maintain and register container images.</li>
<li><strong>Azure Container Instance</strong>: The Azure Container Instance, also referred to as ACI, is a solution for running isolated containers without a lot of management.</li>
</ul>
<div class="packt_infobox">For the simplicity of this guide, the files are already added to the repository and the Azure resource is already created.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a service endpoint</h1>
                </header>
            
            <article>
                
<p>As already discussed within the book, connections within Azure DevOps with external services such as Azure and container registries are configured within a service endpoint. Because the image needs to be available in order for Azure Container Instances to retrieve it, it needs to be published to a container registry. The connection from Azure DevOps to the registry is configured within a service connection.</p>
<p>Perform the following steps to configure the service connection:</p>
<ol>
<li>In the Azure DevOps project, open the project settings.</li>
<li>Within the project settings, click on <span class="packt_screen">Service connections<span>.</span></span></li>
<li>In the service connection overview, click on <span class="packt_screen">Create service connection</span> and choose <span class="packt_screen">Docker Registry</span>.</li>
<li>In the fly-out that appears, fill in the correct information and save the connection:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1093 image-border" src="assets/7895daf8-24f3-4591-8a3c-5d24d6ffff52.png" style="width:38.58em;height:39.67em;"/></p>
<p>Saving the connection will add a service connection to the project that can be used by the pipelines we will create, or that you will create in the future.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a new pipeline</h1>
                </header>
            
            <article>
                
<p>To be able to start building the container image and publish it to the registry, we will create a new pipeline. For this example, we will make use of the YAML pipeline experience.</p>
<p>Perform the following steps to get started with the pipeline:</p>
<ol>
<li>Open you Azure DevOps project and click on <span class="packt_screen">Pipelines</span>.</li>
<li>In the pipelines overview, click on <span class="packt_screen">New Pipeline</span>.</li>
<li>Select <span class="packt_screen">Azure Repos Git</span>, choose the correct repository, and then choose the <span class="packt_screen">Starter pipeline</span>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1094 image-border" src="assets/4968a66e-f56a-4855-8f58-6ad821fed19b.png" style="width:39.25em;height:39.75em;"/></p>
<ol start="4">
<li>From the starter pipeline, remove the two dummy script tasks and open the assistant.</li>
<li>In the assistant, search for the <kbd>Docker</kbd> tasks and add the tasks to the pipeline.</li>
<li>Choose the service connection <span>created </span>for the container registry and keep the other information as the defaults.</li>
</ol>
<div class="packt_infobox">Make sure to change the <kbd>buildContext</kbd> property of the tasks to point to the correct directory. This is required for Docker to be able to reference the correct paths when building your image.</div>
<p style="padding-left: 60px">When added, the YAML should look like this:</p>
<pre style="padding-left: 90px">- task: Docker@2<br/>  inputs:<br/>    containerRegistry: 'MSFT Container Registry'<br/>    repository: 'azuredevops'<br/>    command: 'buildAndPush'<br/>    Dockerfile:'**/Dockerfile'<br/>    buildContext:<br/>'$(System.DefaultWorkingDirectory)/ExistingDevOpsProject'</pre>
<ol start="7">
<li>Save and run the pipeline. After the first run, the container image is created and published to the container registry.</li>
</ol>
<p style="padding-left: 60px">The images in the container registry can be retrieved by using a predefined URL. This URL comprises a few specific components:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li><kbd>[container registry]/[repository]:[tag]</kbd>:
<ul>
<li><strong>Container registry</strong>: The base URL of the container registry.</li>
<li><strong>Repository</strong>: The repository as specified during the process of publishing the image.</li>
<li><strong>Tag</strong>: The tag for the specific version of the image. By default, the Docker tag used is <kbd>BuildId</kbd>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<ol start="8">
<li>Now that we have a reference to the container image, Azure Container Instances should be able to retrieve the container and run it. The only thing needed for this is an Azure CLI command:</li>
</ol>
<pre style="padding-left: 90px"><strong><span>az container create --resource-group [resource group] --name [ACI name] –location westeurope –image [Image reference] --dns-name-label [dns reference] –ports 80 --registry-username [username of the registry] --registry-password [password of the registry]</span></strong></pre>
<p style="padding-left: 60px">Since the reference to the image is different for each build (<kbd>BuildId</kbd> for the tag value), <kbd>BuildId</kbd> is retrieved in the Azure CLI command via the <kbd>$(Build.BuildId)</kbd> <span>variable:</span></p>
<pre style="padding-left: 90px"><strong><span>az container create --resource-group aci-rg-devops --name aci-demo-app –location westeurope –image msftazuredevops.azurecr.io/azuredevops:$(Build.BuildId) --dns-name-label aci-msft-demo –ports 80 --registry-username $(username) --registry-password $(password)</span></strong></pre>
<p style="padding-left: 60px">To execute the preceding script, the Azure CLI task is added to the pipeline. In this task, we configure the correct subscription via the service endpoint and set the inline script.</p>
<p style="padding-left: 60px">The script will create a container instance in the <kbd>aci-rg-devops</kbd> resource group with the name <kbd>aci-demo-app</kbd> and retrieve the <kbd>azuredevops</kbd> container image from the <kbd>msftazuredevops.azurecr.io</kbd> repository.</p>
<p style="padding-left: 60px">The complete YAML for this task looks like this:</p>
<pre style="padding-left: 90px">- task: AzureCLI@2<br/>  inputs:<br/>  azureSubscription: 'Subscription MPN'<br/>  scriptType: 'bash'<br/>  scriptLocation: 'inlineScript'<br/>  inlineScript: 'az container create --resource-group aci-rg-devops -<br/>name aci-demo-app --location westeurope --image msftazuredevops.azurecr.io/azuredevops:$(Build.BuildId) --dns-name-label aci-msft-demo --ports 80 --registry-username $(username) --registry-password $(password)'</pre>
<p>Running this pipeline will result in an Azure Container Instance in Azure. That container will be running the exact same application that was running locally:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1095 image-border" src="assets/55aa2959-0840-41e1-b4d4-63b1bb725ad6.png" style="width:45.42em;height:5.00em;"/></p>
<p>When opening the Azure Container Instance in the Azure portal, you will see that it is a running instance and that there is an FQDN attached to the Azure Container Instance based on the value supplied, <kbd>dns-name-label</kbd>, within the Azure CLI command, <kbd>aci-msft-demo.westeurope.azurecontainer.io</kbd>. Open the URL in your browser and see the application we have pushed to the container:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1096 image-border" src="assets/fb1fd6f7-038f-4ce1-9933-b9ffdf6cbd7a.png" style="width:63.50em;height:27.67em;"/></p>
<p>It shows the same content as the container that was started locally. This is because, in both places, the same container image was started.</p>
<p>In this section, we started the container on Azure Container Instances, but how will we manage running containers and restart them when there are problems? This is where Kubernetes comes in.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">An introduction to Kubernetes</h1>
                </header>
            
            <article>
                
<p>Kubernetes is another service for running your containers. Kubernetes is a cluster orchestration technology first developed by Google. It is now an open source platform for automating deployment, scaling, and operations of application containers across clusters of hosts, thereby providing a container-centric infrastructure.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Functionalities of Kubernetes</h1>
                </header>
            
            <article>
                
<p>As mentioned earlier, containers offer you a great way to package your applications. When running the applications, you need to make sure that applications keep running and this is where Kubernetes comes in as it has the following core functionalities:</p>
<ul>
<li><strong>Service discovery and load balancing</strong>: How a container is exposed is controlled within Kubernetes and, in addition, it is also capable of balancing the traffic within the orchestration.</li>
<li><strong>Storage orchestration</strong>: The ability to mount different kinds of storage providers to the platform.</li>
<li><strong>Rollouts and rollbacks</strong>: Kubernetes can automatically create and restart containers for the specified deployment.</li>
<li><strong>Self-healing</strong>: Kubernetes can heal containers when they are failing.</li>
<li><strong>Secret and configuration management</strong>: Kubernetes has a built-in functionality to manage secrets such as tokens, passwords, and keys.</li>
</ul>
<p>In order to provide these functionalities, Kubernetes consists of a number of components.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Kubernetes core components and services</h1>
                </header>
            
            <article>
                
<p>Kubernetes consists of a few core components that make it run. These components together make a great and stable product for running and managing containers. The next few subsections will go over each of these components individually.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Master node</h1>
                </header>
            
            <article>
                
<p>One of the important components within Kubernetes is the master node. The node manages the cluster. It contains all the Kubernetes core components in order to manage the cluster:</p>
<ul>
<li><kbd>kube-apiserver</kbd>: A component for exposing the Kubernetes API. This API is used by management tools of Kubernetes, such as <kbd>kubectl</kbd>, and the Kubernetes dashboard.</li>
<li><kbd>etcd</kbd>: Used to maintain the state of the Kubernetes cluster.</li>
<li><kbd>kube-scheduler</kbd>: A component that selects nodes for the pods to run on.</li>
<li><kbd>kube-controller-manager</kbd>: The controller manager oversees a number of smaller controllers that perform actions such as replicating pods and managing node operations.</li>
</ul>
<p>By using these components, the master node can maintain the desired state for the cluster. It is good to know that when you are interacting with Kubernetes, you are communicating with the master node. The master node itself will then communicate with the other components within the cluster.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Regular nodes</h1>
                </header>
            
            <article>
                
<p>These nodes are the nodes that will run the containers. These can be virtual machines or even physical machines. On these machines, the so called <kbd>kubelet</kbd> is installed. <kbd>kubelet</kbd> is the agent that's used to run pods/containers within the nodes.</p>
<p>As you may have noticed in the preceding sections, there are also other core services within Kubernetes and we will discuss these next.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pod</h1>
                </header>
            
            <article>
                
<p>Within Kubernetes, pods are used to run the applications. Within the pods, it is specified which resources are required to run the application. The scheduler (<kbd>kube-schedular</kbd>) within Kubernetes checks where to run the application depending on the demands and the nodes <span>coupled </span>to the cluster.</p>
<p>Pods themselves have a limited lifespan and are removed when new versions are deployed or, for example, when a node fails, pods can be replaced by pods on the same or another node.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Service</h1>
                </header>
            
            <article>
                
<p>The service is sometimes also referred to as the load balancer and is used to provide a logical grouping of pods and furnish them with connectivity (a way to connect).</p>
<p>Three major services are as follows:</p>
<ul>
<li><strong>Cluster IP</strong>: Adding an internal IP to a cluster of pods.</li>
<li><strong>Node port</strong>: Port mapping to the underlying node directory <span>to </span>connect to the application/pod with the IP address of the node.</li>
<li><strong>Load balancer</strong>: This service adds a load balancer resource and configures an external IP address on the load balancer. On the external side, the load balancer will route traffic to the specific nodes based on the rules configured in the load balancer and internally to the correct pod.</li>
</ul>
<p>With these services, the internal and external connections for pods are arranged. The services and pods are all specified within a deployment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deployment</h1>
                </header>
            
            <article>
                
<p>A deployment describes the desired state of an application. It describes the number of replicas, but also the update strategy. Kubernetes will track the health of the pods and will remove or add pods when needed to comply with the desired state that is described in the deployment.</p>
<p>These deployments are specified in a YAML file. For example, when running a container in Kubernetes, you must specify a replica set. A replica set ensures that a specified number of pod replicas are running at any given time.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Operation of Kubernetes </h1>
                </header>
            
            <article>
                
<p>When you are new to containers, and especially to Kubernetes, it is hard to figure things out immediately. However, to aid your understanding of the concept, take a look at the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1097 image-border" src="assets/efb2bde7-c6dd-48c6-9261-6377d9728cfc.png" style="width:65.92em;height:41.08em;"/></p>
<p>Deployments of containers to a Kubernetes cluster are defined in the so-called deployment file (<strong>1</strong>). In these deployment files, the desired state of the application is described. This desired state is described as a YAML file.</p>
<p>In this example, the desired state is a load balancer service and three pods (<strong>2</strong>). These pods are divided by the Kubernetes API on the nodes that run the containers (<strong>3</strong>). The service defined in the deployments file ensures that the traffic is routed to the specific pods. The deployment can be changed by updating it.</p>
<p>The scheduler can also change deployments when, for example, automatic scaling is configured for the application. In that kind of scenario, a fourth pod could be added to the cluster. In the service, there can also be an external load balancer to route traffic to the internal load balancer of Kubernetes (<strong>4</strong>).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Azure Kubernetes Service</h1>
                </header>
            
            <article>
                
<p><strong>Azure Kubernetes Service</strong>, or <strong>AKS</strong>, is the Microsoft implementation of Kubernetes. Setting up a regular Kubernetes cluster is a lot of work, but with AKS, it has been made easier. This is because Kubernetes is a managed platform and the reason why almost all operational tasks are handled by the platform itself.</p>
<p>Some key functionalities of AKS are as follows:</p>
<ul>
<li>Azure manages critical tasks, such as health monitoring and maintenance, including Kubernetes version upgrades and patching.</li>
<li>Azure performs simple cluster scaling.</li>
<li>The master node of Kubernetes is fully managed.</li>
<li>Master nodes are free, and you only pay for running agent nodes.</li>
</ul>
<p>By using the AKS, a Kubernetes cluster can be operational within minutes. Besides that, the focus will be on the application as the master node is fully managed. Now, let's try to run a Kubernetes cluster with custom images.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Kubernetes in action </h1>
                </header>
            
            <article>
                
<p>In the first few sections of this chapter, we created a container and deployed it to an Azure Container Instance. Let's now deploy this container to a Kubernetes cluster.</p>
<p>Creating a cluster can be done via the Azure CLI or an ARM template. For ease of demonstration, the Azure CLI is used.</p>
<p>First, a new resource group needs to be created to host the Azure Kubernetes cluster:</p>
<pre><span><strong>az group create --name mpn-rg-kubernetes --location westeurope</strong><br/></span></pre>
<p>Now, we can create our Kubernetes cluster.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a Kubernetes cluster</h1>
                </header>
            
            <article>
                
<p>When the resource group is created, a new Kubernetes cluster can be added to the group:</p>
<pre><strong><span>az aks create --resource-group mpn-rg-kubernetes --name mykubernetescluster --node-count 1 --enable-addons monitoring --generate-ssh-keys</span></strong></pre>
<p>This command creates a new Kubernetes cluster with the name <kbd>mykubernetescluster</kbd> and with a single node. This means that there will be one virtual machine created in the Azure portal that is configured as a node for the Kubernetes cluster. In addition, the monitoring add-ons will be enabled on the cluster.</p>
<p>The creation of this cluster will take a couple of minutes. In Azure, the <kbd>mykubernetescluster</kbd> service will be created in the specified resource group. Alongside this resource group, another group will be created by the Azure platform itself.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Kubernetes infrastructure</h1>
                </header>
            
            <article>
                
<p>In this resource group, all virtualized infrastructure that is needed to run the cluster is created. This also means that in the future, new components can be added to this resource group depending on the demands of the application:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1098 image-border" src="assets/557e2c0d-fe12-4e28-a57e-7eaaaf033bb1.png" style="width:26.25em;height:8.17em;"/></p>
<p>In the resource group <span>created</span>, you will find all the resources as mentioned to run the cluster:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1099 image-border" src="assets/8d9d45c5-bb83-437e-b183-bf2588a7b9ef.png" style="width:34.42em;height:14.08em;"/></p>
<p>With the Kubernetes infrastructure now up and running, the management and deployment of resources can begin.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Managing Kubernetes</h1>
                </header>
            
            <article>
                
<p>To manage Kubernetes, the <kbd>kubectl</kbd> command line is used and installed locally (or used in the Azure cloud shell). This is command-line interface tooling that will communicate with the Kubernetes API. Let's see how to work with Kubernetes with this command line:</p>
<ol>
<li>If you do not already have it installed, run the following command to install the Azure CLI on your machine:</li>
</ol>
<pre style="padding-left: 90px"><strong><span>az aks install-cli</span></strong></pre>
<ol start="2">
<li>To connect to the cluster, the credentials need to be retrieved and saved to the local system. This can be done by using the <kbd>az aks get-credentials</kbd> <span>command </span>and specifying the resource group and cluster name:</li>
</ol>
<pre style="padding-left: 90px"><strong><span>az aks get-credentials --resource-group mpn-rg-kubernetes --name mykubernetescluster</span></strong></pre>
<ol start="3">
<li>With all the prerequisites configured, a lot of the base functionality can be run against the Kubernetes cluster. Take a look at these two commands for example:</li>
</ol>
<ul>
<li style="list-style-type: none">
<ul>
<li>Retrieve the nodes of the cluster:</li>
</ul>
</li>
</ul>
<pre style="padding-left: 150px"><strong><span>kubectl get nodes</span></strong></pre>
<ul>
<li style="list-style-type: none">
<ul>
<li>Get the pods in the cluster:</li>
</ul>
</li>
</ul>
<pre style="padding-left: 150px"><strong><span>kubectl get pods</span></strong></pre>
<ol start="4">
<li>Next to the preceding commands, you can also try the following Azure CLI command to open up the Kubernetes dashboard. This dashboard is a management interface built on top of the Kubernetes API that can be used next to the <kbd>kubectl</kbd> command line:</li>
</ol>
<pre style="padding-left: 90px"><strong><span>az aks browse --resource-group mpn-rg-kubernetes --name mykubernetescluster</span></strong></pre>
<p style="padding-left: 60px">The dashboard is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1100 image-border" src="assets/ae230049-85ac-4017-b74a-cb55061420ee.png" style="width:53.50em;height:36.00em;"/></p>
<p>A deployment file needs to be created to be able to run containers within the cluster. So let's see how to do this.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying a container image</h1>
                </header>
            
            <article>
                
<p>We will create a deployment file and deploy it to Kubernetes. To do this, perform the following steps:</p>
<ol>
<li>Make a new file in your favorite text editor and call it <kbd>deploy.yaml</kbd>. Add the following information to the <kbd>deploy.yaml</kbd> file:</li>
</ol>
<pre style="padding-left: 90px">apiVersion: apps/v1<br/>kind: Deployment<br/>metadata:<br/>  name: kubernetes-deployment<br/>  labels:<br/>    app: customapplication<br/>spec:<br/>  replicas: 3<br/>  selector:<br/>    matchLabels:<br/>      app: customapplication<br/>  template:<br/>    metadata:<br/>      labels:<br/>        app: customapplication<br/>    spec:<br/>      containers:<br/>      - name: azuredevops<br/>        image: msftazuredevops.azurecr.io/azuredevops:586<br/>        ports:<br/>        - containerPort: 80</pre>
<p style="padding-left: 60px">In this example, the following is specified:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li>A deployment is created with the name <kbd>kubernetes-deployment</kbd> (<kbd>metadata.name</kbd>).</li>
</ul>
<ul>
<li>The deployment will create three replicas of the specified container (<kbd>spec.replicas</kbd>).</li>
<li>The selector, in combination with the labels tag, is used to specify which components this deployment file will manage within Kubernetes.</li>
<li>The deployment file will create a container for the <kbd>msftazuredevops.azurecr.io/azuredevops:586</kbd> <span>image file.</span></li>
</ul>
</li>
</ul>
<ol start="2">
<li>To deploy this file to Kubernetes, we will again use the <kbd>kubectl</kbd> command line and make use of the <kbd>apply</kbd> command:</li>
</ol>
<pre style="padding-left: 90px"><strong><span>kubectl apply -f deploy.yaml</span></strong></pre>
<p style="padding-left: 60px">The <kbd>-f</kbd> argument is used to specify that a local path is used as a reference to a deployment file. After executing the command, you can open the Kubernetes dashboard to see the status and maybe even observe errors.</p>
<div class="packt_infobox">It is possible that you encounter an error stating that pulling the image from your location failed. This could be a security issue. Under the hood, AKS is using a service principal. You should also see this when creating a new Kubernetes cluster. Make sure to give this service principal access rights on the Azure registry.</div>
<ol start="3">
<li>Following a successful execution, try the <kbd>get pods</kbd> command to see whether there are three pods within the system. If everything proceeded correctly, there should be three pods running within Kubernetes, but the application is still not available to the outside world.</li>
</ol>
<p style="padding-left: 60px">To make it available, we need to add a service to the deployment file.</p>
<div class="packt_infobox">If you want to add it to the same file, add a line with these characters, <kbd>---</kbd>, between the deployments. This is not required when you also define separate files for deployment.</div>
<p style="padding-left: 90px">In the <kbd>deploy.yaml</kbd> file, add the following section:</p>
<pre style="padding-left: 90px">---<br/>apiVersion: v1<br/>kind: Service<br/>metadata:<br/>    name: customapplication-service<br/>spec:<br/>    type: LoadBalancer<br/>    ports:<br/>    - port: 80<br/>    selector:<br/>        app: customapplication</pre>
<p style="padding-left: 60px">This YAML section creates a load balancer and attaches it to the specified selector (<kbd>spec.selector.app</kbd>), meaning it will be used for the pods as we previously specified.</p>
<p style="padding-left: 60px">In the background, Kubernetes will create an Azure load balancer and a public IP for connection to the pods.</p>
<ol start="4">
<li>To retrieve the external IP address of the service, use the following command until it displays the external IP address:</li>
</ol>
<pre style="padding-left: 90px"><strong><span>kubectl get service</span></strong></pre>
<p style="padding-left: 60px">This will return all services and their external IP addresses if it is present. Also take a quick peak at the additional resource group of Kubernetes to see which Azure resources are created.</p>
<p>Well done! In this section, you learned how to create a Kubernetes cluster and deploy a container image on it via <kbd>kubectl</kbd> and deployment files. In the next section, we will take this forward and learn how to upgrade these containers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Upgrading containers</h1>
                </header>
            
            <article>
                
<p>In Kubernetes, applications are very easily updated. For this, Kubernetes uses rolling updates, which means that traffic to a container is first drained before the container is replaced. During an upgrade of the application, Kubernetes will deploy an additional pod and run it through some specified probes.</p>
<p>A probe is a diagnostic that is periodically performed on a pod to check its status. During the upgrading or creation of a pod, Kubernetes brings up the additional pod and makes sure that it passes the liveness and readiness probes.</p>
<p>If the newly created pod succeeds with both probes, the traffic to a single old pod is terminated and traffic to the new pod is opened. For this termination, Kubernetes uses a termination grace period. During this period, the 2 connection to the load balancer is stopped and active connections are processed successfully, and new traffic is routed to a running pod. The default grace period is 30 seconds, during which the pod will be in a termination state and all old traffic to this pod is redirected to the other pods.</p>
<p>This process continues until all pods are replaced with the new version. All of this is default behavior within Azure Kubernetes. A deployment is simply triggered by adjusting the deployment file and applying it with the same command as used previously:</p>
<pre><strong><span>Kubectl apply -f [file]</span></strong></pre>
<p>By default, <kbd>httpGet</kbd> probes are added to pods that are being exposed, but they can also be customized by adding the readiness probe or liveness probe to the deployment:</p>
<pre>readinessProbe:<br/>          httpGet:<br/>             path: /<br/>             port: 80<br/>             initialDelaySeconds: 5<br/>             periodSeconds: 5<br/>             successThreshold: 1</pre>
<p>This readiness probe performs an <kbd>httpGet</kbd> request on the pod and has the following options:</p>
<ul>
<li><kbd>path</kbd>: The path it should call for the <kbd>httpGet</kbd> request.</li>
<li><kbd>port</kbd>: The port number it should use for the call. This is also configured in our deployment file.</li>
<li><kbd>initialDelaySeconds</kbd>: The seconds it waits before running the probe once the container is started.</li>
</ul>
<ul>
<li><kbd>periodSeconds</kbd>: The number of seconds the probe waits before it times out.</li>
<li><kbd>successThreshold</kbd>: The amount of success required for the probe minimum value is <kbd>1</kbd>.</li>
</ul>
<p>As mentioned, a deployment has a default rolling upgrade scenario configured. The configuration of the rolling deployment can be retrieved by using the following command:</p>
<pre><strong><span>kubectl describe deployment kubernetes-deployment</span></strong></pre>
<div class="packt_infobox">If you are interested in doing so, build a new version of your container and upgrade it within Kubernetes. Before running the upgrade, make sure you have the dashboard open and refresh the page during the update and you will see extra pods coming up and old pods being terminated.</div>
<div>
<p>In this section, we learned how to upgrade containers, which will help you stay up to date with the latest version. Moving forward, in the next section, we will look further into the scaling of containers and Kubernetes. </p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Scaling containers and Kubernetes</h1>
                </header>
            
            <article>
                
<p>As the demand for your application may grow, you will need to scale the application. Scaling the application can be done in multiple ways and different components can be scaled:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1101 image-border" src="assets/0ba82303-be6e-4768-9396-6f29a7de1f2a.png" style="width:33.67em;height:17.58em;"/></p>
<p>The preceding diagram shows you the different ways to scale your application or cluster, which we will discuss over the upcoming subsections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Scaling pods manually</h1>
                </header>
            
            <article>
                
<p>Pods can easily be scaled by updating the number of replicas. Try getting your pods by using the <kbd>kubectl get pods</kbd> command and increase the number of replicas by using the following command:</p>
<pre><strong><span>kubectl scale --replicas=[number of pods] deployment/[deploymentname]</span></strong></pre>
<p>With this command, the pods are scaled up or down depending on the number of replicas. The up or specified scaling is down as per deployment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Autoscaling pods</h1>
                </header>
            
            <article>
                
<p>Azure Kubernetes also supports autoscaling. The scheduler will then update the number of pods depending on CPU utilization or other metrics that are available.</p>
<p>Kubernetes uses the metrics server for this. The metrics server collects metrics from the summary API of the kubelet agents that run on the nodes within the cluster.</p>
<div class="packt_infobox">The metrics service is available by default if you are using Kubernetes version 1.10 or above. If you are using an older version, you will have to install the metrics server <span>manually</span>.</div>
<p>The autoscale functionality also requires some configuration on the deployment side of Kubernetes. For a deployment, you need to specify the requests and limits for the running container. These values are specified for a specific metric, for example, the CPU.</p>
<p>In the following example, there are requests and limits specified for the CPU metric. The CPU metric is measured in CPU units. In Azure, one unit stands for one core. For different platforms, it can have a different meaning:</p>
<pre>resources:<br/>  requests:<br/>     cpu: 0.25<br/>  limits:<br/>     cpu: 0.5</pre>
<p>This part can be added to the container in the deployment file and this will make sure that the pods can be autoscaled when large numbers of requests need to be served.</p>
<p>With the updated deployment file, deploy it and make an autoscale rule within the Kubernetes cluster:</p>
<pre><strong><span>kubectl autoscale deployment [deployment name] --cpu-percent=60 --min=1 --max=10</span></strong></pre>
<p>This rule will update the deployment with autoscale functionality. If average CPU utilization across all pods exceeds 60% of their requested usage, the autoscaler increases the pods up to a maximum of 10 instances. A minimum of one instance is then defined for the deployment:</p>
<p>After creating the autoscaler, you can check it by running the following command:</p>
<pre><strong><span>kubectl get hpa</span></strong></pre>
<p><strong>HPA</strong> stands for <strong>horizontal pod autoscaler</strong>.</p>
<p>Try creating a CPU-intensive operation within an application and checking automatic pod creation during execution. The Kubernetes cluster will notice the significant amount of CPU usage and will scale out the cluster automatically by creating multiple pods.</p>
<p>Once the intensive operation is finished, Kubernetes will scale the number of pods <span>down </span>to the minimum.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Scaling nodes</h1>
                </header>
            
            <article>
                
<p>Alongside scaling pods, Kubernetes can also scale the number of nodes that run within the Kubernetes cluster. The number of nodes can be scaled using the following commands:</p>
<ol>
<li>First, get the information pertaining to the current environment by requesting the number of nodes:</li>
</ol>
<pre style="padding-left: 90px"><strong><span>az aks show --resource-group mpn-rg-kubernetes --name mykubernetescluster  --query agentPoolProfiles</span></strong></pre>
<ol start="2">
<li>Then, use this command to update the <kbd>nodepool</kbd>. Extract the name of the <kbd>nodepool</kbd> from the result of the last command:</li>
</ol>
<pre style="padding-left: 90px"><strong><span>az aks scale --resource-group mpn-rg-kubernetes --name mykubernetescluster --node-count 2 --nodepool-name nodepool1</span></strong></pre>
<p>Scaling the number of nodes up can increase the performance drastically. This will also make the cluster more expensive. By scaling the number of cluster nodes down, costs can decrease and you are only using the resources that are actually required by your application. To keep track of this, the nodes can also be autoscaled. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Autoscaling nodes</h1>
                </header>
            
            <article>
                
<p>Alongside the manual scaling of nodes, nodes can also scale <span>automatically </span>by updating the Kubernetes cluster. This can be done by using the <kbd>az aks update</kbd> command. With this command, you can set the minimum and maximum node counts. The autoscaler will then make sure that nodes are created when needed:</p>
<pre><strong>az aks update --resource-group mmpn-rg-kubernetes --name mykubernetescluster   --update-cluster-autoscaler --min-count 1 --max-count 5</strong></pre>
<p>Azure Kubernetes also has the option to scale out with Azure Container Instances. To use this option, a specific configuration needs to be applied when creating the AKS cluster. This is mainly required because Azure Container Instances needs a specific subnet within the virtual network.</p>
<p>In this section, we learned to scale containers and the cluster to drastically increase performance. Next up is deployment from Azure DevOps to facilitate continuous deployment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying to Kubernetes with Azure DevOps</h1>
                </header>
            
            <article>
                
<p>We have seen a lot of options for deploying and configuring the Kubernetes cluster via the command line. When working with DevOps, however, changes need to be applied in a continuous way.</p>
<p>For this, there is the Kubernetes manifest task within Azure DevOps, which contains a lot of functionalities to manage a Kubernetes cluster:</p>
<pre>task: KubernetesManifest@0<br/>  inputs:<br/>  action: 'deploy'<br/>  kubernetesServiceConnection: '[service connection name]'<br/>  manifests: '[path to your deployment file]'<br/>  containers: 'msftazuredevops.azurecr.io/azuredevops:$(Build.BuildID)'</pre>
<p>In the preceding example, the following is configured:</p>
<ul>
<li><kbd>action</kbd>: The kind of action to we want to perform. In this example, the <kbd>deploy</kbd> action is used because we want to deploy/apply a deployment file.</li>
<li><kbd>kubernetesServiceConnection</kbd>: The service connection to the Kubernetes cluster.</li>
<li><kbd>manifests</kbd>: The path to the manifest file. As we are using the <kbd>deploy</kbd> action, this should be a reference to the deployment file.</li>
<li><kbd>containers</kbd>: A special field where you can override the version of the container being deployed. By specifying the above, every image is specified in the deployment manifest with the <kbd>msftazuredevops.azurecr.io</kbd> <span>reference </span>and the <kbd>azuredevops</kbd> <span>repository </span>is replaced by the new value as configured in this field.</li>
</ul>
<p>Using a Kubernetes destination environment within Azure DevOps pipelines also has the advantage of seeing the environment running within Azure DevOps. This will show the number of running pods within the cluster.</p>
<p>Try it out with the following stage configuration for a build that will publish the deployment files to the artifact location of Azure DevOps:</p>
<pre>stages:<br/>  - stage : Build<br/>    displayName : Build<br/>    jobs:<br/>     - job:<br/>       pool:<br/>           vmImage: 'ubuntu-latest'<br/>       continueOnError: false<br/>       steps:<br/>       - task: Docker@2<br/>         inputs:<br/>           containerRegistry: '[Container Registry service connection]'<br/>           repository: 'azuredevops'<br/>           command: 'buildAndPush'<br/>           Dockerfile: '**/Dockerfile'<br/>           buildContext: '$(System.DefaultWorkingDirectory)/[folder path<br/> for docker]'<br/>       - task: CopyFiles@2<br/>         inputs:<br/>           SourceFolder: '$(system.defaultworkingdirectory)/[path to the<br/> deployment manifest files]'<br/>           Contents: '*'<br/>           TargetFolder: '$(build.artifactstagingdirectory)'<br/>           flattenFolders: true<br/>       - task: PublishBuildArtifacts@1<br/>         inputs:<br/>           PathtoPublish: '$(Build.ArtifactStagingDirectory)'<br/>           ArtifactName: 'drop'<br/>           publishLocation: 'Container'</pre>
<p>Next to the build stage, add the following release stage. Following the initial execution of the pipeline, a new environment will be available within Azure DevOps. In the environment created by the release, attach the Kubernetes cluster to see information on the running pods:</p>
<div>
<pre>- stage : Release<br/>    displayName : Release<br/>    jobs:<br/>     - deployment: KubernetesDeploy<br/>       displayName: Deploy Kubernetes<br/>       pool:<br/>         vmImage: 'ubuntu-latest'<br/>       environment: 'Kubernetes'<br/>       strategy:<br/>         runOnce:<br/>           deploy:<br/>             steps:<br/>             - task: DownloadPipelineArtifact@2<br/>               displayName: 'Download pipeline artifacts'<br/>               inputs:<br/>                 buildType: 'current'<br/>                 targetPath: '$(Pipeline.Workspace)'<br/>             - task: KubernetesManifest@0<br/>               inputs:<br/>                 action: 'deploy'<br/>                 kubernetesServiceConnection: '[Kubernetes service<br/> connection]'<br/>                 manifests: '$(Pipeline.Workspace)[deployment manifest]’<br/>                 containers: '[container registry]:$(Build.BuildID)'</pre></div>
<p>In the example, two stages are specified for a multi-stage pipeline. The first stage will build the container image via the Docker task and publish it to a container registry. After publishing the image, it also publishes a number of build artifacts, in this case, the Kubernetes manifests.</p>
<p>The second stage deploys to a specific environment called Kubernetes. This environment will also be created in Azure DevOps if it has not already been added. During the remainder of the process, it retrieves the published artifacts of the build stage and uses the Kubernetes manifest task to deploy the Kubernetes resources.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary </h1>
                </header>
            
            <article>
                
<p>In this chapter, you have learned what containers are and how they relate to DevOps. Where DevOps is more of a cultural thing, containers are a way to support it technically. You have also learned how to create container images via a Dockerfile, and specifically by using a multi-stage build file. Finally, we dived into Kubernetes, where we learned a way to host containers and also manage the running containers by using the <kbd>kubectl</kbd> command.</p>
<p>Using the knowledge acquired in this chapter, you are now able to deploy applications to Kubernetes and make sure that it scales with the number of requests it receives.</p>
<p>In the next chapter, you will learn more about facilitating the DevOps process by using Azure DevOps. You will learn what works for your organization and team and what doesn't and how to implement that structure and your approach using Azure DevOps.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<p>As we conclude, here is a list of questions for you to test your knowledge regarding the material covered in this chapter. You will find the answers in the <em>Assessments</em> section of the Appendix:</p>
<ol>
<li>What are the benefits of containers for DevOps?</li>
<li>True or false: A specific container can be hosted on different platforms (Azure/AWS).</li>
<li>Is it possible to add container support to an existing application?</li>
<li>What is the <kbd>RUN</kbd> command used for within a Dockerfile?</li>
<li>Kubernetes can be scaled on different components. What are these components?</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading </h1>
                </header>
            
            <article>
                
<ul>
<li>Information on installing the Azure CLI: <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest">https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest</a></li>
<li>Information on installing Docker Desktop: <a href="https://docs.docker.com/docker-for-windows/install/">https://docs.docker.com/docker-for-windows/install/</a></li>
<li>More information on Kubernetes: <a href="https://kubernetes.io/docs/home/">https://kubernetes.io/docs/home/</a></li>
<li>You can find more information regarding Azure Kubernetes at the following link: <a href="https://azure.microsoft.com/en-us/topic/what-is-kubernetes/">https://azure.microsoft.com/en-us/topic/what-is-kubernetes/</a></li>
<li>Information on Azure Container Registry: <a href="https://docs.microsoft.com/en-us/azure/container-registry/container-registry-intro">https://docs.microsoft.com/en-us/azure/container-registry/container-registry-intro</a></li>
<li>More information regarding multi-stage builds: <a href="https://docs.docker.com/develop/develop-images/multistage-build/">https://docs.docker.com/develop/develop-images/multistage-build/</a></li>
</ul>


            </article>

            
        </section>
    </body></html>