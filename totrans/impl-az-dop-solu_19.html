<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Assessments</h1>
                </header>
            
            <article>
                


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 1</h1>
                </header>
            
            <article>
                
<ol>
<li>True. In traditional organizations, development is often tasked with creating changes to software, while operations is responsible for maintaining the stability of the target systems for these changes. Since changes inherently carry risk and may disturb stability, operations is often resistant to change.</li>
<li>False. While, in theory, it is possible to practice the different DevOps practices in isolation from on another, the real value comes from combining them. For example, continuous deployment without continuous integration and test automation does not only make very little sense; it is even dangerous to continuously deploy changes without the quality assurances that continuous integration and test automation offer.</li>
<li>The incorrect answer is number 4. DevOps is not a job title, but a cultural movement. Actually, creating a new DevOps team in between development and operations is often at loggerheads with the DevOps philosophy. Instead of two teams or departments with their separate goals, there are now three.</li>
<li>Fastlaning is an approach to expediting unplanned, high-priority work over planned work, all while maintaining a single sprint board for the whole team.</li>
<li>There are many definitions of DevOps. Some of the main elements that are frequently included are business value, end users, continuous deployment, automation, and collaboration.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 2</h1>
                </header>
            
            <article>
                
<ol>
<li>The main difference between centralized and decentralized source control is that in a decentralized source control system, every user of the system has the full history of the sources. In a centralized system, only the server has the full history. Decentralized systems work best when working disconnected from the server, whereas centralized systems often allow for more detailed access control.</li>
<li>True. Git is the best known decentralized source control system.</li>
<li>The correct answer is number 3. Rebasing is not a branching strategy, but a merging strategy.</li>
</ol>
<ol start="4">
<li>When working with Git, a pull request is used to request the merging of changes from one branch with another. Pull requests can be reviewed, approved, or denied. To enforce the use of pull requests, Git policies can be used.</li>
<li>The correct answer is number 2. Trunk-based development is not a merging strategy, but a branching strategy.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 3</h1>
                </header>
            
            <article>
                
<ol>
<li>False. Continuous integration is about integrating the work of every developer with that of their colleagues at least daily and building and testing the integrated sources. Just running a daily build does not constitute continuous integration.</li>
<li>True. A classic build pipeline is always connected to a source code repository. It might be that the sources are not used in the build pipeline, but the connection is always there.</li>
<li>False. It is possible to create a YAML pipeline that starts directly with a stage. A link to a source control repository is no longer mandatory.</li>
<li>The correct answer is number 1: a service connection. Service connections are configured in the organization or project that contains the pipeline that needs to call into the external tool. Once a service connection is configured, it can be used from one or more pipelines.</li>
<li>The correct answers are numbers 1 and 3: access to closed networks and the ability to install extra software. Self-hosted agents are deployed on infrastructure owned by you. This means that you can deploy them on networks that you control, giving them network access to that network. Since the agents are deployed on your infrastructure, you can also decide on which software is installed (and which is not). Tasks and extension tasks are automatically downloaded to the agent before it executes a job. You can have as many parallel pipelines as you want without using self-hosted agents. However, you will need to buy extra parallel executions from Microsoft for this purpose.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 4</h1>
                </header>
            
            <article>
                
<ol>
<li>False. It is also possible to trigger a new release on a schedule or manually.</li>
<li>All of the answers are correct.</li>
<li>Numbers 2 and 3 are correct. Both ring-based deployments and canary deployments expose only a limited group of users to the new version of your application. Feature toggles are also used for progressive exposure, but are not used to limit the risks of a deployment but that of a new feature release.</li>
</ol>
<ol start="4">
<li>True. Deployment groups are used to perform tasks from a release pipeline not on one agent in the group, but on all agents. Deployment groups are intended to be used to deploy software on the machine that is also running the agent.</li>
<li>One possible advantage is that end-to-end traceability of all steps is retained in Azure DevOps. If you also manage your work items and source code in Azure DevOps, you will keep end-to-end traceability from the work item to release within Azure DevOps, and all this while still using the App Center for actual deployments.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 5</h1>
                </header>
            
            <article>
                
<ol>
<li>False. A version of a package can be visible in more than one view.</li>
<li>False. Pipeline artifacts can only be consumed from within other pipelines within Azure DevOps.</li>
<li>True. Azure Artifact feeds can be used to share universal packages to other products. This allows you to compile an application in Azure DevOps, upload the binaries as a universal package, and download it again in another product. This is useful when using another deployment tool, for example, Octopus Deploy.</li>
<li>The correct answers are numbers 2 and 4. Answer number 1 is incorrect since the package references (either in a <kbd>.csproj</kbd> file or in a <kbd>nuget.config</kbd> file) should only reference packages by name and version. Answer number 3 is incorrect since <kbd>consumer</kbd> is not a valid access level in Azure Artifact feeds. The correct access level is reader (or higher), making answer number 2 correct. Answer number 4 is also correct. You need to add the package location to your NuGet configuration.</li>
<li>One motivator can be the size of the solution. If compiling and testing the solution is taking so long that developers have to wait for feedback in relation to their work, it can be better to split the solution into smaller parts. This will shorten the feedback loop for developers, thereby increasing speed. Another motivator can be that multiple teams are working on an application and they want to increase the amount of isolation between teams.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 6</h1>
                </header>
            
            <article>
                
<ol>
<li>True. ARM templates allow you to specify the end state for all resources in an Azure resource group. Applying an ARM template will always result in the creation of missing resources and updates for existing resources. If a deployment mode of <kbd>complete</kbd> is specified, even resources not in the template will be removed.</li>
<li>The correct answer is number 2. Modules, Run As accounts, and variables are all constructs that were discussed in <a href="d981a2b6-8bf4-4fb7-8a2e-ceff84691588.xhtml">Chapter 6</a>, <em>Infrastructure and Configuration as Code</em>.</li>
<li>False. ARM template parameters allow the referencing of values in an Azure Key Vault, so as to prevent users from having to enter secrets or other sensitive information in source control. At the time of deployment, the secrets are retrieved and used within Azure, provided the identity that starts the operation has access to that key vault.</li>
<li>True. You can define one or more schedules within an Azure Automation Account and then link these to a Runbook.</li>
<li>Many benefits can be expected when practicing infrastructure as code. Two oft cited examples are the prevention of configuration drift and the ability to create new environments on demand. Configuration drift is prevented by reapplying the same infrastructure specification to an environment at a schedule. Environments on demand can be used to quickly create a new test environment, performing tests and then removing the environment again. This allows for more repeatable test results and, possibly, savings in terms of testing infrastructure.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 7</h1>
                </header>
            
            <article>
                
<ol>
<li>True. Entity Framework and Entity Framework Core both have built-in support to generate a migration after changes to the schema definition have been made.</li>
<li>False. Most migration-based approaches use an extra table to keep track of which migrations have already been applied to the database.</li>
<li>True. End state-based approaches work by comparing the current schema to the target schema. This results in the generation of a one-time SQL script that is run against the database to update the schema. There is no state stored between runs.</li>
</ol>
<ol start="4">
<li>The correct answers are numbers 1 and 2. Running side by side, if done correctly, reduces change risks dramatically. If there are issues, you can always remove all new code, along with the database copy, and restart afresh from a working situation. Having both situations working correctly also allows for very precise performance measurements regarding the production workload. However, one of the disadvantages is that the cycle time is actually very likely to increase. You have to move multiple smaller changes to production one by one, which increases the total time taken.</li>
<li>False. Your schema (either implicit or captured in data objects) still changes. However, this only becomes visible when reading an object back from the database that was persisted with a previous version of the object. In essence, you are only delaying coping with the issue of schema changes.</li>
<li>You can choose to not use database-level coding techniques, such as stored procedures and triggers. The more of your logic you capture outside of the database, the smaller the total number of database changes you have to make.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 8</h1>
                </header>
            
            <article>
                
<ol>
<li>True. In a unit test, a individual component is tested in isolation. In an object-oriented language, this is often a single class.</li>
<li>False. In an integration test, the correct working of a group of components is verified, and not the entire assembled system. If the entire assembled and deployed system is tested, this is referred to as a system test.</li>
<li>Answer number 2 is correct. The testing pyramid prescribes a large set of unit tests that verify as many requirements as possible. Integration tests are added only for those risks that cannot be covered using unit tests, resulting in a lower number of integration tests. Even fewer system tests are added, only to cover the risks not covered by either unit or integration tests.</li>
<li>Answer number 3 is correct. All other types of testing are covered in this chapter.</li>
<li>Two techniques that can be mentioned here are code reviews and pipeline gates. Code reviews allow developers to review the work of their colleagues to help each other keep quality high. Pipeline gates can be used to not allow a build or version of an application to propagate further down a pipeline if certain conditions are not met. Example conditions can include certain quality metrics, or minimum standards for test coverage or test results.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 9</h1>
                </header>
            
            <article>
                
<ol>
<li>False. To securely create and deliver software, the whole process, and especially the pipeline, needs to be secured. Just adding security at the end will not work, as security has to be woven through all different steps of the delivery process.</li>
<li>The OWASP <strong>Zed Attack Proxy</strong> (<strong>ZAP</strong>) can be used for this type of testing.</li>
<li>True. In modern applications, up to 80% of the code can be from open source libraries or frameworks.</li>
<li>The correct answers are 1, 2, 4, and 6. There is no such thing as Azure DevOps Secure Variables or Azure DevOps Key Vault.</li>
<li>Azure Policy can be used to prohibit or list undesired Azure configurations, often relating to infrastructure provisioning or configuration. Azure Security Center can be used to identify and remediate runtime security risks.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 10</h1>
                </header>
            
            <article>
                
<ol>
<li>False. The platform metrics that are emitted by Azure are defined by every individual service and cannot be changed.</li>
<li>93 days. This number guarantees that there is always at least 3 months of history.</li>
<li>True. Custom metrics can be calculated in your own application code and emitted to Application Insights through the SDK or REST API.</li>
<li>Alert fatigue.</li>
<li>True. Azure allows for the creation of action groups that can contain webhooks to be called in response to an alert being raised.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 11</h1>
                </header>
            
            <article>
                
<ol>
<li>False. One possible downside is losing a competitive edge in the market. If competitors know what you are going to develop next, they may anticipate in that regard.</li>
<li>Possible concerns are that some users or groups of users are more vocal than others, which might result in a difference between the general opinion and the opinion that is heard. Also, feedback on a public roadmap is most likely coming from existing users only. While it is important to retain those, prospects might not comment on your roadmap with features they are missing.</li>
<li>Two examples that are discussed in this chapter are sentiment on social media channels and the number and severity of support requests.</li>
</ol>
<ol start="4">
<li>Answer number 3 is correct. A hypothesis states a belief that a certain feature is needed – the hypothesis. The second part is a measurable user response that is to be observed before the belief is confirmed. This is called the confirmation threshold. A hypothesis does not yet have a conclusion.</li>
<li>Possible benefits of user interviews or focus groups are that they are often conducted at a smaller scale, allowing not only for the measuring of feedback, but for also understanding the reasons behind it. Another benefit is that participants can be carefully selected to be representative of all users or a particular segment.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 12</h1>
                </header>
            
            <article>
                
<ol>
<li>The benefits of containers for DevOps are consistency, the separation of concerns, and platform portability.</li>
<li>True: Depending on the host operating system, it does not matter where the container is hosted.</li>
<li>Yes, this is possible. This can be done by adding Docker support and a project level.</li>
<li>The <kbd>RUN</kbd> command is used for the installation of components or for performing operations during the process of building the container image.</li>
<li>Nods and pods can be scheduled within Azure Kubernetes Service. Both of these components can be scaled manually or automatically.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chapter 13</h1>
                </header>
            
            <article>
                
<ol>
<li>False. Some information can travel to other regions or is available globally. For example, sometimes, agents are running in other regions when capacity in the chosen region is low.</li>
<li><span class="packt_screen">Work item</span> | <span class="packt_screen">Project</span> | <span class="packt_screen">Organization</span> | <span class="packt_screen">Region</span>. An Azure DevOps organization is the top-level construct that can be created by users. Every organization is in precisely one region, which is maintained by Microsoft. Within an organization, one or more projects can be created. In turn, a project can contain many work items, such as user stories, features, or epics.</li>
<li>False. The general recommendation is to have just enough projects: the fewer the better. Isolation and very strict authorization boundaries may be reasons for choosing to use multiple projects.</li>
</ol>
<ol start="4">
<li>Authorizations and licensing. Authorizations can be set up to the limit that can be accessed by every individual user or a group of users. The license assigned to a user can also prohibit the use of certain features. For example, users with a stakeholder licence cannot work with source control.</li>
<li>End-to-end traceability. When executing work management, source control, building, artifacts, and deployments from a single tool, it is possible to trace the deployment in which a user story was delivered to users.</li>
</ol>


            </article>

            
        </section>
    </body></html>