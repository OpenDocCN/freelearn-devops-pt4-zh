- en: Deploying Ceph with Containers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用容器部署 Ceph
- en: Once you have planned your Ceph project and are ready to deploy either a test
    or production cluster, you will need to consider the method you wish to use to
    both deploy and maintain it. This chapter will demonstrate how to quickly deploy
    test environments for testing and development by the use of Vagrant. It will also
    explain why you might want to consider using an orchestration tool to deploy Ceph
    rather than using the supplied Ceph tools. As a popular orchestration tool, Ansible
    will be used to show how quickly and reliably a Ceph cluster can be deployed and
    the advantages that using it can bring.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你规划好 Ceph 项目，并准备好部署测试或生产集群，你需要考虑部署和维护的方式。本章将演示如何通过使用 Vagrant 快速部署用于测试和开发的测试环境。同时，也会解释为何你可能希望使用编排工具来部署
    Ceph，而不是使用 Ceph 自带的工具。作为一个流行的编排工具，本书将使用 Ansible 展示如何快速可靠地部署 Ceph 集群，并说明使用它的优势。
- en: 'In this chapter, we will learn the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习以下内容：
- en: How to prepare a testing environment with Vagrant and VirtualBox
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 Vagrant 和 VirtualBox 准备测试环境
- en: The differences between Ceph's deploy and orchestration tools
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ceph 的部署和编排工具之间的区别
- en: The advantages over using orchestration tools
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相较于使用编排工具的优势
- en: How to install and use Ansible
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何安装和使用 Ansible
- en: How to configure Ceph Ansible modules
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何配置 Ceph Ansible 模块
- en: How to deploy a test cluster with Vagrant and Ansible
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 Vagrant 和 Ansible 部署测试集群
- en: Ideas concerning how to manage your Ceph configuration
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何管理 Ceph 配置的想法
- en: What the Rook project is and what it enables a Ceph operator to do
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rook 项目是什么，它使 Ceph 操作员能做什么
- en: How to deploy a basic Kubernetes cluster
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何部署基本的 Kubernetes 集群
- en: How to use Rook to deploy Ceph on Kubernetes
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 Rook 在 Kubernetes 上部署 Ceph
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In order to be able to run the Ceph environment described later in this chapter,
    it''s important that your computer meets a number of requirements to ensure that
    the VM can be provided with sufficient resources. These requirements are as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够运行本章后续描述的 Ceph 环境，确保计算机满足一定的要求是很重要的，以便为虚拟机提供足够的资源。具体要求如下：
- en: Operating system compatible with Vagrant and VirtualBox, including Linux, macOS,
    and Windows
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 兼容 Vagrant 和 VirtualBox 的操作系统，包括 Linux、macOS 和 Windows
- en: 2-core CPU
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 核 CPU
- en: 8 GB ram
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 8 GB 内存
- en: Virtualization instructions enabled in the BIOS
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 BIOS 中启用虚拟化指令
- en: Preparing your environment with Vagrant and VirtualBox
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Vagrant 和 VirtualBox 准备你的环境
- en: While a test cluster can be deployed on any hardware or virtual machine, for
    the purposes of this book a combination of Vagrant and VirtualBox will be used.
    This will allow rapid provision of the virtual machines and ensure a consistent
    environment.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管可以在任何硬件或虚拟机上部署测试集群，但本书将使用 Vagrant 和 VirtualBox 的组合。这将快速提供虚拟机并确保环境的一致性。
- en: VirtualBox is a free and open source hypervisor currently being developed by
    Oracle; while its performance and features may be lacking compared to high-end
    hypervisors, its lightweight approach and multi-OS support lend itself to its
    being a prime candidate for testing.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: VirtualBox 是一个免费的开源虚拟机管理程序，目前由 Oracle 开发；虽然其性能和功能可能不如高端虚拟机管理程序，但其轻量级的方式和多操作系统支持使其成为测试的理想选择。
- en: Vagrant assists in allowing an environment that may comprise many machines to
    be created quickly and efficiently. It works with the concepts of boxes, which
    are predefined templates for use with hypervisors and its Vagrantfile, which defines
    the environment to be built. It supports multiple hypervisors and allows a Vagrantfile
    to be portable across them.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Vagrant 可以帮助快速高效地创建可能包含多台机器的环境。它基于 box 的概念，box 是为虚拟机管理程序预定义的模板，而 Vagrantfile
    则定义了要构建的环境。它支持多个虚拟机管理程序，并允许 Vagrantfile 在它们之间进行移植。
- en: How to install VirtualBox
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何安装 VirtualBox
- en: 'Consult the VirtualBox website for the appropriate method to install VirtualBox
    on your operating system: [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考 VirtualBox 网站，以获取适用于你操作系统的 VirtualBox 安装方法：[https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads)
- en: '![](img/6564aeef-931e-4d05-b30f-acb66cc210a0.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6564aeef-931e-4d05-b30f-acb66cc210a0.png)'
- en: How to set up Vagrant
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何设置 Vagrant
- en: 'Follow the installation instructions on Vagrant''s website to get Vagrant installed
    on your chosen OS: [https://www.vagrantup.com/downloads.html](https://www.vagrantup.com/downloads.html):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照 Vagrant 网站上的安装说明，在您选择的操作系统上安装 Vagrant：[https://www.vagrantup.com/downloads.html](https://www.vagrantup.com/downloads.html)：
- en: '![](img/f6af1621-45ce-48d8-8190-bb636a65824e.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f6af1621-45ce-48d8-8190-bb636a65824e.png)'
- en: Create a new directory for your Vagrant project, for example `ceph-ansible`
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为您的 Vagrant 项目创建一个新目录，例如 `ceph-ansible`
- en: 'Change to this directory and run the following commands:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换到此目录并运行以下命令：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](img/edc06af7-db73-43f5-9928-d5eb0fa179b5.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/edc06af7-db73-43f5-9928-d5eb0fa179b5.png)'
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](img/2d24df85-01f5-49bb-ab4c-19cd0a78f815.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2d24df85-01f5-49bb-ab4c-19cd0a78f815.png)'
- en: 'Now create an empty file called `Vagrantfile` and place the following into
    it:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在创建一个名为 `Vagrantfile` 的空文件，并将以下内容放入其中：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Run `vagrant up` to bring up the virtual machines defined in the `Vagrantfile`:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `vagrant up` 来启动 `Vagrantfile` 中定义的虚拟机：
- en: '![](img/dc46eff2-b018-4dbb-95ac-354e3a6c8d3e.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dc46eff2-b018-4dbb-95ac-354e3a6c8d3e.png)'
- en: 'Now, let''s `ssh` into one of them:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们 `ssh` 连接到其中一台虚拟机：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](img/3b09d065-1709-415a-9ab9-36540009fe10.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3b09d065-1709-415a-9ab9-36540009fe10.png)'
- en: If you are running `vagrant` on Windows, the `ssh` command will inform you that
    you need to use a SSH client of your choosing and provide the details to use with
    it. Putty would be a good suggestion for a SSH client. On Linux, the command will
    connect you straight onto the VM.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在 Windows 上运行 `vagrant`，`ssh` 命令会提醒您需要使用您选择的 SSH 客户端，并提供相关的使用信息。Putty 是一个不错的
    SSH 客户端建议。在 Linux 上，该命令会直接连接到虚拟机。
- en: 'The username and password are both `vagrant`. After logging in, you should
    find yourself at the bash prompt for the `ansible vm`:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 用户名和密码都是 `vagrant`。登录后，您应该看到 `ansible vm` 的 bash 提示符：
- en: '![](img/1726344c-a906-4a00-a609-2ddcb9fffd4a.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1726344c-a906-4a00-a609-2ddcb9fffd4a.png)'
- en: Simply type exit to return to your host machine.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 只需输入 exit 即可返回到您的主机。
- en: 'Congratulations, you have just deployed three servers for use as Ceph monitors,
    three servers for use as Ceph OSDs, and an Ansible server. The `Vagrantfile` could
    have also contained extra steps to execute commands on the servers to configure
    them but for now let''s shut down the servers; we can bring them back up when
    required by the examples later in this chapter:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您，您已经成功部署了三个 Ceph 监视器服务器，三个 Ceph OSD 服务器，以及一台 Ansible 服务器。`Vagrantfile` 还可以包含一些额外步骤，用于在服务器上执行命令进行配置，但现在我们先关闭这些服务器；当本章后续的示例需要时，我们可以重新启动它们：
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Ceph-deploy
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ceph-deploy
- en: Ceph-deploy is the official tool for deploying Ceph clusters. It works on the
    principle of having an admin node with password-less SSH access to all machines
    in your Ceph cluster; it also holds a copy of the Ceph configuration file. Every
    time you carry out a deployment action, it uses SSH to connect to your Ceph nodes
    to carry out the necessary steps. While the Ceph-deploy tool is an entirely supported
    method that will leave you with a perfectly functioning Ceph cluster, ongoing
    management of Ceph will not be as easy as desired.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Ceph-deploy 是官方的 Ceph 集群部署工具。它的工作原理是通过一个管理员节点，通过免密码 SSH 访问所有 Ceph 集群中的机器；并且该管理员节点还保存一份
    Ceph 配置文件。每次执行部署操作时，Ceph-deploy 工具会通过 SSH 连接到 Ceph 节点，执行必要的步骤。虽然 Ceph-deploy 工具是一个完全支持的方法，可以确保
    Ceph 集群功能正常，但 Ceph 的后续管理并不会像预期的那样简便。
- en: Larger-scale Ceph clusters will also cause a lot of management overhead if Ceph-deploy
    is used. For that reason, it is recommended that Ceph-deploy be limited to test
    or small-scale production clusters, although as you will see an orchestration
    tool allows for the rapid deployment of Ceph and is probably better suited for
    test environments where you might need to continually be building new Ceph clusters.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用 Ceph-deploy 来管理大规模的 Ceph 集群，会增加很多管理开销。因此，建议将 Ceph-deploy 限制在测试或小规模的生产集群中，尽管正如您所看到的，编排工具可以快速部署
    Ceph，并且可能更适合用于测试环境，尤其是当您需要不断构建新的 Ceph 集群时。
- en: Orchestration
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编排
- en: 'One solution to make installing and managing Ceph easier is to use an orchestration
    tool. There are several tools available, such as Puppet, Chef, Salt, and Ansible,
    all of which have Ceph modules available. If you are already using an orchestration
    tool in your environment, then it is recommended that you stick to using that
    tool. For the purposes of this book, Ansible will be used. This is due a number
    of reasons, as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让安装和管理Ceph更容易的一个解决方案是使用编排工具。现在有多种可用的工具，如Puppet、Chef、Salt和Ansible，这些工具都有Ceph模块可用。如果你在环境中已经使用了编排工具，建议继续使用该工具。本书将使用Ansible，原因如下：
- en: It's the deployment method that is favored by Red Hat, who are the owners of
    both the Ceph and Ansible projects
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是Red Hat偏爱的部署方法，Red Hat是Ceph和Ansible项目的拥有者。
- en: It has a well-developed, mature set of Ceph roles and playbooks
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它拥有一套成熟且完备的Ceph角色和剧本。
- en: Ansible tends to be easier to learn if you have never used an orchestration
    tool before
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你以前从未使用过编排工具，Ansible往往更容易学习。
- en: It doesn't require a central server to be set up, which means demonstrations
    are more focused on using the tool than installing it
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不需要设置中央服务器，这意味着演示更专注于使用工具，而不是安装工具。
- en: All tools follow the same principle, where you provide them with an inventory
    of hosts and a set of tasks to be carried out on the hosts. These tasks often
    reference variables that allow customization of the task at runtime. Orchestration
    tools are designed to be run on a schedule so that, if for any reason the state
    or configuration of a host changes, it will be correctly changed back to the intended
    state during the next run.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 所有工具遵循相同的原则，即提供主机清单和要在主机上执行的任务集。这些任务通常引用变量，允许在运行时定制任务。编排工具设计为按计划运行，这样，如果由于某种原因主机的状态或配置发生变化，在下一次运行时将会正确地恢复到预定状态。
- en: Another advantage of using orchestration tools is documentation. While they
    are not a replacement for good documentation, the fact that they clearly describe
    your environment, including roles and configuration options, means that your environment
    starts to become self-documenting. If you ensure that any installations or changes
    are carried out via your orchestration tool, then the configuration file of the
    orchestration tool will clearly describe the current state of your environment.
    If this is combined with something such as a Git repository to store the orchestration
    configuration, you have the makings of a change control system. This is covered
    in more detail later in this chapter. The only disadvantages center around the
    extra time it takes to carry out the initial setup and configuration of the tool.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用编排工具的另一个优点是文档管理。虽然它们不能替代良好的文档，但它们清晰地描述了你的环境，包括角色和配置选项，这意味着你的环境开始自带文档功能。如果确保通过编排工具执行任何安装或更改，编排工具的配置文件将清晰地描述你环境的当前状态。如果将其与Git仓库等存储编排配置的工具结合使用，你就能拥有一个变更控制系统。本章稍后将更详细地介绍这一点。唯一的缺点是需要花费额外的时间来完成工具的初始设置和配置。
- en: So, by using an orchestration tool, not only do you get a faster and less error-prone
    deployment, you also get documentation and change management for free. If you
    haven't got the hint by now, this is something you should really be looking at.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过使用编排工具，你不仅能够实现更快速、出错率更低的部署，还能免费获得文档和变更管理。如果你现在还没有意识到这一点，这正是你应该关注的内容。
- en: Ansible
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ansible
- en: As mentioned earlier, Ansible will be the orchestration tool of choice for this
    book, so let's look at it in a bit more detail.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Ansible将是本书首选的编排工具，让我们更详细地了解它。
- en: Ansible is an agent-less orchestration tool written in Python that uses SSH
    to carry out configuration tasks on remote nodes. It was first released in 2012,
    has gained widespread adoption, and is known for its ease of adoption and low
    learning curve. Red Hat purchased the commercial company Ansible Inc. in 2015
    and so has a very well developed and close-knit integration for deploying Ceph.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Ansible是一个无代理的编排工具，用Python编写，通过SSH在远程节点上执行配置任务。它首次发布于2012年，已广泛采用，且因其易于采用和学习曲线低而著名。Red
    Hat在2015年收购了Ansible公司，因此为部署Ceph提供了一个高度开发且紧密集成的方案。
- en: Files called playbooks are used in Ansible to describe a list of commands, actions,
    and configurations to be carried out on specified hosts or groups of hosts and
    are stored in the `yaml` file format. Instead of having large unmanageable playbooks,
    Anisble roles can be created to allow a playbook to contain a single task, which
    may then carry out a number of tasks associated with the role.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Ansible 中，名为 playbooks 的文件用于描述要在指定的主机或主机组上执行的命令、操作和配置，并存储在 `yaml` 文件格式中。为了避免出现大型且难以管理的
    playbooks，可以创建 Ansible 角色，以便让 playbook 包含单个任务，该任务可以执行与该角色相关的多个操作。
- en: The use of SSH to connect to remote nodes and execute playbooks means that it
    is very lightweight and does not require either an agent or a centralized server.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SSH 连接到远程节点并执行 playbooks 意味着它非常轻量，不需要代理或中央服务器。
- en: For testing Ansible also integrates well with Vagrant; an Ansible playbook can
    be specified as part of the Vagrant provisioning configuration and will automatically
    generate an inventory file from the VMs Vagrant that has been created and will
    run the playbook once the servers have booted. This allows a Ceph cluster, including
    its OS, to be deployed via just a single command.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试，Ansible 还可以与 Vagrant 很好地集成；可以将 Ansible playbook 作为 Vagrant 配置的一部分指定，并且
    Vagrant 会自动生成一个来自已创建虚拟机的清单文件，并在服务器启动后运行 playbook。这允许通过一个简单的命令部署一个包含其操作系统的 Ceph
    集群。
- en: Installing Ansible
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 Ansible
- en: 'You''ll bring your Vagrant environment you created earlier back up that and
    ssh onto the Ansible server. For this example only `ansible`, `mon1`, and `osd1`
    will be needed:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 你将把之前创建的 Vagrant 环境恢复，并通过 SSH 登录到 Ansible 服务器。对于这个示例，只需要 `ansible`、`mon1` 和
    `osd1`：
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Add the Ansible PPA:'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加 Ansible PPA：
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**![](img/feb347d6-a7f2-4501-9912-779f3cec60de.png)**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**![](img/feb347d6-a7f2-4501-9912-779f3cec60de.png)**'
- en: 'Update `apt-get` sources and install Ansible:'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新 `apt-get` 源并安装 Ansible：
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**![](img/f52965dc-038e-4003-a0a7-608c0566d546.png)**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**![](img/f52965dc-038e-4003-a0a7-608c0566d546.png)**'
- en: Creating your inventory file
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建你的清单文件
- en: The Ansible inventory file is used by Ansible to reference all known hosts and
    specify which group they belong to. A group is defined by placing its name in
    square brackets; groups can be nested inside other groups by the use of the children
    definition.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Ansible 清单文件用于 Ansible 引用所有已知主机并指定它们所属的组。通过将组名放入方括号中来定义一个组；组可以通过使用 children
    定义在其他组内进行嵌套。
- en: 'Before we add hosts to the inventory file, we first need to configure the remote
    nodes for password-less SSH, otherwise we will have to enter a password every
    time Ansible tries to connect to a remote machine as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将主机添加到清单文件之前，我们首先需要配置远程节点以实现无密码 SSH，否则每次 Ansible 尝试连接到远程机器时，我们都需要输入密码，如下所示：
- en: 'Generate a SSH key:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成 SSH 密钥：
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](img/1c87f1a8-3433-4066-be27-7ca9cf6b493d.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1c87f1a8-3433-4066-be27-7ca9cf6b493d.png)'
- en: 'Copy the key to the remote hosts:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将密钥复制到远程主机：
- en: '[PRE9]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](img/c79eb509-7219-4122-9c33-a11fff81774b.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c79eb509-7219-4122-9c33-a11fff81774b.png)'
- en: This will need to be repeated for each host. Normally, you would include this
    step in your Vagrant provisioning stage, but it is useful to carry out these tasks
    manually the first couple of times, so that you understand the process.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要对每个主机重复执行。通常，你会在 Vagrant 配置阶段包括此步骤，但手动执行这些任务几次是有用的，这样你可以理解整个过程。
- en: 'Now try logging in to the machine with: `ssh mon1`:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试通过 `ssh mon1` 登录到机器：
- en: '![](img/b3f98e3b-11a6-4111-aaa1-acdce0d9343a.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b3f98e3b-11a6-4111-aaa1-acdce0d9343a.png)'
- en: 'Type `exit` to return to the Ansible VM. Now let''s create the `Ansible` inventory
    file. Edit the file called `hosts` in `/etc/ansible`:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 输入 `exit` 返回到 Ansible 虚拟机。现在让我们创建 `Ansible` 清单文件。编辑 `/etc/ansible` 中名为 `hosts`
    的文件：
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Create three groups called `osds, mgrs`, and `mons` and finally a fourth group
    called `ceph`. This fourth group will contain the `osds` and `mons` groups as
    children.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 创建三个组，分别命名为 `osds`、`mgrs` 和 `mons`，然后创建一个第四个组，命名为 `ceph`。这个第四组将包含 `osds` 和 `mons`
    作为子组。
- en: 'Enter a list of your hosts under the correct group:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在正确的组下输入主机列表：
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Variables
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变量
- en: Most playbooks and roles will make use of variables, which can be overridden
    in several ways. The simplest way is to create files in the `host_vars` and `groups_vars`
    folders; these allow you to override variables either based on the host or group
    membership, respectively.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 playbooks 和角色将使用变量，这些变量可以通过多种方式覆盖。最简单的方法是创建 `host_vars` 和 `groups_vars`
    文件夹中的文件；这些文件允许你基于主机或组成员身份分别覆盖变量。
- en: 'Create a `/etc/ansible/group_vars` directory. Create a file in `group_vars`
    called `mons` and place the following inside it:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个`/etc/ansible/group_vars`目录。在`group_vars`中创建一个名为`mons`的文件，并将以下内容放入其中：
- en: '`a_variable: "foo"`'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`a_variable: "foo"`'
- en: 'Create a file in `group_vars` called `osds` and place the following inside
    it:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在`group_vars`中创建一个名为`osds`的文件，并将以下内容放入其中：
- en: '`a_variable: "bar"`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`a_variable: "bar"`'
- en: Variables follow a precedence order; you can also create an `all` file which
    will apply to all groups. However, a variable of the same name that is in a more
    specific matching group will override it. Ceph Ansible modules make use of this
    to allow you to have a set of default variables and then specify different values
    for the specific roles.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 变量遵循优先级顺序；你还可以创建一个`all`文件，该文件将应用于所有组。然而，如果同名的变量出现在一个更具体的匹配组中，它将覆盖该`all`文件中的变量。Ceph
    Ansible模块利用这一点，使你能够拥有一组默认变量，并为特定角色指定不同的值。
- en: Testing
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试
- en: 'To verify that Ansible is working correctly and that we can successfully connect
    and run commands remotely, let''s use ping with Ansible to check one of our hosts.
    Note: this is not like a network ping; Ansible''s ping confirms that it can communicate
    via SSH and execute commands remotely:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证Ansible是否正常工作，并确保我们能够成功远程连接并执行命令，让我们使用ping命令与Ansible检查我们的一个主机。注意：这与网络ping不同；Ansible的ping命令确认它可以通过SSH通信并远程执行命令：
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](img/fe8b4d00-26a0-419f-ae9a-de2165321a9f.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fe8b4d00-26a0-419f-ae9a-de2165321a9f.png)'
- en: 'Excellent, that worked. Now let''s run a simple command remotely to demonstrate
    Ansible''s capabilities. The following command will retrieve the currently running
    kernel version on the specified remote node:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 很棒，成功了。现在让我们运行一个简单的远程命令来展示Ansible的功能。以下命令将检索指定远程节点当前运行的内核版本：
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](img/b8815f88-f9ce-4d8b-b952-85b81e107536.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b8815f88-f9ce-4d8b-b952-85b81e107536.png)'
- en: A very simple playbook
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个非常简单的playbook
- en: 'To demonstrate how playbooks works, the following example will showcase a small
    playbook that also makes use of the variables we configured earlier:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示playbook是如何工作的，以下示例将展示一个小的playbook，它也使用了我们之前配置的变量：
- en: '[PRE14]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'And now run the playbook. Notice that the command to run a playbook differs
    from running ad hoc Ansible commands:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 然后运行playbook。请注意，运行playbook的命令与运行临时Ansible命令不同：
- en: '[PRE15]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**![](img/ee0095ec-b237-4767-b8c8-3925cf90aa4e.png)**'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**![](img/ee0095ec-b237-4767-b8c8-3925cf90aa4e.png)**'
- en: The output shows the playbook being executed on both `mon1` and `osd1` as they
    are in groups, which are children of the parent group, Ceph. Also note how the
    output of the two servers is different as they pick up the variables that you
    set earlier in the `group_vars` directory.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了在`mon1`和`osd1`上执行的playbook，它们属于组的成员，这些组是父组Ceph的子组。同时注意输出中两个服务器的不同之处，因为它们会根据你之前在`group_vars`目录中设置的变量来处理。
- en: 'Finally, the last couple of lines show the overall run status of the playbook
    run. You can now destroy your `Vagrant` environment again, ready for the next
    section:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，最后几行显示了playbook运行的整体状态。现在你可以再次销毁你的`Vagrant`环境，为下一部分做准备：
- en: '[PRE16]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This concludes the introduction to Ansible, but is no means meant to be a complete
    guide. It's recommended that you explore other resources to gain a more in-depth
    knowledge of Ansible before using it in a production environment.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是Ansible介绍的结束，但这并不意味着它是一本完整的指南。建议在将其用于生产环境之前，先深入了解其他资源，以获得对Ansible的更全面的理解。
- en: Adding the Ceph Ansible modules
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加Ceph Ansible模块
- en: 'We can use Git to clone the Ceph Ansible repository, as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Git来克隆Ceph Ansible仓库，如下所示：
- en: '[PRE17]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](img/b937eb3f-be81-431e-8677-68134760b576.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b937eb3f-be81-431e-8677-68134760b576.png)'
- en: 'We also need to install a few extra packages that `ceph-ansible` requires:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要安装一些`ceph-ansible`所需要的额外软件包：
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](img/5c0c8b9d-406f-4358-bf86-cc6d87520c83.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5c0c8b9d-406f-4358-bf86-cc6d87520c83.png)'
- en: '[PRE19]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](img/faceecf7-55ad-4338-b0db-b7f1e5af013e.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/faceecf7-55ad-4338-b0db-b7f1e5af013e.png)'
- en: 'Let''s also explore some key folders in the Git repository:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们还探讨一下Git仓库中的一些关键文件夹：
- en: '`group_vars`: We''ve already covered what lives here and will explore possible
    configuration options in more detail later'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`group_vars`：我们已经介绍了这里存放的内容，并将在稍后更详细地探讨可能的配置选项'
- en: '`infrastructure-playbooks`: This directory contains pre-written playbooks to
    carry out some standard tasks, such as deploying clusters or adding OSDs to an
    existing one. The comments at the top of the playbooks give a good idea of what
    they do.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`infrastructure-playbooks`：此目录包含预先编写的playbook，用于执行一些标准任务，例如部署集群或向现有集群中添加OSD。playbook顶部的注释很好地说明了它们的作用。'
- en: '`roles`: This directory contains all the roles that make up the Ceph Ansible
    modules. You will see that there is a role for each Ceph component; these are
    called via playbooks to install, configure, and maintain Ceph.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roles`：此目录包含构成 Ceph Ansible 模块的所有角色。你会看到每个 Ceph 组件都有一个角色；这些角色通过 playbook 被调用，以便安装、配置和维护
    Ceph。'
- en: 'In order to be able to deploy a Ceph cluster with Ansible, a number of key
    variables need to be set in the `group_vars` directory. The following variables are required
    to be set; alternatively, it''s recommended you change them from their defaults.
    For the remaining variables, it suggested that you read the comments in the variable
    files. Key global variables include the following:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够使用 Ansible 部署 Ceph 集群，需要在 `group_vars` 目录中设置若干关键变量。以下变量是必需设置的；另外，建议你修改它们的默认值。对于其余变量，建议你阅读变量文件中的注释。关键的全局变量包括以下内容：
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'These control what group name modules use to identify the Ceph host types.
    If you will be using Ansible in a wider setting, it might be advisable to prepend
    `ceph-` to the start to make it clear that these groups are related to Ceph:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这些控制模块使用什么组名称来识别 Ceph 主机类型。如果你将在更广泛的环境中使用 Ansible，建议在组名前加上 `ceph-`，以明确这些组与 Ceph
    相关：
- en: '[PRE21]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Employ the `''upstream''` setting to use packages generated by the Ceph team,
    or `distro` for packages generated by your distribution maintainer. The former
    is recommended if you want to be able to upgrade Ceph independently of your distribution:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `'upstream'` 设置来使用 Ceph 团队生成的包，或使用 `distro` 设置来使用分发版维护者生成的包。如果你希望能够独立于你的分发版升级
    Ceph，建议使用前者：
- en: '[PRE22]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'By default, a `fsid` will be generated for your cluster and stored in a file
    where it can be referenced again. You shouldn''t need to touch this unless you
    want control over the `fsid` or you wish to hardcode the `fsid` in the group variable
    file:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`fsid` 会为你的集群生成并存储在一个文件中，以便以后可以再次引用。除非你希望控制 `fsid` 或将 `fsid` 硬编码到组变量文件中，否则你不需要修改它：
- en: '[PRE23]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'One of the preceding commands should be specified. If you are using a variable
    in `group_vars` then you probably want to use `monitor_interface`, which is the
    interface name in Linux, as they will probably be the same across all `mons`.
    Otherwise if you specify `monitor_address` in `host_vars`, you can specify the
    IP of the interface, which obviously will be different across your three or more
    `mons`:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 应指定上述命令之一。如果你在 `group_vars` 中使用了变量，那么你可能希望使用 `monitor_interface`，这是 Linux 中的接口名称，通常在所有
    `mons` 中是相同的。否则，如果你在 `host_vars` 中指定了 `monitor_address`，你可以指定接口的 IP，显然，在三个或更多
    `mons` 中它们会有所不同：
- en: '[PRE24]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Not every Ceph variable is directly managed by Ansible, but the preceding variable
    is provided to allow you to pass any extra variables through to the `ceph.conf`
    file and its corresponding sections. An example of how this would look follows
    (notice the indentation):'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 并非每个 Ceph 变量都由 Ansible 直接管理，但提供了上述变量，以便你可以将任何额外的变量传递给 `ceph.conf` 文件及其对应的部分。以下是如何实现的示例（请注意缩进）：
- en: '[PRE25]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Key variables from the OSD variable file are as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: OSD 变量文件中的关键变量如下：
- en: '[PRE26]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'If you want to be able to manage your cluster from your OSD nodes instead of
    just your monitors, set this to `true`, which will copy the admin key to your
    OSD nodes:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望能够从 OSD 节点而不仅仅是从监视节点管理你的集群，将此设置为 `true`，这将把管理员密钥复制到你的 OSD 节点：
- en: '[PRE27]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: These are probably the most crucial set of variables in the entire configuration
    of Ansible. They control what disks get used as OSDs and how journals are placed.
    You can either manually specify the devices that you wish to use as OSDs or you
    can use auto discovery. The examples in this book use static device configuration.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可能是整个 Ansible 配置中最关键的一组变量。它们控制哪些磁盘被用作 OSD 以及日志的位置。你可以手动指定你希望用作 OSD 的设备，或者使用自动发现。本书中的示例使用的是静态设备配置。
- en: The `journal_collocation` variable sets whether you want to store the journal
    on the same disk as the OSD data; a separate partition will be created for it.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`journal_collocation` 变量设置是否希望将日志存储在与 OSD 数据相同的磁盘上；将为其创建一个单独的分区。'
- en: '`raw_journal_devices` allows you to specify the devices you wish to use for
    journals. Quite often, a single SSD will be a journal for several OSDs; in this
    case, enable `raw_multi_journal` and simply specify the journal device multiple
    times; no partition numbers are needed if you want Ansible to instruct ceph-disk
    to create them for you.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`raw_journal_devices`允许你指定希望用作日志的设备。通常，一个单独的SSD会作为多个OSD的日志；在这种情况下，启用`raw_multi_journal`，并简单地多次指定日志设备；如果你希望Ansible指示ceph-disk为你创建它们，则不需要指定分区号。'
- en: These are the main variables that you should need to consider; it is recommended
    you read the comments in the variable files to see if there are any others you
    may need to modify for your environment.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是你应该考虑的主要变量；建议你阅读变量文件中的注释，查看是否有其他变量需要根据你的环境进行修改。
- en: Deploying a test cluster with Ansible
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Ansible部署测试集群
- en: There are several examples on the internet that contain a fully configured `Vagrantfile`
    and associated Ansible playbooks; this allows you to bring up a fully functional
    Ceph environment with just one command. As handy as this may be, it doesn't help
    you learn how to correctly configure and use the Ceph Ansible modules as you would
    if you were deploying a Ceph cluster on real hardware in a production environment.
    As such, this book will guide you through configuring Ansible from the start,
    even though it's running on Vagrant provisioned servers. Its important to note
    that, like Ceph itself, Ansible playbooks are constantly changing and therefore
    it is recommended that you review the `ceph-ansible` documentation for any breaking
    changes.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 网上有多个示例，包含完全配置的`Vagrantfile`和相关的Ansible剧本；这允许你只用一个命令启动一个完全功能的Ceph环境。虽然这非常方便，但它并没有帮助你学习如何正确配置和使用Ceph的Ansible模块，就像你在生产环境中部署Ceph集群时那样。因此，本书将从头开始指导你配置Ansible，即使它运行在Vagrant配置的服务器上。需要特别注意的是，像Ceph本身一样，Ansible剧本也在不断变化，因此建议你查看`ceph-ansible`文档以了解是否有任何重大变更。
- en: At this point, your Vagrant environment should be up-and-running and Ansible
    should be able to connect to all six of your Ceph servers. You should also have
    a cloned copy of the Ceph Ansible module.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，你的Vagrant环境应该已经启动，并且Ansible应该能够连接到所有六个Ceph服务器。你还应该有一个Ceph Ansible模块的克隆副本。
- en: 'Create a file called `/etc/ansible/group_vars/ceph`:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为`/etc/ansible/group_vars/ceph`的文件：
- en: '[PRE28]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Create a file called `/etc/ansible/group_vars/osds`:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为`/etc/ansible/group_vars/osds`的文件：
- en: '[PRE29]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Create a `fetch` folder and change the owner to the `vagrant` user:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个`fetch`文件夹，并将所有者更改为`vagrant`用户：
- en: '[PRE30]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Run the Ceph cluster deployment playbook:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 运行Ceph集群部署剧本：
- en: '[PRE31]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The `K` parameter tells Ansible that it should ask you for the `sudo` password.
    Now sit back and watch Ansible deploy your cluster:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`K`参数告诉Ansible应该询问你输入`sudo`密码。现在请放松并观看Ansible部署你的集群：'
- en: '![](img/52d49e38-7c73-4c1a-8279-65c86ad8e5a7.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](img/52d49e38-7c73-4c1a-8279-65c86ad8e5a7.png)'
- en: 'Once this is completed, and assuming Ansible completed without errors, `ssh`
    into `mon1` and run:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成，并且假设Ansible没有错误地完成，`ssh`进入`mon1`并运行：
- en: '[PRE32]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![](img/8615022f-765a-40ee-a30e-d0723f545988.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8615022f-765a-40ee-a30e-d0723f545988.png)'
- en: And that concludes the deployment of a fully functional Ceph cluster via Ansible.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是通过Ansible部署一个完全功能的Ceph集群的全部过程。
- en: 'If you want to be able to stop the Vagrant Ceph cluster without losing your
    work so far, you can run the following command:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想能够停止Vagrant Ceph集群而不丢失到目前为止的工作，可以运行以下命令：
- en: '[PRE33]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'To pause all the VM''s in their current state, run the following:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要暂停所有虚拟机的当前状态，请运行以下命令：
- en: '[PRE34]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This will power on the VMs; they'll resume running at the state you left them
    in.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动虚拟机；它们将恢复到你离开时的状态。
- en: Change and configuration management
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变更与配置管理
- en: If you deploy your infrastructure with an orchestration tool such as Ansible,
    managing Ansible playbooks becomes important. As we have seen, Ansible allows
    you to rapidly deploy both the initial Ceph cluster and also configuration updates
    further down the line. It must be appreciated that this power can also have devastating
    effects if incorrect configurations or operations are deployed. By implementing
    some form of configuration management, Ceph administrators will be able to see clearly what
    changes have been made to the Ansible playbooks before running them.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你通过 Ansible 等编排工具部署基础设施，管理 Ansible playbook 就变得很重要。正如我们所看到的，Ansible 允许你快速部署初始的
    Ceph 集群，也能在后续进行配置更新。必须认识到，如果部署了错误的配置或操作，这种强大的能力也可能产生毁灭性的影响。通过实施某种形式的配置管理，Ceph
    管理员将能够在运行 Ansible playbook 之前清晰地看到已做出的更改。
- en: A recommended approach would be to store your Ceph Ansible configuration in
    a Git repository; this will allow you to track changes and implement some form
    of change control either by monitoring Git commits or by forcing people to submit
    merge requests into the master branch.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 一种推荐的方法是将 Ceph 的 Ansible 配置存储在 Git 仓库中；这样可以跟踪更改，并通过监控 Git 提交或强制用户向主分支提交合并请求来实现某种形式的变更控制。
- en: Ceph in containers
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ceph 容器化
- en: We have seen previously that by using orchestration tools such as Ansible we
    can reduce the work required to deploy, manage, and maintain a Ceph cluster. We
    have also seen how these tools can help you discover available hardware resources
    and deploy Ceph to them.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已经看到，通过使用 Ansible 等编排工具，我们可以减少部署、管理和维护 Ceph 集群所需的工作量。我们还看到这些工具如何帮助你发现可用的硬件资源，并将
    Ceph 部署到这些资源上。
- en: However, using Ansible to configure bare-metal servers still results in a very
    static deployment, possibly not best suited for today's more dynamic workloads.
    Designing Ansible playbooks also needs to take into account several different
    Linux distributions and also any changes that may occur between different releases;
    systemd is a great example of this. Furthermore, a lot of development in orchestration
    tools needs to be customized to handle discovering, deploying, and managing Ceph.
    This is a common theme that the Ceph developers have thought about; with the use
    of Linux containers and their associated orchestration platforms, they hope to
    improve Ceph's deployment experience.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用 Ansible 配置裸金属服务器仍然会导致非常静态的部署，可能不太适合今天更动态的工作负载。设计 Ansible playbook 时还需要考虑多个不同的
    Linux 发行版，以及可能在不同版本之间发生的任何变化；systemd 就是一个很好的例子。此外，许多编排工具的开发需要定制化，以便处理发现、部署和管理
    Ceph。这是 Ceph 开发人员思考过的一个常见主题；通过使用 Linux 容器及其相关的编排平台，他们希望改善 Ceph 的部署体验。
- en: One such approach, which has been selected as the preferred option, is to join
    forces with a project called Rook. Rook works with the container management platform
    Kubernetes to automate the deployment, configuration, and consumption of Ceph
    storage. If you were to draw up a list of requirements and features which a custom
    Ceph orchestration and management framework would need to implement, you would
    likely design something which functions in a similar fashion to Kubernetes. So
    it makes sense to build functionality on top of the well-established Kubernetes
    project, and Rook does exactly that.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一种被选为首选方案的方法是与一个名为 Rook 的项目合作。Rook 与容器管理平台 Kubernetes 配合使用，自动化 Ceph 存储的部署、配置和使用。如果你列出一个自定义
    Ceph 编排和管理框架所需实现的需求和功能，你很可能会设计出一个与 Kubernetes 类似的框架。所以，在已经成熟的 Kubernetes 项目上构建功能是合乎逻辑的，而
    Rook 正是这样做的。
- en: One major benefit of running Ceph in containers is that is allows collocation
    of services on the same hardware. Traditionally in Ceph clusters it was expected
    that Ceph monitors would run on dedicated hardware; when utilizing containers
    this requirement is removed. For smaller clusters, this can amount to a large
    saving in the cost of running and purchasing servers. If resources permit, other
    container-based workloads could also be allowed to run across the Ceph hardware,
    further increasing the Return on Investment for the hardware purchase. The use
    of Docker containers reserves the required hardware resources so that workloads
    cannot impact each other.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器中运行 Ceph 的一个主要好处是它允许将服务部署在相同的硬件上。传统上，在 Ceph 集群中，Ceph 监视器需要运行在专用硬件上；而使用容器时，这一要求被去除了。对于较小的集群，这可以在运行和购买服务器的成本上节省大量开支。如果资源允许，其他基于容器的工作负载也可以在
    Ceph 硬件上运行，从而进一步提高硬件采购的投资回报率。使用 Docker 容器可以预留所需的硬件资源，以避免不同工作负载之间互相影响。
- en: To better understand how these two technologies work with Ceph, we first need
    to cover Kubernetes in more detail and actual containers themselves.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这两种技术如何与 Ceph 配合使用，我们首先需要更详细地了解 Kubernetes 和容器本身。
- en: Containers
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器
- en: Although containers in their current form are a relatively new technology, the
    principle of isolating sets of processes from each other has been around for a
    long time. What the current set of technologies enhances is the completeness of
    the isolation. Previous technologies maybe only isolated parts of the filesystem,
    whereas the latest container technologies also isolate several areas of the operating
    system and can also provide quotas for hardware resources. One technology in particular,
    Docker, has risen to become the most popular technology when talking about containers,
    so much so that the two words are often used interchangeably. The word **container** describes
    a technology that performs operating system-level virtualization. Docker is a
    software product that controls primarily Linux features such as groups and namespaces
    to isolate sets of Linux processes.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管容器技术作为一种新兴技术已经出现不久，但将一组进程相互隔离的原则已经存在很长时间。当前的技术增强了隔离的完整性。以往的技术可能仅仅隔离了文件系统的某些部分，而最新的容器技术则还隔离了操作系统的多个区域，并且还可以为硬件资源提供配额。尤其是
    Docker 技术，它已成为讨论容器时最受欢迎的技术，以至于这两个词经常被交替使用。**容器**一词描述了一种执行操作系统级虚拟化的技术。Docker 是一个控制主要是
    Linux 特性的软体产品，例如控制组（cgroups）和命名空间（namespaces），用于隔离一组 Linux 进程。
- en: It's important to note that, unlike full-blown virtualization solutions such
    as VMWare, Hyper-V, and KVM, which provides virtualized hardware and require a
    separate OS instance, containers utilize the operating system of the host. The
    full OS requirements of virtual machines may lead to several 10s of GB of storage
    being wasted on the operating system installation and potentially several GB of
    RAM as well. Containers typically consume overheads of storage and RAM measured
    in MB, meaning that a lot more containers can be squeezed onto the same hardware
    when compared to full virtualization technologies.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，与 VMware、Hyper-V 和 KVM 等完整的虚拟化解决方案不同，后者提供虚拟化的硬件并需要一个单独的操作系统实例，容器利用宿主机的操作系统。虚拟机的完整操作系统需求可能导致存储空间浪费数十
    GB 用于操作系统安装，并可能浪费数 GB 的 RAM。而容器通常只消耗以 MB 为单位的存储和 RAM 开销，这意味着与完全虚拟化技术相比，更多的容器可以被部署在相同的硬件上。
- en: Containers are also much easier to orchestrate as they are completely configurable
    from the host system; this, when combined with their ability to be started in
    milliseconds, means that they are very well suited to dynamically changing environments.
    Particularly in DevOps environments, they are becoming extremely popular where
    the line between infrastructure and application is starting to become blurred.
    The management of infrastructure, which tends to operate at a slower pace than
    application development, means that in an Agile development environment the infrastructure
    team is often always playing catch-up. With DevOps and containers, the infrastructure
    team can concentrate on providing a solid base and the developers can ship their
    application combined with the OS and middleware required to run.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 由于容器可以完全从主机系统配置，因此它们的编排也更加容易；再加上它们可以在毫秒内启动的能力，这意味着它们非常适合动态变化的环境。特别是在DevOps环境中，当基础设施和应用程序之间的界限开始变得模糊时，它们变得非常受欢迎。基础设施管理往往比应用程序开发的速度慢，这意味着在敏捷开发环境中，基础设施团队通常总是在追赶进度。有了DevOps和容器，基础设施团队可以集中精力提供一个坚实的基础，而开发人员则可以打包他们的应用程序以及运行所需的操作系统和中间件。
- en: Kubernetes
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes
- en: The ability to quickly and efficiently spin up 10's of containers in seconds
    soon makes you realize that. if VM sprawl was bad enough, with containers the
    problem can easily get a whole lot worse. With the arrival of Docker in the modern
    IT infrastructure, a need to manage all these containers arose. Enter Kubernetes.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 能够在几秒钟内快速高效地启动数十个容器很快让你意识到，如果虚拟机的泛滥已经够糟糕了，那么使用容器，问题很容易会变得更加严重。随着Docker在现代IT基础设施中的出现，管理所有这些容器的需求应运而生。这就是Kubernetes的出现。
- en: Although several container orchestration technologies are available, Kubernetes
    has enjoyed wide-ranging success and, as it is the product on which Rook is built,
    this book will focus on it.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有多种容器编排技术可供选择，但Kubernetes已经取得了广泛的成功，并且作为Rook构建的产品，本书将重点介绍它。
- en: Kubernetes is an open source container-orchestration system for automating the
    deployment, scaling, and management of containerized applications. It was originally
    developed at Google to run their internal systems but has since been open sourced
    and seen its popularity flourish.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个用于自动化部署、扩展和管理容器化应用程序的开源容器编排系统。它最初是在Google开发用于运行其内部系统的，但后来已开源并且其受欢迎程度不断增长。
- en: Although this chapter will cover deploying an extremely simple Kubernetes cluster
    to deploy a Ceph cluster with Rook, it is not meant to be a full tutorial and
    readers are encouraged to seek other resources in order to learn more about Kubernetes.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本章将涵盖部署一个非常简单的Kubernetes集群来部署一个带有Rook的Ceph集群，但它并不是一个完整的教程，建议读者查找其他资源以了解更多关于Kubernetes的信息。
- en: Deploying a Ceph cluster with Rook
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Rook部署Ceph集群
- en: To deploy a Ceph cluster with Rook and Kubernetes, Vagrant will be used to create
    three VMs that will run the Kubernetes cluster.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Vagrant创建三个虚拟机来运行Kubernetes集群，以部署带有Rook的Ceph集群。
- en: The first task you'll complete is the deployment of three VMs via Vagrant. If
    you have followed the steps at that start of this chapter and used Vagrant to
    build an environment for Ansible, then you should have everything you require
    to deploy VMs for the Kubernetes cluster.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 你将完成的第一个任务是通过Vagrant部署三个虚拟机。如果你已经按照本章节开始时的步骤，并使用Vagrant构建了Ansible环境，那么你应该拥有部署Kubernetes集群所需的一切。
- en: 'The following is the `Vagrantfile` to bring up three VMs; as before, place
    the contents into a file called `Vagrantfile` in a new directory and then run
    `vagrant up`:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是用于启动三个虚拟机的`Vagrantfile`；和之前一样，将内容放入名为`Vagrantfile`的新目录中，然后运行`vagrant up`：
- en: '[PRE35]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![](img/59b45113-acd5-4b83-a72c-88c34f0ef2d7.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](img/59b45113-acd5-4b83-a72c-88c34f0ef2d7.png)'
- en: 'SSH in to the first VM, `Kube1`:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: SSH到第一个虚拟机`Kube1`：
- en: '![](img/8b60c47d-783d-4180-bcc7-4090fc1c9afb.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b60c47d-783d-4180-bcc7-4090fc1c9afb.png)'
- en: 'Update the kernel to a newer version; this is required for certain Ceph features
    in Rook to function correctly:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 将内核更新到更新版本；这对于Rook中某些Ceph功能的正常运行是必需的：
- en: '![](img/5edf43c2-a86e-4ca5-8aa7-4bc2290cbbd0.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5edf43c2-a86e-4ca5-8aa7-4bc2290cbbd0.png)'
- en: 'Install Docker, as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 安装Docker，如下所示：
- en: '[PRE36]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![](img/f166db31-a380-4785-aaf3-72f5888d7391.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f166db31-a380-4785-aaf3-72f5888d7391.png)'
- en: 'Enable and start the Docker service, as follows:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 启用并启动Docker服务，如下所示：
- en: '[PRE37]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '![](img/5db6f822-1bfa-499a-9f04-c629487902a0.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5db6f822-1bfa-499a-9f04-c629487902a0.png)'
- en: 'Disable swap for future boots by editing `/etc/fstab` and commenting out the
    swap line:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 通过编辑 `/etc/fstab` 并注释掉交换分区行，禁用未来启动时的交换分区：
- en: '![](img/3f56c9af-52e2-44f9-9b1f-976c8362ffd0.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f56c9af-52e2-44f9-9b1f-976c8362ffd0.png)'
- en: 'And also disable swap now, as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在也禁用交换分区，如下所示：
- en: '[PRE38]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '![](img/b14483a2-93dd-4c74-8fe5-7b2058b92481.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b14483a2-93dd-4c74-8fe5-7b2058b92481.png)'
- en: 'Add the Kubernetes repository, as follows:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 添加 Kubernetes 仓库，如下所示：
- en: '[PRE39]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '![](img/b7017f9c-bfd1-4a91-a072-20c8f598dca9.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b7017f9c-bfd1-4a91-a072-20c8f598dca9.png)'
- en: 'Add the Kubernetes GPG key, as follows:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 添加 Kubernetes GPG 密钥，如下所示：
- en: '[PRE40]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![](img/9f1e1e1e-d49d-4a24-88c9-4f2bae8a111d.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9f1e1e1e-d49d-4a24-88c9-4f2bae8a111d.png)'
- en: 'Install Kubernetes, as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Kubernetes，如下所示：
- en: '[PRE41]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![](img/59bbee82-521a-4acb-a932-209b54c4012c.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](img/59bbee82-521a-4acb-a932-209b54c4012c.png)'
- en: Repeat the installation steps for Docker and Kubernetes on both the `kube2`
    and `kube3` VMs.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `kube2` 和 `kube3` 虚拟机上重复 Docker 和 Kubernetes 的安装步骤。
- en: 'Once all the VMs have a working copy of Docker and Kubernetes, we can now initialize
    the Kubernetes cluster:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有虚拟机都成功安装了 Docker 和 Kubernetes，我们就可以初始化 Kubernetes 集群：
- en: '[PRE42]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![](img/4011cf71-ac86-43c5-91d9-49698abcd82a.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4011cf71-ac86-43c5-91d9-49698abcd82a.png)'
- en: 'At the end of the process, a command string is output; make a note of this
    as it is needed to join our additional nodes to the cluster. An example of this
    is as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 过程结束时会输出一个命令字符串，请记下它，因为它用于将额外的节点加入到集群中。示例如下：
- en: '![](img/d462c64b-b453-43e4-aada-b5f72764ceef.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d462c64b-b453-43e4-aada-b5f72764ceef.png)'
- en: 'Now that we have installed Docker and Kubernetes on all our nodes and have
    initialized the master, let''s add the remaining two nodes into the cluster. Remember
    that string of text you were asked to note down? Now we can run it on the two
    remaining nodes:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经在所有节点上安装了 Docker 和 Kubernetes，并初始化了主节点，接下来让我们将剩下的两个节点添加到集群中。记得之前让你记下的那串文本吗？现在我们可以在剩余的两个节点上运行它：
- en: '[PRE43]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '![](img/45f7274d-3629-4955-8fd3-a76da38d88d9.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](img/45f7274d-3629-4955-8fd3-a76da38d88d9.png)'
- en: '[PRE44]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![](img/ba167f19-0e66-41ba-bd9f-bbcbb2f67e22.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba167f19-0e66-41ba-bd9f-bbcbb2f67e22.png)'
- en: 'We can now install some additional container networking support. Flannel, a
    simple networking add-on for Kubernetes, uses VXLAN as an overlay to enable container-to-container
    networking. First download the `yaml` file from GitHub:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以安装一些额外的容器网络支持。Flannel，一个简单的 Kubernetes 网络插件，使用 VXLAN 作为覆盖层来实现容器之间的网络连接。首先从
    GitHub 下载 `yaml` 文件：
- en: '[PRE45]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '![](img/a5fb2c92-1a01-4390-afa7-e7e6eef19c79.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a5fb2c92-1a01-4390-afa7-e7e6eef19c79.png)'
- en: 'Before we install the Flannel networking component, we need to make a few changes
    to the `YAML` spec file:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装 Flannel 网络组件之前，我们需要对 `YAML` 规范文件进行一些更改：
- en: '[PRE46]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Don't indent with tabs, use spaces.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 请不要使用制表符缩进，要使用空格。
- en: 'We need to find the following lines and make the required changes, as follows:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要找到以下几行并进行必要的更改，如下所示：
- en: 'Line 76: `"Network": "10.1.0.0/16"`:'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '第76行：`"Network": "10.1.0.0/16"`：'
- en: '![](img/5cd9200d-2e46-4ac2-adc7-b18489214402.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5cd9200d-2e46-4ac2-adc7-b18489214402.png)'
- en: 'Line 126: `- --iface=eth1`:'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第126行：`- --iface=eth1`：
- en: '![](img/eeae51a7-63e3-4e26-9a6f-106802fd377b.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eeae51a7-63e3-4e26-9a6f-106802fd377b.png)'
- en: 'Now we can issue the relevant Kubernetes command to apply the specification
    file and install Flannel networking:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以发出相关的 Kubernetes 命令来应用规范文件并安装 Flannel 网络：
- en: '[PRE47]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '![](img/e0e3136a-ddf5-4621-843a-3ff3474cd2ec.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e0e3136a-ddf5-4621-843a-3ff3474cd2ec.png)'
- en: 'After networking has been installed, we can confirm everything is working and
    that our Kubernetes worker nodes are ready to run workloads:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 网络安装完成后，我们可以确认一切正常，并且我们的 Kubernetes 工作节点已准备好运行工作负载：
- en: '[PRE48]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '![](img/988ac417-c9ca-47ee-b5b8-390b807b4f78.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](img/988ac417-c9ca-47ee-b5b8-390b807b4f78.png)'
- en: 'Now let''s also check that all containers that support internal Kubernetes
    services are running:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们检查所有支持 Kubernetes 内部服务的容器是否都在运行：
- en: '[PRE49]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '![](img/dfe36616-5a15-45ba-ab82-1d4aec8ecbd0.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dfe36616-5a15-45ba-ab82-1d4aec8ecbd0.png)'
- en: Note that the container networking service (Flannel) that we installed in the
    previous step has automatically been deployed  across all three nodes. At this
    point, we have a fully functioning Kubernetes cluster that is ready to run whatever
    containers we wish to run on it.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在前一步安装的容器网络服务（Flannel）已经自动部署到了所有三个节点上。此时，我们已经拥有了一个完全功能正常的 Kubernetes 集群，准备运行任何我们希望在其上运行的容器。
- en: 'We can now deploy Rook into the Kubernetes cluster. First, let''s clone the
    Rook project from GitHub:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将 Rook 部署到 Kubernetes 集群中。首先，从 GitHub 克隆 Rook 项目：
- en: '[PRE50]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '![](img/273847d6-4b95-4851-bbb4-15034b9dc481.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![](img/273847d6-4b95-4851-bbb4-15034b9dc481.png)'
- en: 'Change to the `examples` directory, as follows:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 切换到 `examples` 目录，如下所示：
- en: '[PRE51]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '![](img/2c75952e-012a-47b1-83ba-df86c60bfd12.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2c75952e-012a-47b1-83ba-df86c60bfd12.png)'
- en: 'And now finally create the Rook-powered Ceph cluster by running the following
    two commands:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过运行以下两个命令创建 Rook 驱动的 Ceph 集群：
- en: '[PRE52]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '![](img/7d0417fd-0ef8-41cd-8b51-634521f47ea1.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7d0417fd-0ef8-41cd-8b51-634521f47ea1.png)'
- en: '[PRE53]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '![](img/4a40c789-6611-4a70-ba20-d01085686be0.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4a40c789-6611-4a70-ba20-d01085686be0.png)'
- en: 'To confirm our Rook cluster is now working, let''s check the running containers
    under the Rook namespace:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确认我们的 Rook 集群现在正在工作，让我们检查 Rook 命名空间下的运行容器：
- en: '[PRE54]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '![](img/33fa2330-3efa-4b78-b420-fa0125fcc989.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![](img/33fa2330-3efa-4b78-b420-fa0125fcc989.png)'
- en: 'You will see that Rook has deployed a couple of `mons` and has also started
    some discover containers. These discover containers run a discovery script to
    locate storage devices attached to the Kubernetes physical host. Once the discovery
    process has completed for the first time, Kubernetes will then run a one-shot
    container to prepare the OSD by formatting the disk and adding the OSD into the
    cluster. If you wait a few minutes and re-run the `get pods` command, you should
    hopefully see that Rook has detected the two disks connected to `kube2` and `kube3`
    and created `osd` containers for them:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到 Rook 部署了一些 `mons`，并且还启动了一些发现容器。这些发现容器运行一个发现脚本来定位附加到 Kubernetes 物理主机的存储设备。一旦发现过程首次完成，Kubernetes
    将运行一个一次性容器，通过格式化磁盘并将 OSD 添加到集群中来准备 OSD。如果您等待几分钟并重新运行 `get pods` 命令，您应该能看到 Rook
    已经检测到连接到 `kube2` 和 `kube3` 的两个磁盘，并为它们创建了 `osd` 容器：
- en: '![](img/13c8d2e1-72f3-4dd0-a6d8-a8fc8be85ad2.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![](img/13c8d2e1-72f3-4dd0-a6d8-a8fc8be85ad2.png)'
- en: 'To interact with the cluster, let''s deploy the toolbox container; this is
    a simple container containing the Ceph installation and the necessary cluster
    keys:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与集群交互，让我们部署 toolbox 容器；这是一个包含 Ceph 安装和必要集群密钥的简单容器：
- en: '[PRE55]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '![](img/04652c84-6c80-4481-a54a-ba8745af9028.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![](img/04652c84-6c80-4481-a54a-ba8745af9028.png)'
- en: 'Now execute `bash` in the toolbox container:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在 toolbox 容器中执行 `bash`：
- en: '[PRE56]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'This will present you with a root shell running inside the Ceph toolbox container,
    where we can check the status of the Ceph cluster by running `ceph –s` and see
    the current OSDs with `ceph osd tree`:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为您提供一个在 Ceph toolbox 容器中运行的 root shell，在这里我们可以通过运行 `ceph –s` 来检查 Ceph 集群的状态，并通过
    `ceph osd tree` 查看当前的 OSD：
- en: '![](img/79cffe21-64bb-4642-a441-7a739d0c8e08.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](img/79cffe21-64bb-4642-a441-7a739d0c8e08.png)'
- en: You will notice that, although we built three VMs, Rook has only deployed OSDs
    on `kube2` and `kube3`. This is because by default Kubernetes will not schedule
    containers to run on the master node; in a production cluster this is the desired
    behavior, but for testing we can remove this limitation.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到，虽然我们构建了三个虚拟机，Rook 仅在 `kube2` 和 `kube3` 上部署了 OSD。这是因为默认情况下 Kubernetes 不会将容器调度到主节点上；在生产集群中，这是期望的行为，但为了测试，我们可以移除这一限制。
- en: 'Exit back to the master Kubernetes node and run the following:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 退出回到主 Kubernetes 节点，并运行以下命令：
- en: '[PRE57]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '![](img/0ed75efe-b23f-4e1e-9499-02ac2a7ce963.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0ed75efe-b23f-4e1e-9499-02ac2a7ce963.png)'
- en: You will notice that Kubernetes will deploy a couple of new containers onto
    `kube1`, but it won't deploy any new OSDs; this is due to a current limitation
    to the effect that the `rook-ceph-operator` component only deploys new OSDs on
    first startup. In order to detect newly available disks and prepare them as OSDs,
    the `rook-ceph-operator` container needs to be deleted.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到 Kubernetes 将会在 `kube1` 上部署一些新容器，但不会部署新的 OSD；这是由于目前的限制，`rook-ceph-operator`
    组件只在首次启动时部署新的 OSD。为了检测新可用的磁盘并将它们准备为 OSD，需要删除 `rook-ceph-operator` 容器。
- en: 'Run the following command, but replace the container name with the one that
    is listed from the `get pods` command:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令，但将容器名称替换为 `get pods` 命令中列出的名称：
- en: '[PRE58]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '![](img/26d6e5b1-6938-47d4-a7e3-50e80e3cfd9e.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![](img/26d6e5b1-6938-47d4-a7e3-50e80e3cfd9e.png)'
- en: 'Kubernetes will now automatically spin up a new `rook-ceph-operator` container
    and in doing so will kick-start the deployment of the new `osd`; this can be confirmed
    by looking at the list of running containers again:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 现在将自动启动一个新的 `rook-ceph-operator` 容器，并通过此操作启动新 `osd` 的部署；可以通过再次查看正在运行的容器列表来确认这一点：
- en: '![](img/f7eeb3cb-07bc-4736-a8e7-430888406359.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f7eeb3cb-07bc-4736-a8e7-430888406359.png)'
- en: You can see `kube1` has run a `rook-discover` container, a `rook-ceph-osd-prepare`,
    and finally a `rook-ceph-osd` container, which in this case is `osd` number `2`.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到 `kube1` 运行了一个 `rook-discover` 容器，一个 `rook-ceph-osd-prepare` 容器，最后是一个 `rook-ceph-osd`
    容器，在这个例子中是 `osd` 编号 `2`。
- en: 'We can also check, by using our toolbox container as well, that the new `osd`
    has joined the cluster successfully:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过使用我们的工具箱容器来检查，新的`osd`是否已经成功加入集群：
- en: '![](img/bedb6265-2abc-4c9b-9d25-892d01eee246.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bedb6265-2abc-4c9b-9d25-892d01eee246.png)'
- en: Now that Rook has deployed our full test Ceph cluster, we need to make use of
    it and create some RADOS pools and also consume some storage with a client container.
    To demonstrate this process, we will deploy a CephFS filesystem.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Rook已经部署了我们的完整测试Ceph集群，我们需要利用它并创建一些RADOS池，同时通过客户端容器使用一些存储。为了演示这个过程，我们将部署一个CephFS文件系统。
- en: 'Before we jump straight into deploying the filesystem, let''s first have a
    look at the example `yaml` file we will be deploying. Make sure you are still
    in the `~/rook/cluster/examples/kubernetes/ceph` directory and use a text editor
    to view the `filesystem.yaml` file:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们直接开始部署文件系统之前，先看看我们将要部署的示例`yaml`文件。确保你仍然在`~/rook/cluster/examples/kubernetes/ceph`目录下，并使用文本编辑器查看`filesystem.yaml`文件：
- en: '![](img/b4371fe2-f5db-4e22-aa93-c9256587b5df.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b4371fe2-f5db-4e22-aa93-c9256587b5df.png)'
- en: You can see that the file contents describe the RADOS pools that will be created
    and the MDS instances that are required for the filesystem. In this example, three
    pools will be deployed, two replicated and one erasure-coded for the actual data.
    Two MDS servers will be deployed, one running as active and the other running
    as a standby-replay.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到文件内容描述了将要创建的RADOS池以及文件系统所需的MDS实例。在这个例子中，将部署三个池，其中两个为复制池，一个为纠删码池用于实际数据存储。将部署两个MDS服务器，一个作为活动实例，另一个作为备用回放实例。
- en: 'Exit the text editor and now deploy the CephFS configuration in the `yaml`
    file:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 退出文本编辑器，现在部署`yaml`文件中的CephFS配置：
- en: '[PRE59]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '![](img/fbb6d097-f8a4-498b-941a-4ba3b797b496.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fbb6d097-f8a4-498b-941a-4ba3b797b496.png)'
- en: 'Now let''s jump back into our toolbox container, check the status, and see
    what''s been created:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们回到工具箱容器，检查状态，看看已经创建了什么：
- en: '![](img/7078fbe6-a088-41a8-8608-b5550f73d735.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7078fbe6-a088-41a8-8608-b5550f73d735.png)'
- en: '![](img/4a9d97df-9ee0-44a8-8e1f-7343260e19f5.png)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4a9d97df-9ee0-44a8-8e1f-7343260e19f5.png)'
- en: We can see that two pools have been created, one for the CephFS metadata and
    one for the actual data stored on the CephFS filesystem.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到已经创建了两个池，一个用于CephFS元数据，另一个用于实际存储在CephFS文件系统中的数据。
- en: To give an example of how Rook can then be consumed by application containers,
    we will now deploy a small NGINX web server container that stores its HTML content
    on the CephFS filesystem.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 为了举例说明Rook如何被应用容器使用，我们现在将部署一个小型的NGINX Web服务器容器，将其HTML内容存储在CephFS文件系统上。
- en: 'Place the following inside a file called `nginx.yaml`:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下内容放入名为`nginx.yaml`的文件中：
- en: '[PRE60]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'And now use the `kubectl` command to create the `pod/nginx`:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用`kubectl`命令来创建`pod/nginx`：
- en: '![](img/77c41c5a-2fe6-4930-8bf0-736b9b01b8e8.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77c41c5a-2fe6-4930-8bf0-736b9b01b8e8.png)'
- en: 'After a while, the container will be started and will enter a running state;
    use the `get pods` command to verify this:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 稍等一会儿，容器将启动并进入运行状态；使用`get pods`命令来验证这一点：
- en: '![](img/79b79484-adba-4a97-9793-58e32fd4c3b0.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![](img/79b79484-adba-4a97-9793-58e32fd4c3b0.png)'
- en: 'We can now start a quick Bash shell on this container to confirm the CephFS
    mount has worked:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以在这个容器上启动一个快速的Bash shell来确认CephFS挂载是否成功：
- en: '[PRE61]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '![](img/ef51b95e-65d1-41ab-815b-4aa31ba2c286.png)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef51b95e-65d1-41ab-815b-4aa31ba2c286.png)'
- en: We can see that the CephFS filesystem has been mounted into `/usr/share/nginx/html`.
    This has been done without having to install any Ceph components in the container
    and without any configuration or copying of key rings. Rook has taken care of
    all of this behind the scenes; once this is understood and appreciated, the real
    power of Rook can be seen. If the simple NGINX pod example is expanded to become
    an auto-scaling service that spins up multiple containers based on load, the flexibility
    given by Rook and Ceph to automatically present the same shared storage across
    the web farm with no additional configuration is very useful.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到CephFS文件系统已被挂载到`/usr/share/nginx/html`。这一切都在没有在容器中安装任何Ceph组件、没有任何配置或密钥环复制的情况下完成。Rook在后台处理了所有这些；一旦理解并欣赏这一点，Rook的真正强大之处便显现出来。如果这个简单的NGINX
    pod示例扩展成一个基于负载自动扩展的服务，自动启动多个容器，那么Rook和Ceph所提供的灵活性，即无需额外配置便能自动在web集群中呈现相同的共享存储，显得尤为有用。
- en: Summary
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned about Ceph's various deployment methods and the
    differences between them. You will now also have a basic understanding of how
    Ansible works and how to deploy a Ceph cluster with it. It would be advisable
    at this point to continue investigating and practicing the deployment and configuration
    of Ceph with Ansible, so that you are confident enough to use it in production
    environments. The remainder of this book will also assume that you have fully
    understood the contents of this chapter in order to manipulate the configuration
    of Ceph.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了 Ceph 的各种部署方法及其之间的差异。你现在也会对 Ansible 的工作原理以及如何用它部署 Ceph 集群有一个基本的理解。此时，建议你继续研究并实践使用
    Ansible 部署和配置 Ceph，以便你能够自信地在生产环境中使用它。本书的其余部分也将假设你已经完全理解了本章的内容，以便能够操作 Ceph 的配置。
- en: You have also learned about the exciting new developments in deploying Ceph
    in containers running on the Kubernetes platform. Although the Rook project is
    still in the early stages of development, it is clear it is already a very powerful
    tool that will enable Ceph to function to the best of its ability while at the
    same time simplifying the deployment and administration required. With the continued
    success enjoyed by Kubernetes in becoming the recommended container management
    platform, integrating Ceph with the use of Rook will result in a perfect match
    of technologies.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 你还学习了在 Kubernetes 平台上运行的容器中部署 Ceph 的一些令人兴奋的新进展。尽管 Rook 项目仍处于开发的初期阶段，但显然它已经是一个非常强大的工具，能够让
    Ceph 发挥其最佳功能，同时简化所需的部署和管理。随着 Kubernetes 成为推荐的容器管理平台并持续获得成功，将 Ceph 与 Rook 集成将会是技术上的完美匹配。
- en: It is highly recommended that the reader should continue to learn further about
    Kubernetes as this chapter has only scratched the surface of the functionality
    it offers. There are strong signs across the industry that containerization is
    going to be the technology for deploying and managing applications and having
    an understanding of both Kubernetes and how Ceph integrates with Rook is highly
    recommended.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 强烈建议读者继续深入学习 Kubernetes，因为本章仅仅触及了它提供的功能表面。行业内的强烈迹象表明，容器化将成为部署和管理应用程序的主要技术，因此，理解
    Kubernetes 以及 Ceph 如何与 Rook 集成是非常有必要的。
- en: Questions
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What piece of software can be used to rapidly deploy test environments?
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个软件可以用来快速部署测试环境？
- en: Should vagrant be used to deploy production environments?
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否应该使用 vagrant 来部署生产环境？
- en: What project enables the deployment of Ceph on top of Kubernetes?
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个项目使得可以在 Kubernetes 上部署 Ceph？
- en: What is Docker?
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是 Docker？
- en: What is the Ansible file called which is used to run a series of commands?
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用于执行一系列命令的 Ansible 文件叫什么？
