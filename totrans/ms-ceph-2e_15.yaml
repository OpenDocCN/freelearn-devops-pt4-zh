- en: Disaster Recovery
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 灾难恢复
- en: In the previous chapter, you learned how to troubleshoot common Ceph problems,
    which, although they may be affecting the operation of the cluster, weren't likely
    to cause a total outage or data loss. This chapter will cover more serious scenarios,
    where the Ceph cluster is down or unresponsive. It will also cover various techniques
    to recover from data loss. It is to be understood that these techniques are more
    than capable of causing severe data loss themselves and should only be attempted
    as a last resort. If you have a support contract with your Ceph vendor or have
    a relationship with Red Hat, it is highly advisable to consult them first before
    carrying out any of the recovery techniques listed in this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了如何排除常见的Ceph问题，尽管这些问题可能影响集群的运行，但不太可能导致完全停机或数据丢失。本章将涵盖更严重的场景，涉及Ceph集群完全停机或无响应的情况。还将介绍从数据丢失中恢复的各种技术。需要理解的是，这些技术本身可能会导致严重的数据丢失，因此应仅作为最后手段尝试。如果你与Ceph供应商有支持合同，或与Red
    Hat有合作关系，强烈建议在执行本章列出的任何恢复技术之前先咨询他们。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Avoiding data loss
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免数据丢失
- en: Using RBD mirroring to provide highly available block storage
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用RBD镜像提供高可用的块存储
- en: Investigating asserts
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调查断言
- en: Rebuilding monitor databases from OSDs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从OSD重建监视器数据库
- en: Extracting PGs from a dead OSD
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从故障的OSD中提取PG
- en: Examining data from an offline Bluestore OSD
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从离线Bluestore OSD中检查数据
- en: Recovering from lost objects or inactive PGs
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从丢失对象或非活动PG中恢复
- en: Recovering from a failed CephFS filesystem
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从故障的CephFS文件系统中恢复
- en: Rebuilding an RBD from dead OSDs
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从故障的OSD中重建RBD
- en: What is a disaster?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是灾难？
- en: To be able to recover from a disaster, you first have to understand and be able
    to recognize one. For the purpose of this chapter, we will assume that anything
    that leads to a sustained period of downtime is classed as a disaster. This will
    not cover scenarios where a failure happens that Ceph is actively working to recover
    from, or where it is believed that the cause is likely to be short-lived. The
    other type of disaster is one that leads to a permanent loss of data unless recovery
    of the Ceph cluster is possible. Data loss is probably the most serious issue,
    as the data may be irreplaceable or can cause serious harm to the future of the
    business.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够从灾难中恢复，首先你需要理解并能够识别灾难。对于本章的目的，我们假设任何导致持续停机的情况都被视为灾难。这里不会涵盖Ceph正在积极修复的故障场景，或者认为故障可能是短暂的灾难。另一种灾难是导致数据永久丢失，除非可以恢复Ceph集群。数据丢失可能是最严重的问题，因为数据可能是不可替代的，或者会对公司的未来造成严重损害。
- en: Avoiding data loss
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免数据丢失
- en: Before starting to cover some recovery techniques, it is important to cover
    some points discussed in [Chapter 1](0f4119df-b421-4349-86c8-b68444743f8a.xhtml),
    *Planning for Ceph*. Disaster-recovery should be seen as a last resort; the recovery
    guides in this chapter should not be relied upon as a replacement for adhering
    to best practices.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始介绍一些恢复技术之前，重要的是先讨论[第1章](0f4119df-b421-4349-86c8-b68444743f8a.xhtml)中提到的一些要点，*Ceph的规划*。灾难恢复应视为最后的手段；本章中的恢复指南不应被视为代替遵循最佳实践的手段。
- en: First, make sure you have working and tested backups of your data; in the event
    of an outage, you will feel a million times more relaxed if you know that in the
    worst cases, you can fall back to backups. While an outage may cause discomfort
    for your users or customers, informing them that their data, which they had entrusted
    you with, is now gone is far worse. Also, just because you have a backup system
    in place, does not mean you should blindly put your trust in it. Regular test
    restores will mean that you will be able to rely on them when needed.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，确保你有可用且经过测试的数据备份；在发生故障时，如果你知道在最坏的情况下可以依赖备份，你会感到轻松万分。虽然故障可能会给你的用户或客户带来不便，但告诉他们曾托付给你们的数据现在丢失了，远比故障本身要糟糕得多。此外，虽然你可能已经建立了备份系统，但并不意味着你可以盲目依赖它。定期进行恢复测试，确保在需要时可以依赖它们。
- en: Make sure you follow some design principles also mentioned in [Chapter 1](0f4119df-b421-4349-86c8-b68444743f8a.xhtml),
    *Planning for Ceph*. Don't use configuration options, such as `nobarrier`, and
    strongly consider the replication level you use with in Ceph to protect your data.
    The chances of data loss are strongly linked to the redundancy level configured
    in Ceph, so careful planning is advised here.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你遵循一些在[第 1 章](0f4119df-b421-4349-86c8-b68444743f8a.xhtml)中提到的设计原则，*为 Ceph
    规划*。不要使用诸如 `nobarrier` 之类的配置选项，并强烈考虑在 Ceph 中使用的复制级别来保护你的数据。数据丢失的几率与 Ceph 中配置的冗余级别密切相关，因此在此需要进行仔细规划。
- en: What can cause an outage or data loss?
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么原因可能导致停机或数据丢失？
- en: The majority of outages and cases of data loss will be directly caused by the
    loss of a number of OSDs that exceed the replication level in a short period of
    time. If these OSDs do not come back online, either due to a software or hardware
    failure, and Ceph was not able to recover objects between OSD failures, these
    objects are now lost.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数停机和数据丢失情况将直接由在短时间内丧失超过复制级别的多个 OSD 导致。如果这些 OSD 无法重新上线，无论是由于软件还是硬件故障，且 Ceph
    无法在 OSD 故障之间恢复对象，则这些对象将丢失。
- en: If an OSD has failed due to a failed disk, it is unlikely that recovery will
    be possible unless costly disk-recovery services are utilized, and there is no
    guarantee that any recovered data will be in a consistent state. This chapter
    will not cover recovering from physical disk failures and will simply suggest
    that the default replication level of 3 should be used to protect you against
    multiple disk failures.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 OSD 因磁盘故障而失败，除非使用昂贵的磁盘恢复服务，否则恢复的可能性不大，并且没有任何保证恢复的数据会处于一致状态。本章不会涵盖从物理磁盘故障中恢复的内容，只是建议使用默认的复制级别
    3 来保护你免受多次磁盘故障的影响。
- en: If an OSD has failed due to a software bug, the outcome is possibly a lot more
    positive, but the process is complex and time-consuming. Usually an OSD, which,
    although the physical disk is in a good condition is unable to start, is normally
    linked to either a software bug or some form of corruption. A software bug may
    be triggered by an uncaught exception that leaves the OSD in a state that it cannot
    recover from. Corruption may occur after an unexpected loss of power, where the
    hardware or software was not correctly configured to maintain data consistency.
    In both cases, the outlook for the OSD itself is probably terminal, and if the
    cluster has managed to recover from the lost OSDs, it's best just to erase and
    reintroduce the OSD as an empty disk.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 OSD 因软件错误而失败，结果可能会更加积极，但过程复杂且耗时。通常，虽然物理磁盘状况良好但无法启动的 OSD，通常与软件错误或某种形式的损坏有关。软件错误可能是由未捕获的异常引发的，使得
    OSD 处于无法恢复的状态。损坏可能发生在意外断电后，硬件或软件未正确配置以维持数据一致性。在这两种情况下，OSD 本身的前景可能是终结的，如果集群已经从丢失的
    OSD 中恢复，最好将 OSD 清除并作为空磁盘重新引入。
- en: If the number of offline OSDs has meant that all copies of an object are offline,
    recovery procedures should be attempted to extract the objects from the failed
    OSDs, and insert them back into the cluster.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果离线的 OSD 数量导致所有对象副本都离线，应尝试恢复过程，从故障的 OSD 中提取对象，并将其重新插入到集群中。
- en: RBD mirroring
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RBD 镜像
- en: As mentioned, working backups are a key strategy in ensuring that a failure
    does not result in the loss of data. Starting with the Jewel release, Ceph introduced
    RBD mirroring, which allows you to asynchronously mirror an RBD from one cluster
    to another. Note the difference between Ceph's native replication, which is synchronous,
    and RBD mirroring. With synchronous replication, low latency between peers is
    essential, and asynchronous replication allows the two Ceph clusters to be geographically
    remote, as latency is no longer a factor.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，正常工作的备份是确保故障不会导致数据丢失的关键策略。从 Jewel 版本开始，Ceph 引入了 RBD 镜像，它允许你将一个集群的 RBD 异步镜像到另一个集群。请注意，Ceph
    的本地复制是同步的，而 RBD 镜像是异步的。同步复制要求节点之间的低延迟，而异步复制允许两个 Ceph 集群地理位置遥远，因为延迟不再是一个问题。
- en: By having a replicated copy of your RBD images on a separate cluster, you can
    dramatically reduce both your **Recovery Time Objective** (**RTO**) and **Recovery
    Point Objective** (**RPO**). The RTO is a measure of how long it takes from initiating
    recovery to when the data is usable. It is the worst-case measurement of time
    between each data point and describes the expected data loss. A daily backup would
    have an RPO of 24 hours; for example, potentially, any data written up to 24 hours
    since the last backup would be lost if you had to restore from a backup.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在一个单独的集群上复制一份 RBD 镜像，你可以显著减少 **恢复时间目标**（**RTO**）和 **恢复点目标**（**RPO**）。RTO 是从启动恢复到数据可用所需的时间度量。它是每个数据点之间的最坏情况时间测量，描述了预期的数据丢失。每日备份的
    RPO 为 24 小时；例如，如果你必须从备份中恢复，可能会丢失自上次备份以来的最多 24 小时内写入的任何数据。
- en: With RBD mirroring, data is asynchronously replicated to the target RBD, and
    so, in most cases, the RPO should be under a minute. As the target RBD is also
    a replica and not a backup that would need to be first restored, the RTO is also
    likely going to be extremely low. Additionally, as the target RBD is stored on
    a separate Ceph cluster, it offers additional protection for snapshots, which
    could also be impacted if the Ceph cluster itself experiences issues. At first
    glance, this makes RBD mirroring seem like the perfect tool to protect against
    data loss, and in most cases, it is a very useful tool. RBD mirroring is not a
    replacement for a proper backup routine though. In cases where data loss is caused
    by actions internal to the RBD, such as filesystem corruption or user error, these
    changes will be replicated to the target RBD. A separate isolated copy of your
    data is vital.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 RBD 镜像时，数据会异步地复制到目标 RBD，因此，在大多数情况下，RPO 应该在一分钟以内。由于目标 RBD 也是一个副本，而不是需要先恢复的备份，因此
    RTO 也可能非常低。此外，由于目标 RBD 存储在一个单独的 Ceph 集群中，它为快照提供了额外的保护，如果 Ceph 集群本身出现问题，快照也可能受到影响。乍一看，RBD
    镜像似乎是防止数据丢失的完美工具，在大多数情况下，它确实是一个非常有用的工具。然而，RBD 镜像并不能替代正确的备份流程。在因 RBD 内部操作（如文件系统损坏或用户错误）导致数据丢失的情况下，这些更改将被复制到目标
    RBD。拥有一个独立的隔离数据副本至关重要。
- en: With that said, let's take a closer look at how RBD mirroring works.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，让我们更详细地了解一下 RBD 镜像如何工作。
- en: The journal
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志
- en: One of the key components in RBD mirroring is the journal. The RBD mirroring
    journal stores all writes to the RBD and notifies the client once they have been
    written. These writes are then written to the primary RBD image. The journal itself
    is stored as an RADOS object, prefixed similarly to how RBD images are. Separately,
    the remote `rbd-mirror` daemon polls the configured RBD mirrors and pulls the
    newly-written journal objects across to the target cluster and replays them in
    the target RBD.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: RBD 镜像的一个关键组件是日志。RBD 镜像日志存储所有写入到 RBD 的数据，并在写入完成后通知客户端。然后，这些写入会写入主 RBD 镜像。日志本身作为
    RADOS 对象存储，并以类似于 RBD 镜像的方式加上前缀。远程的 `rbd-mirror` 守护进程会轮询配置的 RBD 镜像，并将新写入的日志对象拉取到目标集群并在目标
    RBD 中重放。
- en: The rbd-mirror daemon
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: rbd-mirror 守护进程
- en: The `rbd-mirror` daemon is responsible for replaying the contents of the journal
    to a target RBD in another Ceph cluster. The `rbd-mirror` daemon only needs to
    run on the target cluster, unless you wish to replicate both ways, in which case,
    it will need to run on both clusters.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`rbd-mirror` 守护进程负责将日志内容重放到另一个 Ceph 集群中的目标 RBD。`rbd-mirror` 守护进程只需要在目标集群上运行，除非你希望实现双向复制，在这种情况下，它需要在两个集群上都运行。'
- en: Configuring RBD mirroring
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置 RBD 镜像
- en: In order to use the RBD mirroring functionality, we will require two Ceph clusters.
    We could deploy two identical clusters we have been using previously, but the
    number of VMs involved may exceed the capabilities of what most people's personal
    machines can run. Therefore, we will modify our vagrant and ansible configuration
    files to deploy two separate Ceph clusters, each with a single monitor and an
    OSD node.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 RBD 镜像功能，我们需要两个 Ceph 集群。我们可以部署之前使用过的两个相同的集群，但涉及的虚拟机数量可能超过大多数个人计算机的承载能力。因此，我们将修改我们的
    vagrant 和 ansible 配置文件，以部署两个独立的 Ceph 集群，每个集群都包含一个监视器和一个 OSD 节点。
- en: 'The required `Vagrantfile` is very similar to the one used in [Chapter 2](dd1d6803-6e40-4bfb-8150-b605bcc08d59.xhtml),
    *Deploying Ceph with Containers*, to deploy your initial test cluster; the hosts
    part at the top should now look like this:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 所需的`Vagrantfile`与[第2章](dd1d6803-6e40-4bfb-8150-b605bcc08d59.xhtml)《使用容器部署Ceph》中的非常相似，用于部署初始测试集群；顶部的hosts部分现在应该如下所示：
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For the Anisble configuration, we will maintain two separate Ansible configuration
    instances so that each cluster can be deployed separately. We will then maintain
    separate hosts files per instance, which we will specify when we run the playbook.
    To do this, we will not copy the `ceph-ansible` files into `/etc/ansible`, but
    keep them in the home directory by using the following command:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Ansible配置，我们将维护两个独立的Ansible配置实例，以便每个集群可以单独部署。然后，我们将为每个实例维护独立的主机文件，并在运行playbook时指定它们。为了实现这一点，我们不会将`ceph-ansible`文件复制到`/etc/ansible`，而是通过以下命令将其保留在主目录中：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create the same two files, called `all` and `Ceph`, in the `group_vars` directory
    as we did in [Chapter 2](dd1d6803-6e40-4bfb-8150-b605bcc08d59.xhtml), *Deploying
    Ceph with Containers*. This needs to be done in both copies of `ceph-ansible`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在`group_vars`目录中创建与[第2章](dd1d6803-6e40-4bfb-8150-b605bcc08d59.xhtml)《使用容器部署Ceph》相同的两个文件，分别命名为`all`和`Ceph`。这需要在`ceph-ansible`的两个副本中完成：
- en: 'Create a hosts file in each `ansible` directory, and place the two hosts in
    each:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个`ansible`目录中创建一个hosts文件，并将两个主机添加到其中：
- en: '![](img/80a1dcb8-1dde-46a6-bf07-eb98ed5fbb42.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/80a1dcb8-1dde-46a6-bf07-eb98ed5fbb42.png)'
- en: 'The preceding screenshot is for the first host and the following screenshot
    is for the second host:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的截图是第一个主机的，下面的截图是第二个主机的：
- en: '![](img/574a9c43-bbb0-4d4f-9721-89d5e2359d0d.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/574a9c43-bbb0-4d4f-9721-89d5e2359d0d.png)'
- en: 'Run the `site.yml` playbook under each `ceph-ansible` instance to deploy our
    two Ceph clusters:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个`ceph-ansible`实例下运行`site.yml` playbook，以部署我们的两个Ceph集群：
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Adjust the replication level of the default pools to `1`, as our clusters only
    have `1` OSD. Run these commands on both clusters:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将默认池的复制级别调整为`1`，因为我们的集群只有`1`个OSD。请在两个集群上运行以下命令：
- en: '![](img/fb3d835f-5841-4341-8234-6f016fb8cb57.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fb3d835f-5841-4341-8234-6f016fb8cb57.png)'
- en: 'Install the RBD mirroring daemon on both clusters:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在两个集群上安装RBD镜像守护进程：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前一个命令的输出：
- en: '![](img/acb7ca25-6863-4aaf-9834-b873b912180b.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/acb7ca25-6863-4aaf-9834-b873b912180b.png)'
- en: Copy `ceph.conf` and  `keyring` from both clusters to each other.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`ceph.conf`和`keyring`从两个集群互相复制。
- en: Copy `ceph.conf` from `site1-mon1` to `site2-mon1` and call it `remote.conf`.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`ceph.conf`从`site1-mon1`复制到`site2-mon1`，并命名为`remote.conf`。
- en: Copy `ceph.client.admin.keyring` from `site1-mon1` to `site2-mon1` and call
    it `remote.client.admin.keyring`.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`ceph.client.admin.keyring`从`site1-mon1`复制到`site2-mon1`，并命名为`remote.client.admin.keyring`。
- en: Repeat the preceding two steps but this time copy the files from `site2-mon1`
    to `site1-mon1`.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复前两步，但这次将文件从`site2-mon1`复制到`site1-mon1`。
- en: 'Make sure the instances of `keyring` are owned by `ceph:ceph`:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保`keyring`的实例由`ceph:ceph`所有：
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Tell Ceph that the pool called `rbd` should have the mirroring function enabled:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 告诉Ceph，名为`rbd`的池应该启用镜像功能：
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Repeat this for the target cluster:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对目标集群重复此操作：
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Add the target cluster as a peer of the pool mirroring configuration:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将目标集群添加为池镜像配置的对等集群：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Run the same command locally on the second Ceph cluster:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二个Ceph集群上本地运行相同的命令：
- en: '[PRE8]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Back on the first cluster, let''s create a test RBD to use with our mirroring
    lab:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回第一个集群，我们来创建一个测试的RBD以供镜像实验使用：
- en: '[PRE9]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Enable the journaling feature on the RBD image:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在RBD映像上启用日志功能：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Enable mirroring for the RBD:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为RBD启用镜像功能：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](img/16a0f6ec-843a-45b5-be72-ccfdca4d3953.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/16a0f6ec-843a-45b5-be72-ccfdca4d3953.png)'
- en: 'It''s important to note that RBD mirroring works via a pull system. The `rbd-mirror`
    daemon needs to run on the cluster that you wish to mirror the RBDs to; it then
    connects to the source cluster and pulls the RBDs across. If you were intending
    to implement a two-way replication where each Ceph cluster replicates with each
    other, you would run the `rbd-mirror` daemon on both clusters. With this in mind,
    let''s enable and start the `systemd` service for `rbd-mirror` on your target
    host:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，RBD镜像是通过拉取系统工作的。`rbd-mirror`守护进程需要在你希望镜像RBD的集群上运行；它然后连接到源集群并拉取RBD。 如果你打算实现双向复制，即每个Ceph集群相互复制，你需要在两个集群上都运行`rbd-mirror`守护进程。考虑到这一点，让我们在目标主机上启用并启动`rbd-mirror`的`systemd`服务：
- en: '[PRE12]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `rbd-mirror` daemon will now start processing all the RBD images configured
    for mirroring on your primary cluster.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`rbd-mirror` 守护进程现在将开始处理你在主集群上配置的所有 RBD 镜像。'
- en: 'We can confirm that everything is working as expected by running the following
    command on the target cluster:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在目标集群上运行以下命令来确认一切按预期工作：
- en: '[PRE13]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是之前命令的输出：
- en: '![](img/2f465a33-48f9-4a12-914a-d1b44678e841.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2f465a33-48f9-4a12-914a-d1b44678e841.png)'
- en: In the previous screenshot, we can see that our `mirror_test` RBD is in a `up+replaying`
    state; this means that mirroring is in progress, and we can see via `entries_behind_master`
    that it is currently up to date.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，我们可以看到我们的 `mirror_test` RBD 处于 `up+replaying` 状态；这意味着镜像正在进行中，我们可以通过
    `entries_behind_master` 看到它目前是最新的。
- en: Note the difference in the output of the RBD `info` commands on either of the
    clusters. On the source cluster, the primary status is `true`, which allows you
    to determine which cluster the RBD is the master state and can be used by clients.
    This also confirms that although we only created the RBD on the primary cluster,
    it has been replicated to the secondary one.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 注意两集群上 RBD `info` 命令输出的不同。在源集群上，主状态为 `true`，这使你能够确定哪个集群的 RBD 处于主状态，并且可以被客户端使用。这也确认了，尽管我们只在主集群上创建了
    RBD，但它已经被复制到了副集群。
- en: 'The source cluster is shown here:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示的是源集群：
- en: '![](img/fd0c04ac-e659-4e7c-96b4-13eb3a62a0c3.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fd0c04ac-e659-4e7c-96b4-13eb3a62a0c3.png)'
- en: 'The target cluster is shown here:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示的是目标集群：
- en: '![](img/a9ed69e6-0fcf-475e-b8f0-34262a6be052.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a9ed69e6-0fcf-475e-b8f0-34262a6be052.png)'
- en: Performing RBD failover
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行 RBD 故障转移
- en: 'Before we failover the RBD to the secondary cluster, let''s map it, create
    a filesystem, and place a file on it, so we can confirm that the mirroring is
    working correctly. As of Linux kernel 4.11, the kernel RBD driver does not support
    the RBD journaling feature required for RBD mirroring; this means you cannot map
    the RBD using the kernel RBD client. As such, we will need to use the `rbd-nbd`
    utility, which uses the `librbd` driver in combination with Linux `nbd` devices
    to map RBDs via user space. Although there are many things that may cause Ceph
    to experience slow performance, here are some of the most likely causes:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将 RBD 故障转移到副集群之前，让我们映射它，创建文件系统，并在其上放置一个文件，以便确认镜像是否正常工作。从 Linux 内核 4.11 开始，内核
    RBD 驱动不支持 RBD 镜像所需的 RBD 日志功能；这意味着你不能使用内核 RBD 客户端映射 RBD。因此，我们需要使用 `rbd-nbd` 工具，它结合了
    `librbd` 驱动和 Linux `nbd` 设备，通过用户空间映射 RBD。虽然有许多因素可能导致 Ceph 性能较慢，以下是一些最可能的原因：
- en: '[PRE14]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](img/d6f22175-2f4f-4d32-84e3-db3a4e85a09a.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d6f22175-2f4f-4d32-84e3-db3a4e85a09a.png)'
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](img/9f3d999b-be44-4d27-9a3d-e737eb5c6c0e.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9f3d999b-be44-4d27-9a3d-e737eb5c6c0e.png)'
- en: '[PRE16]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, map and mount the RBD on the secondary cluster, and you should be able
    to read the test text file that you created on the primary cluster:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在副集群上映射并挂载 RBD，你应该能够读取在主集群上创建的测试文本文件：
- en: '![](img/ac3321f6-14f1-47cc-9196-6c266177d5e5.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ac3321f6-14f1-47cc-9196-6c266177d5e5.png)'
- en: We can clearly see that the RBD has successfully been mirrored to the secondary
    cluster, and the filesystem content is just as we left it on the primary cluster.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以清楚地看到，RBD 已经成功地被镜像到副集群，文件系统的内容与我们在主集群上留下的一样。
- en: If you try to map and mount the RBD on the cluster where the RBD is not in the
    primary state, the operation will just hang; this is because Ceph will not permit
    I/O to an RBD image in a non-master state.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试在 RBD 不处于主状态的集群上映射和挂载 RBD，操作将会挂起；这是因为 Ceph 不允许对非主状态的 RBD 镜像进行 I/O 操作。
- en: RBD recovery
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RBD 恢复
- en: In the event that a number of OSDs have failed, and you are unable to recover
    them via the `ceph-object-store` tool, your cluster will most likely be in a state
    where most, if not all, RBD images are inaccessible. However, there is still a
    chance that you may be able to recover RBD data from the disks in your Ceph cluster.
    There are tools that can search through the OSD data structure, find the object
    files relating to RBDs, and then assemble these objects back into a disk image,
    resembling the original RBD image.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有多个 OSD 失败，并且你无法通过 `ceph-object-store` 工具恢复它们，集群很可能会处于一种大多数（如果不是所有）RBD 镜像都无法访问的状态。然而，你仍然有可能从
    Ceph 集群中的磁盘中恢复 RBD 数据。有一些工具可以搜索 OSD 数据结构，找到与 RBD 相关的对象文件，然后将这些对象组装回磁盘映像，类似于原始的
    RBD 镜像。
- en: In this section, we will focus on a tool by Lennart Bader to recover a test
    RBD image from our test Ceph cluster. The tool allows the recovery of RBD images
    from the contents of Ceph OSDs, without any requirement that the OSD is in a running
    or usable state. It should be noted that if the OSD has been corrupted due to
    an underlying filesystem corruption, the contents of the RBD image may still be
    corrupt. The RBD recovery tool can be found in the following GitHub repository: [https://gitlab.lbader.de/kryptur/ceph-recovery](https://gitlab.lbader.de/kryptur/ceph-recovery).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将重点介绍 Lennart Bader 的一个工具，用于从我们的测试 Ceph 集群中恢复测试 RBD 镜像。该工具允许从 Ceph OSD 的内容中恢复
    RBD 镜像，而不要求 OSD 处于运行或可用状态。需要注意的是，如果 OSD 由于底层文件系统损坏而遭到损坏，则 RBD 镜像的内容可能仍然损坏。RBD
    恢复工具可以在以下 GitHub 仓库中找到：[https://gitlab.lbader.de/kryptur/ceph-recovery](https://gitlab.lbader.de/kryptur/ceph-recovery)。
- en: Before we start, make sure you have a small test RBD with a valid filesystem
    created on your Ceph cluster. Due to the size of the disks in the test environment
    that we created in [Chapter 2](dd1d6803-6e40-4bfb-8150-b605bcc08d59.xhtml), *Deploying
    Ceph with Containers*, it is recommended that the RBD is only a gigabyte in size.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保在 Ceph 集群上创建了一个小的、具有有效文件系统的测试 RBD。由于我们在[第 2 章](dd1d6803-6e40-4bfb-8150-b605bcc08d59.xhtml)《使用容器部署
    Ceph》中创建的测试环境中磁盘的大小，建议 RBD 仅为 1GB 大小。
- en: We will perform the recovery on one of the monitor nodes, but in practice, this
    recovery procedure can be done from any node that can access the Ceph OSD disks.
    To access the disks, we need to make sure that the recovery server has sufficient
    space to recover the data.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在其中一个监视器节点上执行恢复，但实际上，这个恢复过程可以在任何可以访问 Ceph OSD 磁盘的节点上进行。为了访问磁盘，我们需要确保恢复服务器有足够的空间来恢复数据。
- en: 'In this example, we will mount the remote OSDs contents via `sshfs`, which
    allows you to mount remote directories over `ssh`. However in real life, there
    is nothing to stop you from physically inserting disks into another server or
    whatever method is required. The tool only requires to see the OSDs data directories:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们将通过 `sshfs` 挂载远程 OSD 的内容，`sshfs` 允许您通过 `ssh` 挂载远程目录。然而，在实际情况中，没有什么能阻止您将磁盘物理插入到另一台服务器中或使用所需的任何方法。该工具仅需要查看
    OSD 的数据目录：
- en: 'Clone the Ceph recovery tool from the Git repository:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Git 仓库克隆 Ceph 恢复工具：
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前述命令的输出：
- en: '![](img/af283c1a-0176-44c8-921b-a1e0e7f64888.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/af283c1a-0176-44c8-921b-a1e0e7f64888.png)'
- en: 'Make sure you have `sshfs` installed:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保已安装 `sshfs`：
- en: '[PRE18]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前述命令的输出：
- en: '![](img/e0e5f4f8-8f8d-4ea7-b891-3b73af8dcdba.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e0e5f4f8-8f8d-4ea7-b891-3b73af8dcdba.png)'
- en: 'Change into the cloned tool directory, and create the empty directories for
    each of the OSDs:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换到克隆的工具目录，并为每个 OSD 创建空目录：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Filestore
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Filestore
- en: 'For filestore, we can simply mount each remote OSD to the directories that
    we have just created. Note that you need to make sure your OSD directories match
    your actual test cluster:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对于文件存储，我们可以将每个远程 OSD 挂载到我们刚创建的目录中。请注意，您需要确保您的 OSD 目录与实际测试集群匹配：
- en: '[PRE20]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: BlueStore
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BlueStore
- en: As Bluestore does not store the objects in a native Linux filesystem, we can't
    just mount the filesystems. However, the `ceph-object-store` tool allows you to
    mount the contents of a BlueStore OSD as a `fuse` filesystem.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Bluestore 不会将对象存储在本地 Linux 文件系统中，因此我们不能直接挂载文件系统。然而，`ceph-object-store` 工具允许您将
    BlueStore OSD 的内容作为 `fuse` 文件系统挂载。
- en: 'On each OSD node, create a directory under the `/mnt` folder to mount each
    OSD on that node:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个 OSD 节点上，在 `/mnt` 文件夹下创建一个目录，以挂载该节点上的每个 OSD：
- en: '[PRE21]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now mount the BlueStore OSD to this new directory:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将 BlueStore OSD 挂载到这个新目录：
- en: '[PRE22]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前述命令的输出：
- en: '![](img/6f27079b-d5c0-4eb1-bd2b-559ee2788071.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f27079b-d5c0-4eb1-bd2b-559ee2788071.png)'
- en: 'The BlueStore OSD is now mounted as a `fuse` filesystem to the `/mnt/osd-0`
    directory. However, it will only remain mounted while the `ceph-object-store`
    command is running. So if you wish to mount multiple OSDs or manually browse through
    the directory tree, open additional SSH sessions to the Ceph node. The following
    is a screenshot showing the contents of the `/mnt/osd-0` directory from a new
    SSH session:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: BlueStore OSD现在作为`fuse`文件系统挂载到`/mnt/osd-0`目录中。然而，它只会在`ceph-object-store`命令运行时保持挂载状态。因此，如果你希望挂载多个OSD或手动浏览目录树，请打开到Ceph节点的额外SSH会话。以下是一个截图，展示了来自新的SSH会话的`/mnt/osd-0`目录的内容：
- en: '![](img/eea946d5-22b9-48bd-ab4e-0304c43d382d.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eea946d5-22b9-48bd-ab4e-0304c43d382d.png)'
- en: When you have finished with the OSD, simply use *Ctrl* + *C* on the SSH session
    running the `ceph-objectstore-tool` command to unmount.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成对OSD的操作时，只需在运行`ceph-objectstore-tool`命令的SSH会话中按下*Ctrl* + *C*即可卸载。
- en: 'Now we can mount the fuse-mounted OSDs to our management server like we did
    with filestore:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以像处理filestore一样，将fuse挂载的OSD挂载到我们的管理服务器：
- en: '[PRE23]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: RBD assembly – filestore
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RBD组装 - filestore
- en: 'Now we can use the tool to scan the OSD directories and compile a list of the
    RBDs that are available. The only parameter needed for this command is the location
    where the OSDs are mounted. In this case, it is in a directory called `osds`.
    The results will be listed in the VM directory:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用工具扫描OSD目录并编译一个可用的RBD列表。此命令唯一需要的参数是OSD挂载的位置。在本例中，它位于名为`osds`的目录中。结果将列出在VM目录中：
- en: '[PRE24]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是上面命令的输出：
- en: '![](img/03846663-92d1-421a-b9e8-1d850a466aec.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/03846663-92d1-421a-b9e8-1d850a466aec.png)'
- en: 'If we look inside the VM directory, we can see that the tool has found our
    test RBD image. Now that we have located the image, the next step is to assemble
    various objects located on the OSDs. The three parameters for this command are
    the name of the RBD image found in the previous step, the size of the image, and
    the destination for the recovered image file. The size of the image is specified
    in bytes, and it is important that it is at least as big as the original image;
    it can be bigger, but the RBD will not recover if the size is smaller:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看VM目录，就会看到工具找到了我们的测试RBD镜像。现在我们已经找到了镜像，下一步是组装位于OSD上的各种对象。此命令的三个参数是前一步中找到的RBD镜像名称、镜像的大小以及恢复镜像文件的目标位置。镜像的大小以字节为单位指定，重要的是它至少与原始镜像一样大；它可以更大，但如果大小小于原始镜像，RBD将无法恢复：
- en: '[PRE25]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是上面命令的输出：
- en: '![](img/fb8634ea-7537-4ca6-8c1e-85ec5ed09712.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fb8634ea-7537-4ca6-8c1e-85ec5ed09712.png)'
- en: The RBD will now be recovered from the mounted OSD contents to the specified
    image file. Depending on the size of the image, it may take a while, and a progress
    bar will show you its progress.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: RBD现在将从挂载的OSD内容恢复到指定的镜像文件中。根据镜像的大小，恢复可能需要一段时间，并且进度条将显示恢复的进度。
- en: RBD assembly – BlueStore
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RBD组装 - BlueStore
- en: The RBD assembly script will not work with BlueStore OSDs as BlueStore stores
    the RBD objects with a slightly different naming convention. An updated script
    is provided in the following steps to aid with RBD recovery.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: RBD组装脚本不适用于BlueStore OSD，因为BlueStore使用稍有不同的命名规则来存储RBD对象。以下步骤提供了一个更新的脚本，以帮助进行RBD恢复。
- en: 'Download the script to assist with the recovery of RBDs from BlueStore OSDs:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 下载脚本以帮助从BlueStore OSD恢复RBD：
- en: '[PRE26]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Run the recovery script with three parameters, where first is the RBD image
    hash name, the second is the RBD size in bytes, and the third is the output filename.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 使用三个参数运行恢复脚本，第一个是RBD镜像的哈希名称，第二个是RBD的大小（以字节为单位），第三个是输出文件的文件名。
- en: 'The following example is from a 10 GB test RBD:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例来自一个10 GB的测试RBD：
- en: '[PRE27]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是上面命令的输出：
- en: '![](img/9730a343-be26-4597-96f9-efc388c15e15.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9730a343-be26-4597-96f9-efc388c15e15.png)'
- en: The RBD image should now be recovered.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: RBD镜像现在应该已经恢复。
- en: Confirmation of recovery
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 恢复确认
- en: 'Once completed, we can run a file system called `fsck` on the image to make
    sure that it has been recovered correctly. In this case, the RBD was formatted
    with `ext4`, so we can use the `e2fsck` tool to check the image:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们可以在镜像上运行一个名为`fsck`的文件系统检查工具，以确保其已经正确恢复。在这种情况下，RBD是使用`ext4`格式化的，因此我们可以使用`e2fsck`工具检查该镜像：
- en: '[PRE28]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是上面命令的输出：
- en: '![](img/7a9343f3-db9d-452e-b4f1-54b2af36e6cf.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7a9343f3-db9d-452e-b4f1-54b2af36e6cf.png)'
- en: Excellent, the image file is clean, which means that there is now a very high
    chance that all our data has been recovered successfully.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，图像文件是干净的，这意味着现在我们的所有数据恢复成功的可能性非常高。
- en: 'Now we can finally mount the image as a loopback device to access our data.
    If the command returns no output, we have successfully mounted it:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以最终将图像挂载为回环设备来访问我们的数据。如果命令没有返回任何输出，则表示我们已成功挂载：
- en: '[PRE29]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You can see that the image is successfully mounted as a loop device:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到图像已成功挂载为回环设备：
- en: '![](img/544665dd-0be5-4140-a6ea-bf07f3219bd1.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/544665dd-0be5-4140-a6ea-bf07f3219bd1.png)'
- en: RGW Multisite
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RGW 多站点
- en: Ceph also supports the ability to run two or more RADOS Gateway Zones to provide
    high availability of the S3 and swift-compatible storage across multiple sites.
    Each zone is backed by a completely separate Ceph cluster, meaning that it is
    extremely unlikely that any hardware of software failure can take the service
    completely offline. When using RGW in a multisite configuration, it's important
    to note that data is eventually consistent, so that data is not guaranteed to
    be in the same state in every zone immediately after it has been written.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Ceph 还支持运行两个或更多的 RADOS 网关区（RGW）以提供多个站点之间的 S3 和 swift 兼容存储的高可用性。每个区域都由一个完全独立的
    Ceph 集群支持，这意味着硬件或软件故障完全使服务下线的可能性极低。使用 RGW 的多站点配置时，必须注意数据是最终一致的，因此数据在每个区域中并不保证在写入后立即处于相同的状态。
- en: For more information on RGW multi-site configurations, please consult the official
    Ceph documentation.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多有关 RGW 多站点配置的信息，请参阅官方 Ceph 文档。
- en: CephFS recovery
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CephFS 恢复
- en: Unlike RBDs, which are simply a concatenation of objects, CephFS requires consistent
    data in both the data and metadata pools. It also requires a healthy CephFS journal;
    if any of these data sources have issues, CephFS will go offline and may not recover.
    This section of the chapter will look at recovering CephFS to an active state
    and then further recovery steps in the scenario that the metadata pool is corrupt
    or incomplete.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 与 RBD（仅是对象的串联）不同，CephFS 在数据池和元数据池中都需要一致的数据。它还要求 CephFS 日志健康；如果这些数据源中的任何一个出现问题，CephFS
    将下线并可能无法恢复。本章的这一部分将讨论如何将 CephFS 恢复到活动状态，并在元数据池损坏或不完整的情况下采取进一步的恢复步骤。
- en: There are a number of conditions where CephFS may go offline but will not result
    in any permanent data loss; these are often caused by transient events in the
    Ceph cluster but shouldn't result in any long-term data loss, and in most cases
    CephFS should automatically recover.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: CephFS 可能会在某些条件下下线，但不会导致任何永久性的数据丢失；这些通常是由 Ceph 集群中的瞬态事件引起的，但不应导致长期的数据丢失，并且在大多数情况下，CephFS
    应该会自动恢复。
- en: As CephFS sits on RADOS, barring any software bugs in CephFS, any data loss
    or corruption should only occur in the instance where there has been a data loss
    occurrence in the RADOS layer, perhaps due to multiple OSD failures leading to
    the loss of a PG.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 CephFS 基于 RADOS，除非 CephFS 中存在软件缺陷，否则数据丢失或损坏应仅在 RADOS 层发生数据丢失的情况下发生，这可能是由于多个
    OSD 故障导致 PG 丢失。
- en: The loss of objects or PGs from the data pool will not take the CephFS filesystem
    offline, but will result in access requests to the affected files to return zeroes.
    This will likely cause any applications higher up the stack to fail and, due to
    the semi-random nature of files or parts of files, which map to PGs, the result
    would likely mean that the CephFS filesystem is largely usable. The best case
    in this scenario would be to try to recover the RADOS pool PGs as seen later in
    this chapter.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 数据池中对象或 PG 的丢失不会导致 CephFS 文件系统下线，但会导致对受影响文件的访问请求返回零值。这很可能导致堆栈更高层的任何应用程序失败，并且由于文件或文件部分与
    PG 的映射具有半随机性质，结果很可能意味着 CephFS 文件系统仍然大部分可用。在这种情况下，最好的情况是尝试恢复 RADOS 池 PG，如本章后续所示。
- en: The loss of objects or PGs from the metadata pool will take the CephFS filesystem
    offline and it will not recover without manual intervention. It is important to
    point out that the actual data contents are unaffected by metadata loss, but the
    objects storing this data would be largely meaningless without the metadata. Ceph
    has a number of tools that can be used to recover and rebuild metadata, which
    may enable you to recover from metadata loss. However, as has been mentioned several
    times throughout this book, prevention is better than cure and as such, these
    tools should not been seen as a standard recovery mechanism, but only to be used
    as a last resort when recovery from regular backups have failed.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据池中的对象或 PG 丢失将使 CephFS 文件系统下线，并且在没有人工干预的情况下无法恢复。需要指出的是，实际的数据内容不会受到元数据丢失的影响，但存储这些数据的对象在没有元数据的情况下将大多毫无意义。Ceph
    提供了多种工具，可以用来恢复和重建元数据，这可能会帮助你从元数据丢失中恢复。然而，正如本书多次提到的那样，预防总是胜于治疗，因此这些工具不应被视为标准恢复机制，而应仅在常规备份恢复失败时作为最后的手段使用。
- en: Creating the disaster
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建灾难
- en: To create the scenario where a CephFS filesystem has lost or corrupted its metadata
    pool, we will simply delete all objects in the metadata pool. This example will
    use the filesystem deployed in [Chapter 5](a01c8234-61a1-4d8e-9393-33a7218cf49d.xhtml), *RADOS
    Pools and Client Access*, but the procedure should be identical to any other deployed
    CephFS filesystem.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建 CephFS 文件系统丢失或损坏元数据池的场景，我们将简单地删除元数据池中的所有对象。本示例将使用[第 5 章](a01c8234-61a1-4d8e-9393-33a7218cf49d.xhtml)中部署的文件系统，*RADOS
    池与客户端访问*，但此过程应该与任何其他部署的 CephFS 文件系统相同。
- en: 'First, let''s switch to the root account and mount the CephFS filesystem:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们切换到 root 账户并挂载 CephFS 文件系统：
- en: '[PRE30]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Place a few test files on the CephFS filesystem that we will later attempt
    to recover:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在 CephFS 文件系统上放置一些测试文件，稍后我们将尝试恢复它们：
- en: '[PRE31]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now that we have the test files in place, let''s delete all the objects in
    the metadata pool to simulate a loss of the metadata pool:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经放置了测试文件，让我们删除元数据池中的所有对象，以模拟元数据池丢失：
- en: '[PRE32]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前面命令的输出：
- en: '![](img/43d3be7e-aacc-4c02-ae94-944b07580388.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/43d3be7e-aacc-4c02-ae94-944b07580388.png)'
- en: 'Let''s restart the `mds` daemon; trigger the failure:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重启 `mds` 守护进程；触发故障：
- en: '[PRE33]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'If we now check the CephFS status with the `ceph -s` command, we can see that `mds`
    has detected metadata damage and taken the filesystem offline:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在使用 `ceph -s` 命令检查 CephFS 状态，可以看到 `mds` 已经检测到元数据损坏，并将文件系统下线：
- en: '![](img/f09752de-1e15-4ebe-8ac7-822be060c44b.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f09752de-1e15-4ebe-8ac7-822be060c44b.png)'
- en: 'To get more information on the damage, we can run the following command. Check
    the CephFS journal:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取更多关于损坏的信息，我们可以运行以下命令。检查 CephFS 日志：
- en: '[PRE34]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前面命令的输出：
- en: '![](img/f3f4ab78-93f3-4b3b-8d5f-190cf2cb03f8.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f4ab78-93f3-4b3b-8d5f-190cf2cb03f8.png)'
- en: Yep, that's severely damaged, as expected.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，正如预期的那样，它被严重损坏了。
- en: CephFS metadata recovery
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CephFS 元数据恢复
- en: 'Normally it would be suggested to export the journal for safe-keeping to minimize
    data loss, but in this case as we know we can safely just reset it straight away:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 通常建议导出日志以便安全保存，最小化数据丢失，但在这种情况下，由于我们知道可以安全地立即重置日志：
- en: '[PRE35]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前面命令的输出：
- en: '![](img/ddb9cda4-559a-46f9-88e3-9723db0aaf32.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ddb9cda4-559a-46f9-88e3-9723db0aaf32.png)'
- en: 'The next command resets the RADOS state of the filesystem to allow the recovery
    process to rebuild from a consistent state:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 下一条命令重置文件系统的 RADOS 状态，以便恢复过程能够从一致的状态重新构建：
- en: '[PRE36]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Next, the MDS tables are reset to enable them to be generated from scratch.
    These tables are stored as objects in the metadata pool. The following commands
    create new objects:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，MDS 表会被重置，以便重新生成。这些表作为对象存储在元数据池中。以下命令会创建新的对象：
- en: '[PRE37]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前面命令的输出：
- en: '![](img/4cd27b59-123f-4db7-a783-b055cf9eb70b.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4cd27b59-123f-4db7-a783-b055cf9eb70b.png)'
- en: 'Reset the CephFS journal:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 重置 CephFS 日志：
- en: '[PRE38]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Finally, create the root inodes and prepare for data-object discovery:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，创建根 inode 并准备数据对象的发现：
- en: '[PRE39]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now that the state of CephFS has been fully reset, scans of the data pool can
    be undertaken to rebuild the metadata from the available data objects. This is
    a three-stage process using the following three commands. The first command scans
    through the data pool, finds all the extents that make up each file, and stores
    this as temporary data. Information, such as creation time and file size is also
    calculated and stored. The second stage then searches through this temporary data
    and rebuilds inodes into the metadata pool. Finally the linking of the inodes
    occurs:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 CephFS 的状态已完全重置，可以开始对数据池进行扫描，以从可用的数据对象中重建元数据。这是一个三阶段的过程，使用以下三个命令。第一个命令扫描数据池，找到构成每个文件的所有扩展并将其存储为临时数据。信息，如创建时间和文件大小也会被计算并存储。第二阶段将搜索这些临时数据并将
    inode 重建到元数据池中。最后，inodes 的链接操作会发生：
- en: '[PRE40]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The scan inodes and extents commands can take an extremely long time to run
    on large filesystems. The operations can be run in parallel to speed the process
    up; check out the official Ceph documentation for more information.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 扫描 inodes 和扩展命令在大型文件系统上运行时可能需要极长时间。为了加速这个过程，可以并行运行这些操作；更多信息请查看官方 Ceph 文档。
- en: 'Once the process is complete, check that the CephFS filesystem is now in a
    healthy state:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦过程完成，请检查 CephFS 文件系统是否现在处于健康状态：
- en: '![](img/e9579401-5845-4773-a473-28a62880372b.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e9579401-5845-4773-a473-28a62880372b.png)'
- en: 'We should also now be able to browse the filesystem from the mount point where
    we mounted it at the start of this section:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在还应该能够从挂载点浏览文件系统，那个挂载点是在本节开始时挂载的：
- en: '![](img/0042412f-2cd6-4f84-bf19-4d45169a27a7.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0042412f-2cd6-4f84-bf19-4d45169a27a7.png)'
- en: Note that although the recovery tools have managed to locate the files and rebuild
    some of their metadata, information such as their name has been lost and hence
    placed inside the `lost+found` directory. By examining the contents of the files,
    we could identify which file is which and rename it to the original filename.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，尽管恢复工具已经成功定位了文件并重建了一些元数据，但像文件名这样的信息已经丢失，因此被放入了 `lost+found` 目录中。通过检查文件内容，我们可以识别每个文件，并将其重命名为原始文件名。
- en: In practice, although we have restored the CephFS filesystem, the fact that
    we are missing the files' original names and directory location likely means recovery
    is only partially successful. It should also be noted that the recovered filesystem
    may not be stable and it is highly recommended that any salvaged files be recovered
    before the filesystem is trashed and rebuilt. This is a disaster-recovery process
    that should only be used after ruling out restoring from backups.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，尽管我们已经恢复了 CephFS 文件系统，但由于缺少文件的原始名称和目录位置，可能意味着恢复只是部分成功。还应注意，恢复的文件系统可能不稳定，强烈建议在文件系统被销毁并重建之前，尽可能恢复任何抢救出来的文件。这是一个灾难恢复过程，应该在排除了从备份恢复的可能性后使用。
- en: Lost objects and inactive PGs
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 丢失的对象和非活动的 PG
- en: This section of the chapter will cover the scenario where a number of OSDs have
    gone offline in a short period of time, leaving some objects with no valid replica
    copies. It's important to note that there is a difference between an object that
    has no remaining copies and an object that has a remaining copy, but it is known
    that another copy has had more recent writes. The latter is normally seen when
    running the cluster with `min_size` set to `1`.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的这一部分将介绍一个场景，其中多个 OSD 在短时间内下线，导致某些对象没有有效的副本。需要注意的是，丢失副本的对象与仍有副本但另一个副本已做过更改的对象之间是有区别的。后者通常出现在将集群的
    `min_size` 设置为 `1` 时。
- en: 'To demonstrate how to recover an object that has an out-of-date copy of data,
    let''s perform a series of steps to break the cluster:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示如何恢复一个拥有过期数据副本的对象，让我们执行一系列步骤来破坏集群：
- en: 'Set `min_size` to `1`; hopefully by the end of this example, you will see why
    you don''t ever want to do this in real life:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `min_size` 设置为 `1`；希望通过本示例的结束，您能明白为什么在实际操作中绝对不想这样做：
- en: '[PRE41]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前面命令的输出：
- en: '![](img/680a90b5-efe5-4664-acf9-7157cb8cd463.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](img/680a90b5-efe5-4664-acf9-7157cb8cd463.png)'
- en: 'Create a test object that we will make later make Ceph believe is lost:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个测试对象，稍后我们将让 Ceph 认为它丢失了：
- en: '[PRE42]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: These two flags make sure that when the OSDs come back online after making the
    write to a single OSD, the changes are not recovered. Since we are only testing
    with a single option, we need these flags to simulate the condition in real life,
    where it's likely that not all objects can be recovered in sufficient time before
    the OSD, when the only copy goes offline for whatever reason.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个标志确保当OSD重新上线并向单个OSD写入时，变更不会被恢复。由于我们仅用单一选项进行测试，我们需要这些标志来模拟实际生活中的情况，在这种情况下，可能并非所有对象都能在足够的时间内恢复，尤其是当唯一副本的OSD由于某种原因离线时。
- en: 'Shut down two of the OSD nodes, so only one OSD is remaining. Since we have
    set `min_size` to `1`, we will still be able to write data to the cluster. You
    can see that the Ceph status shows that the two OSDs are now down:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭两个OSD节点，剩下一个OSD。由于我们已将`min_size`设置为`1`，我们仍然可以向集群写入数据。你可以看到，Ceph状态显示两个OSD现在都已离线：
- en: '![](img/02b12728-2ab5-435a-846e-f5cfc5ac05f6.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02b12728-2ab5-435a-846e-f5cfc5ac05f6.png)'
- en: 'Write to the object again, the write will go to the remaining OSD:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次写入该对象，写入将进入剩余的OSD：
- en: '[PRE43]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Shut down the remaining OSDs; once it has gone offline, power back the remaining
    two OSDs:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭剩余的OSD；当其离线后，重新启动另外两个OSD：
- en: '![](img/3dc3fc96-c9ea-410d-83c9-0f22e11fdd7b.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3dc3fc96-c9ea-410d-83c9-0f22e11fdd7b.png)'
- en: You can see that Ceph knows that it already has an unfound object even before
    the recovery process has started. This is because during the peering phase, the
    PG containing the modified object knows that the only valid copy is on `osd.0`,
    which is now offline.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，Ceph已经知道它在恢复过程开始之前就已经有一个未找到的对象。这是因为在对等阶段，包含修改对象的PG已经知道唯一有效的副本在`osd.0`上，而该副本现在已离线。
- en: Remove the `nobackfill` and `norecover` flags, and let the cluster try to perform
    recovery. You will see that even after the recovery has progressed, there will
    be one PG in a degraded state, and the unfound object warning will still be present.
    This is a good thing, as Ceph is protecting your data from corruption. Imagine
    what would happen if a 4 MB chunk of an RBD that contained a database suddenly
    went back in time.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除`nobackfill`和`norecover`标志，让集群尝试执行恢复。你会看到，即使恢复过程有所进展，仍然会有一个PG处于降级状态，且未找到对象的警告依然存在。这是一个好现象，因为Ceph正在保护你的数据免受损坏。试想，如果一个包含数据库的RBD的4
    MB块突然回退到之前的状态，会发生什么。
- en: If you try to read or write to our test object, you will notice the request
    will just hang; this is Ceph protecting your data. There are three ways to fix
    this problem. The first solution and the most ideal one is to get a valid copy
    of this object back online; this could either be done by bringing `osd.0` online,
    or by using the `objectstore` tool to export and import this object into a healthy
    OSD. For the purpose of this section, let's assume that neither of those options
    is possible. Before we cover the remaining two options, let's investigate further
    to uncover what is going on under the hood.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试读取或写入我们的测试对象，你会注意到请求会一直挂起；这是Ceph在保护你的数据。解决此问题有三种方法。第一种也是最理想的解决方案是让该对象的有效副本重新上线；这可以通过将`osd.0`重新上线，或使用`objectstore`工具导出并将此对象导入到健康的OSD中。为了本节的目的，假设这两种方法都不可行。在介绍剩下的两种解决方案之前，让我们进一步调查，揭示其背后的情况。
- en: 'Run the Ceph health detail to find out which PG is having the problem:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 运行Ceph健康详细信息，找出哪个PG存在问题：
- en: '![](img/4985dfe4-dd65-4f14-a96a-38319e8e59ee.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4985dfe4-dd65-4f14-a96a-38319e8e59ee.png)'
- en: 'In this case, it''s `pg 0.31`, which is in a degraded state, because it has
    an unfound object. Let''s query the `pg`:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，是`pg 0.31`，处于降级状态，因为它有一个未找到的对象。让我们查询一下这个`pg`：
- en: '[PRE44]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前面命令的输出：
- en: '![](img/8a0cc1a9-ac7a-4928-88c5-924fcc9e84b9.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8a0cc1a9-ac7a-4928-88c5-924fcc9e84b9.png)'
- en: 'Look for the recovery section; we can see that Ceph has tried to probe `"osd":
    "0"` for the object, but it is down. It has tried to probe `"osd": "1"` for the
    object, but for whatever reason it was of no use, we know the reason is that it
    is an out-of-date copy.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '查找恢复部分，我们可以看到Ceph已经尝试对对象进行探测，探测对象时，`"osd": "0"`不可用。它尝试对`"osd": "1"`进行探测，但由于某些原因无效，我们知道的原因是因为它是一个过时的副本。'
- en: 'Now, let''s look into some more detail on the missing object:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们更详细地查看缺失的对象：
- en: '[PRE45]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前面命令的输出：
- en: '![](img/721776ae-9340-4867-a3cb-04b3690a84cf.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![](img/721776ae-9340-4867-a3cb-04b3690a84cf.png)'
- en: The `need` and `have` lines reveal the reason. We have `epoch 383'5`, but the
    valid copy of the object exists in `398'6`; this is why `min_size=1` is bad. You
    might be in a situation where you only have a single valid copy of an object.
    If this was caused by a disk failure, you would have bigger problems.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '`need`和`have`行揭示了原因。我们有`epoch 383''5`，但该对象的有效副本存在于`398''6`；这就是为什么`min_size=1`是错误的原因。你可能会处于只有一个有效对象副本的情况。如果这是由磁盘故障引起的，那你将面临更大的问题。'
- en: 'To recover from this, we have two options: we can either choose to use the
    older copy of the object or simply delete it. It should be noted that if this
    object is new and an older copy does not exist on the remaining OSDs, it will
    also delete the object.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从中恢复，我们有两种选择：要么选择使用较旧的对象副本，要么直接删除它。需要注意的是，如果这个对象是新的，而剩余的OSD中没有较旧的副本，它也将删除该对象。
- en: 'To delete the object, run this:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除该对象，请运行以下命令：
- en: '[PRE46]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'To revert it, run this:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 要恢复，请运行以下命令：
- en: '[PRE47]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Recovering from a complete monitor failure
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从完整的监视器故障中恢复
- en: In the unlikely event that you lose all of your monitors, all is not lost. You
    can rebuild the monitor database from the contents of the OSDs with the use of `ceph-objectstore-tool`.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不太可能的情况下你丢失了所有监视器，仍然不算彻底失败。你可以使用`ceph-objectstore-tool`从OSD的内容中重建监视器数据库。
- en: To set the scenario, we will assume that an event has occurred and has corrupted
    all three monitors, effectively leaving the Ceph cluster inaccessible. To recover
    the cluster, we will shut down two of the monitors and leave a single failed monitor
    running. We will then rebuild the monitor database, overwrite the corrupted copy,
    and restart the monitor to bring the Ceph cluster back online.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设置场景，我们假设发生了某种事件，导致所有三个监视器都遭到破坏，从而使Ceph集群无法访问。为了恢复集群，我们将关闭两个监视器，只保留一个失败的监视器运行。然后，我们将重建监视器数据库，覆盖损坏的副本，并重新启动监视器，使Ceph集群恢复上线。
- en: The `objectstore` tool needs to be able to access every OSD in the cluster to
    rebuild the monitor database; in this example, we will use a script, which will
    connect via `ssh` to access the OSD data. As the OSD data is not accessible by
    every user, we will use the root user to log into the OSD hosts. By default, most
    Linux distributions will not allow remote, password-based root logins, so ensure
    you have copied your public `ssh` key to the root users on some remote OSD nodes.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '`objectstore`工具需要能够访问集群中的每个OSD，以便重建监视器数据库；在本示例中，我们将使用一个脚本，通过`ssh`连接来访问OSD数据。由于OSD数据并非所有用户都能访问，我们将使用root用户登录到OSD主机。默认情况下，大多数Linux发行版不允许远程通过密码登录root用户，因此请确保你已经将你的公钥`ssh`复制到某些远程OSD节点的root用户。'
- en: 'The following script will connect to each of the OSD nodes specified in the
    hosts variable, and it will extract the data required to build the monitor database:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本将连接到`hosts`变量中指定的每个OSD节点，并提取构建监视器数据库所需的数据：
- en: '[PRE48]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This will generate the following contents in the `/tmp/mon-store` directory:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下内容到`/tmp/mon-store`目录：
- en: '![](img/0cca07f6-fdc4-4f29-a8e8-041ae47b8c4d.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0cca07f6-fdc4-4f29-a8e8-041ae47b8c4d.png)'
- en: 'We also need to assign new permissions via the `keyring`:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要通过`keyring`分配新的权限：
- en: '[PRE49]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图为前述命令的输出：
- en: '![](img/10feb3c6-60c8-478b-86dc-b78a329c1e95.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](img/10feb3c6-60c8-478b-86dc-b78a329c1e95.png)'
- en: '[PRE50]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '![](img/35b21c1e-aa9b-4cec-8c54-609dd0eb3dc7.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![](img/35b21c1e-aa9b-4cec-8c54-609dd0eb3dc7.png)'
- en: 'Now that the monitor database is rebuilt, we can copy it to the monitor directory,
    but before we do so, let''s take a backup of the existing database:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在监视器数据库已重建，我们可以将其复制到监视器目录中，但在此之前，让我们先备份现有数据库：
- en: '[PRE51]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Now, copy the rebuilt version:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，复制重建后的版本：
- en: '[PRE52]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'If you try to start the monitor now, it will get stuck in a probing state,
    as it tries to probe for other monitors. This is Ceph trying to avoid a split-brain
    scenario; however, in this case, we want to force it to form a quorum and go fully
    online. To do this, we need to edit `monmap`, remove the other monitors, and then
    inject it back into the monitors database:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在尝试启动监视器，它会陷入探测状态，因为它试图探测其他监视器。这是Ceph试图避免脑裂情况；然而，在这种情况下，我们希望强制它形成法定人数并完全上线。为此，我们需要编辑`monmap`，删除其他监视器，然后将其重新注入监视器数据库：
- en: '[PRE53]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Check the contents of `monmap`:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 检查`monmap`的内容：
- en: '[PRE54]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图为前述命令的输出：
- en: '![](img/6b94da93-d24d-438c-afb3-23d1d79c8a56.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6b94da93-d24d-438c-afb3-23d1d79c8a56.png)'
- en: 'You will see that there are three `mons` present, so let''s remove two of them:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Now, check again to make sure they are completely gone:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5f0a16e4-2500-4f5f-bd48-d7ad9b961af2.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
- en: '[PRE57]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Restart all your OSDs, so they rejoin the cluster; then you will be able to
    successfully query the cluster status and see that your data is still there:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d1eb22c8-c9fd-478e-9029-788cdbb74f97.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
- en: Using the Ceph object-store tool
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hopefully, if you have followed best practices, your cluster is running with
    three replicas and is not configured with any dangerous configuration options.
    Ceph, in most cases, should be able to recover from any failure.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: However, in the scenario where a number of OSDs go offline, a number of PGs
    and/or objects may become unavailable. If you are unable to reintroduce these
    OSDs back into the cluster to allow Ceph to recover them gracefully, the data
    in those PGs is effectively lost. However, there is a possibility that the OSD
    is still readable to use the `objectstore` tool to recover the PGs contents. The
    process involves exporting the PGs from the failed OSDs and then importing the
    PGs back into the cluster. The `objectstore` tool requires that the OSDs' internal
    metadata is still in a consistent state, so full recovery is not guaranteed.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to demonstrate the use of the `objectstore` tool, we will shut down
    two of our three test cluster OSDs, and then recover the missing PGs back into
    the cluster. In real life, it''s unlikely you would be facing a situation where
    every single PG from the failed OSDs is missing, but for demonstration purposes,
    the required steps are the same:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: 'Set the pool size to `2`, so we can make sure that we lose all the copies of
    some PGs when we stop the OSD service:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/023010d3-2bab-462a-a54e-eaee3b8ffe27.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
- en: 'Shut down two of the OSD services, and you will see from the Ceph status screen
    that the number of PGs will go offline:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8e86c55f-84bc-4853-85e5-87ae38a2d9c3.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
- en: 'Running a Ceph health detail will also show which PGs are in a degraded state:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/43a5b418-5f23-48c5-9549-f8836f399cd7.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
- en: The stale PGs are the ones that no longer have a surviving copy, and it can
    be seen that the acting OSD is the one that was shut down.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: If we use `grep` to filter out just the stale PGs, we can use the resulting
    list to work out what PGs we need to recover. If the OSDs have actually been removed
    from the cluster, the PGs will be listed as incomplete rather than stale.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'Check the OSD to make sure the PG exists in it:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c2f4b88f-9d71-4e1f-9381-f38af27cd549.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
- en: 'Use the `objectstore` tool to export the `pg` to a file. As the amount of data
    in our test cluster is small, we can just export the data to the OS disk. In real
    life, you probably want to consider connecting additional storage to the server.
    USB disks are ideal for this, as they can easily be moved between servers as part
    of the recovery process:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7ff2b4b2-413c-46c2-9aa1-9b29c935605d.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
- en: If you experience an assert while running the tool, you can try running it with
    the `--skip-journal-replay` flag, which will skip replaying the journal into the
    OSD. If there was any outstanding data in the journal, it will be lost. But this
    may allow you to recover the bulk of the missing PGs that would have otherwise
    been impossible. And repeat this until you have exported all the missing PGs.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Import the missing PGs back into an operating OSD. While we could import the
    PGs into an existing OSD, it is much safer to perform the import on a new OSD,
    so we don't risk further data loss. For this, create a directory-based OSD on
    the disk used by the failed OSD. It's highly recommended in a real disaster scenario
    that the data would be inserted into an OSD running on a separate disk, rather
    than using an existing OSD. This is done so that there is no further risk to any
    data in the Ceph cluster.
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Also, it doesn't matter that the PGs that are being imported are all inserted
    into the same temporary OSD. As soon as Ceph discovers the objects, it will recover
    them to the correct location in the cluster.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new empty folder for the OSD:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Use `ceph-disk` or `ceph-volume` to prepare the directory for Ceph:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Change the ownership of the folder to the `ceph` user and the group:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Activate the OSD to bring it online:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Set the weight of the OSD to stop any objects from being backfilled into it:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Proceed with the PG import, specifying the temporary OSD location and the PG
    files that we exported earlier:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The following screenshot is the output for the preceding command:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d99e0733-217c-47b3-ad51-6e1f9becc339.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
- en: 'Repeat this for every PG that you exported previously. Once complete, reset
    file ownership and restart the new temp OSD:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Check the Ceph status output, you will see that your PGs are now active, but
    in a degraded state. In the case of our test cluster, there are not sufficient
    OSDs to allow the objects to recover to the correct amount of copies. If there
    were more OSDs in the cluster, the objects would then be backfilled around the
    cluster and would recover to full health with the correct number of copies:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2dbf57f8-5e7b-4825-ada7-e60441f96a32.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
- en: Investigating asserts
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Assertions are used in Ceph to ensure that, during the execution of the code,
    any assumptions that have been made about the operating environment remain true.
    These assertions are scattered throughout the Ceph code and are designed to catch
    any conditions that may go on to cause further problems if the code is not stopped.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: If you trigger an assertion in Ceph, it's likely that some form of data has
    a value that is unexpected. This may be caused by some form or corruption or unhandled
    bug.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在Ceph中触发了断言，很可能是某些数据的值超出了预期。这可能是由于某种形式的损坏或未处理的Bug造成的。
- en: If an OSD causes an assert and refuses to restart, the usual recommended approach
    would be to destroy the OSD, recreate it, and then let Ceph backfill objects back
    to it. If you have a reproducible failure scenario, it is probably also worth
    filing a bug in the Ceph bug tracker.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个OSD触发了断言并且拒绝重启，通常推荐的做法是销毁该OSD，重新创建它，然后让Ceph将对象回填到它上面。如果你有可复现的失败场景，可能也值得在Ceph的缺陷跟踪系统中提交一个Bug。
- en: As mentioned, OSDs can fail either due to hardware or software faults in either
    the stored data or OSD code. Software faults are much more likely to affect multiple
    OSDs at once; if your OSDs have become corrupted due to a power outage, it's highly
    likely more than one OSD will be affected. In the case where multiple OSDs are
    failing with asserts and they are causing one or more PGs in the cluster to be
    offline, simply recreating the OSDs is not an option. The OSDs that are offline
    contain all the three copies of the PG, so recreating the OSDs would make any
    form of recovery impossible and result in permanent data loss.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，OSD失败可能是由于硬件或软件故障，故障可能发生在存储的数据或OSD代码中。软件故障更有可能影响多个OSD；如果你的OSD因停电而遭到损坏，很可能会影响多个OSD。在多个OSD发生断言并导致集群中一个或多个PG处于离线状态的情况下，单纯重建OSD并不是一个选择。离线的OSD包含了PG的三份副本，因此重建这些OSD会使任何形式的恢复变得不可能，并导致数据永久丢失。
- en: Before attempting the recovery techniques in this chapter, such as exporting
    and importing PGs, investigation into the asserts should be done. Depending on
    your technical ability and how much downtime you can tolerate before you need
    to start focusing on other recovery steps, investigating the asserts may not result
    in any success. By investigating the assert and looking through the Ceph source
    referenced by the assert, it may be possible to identify the cause of the assert.
    If this is possible, a fix can be implemented in the Ceph code to avoid the OSD
    asserting. Don't be afraid to reach out to the community for help on these matters.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试本章中的恢复技术之前，如导出和导入PG，应该先调查断言。根据你的技术能力和在开始关注其他恢复步骤之前能容忍的停机时间，调查断言可能并不会取得任何成功。通过调查断言并查看断言中引用的Ceph源代码，可能可以识别出断言的原因。如果可能的话，可以在Ceph代码中实施修复，以避免OSD断言。不要害怕在这些问题上向社区寻求帮助。
- en: In some cases, the OSD corruption may be so severe that even the `objectstore`
    tool itself may assert when trying to read from the OSD. This will limit the recovery
    steps outlined in this chapter, and trying to fix the reason behind the assert
    might be the only option. Although by this point, it is likely that the OSD has
    sustained heavy corruption, and recovery may not be possible.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，OSD损坏可能非常严重，以至于即使是`objectstore`工具本身在尝试从OSD读取时也可能会触发断言。这将限制本章中概述的恢复步骤，而尝试修复断言背后的原因可能是唯一的选择。尽管到这时，OSD可能已经遭受了严重的损坏，恢复可能已不再可能。
- en: Example assert
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例断言
- en: 'The following assert was taken from the Ceph user''s mailing list:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 以下断言来自Ceph用户邮件列表：
- en: '[PRE67]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: The top part of the assert shows the function from where the assert was triggered
    and also the line number and file where the assert can be found. In this example,
    the `hit_set_trim` function is apparently the cause of the assert. We can look
    into the `ReplicatedPG.cc` file around line 10,514 to try to understand what might
    have happened. Note the version of the Ceph release (0.94.7), as the line number
    in GitHub will only match if you are looking at the same version.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 断言的顶部部分显示了触发断言的函数，以及可以找到该断言的行号和文件。在这个例子中，`hit_set_trim`函数显然是断言的原因。我们可以查看`ReplicatedPG.cc`文件中的第10,514行左右，尝试理解可能发生了什么。请注意Ceph版本（0.94.7），因为GitHub上的行号只有在查看相同版本时才会匹配。
- en: From looking at the code, it appears that the returned value from the `get_object_context`
    function call is directly passed to the `assert` function. If the value is zero –
    indicating the object containing the hit-set to be trimmed could not be found – the
    OSD will assert. From this information, there is a chance that investigation could
    be done to work out why the object is missing and recover it. Or the `assert`
    command could be commented out to see whether it allows the OSD to continue functioning.
    In this example, allowing the OSD to continue processing will likely not cause
    an issue, but in other cases, an assert may be the only thing stopping more serious
    corruption from occurring. If you don't 100% understand why something is causing
    an assert, and the impact of any potential change you might make, seek help before
    continuing.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to troubleshoot Ceph when all looks lost. If
    Ceph is unable to recover PGs itself, you now understand how to manually rebuild
    PGs from failed OSDs. You can also rebuild the monitor's database if you lose
    all of your monitor nodes but still have access to your OSDs. You explored the
    process of recreating RBDs from the raw data remaining on your OSDs. Finally,
    you configured two separate Ceph clusters and configured replication between them
    using RBD mirroring to provide a failover option, should you encounter a complete
    Ceph cluster failure.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-334
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What Ceph daemon allows RBDs to be replicated to another Ceph cluster?
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True or false: RBDs by default are just a concatenated string of objects.'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What tool can be used to export or import a PG from or to an OSD?
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True or false: An unfound object status means that data has been lost forever.'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the main disadvantage you are left with after rebuilding CephFS metadata?
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
