<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Introducing the GitLab Architecture</h1>
                </header>
            
            <article>
                
<p>Understanding the context of the GitLab project will help us to appreciate the choices that were made with regard to the design of the GitLab workflow. The GitLab project started out as a small, open source project, and has grown to be an organization of 400 people and thousands of volunteers. It is currently available in two versions, a free <strong>Community Edition</strong> (<strong>CE</strong>) and an <strong>Enterprise Edition</strong> (<strong>EE</strong>) with a proprietary license. There are several tiers of support for the enterprise version. Although it is proprietary licensed, the source code for that version is publicly available from GitLab.</p>
<p>To master GitLab, it is necessary to have a solid understanding of its individual components. In this chapter, we will look at the basic components of a GitLab installation, paying special attention to GitLab <strong>Continuous Integration</strong> (<strong>CI</strong>) and the accompanying runners. As the different components can be distributed across servers or even cloud providers, we will also provide an overview of those providers and how GitLab views them.</p>
<p>In this chapter, we will be covering the following topics:</p>
<ul>
<li class="mce-root"><span>The origins of GitLab</span></li>
<li>GitLab CE or EE</li>
<li>The core components of GitLab</li>
<li>GitLab CI</li>
<li>GitLab Runners</li>
<li>Cloud native</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p><span>To follow along with the instructions in this chapter, please download the Git repository with examples<strong>,</strong> available at GitHub: <a href="https://github.com/PacktPublishing/Mastering-GitLab-12/tree/master/Chapter01">https://github.com/PacktPublishing/Mastering-GitLab-12/tree/master/Chapter01</a>. </span>You will also require Homebrew<span>: </span><a href="https://brew.sh/">https://brew.sh/</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The origins of GitLab</h1>
                </header>
            
            <article>
                
<p>The story began in 2011, when Dimitri Zaporozhets, a <span><span>web </span></span>programmer from Ukraine, was faced with a common problem. He wanted to switch to Git for version management and GitHub to collaborate, but that was not allowed in his company. He needed a tool that did not hinder him in developing code and was easy to use. Like many developers, he had issues with the collaboration tool that he was obliged to use. To get around those issues, he created his side project in Ruby on Rails: GitLab. Together with his colleague, Valery Sizov, he developed this project alongside his regular work.</p>
<p>After this initiative, the project grew enormously:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p><strong>Date</strong></p>
</td>
<td>
<p><strong>Fact</strong></p>
</td>
</tr>
<tr>
<td>
<p>2011</p>
</td>
<td>
<p><span><span>Sytze Sybrandij,</span></span><span> the future CEO of GitLab, is impressed by the GitLab project and code, and offers Zaporozhets the opportunity to try to commercialize it via <a href="https://about.gitlab.com/">https://about.gitlab.com/.</a></span></p>
</td>
</tr>
<tr>
<td>
<p>2012</p>
</td>
<td>
<p><span>GitLab was announced to a broader audience via Hacker News (<a href="https://news.ycombinator.com/item?id=4428278">https://news.ycombinator.com/item?id=4428278</a></span>).</p>
</td>
</tr>
<tr>
<td>
<p>2013</p>
</td>
<td>
<p><span>Dimitri Zaporozhets decides to work full-time on GitLab and joins the company.</span></p>
</td>
</tr>
<tr>
<td>
<p>2015</p>
</td>
<td>
<p>GitLab becomes part of the Y Combinator class and received VC funding that year.</p>
</td>
</tr>
<tr>
<td>
<p>2018</p>
</td>
<td>
<p>GitLab receives another $100 million of VC funding and is valued at $1 billion.</p>
</td>
</tr>
<tr>
<td>
<p>2019</p>
</td>
<td>
<p>The GitLab company employs over 600 employees.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>The<span> initial idea of GitLab was to earn money from open source technology by offering support services. However, what happened was that companies started to bring in consultants only to upgrade GitLab, and then they would stop the service contract. It became clear that going for a 100% open source was not going to be competitive. Instead of this, therefore, they chose <strong>open core</strong>. Under open core, a company releases a core software system under an open source license. A different version of the software is sold under a commercial license and contains more features.<br/></span></p>
<p>So, GitLab was split up into two editions: an open source version, and an enterprise version.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring GitLab editions – CE and EE</h1>
                </header>
            
            <article>
                
<p>The core of the GitLab software is called the <strong>CE</strong>. It is distributed under the MIT license, which is a permissive free software license created at the Massachusetts Institute of Technology. You are allowed to modify the software and use it in your creations.</p>
<p>No <span>feature that ever made it to CE will ever be removed, or moved to a closed source version. </span>When GitLab EE was created in 2013, it was, at its core, GitLab CE, but it had additional enterprise features, such as <strong>Lightweight Directory Access Protocol</strong> (<strong>LDAP</strong>) groups. Those features are not open source, per se, but can be added to the core version if they are perceived by the company as a core feature. The idea was that companies should also contribute as much as possible to solving problems and creating new features.</p>
<p>In 2016, the GitLab EE product was divided into three tiers: Starter, Premium, and Ultimate. Each tier is about five times more expensive than the previous one and contains more features and support options, as mentioned in the following table:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p><strong>Version</strong></p>
</td>
<td>
<p><strong>Features (short list)</strong></p>
</td>
</tr>
<tr>
<td>
<p>Starter</p>
</td>
<td>
<p>Everything on core GitLab CE:</p>
<ul>
<li>CI/CD</li>
<li>Project Issue Board</li>
<li>Mattermost integrations</li>
<li>Time tracking</li>
<li>GitLab pages</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>Premium</p>
</td>
<td>
<p>More enterprise features such as the following:</p>
<ul>
<li>Maven and NPM repository functionality</li>
<li>Protected environments</li>
<li>Burndown charts</li>
<li>Multiple LDAP servers and Active Directory support</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>Ultimate</p>
</td>
<td>
<p>All options, including the following:</p>
<ul>
<li>All security scanning tools</li>
<li>Epics</li>
<li>Free guest users</li>
<li>Web terminal for the web IDE</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>GitLab has a lot of features, but let's concentrate first on the basic building blocks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The core system components of GitLab</h1>
                </header>
            
            <article>
                
<p><span><span>GitLab is not a monolithic application. It tries to follow the Unix philosophy, which means that a software module should do only one particular thing, and do it well. The components that GitLab is made of are not as small and elegant as Unix's <kbd>awk</kbd> and <kbd>sed</kbd>, but each component has a single purpose. You can find a high-level overview of these components in the following diagram:</span></span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f9662aa4-972d-4c6f-9b9b-c406e97a3768.png" style="width:41.75em;height:30.75em;"/></p>
<p><span>Gitlab started as a pure Ruby on Rails application, but </span><span>some components </span><span>were</span><span> </span><span>later redesigned using Go. </span>Ruby on Rails is a development framework built on top of the Ruby programming language. It implements a model-view-controller pattern and offers methods to connect to different databases (for example, ActiveRecord). It values convention over configuration and <strong>don't-repeat-yourself</strong> (<strong>DRY</strong>) programming. <span>It is very well suited to rapid development, and at the same time, it is highly </span>performant <span>and has many features.</span></p>
<p>Let's dive a little deeper into those components in order to understand their roles.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">NGINX</h1>
                </header>
            
            <article>
                
<p>The Unicorn web component cannot be used directly as it does not offer all the features for handling clients. The reverse proxy that is bundled by default is NGINX. It is also possible to use Apache as a frontend for GitLab, but it is preferable to use NGINX. There are many web servers available that could be installed in front of Unicorn, but in the end, there are basically two types, which are as follows: </p>
<ul>
<li>Process-based (forking or threaded)</li>
<li>Asynchronous</li>
</ul>
<p>NGINX and lighttpd are probably the two most-well known asynchronous servers. Apache is without a doubt the de facto standard process-based server. The biggest difference between the two types is how they handle scalability. For a process-based server, any new connections require a thread, while an event-driven, asynchronous server such as NGINX only needs a few threads (or, theoretically, only one). For lighter workloads, this does not matter much, but you will see a big difference when the number of connections grows, especially in terms of RAM. When serving tens of thousands of simultaneous connections, the amount of RAM used by NGINX would still hover around a couple of megabytes. Apache would either use hundreds, or it would not work at all. This is why NGINX is the better choice.</p>
<p>You can run NGINX on many platforms and it is quite easy to install, as you can see in the next section, where you'll try it yourself!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing NGINX</h1>
                </header>
            
            <article>
                
<p>NGINX is part of most package management repositories, including <kbd>yum</kbd> and <kbd>apt</kbd>. Installing NGINX on <span><kbd>apt</kbd>-based distributions such as Debian and Ubuntu </span><span>would involve the following commands:</span></p>
<pre><strong>sudo apt-get update</strong><br/><strong>sudo apt-get install nginx</strong></pre>
<p>On macOS, we can use <kbd>brew</kbd> for a fast one-line command:</p>
<pre><strong>brew install nginx</strong></pre>
<p>Of course, it is always possible to install from the source. Remember to install the dependencies first. These include PCRE, zlib, and OpenSSL. You can find the source code at the following website: <a href="http://nginx.org/en/download.html">http://nginx.org/en/download.html</a>.</p>
<p>Before you start NGINX, you need to provide a configuration file for it to connect to the Unicorn web component. The interface between the two servers is a local Unix domain socket. </p>
<p>Please create a file called <kbd>nginx.config</kbd> and add the following:</p>
<pre>events{}</pre>
<p>The preceding section is mandatory and you can specify how NGINX will handle connections. For this example, we just accept the default; that is why the section is empty.</p>
<p>The next section is an HTTP block. You can define several and let settings be inherited, but here, we define that HTTP requests should be redirected to <kbd>upstream gitlab-app</kbd>, which is Unicorn. You can also see that the interface is the Unix socket:</p>
<pre><br/>http {<br/><br/># Tell nginx there is a unicorn waiting<br/> upstream gitlab-app {<br/> server unix:/var/www/gitlab-app/tmp/sockets/unicorn.sock fail_timeout=0;<br/> }</pre>
<p>So, we have defined how NGINX connects to the backend, which is GitLab. On the frontend, we want to accept requests from HTTP clients. This is taken care of via a <kbd>server</kbd> block:</p>
<pre>server {<br/> listen 8080;<br/> server_name localhost;</pre>
<p>The next directive inside this block handles a path that doesn't exist on disk. It forwards the request to the app:</p>
<pre><br/> try_files $uri/index.html $uri @gitlab-app;</pre>
<p>The following is the definition of <kbd>gitlab-app</kbd>, and it modifies request headers to proxy the request to the upstream Unicorn server via the Unix socket:</p>
<pre><br/> location @gitlab-app {<br/> proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;<br/> proxy_set_header Host $http_host;<br/> proxy_redirect off;<br/> proxy_pass http://gitlab-app;<br/> }</pre>
<p>Don't forget to close the server and HTTP block:</p>
<pre> }<br/>}</pre>
<p>Now that we have a configuration, you can run this NGINX in the following way:</p>
<pre class="mce-root"><strong>nginx -c /path/to/nginx.config</strong></pre>
<p>The command should return no output and the NGINX server runs in the background. You can<strong> </strong>verify this yourself<strong> </strong>by checking the process list:</p>
<pre><strong>$ ps -ax|grep nginx |grep -v grep</strong><br/><strong>33310 ?? 0:00.00 nginx: master process nginx -c /Users/joostevertse/nginx.config </strong><br/><strong>33312 ?? 0:00.00 nginx: worker process</strong></pre>
<p>Now that you have a running NGINX server, if you point your browser to <kbd>http://localhost:8080</kbd><span>,</span> you should receive a 502 error. This is because there is no Unicorn server listening on a Unix socket yet. We will demonstrate how to run Unicorn in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Unicorn</h1>
                </header>
            
            <article>
                
<p>Unicorn is an HTTP server for applications that deal with well-performing<span> clients on connections that show low latency and have enough bandwidth.</span> <span>It takes advantage of features that are present in the core of Linux-like systems.</span> <span>It is called a <strong>Rack HTTP server</strong> because it implements HTTP for Rack applications. Rack, in turn, is actually a Ruby implementation of a minimal interface to deal with web requests, which you can use in your code.</span></p>
<div class="packt_infobox"><span>You can find the project at <a href="https://rack.github.io">https://rack.github.io</a>.</span></div>
<p class="mce-root">Unicorn runs as a daemon <span>server</span> in Unix and is programmed in Ruby and the C programming language. Using Ruby means that it can also run a Ruby on Rails application such as GitLab. </p>
<p>Now that you have a grasp of the basic concepts of Unicorn, we can install it, and also connect NGINX, which we installed earlier, to it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing Unicorn</h1>
                </header>
            
            <article>
                
<p>If <span>you have Ruby installed, you can easily install Unicorn using the following steps:</span></p>
<ol>
<li>The first step is installing Ruby on Rails:</li>
</ol>
<pre style="padding-left: 60px"><strong>$gem install rails</strong></pre>
<ol start="2">
<li>The next step it to install the Unicorn server binary:</li>
</ol>
<pre style="padding-left: 60px"><strong>$gem install unicorn</strong></pre>
<ol start="3">
<li>Let's continue with installing web documents in <kbd>/usr/local/www</kbd>. We'll begin by creating the directory:</li>
</ol>
<pre style="padding-left: 60px"><strong>$mkdir /usr/local/www</strong><br/><strong>$chmod 755 /usr/local/www</strong><br/><strong>$cd /usr/local/www</strong></pre>
<ol start="4">
<li>We can now create our Rails application that is to be served with Unicorn:</li>
</ol>
<pre style="padding-left: 60px"><strong>$rails new gitlab-app</strong></pre>
<ol start="5">
<li>After an enormous output, which may look a bit scary, there is a preconfigured application ready for you. Let's configure Unicorn to serve it. We can get a default configuration file here:</li>
</ol>
<pre style="padding-left: 60px"><strong>cd gitlab-app/config</strong><br/><strong>wget https://raw.github.com/defunkt/unicorn/master/examples/unicorn.conf.rb</strong></pre>
<ol start="6">
<li>We have to change some things. Let's start by making a variable for the basic application folder:</li>
</ol>
<pre style="padding-left: 60px"><strong>APP_PATH = "/var/www/gitlab-app"</strong></pre>
<ol start="7">
<li>Now we can change the following paths:</li>
</ol>
<pre style="padding-left: 60px"><strong>working_directory APP_PATH</strong><br/><strong>stderr_path APP_PATH + "/log/unicorn.stderr.log"</strong><br/><strong>stdout_path APP_PATH + "/log/unicorn.stderr.log"</strong><br/><strong>pid APP_PATH + "/tmp/pid/unicorn.pid"</strong></pre>
<ol start="8">
<li>Unicorn can listen on ports and/or sockets. We are going to use listen on a Unix socket because that is the shortest path:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>#change the path to the socket (defined also in nginx config)</strong><br/><strong>listen app_path + '/tmp/sockets/unicorn.sock', backlog: 64</strong></pre>
<ol start="9">
<li>We <span>can start Unicorn with the following command:</span></li>
</ol>
<pre style="padding-left: 60px"><strong>unicorn -c config/unicorn.rb</strong></pre>
<p>If NGINX was started <span>earlier </span><span>as well, we can now point our browser to <kbd>http://localhost:8080</kbd>.</span></p>
<p>Now, maybe you encountered errors and want to find out what went wrong. It may be necessary to know how to debug NGINX and Unicorn when there are problems. This will be covered in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Debugging Unicorn</h1>
                </header>
            
            <article>
                
<p>Maybe installing Unicorn produced errors, or you are experiencing bad performance that you suspect is caused by Unicorn not working properly.</p>
<p>There are several ways to find the cause. The log files can point you in the right direction.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Timeouts in Unicorn logs</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>The following output is what a Unicorn worker timeout looks like in <kbd>unicorn_stderr.log</kbd>. This is not necessarily bad; it just means that a new worker is spawned:</span></p>
<div>
<pre><strong> [2015-06-05T10:58:08.660325 #56227] ERROR -- : worker=10 PID:53009 timeout (61s &gt; 60s), killing</strong><br/><strong> [2015-06-05T10:58:08.699360 #56227] ERROR -- : reaped #&lt;Process::Status: pid 53009 SIGKILL (signal 9)&gt; worker=10</strong><br/><strong> [2015-06-05T10:58:08.708141 #62538] INFO -- : worker=10 spawned pid=62538</strong><br/><strong> [2015-06-05T10:58:08.708824 #62538] INFO -- : worker=10 ready</strong></pre></div>
<p>It could be that there are just not enough Unicorn workers available to respond to the requests at hand. NGINX buffers a lot of requests so we must check on the handover socket whether Unicorn can keep up. To do this,<strong> </strong>a little nifty script is available here: <a href="https://github.com/jahio/unicorn-status">https://github.com/jahio/unicorn-status</a>.</p>
<p>It can be called with the following command:</p>
<pre><strong>$ ruby unicorn_status.rb /var/opt/gitlab/gitlab-rails/sockets/gitlab.socket 10</strong><br/><strong>Running infinite loop. Use CTRL+C to exit.</strong><br/><strong>------------------------------------------</strong><br/><strong>Active Requests Queued Requests</strong><br/><strong>20 11</strong></pre>
<p>The first argument here is the <kbd>unicorn_status.rb</kbd> script, the second is the socket to connect to <kbd>../.socket</kbd>, and the last argument is the poll interval (<kbd>10</kbd>).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Unicorn processes disappear </h1>
                </header>
            
            <article>
                
<p>On Linux, there is a mechanism called <strong>Out-of-Memory</strong> (<strong>OOM</strong>) <strong>Killer</strong> that will free up memory if the system is running low on memory, and you <span><span>don't have any swap memory left</span></span>. It might kill Unicorn if it is using too much memory.</p>
<p>Use <kbd>dmesg | egrep -i 'killed process'</kbd> to search for OOM events:</p>
<pre><strong>[102335.3134488] Killed process 5567 (ruby) total-vm:13423004kB, anon-rss:554088kB</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Other kinds of errors or 100% CPU load</h1>
                </header>
            
            <article>
                
<p>The ultimate way to debug Unicorn processes is to run strace on them:</p>
<ol>
<li>Run <kbd>sudo gdb -p (PID)</kbd> to attach to the Unicorn process.</li>
<li>Run <kbd>call (void) rb_backtrace()</kbd> in the <span>GDB</span> console and find the generated Ruby backtrace in <kbd>/var/log/gitlab/unicorn/unicorn_stderr.log</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong> from /opt/gitlab/embedded/lib/ruby/gems/2.4.0/gems/bundler-1.16.2/lib/bundler/cli/exec.rb:28:in `run'</strong><br/><strong> from /opt/gitlab/embedded/lib/ruby/gems/2.4.0/gems/bundler-1.16.2/lib/bundler/cli/exec.rb:74:in `kernel_load'</strong><br/><strong> from /opt/gitlab/embedded/lib/ruby/gems/2.4.0/gems/bundler-1.16.2/lib/bundler/cli/exec.rb:74:in `load'</strong><br/><strong> from /opt/gitlab/embedded/bin/unicorn:23:in `&lt;top (required)&gt;'&lt;br/&gt; from /opt/gitlab/embedded/bin/unicorn:23:in `load</strong><br/><strong> from /opt/gitlab/embedded/lib/ruby/gems/2.4.0/gems/unicorn-5.1.0/bin/unicorn:126:in `&lt;top (required)&gt;'</strong><br/><strong> from /opt/gitlab/embedded/lib/ruby/gems/2.4.0/gems/unicorn-5.1.0/lib/unicorn/http_server.rb:132:in `start'</strong><br/><strong> from /opt/gitlab/embedded/lib/ruby/gems/2.4.0/gems/unicorn-5.1.0/lib/unicorn/http_server.rb:508:in `spawn_missing_workers'</strong><br/><strong> from /opt/gitlab/embedded/lib/ruby/gems/2.4.0/gems/unicorn-5.1.0/lib/unicorn/http_server.rb:678:in `worker_loop'</strong><br/><strong> from /opt/gitlab/embedded/lib/ruby/gems/2.4.0/gems/unicorn-5.1.0/lib/unicorn/http_server.rb:678:in `select'</strong></pre>
<ol start="3">
<li>When you are done, leave <span>GDB</span> with <kbd>detach</kbd> and <kbd>exit</kbd>.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sidekiq</h1>
                </header>
            
            <article>
                
<p><strong>Sidekiq</strong> is a framework for background job processing. It allows you to scale your application by performing work in the background. For more information on Sidekiq, consult the following website: <a href="https://github.com/mperham/sidekiq/wiki">https://github.com/mperham/sidekiq/wiki</a>.</p>
<p>Each Sidekiq server process pulls jobs from the queue in Redis and processes them. Like your web processes, Sidekiq boots Rails so that your jobs and workers have the full Rails API <span>available for use</span><span>, including ActiveRecord. The server will instantiate the worker and call perform with the given arguments. Everything else is up to your code.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing Sidekiq</h1>
                </header>
            
            <article>
                
<p>It's very easy to start using Sidekiq. It can be installed as <kbd>gem</kbd>:</p>
<pre><strong>$ sudo gem install sidekiq</strong><br/><strong>Password:</strong><br/><strong>Fetching: redis-4.0.2.gem (100%)</strong><br/><strong>Successfully installed redis-4.0.2</strong><br/><strong>Fetching: connection_pool-2.2.2.gem (100%)</strong><br/><strong>.,,,</strong><br/><strong>Done installing documentation for redis, connection_pool, rack, rack-protection, sidekiq after 7 seconds</strong><br/><strong>5 gems installed</strong></pre>
<p>As you can see, some dependencies are installed as well, such as Redis, connection pooling, Rack, and Rack protection.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Debugging Sidekiq</h1>
                </header>
            
            <article>
                
<p class="mce-root">As with Unicorn, there are several ways to debug Sidekiq processing. The easiest way is to log in to GitLab as an administrator and view the logs from there, and especially view the queues and jobs on the <span class="packt_screen">Background Jobs</span> page, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d6577d62-2591-45a1-b48d-e7caacf8e987.png"/></p>
<p class="mce-root">Sometimes, you experience troubles and find situations on your Linux server.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sidekiq processes disappear</h1>
                </header>
            
            <article>
                
<p><span><span>As mentioned before, in the Unicorn section, the </span></span>OOM Killer might kill Sidekiq if it is using too much memory.</p>
<p>Use <kbd>dmesg | egrep -i 'killed process'</kbd> to search for OOM events:</p>
<pre><strong>[102335.3134488] Killed process 8887 (ruby) total-vm:13523004kB, anon-rss:5540458kB</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A Sidekiq process is seemingly doing nothing</h1>
                </header>
            
            <article>
                
<p>If Sidekiq isn't doing any work and it seems stuck most of the time, this means that the program is waiting for something. A common wait situation is when you are doing remote network calls. If you think this could be the case, you could make S<span><span>idekiq processes</span></span> dump a backtrace to the log by sending it a TTIN signal.</p>
<p>This is what a Sidekiq worker looks like in the log file in <kbd>/var/log/gitlan/sidekiq/current</kbd>:</p>
<pre> {"severity":"INFO","time":"2019-06 23T19:00:14.493Z","class":"RemoteMirrorNotificationWorker","retry":3,"queue":"remote_mirror_notification","jid":"69eb806bfb66b82315bcb249","created_at":"2019-06-23T19:00:14.461Z","correlation_id":"toX0HnYW0s9","enqueued_at":"2019-06-23T19:00:14.461Z","pid":471,"message":"RemoteMirrorNotificationWorker JID-69eb806bfb66b82315bcb249: done: 0.03 sec","job_status":"done","duration":0.03,"completed_at":"2019-06-23T19:00:14.493Z"}</pre>
<p>Since GitLab 12.0, the default output log format for Sidekiq is JSON, this makes it easier to read the log files into a tool like logstash because it is more structured.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Other kind of errors or 100% CPU load</h1>
                </header>
            
            <article>
                
<p>The ultimate way to debug Sidekiq processes is to make it dump a backtrace via GDB:</p>
<ol>
<li>Run <kbd>sudo gdb -p (PID)</kbd> to attach to the Sidekiq worker process.</li>
<li>Run <kbd>call (void) rb_backtrace()</kbd> in the <span>GDB</span> console and find the generated Ruby backtrace in <kbd>/var/log/gitlab/sidekiq/current</kbd>:</li>
</ol>
<pre style="padding-left: 60px">2018-09-21_19:55:03.48430 from /opt/gitlab/embedded/lib/ruby/gems/2.4.0/gems/redis-3.3.5/lib/redis/connection/ruby.rb:83:in `_read_from_socket'<br/>2018-09-21_19:55:03.48431 from /opt/gitlab/embedded/lib/ruby/gems/2.4.0/gems/redis-3.3.5/lib/redis/connection/ruby.rb:87:in `rescue in _read_from_socket'<br/>2018-09-21_19:55:03.48432 from /opt/gitlab/embedded/lib/ruby/gems/2.4.0/gems/redis-3.3.5/lib/redis/connection/ruby.rb:87:in `select'</pre>
<ol start="3">
<li>It is very hard to read backtraces, but this process was doing network operations while being traced, we can see a  (<kbd>_read_from _socket</kbd>). You can read the source code to check what it is doing (there are line numbers mentioned).</li>
<li>When you are done, leave <span>GDB</span> with <kbd>detach</kbd> and <span><span>quit</span></span>.</li>
</ol>
<p><span>You can also use other tracing tools to examine the behavior of the looping process. On Linux, for instance,</span> <kbd>strace -p &lt;pid&gt;</kbd> <span>allows you to view the system calls that are being made by the process.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">GitLab Shell</h1>
                </header>
            
            <article>
                
<p>This component is used to provide access to Git repositories through SSH. In fact, for pushes via the <kbd>git-http</kbd> protocol, it is also called instead of the Rails app. It's essentially a small Ruby wrapper around the Git client. Git, through SSH, uses predefined commands that can be executed on the GitLab server. For authorization, it makes calls to the GitLab API. Before GitLab 5.0, this functionality was delivered by Gitolite and powered by the Perl programming language.</p>
<p class="CDPAlignLeft CDPAlign">The source code of this project can be found here: <a href="https://gitlab.com/gitlab-org/gitlab-shell">https://gitlab.com/gitlab-org/gitlab-shell</a>. You can see the following page:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/e2bdece6-99dd-4f04-acf2-0f287a96396c.png"/></p>
<p>You can install it locally, but it's <span>really</span> only useful when deployed together with other GitLab components. When you have that installed (see <a href="8e9ca130-15d0-4c6e-af6b-2fe5292f3618.xhtml">Chapter 2</a>, <em>Installing GitLab</em>, for instructions on how), the next section describes a way to debug when you have problems.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Debugging GitLab Shell</h1>
                </header>
            
            <article>
                
<p>In an omnibus installation, the log file for GitLab Shell can be found in the following location:</p>
<pre>/var/log/gitlab/gitlab-shell/gitlab-shell.log </pre>
<p>Alternatively, it may be found in the following location, for installations from source:</p>
<pre>/home/git/gitlab-shell/gitlab-shell.log </pre>
<p>What you <span>will </span><span>generally find are log lines that concern the basic operations of GitLab Shell:</span></p>
<ul>
<li>Git commands (such as <kbd>git push</kbd> and <kbd>git pull</kbd>).</li>
<li>Authorization calls to the GitLab Rails API to check whether you are allowed to connect</li>
<li>Execution of pre-receive hooks </li>
<li>Actions requested</li>
<li>Post-receive actions</li>
<li>Any custom post-receive actions</li>
</ul>
<p>Here, we have listed some lines from the log file:</p>
<pre><strong>bash-4.1$ tail gitlab-shell.log</strong><br/><strong>time="2018-09-26T08:59:53+02:00" level=info msg="executing git command" command="gitaly-upload-pack unix:/var/opt/gitlab/gitaly/gitaly.socket {\"repository\":{\"storage_name\":\"default\",\"relative_path\":\"xxx/xxx.git\",\"git_object_directory\":\"\",\"git_alternate_object_directories\":[],\"gl_repository\":\"xxx\"},\"gl_repository\":\"project-xx\",\"gl_id\":\"key-xx\",\"gl_username\":\"xxxxxx\"}" pid=18855 user="user with key key-xx"</strong><br/><br/><strong>time="2018-09-26T08:59:53+02:00" level=info msg="finished HTTP request" duration=0.228132057 </strong><br/><strong>method=POST pid=18890 url="http://127.0.0.1:8080/api/v4/internal/allowed"</strong><br/><br/><strong>time="2018-09-26T08:59:54+02:00" level=info msg="finished HTTP request" duration=0.030036933 method=POST pid=18890 url="http://127.0.0.1:8080/api/v4/internal/pre_receive"</strong><br/><br/><strong>time="2018-09-26T08:59:54+02:00" level=info msg="finished HTTP request" duration=0.094035804 method=POST pid=18979 url="http://127.0.0.1:8080/api/v4/internal/post_receive"</strong></pre>
<p>One way to find errors is to look for certain patterns, such as <kbd>failed</kbd>, as follows. This particular error points to a 500 error from Unicorn while checking whether a user has the right authorization to make a call to the GitLab API.</p>
<p>This error should show up in the Unicorn logs (<kbd>production.log</kbd>) if you search for an HTTP 500 error:</p>
<pre><strong>bash-4.1$ grep -i failed gitlab-shell.log</strong><br/><strong>time="2018-09-26T08:05:52+02:00" level=error msg="API call failed" body="{\"message\":\"500 Internal Server Error\"}" code=500 method=POST pid=1587 url="http://127.0.0.1:8080/api/v4/internal/allowed"</strong><br/><strong>time="2018-09-26T08:45:13+02:00" level=error msg="API call failed" body="{\"message\":\"500 Internal Server Error\"}" code=500 method=POST pid=24813 url="http://127.0.0.1:8080/api/v4/internal/allowed"</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Redis</h1>
                </header>
            
            <article>
                
<p>Redis is a caching tool and HTTP session store<span><span> t</span></span>hat allows you to save cached data and session information from your website to an external location. This means that your website doesn't have to calculate everything every time; instead, it can retrieve the data from the cache and load the website much faster. The user sessions are in memory even if the application goes down. <span>Redis is a fast caching tool b</span><span>ecause it uses memory first. </span>It has several useful advantages:</p>
<ul>
<li>Everything is stored in one place, so you only have to flush one cache.</li>
<li>It is faster than Memcache. This is noticeable when using the websites of large shops.</li>
<li>Sessions are stored in memory and not in the database.</li>
<li>The backend becomes faster.</li>
</ul>
<p>Redis is not merely a cache, but is also a data structure store. It is basically a database and should be viewed conceptually as such. With regard to its operation and how it handles data, it has more in common with a NoSQL database.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing Redis</h1>
                </header>
            
            <article>
                
<p>Redis is available through all major package management systems. The following are the commands used to install it on different platforms: </p>
<ul>
<li>This is for Mac with Homebrew installed:</li>
</ul>
<pre style="padding-left: 60px"><strong>brew install redis</strong></pre>
<ul>
<li>This is for Linux Ubuntu or other APT-based distributions:</li>
</ul>
<pre style="padding-left: 60px"><strong>apt-get install redis</strong> </pre>
<ul>
<li>This is for Red Hat or other YUM-based distributions:</li>
</ul>
<pre style="padding-left: 60px"><strong>yum install redis</strong> </pre>
<p>However, the preferred way of installing Redis is by compiling it from the source. This way, you can easily stay up to date. It has no special dependencies other than the GCC compiler and the standard C library. You can find the latest stable version at <a href="http://download.redis.io/redis-stable.tar.gz">http://download.redis.io/redis-stable.tar.gz</a>.</p>
<p>Installing and compiling it is as easy as entering the following command:</p>
<pre><strong>curl http://download.redis.io/redis-stable.tar.gz | tar xvz</strong><br/><strong>cd redis-stable</strong><br/><strong>make</strong></pre>
<p>After completing this successfully, you can choose to carry out the next logical step, which is to issue <kbd>make test</kbd> to execute tests against compiled sources.</p>
<p>To install the binary in a useful place, use the following command:</p>
<pre><strong><span class="attribute">sudo</span><span> make install</span></strong></pre>
<p>For a further explanation about the structure that has been compiled, go to the <kbd>src</kbd> directory. You will find the following information: </p>
<ul>
<li><kbd>redis-server</kbd>: The Redis server program</li>
<li><kbd>redis-sentinel</kbd>: This is used to monitor Redis clusters</li>
<li><kbd>redis-cli</kbd>: The command-line program to control Redis</li>
<li><kbd>redis-benchmark</kbd>: The program to be used to measure Redis performance</li>
<li><kbd>redis-check-aof</kbd> and <kbd>redis-check-dump</kbd>: Utilities to assist when there is data corruption</li>
</ul>
<p>Now we have everything in place, let's start the server.</p>
<p>When installed on macOS with <kbd>brew</kbd>, use the following command:</p>
<pre class="p1"><strong><span class="s1">brew services start redis</span></strong></pre>
<p>On other platforms, when built from the source, y<span>ou can directly start the Redis server by running the <kbd>redis-server</kbd> command. In a fresh shell window, type the following:</span></p>
<pre><strong>redis-server</strong></pre>
<p>After hitting <em>Enter</em>, you will see the server starting:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/aac23216-7d52-47e3-b04c-2c1dc3ee461e.png" style="width:64.17em;height:25.58em;"/></p>
<p>You can test whether your Redis instance is working by issuing the following command:</p>
<pre class="p1"><span class="s1"><strong>$ redis-cli ping</strong><br/></span></pre>
<p>When Redis is operational, there will be a reaction:</p>
<pre class="p1"><strong><span class="s1">PONG</span></strong></pre>
<p>If you receive <kbd>PONG</kbd>, then everything is in order.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Basic data operations in Redis</h1>
                </header>
            
            <article>
                
<p>Let's discover some of the basics of Redis by playing with the data structures. Start the <kbd>redis-cli</kbd> <span>command-line utility </span>again without the <kbd>ping</kbd> argument, and it will connect to the local Redis server:</p>
<pre><strong>$redis-cli</strong><br/><strong>127.0.0.1:6379&gt;</strong></pre>
<p>It is not fair to view Redis as a simple hash database with key values. But still, the five data structures that are provided do actually consist of a key and a value. Let's sum up the five data structures:</p>
<ul>
<li><strong>String</strong>: You can use the <kbd>set</kbd> command to write a value to Redis. In the case of a simple string, you can simply save the value in the datastore shown as follows. After setting the string value, you can retrieve the value again by issuing the <kbd>get</kbd> command:</li>
</ul>
<pre style="padding-left: 60px"><strong>$ redis-cli</strong><br/><strong>127.0.0.1:6379&gt; set mykind "Human" </strong><br/><strong>OK</strong><br/><strong>127.0.0.1:6379&gt; get mykind</strong><br/><strong>"Human"</strong><br/><strong>127.0.0.1:6379&gt;</strong> </pre>
<ul>
<li><strong>Hash</strong>: In the same way as the string, you can <kbd>set</kbd> an arbitrary number of values to a key. <span>Generally speaking, Redis treats values as a byte array and doesn't care what they are. This make Redis v</span><span>ery handy for representing objects. Again, with the <kbd>get</kbd> command, you can retrieve the values. GitLab uses this type to store web session information from users:</span></li>
</ul>
<pre style="padding-left: 60px"><strong>$ redis-cli</strong><br/><strong>127.0.0.1:6379&gt; set programs:tron '{"name": "tron","kind": "program"}'</strong><br/><strong>OK</strong><br/><strong>127.0.0.1:6379&gt; get programs:tron</strong><br/><strong>"{\"name\": \"tron\",\"kind\": \"program\"}"</strong></pre>
<ul>
<li><strong>List</strong>: The list type in Redis is implemented as a linked list. You can add items to the list<strong> </strong>quite quickly with <kbd>rpush</kbd> (right push, to the tail of the list) or <kbd>lpush</kbd> (left push, to the head of the list). On the other hand, accessing an item by index is not that fast because it has to search the linked list. Still, for a queue mechanism, this is a good solution. </li>
</ul>
<pre style="padding-left: 60px"><strong>$ redis-cli</strong><br/><strong>127.0.0.1:6379&gt; rpush specieslist human computer cyborg</strong><br/><strong>(integer) 3</strong><br/><strong>127.0.0.1:6379&gt; rpop specieslist</strong><br/><strong>"cyborg"</strong><br/><strong>127.0.0.1:6379&gt; rpop specieslist</strong><br/><strong>"computer"</strong><br/><strong>127.0.0.1:6379&gt; rpop specieslist</strong><br/><strong>"human"</strong><br/><strong>127.0.0.1:6379&gt; rpop specieslist</strong><br/><strong>(nil)</strong></pre>
<ul>
<li><strong>Sets</strong>: Another datatype is the set. You add members with the <kbd>sadd</kbd> command. Don't forget that these sets are unordered, so if you ask for the members with <kbd>smembers</kbd>, the order will mostly be different to how you entered it:</li>
</ul>
<pre style="padding-left: 60px"><strong>$ redis-cli</strong><br/><strong>127.0.0.1:6379&gt; sadd speciesset human computer cyborg</strong><br/><strong>(integer) 3</strong><br/><strong>127.0.0.1:6379&gt; smembers speciesset</strong><br/><strong>1) "computer"</strong><br/><strong>2) "human"</strong><br/><strong>3) "cyborg"</strong></pre>
<ul>
<li><strong>Sorted sets</strong>: Fortunately, there is an ordered set as well. It is almost the same, but one difference is that you add a score to the entry, and that will automatically score the sort order, as you can see from the following:</li>
</ul>
<pre style="padding-left: 60px"><strong>127.0.0.1:6379&gt; zadd speciessortedset 1 human</strong><br/><strong>(integer) 1</strong><br/><strong>127.0.0.1:6379&gt; zadd speciessortedset 2 computer</strong><br/><strong>(integer) 1</strong><br/><strong>127.0.0.1:6379&gt; zadd speciessortedset 3 cyborg</strong><br/><strong>(integer) 1</strong><br/><strong>127.0.0.1:6379&gt; zrange speciessortedset 0 -1</strong><br/><strong>1) "human"</strong><br/><strong>2) "computer"</strong><br/><strong>3) "cyborg"</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Gitaly</h1>
                </header>
            
            <article>
                
<p>In the first versions of GitLab, all Git operations relied on using a local disk or network share. Gitaly is a project that tries to eliminate reliance on the <strong>Network File System</strong> (<strong>NFS</strong>). Instead of calls to a filesystem service, Gitaly provides GitLab with a system based on <strong>Remote Procedure Calls</strong> (<strong>RPCs</strong>) to access Git repositories. It is written in Go and uses <strong>gRPC Remote Procedure</strong> <strong>Call</strong> (<strong>gRPC</strong><span>)</span>, a cross-platform RPC framework from Google. It has been steadily developing since the beginning of 2017, and since GitLab 11.4, it can replace the need for a shared NFS filesystem.</p>
<p>You can find an overview of Gitaly and its place in the GitLab architecture in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/604f4f42-3c54-490d-8b34-5c07ae8217a1.png" style="width:21.25em;height:30.75em;"/></p>
<p>On a small installation, it runs in the same servers as all other components. In big clustered environments, you can set up dedicated Gitaly servers, which can be used by Gitaly clients such as the following:</p>
<ul>
<li>Unicorn</li>
<li>Sidekiq</li>
<li><kbd>gitlab-workhorse</kbd></li>
<li><kbd>gitlab-shell</kbd></li>
<li>Elasticsearch indexer</li>
<li>Gitaly as a client</li>
</ul>
<p>The source code of this project can be found here: <a href="https://gitlab.com/gitlab-org/gitaly">https://gitlab.com/gitlab-org/gitaly</a><a href="https://gitlab.com/gitlab-org/gitaly">.</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Debugging Gitaly</h1>
                </header>
            
            <article>
                
<p>You can use debugging tools that are available for Golang. But for starters, you can take a look at the log file. </p>
<p>For source installs, use this:</p>
<pre>/home/git/gitaly/</pre>
<p>For Omnibus installations, use this:</p>
<pre>/var/log/gitlab/gitaly/current</pre>
<p>The following is an example of a log line:</p>
<pre>2018-09-26_13:23:40.57373 lrv162w2 gitaly: time="2018-09-26T13:23:40Z" level=info msg="finished streaming call" grpc.code=OK grpc.method=SSHUploadPack grpc.request.glRepository=project111111 grpc.request.repoPath=namespace/project-bl.git grpc.request.repoStorage=default grpc.request.topLevelGroup=hb-backend grpc.service=gitaly.SSHService grpc.time_ms=150 peer.address=@ span.kind=server system=grpc</pre>
<p>You can see the log level is <kbd>info</kbd> and this is a log event that captures a Git SSH command (<kbd>method=SSHUploadPack</kbd>). It started a Git <kbd>pack</kbd> command on the server, which means it rearranged and compressed data in a repository. </p>
<p>To generate more verbose logging, you can set the log level to a debug in the configuration file. It is configured via a <strong>Tom's Obvious Minimal Language</strong> (<strong>TOML</strong>) configuration file. This file is documented in the Gitaly source code repository mentioned previously.</p>
<p>For source installations, look here:</p>
<pre> /home/git/gitaly/config.toml</pre>
<p>You can change the following section and change the level:</p>
<pre># # Optional: Set log level to only log entries with that severity or above<br/># # One of, in order: debug, info, warn, error, fatal, panic<br/># # Defaults to "info"<br/># level = "warn"<br/><br/></pre>
<p>For Omnibus installs, the following directives can be added to <kbd>gitlab.rb</kbd> to influence the level of monitoring of Gitaly. Set it to <kbd>debug</kbd> to enable debug-level logging:</p>
<pre>gitaly['log_directory'] = "/var/log/gitlab/gitaly"<br/>gitaly['logging_level'] = "debug" </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">GitLab Workhorse</h1>
                </header>
            
            <article>
                
<p>GitLab Workhorse is a sophisticated reverse proxy that is set up in front of GitLab. Initially conceived to solve the problem of handling <kbd>git-http</kbd> requests, it started as a weekend project with the name <kbd>gitlab-git-httpserver</kbd>. The functionality was previously delivered by <kbd>gitlab-grack</kbd> (<a href="https://gitlab.com/gitlab-org/gitlab-grack">https://gitlab.com/gitlab-org/gitlab-grack</a>). The main web application server, Unicorn, was not especially suited to cater for these requests, which can take a long time to finish. Handling these directly in Unicorn actually reverses the advantages that Unicorn can provide: fast and scalable HTTP requests.</p>
<p>Workhorse was created in Golang, and was conceived by Jacob Vosmaer, one of the GitLab developers. You can read all about the process of creating it at <a href="https://about.gitlab.com/2016/04/12/a-brief-history-of-gitlab-workhorse/">https://about.gitlab.com/2016/04/12/a-brief-history-of-gitlab-workhorse/</a>.</p>
<p>Although it was first designed to handle the Git HTTP protocol, GitLab Workhorse increasingly gained functionalities, such as these:</p>
<ul>
<li>Certain static files, such as JavaScript and CSS files, are served directly.</li>
<li>It can intercept requests from Rails about opening a file. Workhorse will open the file and send the content in the response body.</li>
<li>It can intercept calls for Git <strong>Large File Storage</strong> (<strong>LFS</strong>) and insert a temporary path after preparing the file <span><span>in the upload location. </span></span>Git LFS is<span> a feature where large files can be stored outside the project space in GitLab.</span></li>
<li>It can control WebSocket connections for Rails, such as the terminal output.</li>
</ul>
<p>Workhorse sits behind NGINX, which handles request routing and SSL termination.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Debugging GitLab Workhorse</h1>
                </header>
            
            <article>
                
<p><span><span>As workhorse is a Golang written application, you can use methods for this language to debug programs.</span></span></p>
<p>It also supports remote error logging with Sentry. To activate this feature, set the <kbd>GITLAB_WORKHORSE_SENTRY_DSN</kbd> environment variable.</p>
<p class="mce-root"><strong>For Omnibus installations</strong></p>
<p class="mce-root">The following is defined in the file (<kbd>/etc/gitlab/gitlab.rb</kbd>):</p>
<pre class="mce-root"><strong>gitlab_workhorse['env'] = {'GITLAB_WORKHORSE_SENTRY_DSN' =&gt; 'https://foobar'}</strong></pre>
<p class="mce-root"><strong>For Source installations</strong></p>
<p class="mce-root">The following environment variable can be set in the file (/<kbd>etc/default/gitlab</kbd>):</p>
<pre class="mce-root"><strong>export GITLAB_WORKHORSE_SENTRY_DSN='https://foobar'</strong></pre>
<p>Of course,<span><span> the first thing to look at is the log files that are produced by this component. On an Omnibus-based GitLab installation, you can find them in <kbd>/var/log/gitlab/gitlab-workhorse</kbd>.</span></span></p>
<p>The following is an excerpt of the default log file:</p>
<pre>"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/11.1.1 Safari/605.1.15" 0.478<br/> 2018-08-16_20:26:43.42795 localhost:8080 @ - - [2018/08/16:20:26:43 +0000] "GET /root/mastering-gitlab-12.git/info/refs?service=git-upload-pack HTTP/1.1" 401 26 "" "git/2.15.2 (Apple Git-101.1)" 0.066<br/> 2018-08-16_20:26:50.60861 localhost:8080 @ - - [2018/08/16:20:26:50 +0000] "POST /root/mastering-gitlab-12.git/git-upload-pack HTTP/1.1" 200 329 "" "git/2.15.2 (Apple Git-101.1)" 0.249</pre>
<p>In the preceding log file, you see, for example, <kbd>git-http</kbd> operations such as <kbd>git-upload-pack</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Database</h1>
                </header>
            
            <article>
                
<p>There are two database varieties available for GitLab: PostgreSQL and MySQL/MariaDB. The use of the latter is not recommended because the fast development of iterations of GitLab, as a product, have focused primarily on PostgreSQL, meaning that a number of optimizations are not available on MySQL. Furthermore, the zero-downtime method is not available when using MySQL, and neither are features such as subgroups and GEO, which will be explained later in this book.</p>
<p>As explained earlier, Ruby on Rails uses a so-called MVC approach. MVC is a well known architectural pattern that was developed by Trygve Reenskaug in the Smalltalk language. It was later enhanced for web applications (Model 2). The model in MVC is implemented by the <kbd>ActiveRecord</kbd> library, which is part of Ruby on Rails. </p>
<p>The authoritative source for the data model can be found here: <a href="https://gitlab.com/gitlab-org/gitlab-ee/blob/master/db/schema.rb">https://gitlab.com/gitlab-org/gitlab-ee/blob/master/db/schema.rb</a>. It is auto generated and represents the current state of the database.</p>
<p>The default PostgreSQL database that is included in the Omnibus package can handle workloads for up to 10,000 users. Also, if you would like to create a <strong>Disaster Recovery</strong> (<strong>DR</strong>) plan using a cold standby setup, you can use specific failover mechanisms.</p>
<p>A frequently used technique is to create a cold standby database (PostgreSQL DB 2) at another site, as illustrated by the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/37c0d3a0-1133-4125-ba0e-84de5982ddc0.png" style="width:38.67em;height:29.42em;"/></p>
<p><span>When you want to scale or increase the number of application servers, you need to scale the database too. There are three important aspects of database scaling. Firstly, you want to be able to scale database client connections as efficiently as possible. To do this, you can use PgBouncer, which is a lightweight connection pooler. </span></p>
<p>Secondly, you want to have several database instances, one being the master node, and replicate the data from the master to the slave. In the former, DR situation, this was done by the basic built-in replication mechanism of PostgreSQL. In the current situation, a specific tool, repmgr, is used, a tool for clustering PostgreSQL and handling the failover.</p>
<p>Finally, a service discovery tool such as <strong>Consul</strong> can be used to detect the PostgreSQL status of each node, and update the PGbouncer service setting that determines which Postgres instance to connect to.</p>
<p>The resulting architecture is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/682c99a5-6e3f-4586-bf5c-66fff93cef8f.png" style="width:23.83em;height:31.75em;"/></p>
<p>As you can see, there are different ways of setting up your database for GitLab. The architectures highlighted in the preceding diagram will be used in examples for building high-availability environments in <em>Scaling the Server Infrastructure (High- Availability Setup</em>) section of this book.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">GitLab CI</h1>
                </header>
            
            <article>
                
<p class="CDPAlignLeft CDPAlign">GitLab CI is a feature that helps perform the <strong>Continuous Integration</strong> (<strong>CI</strong>) of software components. When several developers work together using a versioning system, problems can arise when changes made by one developer break the product as a whole. The best way to make sure this happens less often, or at least early in the process, is to use integration tests more frequently, hence the name continuous.</p>
<p class="CDPAlignLeft CDPAlign">GitLab CI was launched as a standalone project in 2013, but was later integrated into the main GitLab package. Combined with the GitLab Runner software, this feature has been very popular with developers and is an important driver of the business. It also enabled GitLab to build their product into a solution that not only does CI, but even continuous delivery up to production environments. The current product vision for GitLab is to serve as a complete DevOps life cycle product, from idea to production.</p>
<p class="CDPAlignLeft CDPAlign">Forrester classified GitLab as a leader in CI in <em>The Forrester Wave: Continuous Integration Tools, Q3 2017</em>. This is shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/baa860a0-b398-48a1-9f42-754053ffd5d1.png" style="width:31.25em;height:30.83em;"/></p>
<p class="CDPAlignLeft CDPAlign">Feedback, one of the important aspects of the <strong>Extreme Programming</strong> (<strong>XP</strong>) movement, is an important element of GitLab CI. It also serves as a way to communicate between developers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pipelines and jobs</h1>
                </header>
            
            <article>
                
<p>Pipelines and build jobs are basic building blocks for a <strong>Continuous Integrations/Continuous Delivery</strong> (<strong>CI/CD</strong>) system nowadays. In GitLab, it is very easy to start a pipeline. You only need to add a <kbd>.gitlab-ci.yml</kbd> file to your project and then, on every commit/push to your repository, a pipeline will start. Every project has a pipeline's overview; you can find it in the left-hand menu bar, under CI/CD:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/9500b78c-c838-4e0f-ba0d-724581246c4c.png" style="width:68.92em;height:29.58em;"/></p>
<p class="mce-root CDPAlignLeft CDPAlign">Alternatively, you can view all jobs, by going to the Pipelines' <span class="packt_screen">Jobs</span> page, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d3a96279-4d98-4ae2-a324-1e8de043d63f.png" style="width:70.25em;height:23.00em;"/></p>
<p>You can check the log of a job by clicking on the status of the job (for example, <strong>failed</strong> or <strong>passed</strong>). You can debug why some jobs fail and see exactly<span> what</span> happened:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c2751d76-eda1-4258-b975-69917c7e97ae.png"/></p>
<p>The importance of using pipelines and jobs for CI/CD cannot be overstated. In this section, you've seen the basic interface to pipelines in GitLab, but in several chapters time, this will be discussed in more detail (<em>Utilizing GitLab CI and CI Runners</em> section).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">GitLab Runners</h1>
                </header>
            
            <article>
                
<p>GitLab Runners were originally developed by Kamil Trzciński in 2015. They're now one of the most popular features of GitLab.</p>
<p>The initial GitLab-CI-Runner was a very simple application written in Ruby, but worked well in quite basic setups. You can think of it as a reference implementation of what a bare runner could look like.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Issues with the old runner</h1>
                </header>
            
            <article>
                
<p>The main problem with the old runner is that it could only run one concurrent job at a time. If you wanted to run more, you could either set up a new server or create an additional user to build jobs.</p>
<p>Secondly, it always ran projects on the server shell. This made it really hard to test projects using different versions of Ruby or any other dependencies. It was not stateless, meaning you had a contaminated build environment. Builds were therefore not very trustworthy. Nowadays, having a stateless and clean build environment every time is essential.</p>
<p>Another aspect of the old Runner that made it less favorable was that it only ran on Linux-based platforms. To make it work on macOS, a big GitLab user platform, you had to carry out additional hacking. Support for Microsoft Windows was out of the question.</p>
<p>Finally, there were some heavy administrative burdens. The server was hard to scale, because setting up a new server took a long time due to the dependencies you needed to take care of in order to build projects.</p>
<p>The newer runner is a binary that you can put on a machine of any kind. It is really easy to set up as a service and can work with multiple projects and multiple GitLab CI coordinators. It also provides support for Docker, making it really easy to set up a build environment with different versions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Switching to Go</h1>
                </header>
            
            <article>
                
<p><span>Go (or Golang) is a new language (less than 10 years old). It is already widely used by some impressive parties, such as Docker (<a href="https://docker.com">https://docker.com</a>), Google, Kubernetes (<a href="https://kubernetes.io">https://kubernetes.io</a>), and Prometheus (<a href="https://prometheus.io">https://prometheus.io</a>). Go is a versatile tool that can help you to program at a low level, close to the operating system or at a high level in a language such as Java. It is perfectly suited to creating systems software. The language was created in 2009 by R. Griesemer, R. Pike, and K.Thompson while working for Google. The latter is very famous for co-creating the first Unix implementation and the B programming language. The most important feature of the Go language is that it can compile one binary without dependencies for multiple operating systems such as Linux, macOS, the BSDs, and Windows. This also means it runs on different processor architectures (i386, amd64, ARM, and PowerPC).</span></p>
<p><span>A short list of the benefits of Go follows:</span></p>
<ul>
<li>Very good standard libraries (with good optional ones available elsewhere).</li>
<li>It is very fast to develop and test in Go.</li>
<li>The culture/community chooses boring solutions over complex ones (which is good).</li>
<li>Cool tools such as Gofmt, race detector, and <kbd>go vet</kbd>.</li>
<li>Made for concurrency—for instance, you can use goroutines and channels.</li>
<li>Type safety—will save you many times from run-time errors and wrongly defined data types.</li>
<li>Garbage collection—while programmers who use C know how to clean up, this can still be helpful.</li>
<li>Closures or anonymous functions—enable the use of functional principles (higher-order functions).</li>
</ul>
<p><span>A</span><span>ll these characteristics make Go the perfect choice for GitLab Runners. With Go, you can create a relatively small binary that runs on a lot of platforms. It contains all that is needed to run your projects.</span></p>
<p>In a GitLab environment, jobs are being executed by the Runners. They run them as they are defined in a <kbd>.gitlab-ci.yml</kbd> file. The Runner itself can be running on a <strong>Virtual Machine</strong> (<strong>VM</strong>) such as VmWare (VM), VPS, a laptop, a Docker container, or in a Kubernetes cluster. Communication is one way from runner to GitLab and is mostly via an HTTP API, so that path must be accessible by the Runner.</p>
<p><span>The <kbd>.yml</kbd> file defines what stages your CI/CD pipeline has and what to do in each stage. This typically consists of build, test, and deploy stages.</span></p>
<div class="packt_infobox">GitLab mentions <em>boring</em> in its handbook as a valued way of reducing complexity; see <a href="https://about.gitlab.com/handbook/values/#efficiency">https://about.gitlab.com/handbook/values/#efficiency</a>. </div>
<p><span>The project can be found at </span><a href="https://gitlab.com/gitlab-org/gitlab-runner">https://gitlab.com/gitlab-org/gitlab-runner</a><span>:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f2c04da4-3bda-4d67-a67d-12136489b33b.png" style="width:50.58em;height:16.92em;"/></p>
<p>A runner can either be specific to a certain project or it can serve multiple projects in GitLab. If it serves all projects, it's known as a Shared Runner. GitLab Runners implement a number of <strong>executors</strong> that can be used for your builds in different scenarios:</p>
<ul>
<li><strong>Shell executor</strong>: The runner simply executes a shell. The dependencies for the build have to be installed manually.</li>
<li><strong>Docker-based executor</strong>: The runner runs from a container. This makes it easier to create clean builds because dependency management is shifted to the container image. It is also easier to create a build environment with services that need each other, such as PostgreSQL.</li>
<li><strong>Autoscaling Docker SSH</strong>: A Docker machine creates instances with the Docker Engine to run Docker containers.</li>
<li><strong>Kubernetes</strong>: GitLab Runner can use Kubernetes to run builds on a Kubernetes cluster.</li>
</ul>
<p>Runners have evolved enormously over the last couple of years. GitLab itself sees them as one of the most important components of their suite. This section has given more insight into the development of this popular tool.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Cloud native</h1>
                </header>
            
            <article>
                
<p>Toward the end of 2016 and at the start of 2017, there was a public debate in the GitLab community about whether reverting back from the cloud to bare metal would be cost-effective for <a href="https://about.gitlab.com/">GitLab.com</a>. At the time, the filesystem used for repositories was Ceph. The performance of that distributed filesystem was not good enough to handle <a href="https://about.gitlab.com/">GitLab.com</a>. They asked the community for advice and received a lot of feedback from people who experienced similar moves firsthand. In the end, the decision was made to stay in the cloud (<a href="https://about.gitlab.com/2017/03/02/why-we-are-not-leaving-the-cloud/">https://about.gitlab.com/2017/03/02/why-we-are-not-leaving-the-cloud/</a>). Instead, GitLab would focus on creating a solution, not on the filesystem level, but making sure that Git <span><span>input/output (I/O)</span></span> behavior is better managed at the application level. This can be seen as the birth of the Gitaly component. Sid Sijbrandij emphasized the importance of being a software company, not an infrastructure company.</p>
<p>In August 2018, GitLab migrated their cloud-based offering, <a href="https://about.gitlab.com/">GitLab.com</a>, from Azure to <strong>Google Cloud Platform</strong> (<strong>GCP</strong>). The main reason for switching to GCP according to CEO, Sid Sijbrandij was as follows:</p>
<div class="packt_quote">"Google as a public cloud, they have more experience than the other public cloud providers because they basically made a cloud for themselves [...] you find that in things such as networking, where their network quality is ahead of everyone else. It's more reliable, it has less jitter, and it's just really, really impressive how they do that, and we're happy to start hosting GitLab.com on that."</div>
<p>It seems the move paid off; users have reported that <a href="https://about.gitlab.com/">GitLab.com</a> is noticeably faster. Another transformation that is likely to cause further acceleration soon is the move to using Kubernetes as a container orchestrator. This is an important part of their strategy to incorporate functionality in a lot of places in GitLab besides the autoscaling of GitLab runners. GitLab's own high-availability tool, GEO, was used to synchronize the data from one cloud to another. Running on Google's architecture also allows GitLab to utilize object-storage for particular features as well, such as Git LFS.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have learned about the people and the organization behind GitLab. Starting from the beginning, we have shown you how the project has developed over the years. We went through the core components of GitLab and how to install them. For some components, we included ways to debug the installation.</p>
<p>We also gave a brief introduction to GitLab CI and the client programs that interact with it, such as GitLab Runner. We showed you why this feature is so important and how it is perceived by the IT industry. </p>
<p>In the next chapter, we will install and configure GitLab on different kinds of systems. If you're new to the product, prepare to be amazed!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li class="mce-root"><span>When and by whom was GitLab initially developed?</span></li>
<li>How is GitLab funded?</li>
<li>Name all the programming languages that are used in the GitLab software.</li>
<li>Which licenses are used by GitLab?</li>
<li>Why are they using these licenses?</li>
<li>Name the core components of GitLab.</li>
<li>How many offices does GitLab have?</li>
<li>What is stored in Redis?</li>
<li>What has Gitaly replaced?</li>
<li>Which cloud service was chosen by GitLab to focus on in 2018?</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<ul>
<li class="mce-root">Sidekiq—source and documentation: <a href="https://github.com/mperham/sidekiq">https://github.com/mperham/sidekiq</a></li>
<li class="mce-root">Ruby on Rails: <a href="https://rubyonrails.org">https://rubyonrails.org</a></li>
<li class="mce-root">Unicorn: <a href="https://thorstenball.com/blog/2014/11/20/unicorn-unix-magic-tricks/">https://thorstenball.com/blog/2014/11/20/unicorn-unix-magic-tricks/</a></li>
<li class="mce-root"><em>Cloud Native programming with Golang</em> by <em>Mina Andrawos</em>, <em>Martin Helmich</em>: <a href="https://www.packtpub.com/in/application-development/cloud-native-programming-golang">https://www.packtpub.com/in/application-development/cloud-native-programming-golang</a></li>
<li><span><em>Nginx HTTP Server - Fourth Edition</em> by <em>Clement Nedelcu</em>, <em>Martin Fjordvald</em>: <a href="https://www.packtpub.com/in/virtualization-and-cloud/nginx-http-server-fourth-edition">https://www.packtpub.com/in/virtualization-and-cloud/nginx-http-server-fourth-edition</a></span></li>
<li class="mce-root"><em>Mastering Redis</em> by <em>Jeremy Nelson</em>: <a href="https://www.packtpub.com/in/big-data-and-business-intelligence/mastering-redis">https://www.packtpub.com/in/big-data-and-business-intelligence/mastering-redis</a></li>
<li class="mce-root"><em>PostgreSQL Administration Cookbook, 9.5/9.6 Edition</em> by <em>Simon Riggs</em><em>,</em> <em>Gianni Ciolli</em>, <em>Gabriele Bartolini</em>: <a href="https://www.packtpub.com/in/big-data-and-business-intelligence/postgresql-administration-cookbook-9596-edition">https://www.packtpub.com/in/big-data-and-business-intelligence/postgresql-administration-cookbook-9596-edition</a></li>
</ul>


            </article>

            
        </section>
    </body></html>