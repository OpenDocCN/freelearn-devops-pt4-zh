<html><head></head><body>
		<div id="_idContainer022">
			<h1 id="_idParaDest-45"><em class="italic"><a id="_idTextAnchor044"/>Chapter 2</em>: Comparing Podman and Docker </h1>
			<p>As we learned from the previous chapter, container technology is not as new as we may think and therefore its implementation and architecture has been influenced over the years to reach its current status.</p>
			<p>In this chapter, we’ll go through a bit of the history and the main architecture of Docker and Podman container engines, completing the picture with a side-by-side comparison to let readers with some Docker experience easily get on board and learn the main differences before going into a deep exploration of Podman.</p>
			<p>If you don’t have much experience with Docker, you can easily jump to the next chapter and return to this one once you feel it is time to learn the differences between Podman and Docker container engines.</p>
			<p>In this chapter, we’re going to cover the following main topics:</p>
			<ul>
				<li>Docker container daemon architecture</li>
				<li>Podman daemonless architecture</li>
				<li>The main differences between Docker and Podman </li>
			</ul>
			<h1 id="_idParaDest-46"><a id="_idTextAnchor045"/>Technical requirements</h1>
			<p>This chapter does not require any technical prerequisites; feel free to read it without worrying too much about installing or setting up any kind of software on your workstation! </p>
			<p>If you want to replicate some of the examples that will be described in this chapter, you’ll need to install and configure Podman and Docker on your workstation. As we described before, you can easily jump to the next chapter and come back to this one once you feel it’s time to learn the differences between Podman and Docker container engines.</p>
			<p>Please consider that in the next chapter, you’ll be introduced to Podman’s installation and configuration, so you’ll be soon able to replicate any example you’ll see in this chapter and in the following ones.</p>
			<h1 id="_idParaDest-47"><a id="_idTextAnchor046"/>Docker container daemon architecture</h1>
			<p>Containers are a simple and smart answer to the need to run isolated process instances. We can safely affirm that <a id="_idIndexMarker149"/>containers are a form of application isolation that works at many levels, such as filesystem, network, resource usage, process, and so on.</p>
			<p>As we saw in <a href="B17908_01_epub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Container Technology</em>, in the <em class="italic">Containers versus virtual machines</em> section, containers also differ from virtual machines because containers share the same kernel with the host, while virtual machines have their own guest OS kernel. From a security point of view, virtual machines provide better isolation from potential attacks, but a virtual machine will usually consume more resources than a container. To spin up a guest OS, we usually need to allocate more RAM, CPU, and storage than the resources needed to start a container.</p>
			<p>Back in 2013, the Docker container engine appeared in the container landscape, and it rapidly became very popular. </p>
			<p>As we explained before, a container engine is a software tool that accepts and processes requests from users to create a container; it can be seen as a sort of orchestrator. On the other hand, a container runtime is a lower-level piece of software used by container engines to run containers in the host, managing isolation, storage, networking, and so on.</p>
			<p>In the early stages, the Docker container engine used LXC as a container runtime but then replaced it after a while with their own implementation, <em class="italic">libcontainer</em>.</p>
			<p>The Docker container engine consists of three fundamental pillars:</p>
			<ul>
				<li>Docker daemon</li>
				<li>Docker REST API</li>
				<li>Docker CLI</li>
			</ul>
			<p>These three pillars are represented in the following architecture:</p>
			<div>
				<div id="_idContainer013" class="IMG---Figure">
					<img src="image/B17908_02_01.jpg" alt="Figure 2.1 – Docker architecture&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.1 – Docker architecture</p>
			<p>Once a Docker daemon is running, as shown in the preceding diagram, you can interact with it through a Docker <a id="_idIndexMarker150"/>client or a remote API. The Docker daemon is responsible for many local container activities as well as interacting with external registries to pull or push container images.</p>
			<p>The Docker daemon is the most critical piece of the architecture, and it should always be up and running, otherwise your beloved containers will not survive for long! Let’s see its details in the next section.</p>
			<h2 id="_idParaDest-48"><a id="_idTextAnchor047"/>The Docker daemon</h2>
			<p>A daemon is a process <a id="_idIndexMarker151"/>that runs in the background; it supervises the system or provides functionality to other processes.</p>
			<p>The Docker daemon is the background process that is responsible for the following:</p>
			<ul>
				<li>Listening for Docker API requests</li>
				<li>Handling, managing, and checking for running containers</li>
				<li>Managing Docker images, networks, and storage volumes</li>
				<li>Interacting with external/remote container image registries</li>
			</ul>
			<p>All these actions <a id="_idIndexMarker152"/>should be instructed to the daemon through a client or by calling its API, but let’s see how to communicate with it.</p>
			<h2 id="_idParaDest-49"><a id="_idTextAnchor048"/>Interacting with the Docker daemon</h2>
			<p>The Docker daemon can <a id="_idIndexMarker153"/>be contacted through the socket of a process, usually available in the filesystem of the host machine: <strong class="source-inline">/var/run/docker.sock</strong>.</p>
			<p>Depending on the Linux distribution of your choice, you may need to set the right permission for your non-root users to be able to interact with the Docker daemon or simply add your non-privileged users to the <strong class="source-inline">docker</strong> group.</p>
			<p>As you can see in the following command, these are the permissions set for the Docker daemon in a Fedora 34 operating system:</p>
			<p class="source-code">[root@fedora34 ~]# ls -la /var/run/docker.sock </p>
			<p class="source-code">srw-rw----. 1 root docker 0 Aug 25 12:48 /var/run/docker.sock</p>
			<p>There is no other kind of security or authentication for a Docker daemon enabled by default, so be careful not to publicly expose the daemon to untrusted networks.</p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor049"/>The Docker REST API</h2>
			<p>Once a Docker daemon is up and running, you can communicate through a client or directly through <a id="_idIndexMarker154"/>the REST API. Through the Docker API, you can do every kind of activity you can perform through the command-line tool, such as the following:</p>
			<ul>
				<li>List containers</li>
				<li>Create a container</li>
				<li>Inspect a container</li>
				<li>Get container logs</li>
				<li>Export a container</li>
				<li>Start or stop a container</li>
				<li>Kill a container</li>
				<li>Rename a container</li>
				<li>Pause a container</li>
			</ul>
			<p>The list goes on. Looking at one of these APIs, we can easily discover how they work and what the sample output returned by the daemon is.</p>
			<p>In the following <a id="_idIndexMarker155"/>command, we are going to use the Linux command line tool <strong class="source-inline">curl</strong> for making an HTTP request to get details about any container image already stored in the daemon’s local cache:</p>
			<p class="source-code">[root@fedora34 ~]# curl --unix-socket /var/run/docker.sock \ http://localhost/v1.41/images/json | jq </p>
			<p class="source-code">[</p>
			<p class="source-code">  {</p>
			<p class="source-code">    “Containers”: -1,</p>
			<p class="source-code">    “Created”: 1626187836,</p>
			<p class="source-code">    “Id”: “sha256:be72532cbd81ba4adcef7d8f742abe7632e6f5b35 bbd53251e5751a88813dd5f”,</p>
			<p class="source-code">    “Labels”: {</p>
			<p class="source-code">      “architecture”: “x86_64”,</p>
			<p class="source-code">      “build-date”: “2021-07-13T14:50:13.836919”,</p>
			<p class="source-code">      “com.redhat.build-host”: “cpt-1005.osbs.prod.upshift.rdu2.redhat.com”,</p>
			<p class="source-code">      “com.redhat.component”: “ubi7-minimal-container”,</p>
			<p class="source-code">      “com.redhat.license_terms”: “https://www.redhat.com/en/about/red-hat-end-user-license-agreements#UBI”,</p>
			<p class="source-code">      “description”: “The Universal Base Image Minimal is a stripped down image that uses microdnf as a package manager. This base image is freely redistributable, but Red Hat only supports Red Hat technologies through subscriptions for Red Hat products. This image is maintained by Red Hat and updated regularly.”,</p>
			<p class="source-code">      “distribution-scope”: “public”,</p>
			<p class="source-code">      “io.k8s.description”: “The Universal Base Image Minimal is a stripped down image that uses microdnf as a package manager. This base image is freely redistributable, but Red Hat only supports Red Hat technologies through subscriptions for Red Hat products. This image is maintained by Red Hat and updated regularly.”,</p>
			<p class="source-code">      “io.k8s.display-name”: “Red Hat Universal Base Image 7 Minimal”,</p>
			<p class="source-code">      “io.openshift.tags”: “minimal rhel7”,</p>
			<p class="source-code">      “maintainer”: “Red Hat, Inc.”,</p>
			<p class="source-code">      “name”: “ubi7-minimal”,</p>
			<p class="source-code">      “release”: “432”,</p>
			<p class="source-code">      “summary”: “Provides the latest release of the minimal Red Hat Universal Base Image 7.”,</p>
			<p class="source-code">      “url”: “https://access.redhat.com/containers/#/registry.access.redhat.com/ubi7-minimal/images/7.9-432”,</p>
			<p class="source-code">      “vcs-ref”: “8c60d5a9644707e7c4939980a221ec2927d9a88a”,</p>
			<p class="source-code">      “vcs-type”: “git”,</p>
			<p class="source-code">      “vendor”: “Red Hat, Inc.”,</p>
			<p class="source-code">      “version”: “7.9”</p>
			<p class="source-code">    },</p>
			<p class="source-code">    “ParentId”: “”,</p>
			<p class="source-code">    “RepoDigests”: [</p>
			<p class="source-code">      “registry.access.redhat.com/ubi7/ubi-minimal@sha256:73b4f78b569d178a48494496fe306dbefc3c0434c4b 872c7c9d7f23eb4feb909”</p>
			<p class="source-code">    ],</p>
			<p class="source-code">    “RepoTags”: [</p>
			<p class="source-code">      “registry.access.redhat.com/ubi7/ubi-minimal:latest”</p>
			<p class="source-code">    ],</p>
			<p class="source-code">    “SharedSize”: -1,</p>
			<p class="source-code">    “Size”: 81497870,</p>
			<p class="source-code">    “VirtualSize”: 81497870</p>
			<p class="source-code">  }</p>
			<p class="source-code">] </p>
			<p>As you can see <a id="_idIndexMarker156"/>in the preceding command, the output is in JSON format, very detailed with <a id="_idIndexMarker157"/>multiple metadata information, from container image name to its size. In this example, we pre-fetched a <strong class="bold">RHEL Universal Base Image</strong> version 7 in its minimal flavour that is only 80 MB!</p>
			<p>Of course, APIs are not made for human consumption or interaction; they fit well with machine-to-machine interaction and so they are commonly used for software integration. For this reason, let’s now explore how the command-line client works and which options are available.</p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor050"/>Docker client commands</h2>
			<p>The Docker daemon has its <a id="_idIndexMarker158"/>own companion that instructs and configures it – a command-line client.</p>
			<p>The Docker command-line client has more than 30 commands with respective options that will enable any system administrator or Docker user to instruct and control the daemon <a id="_idIndexMarker159"/>and its containers. The following is an overview of the most common commands:</p>
			<ul>
				<li><strong class="source-inline">build</strong>: Build an image from a Dockerfile</li>
				<li><strong class="source-inline">cp</strong>: Copy files/folders between a container and the local filesystem</li>
				<li><strong class="source-inline">exec</strong>: Run a command in a running container</li>
				<li><strong class="source-inline">images</strong>: List images</li>
				<li><strong class="source-inline">inspect</strong>: Return low-level information on Docker objects</li>
				<li><strong class="source-inline">kill</strong>: Kill one or more running containers</li>
				<li><strong class="source-inline">load</strong>: Load an image from a TAR archive or stdin</li>
				<li><strong class="source-inline">login</strong>: Log in to a Docker registry</li>
				<li><strong class="source-inline">logs</strong>: Fetch the logs of a container</li>
				<li><strong class="source-inline">ps</strong>: List running containers</li>
				<li><strong class="source-inline">pull</strong>: Pull an image or a repository from a registry</li>
				<li><strong class="source-inline">push</strong>: Push an image or a repository to a registry</li>
				<li><strong class="source-inline">restart</strong>: Restart one or more containers</li>
				<li><strong class="source-inline">rm</strong>: Remove one or more containers</li>
				<li><strong class="source-inline">rmi</strong>: Remove one or more images</li>
				<li><strong class="source-inline">run</strong>: Run a command in a new container</li>
				<li><strong class="source-inline">save</strong>: Save one or more images to a TAR archive (streamed to stdout by default)</li>
				<li><strong class="source-inline">start</strong>: Start one or more stopped containers</li>
				<li><strong class="source-inline">stop</strong>: Stop one or more running containers</li>
				<li><strong class="source-inline">tag</strong>: Create a <strong class="source-inline">TARGET_IMAGE</strong> tag that refers to <strong class="source-inline">SOURCE_IMAGE</strong></li>
			</ul>
			<p>The list goes on. As you can see from this subset, there are many commands available for managing the <a id="_idIndexMarker160"/>container images and the running containers, even exporting a container image or building a new one.</p>
			<p>Once you launch the Docker client with one of these commands and its respective options, the client will contact the Docker daemon, where it’ll instruct it in what is needed, and which action must be performed. Again, the daemon here is the key element of the architecture and it needs to be up and running, so ensure this before trying to use the Docker client as well as any of its REST APIs.</p>
			<h2 id="_idParaDest-52"><a id="_idTextAnchor051"/>Docker images</h2>
			<p>A Docker image is a format introduced by Docker for managing binary data and metadata as a <a id="_idIndexMarker161"/>template for container creation. Docker images are packages for shipping and transferring runtimes, libraries, and all the stuff needed for a given process to be up and running.</p>
			<p>As we mentioned in <a href="B17908_01_epub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Container Technology</em>, in the <em class="italic">Where do containers come from?</em> section, the creation of this format was really a game changer and significantly different from the various other container technologies that arose in the past.</p>
			<p>Starting from version 1.12, Docker started adopting an image specification that has over the years evolved <a id="_idIndexMarker162"/>into the current version that adheres to the <strong class="bold">OCI Image Format Specification</strong>.</p>
			<p>The first Docker Image Specification included many concepts and fields that are now part of the OCI Image Format Specification, such as the following:</p>
			<ul>
				<li>A list of layers</li>
				<li>Creation date</li>
				<li>Operating system</li>
				<li>CPU architecture</li>
				<li>Configuration parameters for use within a container runtime</li>
			</ul>
			<p>A Docker image’s content (binaries, libraries, filesystem data) is organized in layers. A layer is just a <a id="_idIndexMarker163"/>set of filesystem changes that does not contain any environment variable or default arguments for a given command. This data is stored in the <strong class="bold">Image Manifest</strong> that owns the configuration parameters.</p>
			<p>But how are these layers created and then aggregated in a Docker image? The answer is not so simple. The layers in a container image are composed together using image metadata and merged into a single filesystem view. This result can be achieved in many ways, but as anticipated in the previous chapter, the most common approach today is by using union filesystems – combining two filesystems and providing a unique, <em class="italic">squashed</em> view. Finally, when a container is executed, a new, <em class="italic">read/write</em> ephemeral layer is created on top of the image, which will be lost after the container is destroyed.</p>
			<p>As we said earlier in this chapter, container images and their distribution were the killer feature of Docker containers. So, in the next section, let’s look at the key element for container distribution, <strong class="bold">Docker registries</strong>. </p>
			<h2 id="_idParaDest-53"><a id="_idTextAnchor052"/>Docker registries</h2>
			<p>A Docker registry is just a repository of Docker container images that holds the metadata and the <a id="_idIndexMarker164"/>layers of container images for making them available to several Docker daemons.</p>
			<p>A Docker daemon acts as a client to a Docker registry through an HTTP API, pushing and pulling container images depending on the action that the Docker client instructs.</p>
			<p>Using a container registry could really help the use of containers on many independent machines that <a id="_idIndexMarker165"/>could be configured to ask to a registry some container images if they are <a id="_idIndexMarker166"/>not present in the Docker daemon local cache. The default registry that is preconfigured in Docker daemon settings is <strong class="bold">Dockerhub</strong>, a <strong class="bold">Software-as-a-Service</strong> container registry hosted by Docker company in the cloud. However, Dockerhub is not the only registry; many other container registries have appeared in recent years.</p>
			<p>Almost every company or community working with containers created their own container registry with a <a id="_idIndexMarker167"/>different web interface. One of the free alternative services to Dockerhub is <strong class="bold">Quay.io</strong>, a Software-as-a-Service container registry hosted by the Red Hat company.</p>
			<p>One great alternative to cloud services is the on-premises Docker registry, which can be created through a container on a machine running the Docker daemon with just one command:</p>
			<p class="source-code">$ docker run -d -p 5000:5000 --restart=always --name registry registry:2</p>
			<p>It is not the objective of this book to go through the various Docker options and configuration, but if <a id="_idIndexMarker168"/>you want to know more about the Docker registry, you <a id="_idIndexMarker169"/>can refer to the main Docker documentation at <a href="https://docs.docker.com/registry/deploying/">https://docs.docker.com/registry/deploying/</a>.</p>
			<p>We have looked at a lot of stuff so far, namely the Docker API, client, daemon, images, and finally the registry, but, as we mentioned earlier, it’s all dependent on the correct usage of the Docker daemon that should be always healthy and up and running. So, let’s explore now what happens in the event that it stops working.</p>
			<h2 id="_idParaDest-54"><a id="_idTextAnchor053"/>What does a running Docker architecture look like?</h2>
			<p>The Docker daemon is the <a id="_idIndexMarker170"/>central key element of the whole Docker architecture. We will explore in this section what a Docker daemon and a bunch of running containers look like.</p>
			<p>We will not dive into the steps needed for installing and setting up the Docker daemon; instead, we will directly analyze a preconfigured operating system with it:</p>
			<p class="source-code">[root@fedora34 ~]# systemctl status docker</p>
			<p class="source-code">● docker.service - Docker Application Container Engine</p>
			<p class="source-code">     Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled)</p>
			<p class="source-code">     Active: active (running) since Tue 2021-08-31 19:46:57 UTC; 1h 39min ago</p>
			<p class="source-code">TriggeredBy: ● docker.socket</p>
			<p class="source-code">       Docs: https://docs.docker.com</p>
			<p class="source-code">   Main PID: 20258 (dockerd)</p>
			<p class="source-code">      Tasks: 12</p>
			<p class="source-code">     Memory: 31.1M</p>
			<p class="source-code">        CPU: 1.946s</p>
			<p class="source-code">     CGroup: /system.slice/docker.service</p>
			<p class="source-code">             └─20258 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock</p>
			<p>As you can see from the preceding command, we just verified that the Docker daemon is up and running, but it’s not the only container service running on the system. The Docker daemon has a <a id="_idIndexMarker171"/>companion that we skipped in the previous part to keep the description easy to understand: <strong class="bold">Containerd</strong>.</p>
			<p>To better understand the workflow, have a look at the following diagram:</p>
			<div>
				<div id="_idContainer014" class="IMG---Figure">
					<img src="image/B17908_02_02.jpg" alt="Figure 2.2 – Running a Docker container&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.2 – Running a Docker container</p>
			<p>Containerd is the project that <a id="_idIndexMarker172"/>decouples the container management (kernel interaction included) from the Docker daemon, and it also adheres to the OCI standard using <strong class="source-inline">runc</strong> as container runtime.</p>
			<p>So, let’s check the status of Containerd in our preconfigured operating system:</p>
			<p class="source-code">[root@fedora34 ~]# systemctl status containerd</p>
			<p class="source-code">● containerd.service - containerd container runtime</p>
			<p class="source-code">     Loaded: loaded (/usr/lib/systemd/system/containerd.service; disabled; vendor preset: disabled)</p>
			<p class="source-code">     Active: active (running) since Wed 2021-08-25 12:48:17 UTC; 6 days ago</p>
			<p class="source-code">       Docs: https://containerd.io</p>
			<p class="source-code">    Process: 4267 ExecStartPre=/sbin/modprobe overlay (code=exited, status=0/SUCCESS)</p>
			<p class="source-code">   Main PID: 4268 (containerd)</p>
			<p class="source-code">      Tasks: 43</p>
			<p class="source-code">     Memory: 44.1M</p>
			<p class="source-code">        CPU: 8min 36.291s</p>
			<p class="source-code">     CGroup: /system.slice/containerd.service</p>
			<p class="source-code">             ├─ 4268 /usr/bin/containerd</p>
			<p class="source-code">             ├─20711 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 3901d2600732ae1f2681cde0074f290c1839b1a4b0c63ac 9aaccdba4f646e06a -address /run/containerd/containe&gt;</p>
			<p class="source-code">             ├─20864 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 78dc2eeb321433fc67cf910743c0c53e54d9f45cfee8d183 19d03a622dc56666 -address /run/containerd/containe&gt;</p>
			<p class="source-code">             └─21015 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 7433c0613412349833b927efa79a4f589916b12c942003cd 616d45ed7611fc31 -address /run/containerd/containe&gt;</p>
			<p>As you can see from the preceding console output, the service is up and running and it has started <a id="_idIndexMarker173"/>three child processes: <strong class="source-inline">/usr/bin/containerd-shim-runc-v2</strong>. This matches perfectly what we just saw in <em class="italic">Figure 2.2</em>!</p>
			<p>Now, let’s check our running containers interacting with the Docker CLI:</p>
			<p class="source-code">[root@fedora34 ~]# docker ps</p>
			<p class="source-code">CONTAINER ID   IMAGE                            COMMAND                  CREATED          STATUS          PORTS                NAMES</p>
			<p class="source-code">7433c0613412   centos/httpd-24-centos7:latest   “container-entrypoin…”   26 minutes ago   Up 26 minutes   8080/tcp, 8443/tcp   funny_goodall</p>
			<p class="source-code">78dc2eeb3214   centos/httpd-24-centos7:latest   “container-entrypoin…”   26 minutes ago   Up 26 minutes   8080/tcp, 8443/tcp   wonderful_rubin</p>
			<p class="source-code">3901d2600732   centos/httpd-24-centos7:latest   “container-entrypoin…”   26 minutes ago   Up 26 minutes   8080/tcp, 8443/tcp   relaxed_heisenberg</p>
			<p>As you can see, the Docker client confirms that we have three running containers on our system, all started <a id="_idIndexMarker174"/>through the <strong class="source-inline">runc</strong> container runtime, managed by the Containerd system service and configured through a Docker daemon. </p>
			<p>Now that we have introduced this new element, Containerd, let’s look at it in more depth in the next section.</p>
			<h2 id="_idParaDest-55"><a id="_idTextAnchor054"/>Containerd architecture</h2>
			<p>Containerd architecture is composed of several components that are organized in subsystems. Components that <a id="_idIndexMarker175"/>link different subsystems are also referred to as modules in the Containerd architecture, as can be seen in the following diagram:</p>
			<div>
				<div id="_idContainer015" class="IMG---Figure">
					<img src="image/B17908_02_03.jpg" alt="Figure 2.3 – Containerd architecture&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.3 – Containerd architecture</p>
			<p>The two main subsystems available are the following:</p>
			<ul>
				<li>The bundle service that extracts bundles from disk images</li>
				<li>The runtime service that executes the bundles, creating the runtime containers</li>
			</ul>
			<p>The main modules that <a id="_idIndexMarker176"/>make the architecture fully functional are the following:</p>
			<ul>
				<li>The <strong class="source-inline">Executor</strong> module, which implements the container runtime that is represented in the preceding architecture as the <strong class="bold">Runtimes</strong> block</li>
				<li>The <strong class="source-inline">Supervisor</strong> module, which monitors and reports container state that is part of the <strong class="bold">Containers</strong> block in the preceding architecture</li>
				<li>The <strong class="source-inline">Snapshot</strong> module, which manages filesystem snapshots</li>
				<li>The <strong class="source-inline">Events</strong> module, which collects and consumes events</li>
				<li>The <strong class="source-inline">Metrics</strong> module, which exports several metrics via the metrics API</li>
			</ul>
			<p>The steps needed by Containerd to place a container in a running state are too complex to be described in this section, but we can sum them up as follows:</p>
			<ol>
				<li>Pull metadata and content through a <strong class="bold">Distribution Controller</strong>.</li>
				<li>Use the <strong class="bold">Bundle Controller</strong> to unpack the retrieved data, creating snapshots that will compose bundles.</li>
				<li>Execute the container through the bundle just created through the <strong class="bold">Runtime Controller</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer016" class="IMG---Figure">
					<img src="image/B17908_02_04.jpg" alt="Figure 2.4 – Containerd data flow diagram&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.4 – Containerd data flow diagram</p>
			<p>In this section, we have described the key features and design principles of the Docker container engine, with its <a id="_idIndexMarker177"/>daemon-centric approach. We can now move on to analyze the Podman daemonless architecture.</p>
			<h1 id="_idParaDest-56"><a id="_idTextAnchor055"/>Podman daemonless architecture</h1>
			<p>Podman (short for <em class="italic">POD MANager</em>) is a daemonless container engine that enables users to manage <a id="_idIndexMarker178"/>containers, images, and their related resources such as storage volumes or network resources. First-time users installing Podman soon realize that there is no service to start after the installation is complete. No background running daemon is required to run containers with Podman! </p>
			<p>Once installed, the Podman binary acts both as a <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>) and as a container <a id="_idIndexMarker179"/>engine that orchestrates the container <a id="_idIndexMarker180"/>runtime execution. The following subsections will explore the details of the Podman behavior and building blocks.</p>
			<h2 id="_idParaDest-57"><a id="_idTextAnchor056"/>Podman commands and REST API</h2>
			<p>The Podman CLI provides <a id="_idIndexMarker181"/>a growing set of commands. The curated list <a id="_idIndexMarker182"/>is available at <a href="https://docs.podman.io/en/latest/Commands.html">https://docs.podman.io/en/latest/Commands.html</a>. </p>
			<p>The following list explores a subset of the most commonly used commands:</p>
			<ul>
				<li><strong class="source-inline">build</strong>: Build an image from a Containerfile or Dockerfile</li>
				<li><strong class="source-inline">cp</strong>: Copy files/folders between a container and the local filesystem</li>
				<li><strong class="source-inline">exec</strong>: Run a command in a running container</li>
				<li><strong class="source-inline">events</strong>: Show Podman events </li>
				<li><strong class="source-inline">generate</strong>: Generate structured data such as Kubernetes YAML or systemd units </li>
				<li><strong class="source-inline">images</strong>: List local cached images</li>
				<li><strong class="source-inline">inspect</strong>: Return low-level information on containers or images</li>
				<li><strong class="source-inline">kill</strong>: Kill one or more running containers</li>
				<li><strong class="source-inline">load</strong>: Load an image from a container TAR archive or stdin</li>
				<li><strong class="source-inline">login</strong>: Log in to a container registry</li>
				<li><strong class="source-inline">logs</strong>: Fetch the logs of a container</li>
				<li><strong class="source-inline">pod</strong>: Manage pods</li>
				<li><strong class="source-inline">ps</strong>: List running containers</li>
				<li><strong class="source-inline">pull</strong>: Pull an image or a repository from a registry</li>
				<li><strong class="source-inline">push</strong>: Push an image or a repository to a registry</li>
				<li><strong class="source-inline">restart</strong>: Restart one or more containers</li>
				<li><strong class="source-inline">rm</strong>: Remove one or more containers</li>
				<li><strong class="source-inline">rmi</strong>: Remove one or more images</li>
				<li><strong class="source-inline">run</strong>: Run a command in a new container</li>
				<li><strong class="source-inline">save</strong>: Save one or more images to a TAR archive (streamed to stdout by default)</li>
				<li><strong class="source-inline">start</strong>: Start one or more stopped containers</li>
				<li><strong class="source-inline">stop</strong>: Stop one or more running containers</li>
				<li><strong class="source-inline">system</strong>: Manage Podman (disk usage, container migration, REST API services, storage management, and pruning)</li>
				<li><strong class="source-inline">tag</strong>: Create a <strong class="source-inline">TARGET_IMAGE</strong> tag that refers to <strong class="source-inline">SOURCE_IMAGE</strong></li>
				<li><strong class="source-inline">unshare</strong>: Run a command in a modified user namespace</li>
				<li><strong class="source-inline">volume</strong>: Manage container volumes (list, pruning, creation, inspection)</li>
			</ul>
			<p>In the upcoming chapters of the book, we will cover the preceding commands in greater detail and understand how to use them to manage the full container life cycle.</p>
			<p>Users who have <a id="_idIndexMarker183"/>already worked with Docker will immediately spot the <a id="_idIndexMarker184"/>same commands they used to execute with the Docker CLI. Podman CLI commands are compatible with Docker ones to help a smooth transition between the two tools.</p>
			<p>Differently from Docker, Podman does not need a running Docker daemon listening on a Unix socket to execute the preceding commands. Users can still choose to run a Podman service and make it listen to a Unix socket to expose native REST APIs.</p>
			<p>By running the following command, Podman will create a socket endpoint on a path of preference and listen to API calls:</p>
			<p class="source-code">$ podman system service -–time 0 unix://tmp/podman.sock</p>
			<p>If not provided, the default socket endpoint is <strong class="source-inline">unix://run/podman/podman.sock</strong> for rootful services and <strong class="source-inline">unix://run/user/&lt;UID&gt;/podman/podman.sock</strong> for rootless containers.</p>
			<p>As a result, users can then make REST API calls to the socket endpoint. The following example queries Podman for the available local images:</p>
			<p class="source-code">curl --unix-socket /tmp/podman.sock \ http://d/v3.0.0/libpod/images/json | jq .</p>
			<p>The Podman project <a id="_idIndexMarker185"/>maintains OpenAPI-compliant documentation of available REST API calls at <a href="https://docs.podman.io/en/latest/_static/api.html">https://docs.podman.io/en/latest/_static/api.html</a>.</p>
			<p>The piped <strong class="source-inline">jq</strong> command <a id="_idIndexMarker186"/>in the preceding example is useful to produce a more readable <a id="_idIndexMarker187"/>JSON-pretty output. We will explore the Podman REST API and systemd socket-based activation in greater detail in the post-installation customization section of <a href="B17908_03_epub.xhtml#_idTextAnchor068"><em class="italic">Chapter 3</em></a>, <em class="italic">Running the First Container</em>. Let’s now describe Podman building blocks in greater detail.</p>
			<h2 id="_idParaDest-58"><a id="_idTextAnchor057"/>Podman building blocks</h2>
			<p>Podman aims to adhere to open standards as much as possible; therefore, most of the runtime, build, storage, and <a id="_idIndexMarker188"/>networking components rely on community projects and standards. The components described in the following list can be seen as the main Podman building blocks:</p>
			<ul>
				<li>The container life <a id="_idIndexMarker189"/>cycle is managed with the <strong class="bold">libpod</strong> library, already included in the Podman main repository: <a href="https://github.com/containers/podman/tree/main/libpod&#13;">https://github.com/containers/podman/tree/main/libpod.</a></li>
				<li>The container runtime is <a id="_idIndexMarker190"/>based on the OCI specs implemented by OCI-compliant <a id="_idIndexMarker191"/>runtimes, such as <strong class="bold">crun</strong> and <strong class="bold">runc</strong>. We will see in this chapter how container runtimes work and the main difference between the above-mentioned ones.</li>
				<li>At the same time, image <a id="_idIndexMarker192"/>management implements the <strong class="bold">containers/image</strong> library (<a href="https://github.com/containers/image">https://github.com/containers/image</a>). This is a set of Go libraries used both by container engines and container registries.</li>
				<li>Container and image storage is implemented adopting the <strong class="bold">containers/storage</strong> library (<a href="https://github.com/containers/storage">https://github.com/containers/storage</a>), another Go library to manage <a id="_idIndexMarker193"/>filesystem layers, container images, and container volumes at runtime.</li>
				<li>Image builds are implemented with Buildah (<a href="https://github.com/containers/buildah">https://github.com/containers/buildah</a>), which is both a binary tool and a library for building OCI images. We will cover Buildah later in this book.</li>
				<li>Container runtime <a id="_idIndexMarker194"/>monitoring and communication with the engine is implemented with <strong class="bold">Conmon</strong>, a tool for monitoring OCI runtimes, used by both Podman and <strong class="bold">CRI-O</strong> (<a href="https://github.com/containers/conmon">https://github.com/containers/conmon</a>).</li>
			</ul>
			<p>Container networking <a id="_idIndexMarker195"/>support is implemented through the Kubernetes <strong class="bold">Container Network Interface</strong> (<strong class="bold">CNI</strong>) specs. This also <a id="_idIndexMarker196"/>helps shape Podman networking with a plugin-oriented approach. By default, Podman uses the basic <strong class="source-inline">bridge</strong> CNI plugin. An extended list <a id="_idIndexMarker197"/>of plugins is available in the following repository: https://github.com/containernetworking/plugins.</p>
			<p>As stated earlier, Podman orchestrates the container life cycle thanks to the libpod library, described in the next subsection.</p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor058"/>The libpod library</h2>
			<p>Podman core foundations are based on the libpod library, which is also adopted by other open source projects <a id="_idIndexMarker198"/>such as CRI-O. This library contains all the necessary logic to orchestrate the container life cycle and we can safely say that the development of this library was the key to the birth of the Podman project as we know it today. </p>
			<p>The library is written in Go and is thus accessed as a <strong class="bold">Go package</strong> and is intended to implement all the high-level functionalities of the engine. According to the libpod and Podman documentation, its scope includes the following:</p>
			<ul>
				<li>Managing container image format, which includes both OCI and Docker images. This includes the full image life cycle management, from authenticating and pulling from a container registry, and local storage of the image layers and metadata, to the building of new images and pushing to remote registries.</li>
				<li>Container life cycle management – from container creation (with all the necessary preliminary steps involved) and running the container to all the other runtime functionalities such as stop, kill, resume, and delete, process execution on running containers, and logging.</li>
				<li>Managing both simple containers and <strong class="bold">pods</strong>, which are groups of sandboxed containers that share <a id="_idIndexMarker199"/>namespaces together (notably UTC, IPC, Network, and recently Pid) and are also managed together as a whole.</li>
				<li>Supporting <strong class="bold">rootless </strong>containers and pods that can be executed by standard users with no need for privilege escalation.</li>
				<li>Managing container resource isolation. This is achieved at a low level with CGroup but Podman users can interact using CLI options during container execution to manage memory and CPU reservation or limit read/write rate on a storage device. </li>
				<li>Supporting a CLI that can be used as a Docker-compatible alternative. Most Podman commands are the same as in the Docker CLI.</li>
				<li>Providing a Docker-compatible REST API with local Unix sockets (not enabled by default). Libpod REST APIs provide all the functionalities provided by the Podman CLI. </li>
			</ul>
			<p>The lidpod package interacts, at a lower level, with container runtimes, Conmon, and packages such as container/storage, container/image, Buildah, and CNI. In the next section, we will focus on the container runtime execution.</p>
			<h2 id="_idParaDest-60"><a id="_idTextAnchor059"/>The runc and crun OCI container runtimes </h2>
			<p>As illustrated in the <a id="_idIndexMarker200"/>previous chapter, a container engine takes care of <a id="_idIndexMarker201"/>the high-level orchestration of the container life cycle, while the low-level actions necessary to create and run the container are delivered by a container runtime.</p>
			<p>An industry standard has emerged in the last few years, with the help of the major container environment <a id="_idIndexMarker202"/>contributors: the <strong class="bold">OCI Runtime Specification</strong>. The full specification is available at <a href="https://github.com/opencontainers/runtime-spec">https://github.com/opencontainers/runtime-spec</a>.</p>
			<p>From this repository, the <em class="italic">Runtime and Lifecycle</em> document provides a full description of how the container runtime should handle the container creation and execution: <a href="https://github.com/opencontainers/runtime-spec/blob/master/runtime.md">https://github.com/opencontainers/runtime-spec/blob/master/runtime.md</a>.</p>
			<p><strong class="bold">Runc</strong> (<a href="https://github.com/opencontainers/runc">https://github.com/opencontainers/runc</a>) is currently the most widely adopted OCI container runtime. Its history leads back to 2015, when Docker announced the spin out of all its infrastructure plumbing into a dedicated project called runC.</p>
			<p>RunC fully supports Linux containers <a id="_idIndexMarker203"/>and OCI runtime specs. The project repository includes the <strong class="bold">libcontainer</strong> package, which is a Go package for creating containers with namespaces, cgroups, capabilities, and filesystem access controls. Libcontainer was an independent Docker project before, and when the runC project was created, it was moved inside its main repository for the sake of consistence and clarity.</p>
			<p>The libcontainer package defines the inner logic and the low-level system interaction to bootstrap a container from scratch, from the initial isolation of namespaces to the execution as PID 1 of the binary program inside the container itself.</p>
			<p>The runtime recalls the libcontainer library to fulfil the following tasks:</p>
			<ul>
				<li>Consume the container mount point and the container metadata provided by Podman</li>
				<li>Interact with the kernel to start the container and execute the isolated process using the <strong class="source-inline">clone()</strong> and <strong class="source-inline">unshare()</strong> syscalls</li>
				<li>Set up CGroup resource reservations</li>
				<li>Set up SELinux Policy, Seccomp, and App Armor rules</li>
			</ul>
			<p>Along with running processes, libcontainer handles the initialization of namespaces and file descriptors, the <a id="_idIndexMarker204"/>creation of the container rootFS and bind mounts, exporting <a id="_idIndexMarker205"/>logs from container processes, managing security restrictions with seccomp, SELinux and AppArmor, and creating and mapping users and groups </p>
			<p>The libcontainer architecture is quite a complex topic for this book and obviously needs further investigation to better understand its internals.</p>
			<p>For readers interested in viewing the code and understanding Podman internals, the container interface that adheres to the OCI runtime specs is defined in the <a href="https://github.com/opencontainers/runc/blob/master/libcontainer/container.go">https://github.com/opencontainers/runc/blob/master/libcontainer/container.go</a> source file.</p>
			<p>The methods for the <a id="_idIndexMarker206"/>Linux OS that implement the interface are defined in <a href="https://github.com/opencontainers/runc/blob/master/libcontainer/container_linux.go">https://github.com/opencontainers/runc/blob/master/libcontainer/container_linux.go</a>. </p>
			<p>The low-level execution of <strong class="source-inline">clone()</strong> and <strong class="source-inline">unshare() syscall</strong> to isolate the process namespaces is <a id="_idIndexMarker207"/>handled by the <strong class="bold">nsenter </strong>package, more precisely by the <strong class="source-inline">nsexec()</strong> function. This is a C function <a id="_idIndexMarker208"/>embedded in the Go code thanks using <strong class="bold">cgo</strong>. </p>
			<p>The code of <strong class="source-inline">nsexec()</strong> can be found here:</p>
			<p><a href="https://github.com/opencontainers/runc/blob/master/libcontainer/nsenter/nsexec.c&#13;">https://github.com/opencontainers/runc/blob/master/libcontainer/nsenter/nsexec.c</a></p>
			<p>Along with <strong class="source-inline">runC</strong>, many other container runtimes have been created. An alternative runtime we will discuss <a id="_idIndexMarker209"/>in this book is <strong class="bold">crun</strong> (<a href="https://github.com/containers/crun">https://github.com/containers/crun</a>), a fast and low-memory-footprint OCI container runtime fully written in C. The idea behind <strong class="source-inline">crun</strong> was to provide an improved OCI runtime that could leverage the C design approach for a cleaner and lightweight runtime. Since they are both OCI runtimes, <strong class="source-inline">runC</strong> and <strong class="source-inline">crun</strong> can be used interchangeably by a container engine.</p>
			<p>For example, in 2019, the Fedora project made a brave move and chose to release Fedora 31 with CGroup V2 as the default (<a href="https://www.redhat.com/sysadmin/fedora-31-control-group-v2">https://www.redhat.com/sysadmin/fedora-31-control-group-v2</a>). At the time of this choice, <strong class="source-inline">runC</strong> was not yet capable of managing containers under CGroup V2. </p>
			<p>Consequently, the Podman release for Fedora adopted <strong class="source-inline">crun</strong> as the default runtime since it was already capable of managing both CGroup V1 and V2. This switch was almost seamless for <a id="_idIndexMarker210"/>end users, who continued to use Podman in the <a id="_idIndexMarker211"/>same way with the same commands and behaviors. Later, <strong class="source-inline">runC</strong> finally introduced support for CGroup V2, from v1.0.0-rc93, and can now be used on newer distributions seamlessly.</p>
			<p>However, the CGroup topic was not the only differentiator between <strong class="source-inline">runC</strong> and <strong class="source-inline">crun</strong>.</p>
			<p><strong class="source-inline">crun</strong> provides some interesting advantages against <strong class="source-inline">runC</strong>, such as the following:</p>
			<ul>
				<li><strong class="bold">Smaller binary</strong>: A <strong class="source-inline">crun</strong> build is <a id="_idIndexMarker212"/>approximately 50 times smaller than a <strong class="source-inline">runC</strong> build.</li>
				<li><strong class="bold">Faster execution</strong>: <strong class="source-inline">crun</strong> is faster on instrumenting the container than <strong class="source-inline">runC</strong> under the same execution conditions.</li>
				<li><strong class="bold">Less memory usage</strong>: <strong class="source-inline">crun</strong> consumes less than half the memory of <strong class="source-inline">runC</strong>. A smaller memory footprint is extremely helpful when dealing with massive container deployments or IoT appliances.</li>
			</ul>
			<p><strong class="source-inline">crun</strong> can also be used as a library and integrated in other OCI-compliant projects. Both <strong class="source-inline">crun</strong> and <strong class="source-inline">runC</strong> provide a CLI but are not meant to be used manually by end users, who are supposed to use a container engine such as Podman or Docker to manage the container life cycle.</p>
			<p>How easy is it to switch between the two runtimes in Podman? Let’s see the following examples. Both examples run a container using the <strong class="source-inline">–runtime</strong> flag to provide an OCI runtime binary path. The first one runs the container using <strong class="source-inline">runC</strong>:</p>
			<p class="source-code">podman --runtime /usr/bin/runc run --rm fedora echo “Hello World”</p>
			<p>The second line runs the same container with the <strong class="source-inline">crun</strong> binary:</p>
			<p class="source-code">podman --runtime /usr/bin/crun run --rm fedora echo “Hello World”</p>
			<p>The examples assume that <a id="_idIndexMarker213"/>both runtimes are already installed in the system.</p>
			<p>Both <strong class="source-inline">crun</strong> and <strong class="source-inline">runC</strong> support <strong class="bold">eBPF </strong>and <strong class="bold">CRIU</strong>. </p>
			<p><strong class="bold">eBPF</strong> stands for <strong class="bold">Extended Berkeley Packet Filter</strong> and is a kernel-based technology that allows the execution <a id="_idIndexMarker214"/>of user-defined programs in the <a id="_idIndexMarker215"/>Linux kernel to add extra capabilities to the <a id="_idIndexMarker216"/>system without the need to recompile the kernel or load extra modules. All eBPF programs are executed inside a sandbox virtual machine and their execution is secure by design. Today, eBPF is gaining momentum and attracting industry interest, leading to wide adoption in different use cases, most notably networking, security, observability, and tracing.</p>
			<p><strong class="bold">Checkpoint Restore in Userspace</strong> (<strong class="bold">CRIU</strong>) is a piece of software that enables users to freeze a running <a id="_idIndexMarker217"/>container and save its state to disk for further resume. Data structures saved in memory are dumped and restored accordingly. </p>
			<p>Another important architectural component used by Podman is Conmon, a tool for monitoring container runtime status. Let’s investigate this in more detail in the next subsection.</p>
			<h2 id="_idParaDest-61"><a id="_idTextAnchor060"/>Conmon</h2>
			<p>We may still have <a id="_idIndexMarker218"/>some questions about runtime execution.</p>
			<p>How do Podman (the container engine) and <strong class="source-inline">runC</strong>/<strong class="source-inline">crun</strong> (the OCI container runtime) interact with each other? Which is responsible for launching the container runtime process? Is there a way to monitor the container execution?</p>
			<p>Let’s introduce <a id="_idIndexMarker219"/>the Conmon project (<a href="https://github.com/containers/conmon">https://github.com/containers/conmon</a>). Conmon is a monitoring and communication tool that sits between the container engine and the runtime. </p>
			<p>Every time a new container is created, a new instance of Conmon is launched. It detaches from the container manager process and runs daemonized, launching the container runtime as a child process.</p>
			<p>If we attach a tracing tool to a Podman container, we can see in the following the order it’s written in:</p>
			<ol>
				<li value="1">The container engine runs the Conmon process, which detaches and daemonizes itself. </li>
				<li>The Conmon process runs a container runtime instance that starts the container and exits. </li>
				<li>The Conmon process continues to run to provide a monitoring interface, while the manager/engine process has exited or detached.</li>
			</ol>
			<p>The following diagram <a id="_idIndexMarker220"/>shows the logical workflow, from Podman execution to the running container:</p>
			<div>
				<div id="_idContainer017" class="IMG---Figure">
					<img src="image/B17908_02_05.jpg" alt="Figure 2.5 – Running a Podman container&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.5 – Running a Podman container</p>
			<p>On a system with many running containers, users will find many instances of the Conmon process, one for every container created. In other words, Conmon acts as a small, dedicated daemon to the container.</p>
			<p>Let’s look at the following example, where a simple shell loop is used to create three identical nginx containers:</p>
			<p class="source-code">[root@fedora34 ~]# for i in {1..3}; do podman run -d --rm docker.io/library/nginx; done</p>
			<p class="source-code">592f705cc31b1e47df18f71ddf922ea7e6c9e49217f00d1af8 cf18c8e5557bde</p>
			<p class="source-code">4b1e44f512c86be71ad6153ef1cdcadcdfa8bcfa8574f606a0832 c647739a0a2</p>
			<p class="source-code">4ef467b7d175016d3fa024d8b03ba44b761b9a75ed66b2050de3fe c28232a8a7</p>
			<p class="source-code">[root@fedora34 ~]# ps aux | grep conmon</p>
			<p class="source-code">root       21974  0.0  0.1  82660  2532 ?        Ssl  22:31   0:00 /usr/bin/conmon --api-version 1 -c 592f705cc31b1e47df18f71ddf922ea7e6c9e49217f00d1af8 cf18c8e5557bde -u 592f705cc31b1e47df18f71ddf922ea7e6c9e49217f00d1af8 cf18c8e5557bde -r /usr/bin/crun [..omitted output]</p>
			<p class="source-code">root       22089  0.0  0.1  82660  2548 ?        Ssl  22:31   0:00 /usr/bin/conmon --api-version 1 -c 4b1e44f512c86be71ad6153ef1cdcadcdfa8bcfa8574f606a0832 c647739a0a2 -u 4b1e44f512c86be71ad6153ef1cdcadcdfa8bcfa8574f606a0832 c647739a0a2 -r /usr/bin/crun [..omitted output] </p>
			<p class="source-code">root       22198  0.0  0.1  82660  2572 ?        Ssl  22:31   0:00 /usr/bin/conmon --api-version 1 -c 4ef467b7d175016d3fa024d8b03ba44b761b9a75ed66b2050de3f ec28232a8a7 -u 4ef467b7d175016d3fa024d8b03ba44b761b9a75ed66b2050de3f ec28232a8a7 -r /usr/bin/crun [..omitted output]</p>
			<p>After running the containers, a simple regular expression pattern applied to the output of the <strong class="source-inline">ps aux</strong> command <a id="_idIndexMarker221"/>shows three Conmon process instances.</p>
			<p>Even if Podman is not running anymore (since there is no daemon), it is still possible to connect to the Conmon process and attach to the container. At the same time, Conmon exposes console sockets and container logs to log files or the systemd journal.</p>
			<p>Conmon is a lightweight project written in C. It also provides Go language bindings to pass config structures between the manager and the runtime.</p>
			<h2 id="_idParaDest-62"><a id="_idTextAnchor061"/>Rootless containers</h2>
			<p>One of the most interesting features of Podman is the capability to run rootless containers, which <a id="_idIndexMarker222"/>means that users without elevated privileges can run their own containers. </p>
			<p>Rootless containers provide better security isolation and let different users run their own container instances independently and, thanks to <strong class="bold">fork/exec</strong>, a daemonless approach <a id="_idIndexMarker223"/>adopted by Podman, rootless containers are amazingly easy to manage. A rootless container is simply run by the standard user with the usual commands and arguments, as in the following example:</p>
			<p class="source-code">$ podman run –d –-rm docker.io/library/nginx</p>
			<p>When this command is <a id="_idIndexMarker224"/>issued, Podman creates a new user namespace and maps UIDs between the two namespaces using a <strong class="bold">uid_map</strong> file (see <strong class="source-inline">man user_namespaces</strong>). This method <a id="_idIndexMarker225"/>allows you to have, for example, a root user inside the container mapped to an ordinary user in the host. </p>
			<p>Rootless containers and image data are stored under the user home directory, usually under <strong class="source-inline">$HOME/.local/share/containers/storage</strong>.</p>
			<p>Podman manages network connectivity for rootless containers in a different way than rootful containers. An in-depth technical comparison between rootless and rootful containers, especially from the network and security point of view, will be covered later in this book.</p>
			<p>After an in-depth analysis of the runtime workflow, it is useful to provide an overview of the OCI image specs used by Podman.</p>
			<h2 id="_idParaDest-63"><a id="_idTextAnchor062"/>OCI images</h2>
			<p>Podman and the <a id="_idIndexMarker226"/>container/image package implement the <strong class="bold">OCI Image Format Specification</strong>. The full specification is available on GitHub at the following link and <a id="_idIndexMarker227"/>pairs with the OCI runtime specification: <a href="https://github.com/opencontainers/image-spec">https://github.com/opencontainers/image-spec</a>.</p>
			<p>An OCI image is made of the following elements:</p>
			<ol>
				<li value="1">Manifest </li>
				<li>An image index (optional)</li>
				<li>An image layout</li>
				<li>A filesystem layer changeset archive that will be unpacked to create a final filesystem</li>
				<li>An image configuration document to define layer ordering, as well as application arguments and environments</li>
			</ol>
			<p>Let’s see in detail what kinds of information and data are managed by the most relevant of the preceding elements. </p>
			<h3>Manifest</h3>
			<p>An image manifest specification should provide content-addressable images. The image manifest contains <a id="_idIndexMarker228"/>image layers and configurations for a specific architecture <a id="_idIndexMarker229"/>and operating system, such as Linux x86_64.</p>
			<p>Specification: <a href="https://github.com/opencontainers/image-spec/blob/main/manifest.md">https://github.com/opencontainers/image-spec/blob/main/manifest.md</a></p>
			<h3>Image index</h3>
			<p>An image index is an <a id="_idIndexMarker230"/>object that contains a list of manifests related to different architectures (for example, amd64, arm64, or 386) and operating systems, along <a id="_idIndexMarker231"/>with custom annotations.</p>
			<p>Specification: <a href="https://github.com/opencontainers/image-spec/blob/main/image-index.md">https://github.com/opencontainers/image-spec/blob/main/image-index.md</a></p>
			<h3>Image layout</h3>
			<p>The OCI image layout represents the directory structure of image blobs. The image layout also provides the <a id="_idIndexMarker232"/>necessary manifest location references as well as image index (in JSON format) and the image configuration. The image <strong class="source-inline">index.json</strong> contains <a id="_idIndexMarker233"/>the reference to the image manifest, stored as a blob in the OCI image bundle.</p>
			<p>Specification: <a href="https://github.com/opencontainers/image-spec/blob/main/image-layout.md">https://github.com/opencontainers/image-spec/blob/main/image-layout.md</a></p>
			<h3>Filesystem layers</h3>
			<p>Inside an image, one or more layers are applied on top of each other to create a filesystem <a id="_idIndexMarker234"/>that the container can use. </p>
			<p>At a low level, layers are packaged as TAR archives (with compression options with gzip and zstd). The filesystem layer implements the logic of layers stacking and how the changeset layers (layers containing file changes) are applied.</p>
			<p>As described in the previous chapter, a copy-on-write or union filesystem has become a standard to manage <a id="_idIndexMarker235"/>stacking in a graph-like approach. To manage layers stacking, Podman uses <strong class="bold">overlayfs</strong> by default as a graph driver.</p>
			<p>Specification: <a href="https://github.com/opencontainers/image-spec/blob/main/layer.md">https://github.com/opencontainers/image-spec/blob/main/layer.md</a></p>
			<h3>Image configuration</h3>
			<p>An image configuration defines the image layer composition and the corresponding execution <a id="_idIndexMarker236"/>parameters such as entry points, volumes, execution arguments, or environment variables, as well as additional image metadata.</p>
			<p>The image JSON holding <a id="_idIndexMarker237"/>the configurations is an <strong class="bold">immutable</strong> object; changing <a id="_idIndexMarker238"/>it means creating a new derived image. </p>
			<p>Specification: <a href="https://github.com/opencontainers/image-spec/blob/main/config.md">https://github.com/opencontainers/image-spec/blob/main/config.md</a></p>
			<p>The following diagram represents an OCI image implementation, composed of image layer(s), image index, and image configuration:</p>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer018" class="IMG---Figure">
					<img src="image/B17908_02_06.jpg" alt="Figure 2.6 – OCI image implementation&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.6 – OCI image implementation</p>
			<p>Let’s inspect a realistic example from a basic, lightweight <strong class="bold">alpine</strong> image:</p>
			<p class="source-code"><strong class="bold"># tree alpine/</strong></p>
			<p class="source-code">alpine/</p>
			<p class="source-code">├── blobs</p>
			<p class="source-code">│   └── sha256</p>
			<p class="source-code">│       ├── 03014f0323753134bf6399ffbe26dcd75e89c6a7429adfab 392d64706649f07b</p>
			<p class="source-code">│       ├── 696d33ca1510966c426bdcc0daf05f75990d68c4eb820f615 edccf7b971935e7</p>
			<p class="source-code">│       └── a0d0a0d46f8b52473982a3c466318f479767577551a53ffc9074 c9fa7035982e</p>
			<p class="source-code">├── index.json</p>
			<p class="source-code">└── oci-layout</p>
			<p>The directory <a id="_idIndexMarker239"/>layout contains an <strong class="source-inline">index.json</strong> file, with the following content:</p>
			<p class="source-code">{</p>
			<p class="source-code">  “schemaVersion”: 2,</p>
			<p class="source-code">  “manifests”: [</p>
			<p class="source-code">    {</p>
			<p class="source-code">      “mediaType”: “application/vnd.oci.image.manifest.v1+json”,</p>
			<p class="source-code">      “digest”: “sha256:03014f0323753134bf6399ffbe26dcd75e89c6a7429adfab 392d64706649f07b”,</p>
			<p class="source-code">      “size”: 348,</p>
			<p class="source-code">      “annotations”: {</p>
			<p class="source-code">        “org.opencontainers.image.ref.name”: “latest”</p>
			<p class="source-code">      }</p>
			<p class="source-code">    }</p>
			<p class="source-code">  ]</p>
			<p class="source-code">}</p>
			<p>The index contains a manifests array with only one item inside. The object digest is a SHA256 and <a id="_idIndexMarker240"/>corresponds to filename as one of the blobs listed previously. The file is the image manifest and can be inspected:</p>
			<p class="source-code"><strong class="bold"># cat alpine/blobs/sha256/03014f0323753134bf6399ffbe26dcd75e89c6a7429adfab392 d64706649f07b | jq</strong></p>
			<p class="source-code">{</p>
			<p class="source-code">  “schemaVersion”: 2,</p>
			<p class="source-code">  “config”: {</p>
			<p class="source-code">    “mediaType”: “application/vnd.oci.image.config.v1+json”,</p>
			<p class="source-code">    “digest”: “sha256:696d33ca1510966c426bdcc0daf05f75990d 68c4eb820f615edccf7b971935e7”,</p>
			<p class="source-code">    “size”: 585</p>
			<p class="source-code">  },</p>
			<p class="source-code">  “layers”: [</p>
			<p class="source-code">    {</p>
			<p class="source-code">      “mediaType”: “application/vnd.oci.image.layer.v1.tar+gzip”,</p>
			<p class="source-code">      “digest”: “sha256:a0d0a0d46f8b52473982a3c466318f47976 7577551a53ffc9074c9fa7035982e”,</p>
			<p class="source-code">      “size”: 2814446</p>
			<p class="source-code">    }</p>
			<p class="source-code">  ]</p>
			<p class="source-code">}</p>
			<p>The manifest contains references to the image configuration and layers. In this particular case, the image has only one layer. Again, their digests correspond to the blob filenames listed before. </p>
			<p>The config file shows image metadata, environment variables, and command execution. At the same <a id="_idIndexMarker241"/>time, it contains <strong class="source-inline">DiffID</strong> references to the layers used by the image and image creation information:</p>
			<p class="source-code"><strong class="bold"># cat alpine/blobs/sha256/696d33ca1510966c426bdcc0daf05f75990 d68c4eb820f615edccf7b971935e7 | jq</strong></p>
			<p class="source-code">{</p>
			<p class="source-code">  “created”: “2021-08-27T17:19:45.758611523Z”,</p>
			<p class="source-code">  “architecture”: “amd64”,</p>
			<p class="source-code">  “os”: “linux”,</p>
			<p class="source-code">  “config”: {</p>
			<p class="source-code">    “Env”: [</p>
			<p class="source-code">      “PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin”</p>
			<p class="source-code">    ],</p>
			<p class="source-code">    “Cmd”: [</p>
			<p class="source-code">      “/bin/sh”</p>
			<p class="source-code">    ]</p>
			<p class="source-code">  },</p>
			<p class="source-code">  “rootfs”: {</p>
			<p class="source-code">    “type”: “layers”,</p>
			<p class="source-code">    “diff_ids”: [</p>
			<p class="source-code">      “sha256:e2eb06d8af8218cfec8210147357a68b7e13f7c485b991c 288c2d01dc228bb68”</p>
			<p class="source-code">    ]</p>
			<p class="source-code">  },</p>
			<p class="source-code">  “history”: [</p>
			<p class="source-code">    {</p>
			<p class="source-code">      “created”: “2021-08-27T17:19:45.553092363Z”,</p>
			<p class="source-code">      “created_by”: “/bin/sh -c #(nop) ADD file:aad4290d27580 cc1a094ffaf98c3ca2fc5d699fe695dfb8e6e9fac 20f1129450 in / “</p>
			<p class="source-code">    },</p>
			<p class="source-code">    {</p>
			<p class="source-code">      “created”: “2021-08-27T17:19:45.758611523Z”,</p>
			<p class="source-code">      “created_by”: “/bin/sh -c #(nop)  CMD [\”/bin/sh\”]”,</p>
			<p class="source-code">      “empty_layer”: true</p>
			<p class="source-code">    }</p>
			<p class="source-code">  ]</p>
			<p class="source-code">}</p>
			<p>The image layer is the third blob file. This is a TAR archive that could be exploded and inspected. For space <a id="_idIndexMarker242"/>reasons, in this book the example is limited to an inspection of the file type:</p>
			<p class="source-code"><strong class="bold"># file alpine/blobs/sha256/a0d0a0d46f8b52473982a3c466318f47 9767577551a53ffc9074c9fa7035982e</strong></p>
			<p class="source-code">alpine/blobs/sha256/a0d0a0d46f8b52473982a3c466318f479767577 551a53ffc9074c9fa7035982e: gzip compressed data, original size modulo 2^32 5865472</p>
			<p>The result demonstrates that the file is a TAR gzipped archive. </p>
			<h1 id="_idParaDest-64"><a id="_idTextAnchor063"/>The main differences between Docker and Podman </h1>
			<p>In the previous sections, we went through the key features of Docker and Podman, looking into the <a id="_idIndexMarker243"/>underlying layer, discovering the companion open <a id="_idIndexMarker244"/>source projects that made these two tools unique in their container engine role, but now it’s time to compare them.</p>
			<p>As we saw earlier, the significant difference between the two is that Docker has a daemon-centric approach while Podman instead has a daemonless architecture. The Podman binary acts as CLI as well as a container engine and uses Conmon to orchestrate and monitor the container runtime.</p>
			<p>Looking under the hood into the internals of both projects, we will also find many other differences but, in the end, once the container has started, they both leverage OCI standard container runtimes but with some differences: Docker uses <strong class="source-inline">runc</strong> while Podman uses <strong class="source-inline">crun</strong> in most distributions, with some exceptions; for example, it still uses <strong class="source-inline">runc</strong> in the most conservative Red Hat Enterprise Linux 8 with <strong class="source-inline">crun</strong> as an option. </p>
			<p>Despite the <strong class="source-inline">crun</strong> performance advantages described in the previous section, it is not the objective of this book to make a detailed performance comparison between the two. Anyway, readers interested in the topic will easily find literature about the performance differences between the two runtimes.</p>
			<p>Another big gap that was recently filled by the Docker team was the rootless container. Podman was the first container engine to bring out this excellent feature that increases security and improve the usage of containers in many contexts but, as we mentioned, this feature is now available in Docker too.</p>
			<p>But let’s go more practical in the next sections, by comparing them side by side through the command line first and then by running a container.</p>
			<h2 id="_idParaDest-65"><a id="_idTextAnchor064"/>Command-line interface comparison</h2>
			<p>In this <a id="_idIndexMarker245"/>section, we will go through a side-by-side comparison looking at the Docker and Podman CLIs.</p>
			<p>Looking at the available commands for both CLIs, it is easy to spot the many similarities. The following table was truncated to improve readability:</p>
			<div>
				<div id="_idContainer019" class="IMG---Figure">
					<img src="image/Table_2.1.jpg" alt="Table 2.1 – Comparison of Docker and Podman commands&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Table 2.1 – Comparison of Docker and Podman commands</p>
			<p>As we stated many times in the preceding section, as well as in the previous chapter, Docker was born in 2013 while Podman only arrived 4 years later in 2017. Podman was built <a id="_idIndexMarker246"/>keeping in mind how experienced container administrators were with the most famous container engine available at that time: Docker. For this reason, the Podman development team decided to not change too much the <em class="italic">look and feel</em> of the command-line tools for improving Docker users’ migration to the new-born Podman.</p>
			<p>There was a claim, in fact, at the beginning of the distribution of Podman that if you have any existing scripts that run Docker you can create an alias and it should work (<strong class="source-inline">alias docker=podman</strong>). It was also created a package that places a <em class="italic">fake</em> Docker command under <strong class="source-inline">/usr/bin</strong> that points to <em class="italic">Podman</em> binary instead. For this reason, if you are a Docker user, you can expect a smooth transition to Podman once you are ready.</p>
			<p>Another important point is that the images created with Docker are compatible with the OCI standard, so you can easily migrate or pull again any image you previously used with Docker.</p>
			<p>If we take a deep look into the command options available for Podman, you will notice that there are some additional commands that are not present in Docker, while some others are missing.</p>
			<p>For example, Podman can manage, along with containers, <strong class="bold">pods</strong> (the name Podman is quite telling here). The pod concept was introduced with Kubernetes and represents the smallest execution unit in a Kubernetes cluster. </p>
			<p>With Podman, users can create empty pods and then run containers inside them easily using the following command:</p>
			<p class="source-code">$ podman pod create --name mypod</p>
			<p class="source-code">$ podman run –-pod mypod –d docker.io/library/nginx</p>
			<p>This is not as easy with Docker, where users must first run a container and then create new ones attaching to the network namespace of the first container.</p>
			<p>Podman has additional features that could help users to move their containers in Kubernetes environments. Using the command <strong class="source-inline">podman generate kube</strong>, Podman can create a Kubernetes YAML file for a running container that can be used to create a pod inside a Kubernetes cluster.</p>
			<p>Running containers as systemd services is equally easy with the <strong class="source-inline">podman generate systemd</strong> command, which takes a running container or pod and generates a systemd unit file that can be used to automatically run services at system startup. </p>
			<p>A notable example: the <strong class="bold">OpenStack</strong> project, an open source cloud computing infrastructure, adopted Podman <a id="_idIndexMarker247"/>as the default manager for its containerized <a id="_idIndexMarker248"/>services when deployed with TripleO. All the services are executed by Podman and orchestrated by systemd in the control plane and compute nodes.</p>
			<p>Having checked the surface of these container engines and having looked at their command lines, let’s recap the under-the-hood differences in the next section.</p>
			<h2 id="_idParaDest-66"><a id="_idTextAnchor065"/>Running a container</h2>
			<p>Running a container in a Docker environment, as we mentioned earlier, consists of using the Docker <a id="_idIndexMarker249"/>command-line client to communicate with the Docker daemon that will do the actions required to get the container up and running. Just to summarize the concepts we explained in this chapter, we can take a look the following diagram:</p>
			<div>
				<div id="_idContainer020" class="IMG---Figure">
					<img src="image/B17908_02_07.jpg" alt="Figure 2.7 – Docker simplified architecture&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.7 – Docker simplified architecture</p>
			<p>Podman, instead, interacts directly with the image registry, storage, and with the Linux kernel through the <a id="_idIndexMarker250"/>container runtime process (not a daemon), with Conmon as a monitoring process executed between Podman and the OCI runtime, as we can schematize in the following diagram:</p>
			<div>
				<div id="_idContainer021" class="IMG---Figure">
					<img src="image/B17908_02_08.jpg" alt="Figure 2.8 – Podman simplified architecture&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.8 – Podman simplified architecture</p>
			<p>The core difference between the two architectures is the daemon-centric Docker vision versus the fork/exec approach of Podman. </p>
			<p>This book does <a id="_idIndexMarker251"/>not get into the pros and cons of the Docker daemon architecture and features. Anyway, we safely can tell that a significant number of Docker users were concerned about this daemon-centric approach for many reasons, for example:</p>
			<ul>
				<li>The daemon could be a single point of failure.</li>
				<li>If for some reason a failure occurs, then there will be orphaned processes.</li>
				<li>The daemon owns all the running containers as child processes.</li>
			</ul>
			<p>Despite the architectural differences, and the aliasing solutions described before to easily migrate <a id="_idIndexMarker252"/>projects without changing any script, running a container from the command line with Docker or Podman is pretty much the same thing for the end user: </p>
			<p class="source-code">$ docker run –d -–rm docker.io/library/nginx</p>
			<p class="source-code">$ podman run –d -–rm docker.io/library/nginx</p>
			<p>For the same reason, most of the command-line arguments of CLI commands have been kept as close as possible to the original version in Docker.</p>
			<h1 id="_idParaDest-67"><a id="_idTextAnchor066"/>Summary</h1>
			<p>In this chapter, we have discussed the main differences between Podman and Docker, both from architectural and usage points of view. We described the main building blocks of the two container engines and highlighted the different community projects that fuel the Podman project, especially OCI specifications and the <strong class="source-inline">runC</strong> and <strong class="source-inline">crun</strong> runtimes.</p>
			<p>The purpose of this book is not to debate why and how Podman could be a better choice than Docker. We think that everybody who works with containers should be extremely grateful to the Docker company and community for the great work they did in bringing containers to the masses and freeing them from niche adoption. </p>
			<p>At the same time, the evolutionary approach of open source software facilitates the birth of new projects that try to compete to be adopted. Ever since it was born, the Podman project has grown exponentially and gained a wider user base day by day.</p>
			<p>Understanding the engine internals is still an important task, anyway. For troubleshooting, performance tuning, or even just curiosity, investing time in understanding how each component relates to each other, reading the code, and testing builds is a smart choice that will pay back someday.</p>
			<p>In the next chapters, we will uncover in detail the features and behavior of this great container engine.</p>
			<h1 id="_idParaDest-68"><a id="_idTextAnchor067"/>Further reading</h1>
			<p>For more information about the topics covered in this chapter, you can refer to the following:</p>
			<ul>
				<li><a href="https://developers.redhat.com/blog/2020/09/25/rootless-containers-with-podman-the-basics">https://developers.redhat.com/blog/2020/09/25/rootless-containers-with-podman-the-basics</a></li>
				<li><a href="https://developers.redhat.com/blog/2020/11/19/transitioning-from-docker-to-podman">https://developers.redhat.com/blog/2020/11/19/transitioning-from-docker-to-podman</a></li>
				<li><a href="https://github.com/opencontainers/runc/blob/master/docs/cgroup-v2.md">https://github.com/opencontainers/runc/blob/master/docs/cgroup-v2.md</a></li>
				<li><a href="https://www.redhat.com/sysadmin/introduction-crun">https://www.redhat.com/sysadmin/introduction-crun</a></li>
				<li><a href="https://ebpf.io/what-is-ebpf/">https://ebpf.io/what-is-ebpf/</a></li>
			</ul>
		</div>
	</body></html>