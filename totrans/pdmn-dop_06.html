<html><head></head><body>
		<div id="_idContainer025">
			<h1 id="_idParaDest-101"><em class="italic"><a id="_idTextAnchor101"/>Chapter 5</em>: Implementing Storage for the Container's Data</h1>
			<p>In the previous chapters, we explored how to run and manage our containers using Podman, but we will soon come to realize in this chapter that these operations aren't useful in certain scenarios where the applications included in our containers need to store data in a persistent mode. Containers are ephemeral by default, and this is one of their main features, as we described in the first chapter of this book, and for this reason, we need a way to attach persistent storage to a running container to preserve the container's important data.</p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Why does storage matter for containers?</li>
				<li>Containers' storage features</li>
				<li>Copying files into and out of a container</li>
				<li>Attaching host storage to a container</li>
			</ul>
			<h1 id="_idParaDest-102"><a id="_idTextAnchor102"/>Technical requirements</h1>
			<p>Before proceeding with the chapter's lecture and examples, a machine with a working Podman installation is required. As stated in <a href="B17908_03_epub.xhtml#_idTextAnchor068"><em class="italic">Chapter 3</em></a>, <em class="italic">Running the First Container</em>, all the examples in the book are executed on a Fedora 34 system or later but can be reproduced on the reader's OS of choice. </p>
			<p>Finally, a good understanding of the topics covered in <a href="B17908_04_epub.xhtml#_idTextAnchor083"><em class="italic">Chapter 4</em></a>, <em class="italic">Managing Running Containers</em>, is useful in terms of being able to easily grasp concepts regarding OCI images and container execution.</p>
			<h1 id="_idParaDest-103"><a id="_idTextAnchor103"/>Why does storage matter for containers? </h1>
			<p>Before moving<a id="_idIndexMarker451"/> forward in the chapter and answering this interesting question, we need to distinguish between two kinds of storage for containers:</p>
			<ul>
				<li>External storage <a id="_idIndexMarker452"/>attached to running containers to store data, making it persistent on a container's restart</li>
				<li>Underlying storage <a id="_idIndexMarker453"/>for root filesystems of our containers and container images</li>
			</ul>
			<p>Talking about external storage, as we described in <a href="B17908_01_epub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Container Technology</em>, containers are stateless, ephemeral, and often with a read-only filesystem. This is because the theory behind the technology states that containers should be used for spawning scalable and distributed applications that have to scale horizontally instead of vertically.</p>
			<p>Scaling an application horizontally means that in case we require additional resources for our running services, we will not increase CPU or RAM for a single running container, but we will instead launch a brand new container that will handle the incoming requests along with the existing container. This is the same well-known paradigm adopted in the public cloud. The container in principle should be ephemeral because any additional copy of the existing container image should be run at any time for empowering the existing running service.</p>
			<p>Of course, exceptions exist, and it could happen that a running container cannot be scaled horizontally or that it simply needs to share configurations, cache, or any other data relevant to other copies of the same container images at startup time or during runtime.</p>
			<p>Let's understand this with the help of a <a id="_idIndexMarker454"/>real-life example. Using a car-sharing service to get a new car for every destination inside a city can be a useful and smart way to move around without worrying about parking fees, fuel, and other things. However, at the same time, this service cannot allow you to store or leave your stuff inside of a parked car. Therefore, when using a car-sharing service, we can unpack our stuff once we get into a car, but we must pack it back before we leave that car. The same applies similarly to containers, where we must attach to them some storage for letting our container write data down but then, once our container stops, we should detach that storage so that a brand-new container can use it when needed.</p>
			<p>Here's another more<a id="_idIndexMarker455"/> technical example: let's consider a standard three-tier application with a web, a backend, and a database service. Every layer of this application may need storage, which it will use in a variety of ways. The web service may need a place to save a cache, store rendered web pages, some customized images at runtime, and so on. The backend service will need a place to store configuration and synchronization data between the other running backend services, if any, and so on. The database service will surely need a place to store the DB data.</p>
			<p>Storage is often associated with low-level infrastructure, but in a container, the storage becomes important even for developers, who should plan where to attach the storage, and the features needed for their application.</p>
			<p>If we extend the topic to container orchestration, then the storage inherits a strategic role because it should be as elastic and feasible as the Kubernetes orchestrator that we might use it with. The container storage in this case should become more like software-defined storage – able to provide storage resources in a self-service way to developers, and to containers in general.</p>
			<p>Although this book will talk about local storage, it's important to note that this is not enough for the Kubernetes orchestrator because containers should be portable from one host to another depending on the availability and scaling rules defined. This is where software-defined storage could be the solution!</p>
			<p>As we can deduct from the previous examples, external storage matters in containers. The usage may vary depending on the running application inside our container, but it is required. At the same time, another key role is driven by the underlying container storage that is responsible for handling the correct storage of containers and the container images' root filesystem. Choosing the right, stable, and performing underlying local storage will ensure better and correct management of our containers.</p>
			<p>So, let's first explore a bit of the theory of container storage and then discuss how to work with it.</p>
			<h1 id="_idParaDest-104"><a id="_idTextAnchor104"/>Containers' storage features </h1>
			<p>Before going into a<a id="_idIndexMarker456"/> real example and use cases, we should first dig into the main differences<a id="_idIndexMarker457"/> between container storage and a <strong class="bold">container storage interface</strong> (<strong class="bold">CSI</strong>). </p>
			<p>Container storage, previously referred to as <em class="italic">underlying container storage</em>, is responsible for handling container images <a id="_idIndexMarker458"/>on <strong class="bold">Copy-on-Write</strong> (<strong class="bold">COW</strong>) filesystems. Container images need to be transferred and move around until a container engine is instructed to run them, so we need a way to store that image until it is run. That's the role of container storage.</p>
			<p>Once we start using an orchestrator such as Kubernetes, CSI instead is responsible for providing container block or file storage that containers need to write data to.</p>
			<p>In the next section of this chapter, we will concentrate on container storage and its configuration. Later, we will talk about external storage for containers and the options we have in Podman to expose the host local storage to the running containers.</p>
			<p>A great innovation introduced with Podman is the <em class="italic">containers/storage</em> project (<a href="https://github.com/containers/storage">https://github.com/containers/storage</a>), a great way to share an underlying common method for accessing container storage on a host. With the arrival of Docker, we were forced to pass through the Docker daemon to interact with container storage. With no other way to directly interact with the underlying storage, the Docker daemon just hid it from the user as well as the system administrator.</p>
			<p>With the <em class="italic">containers/storage</em> project, we now have an easy way to use multiple tools for analyzing, managing, or working with container storage at the same time.</p>
			<p>The configuration of this low-level piece of software is so important for Podman as well as for other companion tools of Podman and can be inspected or edited through its configuration file available at <strong class="source-inline">/etc/containers/storage.conf</strong>.</p>
			<p>Looking at the configuration file, we can easily discover that we can change a lot of options in terms of how our containers interact with the underlying storage. Let's inspect the most important option – the storage driver.</p>
			<h2 id="_idParaDest-105"><a id="_idTextAnchor105"/>Storage driver</h2>
			<p>The configuration file, as one of its first options, gives the opportunity to choose the default <strong class="bold">Copy On Write</strong> (<strong class="bold">COW</strong>) container storage driver. The <a id="_idIndexMarker459"/>configuration file in the current version, at the time of writing this book, supports the following COW drivers:</p>
			<ul>
				<li>overlay</li>
				<li>vfs</li>
				<li>devmapper</li>
				<li>aufs</li>
				<li>btrfs</li>
				<li>zfs</li>
			</ul>
			<p>These are also often referred to as <strong class="bold">graph drivers</strong> because <a id="_idIndexMarker460"/>most of them organize the layers they handle in a graph structure.</p>
			<p>Using Podman on Fedora 34 or later, the container's storage configuration file is shipped with overlay as the default driver.</p>
			<p>Another important thing to mention is that, at the time of writing this book, there are two versions of the overlay filesystem – version 1 and version 2. </p>
			<p>The original overlay filesystem version 1 was initially used by the Docker container engine, but was later abandoned in favor of version 2. That's why Podman and the container's storage configuration file refers generically to the name overlay, but it instead uses the new version 2.</p>
			<p>Before going into detail regarding the other options and, finally, the practical examples contained in this chapter, let's further explore how one of these COW filesystem drivers works.</p>
			<p>The overlay union filesystem has been present in a Linux kernel since version 3.18. It is usually enabled by default and activated dynamically once a mount is initiated with this filesystem.</p>
			<p>The mechanism behind this filesystem is really simple but powerful – it allows a directory tree to be overlaid on another, storing only the differences, but showing the latest updated, <em class="italic">squashed</em> tree of directories.</p>
			<p>Usually, in the world of containers, we start using a read-only filesystem, adding one or more layers, read-only again, until a running container will use this bunch of <em class="italic">squashed</em> layers as its <a id="_idIndexMarker461"/>root filesystem. This is where the last read-write layer will be created as an overlay of the others.</p>
			<p>Let's see what <a id="_idIndexMarker462"/>happens under the hood once we pull down a brand-new container image with Podman:</p>
			<p class="callout-heading">Important Note </p>
			<p class="callout">If you wish to proceed with testing the following example on your test machine, ensure that you remove any running container and container images to easily match the image with the layers that Podman will download for us.</p>
			<p class="source-code"># podman pull quay.io/centos7/httpd-24-centos7:latest</p>
			<p class="source-code">Trying to pull quay.io/centos7/httpd-24-centos7:latest...</p>
			<p class="source-code">Getting image source signatures</p>
			<p class="source-code">Copying blob 5f2e13673ac2 done  </p>
			<p class="source-code">Copying blob 8dd5a5013b51 done  </p>
			<p class="source-code">Copying blob b2cc5146c9c7 done  </p>
			<p class="source-code">Copying blob e17e89f32035 done  </p>
			<p class="source-code">Copying blob 1b6c93aa6be5 done  </p>
			<p class="source-code">Copying blob 6855d3fe68bc done  </p>
			<p class="source-code">Copying blob f974a2323b6c done  </p>
			<p class="source-code">Copying blob d620f14a5a76 done  </p>
			<p class="source-code">Copying config 3b964f33a2 done  </p>
			<p class="source-code">Writing manifest to image destination</p>
			<p class="source-code">Storing signatures</p>
			<p class="source-code">3b964f33a2bf66108d5333a541d376f63e0506aba8ddd4813f9d4e104 271d9f0</p>
			<p>We can see from the previous command output that multiple layers have been downloaded. That's because the container image we pulled down is composed of many layers.</p>
			<p>Now we can <a id="_idIndexMarker463"/>start inspecting just the downloaded layers. First of all, we have to locate the right directory, which we can search for inside <a id="_idIndexMarker464"/>the configuration file. Alternatively, we can use an easier technique. Podman has a command dedicated to displaying its running configuration and other useful information – <strong class="source-inline">podman info</strong>. Let's see how it works:</p>
			<p class="source-code"># podman info | grep -A19 "store:"</p>
			<p class="source-code">store:</p>
			<p class="source-code">  configFile: /etc/containers/storage.conf</p>
			<p class="source-code">  containerStore:</p>
			<p class="source-code">    number: 0</p>
			<p class="source-code">    paused: 0</p>
			<p class="source-code">    running: 0</p>
			<p class="source-code">    stopped: 0</p>
			<p class="source-code">  graphDriverName: overlay</p>
			<p class="source-code">  graphOptions:</p>
			<p class="source-code">    overlay.mountopt: nodev,metacopy=on</p>
			<p class="source-code">  graphRoot: /var/lib/containers/storage</p>
			<p class="source-code">  graphStatus:</p>
			<p class="source-code">    Backing Filesystem: btrfs</p>
			<p class="source-code">    Native Overlay Diff: "false"</p>
			<p class="source-code">    Supports d_type: "true"</p>
			<p class="source-code">    Using metacopy: "true"</p>
			<p class="source-code">  imageStore:</p>
			<p class="source-code">    number: 1</p>
			<p class="source-code">  runRoot: /run/containers/storage</p>
			<p class="source-code">  volumePath: /var/lib/containers/storage/volumes</p>
			<p>To <a id="_idIndexMarker465"/>reduce the output of the <strong class="source-inline">podman info</strong> command, we used the <strong class="source-inline">grep</strong> command to only match the <strong class="source-inline">store</strong> section that contains the current configuration in place for container storage.</p>
			<p>As we can <a id="_idIndexMarker466"/>see, the driver used is <strong class="source-inline">overlay</strong>, and the root directory to search our layers is reported as the <strong class="source-inline">graphRoot</strong> directory: <strong class="source-inline">/var/lib/containers/storage</strong>; for rootless containers, the equivalent is <strong class="source-inline">$HOME/.local/share/containers/storage</strong>. We also have other paths reported, but we will talk about these later in this section. The keyword <strong class="source-inline">graph</strong> is a term derived from the category of drivers we just introduced earlier.</p>
			<p>Let's take a look into that directory to see what the actual content is:</p>
			<p class="source-code"># cd /var/lib/containers/storage</p>
			<p class="source-code"># ls</p>
			<p class="source-code">libpod  mounts  overlay  overlay-containers  overlay-images  overlay-layers  storage.lock  tmp  userns.lock</p>
			<p>We have several directories available for which the names are pretty self-explanatory. The ones we are looking for are as follows:</p>
			<ul>
				<li><strong class="source-inline">overlay-images</strong>: This contains the metadata of the container images downloaded.</li>
				<li><strong class="source-inline">overlay-layers</strong>: This contains the archives for all the layers of every container image.</li>
				<li><strong class="source-inline">overlay</strong>: This is the directory containing the unpacked layers of every container image.</li>
			</ul>
			<p>Let's check the content of the first directory, <strong class="source-inline">overlay-images</strong>:</p>
			<p class="source-code"># ls -l overlay-images/</p>
			<p class="source-code">total 8</p>
			<p class="source-code">drwx------. 1 root root  630 15 oct 18.36 3b964f33a2bf66108d5333a541d376f63e0506aba8ddd4813f9d4e10427 1d9f0</p>
			<p class="source-code">-rw-------. 1 root root 1613 15 oct 18.36 images.json</p>
			<p class="source-code">-rw-r--r--. 1 root root   64 15 oct 18.36 images.lock</p>
			<p>As we can imagine, in this directory, we can find the metadata of the only container image we pulled down and, in the directory with a very long ID, we will find the manifest file <a id="_idIndexMarker467"/>describing the layers that make up our container image.</p>
			<p>Let's now check <a id="_idIndexMarker468"/>the content of the second directory, <strong class="source-inline">overlay-layers</strong>:</p>
			<p class="source-code"># ls -l overlay-layers/</p>
			<p class="source-code">total 1168</p>
			<p class="source-code">-rw-------. 1 root root   2109 15 oct 18.35 0099baae6cd3ca0ced38d658d7871548b32bd0e42118b788d818b76131ec 8e75.tar-split.gz</p>
			<p class="source-code">-rw-------. 1 root root 795206 15 oct 18.35 53498d66ad83a29fcd7c7bcf4abbcc0def4fc912772aa8a4483b51e232309 aee.tar-split.gz</p>
			<p class="source-code">-rw-------. 1 root root  52706 15 oct 18.35 6c26feaaa75c7bac1f1247acc06e73b46e8aaf2e741ad1b8bacd6774bffdf6 ba.tar-split.gz</p>
			<p class="source-code">-rw-------. 1 root root   1185 15 oct 18.35 74fa1495774e94d5cdb579f9bae4a16bd90616024a6f4b1ffd13344c367df1 f6.tar-split.gz</p>
			<p class="source-code">-rw-------. 1 root root 308144 15 oct 18.36 ae314017e4c2de17a7fb007294521bbe8ac1eeb004ac9fb57d1f1f03090f78 c9.tar-split.gz</p>
			<p class="source-code">-rw-------. 1 root root   1778 15 oct 18.36 beba3570ce7dd1ea38e8a1b919a377b6dc888b24833409eead446bff401d8f 6e.tar-split.gz</p>
			<p class="source-code">-rw-------. 1 root root    697 15 oct 18.36 e59e7d1e1874cc643bfe6f854a72a39f73f22743ab38eff78f91dc019cca91 f5.tar-split.gz</p>
			<p class="source-code">-rw-------. 1 root root   5555 15 oct 18.36 e5a13564f9c6e233da30a7fd86489234716cf80c317e52ff8261bf0cb34dc 7b4.tar-split.gz</p>
			<p class="source-code">-rw-------. 1 root root   3716 15 oct 18.36 layers.json</p>
			<p class="source-code">-rw-r--r--. 1 root root     64 15 oct 19.06 layers.lock</p>
			<p>As we can see, we<a id="_idIndexMarker469"/> just found all the layers' archives downloaded for our container image, but <a id="_idIndexMarker470"/>where they have been unpacked? The answer is easy – in the third folder, <strong class="source-inline">overlay</strong>:</p>
			<p class="source-code"># ls -l overlay</p>
			<p class="source-code">total 0</p>
			<p class="source-code">drwx------. 1 root root  46 15 oct 18.35 0099baae6cd3ca0ced38d658d7871548b32bd0e42118b788d818b76131ec 8e75</p>
			<p class="source-code">drwx------. 1 root root  46 15 oct 18.35 53498d66ad83a29fcd7c7bcf4abbcc0def4fc912772aa8a4483b51e23230 9aee</p>
			<p class="source-code">drwx------. 1 root root  46 15 oct 18.35 6c26feaaa75c7bac1f1247acc06e73b46e8aaf2e741ad1b8bacd6774bffd f6ba</p>
			<p class="source-code">drwx------. 1 root root  46 15 oct 18.35 74fa1495774e94d5cdb579f9bae4a16bd90616024a6f4b1ffd13344c367d f1f6</p>
			<p class="source-code">drwx------. 1 root root  46 15 oct 18.35 ae314017e4c2de17a7fb007294521bbe8ac1eeb004ac9fb57d1f1f03090f 78c9</p>
			<p class="source-code">drwx------. 1 root root  46 15 oct 18.36 beba3570ce7dd1ea38e8a1b919a377b6dc888b24833409eead446bff401d 8f6e</p>
			<p class="source-code">drwx------. 1 root root  46 15 oct 18.36 e59e7d1e1874cc643bfe6f854a72a39f73f22743ab38eff78f91dc019cca 91f5</p>
			<p class="source-code">drwx------. 1 root root  46 15 oct 18.36 e5a13564f9c6e233da30a7fd86489234716cf80c317e52ff8261bf0cb34d c7b4</p>
			<p class="source-code">drwx------. 1 root root 416 15 oct 18.36 l</p>
			<p>The first <a id="_idIndexMarker471"/>question that could arise when looking at the latest directory content is, what's the purpose of the <strong class="source-inline">l</strong> (L in lowercase) directory?</p>
			<p>To answer<a id="_idIndexMarker472"/> this question, we have to inspect the content of a layer directory. We can start with the first one on the list:</p>
			<p class="source-code"># ls -la overlay/0099baae6cd3ca0ced38d658d7871548b32bd0e42118b788d818b 76131ec8e75/</p>
			<p class="source-code">total 8</p>
			<p class="source-code">drwx------. 1 root root   46 15 oct 18.35 .</p>
			<p class="source-code">drwx------. 1 root root 1026 15 oct 18.36 ..</p>
			<p class="source-code">dr-xr-xr-x. 1 root root   24 15 oct 18.35 diff</p>
			<p class="source-code">-rw-r--r--. 1 root root   26 15 oct 18.35 link</p>
			<p class="source-code">-rw-r--r--. 1 root root   86 15 oct 18.35 lower</p>
			<p class="source-code">drwx------. 1 root root    0 15 oct 18.35 merged</p>
			<p class="source-code">drwx------. 1 root root    0 15 oct 18.35 work</p>
			<p>Let's understand the purpose of these files and directories:</p>
			<ul>
				<li><strong class="source-inline">diff</strong>: This directory represents the upper layer of the overlay, and is used to store any changes to the layer.</li>
				<li><strong class="source-inline">lower</strong>: This file reports all the lower layer mounts, ordered from uppermost to lowermost.</li>
				<li><strong class="source-inline">merged</strong>: This directory is the one that the overlay is mounted on.</li>
				<li><strong class="source-inline">work</strong>: This directory is used for internal operations.</li>
				<li><strong class="source-inline">link</strong>: This file contains a unique string for the layer.</li>
			</ul>
			<p>Now, coming <a id="_idIndexMarker473"/>back to our question, what's the purpose of the <strong class="source-inline">l</strong> (L in lowercase) directory?</p>
			<p>Under the <strong class="source-inline">l</strong> directory, there are symbolic links with unique strings pointing to the <strong class="source-inline">diff</strong> directory<a id="_idIndexMarker474"/> for every layer. The symbolic links reference lower layers in the <strong class="source-inline">lower</strong> file. Let's check it:</p>
			<p class="source-code"># ls -la overlay/l/</p>
			<p class="source-code">total 32</p>
			<p class="source-code">drwx------. 1 root root  416 15 oct 18.36 .</p>
			<p class="source-code">drwx------. 1 root root 1026 15 oct 18.36 ..</p>
			<p class="source-code">lrwxrwxrwx. 1 root root   72 15 oct 18.35 A4ZYMM4AK5NM6JYJA7 EK2DLTGA -&gt; ../74fa1495774e94d5cdb579f9bae4a16bd90616024a6f4 b1ffd13344c367df1f6/diff</p>
			<p class="source-code">lrwxrwxrwx. 1 root root   72 15 oct 18.35 D2WVDYIWL6I77ZOIXR VQKCXNG2 -&gt; ../ae314017e4c2de17a7fb007294521bbe8ac1eeb004ac9fb57d1f1f03090 f78c9/diff</p>
			<p class="source-code">lrwxrwxrwx. 1 root root   72 15 oct 18.36 G4KXMAOCE56TIB252 ZMWEFRFHU -&gt; ../beba3570ce7dd1ea38e8a1b919a377b6dc888b24833409eead446bff401 d8f6e/diff</p>
			<p class="source-code">lrwxrwxrwx. 1 root root   72 15 oct 18.35 JHHF5QA7YSKDSKRSC HNADBVKDS -&gt; ../53498d66ad83a29fcd7c7bcf4abbcc0def4fc912772aa8a4483b51e2 32309aee/diff</p>
			<p class="source-code">lrwxrwxrwx. 1 root root   72 15 oct 18.36 KNCK5EDUAQJDAIDWQ6 TWDFQF5B -&gt; ../e59e7d1e1874cc643bfe6f854a72a39f73f22743ab38eff78f91dc019cca 91f5/diff</p>
			<p class="source-code">lrwxrwxrwx. 1 root root   72 15 oct 18.35 LQUM7XDVWHIJRLIWAL CFKSMJTT -&gt; ../0099baae6cd3ca0ced38d658d7871548b32bd0e42118b788d818b76131 ec8e75/diff</p>
			<p class="source-code">lrwxrwxrwx. 1 root root   72 15 oct 18.35 V6OV3TLBBLTATIJDCTU 6N72XQ5 -&gt; ../6c26feaaa75c7bac1f1247acc06e73b46e8aaf2e741ad1b8bacd6774bf fdf6ba/diff</p>
			<p class="source-code">lrwxrwxrwx. 1 root root   72 15 oct 18.36 ZMKJYKM2VJEAYQHCI7SU Q2R3QW -&gt; ../e5a13564f9c6e233da30a7fd86489234716cf80c317e52ff8261bf0cb34dc7 b4/diff</p>
			<p>To double-check what <a id="_idIndexMarker475"/>we just learned, let's find the first layer of our container image and check <a id="_idIndexMarker476"/>whether there is a lower file for it.</p>
			<p>Let's inspect the manifest file for our container image:</p>
			<p class="source-code"># cat overlay-images/3b964f33a2bf66108d5333a541d376f63e0506ab a8ddd4813f9d4e104271d9f0/manifest | head -15</p>
			<p class="source-code">{</p>
			<p class="source-code">   "schemaVersion": 2,</p>
			<p class="source-code">   "mediaType": "application/vnd.docker.distribution.manifest.v2+json",</p>
			<p class="source-code">   "config": {</p>
			<p class="source-code">      "mediaType": "application/vnd.docker.container.image.v1 +json",</p>
			<p class="source-code">      "size": 16212,</p>
			<p class="source-code">      "digest": "sha256:3b964f33a2bf66108d5333a541d376f63e0506aba8ddd4813f9d4 e104271d9f0"</p>
			<p class="source-code">   },</p>
			<p class="source-code">   "layers": [</p>
			<p class="source-code">      {</p>
			<p class="source-code">         "mediaType": "application/vnd.docker.image.rootfs.diff.tar.gzip",</p>
			<p class="source-code">         "size": 75867345,</p>
			<p class="source-code">         "digest": "sha256:b2cc5146c9c7855cb298ca8b77ecb153d37e3e5c69916ef42361 3a46a70c0503"</p>
			<p class="source-code">      },</p>
			<p>Then, we <a id="_idIndexMarker477"/>must compare the checksum of the compressed archive <a id="_idIndexMarker478"/>with the list of all the layers we downloaded:</p>
			<p class="callout-heading">Good to Know </p>
			<p class="callout">SHA-256 is an algorithm used to produce a unique cryptographic hash that can be used to verify the integrity of a file (checksum).</p>
			<p class="source-code"># cat overlay-layers/layers.json | jq | grep -B3 -A10 "sha256:b2cc5"</p>
			<p class="source-code">  {</p>
			<p class="source-code">    "id": "53498d66ad83a29fcd7c7bcf4abbcc0def4fc912772aa8a4483b51e23 2309aee",</p>
			<p class="source-code">    "created": "2021-10-15T16:35:49.782784856Z",</p>
			<p class="source-code">    "compressed-diff-digest": "sha256:b2cc5146c9c7855cb298ca8b77ecb153d37e3e5c69916ef423 613a46a70c0503",</p>
			<p class="source-code">    "compressed-size": 75867345,</p>
			<p class="source-code">    "diff-digest": "sha256:53498d66ad83a29fcd7c7bcf4abbcc0def4fc912772aa8a448 3b51e232309aee",</p>
			<p class="source-code">    "diff-size": 211829760,</p>
			<p class="source-code">    "compression": 2,</p>
			<p class="source-code">    "uidset": [</p>
			<p class="source-code">      0,</p>
			<p class="source-code">      192</p>
			<p class="source-code">    ],</p>
			<p class="source-code">    "gidset": [</p>
			<p class="source-code">      0,</p>
			<p>The file <a id="_idIndexMarker479"/>we just analyzed, <strong class="source-inline">overlay-layers/layers.json</strong>, was not indented. For this reason, we used the <strong class="source-inline">jq</strong> utility to format it and <a id="_idIndexMarker480"/>make it human-readable.</p>
			<p class="callout-heading">Good to Know</p>
			<p class="callout">If you cannot find the <strong class="source-inline">jq</strong> utility on your system, you can install it through the operating system default package manager. On Fedora, for example, you can run <strong class="source-inline">dnf install jq</strong>.</p>
			<p>As you can see, we just found the ID of our root layer. Now, let's look at its content:</p>
			<p class="source-code"># ls -l overlay/53498d66ad83a29fcd7c7bcf4abbcc0def4fc912772aa8a448 3b51e232309aee/</p>
			<p class="source-code">total 4</p>
			<p class="source-code">dr-xr-xr-x. 1 root root 158 15 oct 18.35 diff</p>
			<p class="source-code">drwx------. 1 root root   0 15 oct 18.35 empty</p>
			<p class="source-code">-rw-r--r--. 1 root root  26 15 oct 18.35 link</p>
			<p class="source-code">drwx------. 1 root root   0 15 oct 18.35 merged</p>
			<p class="source-code">drwx------. 1 root root   0 15 oct 18.35 work</p>
			<p>As we can verify, there is not a <strong class="source-inline">lower</strong> file inside the layer's directory because this is the first layer of <a id="_idIndexMarker481"/>our container image! </p>
			<p>The <a id="_idIndexMarker482"/>difference we might notice is the presence of a directory named <strong class="source-inline">empty</strong>. This is because if a layer has no parent, then the overlay system will create a dummy lower directory named <strong class="source-inline">empty</strong> and it will skip writing a <strong class="source-inline">lower</strong> file.</p>
			<p>Finally, as the last stage of our practical example, let's run our container and verify that a new <strong class="source-inline">diff</strong> layer will be created. We expect that this layer will contain only the difference between the lower ones.</p>
			<p>First, we run our container image we just analyzed:</p>
			<p class="source-code"># podman run -d quay.io/centos7/httpd-24-centos7</p>
			<p class="source-code">bd0eef7cd50760dd52c24550be51535bc11559e52eea7d782a1fa69 76524fa76</p>
			<p>As you can see, we started it in the background through the <strong class="source-inline">-d</strong> option to continue working on the system host. After this, we will execute a new shell on the pod to actually check the container's root folder and create a new file on it:</p>
			<p class="source-code"># podman exec -ti bd0eef7cd50760dd52c24550be51535bc11559e52eea7d782a1fa69 76524fa76 /bin/bash</p>
			<p class="source-code">bash-4.2$ pwd</p>
			<p class="source-code">/opt/app-root/src</p>
			<p class="source-code">bash-4.2$ echo "this is my NOT persistent data" &gt; tempfile.txt</p>
			<p class="source-code">bash-4.2$ ls</p>
			<p class="source-code">tempfile.txt</p>
			<p>This new file we just created will be temporary and will only last for the lifetime of the container. It is now time to find the <strong class="source-inline">diff</strong> layer that was just created by the overlay driver on our host system. The easiest way is to analyze the mount points used in the running container:</p>
			<p class="source-code">bash-4.2$ mount | head</p>
			<p class="source-code">overlay on / type overlay (rw,relatime,context="system_u:object_r:container_file_t:s0:c300,c861",lowerdir=/var/lib/containers/storage/overlay/l/ZMKJYKM2VJEAYQHCI7SUQ2R3QW:/var/lib/containers/storage/overlay/l/G4KXMAOCE56TIB252ZMWEFRFHU:/var/lib/containers/storage/overlay/l/KNCK5EDUAQJDAIDWQ6TWDF QF5B:/var/lib/containers/storage/overlay/l/D2WVDYIWL6I77ZOIX RVQKCXNG2:/var/lib/containers/storage/overlay/l/LQUM7XDVWHI JRLIWALCFKSMJTT:/var/lib/containers/storage/overlay/l/A4ZYMM4AK5NM6JYJA7EK2DLTGA:/var/lib/containers/storage/overlay/l/V6OV3TLBBLTATIJDCTU6N72XQ5:/var/lib/containers/storage/overlay/l/JHHF5QA7YSKDSKRSCHNADBVKDS,upperdir=/var/lib/containers/storage/overlay/b71e4bea5380ca233bf6b0c7a1c276179b841e263ee293e987c6cc54 af516f23/diff,workdir=/var/lib/containers/storage/overlay/b71e4bea5380ca233bf6b0c7a1c276179b841e263ee293e987c6cc54af 516f23/work,metacopy=on)</p>
			<p class="source-code">proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)</p>
			<p class="source-code">tmpfs on /dev type tmpfs (rw,nosuid,context="system_u:object _r:container_file_t:s0:c300,c861",size=65536k,mode=755,inode64)</p>
			<p>As you can <a id="_idIndexMarker483"/>see, the first mount point of the list shows a very <a id="_idIndexMarker484"/>long line full of layer paths divided by colons. In this long line, we can find the <strong class="source-inline">upperdir</strong> directory we are searching for:</p>
			<p class="source-code">upperdir=/var/lib/containers/storage/overlay/b71e4bea5380ca233bf6b0c7a1c276179b841e263ee293e987c6cc54af5 16f23/diff</p>
			<p>Now, we can inspect the content of this directory and navigate to the various paths available to find the container root directory where we wrote that file in the previous commands:</p>
			<p class="source-code"># ls -la /var/lib/containers/storage/overlay/b71e4bea5380ca233bf6b0c7a1c276179b841e263ee293e987c6cc54af5 16f23/diff/opt/app-root/src/</p>
			<p class="source-code">total 12</p>
			<p class="source-code">drwxr-xr-x. 1 1001 root   58 16 oct 00.40 .</p>
			<p class="source-code">drwxr-xr-x. 1 1001 root   12 22 set 10.39 ..</p>
			<p class="source-code">-rw-------. 1 1001 root   81 16 oct 00.46 .bash_history</p>
			<p class="source-code">-rw-------. 1 1001 root 1024 16 oct 00.38 .rnd</p>
			<p class="source-code">-rw-r--r--. 1 1001 root   31 16 oct 00.39 tempfile.txt</p>
			<p class="source-code"># cat /var/lib/containers/storage/overlay/b71e4bea5380ca233bf6b0c7a1c276179b841e263ee293e987c6cc54af5 16f23/diff/opt/app-root/src/tempfile.txt </p>
			<p class="source-code">this is my NOT persistent data</p>
			<p>As we <a id="_idIndexMarker485"/>verified, the data is stored on the host operating system, but<a id="_idIndexMarker486"/> it is stored in a temporary layer that will sooner or later be removed once the container is removed!</p>
			<p>Now, coming back to the original topic that sent us on this small trip under the hood of the overlay storage driver, we were talking about <strong class="source-inline">/etc/containers/storage.conf</strong>. This file holds all the configurations for the <em class="italic">containers/storage</em> project that is responsible for sharing an underlying common method to access container storage on a host.</p>
			<p>The other options available in this file are related to the customization of the storage driver as well as changing the default path for the internal storage directories.</p>
			<p>The last point we should briefly talk about is the <strong class="source-inline">runroot</strong> directory. In this folder, the container storage program will store all temporary writable content produced by the container.</p>
			<p>If we inspect the folder on our running host where we started the container for the previous example, we will find that there is a folder named with its ID with various files that have been mounted on the container to replace the original files:</p>
			<p class="source-code"># ls -l /run/containers/storage/overlay-containers/bd0eef7cd50760dd52c24550be51535bc11559e52eea7d782a1fa69765 24fa76/userdata</p>
			<p class="source-code">total 20</p>
			<p class="source-code">-rw-r--r--. 1 root root   6 16 oct 00.38 conmon.pid</p>
			<p class="source-code">-rw-r--r--. 1 root root  12 16 oct 00.38 hostname</p>
			<p class="source-code">-rw-r--r--. 1 root root 230 16 oct 00.38 hosts</p>
			<p class="source-code">-rw-r--r--. 1 root root   0 16 oct 00.38 oci-log</p>
			<p class="source-code">-rwx------. 1 root root   6 16 oct 00.38 pidfile</p>
			<p class="source-code">-rw-r--r--. 1 root root  34 16 oct 00.38 resolv.conf</p>
			<p class="source-code">drwxr-xr-x. 3 root root  60 16 oct 00.38 run</p>
			<p>As you<a id="_idIndexMarker487"/> can see from the preceding output, the container's folder under the <strong class="source-inline">runroot</strong> path contains various files that have been mounted directly onto the container to customize it.</p>
			<p>To wrap up, in <a id="_idIndexMarker488"/>the previous examples, we analyzed the anatomy of a container image and what happens once we run a new container from that image. The technology behind the scenes is amazing and we saw that a lot of features are related to the isolation capabilities offered by the operating system. Here, storage offers other important functionalities that have made containers the greatest technology that we all now know about.</p>
			<h1 id="_idParaDest-106"><a id="_idTextAnchor106"/>Copying files in and out of a container</h1>
			<p>Podman <a id="_idIndexMarker489"/>enables users to move files into and out of a running container. This result is achieved using the <strong class="source-inline">podman cp</strong> command, which can move files and folders to and from a container. Its usage is quite simple and will be illustrated in the next example.</p>
			<p>First, let's start a new Alpine container:</p>
			<p class="source-code">$ podman run -d --name alpine_cp_test alpine sleep 1000</p>
			<p>Now, let's grab a file from the container – we have chosen the <strong class="source-inline">/etc/os-release</strong> file, which provides some information about the distribution and its version ID:</p>
			<p class="source-code">$ podman cp alpine_cp_test:/etc/os-release /tmp</p>
			<p>The file <a id="_idIndexMarker490"/>has been copied to the host <strong class="source-inline">/tmp</strong> folder and can be inspected:</p>
			<p class="source-code">$ cat /tmp/os-release</p>
			<p class="source-code">NAME="Alpine Linux"</p>
			<p class="source-code">ID=alpine</p>
			<p class="source-code">VERSION_ID=3.14.2</p>
			<p class="source-code">PRETTY_NAME="Alpine Linux v3.14"</p>
			<p class="source-code">HOME_URL=<a href="https://alpinelinux.org/">https://alpinelinux.org/</a></p>
			<p class="source-code">BUG_REPORT_URL="https://bugs.alpinelinux.org/"</p>
			<p>In the opposite direction, we can copy files or folders from the host to the running container:</p>
			<p class="source-code">$ podman cp /tmp/build_folder alpine_cp_test:/</p>
			<p>This example copies the <strong class="source-inline">/tmp/build_folder</strong> folder, and all its content, under the root filesystem of the Alpine container. We can then inspect the result of the copy command by using <strong class="source-inline">podman exec</strong> with the <strong class="source-inline">ls</strong> utility command.</p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor107"/>Interacting with overlayfs</h2>
			<p>There<a id="_idIndexMarker491"/> is another way to copy files from a container to the host, which is by using the <strong class="source-inline">podman mount</strong> command and interacting directly with the merged overlays. </p>
			<p>To mount a running rootless container's filesystem, we first need to run the <strong class="source-inline">podman unshare</strong> command, which permits users to run commands inside a modified user namespace:</p>
			<p class="source-code">$ podman unshare</p>
			<p>This command drops a root shell in a new user namespace configured with <em class="italic">UID 0</em> and <em class="italic">GID 0</em>. It is now possible to run the <strong class="source-inline">podman mount</strong> command and obtain the absolute path of the mount point: </p>
			<p class="source-code"># cd $(podman mount alpine_cp_test)</p>
			<p>The<a id="_idIndexMarker492"/> preceding command uses shell expansion to change to the path of the <strong class="source-inline">MergedDir</strong>, which, as the name says, merges the <strong class="source-inline">LowerDir</strong> and <strong class="source-inline">UpperDir</strong> contents to provide a unified view of the different layers. From now on, it is possible to copy files to and from the container root filesystem.</p>
			<p>The previous examples were based on rootless containers, but the same logic applies to rootful containers. Let's start a rootful Nginx container:</p>
			<p class="source-code">$ sudo podman run -d \</p>
			<p class="source-code">  --name rootful_nginx docker.io/library/nginx </p>
			<p>To copy files in and out, we need to prepend the <strong class="source-inline">sudo</strong> command:</p>
			<p class="source-code">$ sudo podman cp \</p>
			<p class="source-code">  rootful_nginx:/usr/share/nginx/html/index.html /tmp</p>
			<p>The preceding command copies the default <strong class="source-inline">index.html</strong> page to the host <strong class="source-inline">/tmp</strong> directory. Keep in mind that <strong class="source-inline">sudo</strong> elevates the user privileges to root, and therefore copied files will have <em class="italic">UID 0</em> and <em class="italic">GID 0</em> ownership.</p>
			<p>The practice of copying files and folders from a container is especially useful for troubleshooting purposes. The opposite action of copying them inside a running container can be useful for updating and testing secrets or configuration files. In that case, we have the option of persisting those changes, as described in the next subsection.</p>
			<h3>Persisting changes with podman commit</h3>
			<p>The <a id="_idIndexMarker493"/>previous examples are not a method <a id="_idIndexMarker494"/>for permanently customizing running containers, since the immutable nature of containers implies that persistent modifications should go through an image rebuild. </p>
			<p>However, if we need to preserve the changes and produce a new image without starting a new build, the <strong class="source-inline">podman commit</strong> command provides a way to persist the changes to a container into a new image.</p>
			<p>The <a id="_idIndexMarker495"/>commit concept is of primary importance in Docker and OCI image builds. In fact, we can see the different steps of a Dockerfile as a series of commits applied during the build process.</p>
			<p>The following <a id="_idIndexMarker496"/>example shows how to persist a file copied into a running container and produce a new image. Let's say we want to update the default <strong class="source-inline">index.html</strong> page of our Nginx container:</p>
			<p class="source-code">$ echo "Hello World!" &gt; /tmp/index.html</p>
			<p class="source-code">$ podman run --name custom_nginx -d -p \  </p>
			<p class="source-code">  8080:80 docker.io/library/nginx </p>
			<p class="source-code">$ podman cp /tmp/index.html \</p>
			<p class="source-code">  custom_nginx:/usr/share/nginx/html/</p>
			<p>Let's test the changes applied:</p>
			<p class="source-code">$ curl localhost:8080</p>
			<p class="source-code">Hello World!</p>
			<p>Now we want to persist the changed <strong class="source-inline">index.html</strong> file into a new image, starting from the running container with <strong class="source-inline">podman commit</strong>: </p>
			<p class="source-code">$ podman commit -p custom_nginx hello-world-nginx</p>
			<p>The preceding command persists the changes by effectively creating a new image layer containing the updated files and folders.</p>
			<p>The previous container can now be safely stopped and removed before testing the new custom image:</p>
			<p class="source-code">$ podman stop custom_nginx &amp;&amp; podman rm custom_nginx</p>
			<p>Let's test the new custom image and inspect the changed <strong class="source-inline">index.html</strong> file:</p>
			<p class="source-code">$ podman run -d -p 8080:80 --name hello_world \</p>
			<p class="source-code">  localhost/hello-world-nginx</p>
			<p class="source-code">$ curl localhost:8080</p>
			<p class="source-code">Hello World!</p>
			<p>In this section, we have learned how to copy files to and from a running container and how to commit the changes on the fly by producing a new image.</p>
			<p>In the next section, we are going to learn how host storage is attached to a container by introducing the concept of <strong class="bold">volumes</strong> and <strong class="bold">bind mounts</strong>.</p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor108"/>Attaching host storage to a container</h1>
			<p>We have <a id="_idIndexMarker497"/>already talked about the immutable nature of containers. Starting from pre-built images, when we run a container, we instance a read/write layer on top of a stack of read-only layers using a copy-on-write approach.</p>
			<p>Containers are<a id="_idIndexMarker498"/> ephemeral objects based on a stateful image. This implies that containers are not meant to store data inside them – if a container crashes or is removed, all the data would be lost. We need a way to store data in a separate location that is mounted inside the running container, preserved when the container is removed, and ready to be reused by a new container.</p>
			<p>There is another important caveat that should not be forgotten – <strong class="bold">secrets</strong> and <strong class="bold">config files</strong>. When we build an image, we can pass all the files and folders we need inside it. However, sealing secrets like certificates or keys inside a build is not a good practice. If we need, for example, to rotate a certificate, we must rebuild the whole image from scratch. In the same way, changing a config file that resides inside an image implies a new rebuild every time we change a setting.</p>
			<p>For these reasons, OCI specifications support <strong class="bold">volumes</strong> and <strong class="bold">bind mounts</strong> to manage storage attached to a container. In the next sections, we will learn how volumes and bind mounts work and how to attach them to a container.</p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor109"/>Managing and attaching bind mounts to a container</h2>
			<p>Let's start <a id="_idIndexMarker499"/>with <a id="_idIndexMarker500"/>bind mounts <a id="_idIndexMarker501"/>since they leverage a <a id="_idIndexMarker502"/>native Linux feature. According to the official Linux man pages, a bind mount is <em class="italic">a way to remount a part of the filesystem hierarchy somewhere else</em>. This means that using bind mounts, we can replicate the view of a directory under another mount point in the host.</p>
			<p>Before<a id="_idIndexMarker503"/> learning how containers use bind mounts, let's see a basic example where we simply bind mount the <strong class="source-inline">/etc</strong> directory under the <strong class="source-inline">/mnt</strong> directory:</p>
			<p class="source-code">$ sudo mount --bind /etc /mnt  </p>
			<p>After<a id="_idIndexMarker504"/> issuing this command, we will see the exact contents of <strong class="source-inline">/etc</strong> under <strong class="source-inline">/mnt</strong>. To unmount, simply run the following command:</p>
			<p class="source-code">$ sudo umount /mnt</p>
			<p>The same <a id="_idIndexMarker505"/>concept can be applied to containers – Podman can bind mount host directories inside a container and offers dedicated CLI options to simplify the mount process.</p>
			<p>Podman offers two options that can be used to bind mount: <strong class="source-inline">-v|--volume</strong> and <strong class="source-inline">–mount</strong>. Let's cover these in more detail.</p>
			<h3>-v|--volume option</h3>
			<p>This <a id="_idIndexMarker506"/>option uses a compact, single field argument to define the source host directory and the container mount point with the pattern <strong class="source-inline">/HOST_DIR:/CONTAINER_DIR</strong>. The following example mounts the <strong class="source-inline">/host_files</strong> directory on the <strong class="source-inline">/mnt</strong> mount point inside the container: </p>
			<p class="source-code">$ podman run -v /host_files:/mnt docker.io/library/nginx</p>
			<p>It is possible to pass extra arguments to define mount behavior; for example, to mount the host directory as read-only:</p>
			<p class="source-code">$ podman run –v /host_files:/mnt:ro \</p>
			<p class="source-code">   docker.io/library/nginx</p>
			<p>Other viable options for bind mounts using the <strong class="source-inline">-v|--volume</strong> option can be found in the run command man page (<strong class="source-inline">man podman-run</strong>).</p>
			<h3>--mount option</h3>
			<p>This <a id="_idIndexMarker507"/>option is more verbose since it uses a <em class="italic">key=value</em> syntax to define source and destinations as well as the mount type and extra arguments. This option accepts different mount types (bind mounts, volumes, tmpfs, images, and devpts) in the <strong class="source-inline">type=TYPE,source=HOST_DIR,destination=CONTAINER_DIR</strong> pattern. The source and destination keys can be replaced with the shorter <strong class="source-inline">src</strong> and <strong class="source-inline">dst</strong>, respectively. The previous example can be rewritten as follows:</p>
			<p class="source-code">$ podman run \</p>
			<p class="source-code">  --mount type=bind,src=/host_files,dst=/mnt \</p>
			<p class="source-code">  docker.io/library/nginx</p>
			<p>We can also pass an extra option by adding an extra comma; for example, to mount the host directory as read-only:</p>
			<p class="source-code">$ podman run \</p>
			<p class="source-code">  --mount type=bind,src=/host_files,dst=/mnt,ro=true \</p>
			<p class="source-code">  docker.io/library/nginx</p>
			<p>Despite being very simple to use and understand, bind mounts have some limitations that could impact the life cycle of the container in some cases. Host files and directories must exist before running the containers and permissions must be set accordingly to make them readable or writable. Another important caveat to keep in mind is that a bind mount always obfuscates the underlying mount point in the container if populated by files or directories. A useful alternative to bind mounts is <strong class="bold">volumes</strong>, described in the next subsection.</p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor110"/>Managing and attaching volumes to a container</h2>
			<p>A volume is<a id="_idIndexMarker508"/> a directory created and managed directly<a id="_idIndexMarker509"/> by the container engine and mounted to a mount point inside the container. They offer a great <a id="_idIndexMarker510"/>solution for persisting data generated by a container. </p>
			<p>Volumes can <a id="_idIndexMarker511"/>be managed using the <strong class="source-inline">podman volume</strong> command, which can be used to list, inspect, create, and remove volumes in the system. Let's start with a basic example, with a volume automatically created by Podman on top of the Nginx document root:</p>
			<p class="source-code">$ podman run -d -p 8080:80  --name nginx_volume1 -v /usr/share/nginx/html docker.io/library/nginx</p>
			<p>This <a id="_idIndexMarker512"/>time, the <strong class="source-inline">–v</strong> option has an argument with only one item – the document root directory. In this case, Podman automatically creates a volume and bind mounts<a id="_idIndexMarker513"/> it to the target mount point. </p>
			<p>To <a id="_idIndexMarker514"/>prove that a new volume has been created, we <a id="_idIndexMarker515"/>can inspect the container:</p>
			<p class="source-code">$ podman inspect nginx_volume1</p>
			<p class="source-code">[...omitted output...]</p>
			<p class="source-code">"Mounts": [</p>
			<p class="source-code">          {</p>
			<p class="source-code">                "Type": "volume",</p>
			<p class="source-code">                "Name": "2ed93716b7ad73706df5c6f56bda262920accec59e7b6642d36f938e936 d36d9",</p>
			<p class="source-code">                "Source": "/home/packt/.local/share/containers /storage/volumes/2ed93716b7ad73706df5c6f56bda262920accec59e7b6 642d36f93 8e936d36d9/_data",</p>
			<p class="source-code">                "Destination": "/usr/share/nginx/html",</p>
			<p class="source-code">                "Driver": "local",</p>
			<p class="source-code">                "Mode": "",</p>
			<p class="source-code">                "Options": [</p>
			<p class="source-code">                    "nosuid",</p>
			<p class="source-code">                    "nodev",</p>
			<p class="source-code">                    "rbind"</p>
			<p class="source-code">                ],</p>
			<p class="source-code">                "RW": true,</p>
			<p class="source-code">                "Propagation": "rprivate"</p>
			<p class="source-code">            }</p>
			<p class="source-code">        ],</p>
			<p class="source-code">[…omitted output]</p>
			<p>In the <strong class="source-inline">Mounts</strong> section, we have a list of objects mounted in the container. The only item is an<a id="_idIndexMarker516"/> object of the <strong class="source-inline">volume</strong> type, with a generated UID as its <strong class="source-inline">Name</strong> and a <strong class="source-inline">Source</strong> field that represents its path in the host, while<a id="_idIndexMarker517"/> the <strong class="source-inline">Destination</strong> field is the mount point inside the container. </p>
			<p>We<a id="_idIndexMarker518"/> can double-check the existence of the volume with the <strong class="source-inline">podman volume ls</strong> command:</p>
			<p class="source-code">$ podman volume ls</p>
			<p class="source-code">DRIVER VOLUME NAME</p>
			<p class="source-code">local  2ed93716b7ad73706df5c6f56bda262920accec59e7b6642d36f93 8e936d36d9</p>
			<p>Looking inside the source path, we will find the default files in the container document root:</p>
			<p class="source-code">$ ls -al </p>
			<p class="source-code">/home/packt/.local/share/containers/storage/volumes/2ed93716b7ad73706df5c6f56bda262920accec59e7b6642d36f93 8e936d36d9/_data</p>
			<p class="source-code">total 16</p>
			<p class="source-code">drwxr-xr-x. 2 gbsalinetti gbsalinetti 4096 Sep  9 20:26 .</p>
			<p class="source-code">drwx------. 3 gbsalinetti gbsalinetti 4096 Oct 16 22:41 ..</p>
			<p class="source-code">-rw-r--r--. 1 gbsalinetti gbsalinetti  497 Sep  7 17:21 50x.html</p>
			<p class="source-code">-rw-r--r--. 1 gbsalinetti gbsalinetti  615 Sep  7 17:21 index.html</p>
			<p>This demonstrated that when an empty volume is created, it is populated with the content of the target mount point. When a container stops, the volume is preserved along with all the data and can be reused when the container is restarted by another container.</p>
			<p>The <a id="_idIndexMarker519"/>preceding<a id="_idIndexMarker520"/> example shows a volume with a generated UID, but it is possible to choose the name of the attached volume, as in the following example:</p>
			<p class="source-code">$ podman run -d -p 8080:80  --name nginx_volume2 -v nginx_vol:/usr/share/nginx/html docker.io/library/nginx</p>
			<p>In the<a id="_idIndexMarker521"/> preceding example, Podman creates a new volume named <strong class="source-inline">nginx_vol</strong> and stores it under the default volumes directory. When a named volume is created, Podman does not need to generate a UID.</p>
			<p>The default volumes directory has different paths for rootless and rootful containers:</p>
			<ul>
				<li>For rootless containers, the default volume storage path is <strong class="source-inline">&lt;USER_HOME&gt;/.local/share/containers/storage/volumes</strong>.</li>
				<li>For rootful containers, the default volume storage path is <strong class="source-inline">/var/lib/containers/storage/volumes</strong>.</li>
			</ul>
			<p>Volumes created in those paths are persisted after the container is destroyed and can be reused by other containers.</p>
			<p>To manually remove a volume, use the <strong class="source-inline">podman volume rm</strong> command:</p>
			<p class="source-code">$ podman volume rm nginx_vol</p>
			<p>When dealing with multiple volumes, the <strong class="source-inline">podman volume prune</strong> command removes all the unused volumes. The following example prunes all the volumes in the user default volume storage (the one used by rootless containers):</p>
			<p class="source-code">$ podman volume prune</p>
			<p>The next example shows how to remove volumes used by rootful containers by using the <strong class="source-inline">sudo</strong> prefix:</p>
			<p class="source-code">$ sudo podman volume prune</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">Do not forget to monitor volumes accumulating in the host since they consume disk space that could be reclaimed, and prune unused volumes periodically to avoid cluttering the host storage. </p>
			<p>Users<a id="_idIndexMarker522"/> can also preliminarily create and populate <a id="_idIndexMarker523"/>volumes before running the container. The following example uses the <strong class="source-inline">podman create volume</strong> command to create the volume mounted to the Nginx document root and then populates it with a test <strong class="source-inline">index.html</strong> file:</p>
			<p class="source-code">$ podman volume create custom_nginx</p>
			<p class="source-code">$ echo "Hello World!" &gt;&gt; $(podman volume inspect custom_nginx –format "{{ .Mountpoint }}")/index.html</p>
			<p>We can<a id="_idIndexMarker524"/> now run a new Nginx container using the pre-populated volume:</p>
			<p class="source-code">$ podman run -d -p 8080:80  --name nginx_volume3 -v custom_nginx:/usr/share/nginx/html docker.io/library/nginx</p>
			<p>The HTTP test shows the updated contents:</p>
			<p class="source-code">$ curl localhost:8080</p>
			<p class="source-code">Hello World!</p>
			<p>This time, the volume, which was not empty in the beginning, obfuscated the container target directory with its contents.</p>
			<h3>Mounting volumes with the --mount option</h3>
			<p>As with <a id="_idIndexMarker525"/>bind mounts, we can freely choose between the <strong class="source-inline">-v|--volume</strong> and the <strong class="source-inline">--mount</strong> options. The following example runs an Nginx container using the <strong class="source-inline">--mount</strong> flag:</p>
			<p class="source-code">$ podman run -d -p 8080:80  --name nginx_volume4 --mount type=volume,src=custom_nginx,dst=/usr/share/nginx/html docker.io/library/nginx</p>
			<p>While the <strong class="source-inline">-v|--volume</strong> option is compact and widely adopted, the advantage of the <strong class="source-inline">--mount</strong> option<a id="_idIndexMarker526"/> is a more clear and expressive syntax, along with an exact statement of the mount type.</p>
			<h3>Volume drivers</h3>
			<p>The<a id="_idIndexMarker527"/> preceding volume examples are all based on the same <strong class="bold">local</strong> volume driver, which<a id="_idIndexMarker528"/> is used to manage volume in the local filesystem of the host. Additional volume drivers can be configured in the <strong class="source-inline">/usr/share/containers/containers.conf</strong> file in the <strong class="source-inline">[engine.volume_plugins]</strong> section by passing the plugin name followed by the file or socket path.</p>
			<p>The local volume driver can also be used to mount <strong class="bold">NFS</strong> shares in the host running the container. This result cannot be achieved with rootless containers anyway. The following example shows how to create a volume backed by an NFS share and mount it inside a MongoDB container on its <strong class="source-inline">/data/db</strong> directory:</p>
			<p class="source-code">$ sudo podman volume create --driver local --opt type=nfs --opt o=addr=nfs-host.example.com,rw,context="system_u:object_r:container_file_t:s0" --opt device=:/opt/nfs-export nfs-volume</p>
			<p class="source-code">$ sudo podman run -d -v nfs-volume:/data/db docker.io/library/mongo</p>
			<p>A prerequisite of the preceding example is the preliminary configuration of the NFS server, which should be accessible by the host running the container.</p>
			<h3>Volumes in builds</h3>
			<p>Volumes<a id="_idIndexMarker529"/> can be pre-defined during the image build process. This lets image maintainers define which container directories will be automatically attached to volumes. To understand this concept, let's inspect this minimal Dockerfile:</p>
			<p class="source-code">FROM docker.io/library/nginx:latest</p>
			<p class="source-code">VOLUME /usr/share/nginx/html</p>
			<p>The only change made to the <strong class="source-inline">docker.io/library/nginx</strong> image is a <strong class="bold">VOLUME</strong> directive, which <a id="_idIndexMarker530"/>defines which directory should be externally mounted as an anonymous volume in the host. This is simply metadata, and the volume will be created only at runtime when a container is started from this image.</p>
			<p>If we<a id="_idIndexMarker531"/> build the image and run a container based on the example Dockerfile, we can see an automatically created anonymous volume:</p>
			<p class="source-code">$ podman build -t my_nginx .</p>
			<p class="source-code">$ podman run -d --name volumes_from_build my_nginx</p>
			<p class="source-code">$ podman inspect volumes_from_build --format "{{ .Mounts }}"</p>
			<p class="source-code">[{volume 4d6ac7edcb4f01add205523b7733d61ae4a5772786eacca68e49 72b20fd1180c /home/packt/.local/share/containers/storage/volumes/4d6ac7edcb4f01add205523b7733d61ae4a5772786eacca68e4972 b20fd1180c/_data /usr/share/nginx/html local  [nodev exec nosuid rbind] true rprivate}]</p>
			<p>Without an explicit volume creation option, Podman has already created and mounted the container volume. This automatic volume definition at build time is a common practice in all containers that are expected to persist data, like databases. </p>
			<p>For example, the <strong class="source-inline">docker.io/library/mongo</strong> image is already configured to create two volumes, one for <strong class="source-inline">/data/configdb</strong> and one for <strong class="source-inline">/data/db</strong>. The same behavior can be identified in the most common databases, including PostgreSQL, MariaDB, and MySQL.</p>
			<p>It is possible to define how pre-defined anonymous volumes should be mounted when the container is started. The default ID <strong class="bold">bind</strong>, which<a id="_idIndexMarker532"/> means that new volumes are created and bind-mounted in the container, but it is possible to use <strong class="bold">tmpfs</strong> or ignore<a id="_idIndexMarker533"/> the mount altogether with the <strong class="source-inline">--image-volume</strong> option. The following example starts a MongoDB container with its default volumes mounted as tmpfs:</p>
			<p class="source-code">$ podman run -d --image-volume tmpfs docker.io/library/mongo</p>
			<p>In <a href="B17908_06_epub.xhtml#_idTextAnchor116"><em class="italic">Chapter 6</em></a>, <em class="italic">Meet Buildah – Building Containers from Scratch</em>, we will cover the build process in greater detail. We now close this subsection with an example of how to mount volumes across multiple containers.</p>
			<h3>Mounting volumes across containers</h3>
			<p>One <a id="_idIndexMarker534"/>of the greatest advantages of volumes is their flexibility. For example, a container can mount volumes from an already running container to share the same data. To accomplish this result, we can use the <strong class="source-inline">--volumes-from</strong> option. The following example starts a MongoDB container and then cross mounts its volumes on a Fedora container:</p>
			<p class="source-code">$ podman run -d --name mongodb01 docker.io/library/mongo</p>
			<p class="source-code">$ podman run -it --volumes-from=mongodb01 docker.io/library/fedora</p>
			<p>The second container drops an interactive root shell we can use to inspect the filesystem content:</p>
			<p class="source-code">[root@c10420016687 /]# ls -al /data</p>
			<p class="source-code">total 20</p>
			<p class="source-code">drwxr-xr-t.  4 root root 4096 Oct 17 15:36 .</p>
			<p class="source-code">dr-xr-xr-x. 19 root root 4096 Oct 17 15:36 ..</p>
			<p class="source-code">drwxr-xr-x.  2  999  999 4096 Sep 20 22:20 configdb</p>
			<p class="source-code">drwxr-xr-x.  4  999  999 4096 Oct 17 15:36 db</p>
			<p>As expected, we can find the MongoDB volumes mounted in the Fedora container. If we stop and even remove the first <strong class="source-inline">mongodb01</strong> container, the volumes remain active and mounted inside the Fedora container.</p>
			<p>Until now, we have seen basic use cases with no specific segregation between containers or mounted resources. If the host has SELinux enabled and in enforcing mode, some extra considerations must be applied.</p>
			<h2 id="_idParaDest-111"><a id="_idTextAnchor111"/>SELinux considerations for mounts</h2>
			<p>SELinux recursively <a id="_idIndexMarker535"/>applies labels to files<a id="_idIndexMarker536"/> and directories to define their context. Those labels are usually stored as extended<a id="_idIndexMarker537"/> filesystem attributes. SELinux uses contexts to manage policies and define which processes can access a specific resource. </p>
			<p>The <strong class="source-inline">ls</strong> command is used to see the type context of a resource:</p>
			<p class="source-code">$ ls -alZ /etc/passwd</p>
			<p class="source-code">-rw-r--r--. 1 root root system_u:object_r:passwd_file_t:s0 2965 Jul 28 21:00 /etc/passwd</p>
			<p>In the preceding example, the <strong class="source-inline">passwd_file_t</strong> label defines the type context of the <strong class="source-inline">/etc/passwd</strong> file. Depending on the type context, a program can or cannot access a file while SELinux is running in enforcing mode.</p>
			<p>Processes also have their type context – containers run with the label <strong class="source-inline">container_t</strong> and have read/write access to files and directories labeled with <strong class="source-inline">container_file_t</strong> type context, and read/execute access to <strong class="source-inline">container_share_t</strong> labeled resources. </p>
			<p>Other host directories accessible by default are <strong class="source-inline">/etc</strong> as read-only and <strong class="source-inline">/usr</strong> as read/execute. Also, resources under <strong class="source-inline">/var/lib/containers/overlay/</strong> are labeled as <strong class="source-inline">container_share_t</strong>.</p>
			<p>What happens if we try to mount a directory not correctly labeled? </p>
			<p>Podman still executes the container without complaining about the wrong labeling, but the mounted directory or file will not be accessible from a process running inside the containers, which are labeled with the <strong class="source-inline">container_t</strong> context type. The following example tries to mount a custom document root for an Nginx container without respecting the labeling constraints:</p>
			<p class="source-code">$ mkdir ~/custom_docroot</p>
			<p class="source-code">$ echo "Hello World!" &gt; ~/custom_docroot/index.html</p>
			<p class="source-code">$ podman run -d \</p>
			<p class="source-code">   --name custom_nginx \</p>
			<p class="source-code">  -p 8080:80 \</p>
			<p class="source-code">   -v ~/custom_docroot:/usr/share/nginx/html \</p>
			<p class="source-code">   docker.io/library/nginx</p>
			<p>Apparently, everything went fine – the container started properly and the processes inside it are<a id="_idIndexMarker538"/> running, but if we try to <a id="_idIndexMarker539"/>contact the Nginx server, we see the error:</p>
			<p class="source-code">$ curl localhost:8080</p>
			<p class="source-code">&lt;html&gt;</p>
			<p class="source-code">&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;</p>
			<p class="source-code">&lt;body&gt;</p>
			<p class="source-code">&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;</p>
			<p class="source-code">&lt;hr&gt;&lt;center&gt;nginx/1.21.3&lt;/center&gt;</p>
			<p class="source-code">&lt;/body&gt;</p>
			<p class="source-code">&lt;/html&gt;</p>
			<p><strong class="source-inline">403 – Forbidden</strong> shows<a id="_idIndexMarker540"/> that the Nginx process cannot access the <strong class="source-inline">index.html</strong> page. To fix this error, we have two options – put SELinux in <strong class="bold">permissive</strong> mode <a id="_idIndexMarker541"/>or relabel the mounted resources. By putting SELinux in permissive mode, it continues to track down the violations without blocking them. Anyway, this is not a good practice and should be used only when we cannot correctly troubleshoot access issues and need to put SELinux out of the equation. The following command sets SELinux to permissive mode:</p>
			<p class="source-code">$ sudo setenforce 0</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">Permissive mode is not equal to disabling SELinux entirely. When working in this mode, SELinux still logs AVC denials without blocking. System admins can immediately switch between permissive and enforcing modes without rebooting. Disabling, on the other hand, implies a full system reboot.</p>
			<p>The second preferred option is to simply relabel the resources we need to mount. To achieve this result, we could use SELinux command-line tools. As a shortcut, Podman offers a simpler way – the <strong class="source-inline">:z</strong> and <strong class="source-inline">:Z</strong> suffixes applied to the volume mount arguments. The difference <a id="_idIndexMarker542"/>between the two suffixes is subtle:</p>
			<ul>
				<li>The <strong class="source-inline">:z</strong> suffix tells Podman to relabel the mounted resources in order to enable all containers to read and write it. It works with both volumes and bind mounts.</li>
				<li>The <strong class="source-inline">:Z</strong> suffix tells Podman to relabel the mounted resources in order to enable only the current container to read and write it exclusively. This also works with both volumes and bind mounts.</li>
			</ul>
			<p>To<a id="_idIndexMarker543"/> test the difference, let's try to run the<a id="_idIndexMarker544"/> container again with the <strong class="source-inline">:z</strong> suffix and see what happens:</p>
			<p class="source-code">$ podman run -d \</p>
			<p class="source-code">   --name custom_nginx \</p>
			<p class="source-code">  –p 8080:80 \</p>
			<p class="source-code">   -v ~/custom_docroot:/usr/share/nginx/html:z \</p>
			<p class="source-code">   docker.io/library/nginx</p>
			<p>Now, the HTTP calls return the expected results since the process was able to access the <strong class="source-inline">index.html</strong> file without being blocked by SELinux:</p>
			<p class="source-code">$ curl localhost:8080</p>
			<p class="source-code">Hello World!</p>
			<p>Let's look at the SELinux file context automatically applied to the mounted directory:</p>
			<p class="source-code">$ ls -alZ ~/custom_docroot</p>
			<p class="source-code">total 20</p>
			<p class="source-code">drwxrwxr-x.  2 packt packt system_u:object_r:container_file_t:s0  4096 Oct 16 15:53 .</p>
			<p class="source-code">drwxrwxr-x. 74 packt packt unconfined_u:object_r:user_home_dir_t:s0 12288 Oct 16 16:32 ..</p>
			<p class="source-code">-rw-rw-r--.  1 packt packt system_u:object_r:container_file_t:s0  13 Oct 16 15:53 index.html</p>
			<p>Let's focus on the <strong class="source-inline">system_u:object_r:container_file_t:s0</strong> label. The final <strong class="source-inline">s0</strong> field is a <strong class="bold">Multi-Level Security</strong> (<strong class="bold">MLS</strong>) sensitivity level, which means that all processes with <a id="_idIndexMarker545"/>the same sensitivity level will have read/write access to the resource. Therefore, other<a id="_idIndexMarker546"/> containers that run with the <strong class="source-inline">s0</strong> sensitivity level will be able to mount the resource with read/write access privileges. This also represents a security issue<a id="_idIndexMarker547"/> since a malicious container on the same host would be able to attack other containers by stealing or overwriting data.</p>
			<p>The <a id="_idIndexMarker548"/>solution to this problem is called <strong class="bold">Multi-Category Security</strong> (<strong class="bold">MCS</strong>). SELinux <a id="_idIndexMarker549"/>uses MCS to configure additional categories, which are plaintext labels applied to the resources along with the other SELinux labels. MCS-labeled objects are then accessible only to processes with the same categories assigned. </p>
			<p>When a container is started, processes inside it are labeled with MCS categories, following the<a id="_idIndexMarker550"/> pattern <strong class="bold">cXXX,cYYY</strong>, where XXX and YYY are<a id="_idIndexMarker551"/> randomly picked integers.</p>
			<p>Podman automatically applies MCS categories to mounted resources when <strong class="source-inline">Z</strong> (uppercase) is passed. To test this behavior, let's run the Nginx container again with the <strong class="source-inline">:Z</strong> suffix:</p>
			<p class="source-code">$ podman run -d \</p>
			<p class="source-code">   --name custom_nginx \</p>
			<p class="source-code">  –p 8080:80 \</p>
			<p class="source-code">   -v ~/custom_docroot:/usr/share/nginx/html:Z \</p>
			<p class="source-code">   docker.io/library/nginx</p>
			<p>We can immediately see that the mounted folder has been relabeled with MCS categories:</p>
			<p class="source-code">$ ls -alZ ~/custom_docroot</p>
			<p class="source-code">total 20</p>
			<p class="source-code">drwxrwxr-x.  2 packt packt system_u:object_r:container_file_t:s0:c16,c898  4096 Oct 16 15:53 .</p>
			<p class="source-code">drwxrwxr-x. 74 packt packt unconfined_u:object_r:user_home_dir_t:s0       12288 Oct 16 21:12 ..</p>
			<p class="source-code">-rw-rw-r--.  1 packt packt system_u:object_r:container_file_t:s0:c16,c898    13 Oct 16 15:53 index.html</p>
			<p>A <a id="_idIndexMarker552"/>simple test will return the expected <strong class="source-inline">Hello World!</strong> text, proving <a id="_idIndexMarker553"/>that the processes <a id="_idIndexMarker554"/>inside the container are allowed to access the target resources:</p>
			<p class="source-code">$ curl localhost:8080</p>
			<p class="source-code">Hello World!</p>
			<p>What happens if we run a second container with the same approach, by applying <strong class="source-inline">:Z</strong> again to the same bind mount?</p>
			<p class="source-code">$ podman run -d \</p>
			<p class="source-code">   --name custom_nginx2 \</p>
			<p class="source-code">  –p 8081:80 \</p>
			<p class="source-code">   -v ~/custom_docroot:/usr/share/nginx/html:Z \</p>
			<p class="source-code">   docker.io/library/nginx</p>
			<p>This time, we run the HTTP test on port <strong class="source-inline">8081</strong> and <strong class="source-inline">HTTP GET</strong> still works correctly:</p>
			<p class="source-code">$ curl localhost:8081</p>
			<p class="source-code">Hello World!</p>
			<p>However, if we test once again the container mapped to port <strong class="source-inline">8080</strong>, we will get an unexpected <strong class="source-inline">403 Forbidden</strong> message:</p>
			<p class="source-code">$ curl localhost:8080</p>
			<p class="source-code">&lt;html&gt;</p>
			<p class="source-code">&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;</p>
			<p class="source-code">&lt;body&gt;</p>
			<p class="source-code">&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;</p>
			<p class="source-code">&lt;hr&gt;&lt;center&gt;nginx/1.21.3&lt;/center&gt;</p>
			<p class="source-code">&lt;/body&gt;</p>
			<p class="source-code">&lt;/html&gt;</p>
			<p>Not <a id="_idIndexMarker555"/>surprisingly, the second container was <a id="_idIndexMarker556"/>executed with the <strong class="source-inline">:Z</strong> suffix and relabeled<a id="_idIndexMarker557"/> the directory with a new pair of MCS categories, thus making the first container unable to access the previously available content. </p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">The previous examples were conducted with bind mounts, but applied to volumes in the same way. Use these techniques with caution to avoid unwanted relabels of a bind mounted system or home directories.</p>
			<p>In this subsection, we demonstrated the power of SELinux to manage containers and resource isolation. Let's conclude this chapter with an overview of other types of storage that can be attached to containers.</p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor112"/>Attaching other types of storage to a container</h2>
			<p>Along with bind mounts and volumes, it is possible to attach other types of storage to containers, more specifically, of the kinds <strong class="bold">tmpfs</strong>, <strong class="bold">image</strong>, and <strong class="bold">devpts</strong>. </p>
			<h3>Attaching tmpfs storage</h3>
			<p>Sometimes, we <a id="_idIndexMarker558"/>need to attach storage to containers that is not meant to be persistent (for example, cache usage). Using volumes or bind mounts would clutter the host local disk (or any other backend if using different storage drivers). In those particular cases, we can use a <strong class="bold">tmpfs</strong> volume.</p>
			<p>tmpfs is a<a id="_idIndexMarker559"/> virtual memory filesystem, which means that all its contents are created inside the host virtual memory. A benefit of tmpfs is that it provides faster I/O since all the read/write operations mostly happen in the RAM.</p>
			<p>To attach <a id="_idIndexMarker560"/>a tmpfs volume to a container, we can use the <strong class="source-inline">--mount</strong> option or the <strong class="source-inline">--tmpfs</strong> option.</p>
			<p>The <strong class="source-inline">--mount</strong> flag has the great advantage of being more verbose and expressive regarding the storage type, source, destination, and extra mount options. The following example runs an <strong class="source-inline">httpd</strong> container with a tmpfs volume attached to the container:</p>
			<p class="source-code">$ podman run –d –p 8080:80 \ </p>
			<p class="source-code">   --name tmpfs_example1 \</p>
			<p class="source-code">   --mount type=tmpfs,tmpfs-size=512M,destination=/tmp \</p>
			<p class="source-code">   docker.io/library/httpd</p>
			<p>The preceding command creates a tmpfs volume of 512 MB and mounts it on the <strong class="source-inline">/tmp</strong> folder of the container. We can test the correct mount creation by running the <strong class="source-inline">mount</strong> command inside the container:</p>
			<p class="source-code">$ podman exec -it tmpfs_example1 mount | grep '\/tmp'</p>
			<p class="source-code">tmpfs on /tmp type tmpfs (rw,nosuid,nodev,relatime,context="system_u:object_r:container_file_t:s0:c375,c804",size=524288k,uid=1000,gid=1000,inode64</p>
			<p>This demonstrates that the tmpfs filesystem has been correctly mounted inside the container. Stopping the container will automatically discard tmpfs:</p>
			<p class="source-code">$ podman stop tmpfs_example1 </p>
			<p>The following example mounts a tmpfs volume using the <strong class="source-inline">--tmpfs</strong> option:</p>
			<p class="source-code">$ podman run –d –p 8080:80 \</p>
			<p class="source-code">   --name tmpfs_example2 \</p>
			<p class="source-code">   --tmpfs /tmp:rw,size= 524288k,mode=1777 \</p>
			<p class="source-code">   docker.io/library/httpd</p>
			<p>This<a id="_idIndexMarker561"/> example provides the same results as the previous <a id="_idIndexMarker562"/>one: a running container with a 512 MB tmpfs volume mounted on the <strong class="source-inline">/tmp</strong> directory in read/write mode and <strong class="source-inline">1777</strong> permissions.</p>
			<p>By default, the tmpfs volume is mounted inside the container with the following mount options – <strong class="bold">rw</strong>, <strong class="bold">noexec</strong>, <strong class="bold">nosuid</strong>, and <strong class="bold">nodev</strong>. </p>
			<p>Another interesting feature is the automatic MCS labeling from SELinux. This provides automatic segregation of the filesystem and prevents any other container from accessing the data in memory.</p>
			<h3>Attaching images</h3>
			<p>OCI images<a id="_idIndexMarker563"/> are the base that provides layers and metadata to start containers, but they can also be attached to a container filesystem at runtime. This <a id="_idIndexMarker564"/>can be useful for troubleshooting purposes or for attaching binaries that are available in a foreign image. When an OCI image is mounted inside a container, an extra overlay is created. This implies that even when the image is mounted with read/write permissions, users never alter the original image but the upper overlay only.</p>
			<p>The following example mounts a <strong class="source-inline">busybox</strong> image with read/write permissions inside an Alpine container:</p>
			<p class="source-code">$ podman run -it \</p>
			<p class="source-code">   --mount type=image,src=docker.io/library/busybox,dst=/mnt,rw=true \</p>
			<p class="source-code">   alpine</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">The mounted image must already be cached in the host. Podman only pulls the base container image if it is available when a container is created, but it expects the mounted images to already be available. A preliminary pull of the images will solve the issue.</p>
			<h3>Attaching devpts</h3>
			<p>This option<a id="_idIndexMarker565"/> is useful for attaching a <strong class="bold">pseudo terminal slave</strong> (<strong class="bold">PTS</strong>) to a <a id="_idIndexMarker566"/>container. This feature was introduced in Podman 2.1.0 to support containers that need to mount <strong class="source-inline">/dev/</strong> from the host into<a id="_idIndexMarker567"/> the container, while still creating a terminal. The <strong class="source-inline">/dev</strong> pseudo filesystem of the host enables containers to gain direct access to the machine's physical or virtual devices.</p>
			<p>To create a container with the <strong class="source-inline">/dev</strong> filesystem and a <strong class="source-inline">devpts</strong> device attached, run the following command:</p>
			<p class="source-code">$ sudo podman run -it \</p>
			<p class="source-code">  -v /dev/:/dev:rslave \</p>
			<p class="source-code">  --mount type=devpts,destination=/dev/pts \</p>
			<p class="source-code">  docker.io/library/fedora</p>
			<p>To check the result of the mount option, we require an extra tool inside the container. For this reason, we can install it with the following command:</p>
			<p class="source-code">[root@034c8a61a4fc /]# dnf install -y toolbox</p>
			<p>The resulting container has an extra, non-isolated, <strong class="source-inline">devpts</strong> device mounted on <strong class="source-inline">/dev/pts</strong>:</p>
			<p class="source-code"># mount | grep '\/dev\/pts'</p>
			<p class="source-code">devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,seclabel,gid=5,mode=620,ptmxmode=000)</p>
			<p class="source-code">devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,context="system_u:object_r:container_file_t:s0:c299,c741",gid=5,mode=620,ptmxmode=666)</p>
			<p>The preceding output was extracted by running the <strong class="source-inline">mount</strong> command inside the container. </p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor113"/>Summary</h1>
			<p>In this chapter, we have completed a journey on container storage and Podman features offered to manipulate it. The material in this chapter is crucial to understanding how Podman manages both ephemeral and persistent data and provides best practices to users to manipulate their data.</p>
			<p>In the first section, we learned why container storage matters and how it should be correctly managed both in single host and orchestrated, multi-host environments.</p>
			<p>In the second section, we took a deep dive into container storage features and storage drivers, with a special focus on overlayfs.</p>
			<p>In the third section, we learned how to copy files to and from a container. We also saw how changes could be committed to a new image.</p>
			<p>The fourth section described the different possible scenarios of storage attached to a container, covering bind mounts, volumes, tmpfs, images, and devpts. This section was also a perfect fit to discuss SELinux interaction with storage management and see how we can use it to isolate storage resources across containers on the same host.</p>
			<p>In the next chapter, we will learn a very important topic for both developers and operations teams, which is how to build OCI images with both Podman and <strong class="bold">Buildah</strong>, an advanced and specialized image-building tool.</p>
			<h1 id="_idParaDest-114"><a id="_idTextAnchor114"/>Further reading</h1>
			<p>Refer to the following resources for more information:</p>
			<ul>
				<li>Containers Storage project page: <a href="https://github.com/containers/storage">https://github.com/containers/storage</a></li>
				<li>Container Labeling: <a href="https://danwalsh.livejournal.com/81269.html ">https://danwalsh.livejournal.com/81269.html</a></li>
				<li>Why you should be using Multi-Category Security for your Linux containers: <a href="https://www.redhat.com/en/blog/why-you-should-be-using-multi-category-security-your-linux-containers">https://www.redhat.com/en/blog/why-you-should-be-using-multi-category-security-your-linux-containers</a></li>
				<li>Udica: Generate SELinux policies: <a href="https://github.com/containers/udica">https://github.com/containers/udica</a></li>
				<li>Overlay source code: <a href="https://github.com/containers/storage/blob/main/drivers/overlay/overlay.go">https://github.com/containers/storage/blob/main/drivers/overlay/overlay.go</a></li>
			</ul>
		</div>
	</body></html>