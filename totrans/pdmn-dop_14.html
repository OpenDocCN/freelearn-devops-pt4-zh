<html><head></head><body>
		<div id="_idContainer046">
			<h1 id="_idParaDest-206"><em class="italic"><a id="_idTextAnchor206"/>Chapter 11</em>: Securing Containers</h1>
			<p>Security is becoming the hottest topic of current times. Enterprises and companies all over the world are making huge investments in security practices and tools that should help protect their systems from internal or external attacks.</p>
			<p>As we saw in <a href="B17908_01_epub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Container Technology</em>, containers and their host systems can be considered a medium to execute and keep a target application running. Security should be applied to all levels of the service architecture, from the base infrastructure to the target application code, all while passing through the virtualization or containerization layer.</p>
			<p>In this chapter, we will look at the best practices and tools that could help improve the overall security of our containerization layer. In particular, we're going to cover the following main topics:</p>
			<ul>
				<li>Running rootless containers with Podman</li>
				<li>Do not run containers with UID 0</li>
				<li>Signing our container images</li>
				<li>Customizing Linux kernel capabilities</li>
				<li>SELinux interaction with containers</li>
			</ul>
			<h1 id="_idParaDest-207"><a id="_idTextAnchor207"/>Technical requirements</h1>
			<p>To complete this chapter's examples, you will need a machine with a working Podman installation. As we mentioned in <a href="B17908_03_epub.xhtml#_idTextAnchor068"><em class="italic">Chapter 3</em></a>, <em class="italic">Running the First Container</em>, all the examples in this book have been executed on a Fedora 34 system or later, but they can be reproduced on your OS of choice.</p>
			<p>Having a good understanding of the topics that were covered in <a href="B17908_04_epub.xhtml#_idTextAnchor083"><em class="italic">Chapter 4</em></a>, <em class="italic">Managing Running Containers</em>, <a href="B17908_05_epub.xhtml#_idTextAnchor101"><em class="italic">Chapter 5</em></a>, <em class="italic">Implementing Storage for the Container's Data</em>, and <a href="B17908_09_epub.xhtml#_idTextAnchor167"><em class="italic">Chapter 9</em></a>, <em class="italic">Pushing Images to a Container Registry</em>, will help you understand the container security topics we'll be discussing here.</p>
			<h1 id="_idParaDest-208"><a id="_idTextAnchor208"/>Running rootless containers with Podman </h1>
			<p>As we briefly <a id="_idIndexMarker959"/>saw in <a href="B17908_04_epub.xhtml#_idTextAnchor083"><em class="italic">Chapter 4</em></a>, <em class="italic">Managing Running Containers</em>, it is <a id="_idIndexMarker960"/>possible for <a id="_idIndexMarker961"/>Podman to let standard users without administrative privileges run containers in a Linux host. These containers are often referred to as "rootless containers."</p>
			<p>Rootless containers have <a id="_idIndexMarker962"/>many advantages, including the following:</p>
			<ul>
				<li>They create an additional security layer that could block attackers trying to get root privileges on the host, even if the container engine, runtime, or orchestrator has been compromised.</li>
				<li>They can allow many unprivileged users to run containers on the same host, making the most of high-performance computing environments.</li>
			</ul>
			<p>Let's think about the approach that's used by any Linux system to handle traditional process services. Usually, the package maintainers tend to create a dedicated user for scheduling and running the target process. If we try to install an Apache web server on our favorite Linux distribution through the default package manager, then we can find out that the installed service will run through a dedicated user named "apache."</p>
			<p>This approach has been the best practice for years because, from a security perspective, allowing fewer privileges improves security.</p>
			<p>Using the same approach but with a rootless container allows us to run the container process without the need for additional privileges escalation. Additionally, Podman is daemonless, so it will just create a child process.</p>
			<p>Running rootless containers in Podman is pretty straightforward and, as we saw in the previous chapters, many of the examples in this book can be run as standard unprivileged users. Now, let's learn what's behind the execution of a rootless container.</p>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor209"/>The Podman Swiss Army knife – subuid and subgid</h2>
			<p>Modern Linux distributions <a id="_idIndexMarker963"/>use a version of the <strong class="source-inline">shadow-utils</strong> package that <a id="_idIndexMarker964"/>leverages two files: <strong class="source-inline">/etc/subuid</strong> and <strong class="source-inline">/etc/subgid</strong>. These files are used to determine which UIDs and GIDs can be used to map a user namespace.</p>
			<p>The default allocation for every user is 65536 UIDs and 65536 GIDs.</p>
			<p>We can run the following simple command to check how the subuid and subgid allocation works in rootless containers:</p>
			<p class="source-code">$ id</p>
			<p class="source-code">uid=1000(alex) gid=1000(alex) groups=1000(alex),10(wheel) </p>
			<p class="source-code">$ podman run alpine cat /proc/self/uid_map /proc/self/gid_map</p>
			<p class="source-code">Resolved "alpine" as an alias (/etc/containers/registries.conf.d/000-shortnames.conf)</p>
			<p class="source-code">Trying to pull docker.io/library/alpine:latest...</p>
			<p class="source-code">Getting image source signatures</p>
			<p class="source-code">Copying blob 59bf1c3509f3 done  </p>
			<p class="source-code">Copying config c059bfaa84 done  </p>
			<p class="source-code">Writing manifest to image destination</p>
			<p class="source-code">Storing signatures</p>
			<p class="source-code">         0       1000          1</p>
			<p class="source-code">         1     100000      65536</p>
			<p class="source-code">         0       1000          1</p>
			<p class="source-code">         1     100000      65536</p>
			<p>As we can see, both files indicate that they start mapping UID and GID 0 with the current user's UID/GID that <a id="_idIndexMarker965"/>we just run the container with; that is, <strong class="source-inline">1000</strong>. After that, it maps UID <a id="_idIndexMarker966"/>and GID 1, starting from <strong class="source-inline">100000</strong> and arriving at <strong class="source-inline">165536</strong>. This is calculated by summing the starting point, <strong class="source-inline">100000</strong>, and the default range, <strong class="source-inline">65536</strong>.</p>
			<p>Using rootless containers is <a id="_idIndexMarker967"/>not the only best practice we can implement for our container <a id="_idIndexMarker968"/>environments. In the next section, we'll learn why we shouldn't run a container with UID 0.</p>
			<h1 id="_idParaDest-210"><a id="_idTextAnchor210"/>Do not run containers with UID 0</h1>
			<p>Container runtimes can be instructed to perform running processes inside a container with a user ID that's different from the one that initially created the container, similar to what we saw for <a id="_idIndexMarker969"/>rootless containers. Running the container's processes as a non-root user can be helpful for security purposes. For example, using an unprivileged user in a container could limit the attack surface inside and outside that container.</p>
			<p>By default, a Dockerfile and Containerfile may set the default user as root (that is, UID=0). To avoid this, we can leverage the USER instruction in those build files – for example, <strong class="source-inline">USER 1001</strong> –  to instruct Buildah or other container build tools to build and run the container image using that particular user (with UID 1001).</p>
			<p>If we want to force a specific UID, we need to adjust the permissions of any file, folder, or mount we plan to use with our running containers.</p>
			<p>Now, let's learn how to adapt an existing image so that it can be run with a standard user.</p>
			<p>We can leverage some prebuilt images on DockerHub or pick one of the official Nginx container images. First, we need to create a basic <strong class="source-inline">nginx</strong> configuration file:</p>
			<p class="source-code">$ cat hello-podman.conf </p>
			<p class="source-code">server {</p>
			<p class="source-code">    listen 80;</p>
			<p class="source-code"> </p>
			<p class="source-code">    location / {</p>
			<p class="source-code">        default_type text/plain;</p>
			<p class="source-code">        expires -1;</p>
			<p class="source-code">        return 200 'Hello Podman user!\nServer address: $server_addr:$server_port\n';</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>The <strong class="source-inline">nginx</strong> configuration file is really simple: we define the listening port (80) and the content message to return once a request arrives on the server.</p>
			<p>Then, we can create a simple Dockerfile to leverage one of the official Nginx container images:</p>
			<p class="source-code">$ cat Dockerfile </p>
			<p class="source-code">FROM docker.io/library/nginx:mainline-alpine</p>
			<p class="source-code">RUN rm /etc/nginx/conf.d/*</p>
			<p class="source-code">ADD hello-podman.conf /etc/nginx/conf.d/</p>
			<p>The Dockerfile contains three instructions:</p>
			<ul>
				<li><strong class="source-inline">FROM</strong>: For selecting the official Nginx image</li>
				<li><strong class="source-inline">RUN</strong>: For cleaning the configuration directory from any default config example</li>
				<li><strong class="source-inline">ADD</strong>: For copying the configuration file we just created</li>
			</ul>
			<p>Now, let's build <a id="_idIndexMarker970"/>the container image with Buildah:</p>
			<p class="source-code">$ buildah bud -t nginx-root:latest -f .</p>
			<p class="source-code">STEP 1/3: FROM docker.io/library/nginx:mainline-alpine</p>
			<p class="source-code">STEP 2/3: RUN rm /etc/nginx/conf.d/*</p>
			<p class="source-code">STEP 3/3: ADD hello-podman.conf /etc/nginx/conf.d/</p>
			<p class="source-code">COMMIT nginx-root:latest</p>
			<p class="source-code">Getting image source signatures</p>
			<p class="source-code">Copying blob 8d3ac3489996 done </p>
			<p class="source-code">...</p>
			<p class="source-code">Copying config 21c5f7d8d7 done  </p>
			<p class="source-code">Writing manifest to image destination</p>
			<p class="source-code">Storing signatures</p>
			<p class="source-code">--&gt; 21c5f7d8d70</p>
			<p class="source-code">Successfully tagged localhost/nginx-root:latest</p>
			<p class="source-code">21c5f7d8d709e7cfdf764a14fd6e95fb4611b2cde52b57aa46d43262a 6489f41</p>
			<p>Once you've built the image, name it <strong class="source-inline">nginx-root</strong>. Now, we are ready to run our container:</p>
			<p class="source-code">$ podman run --name myrootnginx -p 127.0.0.1::80 -d nginx-root </p>
			<p class="source-code">364ec7f5979a5059ba841715484b7238db3313c78c5c577629364aa46b6d 9bdc</p>
			<p>Here, we used the<strong class="source-inline">–p</strong> option to publish the port and make it reachable from the host. Let's find out what local port has been chosen, randomly, in the host system:</p>
			<p class="source-code">$ podman port myrootnginx 80</p>
			<p class="source-code">127.0.0.1:38029</p>
			<p>Finally, let's call our containerized web server:</p>
			<p class="source-code">$ curl localhost:38029</p>
			<p class="source-code">Hello Podman user!</p>
			<p class="source-code">Server address: 10.0.2.100:80</p>
			<p>The container is finally <a id="_idIndexMarker971"/>running, but what user is using our container? Let's find out:</p>
			<p class="source-code">$ podman ps | grep root</p>
			<p class="source-code">364ec7f5979a  localhost/nginx-root:latest  nginx -g daemon o...  55 minutes ago  Up 55 minutes ago  0.0.0.0:38029-&gt;80/tcp      myrootnginx</p>
			<p class="source-code">$ podman exec 364ec7f5979a id</p>
			<p class="source-code">uid=0(root) gid=0(root)</p>
			<p>As expected, the container is running as root! </p>
			<p>Now, let's make a few edits to change the user. First, we need to change the listening port in the Nginx server configuration:</p>
			<p class="source-code">$ cat hello-podman.conf </p>
			<p class="source-code">server {</p>
			<p class="source-code">    listen 8080;</p>
			<p class="source-code"> </p>
			<p class="source-code">    location / {</p>
			<p class="source-code">        default_type text/plain;</p>
			<p class="source-code">        expires -1;</p>
			<p class="source-code">        return 200 'Hello Podman user!\nServer address: $server_addr:$server_port\n';</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>Here, we <a id="_idIndexMarker972"/>replaced the listening port (<strong class="source-inline">80</strong>) with <strong class="source-inline">8080</strong>; we cannot use a port that's below <strong class="source-inline">1024</strong> with unprivileged users.</p>
			<p>Then, we need to edit our Dockerfile:</p>
			<p class="source-code">$ cat Dockerfile </p>
			<p class="source-code">FROM docker.io/library/nginx:mainline-alpine</p>
			<p class="source-code">RUN rm /etc/nginx/conf.d/*</p>
			<p class="source-code">ADD hello-podman.conf /etc/nginx/conf.d/</p>
			<p class="source-code"> </p>
			<p class="source-code">RUN chmod -R a+w /var/cache/nginx/ \</p>
			<p class="source-code">        &amp;&amp; touch /var/run/nginx.pid \</p>
			<p class="source-code">        &amp;&amp; chmod a+w /var/run/nginx.pid</p>
			<p class="source-code">EXPOSE 8080</p>
			<p class="source-code">USER nginx</p>
			<p>As you can see, we fixed the permissions for the main file and folder on the Nginx server, exposed the new <strong class="source-inline">8080</strong> port, and set the default user to an Nginx one.</p>
			<p>Now, we are <a id="_idIndexMarker973"/>ready to build a brand-new container image. Let's call it <strong class="source-inline">nginx-user</strong>:</p>
			<p class="source-code">$ buildah bud -t nginx-user:latest -f .</p>
			<p class="source-code">STEP 1/6: FROM docker.io/library/nginx:mainline-alpine</p>
			<p class="source-code">STEP 2/6: RUN rm /etc/nginx/conf.d/*</p>
			<p class="source-code">STEP 3/6: ADD hello-podman.conf /etc/nginx/conf.d/</p>
			<p class="source-code">STEP 4/6: RUN chmod -R a+w /var/cache/nginx/         &amp;&amp; touch /var/run/nginx.pid         &amp;&amp; chmod a+w /var/run/nginx.pid </p>
			<p class="source-code">STEP 5/6: EXPOSE 8080</p>
			<p class="source-code">STEP 6/6: USER nginx</p>
			<p class="source-code">COMMIT nginx-user:latest</p>
			<p class="source-code">Getting image source signatures</p>
			<p class="source-code">Copying blob 8d3ac3489996 done  </p>
			<p class="source-code">... </p>
			<p class="source-code">Copying config 7628852470 done  </p>
			<p class="source-code">Writing manifest to image destination</p>
			<p class="source-code">Storing signatures</p>
			<p class="source-code">--&gt; 76288524704</p>
			<p class="source-code">Successfully tagged localhost/nginx-user:latest</p>
			<p class="source-code">762885247041fd233c7b66029020c4da8e1e254288e1443b356cbee4d73 adf3e</p>
			<p>Now, we can run the container:</p>
			<p class="source-code">$ podman run --name myusernginx -p 127.0.0.1::8080 -d nginx-user </p>
			<p class="source-code">299e0fb727f339d87dd7ea67eac419905b10e36181dc1ca7e35dc7d0a 9316243</p>
			<p>Find the associated random host port and check whether the web server is working:</p>
			<p class="source-code">$ podman port myusernginx 8080</p>
			<p class="source-code">127.0.0.1:42209</p>
			<p class="source-code">$ curl 127.0.0.1:42209</p>
			<p class="source-code">Hello Podman user!</p>
			<p class="source-code">Server address: 10.0.2.100:8080</p>
			<p>Finally, let's <a id="_idIndexMarker974"/>see whether we changed the user that's running the target process in our container:</p>
			<p class="source-code">$ podman ps | grep user</p>
			<p class="source-code">299e0fb727f3  localhost/nginx-user:latest  nginx -g daemon o...  38 minutes ago  Up 38 minutes ago  127.0.0.1:42209-&gt;8080/tcp  myusernginx</p>
			<p class="source-code">$ podman exec 299e0fb727f3 id</p>
			<p class="source-code">uid=101(nginx) gid=101(nginx) groups=101(nginx)</p>
			<p>As you can see, our container is running as an unprivileged user, which is what we wanted.</p>
			<p>If you want to look at a ready-to-use example of this, please go to this book's GitHub repository: <a href="https://github.com/PacktPublishing/Podman-for-DevOps">https://github.com/PacktPublishing/Podman-for-DevOps</a>.</p>
			<p>Unfortunately, security is not all about permissions and users – we also need to take care of the base image and its source and check container image signatures. We'll learn about this in the next section.</p>
			<h1 id="_idParaDest-211"><a id="_idTextAnchor211"/>Signing our container images</h1>
			<p>When we're dealing with images that have been pulled from external registries, we will have some security <a id="_idIndexMarker975"/>concerns related to the potential attack tactics that have been conducted on the containers (see [<em class="italic">1</em>] in the <em class="italic">Further reading</em> section), especially masquerading techniques, which help the attacker manipulate image components to <a id="_idIndexMarker976"/>make them appear legitimate. This could also happen due to a <strong class="bold">man-in-the-middle</strong> (<strong class="bold">MITM</strong>) attack being conducted by an attacker over the wire.</p>
			<p>To prevent certain kinds of attacks while you're managing containers, the best solution is to use a <a id="_idIndexMarker977"/>detached image signature to trust the image provider and guarantee its reliability. </p>
			<p><strong class="bold">GNU Privacy Guard</strong> (<strong class="bold">GPG</strong>) is a free implementation of the OpenPGP standard and can be used, together <a id="_idIndexMarker978"/>with Podman, to sign images and check their valid signatures once they've been pulled.</p>
			<p>When an image is pulled, Podman can verify the validity of the signatures and reject images without valid signatures.</p>
			<p>Now, let's learn how to implement a basic image signature workflow.</p>
			<h2 id="_idParaDest-212"><a id="_idTextAnchor212"/>Signing images with GPG and Podman</h2>
			<p>In this section, we will create a basic GPG key pair and configure Podman to push and sign the image while <a id="_idIndexMarker979"/>storing the signature in a <a id="_idIndexMarker980"/>staging store. For the sake of clarity, we will run <a id="_idIndexMarker981"/>a registry using the basic Docker Registry V2 <a id="_idIndexMarker982"/>container image without any customization.</p>
			<p>Before testing the image pull and signature validation workflow, we will expose a basic web server to publish the detached signature.</p>
			<p>To create image signatures with GPG, we need to create a valid GPG key pair or use an existing one. For this reason, we will provide a short recap on GPG key pairs to help you understand how image signatures work. </p>
			<p>A key pair is composed of a private key and a public key. The public key can be shared universally, while the <a id="_idIndexMarker983"/>private key is kept private and never shared with anybody. The public key that belongs to the receiver can be used by the sender of a file or message to sign it. In this way, only the owner of the private key (that is, the receiver) will be able to decrypt the message.</p>
			<p>We can easily translate this concept into container images: the image owner that pushes it to the remote registry can sign it using a key pair and store the detached signature on a store (from now on, <em class="italic">sigstore</em>) that is publicly accessible by users. Here, the signature is separated by the image itself – the registry will store the image blobs while the sigstore will hold and expose the image signatures.</p>
			<p>Users who are pulling the image will be able to validate the image signature using the previously shared public key.</p>
			<p>Now, let's go back to creating the GPG key pair. We are going to create a simple one with the following command:</p>
			<p class="source-code">$ gpg --full-gen-key</p>
			<p>The preceding <a id="_idIndexMarker984"/>command will ask you a series <a id="_idIndexMarker985"/>of questions and provide a passphrase to help you <a id="_idIndexMarker986"/>generate the key pair. By default, this will <a id="_idIndexMarker987"/>be stored in the <strong class="source-inline">$HOME/.gnupg</strong> folder.</p>
			<p>The key pair's output should be similar to the following:</p>
			<p class="source-code">$ gpg --list-keys</p>
			<p class="source-code">/home/vagrant/.gnupg/pubring.kbx</p>
			<p class="source-code">pub   rsa3072 2022-01-05 [SC]</p>
			<p class="source-code">      2EA4850C32D29DA22B7659FEC38D92C0F18764AC</p>
			<p class="source-code">uid           [ultimate] Foo Bar foobar@example.com</p>
			<p class="source-code">sub   rsa3072 2022-01-05 [E]</p>
			<p>It is also possible to export generated key pairs. The following command will export the public key to a file:</p>
			<p class="source-code">$ gpg --armor --export foobar@example.com &gt; pubkey.pem</p>
			<p>This command will be useful later when we define the image signature's verification.</p>
			<p>The following command can be used to export the private key:</p>
			<p class="source-code">$ gpg --armor \</p>
			<p class="source-code">  --export-secret-keys foobar@example.com &gt; privkey.pem</p>
			<p>In both <a id="_idIndexMarker988"/>examples, the <strong class="source-inline">--armor</strong> option has been used to export the keys in <strong class="bold">Privacy Enhanced Mail</strong> (<strong class="bold">PEM</strong>) format.</p>
			<p>Once the key pair has been generated, we can create a basic registry that will host our container images. To do so, we will reuse the basic example from <a href="B17908_09_epub.xhtml#_idTextAnchor167"><em class="italic">Chapter 9</em></a>, <em class="italic">Pushing Images to a Container Registry</em>, and run the following command as root:</p>
			<p class="source-code"># mkdir /var/lib/registry</p>
			<p class="source-code"># podman run -d \</p>
			<p class="source-code">   --name local_registry \</p>
			<p class="source-code">   -p 5000:5000 \</p>
			<p class="source-code">   -v /var/lib/registry:/var/lib/registry:z \</p>
			<p class="source-code">   --restart=always registry:2</p>
			<p>We now have <a id="_idIndexMarker989"/>a local registry without <a id="_idIndexMarker990"/>authentication that can be used to push the <a id="_idIndexMarker991"/>test images. As we mentioned previously, the registry <a id="_idIndexMarker992"/>is unaware of the image's detached signature.</p>
			<p>Podman must be able to write signatures on a staging sigstore. There is already a default configuration in the <strong class="source-inline">/etc/containers/registries.d/default.yaml</strong> file, which looks as follows:</p>
			<p class="source-code">default-docker:</p>
			<p class="source-code">#  sigstore: file:///var/lib/containers/sigstore</p>
			<p class="source-code">  sigstore-staging: file:///var/lib/containers/sigstore</p>
			<p>The <strong class="source-inline">sigstore-staging</strong> path is where Podman writes image signatures; it must write them to a writable folder. It is possible to customize this path or keep the default configuration as-is. </p>
			<p>If we want to create multiple user-related sigstores, we can create the <strong class="source-inline">$HOME/.config/containers/registries.d/default.yaml</strong> files and define a custom <strong class="source-inline">sigstore-staging</strong> path in the user's home directory, following the same syntax that was shown in the previous example. This will allow users to run Podman in rootless mode and successfully write to their sigstore.</p>
			<p class="callout-heading">Important</p>
			<p class="callout">It is not a good idea to share the default <strong class="source-inline">sigstore</strong> across all users by allowing general write permissions. This is because every user in the host would have write access to the existing signatures.</p>
			<p>Since we <a id="_idIndexMarker993"/>want to use the default sigstore <a id="_idIndexMarker994"/>while still using the default GPG key pair under the <a id="_idIndexMarker995"/>user's home directory, we will run Podman by <a id="_idIndexMarker996"/>elevating privileges with <strong class="source-inline">sudo</strong>, an exception to the approach that this book follows.</p>
			<p>The following example shows the Dockerfile of a custom <strong class="source-inline">httpd</strong> image that's been built using UBI 8:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Chapter11/image_signature/Dockerfile</p>
			<p class="source-code">FROM registry.access.redhat.com/ubi8</p>
			<p class="source-code"># Update image and install httpd</p>
			<p class="source-code">RUN yum install -y httpd &amp;&amp; yum clean all –y</p>
			<p class="source-code"># Expose the default httpd port 80</p>
			<p class="source-code">EXPOSE 80</p>
			<p class="source-code"># Run the httpd</p>
			<p class="source-code">CMD ["/usr/sbin/httpd", "-DFOREGROUND"]</p>
			<p>To build the image, we can run the following command:</p>
			<p class="source-code">$ cd Chapter11/image_signature </p>
			<p class="source-code">$ sudo podman build -t custom_httpd .</p>
			<p>Now, we can tag the image with the local registry name:</p>
			<p class="source-code">$ sudo podman tag custom_httpd localhost:5000/custom_httpd</p>
			<p>Finally, it's time to push the image on the temporary registry and sign it using the generated key pair. The <strong class="source-inline">--sign-by</strong> option allows users to pass a valid key pair that's been identified by the user's email:</p>
			<p class="source-code">$ <strong class="bold">sudo GNUPGHOME=$HOME/.gnupg podman \</strong></p>
			<p class="source-code"><strong class="bold">   push --tls-verify=false \</strong></p>
			<p class="source-code"><strong class="bold">   --sign-by foobar@example.com \</strong></p>
			<p class="source-code"><strong class="bold">   localhost:5000/custom_httpd</strong></p>
			<p class="source-code">Getting image source signatures</p>
			<p class="source-code">Copying blob 3ba8c926eef9 done  </p>
			<p class="source-code">Copying blob a59107c02e1f done  </p>
			<p class="source-code">Copying blob 352ba846236b done  </p>
			<p class="source-code">Copying config 569b015109 done  </p>
			<p class="source-code">Writing manifest to image destination</p>
			<p class="source-code">Signing manifest</p>
			<p class="source-code">Storing signatures</p>
			<p>The preceding <a id="_idIndexMarker997"/>code successfully pushed the image <a id="_idIndexMarker998"/>blobs to the registry and stored the image <a id="_idIndexMarker999"/>signature. Notice the <strong class="source-inline">GNUPGHOME</strong> variable, which <a id="_idIndexMarker1000"/>was passed at the beginning of the command to define the GPG keystore path that's accessed by Podman.</p>
			<p class="callout-heading">Warning</p>
			<p class="callout">The <strong class="source-inline">--sign-by</strong> option is not supported on the remote Podman client.</p>
			<p>To verify that the image has been signed correctly and that its signature is being saved in the sigstore, we can check the content of <strong class="source-inline">/var/lib/containers/sigstore</strong>:</p>
			<p class="source-code">$ ls -al /var/lib/containers/sigstore/</p>
			<p class="source-code">drwxr-xr-x. 6 root    root    4096 Jan  5 18:58  .</p>
			<p class="source-code">drwxr-xr-x. 5 root    root    4096 Jan  5 13:29  ..</p>
			<p class="source-code">drwxr-xr-x. 2 root    root    4096 Jan  5 18:58 'custom_httpd@sha256=573c1eb93857c0169a606f1820271b143ac5073456f844255c3c7a9e 308bf639'</p>
			<p>As you will see, the new directory contains the image signature file:</p>
			<p class="source-code">$ ls -al /var/lib/containers/sigstore/'custom_httpd@sha256=573c1eb93857c0169a606f1820271b143ac5073456f844255c3c7a9 e308bf639'</p>
			<p class="source-code">total 12</p>
			<p class="source-code">drwxr-xr-x. 2 root root 4096 Jan  5 18:58 .</p>
			<p class="source-code">drwxr-xr-x. 6 root root 4096 Jan  5 18:58 ..</p>
			<p class="source-code">-rw-r--r--. 1 root root  730 Jan  5 18:58 signature-1</p>
			<p>With that, we <a id="_idIndexMarker1001"/>have successfully pushed <a id="_idIndexMarker1002"/>and signed the image, making it more secure for <a id="_idIndexMarker1003"/>future use. Now, let's learn how to configure <a id="_idIndexMarker1004"/>Podman to retrieve signed images.</p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor213"/>Configuring Podman to pull signed images</h2>
			<p>To successfully pull a <a id="_idIndexMarker1005"/>signed image, Podman must be able to retrieve the signature from a sigstore and have access to a public key to verify the signature.</p>
			<p>Here, we are dealing with detached signatures, and we have already learned that the registry doesn't hold any information about image signatures. For this reason, we need to make them available to users with a publicly accessible sigstore: a web server (Nginx, Apache httpd, and so on) will be a good fit.</p>
			<p>Since the signing host will be the same as the one used to test image pulls, we will run an Apache httpd server that exposes the sigstore staging folder as the server document root. In a real-life scenario, we would move the signatures to a dedicated web server.</p>
			<p>For this example, we will use the standard <strong class="source-inline">docker.io/library/httpd</strong> image and run the container with root privileges to grant access to the sigstore folder:</p>
			<p class="source-code"># podman run -d -p 8080:80 \</p>
			<p class="source-code">  --name sigstore_server \</p>
			<p class="source-code">  -v /var/lib/containers/sigstore:/usr/local/apache2/htdocs:z \</p>
			<p class="source-code">  docker.io/library/httpd</p>
			<p>The web server is now available at <strong class="source-inline">http://localhost:8080</strong> and can be used by Podman to retrieve image signatures.</p>
			<p>Now, let's configure Podman for image pulling. First, we must configure the default image sigstore. We have already defined the staging sigstore that's used by Podman to write a <a id="_idIndexMarker1006"/>signature, so now, we need to define the sigstore that's used to read image signatures.</p>
			<p>To do so, we must edit the <strong class="source-inline">/etc/containers/registries.d/default.yaml</strong> file one more time and add a reference to the default sigstore web server that's running on <strong class="source-inline">http://localhost:8080</strong>:</p>
			<p class="source-code">default-docker:</p>
			<p class="source-code">  sigstore: http://localhost:8080</p>
			<p class="source-code">  sigstore-staging: file:///var/lib/containers/sigstore</p>
			<p>The preceding code configures the sigstore that's used by Podman for all images. However, it is possible to add more sigstores for specific registries by populating the <em class="italic">docker</em> field of the file. The following code configures the sigstore for the public Red Hat registry:</p>
			<p class="source-code">docker:</p>
			<p class="source-code">  registry.access.redhat.com:</p>
			<p class="source-code">    sigstore: https://access.redhat.com/webassets/docker/content/sigstore</p>
			<p>Before we test the image pulls, we must implement the public key that's used by Podman to verify the signatures. This public key must be stored in the host that pulls the image and belongs to the key pair that's used to sign the image. </p>
			<p>The configuration file that's used to define the public key's path is <strong class="source-inline">/etc/containers/policy.json</strong>.</p>
			<p>The following code shows the <strong class="source-inline">/etc/containers/policy.json</strong> file with a custom configuration <a id="_idIndexMarker1007"/>for the registry's <strong class="source-inline">localhost:5000</strong>:</p>
			<p class="source-code">{</p>
			<p class="source-code">    "default": [</p>
			<p class="source-code">        {</p>
			<p class="source-code">            "type": "insecureAcceptAnything"</p>
			<p class="source-code">        }</p>
			<p class="source-code">    ],</p>
			<p class="source-code">    "transports": {</p>
			<p class="source-code">        "docker": {</p>
			<p class="source-code">            "localhost:5000": [</p>
			<p class="source-code">                {</p>
			<p class="source-code">                    "type": "signedBy",</p>
			<p class="source-code">                    "keyType": "GPGKeys",</p>
			<p class="source-code">                    "keyPath": "/tmp/pubkey.gpg"</p>
			<p class="source-code">                }</p>
			<p class="source-code">            ]</p>
			<p class="source-code">        },</p>
			<p class="source-code">        "docker-daemon": {</p>
			<p class="source-code">            "": [</p>
			<p class="source-code">                {</p>
			<p class="source-code">                    "type": "insecureAcceptAnything"</p>
			<p class="source-code">                }</p>
			<p class="source-code">            ]</p>
			<p class="source-code">        }</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>To verify the signatures of images that have been pulled from <strong class="source-inline">localhost:5000</strong>, we can use a public key that's stored in the path defined by the <strong class="source-inline">keyPath</strong> field. The public key must exist in the defined path and be readable by Podman. </p>
			<p>If we need <a id="_idIndexMarker1008"/>to extract the public key from the example key pair that was generated at the beginning of this section, we can use the following GPG command:</p>
			<p class="source-code">$ gpg --armor --export foobar@example.com &gt; /tmp/pubkey.gpg</p>
			<p>Now, we are ready to test the image pull and verify its signature:</p>
			<p class="source-code">$ <strong class="bold">podman pull --tls-verify=false localhost:5000/custom_httpd</strong></p>
			<p class="source-code">Getting image source signatures</p>
			<p class="source-code">Checking if image destination supports signatures</p>
			<p class="source-code">Copying blob 23fdb56daf15 skipped: already exists  </p>
			<p class="source-code">Copying blob d4f13fad8263 skipped: already exists  </p>
			<p class="source-code">Copying blob 96b0fdd0552f done  </p>
			<p class="source-code">Copying config 569b015109 done  </p>
			<p class="source-code">Writing manifest to image destination</p>
			<p class="source-code">Storing signatures</p>
			<p class="source-code">569b015109d457ae5fabb969fd0dc3cce10a3e6683ab60dc10505fc2d68 e769f</p>
			<p>The image was successfully pulled into the local store after signature verification using the public key provided.</p>
			<p>Now, let's see how Podman behaves when it is unable to correctly verify the signature.</p>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor214"/>Testing signature verification failures</h2>
			<p>What if we make the sigstore unavailable? Will Podman still succeed in pulling the image if it's <a id="_idIndexMarker1009"/>unable to verify the signature? Let's try to stop the local httpd server that exposes the sigstore:</p>
			<p class="source-code"># podman stop sigstore_server</p>
			<p>Before pulling it again, let's remove the previously cached image to avoid false positives:</p>
			<p class="source-code">$ podman rmi localhost:5000/custom_httpd</p>
			<p>Now, we can try to pull the image again:</p>
			<p class="source-code">$ <strong class="bold">podman pull --tls-verify=false localhost:5000/custom_httpd</strong></p>
			<p class="source-code">Trying to pull localhost:5000/custom_httpd:latest...</p>
			<p class="source-code">WARN[0000] failed, retrying in 1s ... (1/3). Error: Source image rejected: Get "http://localhost:8080/custom_httpd@sha256=573c1eb93857c0169a606f1820271b143ac5073456f844255c3c7a9 e308bf639/signature-1": dial tcp [::1]:8080: connect: connection refused </p>
			<p class="source-code">WARN[0001] failed, retrying in 1s ... (2/3). Error: Source image rejected: Get "http://localhost:8080/custom_httpd@sha256=573c1eb93857c0169a606f1820271b143ac5073456f844255c3c7a9 e308bf639/signature-1": dial tcp [::1]:8080: connect: connection refused </p>
			<p class="source-code">WARN[0002] failed, retrying in 1s ... (3/3). Error: Source image rejected: Get "http://localhost:8080/custom_httpd@sha256=573c1eb93857c0169a606f1820271b143ac5073456f844255c3c7a9 e308bf639/signature-1": dial tcp [::1]:8080: connect: connection refused </p>
			<p class="source-code">Error: Source image rejected: Get "http://localhost:8080/custom_httpd@sha256=573c1eb93857c0169a606f1820271b143ac5073456f 844255c3c7a9e308bf639/signature-1": dial tcp [::1]:8080: connect: connection refused</p>
			<p>The preceding error demonstrates that Podman is trying to connect to the web server that exposes the sigstore and failed. This error blocked the whole image pull process.</p>
			<p>A different error occurs when the public key we use to verify the signature is not valid or not part of the key pair that was used to sign the image. To test this, let's replace the public key with another one from a different key pair – in this example, the public Fedora 34 RPM-GPG key, which has been taken from the <strong class="source-inline">/etc/pki/rpm-gpg</strong> directory (any other public key can be used):</p>
			<p class="source-code">$ mv /tmp/pubkey.gpg /tmp/pubkey.gpg.bak </p>
			<p class="source-code">$ cp /etc/pki/rpm-gpg/RPM-GPG-KEY-fedora-34-x86_64 \</p>
			<p class="source-code">     /tmp/pubkey.gpg</p>
			<p>The previously <a id="_idIndexMarker1010"/>stopped httpd server must be restarted; we want to make the signatures available and focus on the wrong public key error:</p>
			<p class="source-code"># podman start sigstore_server</p>
			<p>Now, we can pull the image again and inspect the generated errors:</p>
			<p class="source-code">$ <strong class="bold">podman pull --tls-verify=false localhost:5000/custom_httpd</strong></p>
			<p class="source-code">Trying to pull localhost:5000/custom_httpd:latest...</p>
			<p class="source-code">Error: Source image rejected: Invalid GPG signature: gpgme.Signature{Summary:128, Fingerprint:"2EA4850C32D29DA22B7659FEC38D92C0F18764AC", Status:gpgme.Error{err:0x9}, Timestamp:time.Time{wall:0x0, ext:63777026489, loc:(*time.Location)(0x560e17e5d680)}, ExpTimestamp:time.Time{wall:0x0, ext:62135596800, loc:(*time.Location)(0x560e17e5d680)}, WrongKeyUsage:false, PKATrust:0x0, ChainModel:false, Validity:0, ValidityReason:error(nil), PubkeyAlgo:1, HashAlgo:8}</p>
			<p>Here, Podman generates an error that's caused by an invalid GPG signature, which is correct since the public key that's being used does not belong to the correct key pair.</p>
			<p class="callout-heading">Important</p>
			<p class="callout">Do not forget to restore the valid public key before proceeding with the following examples.</p>
			<p>Podman can <a id="_idIndexMarker1011"/>manage multiple registries and sigstores, and also offers dedicated commands to help you customize security policies, as we'll see in the next subsection.</p>
			<h2 id="_idParaDest-215"><a id="_idTextAnchor215"/>Managing keys with Podman image trust commands </h2>
			<p>It is possible to edit the <strong class="source-inline">/etc/containers/policy.json</strong> file and modify its JSON objects to add or <a id="_idIndexMarker1012"/>remove configurations <a id="_idIndexMarker1013"/>for dedicated registries. However, manual editing can be prone to errors and hard to automate.</p>
			<p>Alternatively, we can use the <strong class="source-inline">podman image trust</strong> command to dump or modify the current configuration.</p>
			<p>The following code shows how to print the current configuration with the <strong class="source-inline">podman image trust show</strong> command:</p>
			<p class="source-code">$ </p>
			<p class="source-code">default         accept                                         </p>
			<p class="source-code">localhost:5000  signedBy                foobar@example.com  http://localhost:8080</p>
			<p class="source-code">                insecureAcceptAnything                         http://localhost:8080</p>
			<p>It is also possible to configure new trusts. For example, we can add the Red Hat public GPG key to check the signature of UBI images.</p>
			<p>First, we need to download the Red Hat public key:</p>
			<p class="source-code">$ sudo wget -O /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat \ </p>
			<p class="source-code">  https://www.redhat.com/security/data/fd431d51.txt</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Red Hat's product signing keys, including the one that was used in this example, can be found at <a href="https://access.redhat.com/security/team/key">https://access.redhat.com/security/team/key</a>.</p>
			<p>After downloading <a id="_idIndexMarker1014"/>the key, we must configure <a id="_idIndexMarker1015"/>the image trust for UBI 8 images that have been pulled from <em class="italic">registry.access.redhat.com</em> using the <strong class="source-inline">podman image trust set</strong> command:</p>
			<p class="source-code">$ sudo podman image trust set -f /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat registry.access.redhat.com/ubi8</p>
			<p>After running the preceding command, the <strong class="source-inline">/etc/containers/policy.json</strong> file will change, as follows:</p>
			<p class="source-code">{</p>
			<p class="source-code">    "default": [</p>
			<p class="source-code">        {</p>
			<p class="source-code">            "type": "insecureAcceptAnything"</p>
			<p class="source-code">        }</p>
			<p class="source-code">    ],</p>
			<p class="source-code">    "transports": {</p>
			<p class="source-code">        "docker": {</p>
			<p class="source-code">            "localhost:5000": [</p>
			<p class="source-code">                {</p>
			<p class="source-code">                    "type": "signedBy",</p>
			<p class="source-code">                    "keyType": "GPGKeys",</p>
			<p class="source-code">                    "keyPath": "/tmp/pubkey.gpg"</p>
			<p class="source-code">                }</p>
			<p class="source-code">            ],</p>
			<p class="source-code">            "registry.access.redhat.com/ubi8": [</p>
			<p class="source-code">                {</p>
			<p class="source-code">                    "type": "signedBy",</p>
			<p class="source-code">                    "keyType": "GPGKeys",</p>
			<p class="source-code">                    "keyPath": "/etc/pki/rpm-gpg/RPM-GPG-KEY-redhat"</p>
			<p class="source-code">                }</p>
			<p class="source-code">            ]</p>
			<p class="source-code">        },</p>
			<p class="source-code">        "docker-daemon": {</p>
			<p class="source-code">            "": [</p>
			<p class="source-code">                {</p>
			<p class="source-code">                    "type": "insecureAcceptAnything"</p>
			<p class="source-code">                }</p>
			<p class="source-code">            ]</p>
			<p class="source-code">        }</p>
			<p class="source-code">    }</p>
			<p>Note that <a id="_idIndexMarker1016"/>the entry that's related <a id="_idIndexMarker1017"/>to <em class="italic">registry.access.redhat.com/ubi8</em> and the public key that was used to verify the image signatures have been added to the file. </p>
			<p>To complete the configuration, we need to add the Red Hat sigstore configuration to the <strong class="source-inline">/etc/containers/registries.d/default.yaml</strong> configuration file:</p>
			<p class="source-code">docker:</p>
			<p class="source-code">  registry.access.redhat.com:</p>
			<p class="source-code">    sigstore: https://access.redhat.com/webassets/docker/content/sigstore</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">It is possible to create custom registry configuration files for different providers in the <strong class="source-inline">/etc/containers/registries.d</strong> folder. For example, the preceding example could be defined in a dedicated <strong class="source-inline">/etc/containers/registries.d/redhat.yaml</strong> file. This allows you to easily maintain and version registry sigstore configurations.</p>
			<p>From now on, every time a UBI8 image is pulled from <em class="italic">registry.access.redhat.com</em>, its signature will be pulled from the Red Hat sigstore and validated using the provided public key.</p>
			<p>So far, we have <a id="_idIndexMarker1018"/>looked at examples of <a id="_idIndexMarker1019"/>managing keys concerning Podman, but it is also possible to manage signature verification with Skopeo. In the next subsection, we are going to look at some basic examples.</p>
			<h2 id="_idParaDest-216"><a id="_idTextAnchor216"/>Managing signatures with Skopeo</h2>
			<p>We can verify an <a id="_idIndexMarker1020"/>image signature using Skopeo when <a id="_idIndexMarker1021"/>we're pulling an image from a valid transport.</p>
			<p>The following example uses the <strong class="source-inline">skopeo copy</strong> command to pull the image from our registry to the local store. This command has the same effects as using a <strong class="source-inline">podman pull</strong> command but allows more control over the source and destination transports:</p>
			<p class="source-code">$ skopeo copy --src-tls-verify=false \</p>
			<p class="source-code">  docker://localhost:5000/custom_httpd \</p>
			<p class="source-code">  containers-storage:localhost:5000/custom_httpd</p>
			<p>Skopeo does not need any further configuration since the previously modified configuration files already define the sigstore and public key path.</p>
			<p>We can also use Skopeo to sign an image before copying it to a transport:</p>
			<p class="source-code">$ sudo GNUPGHOME=$HOME/.gnupg skopeo copy \</p>
			<p class="source-code">   --dest-tls-verify=false \</p>
			<p class="source-code">   --sign-by foobar@example.com \</p>
			<p class="source-code">   containers-storage:localhost:5000/custom_httpd \</p>
			<p class="source-code">   docker://localhost:5000/custom_httpd</p>
			<p>Once again, the configuration files that are used by Podman are still valid for Skopeo, which uses the same sigstore to write the signatures and the same GPG store to retrieve the key that's used to generate the signature.</p>
			<p>In this section, we <a id="_idIndexMarker1022"/>learned how to verify image signatures and a<a id="_idIndexMarker1023"/>void potential MITM attacks. In the next section, we'll shift focus and learn how to execute the container runtime by customizing Linux kernel capabilities.</p>
			<h1 id="_idParaDest-217"><a id="_idTextAnchor217"/>Customizing Linux kernel capabilities </h1>
			<p>Capabilities are features that were introduced in Linux kernel 2.2 with the purpose of splitting elevated <a id="_idIndexMarker1024"/>privileges into single units that can be arbitrarily assigned to a process or thread.</p>
			<p>Instead of running a process as a fully privileged instance with effective UID 0, we can assign a limited subset of specific capabilities to an unprivileged process. By providing more granular control over the security context of the process's execution, this approach helps mitigate potential attack tactics.</p>
			<p>Before we discuss the capabilities of containers, let's recap on how they work in a Linux system so that we understand their inner logic.</p>
			<h2 id="_idParaDest-218"><a id="_idTextAnchor218"/>Capabilities quickstart guide</h2>
			<p>Capabilities are associated with the file executables using extended attributes (see <strong class="source-inline">man xattr</strong>) and are <a id="_idIndexMarker1025"/>automatically inherited by the process that's executed with an <strong class="source-inline">execve()</strong> system call. </p>
			<p>The list of available capabilities is quite large and still growing; it includes very specific actions that can be performed by a thread. Some basic examples are as follows:</p>
			<ul>
				<li><strong class="bold">CAP_CHOWN</strong>: This capability <a id="_idIndexMarker1026"/>allows a thread to modify a file's UID and GID.</li>
				<li><strong class="bold">CAP_KILL</strong>: This capability allows <a id="_idIndexMarker1027"/>you to bypass the permission checks to send a signal to a process.</li>
				<li><strong class="bold">CAP_MKNOD</strong>: This capability <a id="_idIndexMarker1028"/>allows you to create a special file with the <strong class="source-inline">mknod()</strong> syscall.</li>
				<li><strong class="bold">CAP_NET_ADMIN</strong>: This capability allows you to operate various privileged actions on the <a id="_idIndexMarker1029"/>system's network configuration, including changing the interface configuration, enabling/disabling promiscuous mode for an interface, editing routing tables, and enabling/disabling multicasting.</li>
				<li><strong class="bold">CAP_NET_RAW</strong>: This capability allows a thread to use RAW and PACKET sockets. This capability <a id="_idIndexMarker1030"/>can be used by programs such as ping to send ICMP packets without the need for elevated privileges.</li>
				<li><strong class="bold">CAP_SYS_CHROOT</strong>: This <a id="_idIndexMarker1031"/>capability allows you to use the <strong class="source-inline">chroot()</strong> syscall and change mount namespaces with the <strong class="source-inline">setns()</strong> syscall.</li>
				<li><strong class="bold">CAP_DAC_OVERRIDE</strong>: This <a id="_idIndexMarker1032"/>capability allows you to bypass <strong class="bold">discretionary access control</strong> (<strong class="bold">DAC</strong>) checks for file read, write, and <a id="_idIndexMarker1033"/>execution.</li>
			</ul>
			<p>For more details and an extensive list of available capabilities, see the relevant man page (<strong class="source-inline">man capabilities</strong>).</p>
			<p>To assign a <a id="_idIndexMarker1034"/>capability to an executable, we can use the <strong class="source-inline">setcap</strong> command, as shown in the following example, where <strong class="source-inline">CAP_NET_ADMIN</strong> and <strong class="source-inline">CAP_NET_RAW</strong> are being permitted in the <strong class="source-inline">/usr/bin/ping</strong> executable:</p>
			<p class="source-code">$ sudo setcap 'cap_net_admin,cap_net_raw+p' /usr/bin/ping</p>
			<p>The '<em class="italic">+p</em>' flag in the preceding command indicates that the capabilities have been set to <em class="italic">Permitted</em>.</p>
			<p>To inspect the capabilities of a file, we can use the <strong class="source-inline">getcap</strong> command:</p>
			<p class="source-code">$ getcap /usr/bin/ping</p>
			<p class="source-code">/usr/bin/ping cap_net_admin,cap_net_raw=p</p>
			<p>See <strong class="source-inline">man getcap</strong> and <strong class="source-inline">man setcap</strong> for more details about these utilities.</p>
			<p>We can inspect the active capabilities of a running process by looking at the <strong class="source-inline">/proc/&lt;PID&gt;/status</strong> file. In the following code, we are launching a <strong class="source-inline">ping</strong> command after setting the <strong class="source-inline">CAP_NET_ADMIN</strong> and <strong class="source-inline">CAP_NET_RAW</strong> capabilities. We want to launch the process in the background and check its current capabilities:</p>
			<p class="source-code">$ ping example.com &gt; /dev/null 2&gt;&amp;1 &amp;</p>
			<p class="source-code">$ grep 'Cap.*' /proc/$(pgrep ping)/status</p>
			<p class="source-code">CapInh: 0000000000000000</p>
			<p class="source-code">CapPrm: 0000000000003000</p>
			<p class="source-code">CapEff: 0000000000000000</p>
			<p class="source-code">CapBnd: 000000ffffffffff</p>
			<p class="source-code">CapAmb: 0000000000000000</p>
			<p>Here, we are interested in evaluating the bitmap in the <strong class="source-inline">CapPrm</strong> field, which represents the permitted capabilities. To get a user-friendly value, we can use the <strong class="source-inline">capsh</strong> command to decode the bitmap hex value:</p>
			<p class="source-code">$ capsh --decode=0000000000003000</p>
			<p class="source-code">0x0000000000003000=cap_net_admin,cap_net_raw</p>
			<p>The result is similar to the output of the <strong class="source-inline">getcap</strong> command in the <strong class="source-inline">/usr/bin/ping</strong> file, demonstrating <a id="_idIndexMarker1035"/>that executing the command propagated the file's permitted capabilities to its process instance. </p>
			<p>For a full list of the constants that were used to set the bitmaps, as well as their capabilities, see the following kernel header file: <a href="https://github.com/torvalds/linux/blob/master/include/uapi/linux/capability.h">https://github.com/torvalds/linux/blob/master/include/uapi/linux/capability.h</a>.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Distributions such as RHEL and CentOS use the preceding configuration to allow the ping to send ICMP packets with access from all users without them being executed as privileged processes with <em class="italic">setuid 0</em>. This is an insecure approach where an attacker could leverage a vulnerability or bug in the executable to escalate privileges and gain control of the system.</p>
			<p class="callout">Fedora introduced a new and more secure approach in version 31 that's based on using the <strong class="source-inline">net.ipv4.ping_group_range</strong> Linux kernel parameter. By setting an extensive range that covers all system groups, this parameter allows users to send ICMP packets without the need to enable the <strong class="source-inline">CAP_NET_ADMIN</strong> and <strong class="source-inline">CAP_NET_RAW</strong> capabilities.</p>
			<p class="callout">For more details, see the following wiki page from the Fedora Project: <a href="https://fedoraproject.org/wiki/Changes/EnableSysctlPingGroupRange">https://fedoraproject.org/wiki/Changes/EnableSysctlPingGroupRange</a>.</p>
			<p>Now that we've <a id="_idIndexMarker1036"/>provided a high-level description of the Linux kernel's capabilities, let's learn how they are applied to containers.</p>
			<h2 id="_idParaDest-219"><a id="_idTextAnchor219"/>Capabilities in containers</h2>
			<p>Capabilities can be applied inside containers to allow targeted actions to take place. By default, Podman <a id="_idIndexMarker1037"/>runs containers using a set of Linux kernel capabilities that are defined in the <strong class="source-inline">/usr/share/containers/containers.conf</strong> file. At the time of writing, the following capabilities are enabled inside this file:</p>
			<p class="source-code">default_capabilities = [</p>
			<p class="source-code">    "CHOWN",</p>
			<p class="source-code">    "DAC_OVERRIDE",</p>
			<p class="source-code">    "FOWNER",</p>
			<p class="source-code">    "FSETID",</p>
			<p class="source-code">    "KILL",</p>
			<p class="source-code">    "NET_BIND_SERVICE",</p>
			<p class="source-code">    "SETFCAP",</p>
			<p class="source-code">    "SETGID",</p>
			<p class="source-code">    "SETPCAP",</p>
			<p class="source-code">    "SETUID",</p>
			<p class="source-code">    "SYS_CHROOT"</p>
			<p class="source-code">]</p>
			<p>We can run a simple test to verify that those capabilities have been effectively applied to a process running inside a container. For this test, we will use the official Nginx image:</p>
			<p class="source-code">$ <strong class="bold">podman run -d --name cap_test docker.io/library/nginx</strong></p>
			<p class="source-code">$ <strong class="bold">podman exec -it cap_test sh -c 'grep Cap /proc/1/status'</strong></p>
			<p class="source-code">CapInh: 00000000800405fb</p>
			<p class="source-code">CapPrm: 00000000800405fb</p>
			<p class="source-code">CapEff: 00000000800405fb</p>
			<p class="source-code">CapBnd: 00000000800405fb</p>
			<p class="source-code">CapAmb: 0000000000000000</p>
			<p>Here, we have <a id="_idIndexMarker1038"/>extracted the current capabilities from the parent Nginx process (running with PID 1 inside the container). Now, we can check the bitmap with the <strong class="source-inline">capsh</strong> utility:</p>
			<p class="source-code">$ <strong class="bold">capsh --decode=00000000800405fb</strong></p>
			<p class="source-code">0x00000000800405fb=cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_sys_chroot,cap_setfcap</p>
			<p>The preceding list of capabilities is the same as the list that was defined in the default Podman configuration. Note that the capabilities are applied in both rootless and rootful mode.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you're curious, the capabilities for the containerized process(es) are set up by the container runtime, which is either <strong class="source-inline">runc</strong> or <strong class="source-inline">crun</strong>, based on the distribution.</p>
			<p>Now that we know how capabilities are configured and applied inside containers, let's learn how to customize a container's capabilities.</p>
			<h2 id="_idParaDest-220"><a id="_idTextAnchor220"/>Customizing a container's capabilities</h2>
			<p>We can add or <a id="_idIndexMarker1039"/>drop capabilities either at runtime or statically.</p>
			<p>To statically change the default capabilities, we can simply edit the <em class="italic">default_capabilities</em> field in the <strong class="source-inline">/usr/share/containers/containers.conf</strong> file and add or remove them according to our desired results.</p>
			<p>To modify capabilities at runtime, we can use the <strong class="source-inline">–cap-add</strong> and <strong class="source-inline">–cap-drop</strong> options, both of which are provided by the <strong class="source-inline">podman run</strong> command.</p>
			<p>The following code removes the <strong class="source-inline">CAP_DAC_OVERRIDE</strong> capability from a container:</p>
			<p class="source-code">$ podman run -d --name cap_test2<strong class="bold"> --cap-drop=DAC_OVERRIDE </strong>docker.io/library/nginx</p>
			<p>If we look at the capability bitmaps again, we will see that they were updated accordingly:</p>
			<p class="source-code">$ <strong class="bold">podman exec cap_test2 sh -c 'grep Cap /proc/1/status'</strong></p>
			<p class="source-code">CapInh: 00000000800405f9</p>
			<p class="source-code">CapPrm: 00000000800405f9</p>
			<p class="source-code">CapEff: 00000000800405f9</p>
			<p class="source-code">CapBnd: 00000000800405f9</p>
			<p class="source-code">CapAmb: 0000000000000000</p>
			<p class="source-code">$ <strong class="bold">capsh --decode=00000000800405f9</strong></p>
			<p class="source-code">0x00000000800405f9=cap_chown,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_sys_chroot,cap_setfcap</p>
			<p>It is possible to pass the <strong class="source-inline">--cap-add</strong> and <strong class="source-inline">--cap-drop</strong> options multiple times:</p>
			<p class="source-code">$ podman run -d --name cap_test3 \</p>
			<p class="source-code"><strong class="bold">   --cap-drop=KILL \</strong></p>
			<p class="source-code"><strong class="bold">   --cap-drop=DAC_OVERRIDE \</strong></p>
			<p class="source-code"><strong class="bold">   --cap-add=NET_RAW \</strong></p>
			<p class="source-code"><strong class="bold">   --cap-add=NET_ADMIN \</strong></p>
			<p class="source-code">   docker.io/library/nginx</p>
			<p>When we're dealing with capabilities, we must be careful while dropping a default capability. The following <a id="_idIndexMarker1040"/>code shows an error in the Nginx container when dropping the <strong class="source-inline">CAP_CHOWN</strong> capability:</p>
			<p class="source-code">$ <strong class="bold">podman run --name cap_test4 \</strong></p>
			<p class="source-code"><strong class="bold">  --cap-drop=CHOWN \</strong></p>
			<p class="source-code"><strong class="bold">  docker.io/library/nginx</strong></p>
			<p class="source-code">/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration</p>
			<p class="source-code">/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/</p>
			<p class="source-code">/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh</p>
			<p class="source-code">10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf</p>
			<p class="source-code">10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf</p>
			<p class="source-code">/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh</p>
			<p class="source-code">/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh</p>
			<p class="source-code">/docker-entrypoint.sh: Configuration complete; ready for start up</p>
			<p class="source-code">2022/01/06 23:19:39 [emerg] 1#1: chown("/var/cache/nginx/client_temp", 101) failed (1: Operation not permitted)</p>
			<p class="source-code">nginx: [emerg] chown("/var/cache/nginx/client_temp", 101) failed (1: Operation not permitted)</p>
			<p>Here, the container fails. From the output, we can see that the Nginx process was unable to show the <strong class="source-inline">/var/cache/nginx/client_temp</strong> directory. This is a direct consequence of the <strong class="source-inline">CAP_CHOWN</strong> capability being removed.</p>
			<p>Not all capabilities can be applied to rootless containers. For example, if we try to apply the <strong class="source-inline">CAP_MKNOD</strong> capability to a rootless container, any attempt to create a special file inside a rootless container won't be allowed by the kernel:</p>
			<p class="source-code">$ <strong class="bold">podman run -it --cap-add=MKNOD \</strong></p>
			<p class="source-code"><strong class="bold">  docker.io/library/busybox /bin/sh</strong></p>
			<p class="source-code">/ # mkdir -p /test/dev</p>
			<p class="source-code">/ # mknod -m 666 /test/dev/urandom c 1 8</p>
			<p class="source-code">mknod: /test/dev/urandom: Operation not permitted</p>
			<p>Instead, if we <a id="_idIndexMarker1041"/>run the container with elevated root privileges, the capability can be assigned successfully:</p>
			<p class="source-code"># <strong class="bold">podman run -it --cap-add=MKNOD \</strong></p>
			<p class="source-code"><strong class="bold">  docker.io/library/busybox /bin/sh</strong></p>
			<p class="source-code">/ # mkdir -p /test/dev</p>
			<p class="source-code">/ # mknod -m 666 /test/dev/urandom c 1 8</p>
			<p class="source-code">/ # stat /test/dev/urandom</p>
			<p class="source-code">File: /test/dev/urandom</p>
			<p class="source-code">  Size: 0          Blocks: 0          IO Block: 4096   character special file</p>
			<p class="source-code">Device: 31h/49d Inode: 530019      Links: 1     Device type: 1,8</p>
			<p class="source-code">Access: (0666/crw-rw-rw-)  Uid: (    0/    root)   Gid: (    0/    root)</p>
			<p class="source-code">Access: 2022-01-06 23:50:06.056650747 +0000</p>
			<p class="source-code">Modify: 2022-01-06 23:50:06.056650747 +0000</p>
			<p class="source-code">Change: 2022-01-06 23:50:06.056650747 +0000</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Generally, adding capabilities to containers implies enlarging the potential attack surface that a malicious attacker could use. If it's not necessary, it is a good practice to keep the default capabilities and drop the unwanted ones once the potential side effects have been analyzed.</p>
			<p>In this section, we learned how to manage capabilities inside containers. However, capabilities are not the <a id="_idIndexMarker1042"/>only security aspect to consider when you're securing containers. SELinux, as we will learn in the next section, has a crucial role in guaranteeing container isolation.</p>
			<h1 id="_idParaDest-221"><a id="_idTextAnchor221"/>SELinux interaction with containers</h1>
			<p>In this section, we <a id="_idIndexMarker1043"/>will discuss SELinux policies and <a id="_idIndexMarker1044"/>introduce <strong class="bold">Udica</strong>, a tool that's used to <a id="_idIndexMarker1045"/>generate SELinux profiles for containers.</p>
			<p>SELinux works directly in kernel space and manages object isolation while following a least-privilege model that contains a series of <strong class="bold">policies</strong> that can handle enforcing or exceptions. To define these <a id="_idIndexMarker1046"/>objects, SELinux uses labels that define <strong class="bold">types</strong>. By default, SELinux works in <strong class="bold">Enforcing</strong> mode, denying access to resources with a series of exceptions defined by policies. To disable Enforcing mode, SELinux can <a id="_idIndexMarker1047"/>be put in <strong class="bold">Permissive</strong> mode, where violations are only audited, without them being blocked.</p>
			<p class="callout-heading">Security Alert</p>
			<p class="callout">As we mentioned previously, switching SELinux to Permissive mode or completely disabling it is <em class="italic">not a good practice</em> as it opens you up to potential security threats. Instead of doing that, users should create custom policies to manage the necessary exceptions.</p>
			<p>By default, SELinux uses a <strong class="bold">targeted</strong> policy type, which tries to target and confine specific object types (processes, files, devices, and so on) using a set of predefined policies.</p>
			<p>SELinux allows different kinds <a id="_idIndexMarker1048"/>of access control. They can be summarized as follows:</p>
			<ul>
				<li><strong class="bold">Type Enforcement</strong> (<strong class="bold">TE</strong>): This controls access to resources according to process <a id="_idIndexMarker1049"/>and file types. This is the <a id="_idIndexMarker1050"/>main use case of SELinux access control.</li>
				<li><strong class="bold">Role-Based Access Control</strong> (<strong class="bold">RBAC</strong>): This <a id="_idIndexMarker1051"/>controls access <a id="_idIndexMarker1052"/>to resources using SELinux users (which can be mapped to real system users) and their associated SELinux roles.</li>
				<li><strong class="bold">Multi-Level Security</strong> (<strong class="bold">MLS</strong>): This grants all processes with the same sensitivity <a id="_idIndexMarker1053"/>level read/write <a id="_idIndexMarker1054"/>access to the resources.</li>
				<li><strong class="bold">Multi-Category Security</strong> (<strong class="bold">MCS</strong>): This controls access using <strong class="bold">categories</strong>, which are plain <a id="_idIndexMarker1055"/>text labels that are applied to resources. Categories are used to create compartments <a id="_idIndexMarker1056"/>of objects, along with the other SELinux labels. Only processes that belong to the same category can access a given resource. In <a href="B17908_05_epub.xhtml#_idTextAnchor101"><em class="italic">Chapter 5</em></a>, <em class="italic">Implementing Storage for the Container's Data</em>, we discussed MCS and how we can map categories to resources that have been accessed by containers.</li>
			</ul>
			<p>With Type Enforcement, the <a id="_idIndexMarker1057"/>system files receive <a id="_idIndexMarker1058"/>labels called <strong class="bold">types</strong>, while <a id="_idIndexMarker1059"/>processes receive labels called <strong class="bold">domains</strong>. A process that belongs to a domain can be allowed to access a file <a id="_idIndexMarker1060"/>that belongs to a given type, and this access can be audited by SELinux.</p>
			<p>For example, according to SELinux, the Apache <strong class="source-inline">httpd</strong> process, which is labeled with the <strong class="source-inline">httpd_t</strong> domain, can access files or directories with <strong class="source-inline">httpd_sys_content_t</strong> labels.</p>
			<p>An SELinux-type policy is based on the following pattern: </p>
			<p class="source-code">POLICY DOMAIN TYPE:CLASS OPERATION;</p>
			<p>Here, <strong class="source-inline">POLICY</strong> is the kind of policy (<strong class="source-inline">allow</strong>, <strong class="source-inline">allowxperm</strong>, <strong class="source-inline">auditallow</strong>, <strong class="source-inline">neverallow</strong>, <strong class="source-inline">dontaudit</strong>, and so on), <strong class="source-inline">DOMAIN</strong> is the process domain, <strong class="source-inline">TYPE</strong> is the resource type context, <strong class="source-inline">CLASS</strong> is the object category (for example, <strong class="source-inline">file</strong>, <strong class="source-inline">dir</strong>, <strong class="source-inline">lnk_file</strong>, <strong class="source-inline">chr_file</strong>, <strong class="source-inline">blk_file</strong>, <strong class="source-inline">sock_file</strong>, or <strong class="source-inline">fifo_file</strong>), and <strong class="source-inline">OPERATION</strong> is a list of actions that are handled by the policy (for example, <strong class="source-inline">open</strong>, <strong class="source-inline">read</strong>, <strong class="source-inline">use</strong>, <strong class="source-inline">lock</strong>, <strong class="source-inline">getattr</strong>, or <strong class="source-inline">revc</strong>).</p>
			<p>The following example shows a basic <strong class="source-inline">allow</strong> rule:</p>
			<p class="source-code">allow myapp_t myapp_log_t:file { read_file_perms append_file_perms };</p>
			<p>In this example, the process that's running in the <strong class="source-inline">myapp_t</strong> domain is allowed to access files of the <strong class="source-inline">myapp_log_t</strong> type and perform the <strong class="source-inline">read_file_perms</strong> and <strong class="source-inline">append_file_perms</strong> actions.</p>
			<p>SELinux manages <a id="_idIndexMarker1061"/>policies in a modular fashion, allowing <a id="_idIndexMarker1062"/>you to dynamically load and unload policy modules without the need to recompile the whole policy set every time. Policies can be loaded and unloaded using the <strong class="source-inline">semodule</strong> utility, as shown in the following example, which shows an example of loading a custom policy:</p>
			<p class="source-code"># semodule -i custompolicy.pp</p>
			<p>The <strong class="source-inline">semodule</strong> utility can also be used to view all the loaded policies:</p>
			<p class="source-code"># semodule -l</p>
			<p>On Fedora, CentOS, RHEL, and derivate distributions, the current binary policy is installed under the <strong class="source-inline">/etc/selinux/targeted/policy</strong> directory in a file named <strong class="source-inline">polixy.XX</strong>, with <strong class="source-inline">XX</strong> representing the policy version.</p>
			<p>On the same distributions, container policies are defined inside the <strong class="source-inline">container-selinux</strong> package, which contains the already compiled SELinux module. The source code of the package is <a id="_idIndexMarker1063"/>available on GitHub if you wish to look at it in more detail: <a href="https://github.com/containers/container-selinux">https://github.com/containers/container-selinux</a>.</p>
			<p>By looking at the repository's content, we will find the three most important policy source files for developing any module:</p>
			<ul>
				<li><strong class="source-inline">container.fc</strong>: This file defines the files and directories that are bound to the types defined in the module.</li>
				<li><strong class="source-inline">container.te</strong>: This file defines the policy rules, attributes, and aliases.</li>
				<li><strong class="source-inline">container.if</strong>: This file defines the module interface. It contains a set of public macro functions that are exposed by the module.</li>
			</ul>
			<p>A process that's running inside a container is labeled with the <strong class="source-inline">container_t</strong> domain. It has read/write access to resources labeled with the <strong class="source-inline">container_file_t</strong> type context and read/execute access to resources labeled with the <strong class="source-inline">container_share_t</strong> type context.</p>
			<p>When a container is <a id="_idIndexMarker1064"/>executed, the <strong class="source-inline">podman</strong> process, as well as the <a id="_idIndexMarker1065"/>container runtime and the <strong class="source-inline">conmon</strong> process, run with the <strong class="source-inline">container_runtime_t</strong> domain type and are allowed to execute processes that transition only to specific types.  Those types are grouped in the <strong class="source-inline">container_domain</strong> attribute and can be inspected with the <strong class="source-inline">seinfo</strong> utility (installed with the <strong class="source-inline">setools-console</strong> package on Fedora), as shown in the following code:</p>
			<p class="source-code">$ <strong class="bold">seinfo -a container_domain -x</strong></p>
			<p class="source-code">Type Attributes: 1</p>
			<p class="source-code">   attribute container_domain;</p>
			<p class="source-code">container_engine_t</p>
			<p class="source-code">container_init_t</p>
			<p class="source-code">container_kvm_t</p>
			<p class="source-code">container_logreader_t</p>
			<p class="source-code">container_t</p>
			<p class="source-code">container_userns_t</p>
			<p class="source-code">spc_t</p>
			<p>The <strong class="source-inline">container_domain</strong> attribute is declared in the <strong class="source-inline">container.te</strong> source file in the <strong class="source-inline">container-policy</strong> repository <a id="_idIndexMarker1066"/>using the <strong class="bold">attribute</strong> keyword: </p>
			<p class="source-code">attribute container_domain;</p>
			<p class="source-code">attribute container_user_domain;</p>
			<p class="source-code">attribute container_net_domain;</p>
			<p>The preceding attributes are <a id="_idIndexMarker1067"/>mapped to the <strong class="source-inline">container_t</strong> type using a <strong class="source-inline">typeattribute</strong> declaration:</p>
			<p class="source-code">typeattribute container_t container_domain, container_net_domain, container_user_domain;</p>
			<p>Using this approach, SELinux guarantees process isolations across containers and between a container and its host. In this way, a process escaping the container (maybe exploiting a vulnerability) cannot access resources on the host or inside other containers.</p>
			<p>When a container is <a id="_idIndexMarker1068"/>created, the image's read-only layers, which <a id="_idIndexMarker1069"/>form the OverlayFS set of LowerDirs, are labeled with the <strong class="source-inline">container_ro_file_t</strong> type, which prevents the container from writing inside those directories. At the same time, MergedDir, which is the sum of LowerDirs and UpperDir, is writable and labeled as <strong class="source-inline">container_file_t</strong>.</p>
			<p>To prove this, let's run a <strong class="bold">rootful</strong> container with the <strong class="source-inline">c1</strong> and <strong class="source-inline">c2</strong> MCS categories: </p>
			<p class="source-code"># podman run -d --name selinux_test1 --security-opt label=level:s0:c1,c2 nginx</p>
			<p>Now, we can find all the files labeled as <strong class="source-inline">container_file_t:s0:c1,c2</strong> under the host filesystem:</p>
			<p class="source-code"># find /var/lib/containers/storage/overlay -type f -context '*container_file_t:s0:c1,c2*' -printf '%-50Z%p\n'</p>
			<p class="source-code">system_u:object_r:container_file_t:s0:c1,c2       /var/lib/containers/storage/overlay/4b147975bb5c336b10e71d21c49fe88ddb00d0569b77ddab1 d7737f80056677b/merged/lib/x86_64-linux-gnu/libreadline.so.8.1</p>
			<p class="source-code">system_u:object_r:container_file_t:s0:c1,c2       /var/lib/containers/storage/overlay/4b147975bb5c336b10e71d21c49fe88ddb00d0569b77ddab1 d7737f80056677b/merged/lib/x86_64-linux-gnu/libhistory.so.8.1</p>
			<p class="source-code">system_u:object_r:container_file_t:s0:c1,c2       /var/lib/containers/storage/overlay/4b147975bb5c336b10e71d21c49fe88ddb00d0569b77ddab1 d7737f80056677b/merged/lib/x86_64-linux-gnu/libexpat.so.1.6.12</p>
			<p class="source-code">system_u:object_r:container_file_t:s0:c1,c2       /var/lib/containers/storage/overlay/4b147975bb5c336b10e71d21c49fe88ddb00d0569b77ddab1 d7737f80056677b/merged/lib/udev/rules.d/96-e2scrub.rules</p>
			<p class="source-code">system_u:object_r:container_file_t:s0:c1,c2       /var/lib/containers/storage/overlay/4b147975bb5c336b10e71d21c49fe88ddb00d0569b77ddab1 d7737f80056677b/merged/lib/terminfo/r/rxvt-unicode-256color</p>
			<p class="source-code">system_u:object_r:container_file_t:s0:c1,c2       /var/lib/containers/storage/overlay/4b147975bb5c336b10e71d21c49fe88ddb00d0569b77ddab1 d7737f80056677b/merged/lib/terminfo/r/rxvt-unicode</p>
			<p class="source-code">[…output omitted...]</p>
			<p>As expected, the <strong class="source-inline">container_file_t</strong> label, which is associated with the <strong class="source-inline">c1</strong> and <strong class="source-inline">c2</strong> categories, is applied to all the files under the MergedDir container.</p>
			<p>At the same time, we <a id="_idIndexMarker1070"/>can demonstrate that the container's LowerDirs <a id="_idIndexMarker1071"/>are labeled as <strong class="source-inline">container_ro_file_t</strong>. First, we need to extract the container's LowerDirs list:</p>
			<p class="source-code"># <strong class="bold">podman inspect selinux_test1 \</strong></p>
			<p class="source-code"><strong class="bold">  --format '{{.GraphDriver.Data.LowerDir}}'</strong></p>
			<p class="source-code">/var/lib/containers/storage/overlay/9566cbcf1773eac59951c14c52156a6164db1b0d8026d015 e193774029db18a5/diff:/var/lib/containers/storage/overlay/24de59cced7931bbcc0c4a34d4369c15119a0b8b180f98a0434 fa76a6dfcd490/diff:/var/lib/containers/storage/overlay/1bb84245b98b7e861c91ed4319972ed3287bdd2ef02a8657c696 a76621854f3b/diff:/var/lib/containers/storage/overlay/97f26271fef21bda129ac431b5f0faa03ae0b2b50bda6af 969315308fc16735b/diff:/var/lib/containers/storage/overlay/768ef71c8c91e4df0aa1caf96764ceec999d7eb0aa584 e241246815c1fa85435/diff:/var/lib/containers/storage/overlay/2edcec3590a4ec7f40cf0743c15d78fb39d8326bc029073 b41ef9727da6c851f/diff</p>
			<p>The rightmost <a id="_idIndexMarker1072"/>directory represents the container's lowest <a id="_idIndexMarker1073"/>layer and is usually the base filesystem tree of the image. Let's inspect the type context of this directory:</p>
			<p class="source-code"># <strong class="bold">ls -alZ /var/lib/containers/storage/overlay/2edcec3590a4ec7f40 cf0743c15d78fb39d8326bc029073b41ef9727da6c851f/diff</strong></p>
			<p class="source-code">total 84</p>
			<p class="source-code">dr-xr-xr-x. 21 root root unconfined_u:object_r:container_ro_file_t:s0 4096 Jan  5 23:16 .</p>
			<p class="source-code">drwx------.  6 root root unconfined_u:object_r:container_ro_file_t:s0 4096 Jan  5 23:16 ..</p>
			<p class="source-code">drwxr-xr-x.  2 root root unconfined_u:object_r:container_ro_file_t:s0 4096 Dec 20 00:00 bin</p>
			<p class="source-code">drwxr-xr-x.  2 root root unconfined_u:object_r:container_ro_file_t:s0 4096 Dec 11 17:25 boot</p>
			<p class="source-code">drwxr-xr-x.  2 root root unconfined_u:object_r:container_ro_file_t:s0 4096 Dec 20 00:00 dev</p>
			<p class="source-code">drwxr-xr-x. 30 root root unconfined_u:object_r:container_ro_file_t:s0 4096 Dec 20 00:00 etc</p>
			<p class="source-code">drwxr-xr-x.  2 root root unconfined_u:object_r:container_ro_file_t:s0 4096 Dec 11 17:25 home</p>
			<p class="source-code">drwxr-xr-x.  8 root root unconfined_u:object_r:container_ro_file_t:s0 4096 Dec 20 00:00 lib</p>
			<p class="source-code">[...omitted output...]</p>
			<p>The preceding output also shows another interesting aspect: since the LowerDir layers are shared across multiple containers that use the same image, we won't find any MCS categories that have been applied here.</p>
			<p>Containers do not have read/write access to files or directories that are not labeled as <strong class="source-inline">container_file_t</strong>. Previously, we saw that it is possible to relabel those files by applying the <strong class="source-inline">:z</strong> suffix to mounted volumes or by manually relabeling them in advance before running the containers.</p>
			<p>However, relabeling <a id="_idIndexMarker1074"/>crucial directories such as <strong class="source-inline">/home</strong> or <strong class="source-inline">/var/logs</strong> is a <a id="_idIndexMarker1075"/>very bad idea since many other non-containerized processes won't be able to access them anymore.</p>
			<p>The only solution is to manually create custom policies that override the default behavior. However, this is too complex to manage in everyday use and production environments.</p>
			<p>Luckily, we can solve this limitation with a tool that generates custom SELinux security profiles for our containers: <strong class="bold">Udica</strong>.</p>
			<h2 id="_idParaDest-222"><a id="_idTextAnchor222"/>Introducing Udica</h2>
			<p>Udica is an open source project (<a href="https://github.com/containers/udica">https://github.com/containers/udica</a>) that was created by Lukas Vrabec, SELinux <a id="_idIndexMarker1076"/>evangelist and team leader of the SELinux and Security <a id="_idIndexMarker1077"/>Special Projects engineering teams at Red Hat.</p>
			<p>Udica aims to overcome the rigid policy limitations that were described previously by generating SELinux profiles for containers and allowing them to access resources that would normally be prevented with the common <strong class="source-inline">container_t</strong> domain.</p>
			<p>To install Udica on Fedora, simply run the following command:</p>
			<p class="source-code">$ sudo dnf install -y udica setools-console container-selinux</p>
			<p>On other distributions, Udica can be installed from its source by running the following commands:</p>
			<p class="source-code">$ sudo dnf install -y setools-console git container-selinux</p>
			<p class="source-code">$ git clone </p>
			<p class="source-code">$ cd udica &amp;&amp; sudo python3 ./setup.py install</p>
			<p>To demonstrate how Udica works, we are going to create a container that writes to the <strong class="source-inline">/var/log</strong> directory of the host, which is bind-mounted when the container is created. By default, the process with the <strong class="source-inline">container_t</strong> domain would not be able to write a directory labeled with the <strong class="source-inline">var_log_t</strong> type.</p>
			<p>The following script, which <a id="_idIndexMarker1078"/>has been executed inside the container, is an endless loop that writes a log line composed of the current date and a counter:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Chapter11/custom_logger/logger.sh</p>
			<p class="source-code">#!/bin/bash</p>
			<p class="source-code">set -euo pipefail</p>
			<p class="source-code">trap "echo Exited; exit;" SIGINT SIGTERM</p>
			<p class="source-code"># Run an endless loop writing a simple log entry with date</p>
			<p class="source-code">count=1</p>
			<p class="source-code">while true; do</p>
			<p class="source-code">echo "$(date +%y/%m/%d_%H:%M:%S) - Line #$count" | tee -a /var/log/custom.log</p>
			<p class="source-code">  count=$((count+1))</p>
			<p class="source-code">  sleep 2</p>
			<p class="source-code">done</p>
			<p>The preceding script uses the <strong class="source-inline">set -euo pipefail</strong> option, to exit immediately in case an error occurs, and the <strong class="source-inline">tee</strong> utility, to write both to standard output and the <strong class="source-inline">/var/log/custom.log</strong> file in append mode. The <strong class="source-inline">count</strong> variable increments on each loop cycle.</p>
			<p>The Dockerfile for this container is kept minimal – it just copies the logger script and executes it at container startup:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Chapter11/custom_logger/Dockerfile</p>
			<p class="source-code">FROM docker.io/library/fedora</p>
			<p class="source-code"># Copy the logger.sh script</p>
			<p class="source-code">COPY logger.sh /</p>
			<p class="source-code"># Exec the logger.sh script</p>
			<p class="source-code">CMD ["/logger.sh"]</p>
			<p class="callout-heading">Important</p>
			<p class="callout">The <strong class="source-inline">logger.sh</strong> script must be executed before the build so that it can be launched correctly at container startup.</p>
			<p>The container image is built with the name <strong class="source-inline">custom_logger</strong>:</p>
			<p class="source-code"># cd /Chapter11/custom_logger</p>
			<p class="source-code"># buildah build -t custom_logger .</p>
			<p>Now, it's time to test the container and see how it behaves. The <strong class="source-inline">/var/log</strong> directory is bind-mounted with <strong class="source-inline">rw</strong> permissions <a id="_idIndexMarker1079"/>to the container's <strong class="source-inline">/var/log</strong>, without this altering its type context. We should keep the execution in the foreground to see the immediate output:</p>
			<p class="source-code"># <strong class="bold">podman run -v /var/log:/var/log:rw \</strong></p>
			<p class="source-code"><strong class="bold">  --name custom_logger1 custom_logger</strong></p>
			<p class="source-code">tee: /var/log/custom.log: Permission denied</p>
			<p class="source-code">22/01/08_09:09:33 - Custom log event #1</p>
			<p>As expected, the script failed to write to the target file. We could fix this by changing the directory type context to <strong class="source-inline">container_file_t</strong> but, as we learned previously, this is a poor idea since it would prevent other processes from writing their logs.</p>
			<p>Instead, we can use Udica to generate a custom SELinux security profile for the container. In the following <a id="_idIndexMarker1080"/>code, the container specs are exported to a <strong class="source-inline">container.json</strong> file and then parsed by Udica to generate a custom profile called <em class="italic">custom_logger</em>:</p>
			<p class="source-code"># podman inspect custom_logger1 &gt; container.json</p>
			<p class="source-code"># udica -j container.json custom_logger</p>
			<p class="source-code">Policy custom_logger created!</p>
			<p class="source-code">Please load these modules using: </p>
			<p class="source-code"># semodule -i custom_logger.cil /usr/share/udica/templates/{base_container.cil,log_container.cil}</p>
			<p class="source-code">Restart the container with: "--security-opt label=type:custom_logger.process" parameter</p>
			<p>Once the profile has been generated, Udica outputs the instructions to configure the container. First, we need to load the new custom policy using the <strong class="source-inline">semodule</strong> utility. The generated file is in <strong class="bold">Common Intermediate Language</strong> (<strong class="bold">CIL</strong>) format, an intermediate policy <a id="_idIndexMarker1081"/>language for SELinux. Along with the generated CIL file, the example loads some Udica templates, <strong class="source-inline">/usr/share/udica/templates/base_container.cil</strong> and <strong class="source-inline">/usr/share/udica/templates/log_container.cil</strong>, whose rules are inherited in the custom container policy file.</p>
			<p>Let's load the modules using the suggested command:</p>
			<p class="source-code"># semodule -i custom_logger.cil /usr/share/udica/templates/{base_container.cil,log_container.cil}</p>
			<p>After loading the modules in SELinux, we are ready to run the container with the custom <strong class="source-inline">custom_logger.process</strong> label, passing it as an argument to the Podman <strong class="source-inline">--security-opt</strong> option. The other container option was kept identical, except for its name, which has been updated to <strong class="source-inline">custom_logger2</strong> to differentiate it from the previous instance:</p>
			<p class="source-code"># <strong class="bold">podman run -v /var/log:/var/log:rw \</strong></p>
			<p class="source-code"><strong class="bold">  --name custom_logger2 \</strong></p>
			<p class="source-code"><strong class="bold">  --security-opt label=type:custom_logger.process \</strong></p>
			<p class="source-code"><strong class="bold">  custom_logger</strong></p>
			<p class="source-code">22/01/08_09:05:19 - Line #1</p>
			<p class="source-code">22/01/08_09:05:21 - Line #2</p>
			<p class="source-code">22/01/08_09:05:23 - Line #3</p>
			<p class="source-code">22/01/08_09:05:25 - Line #5</p>
			<p class="source-code">[...Omitted output...]</p>
			<p>This time, the script successfully wrote to the <strong class="source-inline">/var/log/custom.log</strong> file thanks to the custom profile that <a id="_idIndexMarker1082"/>was generated with Udica.</p>
			<p>Note that the container processes are not running with the <strong class="source-inline">container_t</strong> domain, but with the new <strong class="source-inline">custom_logger.process</strong> superset, which includes additional rules on top of the default.</p>
			<p>We can confirm this by running the following command on the host:</p>
			<p class="source-code"># <strong class="bold">ps auxZ | grep 'custom_logger.process'</strong></p>
			<p class="source-code">unconfined_u:system_r:container_runtime_t:s0-s0:c0.c1023 root 26546 0.1  0.6 1365088 53768 pts/0 Sl+ 09:16   0:00 podman run -v /var/log:/var/log:rw --security-opt label=type:custom_logger.process custom_logger system_u:system_r:custom_logger.process:s0:c159,c258 root 26633 0.0  0.0 4180 3136 ? Ss 09:16   0:00 /bin/bash /logger.sh</p>
			<p class="source-code">system_u:system_r:custom_logger.process:s0:c159,c258 root 26881 0.0  0.0 2640 1104 ? S 09:18   0:00 sleep 2 </p>
			<p>Udica creates the custom policy by parsing the JSON spec file and looking for the container mount points, ports, and capabilities. Let's look at the content of the generated <strong class="source-inline">custom_logger.cil</strong> file from our example:</p>
			<p class="source-code">(block custom_logger</p>
			<p class="source-code">    (blockinherit container)</p>
			<p class="source-code">    (allow process process ( capability ( chown dac_override fowner fsetid kill net_bind_service setfcap setgid setpcap setuid sys_chroot ))) </p>
			<p class="source-code">    (blockinherit log_rw_container)</p>
			<p>The CIL language syntax is <a id="_idIndexMarker1083"/>beyond the scope of this book, but we still can notice some interesting things:</p>
			<ul>
				<li>The <em class="italic">custom_logger</em> profile is defined by a <strong class="source-inline">block</strong> statement.</li>
				<li>The <strong class="source-inline">allow</strong> rule enables the default capabilities for the container.</li>
				<li>The policy inherits the <strong class="source-inline">container</strong> and <strong class="source-inline">log_rw_container</strong> blocks with the <strong class="source-inline">blockinherit</strong> statements.</li>
			</ul>
			<p>The generated CIL file inherits the blocks that have been defined in the available Udica templates, each one focused on specific actions. On Fedora, the templates are installed via the <strong class="source-inline">container-selinux</strong> package and are available in the <strong class="source-inline">/usr/share/udica/templates/</strong> folder:</p>
			<p class="source-code"># ls -1 /usr/share/udica/templates/</p>
			<p class="source-code">base_container.cil</p>
			<p class="source-code">config_container.cil</p>
			<p class="source-code">home_container.cil</p>
			<p class="source-code">log_container.cil</p>
			<p class="source-code">net_container.cil</p>
			<p class="source-code">tmp_container.cil</p>
			<p class="source-code">tty_container.cil</p>
			<p class="source-code">virt_container.cil</p>
			<p class="source-code">x_container.cil</p>
			<p>The available templates are implemented for common scenarios, such as accessing log directories or user homes, or even for opening network ports. Among them, the <strong class="source-inline">base_container.cil</strong> template is always included by all the Udica-generated policies as the base building block that's used to generate the custom policies.</p>
			<p>According to the behavior of the container that's derived from the spec file, other templates are included. For example, the policy inherited the <strong class="source-inline">log_rw_container</strong> block from the <strong class="source-inline">log_container.cil</strong> template to let the custom logger container access the <strong class="source-inline">/var/log</strong> directory.</p>
			<p>Udica is a great tool for <a id="_idIndexMarker1084"/>addressing container isolation issues and helps administrators address SELinux confinement use cases by overcoming the complexity of writing rules manually.</p>
			<p>Generated security profiles can also be versioned inside a GitHub repository and reused for similar containers on different hosts.</p>
			<h1 id="_idParaDest-223"><a id="_idTextAnchor223"/>Summary</h1>
			<p>In this chapter, we learned how to develop and apply techniques to improve the overall security of our container-based service architecture. We learned how leveraging rootless containers and avoiding UID 0 can reduce the attack surface of our services. Then, we learned how to sign and trust container images to avoid MITM attacks. Finally, we went under the hood of a containers' tools and looked at the Linux kernel's capabilities and the SELinux subsystem, which can help us fine-tune various security aspects for our running containers.</p>
			<p>Now that we've done a deep dive into security, we are ready to move on to the next chapter, where we will take an advanced look at networking for containers.</p>
			<h1 id="_idParaDest-224"><a id="_idTextAnchor224"/>Further reading</h1>
			<p>For more information about the topics that were covered in this chapter, take a look at the following resources:</p>
			<ul>
				<li>MITRE ATT&amp;CK Container Matrix: <a href="https://attack.mitre.org/matrices/enterprise/containers/">https://attack.mitre.org/matrices/enterprise/containers/</a></li>
				<li>GNU Privacy Guard: <a href="https://gnupg.org/">https://gnupg.org/</a></li>
				<li>RFC4880 – OpenPGP standard: <a href="https://www.rfc-editor.org/info/rfc4880">https://www.rfc-editor.org/info/rfc4880</a></li>
				<li>Podman image signing tutorial: <a href="https://github.com/containers/podman/blob/main/docs/tutorials/image_signing.md">https://github.com/containers/podman/blob/main/docs/tutorials/image_signing.md</a></li>
				<li>Lukas Vrabec's blog: <a href="https://lukas-vrabec.com/">https://lukas-vrabec.com/</a></li>
				<li>CIL introduction and design principles: <a href="https://github.com/SELinuxProject/cl/wiki">https://github.com/SELinuxProject/cl/wiki</a></li>
				<li>Udica introduction on Red Hat's blog: <a href="https://www.redhat.com/en/blog/generate-selinux-policies-containers-with-udica">https://www.redhat.com/en/blog/generate-selinux-policies-containers-with-udica</a></li>
			</ul>
		</div>
	</body></html>